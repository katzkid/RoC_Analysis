{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33420fde",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d11cd5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d840881",
   "metadata": {},
   "source": [
    "## Display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c24af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for displaying ROC curves of multiple classifiers\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_connected_points(results_list, results_original_roc, name=\"All Classifiers\"):\n",
    "    \"\"\"\n",
    "    Creates a plot showing the performance of all classifiers as points,\n",
    "    and connects them with a line, sorted by FPR.\n",
    "\n",
    "    Args:\n",
    "        results_list: A list of dictionaries, where each dict contains 'fpr', 'tpr'.\n",
    "    \"\"\"\n",
    "    if not results_list:\n",
    "        print(\"No results to plot.\")\n",
    "        return\n",
    "\n",
    "    # Convert results to a pandas DataFrame for easy sorting\n",
    "    df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Sort the models by their False Positive Rate to create a left-to-right line\n",
    "    df_sorted = df.sort_values(by='fpr').reset_index(drop=True)\n",
    "    \n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot all the individual model points as a scatter plot\n",
    "    # This helps see the actual performance of each model\n",
    "    plt.scatter(df_sorted['fpr'], df_sorted['tpr'], c='black', marker='o', \n",
    "                alpha=0.6, s=100, zorder=3) # zorder=3 puts dots on top\n",
    "\n",
    "    # Plot the line connecting the points\n",
    "    plt.plot(df_sorted['fpr'], df_sorted['tpr'], color='red', lw=1.5,\n",
    "             alpha=0.8, label=f'{name} (AUC = {auc(df_sorted[\"fpr\"], df_sorted[\"tpr\"]):.2f})')\n",
    "    \n",
    "    #plot the original ROC curve\n",
    "    plt.plot(results_original_roc[\"fpr\"], results_original_roc[\"tpr\"], color='blue', \n",
    "             label=f'{results_original_roc[\"name\"]} (AUC = {results_original_roc[\"auc\"]:.2f})')\n",
    "\n",
    "    # Plot the \"no-skill\" line for reference\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Performance Path of All Trained Classifiers')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23b1ea",
   "metadata": {},
   "source": [
    "## Best ROC envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e350c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def get_best_roc_envelope(results_list, results_original_roc=None):\n",
    "    \"\"\"\n",
    "    Constructs the upper envelope of multiple ROC curves to find the best\n",
    "    possible operating points from a collection of classifiers.\n",
    "\n",
    "    This function is guaranteed to produce a list of points that starts at\n",
    "    (FPR=0, TPR=0) and ends at (FPR=1, TPR=1), making it suitable for direct\n",
    "    plotting and AUC calculation.\n",
    "\n",
    "    Args:\n",
    "        results_list (list): A list of dictionaries. Each dictionary must\n",
    "                             contain a 'model' name and the full ROC results\n",
    "                             under the 'full_roc' key.\n",
    "        results_original_roc (dict, optional): A dictionary containing the\n",
    "                                               ROC results of a baseline model,\n",
    "                                               which will also be included in\n",
    "                                               the comparison. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of dictionaries representing the optimal ROC\n",
    "              envelope. Each dictionary includes 'model', 'fpr', 'tpr',\n",
    "              and 'threshold'.\n",
    "    \"\"\"\n",
    "    all_points = []\n",
    "\n",
    "    # Step 1: Gather all ROC points from all provided models\n",
    "    all_results = results_list[:]\n",
    "    if results_original_roc:\n",
    "        all_results.append({\n",
    "            'model': 'original_baseline',\n",
    "            'full_roc': results_original_roc\n",
    "        })\n",
    "\n",
    "    for result in all_results:\n",
    "        model_name = result.get('model', 'Unknown Model')\n",
    "        roc = result.get('full_roc')\n",
    "        if not roc: continue\n",
    "\n",
    "        fprs = roc.get('fpr', [])\n",
    "        tprs = roc.get('tpr', [])\n",
    "        thresholds = roc.get('thresholds', [])\n",
    "\n",
    "        for i in range(len(fprs)):\n",
    "            threshold = thresholds[i] if i < len(thresholds) else thresholds[-1]\n",
    "            all_points.append({\n",
    "                'model': model_name, 'fpr': fprs[i],\n",
    "                'tpr': tprs[i], 'threshold': threshold\n",
    "            })\n",
    "\n",
    "    # Handle case with no data by returning a default diagonal line\n",
    "    if not all_points:\n",
    "        return [\n",
    "            {'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf},\n",
    "            {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}\n",
    "        ]\n",
    "\n",
    "    # Step 2: Sort all points by FPR (asc), then by TPR (desc)\n",
    "    all_points.sort(key=lambda p: (p['fpr'], -p['tpr']))\n",
    "\n",
    "    # Step 3: Build the core ROC envelope\n",
    "    best_roc_envelope = []\n",
    "    max_tpr_so_far = -1.0\n",
    "    for point in all_points:\n",
    "        # Add a point only if it has a strictly higher TPR\n",
    "        if point['tpr'] > max_tpr_so_far:\n",
    "            # To prevent adding multiple points at the same FPR, check if the last point\n",
    "            # has the same FPR and replace it if so (since this one has a higher TPR)\n",
    "            if best_roc_envelope and best_roc_envelope[-1]['fpr'] == point['fpr']:\n",
    "                best_roc_envelope[-1] = point\n",
    "            else:\n",
    "                best_roc_envelope.append(point)\n",
    "            max_tpr_so_far = point['tpr']\n",
    "    \n",
    "    # Step 4: Manually add extremities if they are missing\n",
    "    \n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not best_roc_envelope or best_roc_envelope[0]['fpr'] > 0.0:\n",
    "        best_roc_envelope.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if best_roc_envelope[-1]['fpr'] < 1.0 or best_roc_envelope[-1]['tpr'] < 1.0:\n",
    "        best_roc_envelope.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return best_roc_envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b781e9",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c3deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_data(dataset):\n",
    "    if dataset == \"data1\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [0, 2], [2, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "    elif dataset == \"data2\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [1, 2], [1, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "    elif dataset == \"pneumoniaMNIST\":\n",
    "        import medmnist\n",
    "        print(medmnist.__version__)\n",
    "        # read in the PneumoniaMNIST dataset\n",
    "        from medmnist import PneumoniaMNIST\n",
    "        train_data = PneumoniaMNIST(split='train', download=True, size=224)\n",
    "        test_data = PneumoniaMNIST(split='test', download=True, size=224)\n",
    "        val_data = PneumoniaMNIST(split='val', download=True, size=224)\n",
    "        # print the dataset info\n",
    "        print(f\"Number of training samples: {len(train_data)}\")\n",
    "        print(f\"Number of test samples: {len(test_data)}\")\n",
    "        print(f\"Number of validation samples: {len(val_data)}\")\n",
    "\n",
    "    return train_data, test_data, val_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59034e",
   "metadata": {},
   "source": [
    "## Data1: NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74133e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a060ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 1\n",
    "NUM_CHANNELS = 1\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 4\n",
    "K_FOLDS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a702675",
   "metadata": {},
   "source": [
    "### Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3760e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "\n",
    "# A simple classifier head\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_features=2, hidden_units=32, num_classes=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_features (int): Number of input features (2 for your data)\n",
    "            hidden_units (int): Number of neurons in the hidden layer\n",
    "            num_classes (int): Number of output classes (1 for binary)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            # --- Hidden Layer 1 ---\n",
    "            # Takes 2 features in, outputs a hidden representation of size 32\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.ReLU(),  # <-- The crucial non-linear activation function\n",
    "\n",
    "            # --- Output Layer ---\n",
    "            # Takes the 16-unit hidden representation, outputs 1 logit\n",
    "            nn.Linear(in_features=hidden_units, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "# A new LightningModule just for training the classifier\n",
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_features=512, hidden_units=32, num_classes=1, learning_rate=1e-4, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = SimpleClassifier(\n",
    "            input_features=self.hparams.input_features,\n",
    "            hidden_units=self.hparams.hidden_units,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "        self.current_test_threshold = 0.5  # Default threshold for binary classification\n",
    "        self.strict_loading = False \n",
    "\n",
    "        # This ensures the model's structure is correct upon initialization\n",
    "        if self.hparams.pos_weight is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(self.hparams.pos_weight))\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        \n",
    "        \n",
    "        # --- METRICS ---\n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_auc = torchmetrics.AUROC(task=\"binary\")\n",
    "        \n",
    "        # This list will store outputs from each test step\n",
    "        self.test_step_outputs = []\n",
    "        # This dictionary will hold the final results\n",
    "        self.last_test_results = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self(features)\n",
    "        \n",
    "        # For the loss function, labels need to be reshaped to match outputs\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "        \n",
    "        # For metrics, squeeze predictions to match labels' shape\n",
    "        self.train_accuracy(outputs.squeeze(), labels.int())\n",
    "        \n",
    "        self.log('classifier_train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('classifier_train_acc', self.train_accuracy, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self.model(features)\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "\n",
    "        # Append predictions and labels to our list for aggregation\n",
    "        self.test_step_outputs.append({\"preds\": outputs.detach(), \"labels\": labels.detach()})\n",
    "        \n",
    "        self.log('test_loss', loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        if not self.test_step_outputs:\n",
    "            return # Avoid errors if test loop was empty\n",
    "\n",
    "        # Concatenate all predictions and labels\n",
    "        all_preds = torch.cat([x['preds'] for x in self.test_step_outputs])\n",
    "        all_labels = torch.cat([x['labels'] for x in self.test_step_outputs])\n",
    "\n",
    "        # --- FIX: Squeeze BOTH predictions and labels to ensure they match ---\n",
    "        squeezed_preds = all_preds.squeeze()\n",
    "        all_probs = torch.sigmoid(squeezed_preds)\n",
    "        # The labels tensor might also be [N, 1], so we squeeze it as well.\n",
    "        int_labels = all_labels.squeeze().int()\n",
    "\n",
    "        # Calculate final scalar metrics\n",
    "        test_acc = self.test_accuracy(squeezed_preds, int_labels)\n",
    "        test_auc_val = self.test_auc(squeezed_preds, int_labels)\n",
    "\n",
    "\n",
    "        # Get the confusion matrix stats at the default 0.0 logit threshold\n",
    "        tp, fp, tn, fn, _ = torchmetrics.functional.stat_scores(\n",
    "            all_probs, int_labels, task=\"binary\", threshold=self.current_test_threshold\n",
    "        ) \n",
    "        \n",
    "        # Calculate TPR and FPR from these raw scores\n",
    "        epsilon = 1e-6\n",
    "        tpr_at_0 = tp / (tp + fn + epsilon)\n",
    "        fpr_at_0 = fp / (fp + tn + epsilon)\n",
    "\n",
    "        # Calculate data for the full ROC Curve\n",
    "        fpr_full, tpr_full, thresholds_full = torchmetrics.functional.roc(\n",
    "            torch.sigmoid(squeezed_preds),\n",
    "            int_labels,\n",
    "            task=\"binary\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"\\n--- Final Classifier Test Metrics ---\")\n",
    "        print(f\"Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"AUC: {test_auc_val:.4f}\")\n",
    "        print(\"-------------------------------------\\n\")\n",
    "        \n",
    "        self.last_test_results = {\n",
    "            \"w\": self.hparams.get('w'),\n",
    "            \"fpr\": fpr_at_0.cpu().numpy(),\n",
    "            \"tpr\": tpr_at_0.cpu().numpy(),\n",
    "            \"threshold\": self.current_test_threshold,\n",
    "            \"auc\": test_auc_val.cpu().numpy(),\n",
    "            \"accuracy\": test_acc.cpu().numpy(),\n",
    "            \"full_roc\": {\n",
    "                \"fpr\": fpr_full.cpu().numpy(),\n",
    "                \"tpr\": tpr_full.cpu().numpy(),\n",
    "                \"thresholds\": thresholds_full.cpu().numpy()\n",
    "            }\n",
    "        }\n",
    "        self.test_step_outputs.clear()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ea652",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f28dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1000, 2), (1000,)\n",
      "Test data shape: (600, 2), (600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train_data, test_data, val_data = generate_data(\"data2\")\n",
    "\n",
    "\n",
    "train_data_tensor = data.TensorDataset(torch.tensor(train_data[:, :-1], dtype=torch.float32),\n",
    "                                        torch.tensor(train_data[:, -1], dtype=torch.float32))\n",
    "train_loader = data.DataLoader(train_data_tensor, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS) #over-write later for k-fold cross-validation\n",
    "test_data_tensor = data.TensorDataset(torch.tensor(test_data[:, :-1], dtype=torch.float32),\n",
    "                                       torch.tensor(test_data[:, -1], dtype=torch.float32))\n",
    "test_loader = data.DataLoader(test_data_tensor, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# initialize fold\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8065beae",
   "metadata": {},
   "source": [
    "### Regular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261a6f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training for 1 epochs on train_loader ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c965bb0694614241a643d2c6127a9f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v18.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v18.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model from Phase 1 saved to: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v18.ckpt\n",
      "\n",
      "--- Testing model from Phase 1 checkpoint: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v18.ckpt ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b641647bb534099866232951c032b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5700\n",
      "AUC: 0.6139\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6873143315315247\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Manually Calculating Metrics on Test Set ---\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[176 124]\n",
      " [135 165]]\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.57      0.59      0.58       300\n",
      "     Class 1       0.57      0.55      0.56       300\n",
      "\n",
      "    accuracy                           0.57       600\n",
      "   macro avg       0.57      0.57      0.57       600\n",
      "weighted avg       0.57      0.57      0.57       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Instantiate the LightningModule\n",
    "model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    "\n",
    "checkpoint_callback_full_model = ModelCheckpoint(\n",
    "    monitor='classifier_train_acc',  # Monitor training accuracy\n",
    "    every_n_epochs=1,                # Save model every epoch\n",
    "    dirpath='checkpoints/',\n",
    "    filename='simple-clf-{epoch:02d}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "train_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',                 # Use GPUs\n",
    "    devices=1,                         # Number of GPUs to use\n",
    "    #strategy='ddp_notebook',                    # DistributedDataParallel strategy (best for multi-GPU)\n",
    "    max_epochs=NUM_EPOCHS,              # Total number of epochs\n",
    "    callbacks=[checkpoint_callback_full_model, progress_bar],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-train\"),\n",
    ")\n",
    "\n",
    "test_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=1,  # Use only one GPU\n",
    "    logger = pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-test\"),\n",
    "    # Add the callback here so the Trainer can find the 'best' path\n",
    "    callbacks=[checkpoint_callback_full_model],\n",
    "    precision='16-mixed'  # Use mixed precision for testing\n",
    ")\n",
    "\n",
    "# --- Phase 1 Training ---\n",
    "print(f\"--- Starting Training for {NUM_EPOCHS} epochs on train_loader ---\")\n",
    "train_trainer_1.fit(model, train_dataloaders=train_loader)\n",
    "\n",
    "# CRITICAL: Save the path to the best model from this phase\n",
    "path_after_phase1 = checkpoint_callback_full_model.best_model_path\n",
    "print(f\"Best model from Phase 1 saved to: {path_after_phase1}\")\n",
    "\n",
    "# --- Test 1: Evaluate the model from after Phase 1 ---\n",
    "print(f\"\\n--- Testing model from Phase 1 checkpoint: {path_after_phase1} ---\")\n",
    "model.current_test_title = \"ROC Curve after training on DataLoader 1\"\n",
    "model = LitClassifier.load_from_checkpoint(path_after_phase1)  # Load the model from Phase 1\n",
    "model.eval().to('cuda:0')  # Ensure the model is in evaluation mode and on GPU\n",
    "test_trainer_1.test(model, dataloaders=test_loader, ckpt_path=path_after_phase1)\n",
    "results_phase1 = model.last_test_results.copy()\n",
    "results_original_roc = {\"fpr\": results_phase1[\"full_roc\"][\"fpr\"], \"tpr\": results_phase1[\"full_roc\"][\"tpr\"], \"thresholds\": results_phase1[\"full_roc\"][\"thresholds\"], \"name\": \"Original NN data1\", \"auc\": results_phase1[\"auc\"], \"model\": model}\n",
    "\n",
    "# Metrics\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval() # Set to evaluation mode\n",
    "\n",
    "final_predictions = [] # This will store binary predictions (0s or 1s)\n",
    "true_labels = []\n",
    "\n",
    "print(\"\\n--- Manually Calculating Metrics on Test Set ---\")\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Move input data to the same device as the model\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # 1. Get the raw model output (logits) and convert to probabilities\n",
    "        outputs = torch.sigmoid(model(inputs))\n",
    "\n",
    "        # 2. Convert probabilities to binary class predictions (0 or 1) using a 0.5 threshold\n",
    "        preds = (outputs > 0.5).int()\n",
    "\n",
    "        final_predictions.extend(preds.cpu().numpy().flatten())\n",
    "        true_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "# Ensure they are numpy arrays for sklearn\n",
    "true_labels = np.array(true_labels)\n",
    "final_predictions = np.array(final_predictions)\n",
    "\n",
    "# Now, calculate metrics using the correct binary predictions\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(true_labels, final_predictions)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "report = classification_report(true_labels, final_predictions, target_names=['Class 0', 'Class 1'], zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c2d0a",
   "metadata": {},
   "source": [
    "### Weighted ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "226e70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSIFIERS = 50\n",
    "w = np.linspace(0.001, 0.999, NUM_CLASSIFIERS, endpoint=True)\n",
    "pos_weights = w/(1-w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19d1bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 1/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd5644e66c5423b9d14b71f665ac12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['criterion.pos_weight']\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v19.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v19.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v19.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v19.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78532d11cdaa4f1bb8d2c8409ccc3c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2655\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7676541209220886\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394bfc68d74e4bbe9aee9137cf95ac47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d84b8e924cc433088ce7b5091efa41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2630\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8202788233757019\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee7e95a9ed64491bbc8e611e7dabece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36dd3c4969d5400190cf12eac2480918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2699\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8832796812057495\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811a796d9e01476da5d918b1bbadcb5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892f5b1318804f5ca501e0cfcfdcfce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2787\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.95215904712677\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482623e5d3794a0aa3d3950e0066927c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa634dedf39e4a4ca36da2fac2ab5a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2981\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0078723430633545\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da516e8dc2441649c6da251ff0c2df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4a2348166c415e932333e3a4fa5268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3113\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0434263944625854\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056389ab57c041f4b008b5d0722cb551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87efcd092aff42b4a2d706d969903af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3248\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.043900728225708\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca7772fa04f4d68acd4b4bcb82e266e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c379d536e54c04a6699d65c16fb8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3416\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9954567551612854\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ea5d5dfcbb4ab2862b1183304ede80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed24a267a2934774b44eafff81ed8711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5120\n",
      "AUC: 0.3591\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9322989583015442\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25781aaed20a4818ae6bd029905294a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560d336a9cae421790314974b71e9db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4292\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8756572008132935\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23273a650b434dc283b286065bb602c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dc71f5759846c0ab9dc07d4d44fb85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.5569\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8254168629646301\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94ad61e00814d85a660436c5c1d6a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba5d9e59a784f4ebfa3203abd11edb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.6213\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7717716097831726\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc3a91dce954832942b44bc980a6041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f398f46d31314576bbd00215e0515e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.6597\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7272616028785706\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72347e0767f4d479df053d9482f4b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b39b70154b4a23910482789d988b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5440\n",
      "AUC: 0.6969\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.688191294670105\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ec5c02141d491ca5a862fddf7908ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8dcf43249f4a478eb970cadaf043d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6240\n",
      "AUC: 0.7201\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6613358855247498\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5fb8ecd758476a8f624db83d09a2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eac7ac9b26e4599944471e46d8e3925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.7568\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6261679530143738\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6711dc4d5f849d0ba6d1be5b963d646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32db018724c42758c1eda81de98f5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.7785\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6027655005455017\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559a1e05145d46d28bc182cc51299191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca16aedaa993446abe165ecf88be732d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7600\n",
      "AUC: 0.7939\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.582801878452301\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c411ee7bcc44dc9dd5fa5bae8683f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645909c6105348d8aedfaf12128940d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8013\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5651361346244812\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55379234254419bbf0926baddafac5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08edc93988724213af7fc64fc79279be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8190\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5444086194038391\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190732c6b8724727b70eeba6754e7b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78498661d9734501b3c08b4dea1ffde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8234\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5318567156791687\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768d255670174ebd9979a8fa4634edf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2de87311c04fe3a207021c3a6db03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8329\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5200207233428955\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03c1feaa27742f3b7f3287682553e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731f8230169448589e15cb141ab8dfcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8371\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5105209350585938\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab24e9bc6f94bd3b38498a08c4b420d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6cf85ca158485cb62be5c20858a9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8391\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5027037858963013\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb9a02091be42c2ac8438db353e10d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38ae809f49047978d22a657d4d3d0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8444\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.49636974930763245\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a052d900e6f64439a330465f180bbc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b1d0dd01894c56873146cdd46b08f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8475\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4918159246444702\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40625b332ea3470aa32135a60fe8e541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2d91386b8f404492311541a8f18bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8502\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4886922240257263\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b26afd03074c6d9ff200088f4913b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04c57d288244c5abec307473a4c3b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8520\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.48591023683547974\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e8b8b1d0924322b2ff8b060cd39ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bbaecd820e4fab9126b100fef283f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8538\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4846198856830597\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c2975fbb9e41a4a983643ec97c039a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889c8c45e03541ed9fee236763266a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8552\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.485297292470932\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fee7743639047729fb895f3befab891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec45895cf72462796201b727697950b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8556\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4809860289096832\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89082d26098f48fc9ec119c2d299c109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964fb318c8c744b1b46a0b9fd0a4ec4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8565\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4855644106864929\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1213fb065d947d7b9d9c292a2395dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db15fc53e354448aa8e499f857f80c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8570\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.49177685379981995\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540c4b0aca2145d28924dfead100c2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846adff8b38b433982951a2f0c2f100e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8575\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4954129159450531\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c285fd495864ff6a2e318bc91ed58e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5939d78226874366968ae23c992e67b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8579\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5056837201118469\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737e1aa001624cdba52e18d5d23c1f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbddc31f69274f5fb0ec131371e49365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8599\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.516907274723053\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7eb9b44c9144f8885cfb3da5fab6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9865079101514cffa6c338d32d05d0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8607\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5264061689376831\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81adbb5be49a444186a49e7962363ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa880765532a46f6b43e058809dda641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8606\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5391298532485962\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3cb3236e7e4ce98c54242df08d3852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d64684b0b5a48c798b384f2de30f858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8610\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5573033690452576\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421c89d3164e4b41b683ad6db27066d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d526130265f040ef97d344f785580886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8616\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5762844085693359\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e5f357ac944f66b50ccc67e366556d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38376c11228a4fed880c64284fb5f776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8614\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5903940200805664\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed784e87d1be432d944197fc4f2933d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4c865c168f42bdad41b91730bf828f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8625\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6163721680641174\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23acae5d93e04ba0aec5e069dbd475cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4a3761d40b4f0ca1499517e57f68ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.8629\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.641635000705719\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc98e7dd15a41d196a2f7577276ccfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9c07193b7b4c158f09886851f8d0e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.8626\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6648041009902954\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c171ac3bd4a74897be1b51d8cebd2039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbcca65fd8940948a2e13c895188396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6960\n",
      "AUC: 0.8625\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6928171515464783\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ef1eff5b724f46b48c0d82a9716fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec83d1fa087b44e0b92d5be5b4da487e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.8619\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7430084943771362\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ab6295ace8412f82b2acc1c663df25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d94c6775d01464b9069262ac5c880b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6960\n",
      "AUC: 0.8615\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8000817894935608\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3096a132a37a434897365d8bd169f6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6432b73c465846f2ad0a2c73dcbf3b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.8613\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8653768301010132\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea190985ff44e6bb40002c8f9529b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8591db3f024cec92bec94da6af4f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.8603\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.931489884853363\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6cae79ab4b44cceb22dfcececba37bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0adfc776565940f3ac1b2683cf8abd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6760\n",
      "AUC: 0.8594\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9756916165351868\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 2/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f8fc1985c44722b45a6140185f3908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe13b2aa8c343288a7867c63f5ba82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2892\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7375627756118774\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0515f1f48f47bdbe20c56c63cbd7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900ff22f955148988f1712c17914f7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2347\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7787456512451172\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2e80baf8de44ec92d16ea8a636f5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ad3e925c2f4906ba4cdd8adb49d63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2118\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8218240737915039\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bef5608577444cab63cfd4a8bc7772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2234a5bf0eeb4bf2a0a77791a8d427c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2010\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8677312135696411\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab3e91e61f64799904be262daa9d11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a141c9a87bce47f5b1d8db5a0538705d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1945\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9167004227638245\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0a0ccfd3f04a669f4388ae75b8748b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d232c330b53e4203bfe7a7521a357c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1969\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9625637531280518\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cd6e073f4747ecb4399b0ba1035f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669c1d6cd8594c27a6257dbbb937dd8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2130\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9677337408065796\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7dff488c7a415988fb86a58a496f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce238e18b23e46e684d4ec91943bfa04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2627\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9560354351997375\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64253dc804364a139b9887e7a7c49974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7ccbe4f61544509428ea8a9aef9ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.3520\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.929405152797699\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73961f5ea0d4e8fb34c755a283ddf7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc157c8819934653b8d691151bbc854a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5122\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8830832242965698\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2014b729a3c40df8dbc47d6b4d73871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aec14d636d34794823aaaac1aa9db00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.6499\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8379887342453003\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95c89815fdc43008f9eeacc61cdff96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8e2f59a0df4c4f94da7d43bf77f394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.6828\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7963687777519226\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fabe18f40b46f983418692d24a3398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9434710cd4494fb153cb34f86855be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.7202\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7508836388587952\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2961eb2f5c134ac699d337b3e302dc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3618f42d99048d897969f3cd9cc61c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5280\n",
      "AUC: 0.7483\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.71025550365448\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe8a7079eab46fb9742430ccbeb2422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9098d25e40314d5cbf4f07a4b13912b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6280\n",
      "AUC: 0.7690\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6741873621940613\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebe89c49c7b4328bf6e9b771fde79c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f46c5e6368440c970be55b83052bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6680\n",
      "AUC: 0.7864\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6397095918655396\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2714ab723743d5a8dee3f2e14daabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377f5b9c47f748328e2fa2dd45e44140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.7976\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6118695139884949\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d9c8646fac4bfd9cef364f5a86356b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f592124897e1403a94db8d3ecdea6cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.8140\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5819606781005859\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f6f1da70fe4e6d8e54b0a8e2a205a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4b54f7aeaa4ce89bdeb1d210e7303b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8245\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5566886067390442\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948745032ff34f71a43a3b3a0e53cc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333a4163292b4e38b595e2b795e388de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8286\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5433878302574158\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece283ada24a44f7b0dfccb9d7f6dc61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ed2f9868574f4f9c16aa303a874e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8342\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5245846509933472\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54d2a735765420fb0480a23408e9c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4357ca730f464d8f90df05912ad428c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8379\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5126435160636902\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb36ce290ae646dcbb9553988fadbd43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff79af4f6cb4fd6b31aeb4db6328e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8412\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4998283088207245\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a9093991cc46959043e5e807bf3dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702ae0e6508b4d10a6f27fcab7c58b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7080\n",
      "AUC: 0.8431\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.48952335119247437\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51841a35bd247f2b6e4db7c5cb15652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf785bd5e34740e387647e664847ad20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8466\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.47830161452293396\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d40ea53a0b2478f9cb0d11a2718ba4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c78b40758d44bfbc7bc7506c15a906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8483\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4712155759334564\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d14d865bc24291b6dec688f01e6805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82233c4d1a6e40098ad280ba25c756f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8502\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4650372862815857\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5467df9d2fcf47838ba1c0c6eb3a324e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d103a2de98449e8ad6ca464967735a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8524\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46011611819267273\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c107e885eeb44af78d49f88e20c2104a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34d67ffb8db4145b83044d22027562c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8534\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45679929852485657\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379ed631b987432d9f720b305c13122d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f9506d10424bf089359daf60ac6574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7560\n",
      "AUC: 0.8557\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45379379391670227\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5798bbd456a45e39b83be0b338834b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7488dd0ac7493cbf39c8a9a22e9411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7520\n",
      "AUC: 0.8567\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4527013897895813\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f5f7514c0a404db440773767902f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9dfc2d839884ad58a68d0c73d8775b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8581\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4535573422908783\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b273ef0c0d9d4539884b7286c953b934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a918c3a3c484daeb70948d5edce86c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8577\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4565396010875702\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4fc17a9d644a34b3f8bb5e72a870fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b48e247e55492094517c90b86b859f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8577\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4596022367477417\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d3a81057b340228423054193c975c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27d0517506d4c2cbed35ccf9803c27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8580\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46450427174568176\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1705b2fadb40ffa635f1c8d568e5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f408a2795a046598338f5d41b8fa15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8572\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4705519378185272\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5092b7dc26ad40a9be6363f320a5091b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7773ff2417d43d096cfc60da8d819b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8571\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.47759875655174255\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77a9841603e4bef947a8909e856762d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f23c4ea04c44d081ae72c9752a021a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8571\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4809812903404236\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc1050e4ede49c5af8061f4576a3584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a28b41fa50b4df7923ff0f3b5965fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8569\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4932645857334137\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d695619bd44c44dfb73f1db73d449703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fb1b4c763b4468b4ad16a9ed673911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8557\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5059277415275574\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40142957af0946238398c8724762a9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a08d6f55d6c4143a72da8178a9c11b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8559\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.526340126991272\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ef3ceab94148938a5d297b0ae48c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb3d5212f1240c39e8afce4ca7d5331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8557\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5434646010398865\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3250d962d53f4eaaa9cdcb36a53831c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8add79f967934ab7b8b31aa89bce3044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8553\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5679275989532471\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7285d73281b4f569b1b001a29053d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1257a5e32231444f9a7c941055460a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8549\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5950807929039001\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15625c866c86406bb25cc1e24a59a8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a136da3bad084b2687e883d41a9510d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8541\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6247408390045166\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095aefe457d942658831b4ff2426335d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76376b46292a42909c4d6d9e0ea54b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8539\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6604481339454651\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8922bb037c4ca0bd42771639fc299b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac4d8bcbc46496ebe03aacbbfce6184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8539\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7071707844734192\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f08ca824494aa6b294578d01148c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a08d9adfa1c48c5aa110d00a5cc1014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8538\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7436138987541199\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0acc7b93c4a47969e1f8e159f373986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b32017f26c946eea001a5e1832f15b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8538\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7938992977142334\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbb62da2bea4a76a45333a9589bf2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ed888e774841719977cca9c207b7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8541\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8308938145637512\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 3/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5b1f39bcb0418eb3cfaff5ce732d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd5e08ddc304ac4830526beaf3848d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1383\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8005256056785583\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15521faf56d74245a5e2e1fac1c2849f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc961c44a2a0408b90243916d8b67f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1434\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.843948245048523\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3d355be1324b0f895b1bea20cce649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169e707993da407da0ab2e897fce69f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1554\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8926207423210144\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761500ebbf404c1ea688a7556a4c5c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3cde52e8d446c9b3edd4e3fe11c7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1760\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.944499135017395\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fbd9e7fd224cfd8200c054d9a75009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168ccf654eb4446689a98a99448606cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2032\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss             0.9883993268013\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f23ecd3c3914217b032ab2901e35375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350e0d3345564e8da42d530d87fc163e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2415\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0235844850540161\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a331bff247474061aae189ecff39b648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015e90071e4e4eb9945b179efb61198a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2863\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0457496643066406\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4f8a91649c42809cd6cd0045796dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea1bee72fe542debd58660eaaff1eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3234\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0318751335144043\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ebfa97ceac405aadd28e85370edb71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff90f9ca0ec4eabb2dfc55d6cb00150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3523\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9877092242240906\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bee6596fb494af8bc9200e81a7d2902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754eac2d75284ebf8c2331f82d2f6bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4230\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9395592212677002\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe51554fbac43409f87082c29adaafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b937288a76464f70a840e7de63b34c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.5488\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8857266902923584\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd4eff6188549748375d1cd45680c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb6af9fa4f04e7fabbe85807d8da761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.6663\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8359194397926331\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c174e15b974b488eb3ec063aeecfae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b710a9205c473ba8f8e503fdeeec86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.7341\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7889459133148193\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8787cc1b14c4632a25c1e2c7e1672a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678886cddf0040fe9428b649cc43a2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.7714\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7429880499839783\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440bf4659e38491eaf58ae2cb8d54134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d2549df41f4ca6852b27a0c3dc6f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.7928\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7057761549949646\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffb4b4acdb04c3f8415b539c062b138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d4f6ec634441c3a90ab2f24e5bd899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4840\n",
      "AUC: 0.8078\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6699056625366211\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a921ac76795d46ec886ebe5102ed597a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823015822f97471fb098fe891c39897d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6480\n",
      "AUC: 0.8180\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6349582672119141\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e00dcc189fb4d5a9ee41c96950d4186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3db806e650d495cb1449fe0ff138ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8258\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6063206791877747\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e71543383f4ef9a9619ec265382efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175077d455f449ebbc4a89da4aaf1f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7680\n",
      "AUC: 0.8359\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5769469141960144\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdea0da1e7284660b952002112fa4ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc95e1de1154e5ca19c0f6601f5e908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7640\n",
      "AUC: 0.8412\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5551362633705139\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb3b3b4269b4a42bc5c7f625849d3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b8ca6fdf5f41eb93908b4cd0f64e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7680\n",
      "AUC: 0.8476\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5325221419334412\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1594c6a70046ac870bffebb2262bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdc82c5ef13458cbce3f17f2f46d0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7600\n",
      "AUC: 0.8494\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5157297253608704\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de3c1ad5335477189a14acbd29aaa4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73bfe608172459cb77ac6aae078b11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8521\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5016684532165527\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd10bf9e16ec4ba1bf2ccf396472c84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338e800423e848f693f02a627afc5f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7520\n",
      "AUC: 0.8537\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4894965589046478\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95de7395bbc743efac9a09d60e5922ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d566b66ba3d4414ea5c85cab1a01eb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8555\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.48001396656036377\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c131e9a12620478f92dfdf52332e717c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23d685a02604f73996fad7694333ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8575\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4732374846935272\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98873aeb1d47442398739da024ffad6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2ba4830582411f9886a2db90443d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8585\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46769091486930847\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97123484a6841b1b360c9ae98ea866f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197a22ebad5846b3a6a8a8875948988b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8602\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46273326873779297\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754f6eebfbd948658bd35837ff73c216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18bd71bc9fc44ffbde90f95985ede9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8609\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4597620666027069\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d0e87658674b2da494b90648488bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa39a15e260400abf5371d5b2aa7fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8615\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45950156450271606\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5d765fc973416390b10e5b05f128bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee4034e7419413dba6e2be71e046739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8624\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45758646726608276\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299766d45c30426bbbf0122d79be4e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e4514a402f44de8c2a1ffc2d03f149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8631\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4556320309638977\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43623e5d829e4612a1def87de992281b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86081e58d5d440b9d48e86f2b834973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8638\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46203815937042236\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b424cf02804c00b4a2ea6b36b608b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b938993adb0b4a7f8e9ada5316b3decc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8645\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4676938056945801\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e79d14705854425b19f6321d6c53b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075806ab505645b5bce0d5ad1c968cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8652\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4736079275608063\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88f7012d2634a28adc0b1465ae9e5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2458f11f03804a9b98028d0979611413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8654\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4788254499435425\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b820268da6343e19b182909eb6bbede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b621dfde084b4d99b2b98107effbfe84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8655\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4825604259967804\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59752bba274446a5a0792da2a048568b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b569252dbc95488ebcb99162dd5249e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8659\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4893953800201416\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42e1c066a1d44dc8142c1bc131b1be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d208d1a0bd84eaeaf94adc9505f9d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8663\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.49854129552841187\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23225ee0f2da47ceaae5191395cd29b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70f3ba544a747d296b95ca32c98566b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8671\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5098155736923218\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c94f1258ab34a8f86cc6b97d6a3cadb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af50b2069c14dd9b26f22d0856aeb91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8663\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5328621864318848\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980f73d1bd6b411eb50ab6a047721686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1974534c69848c09596d9c0dd9b63e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8661\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5516429543495178\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cb73553f2d4c98afd0c3eeb1c8b343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8527a07cf0b14a6698e420f68fad51e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8657\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5789104104042053\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b9abb09b2c451cbf814ff1016b15c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a527e3559bb64e73bbbd22631c61d285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8649\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6100141406059265\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434b9d3056324d3393aa5155de0c6aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cb438e744b4cc1b317a094f5e64ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8640\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6466864943504333\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458f92a7db6d41bea3c31d926e2ca7fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc14dae1d9ca43ff95bca7ca4c7962a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8637\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.689750075340271\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ff7d1cdee14477a18009279382fcf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d99787ca08459eba002c107c3631ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8632\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7408185005187988\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8081b010204694b6893e9a55428039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfc0ffd216740cc9d2a573b14deb3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8623\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7909818291664124\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9658c2afdf4f2b870c7376a94d8bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d2abf205bb46f18eb39559f8cc963a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8611\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8567193150520325\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a88cbb8105b414895c55858fa48d0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ac15a7ee1d44d6855daf200288c4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8605\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9020094275474548\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "--- Starting Fold 4/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a904d874a643a1a33cf978f1d9fc99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c02c133f5543b89ddddb1a8a2e1a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3422\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8193480968475342\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d7f2ea3dc149028a93312eb2d957dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6bc4a675bf4cc2bd35f35725f60ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3370\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8800300359725952\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca3e148fb2f4d77a5ec2e1cbef639ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a27fbc016149ef973b296003613eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3343\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9472030997276306\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f82c2dee1ff445192778db5879c9995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1c2572911e4b2dbc778496e9d96738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3367\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0091711282730103\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b7209af2234a37bb92b438b3307678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac91707f1584aa3acbe69a6e2e8e5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3445\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.030240535736084\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a630bf680ef4701be082ede3a47ec55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5432027bfc424dc5ad1d7abc40f6392c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3593\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.002152681350708\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb68e59050ec4dcfafa0c9eb0015b456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883d1fa26d474d6eb8bbc5c316e8961e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3891\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9554938673973083\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8acc1dd63d4f87b61a60c9f7901395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6b428bb8fc428fbc0521b90eda4c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4683\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.900529146194458\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5176278edb7a47f4966dcca328ef0f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6711b0640644ca8ea379cd1373155a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.5515\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8475346565246582\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217929a6f985463985ba2672158a94df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b30815193384b70ae273f8008f2ef73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.5832\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8003154397010803\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8139c99b054ab69d93732cf07441f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506bb4a9254e4c439a3dcad59f966f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.6089\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.749652624130249\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3030da4878be445f884024f9e3bfd43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e2ae422c2d44a5932765924987a484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5600\n",
      "AUC: 0.6551\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7037526965141296\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b9ab3115cd481faae2876930d60e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826b014965c6489d9fc8fb9fba9663ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6320\n",
      "AUC: 0.7102\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6628682613372803\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3765141fc741b5a84d5886c42e18e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ad62f9425e4935acaaa16745e4c0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.7491\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6346430778503418\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e02b2a613574cefa21e759e489f8d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa1ac000dad4fa2b5f1d4cd411840e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.7772\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6092191934585571\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a66573298848efbc7e7ee5ee9bd6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2967ec206843bd8ce83c76d8bbe295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8095\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5760064721107483\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffaee690b42432f8730c940a5727a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce9f9974d9d4777ac3067060f511a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8254\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5556005835533142\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2c3c26999b4357b9e7b4f041000fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4db2663083f4f8887f7b5fda59c1ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7520\n",
      "AUC: 0.8408\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5302383303642273\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32832957a3a947e5a944723e81e0934c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50c4a4b872840cf88d43df23aba9f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7640\n",
      "AUC: 0.8506\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.511646032333374\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b543e8f6574b8095e2a53e74bd7bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbc0171fdec4cb6bd39f340cbf5f2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7720\n",
      "AUC: 0.8538\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5010159015655518\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f986e805219d41ee8988422fa82763f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce41fcea8994831907d39761c1e2d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7760\n",
      "AUC: 0.8559\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4909391403198242\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c723afe7f924377a09af10031922e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e0d90d059c4258a9e253dcfecd64b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7560\n",
      "AUC: 0.8613\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.476236492395401\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c71249c5e94e7b99f5deae63fb25b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4962e95528b44b659d90a3d4a02ef58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8633\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4675005376338959\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a866076fbb194774a6f16eee43ae95a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b77f08d6d845779300441b2d55aefb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8654\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46079835295677185\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0836a6578b4cc594804ef4967b684f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87eabc1d3d943aa9d520f5b5aef1009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8658\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4557495713233948\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f407b1bd0c409f827e7ee0495e5013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d7f9e6698742328cd42fbeb27c4c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8662\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.451321542263031\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07c96e325944316961a5d629e5b4d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e494ca11fb448ca8c6be2b7ddb0b1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8679\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4482128918170929\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808939d9ba304e18ab5f9d759a1101e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022b10a1ef044f07afcbed49d83e715f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8681\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4461037516593933\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a872d5a41904dd09ea1054b19d87059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4d46cd1b5544f486ee264abcf6a89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8695\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4470636248588562\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4c2210d3794ac590dfa73569b000e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb529f0e6a04cf48ee72031559b7ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7560\n",
      "AUC: 0.8707\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4469273090362549\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3efa3c1fcc84e66b87e5f342a2e6970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97d5e8d8db3464f958a0daa75674efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7560\n",
      "AUC: 0.8715\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.44890812039375305\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5996c59a97de4150adc88e302452ca38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0754f3fd9d42a6ac873eb75a535754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8719\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4505960941314697\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6e9f1b435f42eda093940c117cfddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbef50767a334786984b46cead765b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8736\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45740604400634766\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fef92a7dd34c62bb1590ad5151b89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e138ecef920b42e2b8c8e7138670e40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8742\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4692266583442688\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2e546073e941de9b2b1e54af25b96e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade21ff67d3e454f8ce437670452fa79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8744\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4752771556377411\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0317749f29a415fb50d36a7486a2864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdbe5e5e33841c0901b048561862009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8750\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4810393750667572\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a7b5e9be2e4678b2d6c35a36accbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7a3ff63492407db80bfed6feaa8d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8758\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.49301934242248535\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b893fb75f1734ad9964aa1f2c7b647e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10cce75d9bbb4fe1bd4b215e0abafcad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8759\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4989764392375946\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d324e115a8264612a338730b26c3f1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176b12552de144bd8c45b2fc02cce18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8761\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5211317539215088\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf9f2a43fc9421296362913d790bbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb4b94c077c462dad80bac199baa1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8764\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5289367437362671\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fa266a965041109f1ad4a1823307e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3100861c8e8447a891fd71a3b700bca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8772\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5541742444038391\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f667e051e2994469a84f4278853dcf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f018f2a0ac4a4ba84fce784d657fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8769\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5821071267127991\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2a92f38caa43ccb88b4a9602f0958d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49b866146aa42ed80dc88f6ed4fa2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8771\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6040052175521851\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a770f7d000489da36c43d55b0a83a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52e1b6417434d8084029a53b27da1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8780\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.637010931968689\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af5705e04b54cd8a6221c840775820b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe351d8d2cce46ab9e489f7cebd0e3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8790\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6773172616958618\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976b3af38c604b02baabcbe2ce0edada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563b741f82ab4f9fb9113e37a547bd04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8791\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7290652990341187\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98e2df308a44219a6f92fde1a581212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1c020227d24d2286687b828aae1d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.8783\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7949115037918091\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5b9376d1ce450c8c43f566c02bfa53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e63ab66f38f49b1af7486cf542c6149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.8761\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8667290806770325\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8246e47ad454106be5f7591b44ecd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7aa094d2e064cb1be112ac24a7cc40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6960\n",
      "AUC: 0.8741\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9460022449493408\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc9c37adb3c43efb71ebf3673da4347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08cf61266bbe4622ae4033162bf23caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.8728\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9966281652450562\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "#store the weighted classifiers of all the folds\n",
    "list_folds_weighted_clfs = []  # List to store classifiers from all folds\n",
    "#store the best classfiers of all the folds\n",
    "list_folds_best_models = []  # List to store best models from all folds\n",
    "\n",
    "# Dictionary to store the history of each fold\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "# 3. K-fold cross-validation loop\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data_tensor)):\n",
    "    list_weighted_clfs = [] # List to store the models trained at each stage\n",
    "    best_clfs = [] # List to store the best models from each stage\n",
    "    best_model_paths = [] # List to store the path of the best model from each stage\n",
    "    # 1. Instantiate the LightningModule\n",
    "    model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    "    print(f\"--- Starting Fold {fold + 1}/{K_FOLDS} ---\")\n",
    "\n",
    "    # 4. Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "    train_loader = data.DataLoader(\n",
    "                      train_data_tensor,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      sampler=train_subsampler,\n",
    "                      num_workers=NUM_WORKERS)\n",
    "    fold_loader = data.DataLoader(\n",
    "                    train_data_tensor,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    sampler=val_subsampler,\n",
    "                    num_workers=NUM_WORKERS)\n",
    "\n",
    "\n",
    "    for i, pos_weight in enumerate(pos_weights):\n",
    "        \n",
    "        model.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))  # Set the pos_weight for this stage\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            every_n_epochs=1,                # Save model every epoch\n",
    "            dirpath=f'checkpoints/stage_{i+1}/fold_{fold+1}/',\n",
    "            filename=f'best-model-fold{fold+1}-{{epoch:02d}}',\n",
    "            save_top_k=1,\n",
    "            mode='max',\n",
    "        )\n",
    "        \n",
    "        # 3. Instantiate a NEW Trainer for this specific stage\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}_fold_{fold+1}_ratio_{pos_weight}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "        \n",
    "        # 4. Train the model. It will start with weights from the previous stage.\n",
    "        trainer.fit(model, train_dataloaders=train_loader)\n",
    "        \n",
    "        # 5. Get the path to the best model from THIS stage and store it\n",
    "        if checkpoint_callback.best_model_path:\n",
    "            best_path_this_stage = checkpoint_callback.best_model_path\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. Best model path: {best_path_this_stage} ---\")\n",
    "            best_model_paths.append(best_path_this_stage)\n",
    "            \n",
    "            # 6. CRITICAL: Load the best weights back into the model object\n",
    "            # This ensures we carry forward the BEST model to the next stage, not the last.\n",
    "            print(f\"Loading best weights from {best_path_this_stage} to continue...\")\n",
    "            model = LitClassifier.load_from_checkpoint(best_path_this_stage, strict=False)  # Use strict=False to ignore missing keys if any\n",
    "        else:\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. No checkpoint was saved. ---\")\n",
    "            # If no checkpoint was saved, the model object will just have the weights from the last epoch.\n",
    "\n",
    "        # 7. Test the model after each stage\n",
    "        print(f\"\\n--- Testing model after Fold {fold+1} Stage {i+1} ---\")\n",
    "        trainer.test(model, dataloaders=fold_loader, ckpt_path=best_path_this_stage)\n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "        best_clfs = get_best_roc_envelope(list_weighted_clfs, results_original_roc)\n",
    "    list_folds_weighted_clfs.append(list_weighted_clfs)\n",
    "    list_folds_best_models.append(best_clfs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6b93abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to pickle/NN_data2_weighted.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_models': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.5081967),\n",
       "    'threshold': np.float16(0.504)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0234375),\n",
       "    'tpr': np.float32(0.5163934),\n",
       "    'threshold': np.float16(0.3767)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.03125),\n",
       "    'tpr': np.float32(0.52459013),\n",
       "    'threshold': np.float16(0.669)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0390625),\n",
       "    'tpr': np.float32(0.5327869),\n",
       "    'threshold': np.float16(0.625)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0546875),\n",
       "    'tpr': np.float32(0.5409836),\n",
       "    'threshold': np.float16(0.412)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0625),\n",
       "    'tpr': np.float32(0.5491803),\n",
       "    'threshold': np.float16(0.6436)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.078125),\n",
       "    'tpr': np.float32(0.55737704),\n",
       "    'threshold': np.float16(0.562)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09375),\n",
       "    'tpr': np.float32(0.56557375),\n",
       "    'threshold': np.float16(0.675)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.109375),\n",
       "    'tpr': np.float32(0.57377046),\n",
       "    'threshold': np.float16(0.3923)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.125),\n",
       "    'tpr': np.float32(0.58196723),\n",
       "    'threshold': np.float16(0.879)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1328125),\n",
       "    'tpr': np.float32(0.59016395),\n",
       "    'threshold': np.float16(0.8936)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.140625),\n",
       "    'tpr': np.float32(0.59836066),\n",
       "    'threshold': np.float16(0.905)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1484375),\n",
       "    'tpr': np.float32(0.60655737),\n",
       "    'threshold': np.float16(0.4072)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.171875),\n",
       "    'tpr': np.float32(0.6639344),\n",
       "    'threshold': np.float16(0.7993)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1796875),\n",
       "    'tpr': np.float32(0.6721311),\n",
       "    'threshold': np.float16(0.7783)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1953125),\n",
       "    'tpr': np.float32(0.704918),\n",
       "    'threshold': np.float16(0.9375)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.203125),\n",
       "    'tpr': np.float32(0.71311474),\n",
       "    'threshold': np.float16(0.96)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.21875),\n",
       "    'tpr': np.float32(0.74590164),\n",
       "    'threshold': np.float16(0.8726)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2265625),\n",
       "    'tpr': np.float32(0.75409836),\n",
       "    'threshold': np.float16(0.8027)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.234375),\n",
       "    'tpr': np.float32(0.7704918),\n",
       "    'threshold': np.float16(0.834)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2421875),\n",
       "    'tpr': np.float32(0.77868855),\n",
       "    'threshold': np.float16(0.85)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.25),\n",
       "    'tpr': np.float32(0.78688526),\n",
       "    'threshold': np.float16(0.806)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.265625),\n",
       "    'tpr': np.float32(0.795082),\n",
       "    'threshold': np.float16(0.824)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2734375),\n",
       "    'tpr': np.float32(0.8032787),\n",
       "    'threshold': np.float16(0.8584)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.28125),\n",
       "    'tpr': np.float32(0.8196721),\n",
       "    'threshold': np.float16(0.8955)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.296875),\n",
       "    'tpr': np.float32(0.8278689),\n",
       "    'threshold': np.float16(0.932)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3125),\n",
       "    'tpr': np.float32(0.8360656),\n",
       "    'threshold': np.float16(0.8496)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.328125),\n",
       "    'tpr': np.float32(0.8442623),\n",
       "    'threshold': np.float16(0.8633)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3359375),\n",
       "    'tpr': np.float32(0.86885244),\n",
       "    'threshold': np.float16(0.8975)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3671875),\n",
       "    'tpr': np.float32(0.8852459),\n",
       "    'threshold': np.float16(0.6895)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.375),\n",
       "    'tpr': np.float32(0.90163934),\n",
       "    'threshold': np.float16(0.712)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.40625),\n",
       "    'tpr': np.float32(0.90983605),\n",
       "    'threshold': np.float16(0.5156)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.421875),\n",
       "    'tpr': np.float32(0.92622954),\n",
       "    'threshold': np.float16(0.4807)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4375),\n",
       "    'tpr': np.float32(0.93442625),\n",
       "    'threshold': np.float16(0.878)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4453125),\n",
       "    'tpr': np.float32(0.94262296),\n",
       "    'threshold': np.float16(0.716)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.453125),\n",
       "    'tpr': np.float32(0.9672131),\n",
       "    'threshold': np.float16(0.855)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4609375),\n",
       "    'tpr': np.float32(0.9836066),\n",
       "    'threshold': np.float16(0.849)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4921875),\n",
       "    'tpr': np.float32(0.9918033),\n",
       "    'threshold': np.float16(0.6035)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5859375),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.4111)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.43939394),\n",
       "    'threshold': np.float16(0.8096)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.008474576),\n",
       "    'tpr': np.float32(0.46969697),\n",
       "    'threshold': np.float16(0.5005)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.016949153),\n",
       "    'tpr': np.float32(0.47727272),\n",
       "    'threshold': np.float16(0.36)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025423728),\n",
       "    'tpr': np.float32(0.5151515),\n",
       "    'threshold': np.float16(0.4856)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.042372882),\n",
       "    'tpr': np.float32(0.52272725),\n",
       "    'threshold': np.float16(0.52)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.050847456),\n",
       "    'tpr': np.float32(0.5378788),\n",
       "    'threshold': np.float16(0.5605)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06779661),\n",
       "    'tpr': np.float32(0.5530303),\n",
       "    'threshold': np.float16(0.6377)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.084745765),\n",
       "    'tpr': np.float32(0.56060606),\n",
       "    'threshold': np.float16(0.5815)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09322034),\n",
       "    'tpr': np.float32(0.5681818),\n",
       "    'threshold': np.float16(0.5776)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.11016949),\n",
       "    'tpr': np.float32(0.57575756),\n",
       "    'threshold': np.float16(0.7104)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.12711865),\n",
       "    'tpr': np.float32(0.6136364),\n",
       "    'threshold': np.float16(0.747)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1440678),\n",
       "    'tpr': np.float32(0.6212121),\n",
       "    'threshold': np.float16(0.4407)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15254237),\n",
       "    'tpr': np.float32(0.6287879),\n",
       "    'threshold': np.float16(0.4514)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.16949153),\n",
       "    'tpr': np.float32(0.6439394),\n",
       "    'threshold': np.float16(0.5347)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1779661),\n",
       "    'tpr': np.float32(0.65909094),\n",
       "    'threshold': np.float16(0.4976)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.18644068),\n",
       "    'tpr': np.float32(0.67424244),\n",
       "    'threshold': np.float16(0.4744)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.19491525),\n",
       "    'tpr': np.float32(0.6818182),\n",
       "    'threshold': np.float16(0.5977)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.20338982),\n",
       "    'tpr': np.float32(0.6969697),\n",
       "    'threshold': np.float16(0.4626)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.22033899),\n",
       "    'tpr': np.float32(0.7121212),\n",
       "    'threshold': np.float16(0.4434)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2542373),\n",
       "    'tpr': np.float32(0.75),\n",
       "    'threshold': np.float16(0.6113)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.26271185),\n",
       "    'tpr': np.float32(0.780303),\n",
       "    'threshold': np.float16(0.5527)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.27118644),\n",
       "    'tpr': np.float32(0.7878788),\n",
       "    'threshold': np.float16(0.4998)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.27966103),\n",
       "    'tpr': np.float32(0.81060606),\n",
       "    'threshold': np.float16(0.623)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2881356),\n",
       "    'tpr': np.float32(0.8181818),\n",
       "    'threshold': np.float16(0.6675)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29661018),\n",
       "    'tpr': np.float32(0.82575756),\n",
       "    'threshold': np.float16(0.537)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.30508474),\n",
       "    'tpr': np.float32(0.8333333),\n",
       "    'threshold': np.float16(0.566)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.31355932),\n",
       "    'tpr': np.float32(0.8484849),\n",
       "    'threshold': np.float16(0.822)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3220339),\n",
       "    'tpr': np.float32(0.8712121),\n",
       "    'threshold': np.float16(0.881)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.33050847),\n",
       "    'tpr': np.float32(0.8787879),\n",
       "    'threshold': np.float16(0.641)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3983051),\n",
       "    'tpr': np.float32(0.8939394),\n",
       "    'threshold': np.float16(0.806)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41525424),\n",
       "    'tpr': np.float32(0.9015151),\n",
       "    'threshold': np.float16(0.448)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.42372882),\n",
       "    'tpr': np.float32(0.9166667),\n",
       "    'threshold': np.float16(0.6514)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.43220338),\n",
       "    'tpr': np.float32(0.92424244),\n",
       "    'threshold': np.float16(0.48)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.44915253),\n",
       "    'tpr': np.float32(0.93939394),\n",
       "    'threshold': np.float16(0.4712)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4661017),\n",
       "    'tpr': np.float32(0.9469697),\n",
       "    'threshold': np.float16(0.4656)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.47457626),\n",
       "    'tpr': np.float32(0.95454544),\n",
       "    'threshold': np.float16(0.445)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4915254),\n",
       "    'tpr': np.float32(0.9621212),\n",
       "    'threshold': np.float16(0.4956)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5084746),\n",
       "    'tpr': np.float32(0.969697),\n",
       "    'threshold': np.float16(0.5435)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5338983),\n",
       "    'tpr': np.float32(0.97727275),\n",
       "    'threshold': np.float16(0.604)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5423729),\n",
       "    'tpr': np.float32(0.9848485),\n",
       "    'threshold': np.float16(0.4773)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.59322035),\n",
       "    'tpr': np.float32(0.99242425),\n",
       "    'threshold': np.float16(0.338)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.6101695),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.3115)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.5153846),\n",
       "    'threshold': np.float16(0.425)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.008333334),\n",
       "    'tpr': np.float32(0.56153846),\n",
       "    'threshold': np.float16(0.5303)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.016666668),\n",
       "    'tpr': np.float32(0.5769231),\n",
       "    'threshold': np.float16(0.4202)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025),\n",
       "    'tpr': np.float32(0.5846154),\n",
       "    'threshold': np.float16(0.4377)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.041666668),\n",
       "    'tpr': np.float32(0.5923077),\n",
       "    'threshold': np.float16(0.508)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.05),\n",
       "    'tpr': np.float32(0.6076923),\n",
       "    'threshold': np.float16(0.626)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06666667),\n",
       "    'tpr': np.float32(0.61538464),\n",
       "    'threshold': np.float16(0.5586)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.083333336),\n",
       "    'tpr': np.float32(0.63846153),\n",
       "    'threshold': np.float16(0.578)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.11666667),\n",
       "    'tpr': np.float32(0.64615387),\n",
       "    'threshold': np.float16(0.5947)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.125),\n",
       "    'tpr': np.float32(0.65384614),\n",
       "    'threshold': np.float16(0.67)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.13333334),\n",
       "    'tpr': np.float32(0.66923076),\n",
       "    'threshold': np.float16(0.4548)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.14166667),\n",
       "    'tpr': np.float32(0.6923077),\n",
       "    'threshold': np.float16(0.6016)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.16666667),\n",
       "    'tpr': np.float32(0.7),\n",
       "    'threshold': np.float16(0.664)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.19166666),\n",
       "    'tpr': np.float32(0.7153846),\n",
       "    'threshold': np.float16(0.4585)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2),\n",
       "    'tpr': np.float32(0.7307692),\n",
       "    'threshold': np.float16(0.4312)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.225),\n",
       "    'tpr': np.float32(0.74615383),\n",
       "    'threshold': np.float16(0.495)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.23333333),\n",
       "    'tpr': np.float32(0.75384617),\n",
       "    'threshold': np.float16(0.4712)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.24166666),\n",
       "    'tpr': np.float32(0.76153845),\n",
       "    'threshold': np.float16(0.5337)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.25833333),\n",
       "    'tpr': np.float32(0.77692306),\n",
       "    'threshold': np.float16(0.6035)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.26666668),\n",
       "    'tpr': np.float32(0.7846154),\n",
       "    'threshold': np.float16(0.5713)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.275),\n",
       "    'tpr': np.float32(0.7923077),\n",
       "    'threshold': np.float16(0.674)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3),\n",
       "    'tpr': np.float32(0.8076923),\n",
       "    'threshold': np.float16(0.9546)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.30833334),\n",
       "    'tpr': np.float32(0.8153846),\n",
       "    'threshold': np.float16(0.946)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.325),\n",
       "    'tpr': np.float32(0.83076924),\n",
       "    'threshold': np.float16(0.4607)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.34166667),\n",
       "    'tpr': np.float32(0.8384615),\n",
       "    'threshold': np.float16(0.4553)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.35),\n",
       "    'tpr': np.float32(0.84615386),\n",
       "    'threshold': np.float16(0.9023)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.375),\n",
       "    'tpr': np.float32(0.86153847),\n",
       "    'threshold': np.float16(0.8154)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.38333333),\n",
       "    'tpr': np.float32(0.88461536),\n",
       "    'threshold': np.float16(0.7793)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4),\n",
       "    'tpr': np.float32(0.8923077),\n",
       "    'threshold': np.float16(0.8755)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41666666),\n",
       "    'tpr': np.float32(0.95384616),\n",
       "    'threshold': np.float16(0.8877)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.43333334),\n",
       "    'tpr': np.float32(0.96153843),\n",
       "    'threshold': np.float16(0.856)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.45833334),\n",
       "    'tpr': np.float32(0.97692305),\n",
       "    'threshold': np.float16(0.844)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.475),\n",
       "    'tpr': np.float32(0.9846154),\n",
       "    'threshold': np.float16(0.6187)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5083333),\n",
       "    'tpr': np.float32(0.99230766),\n",
       "    'threshold': np.float16(0.7373)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.56666666),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.585)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.47413793),\n",
       "    'threshold': np.float16(0.3843)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0074626864),\n",
       "    'tpr': np.float32(0.4827586),\n",
       "    'threshold': np.float16(0.4014)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.014925373),\n",
       "    'tpr': np.float32(0.5),\n",
       "    'threshold': np.float16(0.402)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.02238806),\n",
       "    'tpr': np.float32(0.5086207),\n",
       "    'threshold': np.float16(0.4626)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.029850746),\n",
       "    'tpr': np.float32(0.54310346),\n",
       "    'threshold': np.float16(0.518)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.03731343),\n",
       "    'tpr': np.float32(0.5603448),\n",
       "    'threshold': np.float16(0.707)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.052238807),\n",
       "    'tpr': np.float32(0.5948276),\n",
       "    'threshold': np.float16(0.5454)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.05970149),\n",
       "    'tpr': np.float32(0.6034483),\n",
       "    'threshold': np.float16(0.5312)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06716418),\n",
       "    'tpr': np.float32(0.61206895),\n",
       "    'threshold': np.float16(0.4727)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.08955224),\n",
       "    'tpr': np.float32(0.62068963),\n",
       "    'threshold': np.float16(0.642)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.104477614),\n",
       "    'tpr': np.float32(0.62931037),\n",
       "    'threshold': np.float16(0.4487)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.11940298),\n",
       "    'tpr': np.float32(0.63793105),\n",
       "    'threshold': np.float16(0.786)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.13432837),\n",
       "    'tpr': np.float32(0.6465517),\n",
       "    'threshold': np.float16(0.5054)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.14179105),\n",
       "    'tpr': np.float32(0.6551724),\n",
       "    'threshold': np.float16(0.77)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.14925373),\n",
       "    'tpr': np.float32(0.67241377),\n",
       "    'threshold': np.float16(0.9785)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1641791),\n",
       "    'tpr': np.float32(0.6896552),\n",
       "    'threshold': np.float16(0.91)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.17910448),\n",
       "    'tpr': np.float32(0.73275864),\n",
       "    'threshold': np.float16(0.923)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.19402985),\n",
       "    'tpr': np.float32(0.7413793),\n",
       "    'threshold': np.float16(0.9365)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2238806),\n",
       "    'tpr': np.float32(0.75),\n",
       "    'threshold': np.float16(0.935)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.23134328),\n",
       "    'tpr': np.float32(0.76724136),\n",
       "    'threshold': np.float16(0.948)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.24626866),\n",
       "    'tpr': np.float32(0.7758621),\n",
       "    'threshold': np.float16(0.8857)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.25373134),\n",
       "    'tpr': np.float32(0.7844828),\n",
       "    'threshold': np.float16(0.9634)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29104477),\n",
       "    'tpr': np.float32(0.80172414),\n",
       "    'threshold': np.float16(0.677)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29850745),\n",
       "    'tpr': np.float32(0.8189655),\n",
       "    'threshold': np.float16(0.842)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.30597016),\n",
       "    'tpr': np.float32(0.8534483),\n",
       "    'threshold': np.float16(0.7935)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.31343284),\n",
       "    'tpr': np.float32(0.87068963),\n",
       "    'threshold': np.float16(0.925)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.32089552),\n",
       "    'tpr': np.float32(0.9051724),\n",
       "    'threshold': np.float16(0.8286)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3432836),\n",
       "    'tpr': np.float32(0.9137931),\n",
       "    'threshold': np.float16(0.6675)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.35074627),\n",
       "    'tpr': np.float32(0.92241377),\n",
       "    'threshold': np.float16(0.654)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.38059703),\n",
       "    'tpr': np.float32(0.9310345),\n",
       "    'threshold': np.float16(0.4656)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3955224),\n",
       "    'tpr': np.float32(0.9396552),\n",
       "    'threshold': np.float16(0.9165)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41044775),\n",
       "    'tpr': np.float32(0.94827586),\n",
       "    'threshold': np.float16(0.7666)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41791046),\n",
       "    'tpr': np.float32(0.9741379),\n",
       "    'threshold': np.float16(0.8413)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4477612),\n",
       "    'tpr': np.float32(0.98275864),\n",
       "    'threshold': np.float16(0.7373)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4552239),\n",
       "    'tpr': np.float32(0.9913793),\n",
       "    'threshold': np.float16(0.879)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.655)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}]],\n",
       " 'weighted_clfs': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0703125, 0.078125 , 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.15625  , 0.1796875, 0.203125 , 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.25     , 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.609375 , 0.6171875, 0.6171875, 0.6171875,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.625    , 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.7265625, 0.734375 , 0.734375 , 0.734375 , 0.734375 ,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.75     , 0.75     , 0.75     ,\n",
       "            0.75     , 0.7578125, 0.7578125, 0.7578125, 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8046875, 0.8125   , 0.8125   ,\n",
       "            0.8125   , 0.8203125, 0.8203125, 0.828125 , 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.875    , 0.875    , 0.875    ,\n",
       "            0.875    , 0.8828125, 0.8828125, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.02459016, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13114753, 0.13114753, 0.13934426, 0.14754099, 0.14754099,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.21311475, 0.21311475,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.22950819, 0.23770492,\n",
       "            0.23770492, 0.24590164, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.27868852, 0.29508197, 0.30327868, 0.3114754 , 0.3114754 ,\n",
       "            0.31967214, 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40163934, 0.40163934,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.4262295 , 0.4262295 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.4918033 , 0.5       ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6229508 , 0.6393443 , 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6721311 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.71311474, 0.71311474, 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.73770493, 0.74590164,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.86885244, 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4766, 0.4739, 0.4731, 0.4724, 0.472 , 0.4712, 0.471 ,\n",
       "            0.4692, 0.469 , 0.468 , 0.4675, 0.4666, 0.4663, 0.466 , 0.4658,\n",
       "            0.4656, 0.4653, 0.465 , 0.4646, 0.464 , 0.4639, 0.463 , 0.4626,\n",
       "            0.4624, 0.4622, 0.4612, 0.4607, 0.4595, 0.4565, 0.4558, 0.4548,\n",
       "            0.4546, 0.454 , 0.4487, 0.446 , 0.4443, 0.443 , 0.4424, 0.442 ,\n",
       "            0.4414, 0.4404, 0.4375, 0.4348, 0.4326, 0.4304, 0.4302, 0.43  ,\n",
       "            0.4287, 0.427 , 0.426 , 0.4224, 0.4211, 0.4185, 0.4182, 0.4175,\n",
       "            0.4155, 0.415 , 0.4136, 0.4124, 0.4119, 0.411 , 0.41  , 0.4094,\n",
       "            0.4087, 0.4053, 0.4045, 0.4043, 0.4026, 0.402 , 0.4006, 0.3997,\n",
       "            0.3994, 0.3975, 0.3972, 0.397 , 0.3962, 0.3945, 0.394 , 0.3936,\n",
       "            0.3923, 0.3918, 0.3909, 0.3906, 0.39  , 0.3896, 0.3894, 0.3884,\n",
       "            0.388 , 0.3875, 0.3867, 0.386 , 0.3857, 0.3855, 0.385 , 0.3843,\n",
       "            0.3838, 0.3828, 0.3818, 0.381 , 0.3801, 0.3792, 0.3782, 0.3762,\n",
       "            0.376 , 0.3757, 0.3755, 0.3748, 0.374 , 0.373 , 0.3726, 0.3723,\n",
       "            0.3718, 0.3713, 0.3708, 0.3706, 0.3704, 0.37  , 0.3699, 0.3687,\n",
       "            0.3684, 0.3674, 0.3672, 0.3667, 0.3657, 0.3652, 0.3647, 0.3645,\n",
       "            0.3638, 0.3633, 0.3628, 0.3623, 0.362 , 0.3613, 0.3608, 0.3596,\n",
       "            0.3584, 0.3577, 0.3572, 0.357 , 0.3564, 0.3562, 0.356 , 0.3557,\n",
       "            0.3552, 0.354 , 0.3525, 0.3523, 0.3513, 0.35  , 0.3489, 0.3484,\n",
       "            0.348 , 0.3477, 0.3472, 0.3452, 0.344 , 0.3433, 0.3428, 0.3423,\n",
       "            0.342 , 0.3413, 0.341 , 0.3408, 0.3406, 0.3396, 0.339 , 0.3384,\n",
       "            0.3372, 0.3362, 0.336 , 0.3354, 0.331 , 0.3303, 0.33  , 0.3293,\n",
       "            0.3286, 0.327 , 0.3262, 0.326 , 0.3254, 0.3245, 0.323 , 0.3223,\n",
       "            0.3196, 0.3188, 0.3184, 0.3179, 0.317 , 0.3142, 0.3135, 0.3123,\n",
       "            0.3088, 0.3083, 0.306 , 0.305 , 0.3042, 0.3035, 0.302 , 0.2974,\n",
       "            0.297 , 0.2932, 0.2883, 0.2805, 0.2666, 0.262 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.0859375, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1640625, 0.171875 ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.2421875,\n",
       "            0.25     , 0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.6015625,\n",
       "            0.6015625, 0.6171875, 0.625    , 0.625    , 0.625    , 0.625    ,\n",
       "            0.625    , 0.625    , 0.625    , 0.625    , 0.625    , 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6796875,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6953125, 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.75     , 0.7578125, 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8046875, 0.8046875, 0.8125   , 0.8125   , 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.828125 , 0.828125 , 0.8359375, 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.8515625, 0.8515625, 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.8671875, 0.8671875, 0.875    , 0.875    , 0.8828125,\n",
       "            0.8828125, 0.8828125, 0.8828125, 0.890625 , 0.890625 , 0.8984375,\n",
       "            0.8984375, 0.90625  , 0.90625  , 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9296875, 0.9375   , 0.9453125, 0.9453125, 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.9609375, 0.9609375, 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.01639344, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.13934426, 0.13934426,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.19672132, 0.20491803, 0.21311475, 0.21311475,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.24590164, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.32786885, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.352459  , 0.36065573, 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.37704918, 0.39344263, 0.39344263,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.43442622, 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5081967 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.6393443 , 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.71311474, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.74590164, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4568, 0.455 , 0.4546, 0.451 , 0.4507, 0.4504, 0.4495,\n",
       "            0.4478, 0.4475, 0.4473, 0.4465, 0.4463, 0.4458, 0.4456, 0.4448,\n",
       "            0.4446, 0.4438, 0.4434, 0.4429, 0.4421, 0.4417, 0.4414, 0.4412,\n",
       "            0.44  , 0.439 , 0.4368, 0.4365, 0.4363, 0.4358, 0.435 , 0.4343,\n",
       "            0.433 , 0.431 , 0.428 , 0.4265, 0.4248, 0.4238, 0.423 , 0.4204,\n",
       "            0.413 , 0.4116, 0.4094, 0.4092, 0.4075, 0.407 , 0.4014, 0.4006,\n",
       "            0.3965, 0.3962, 0.393 , 0.3926, 0.3896, 0.3872, 0.3857, 0.384 ,\n",
       "            0.379 , 0.3733, 0.371 , 0.37  , 0.3699, 0.3667, 0.3655, 0.3647,\n",
       "            0.3645, 0.364 , 0.3635, 0.3633, 0.3608, 0.3606, 0.3591, 0.359 ,\n",
       "            0.358 , 0.3555, 0.3545, 0.3525, 0.3481, 0.3477, 0.3472, 0.346 ,\n",
       "            0.3452, 0.3438, 0.343 , 0.3403, 0.3394, 0.3374, 0.3372, 0.3367,\n",
       "            0.3362, 0.335 , 0.3345, 0.3337, 0.3335, 0.3333, 0.3325, 0.3313,\n",
       "            0.3308, 0.33  , 0.3298, 0.3296, 0.3293, 0.3284, 0.328 , 0.3257,\n",
       "            0.3254, 0.323 , 0.3228, 0.321 , 0.3203, 0.3198, 0.3186, 0.3167,\n",
       "            0.3162, 0.3154, 0.315 , 0.3142, 0.313 , 0.3123, 0.3115, 0.3108,\n",
       "            0.3103, 0.31  , 0.3098, 0.3088, 0.3086, 0.308 , 0.3079, 0.3076,\n",
       "            0.3066, 0.306 , 0.3057, 0.3047, 0.3044, 0.304 , 0.3035, 0.3032,\n",
       "            0.3027, 0.3022, 0.302 , 0.3018, 0.3013, 0.301 , 0.3003, 0.2998,\n",
       "            0.2969, 0.2966, 0.295 , 0.294 , 0.2932, 0.2927, 0.2922, 0.2915,\n",
       "            0.2903, 0.29  , 0.2898, 0.287 , 0.2852, 0.2847, 0.2844, 0.2842,\n",
       "            0.2825, 0.2817, 0.2815, 0.2812, 0.2803, 0.2795, 0.279 , 0.2786,\n",
       "            0.278 , 0.276 , 0.2756, 0.2737, 0.2734, 0.2732, 0.2727, 0.2725,\n",
       "            0.2722, 0.2705, 0.2695, 0.2693, 0.2676, 0.2646, 0.2637, 0.263 ,\n",
       "            0.2605, 0.2603, 0.2573, 0.2566, 0.2559, 0.2551, 0.2542, 0.2532,\n",
       "            0.253 , 0.2502, 0.2487, 0.2473, 0.2462, 0.2451, 0.2444, 0.244 ,\n",
       "            0.2413, 0.2394, 0.239 , 0.2383, 0.2352, 0.234 , 0.2289, 0.2277,\n",
       "            0.2229, 0.2135, 0.2076, 0.1984], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.125    , 0.1328125, 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.5      , 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.59375  , 0.59375  , 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.6953125, 0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.75     , 0.75     , 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.78125  , 0.7890625, 0.7890625, 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8046875, 0.8046875, 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.828125 , 0.8359375, 0.8359375, 0.84375  , 0.84375  ,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.875    ,\n",
       "            0.875    , 0.8828125, 0.8828125, 0.890625 , 0.890625 , 0.8984375,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9296875,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.9921875, 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.04098361, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.19672132, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.23770492, 0.24590164, 0.24590164, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.30327868, 0.3114754 ,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.32786885, 0.32786885,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.36885247, 0.37704918, 0.37704918,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.5       , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.74590164, 0.74590164, 0.75409836, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4365, 0.4358, 0.4312, 0.43  , 0.4297, 0.4294, 0.4292,\n",
       "            0.4285, 0.4282, 0.4258, 0.4253, 0.425 , 0.4243, 0.4229, 0.4226,\n",
       "            0.422 , 0.4211, 0.4207, 0.4202, 0.4192, 0.4185, 0.418 , 0.4175,\n",
       "            0.4172, 0.4155, 0.4143, 0.4136, 0.4133, 0.4102, 0.41  , 0.4097,\n",
       "            0.4084, 0.4067, 0.4055, 0.4053, 0.4019, 0.3997, 0.396 , 0.3955,\n",
       "            0.3945, 0.393 , 0.392 , 0.3914, 0.3809, 0.3796, 0.3794, 0.3752,\n",
       "            0.3723, 0.3713, 0.366 , 0.3655, 0.3652, 0.3635, 0.3625, 0.3538,\n",
       "            0.353 , 0.348 , 0.344 , 0.3428, 0.3396, 0.3374, 0.334 , 0.3281,\n",
       "            0.327 , 0.3257, 0.3252, 0.3232, 0.3218, 0.3193, 0.3186, 0.3179,\n",
       "            0.3171, 0.317 , 0.3154, 0.3145, 0.3137, 0.3127, 0.3057, 0.3052,\n",
       "            0.303 , 0.3005, 0.298 , 0.2974, 0.297 , 0.293 , 0.292 , 0.2905,\n",
       "            0.2903, 0.2898, 0.288 , 0.2864, 0.2861, 0.285 , 0.2847, 0.2844,\n",
       "            0.2834, 0.2825, 0.2822, 0.282 , 0.2815, 0.281 , 0.2805, 0.2795,\n",
       "            0.2793, 0.279 , 0.2786, 0.2773, 0.276 , 0.2744, 0.2742, 0.2722,\n",
       "            0.2708, 0.2703, 0.27  , 0.2678, 0.2664, 0.2642, 0.263 , 0.2625,\n",
       "            0.2622, 0.2617, 0.2615, 0.2612, 0.2605, 0.2588, 0.2585, 0.2576,\n",
       "            0.2568, 0.2563, 0.2554, 0.255 , 0.2546, 0.2542, 0.2537, 0.2534,\n",
       "            0.2527, 0.252 , 0.2512, 0.2507, 0.2505, 0.25  , 0.249 , 0.2489,\n",
       "            0.2487, 0.2478, 0.2477, 0.247 , 0.2449, 0.2448, 0.2441, 0.244 ,\n",
       "            0.2438, 0.2428, 0.2422, 0.2417, 0.241 , 0.2394, 0.2388, 0.2384,\n",
       "            0.2382, 0.2375, 0.2367, 0.2363, 0.2355, 0.2347, 0.2335, 0.2332,\n",
       "            0.2323, 0.231 , 0.2303, 0.2297, 0.2278, 0.2264, 0.2261, 0.2257,\n",
       "            0.2242, 0.2238, 0.222 , 0.2213, 0.2207, 0.2202, 0.2173, 0.2168,\n",
       "            0.2163, 0.2144, 0.2142, 0.213 , 0.2129, 0.2108, 0.2104, 0.2101,\n",
       "            0.2098, 0.2084, 0.2068, 0.2004, 0.1989, 0.1985, 0.197 , 0.1953,\n",
       "            0.195 , 0.1948, 0.1946, 0.1943, 0.1937, 0.1936, 0.1912, 0.1896,\n",
       "            0.1874, 0.1866, 0.1863, 0.1837, 0.1826, 0.1821, 0.1819, 0.1812,\n",
       "            0.181 , 0.1746, 0.174 , 0.1675, 0.1581, 0.1577, 0.1462],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.703125 , 0.703125 , 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.75     ,\n",
       "            0.75     , 0.75     , 0.75     , 0.75     , 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.7734375, 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.796875 , 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8125   , 0.8125   , 0.8203125, 0.828125 , 0.828125 , 0.828125 ,\n",
       "            0.828125 , 0.8359375, 0.8359375, 0.8359375, 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9296875,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.9609375, 0.9609375,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.984375 , 0.9921875, 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.01639344, 0.02459016, 0.03278688, 0.03278688,\n",
       "            0.03278688, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22950819, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.24590164, 0.25409836, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.29508197, 0.29508197, 0.30327868, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.352459  , 0.36065573,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6557377 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.416 , 0.4158, 0.412 , 0.4116, 0.4102, 0.4087, 0.4082,\n",
       "            0.408 , 0.4062, 0.4048, 0.403 , 0.4028, 0.4023, 0.4006, 0.4004,\n",
       "            0.3987, 0.3984, 0.398 , 0.3977, 0.3972, 0.3967, 0.3958, 0.3936,\n",
       "            0.393 , 0.3928, 0.3926, 0.3906, 0.3892, 0.3884, 0.3835, 0.383 ,\n",
       "            0.3826, 0.381 , 0.3809, 0.3792, 0.3784, 0.3772, 0.373 , 0.3728,\n",
       "            0.3672, 0.3652, 0.3645, 0.3633, 0.3628, 0.3618, 0.3523, 0.3513,\n",
       "            0.3474, 0.3425, 0.339 , 0.3372, 0.337 , 0.3367, 0.3354, 0.3308,\n",
       "            0.328 , 0.3218, 0.3174, 0.3108, 0.3076, 0.3044, 0.3037, 0.3   ,\n",
       "            0.2986, 0.2893, 0.289 , 0.2869, 0.2866, 0.2864, 0.2856, 0.2852,\n",
       "            0.28  , 0.2795, 0.2793, 0.2783, 0.2769, 0.2766, 0.276 , 0.2727,\n",
       "            0.2703, 0.2656, 0.2651, 0.2642, 0.2607, 0.2593, 0.258 , 0.2568,\n",
       "            0.2534, 0.2517, 0.2515, 0.2502, 0.2487, 0.247 , 0.2445, 0.2444,\n",
       "            0.244 , 0.2433, 0.2429, 0.2422, 0.2415, 0.2413, 0.2399, 0.2384,\n",
       "            0.2383, 0.2382, 0.2372, 0.2351, 0.2347, 0.234 , 0.2334, 0.2323,\n",
       "            0.2318, 0.231 , 0.2306, 0.2303, 0.2286, 0.228 , 0.2264, 0.2261,\n",
       "            0.2239, 0.2213, 0.2211, 0.2207, 0.2202, 0.2181, 0.2179, 0.217 ,\n",
       "            0.2148, 0.2147, 0.2145, 0.2144, 0.2142, 0.2115, 0.211 , 0.2104,\n",
       "            0.2095, 0.2094, 0.2089, 0.2086, 0.2079, 0.2075, 0.2074, 0.207 ,\n",
       "            0.2068, 0.2059, 0.2058, 0.2053, 0.2034, 0.2031, 0.2026, 0.2018,\n",
       "            0.2015, 0.2   , 0.1996, 0.1987, 0.1978, 0.1974, 0.1973, 0.1971,\n",
       "            0.1965, 0.1964, 0.1954, 0.1953, 0.1947, 0.1946, 0.1942, 0.194 ,\n",
       "            0.1931, 0.1904, 0.1897, 0.1893, 0.1892, 0.1886, 0.1879, 0.187 ,\n",
       "            0.1863, 0.1859, 0.185 , 0.1843, 0.1842, 0.1833, 0.1815, 0.1805,\n",
       "            0.18  , 0.179 , 0.1781, 0.178 , 0.177 , 0.1768, 0.1766, 0.1754,\n",
       "            0.1743, 0.1715, 0.1714, 0.1698, 0.1686, 0.1685, 0.1677, 0.1671,\n",
       "            0.1647, 0.1644, 0.1626, 0.162 , 0.1604, 0.1602, 0.1588, 0.1542,\n",
       "            0.1525, 0.1519, 0.1512, 0.1509, 0.1506, 0.15  , 0.1475, 0.1471,\n",
       "            0.1469, 0.1454, 0.1442, 0.1436, 0.1434, 0.1406, 0.1395, 0.1392,\n",
       "            0.1385, 0.1365, 0.1349, 0.1337, 0.1328, 0.1302, 0.1242, 0.1184,\n",
       "            0.115 , 0.1058], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.65625  , 0.65625  , 0.6640625, 0.6640625, 0.6640625,\n",
       "            0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6796875, 0.6796875,\n",
       "            0.6796875, 0.6953125, 0.6953125, 0.6953125, 0.6953125, 0.6953125,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.71875  , 0.71875  , 0.71875  , 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.75     , 0.75     , 0.75     ,\n",
       "            0.75     , 0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8046875, 0.8125   , 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.8359375, 0.8359375, 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.9140625, 0.921875 , 0.9296875, 0.9296875, 0.9296875,\n",
       "            0.9296875, 0.9375   , 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.9921875, 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.24590164, 0.25409836,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.36885247, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.40983605, 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.5327869 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.59836066, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.72131145, 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.392  , 0.3916 , 0.391  , 0.3894 , 0.3877 , 0.3848 ,\n",
       "            0.384  , 0.3838 , 0.382  , 0.3809 , 0.3792 , 0.379  , 0.3782 ,\n",
       "            0.3765 , 0.3752 , 0.3743 , 0.3735 , 0.3733 , 0.3728 , 0.3716 ,\n",
       "            0.3713 , 0.369  , 0.3684 , 0.3657 , 0.3652 , 0.3645 , 0.3638 ,\n",
       "            0.3635 , 0.363  , 0.3572 , 0.3555 , 0.3547 , 0.3538 , 0.3528 ,\n",
       "            0.3523 , 0.352  , 0.3518 , 0.3506 , 0.3474 , 0.3438 , 0.3394 ,\n",
       "            0.3372 , 0.3345 , 0.3337 , 0.333  , 0.328  , 0.3271 , 0.3254 ,\n",
       "            0.3174 , 0.3118 , 0.3115 , 0.3079 , 0.3062 , 0.3003 , 0.2998 ,\n",
       "            0.2993 , 0.2969 , 0.29   , 0.2869 , 0.282  , 0.2805 , 0.2778 ,\n",
       "            0.2761 , 0.2722 , 0.265  , 0.2615 , 0.261  , 0.2573 , 0.2544 ,\n",
       "            0.2542 , 0.2524 , 0.252  , 0.251  , 0.249  , 0.2485 , 0.2434 ,\n",
       "            0.243  , 0.2407 , 0.2405 , 0.2394 , 0.237  , 0.2362 , 0.2335 ,\n",
       "            0.2334 , 0.2313 , 0.2307 , 0.2301 , 0.2278 , 0.2238 , 0.2222 ,\n",
       "            0.2218 , 0.2207 , 0.2203 , 0.2185 , 0.2167 , 0.2147 , 0.2113 ,\n",
       "            0.2103 , 0.2089 , 0.2081 , 0.2075 , 0.2068 , 0.2056 , 0.2045 ,\n",
       "            0.2043 , 0.2042 , 0.2035 , 0.2031 , 0.2013 , 0.2007 , 0.1996 ,\n",
       "            0.1987 , 0.1982 , 0.1978 , 0.1971 , 0.1968 , 0.1959 , 0.1958 ,\n",
       "            0.1943 , 0.194  , 0.1925 , 0.1921 , 0.1918 , 0.1909 , 0.1892 ,\n",
       "            0.188  , 0.1857 , 0.1849 , 0.1843 , 0.1842 , 0.1841 , 0.1835 ,\n",
       "            0.1829 , 0.1819 , 0.181  , 0.1796 , 0.1787 , 0.1781 , 0.1776 ,\n",
       "            0.177  , 0.1755 , 0.1743 , 0.174  , 0.1731 , 0.1727 , 0.1724 ,\n",
       "            0.1719 , 0.1718 , 0.1707 , 0.1703 , 0.1698 , 0.1692 , 0.1688 ,\n",
       "            0.1686 , 0.1672 , 0.1669 , 0.1666 , 0.166  , 0.1658 , 0.1654 ,\n",
       "            0.1638 , 0.1633 , 0.1632 , 0.163  , 0.1625 , 0.162  , 0.1616 ,\n",
       "            0.1614 , 0.1611 , 0.1602 , 0.159  , 0.1588 , 0.1587 , 0.1584 ,\n",
       "            0.1575 , 0.157  , 0.1559 , 0.1556 , 0.1525 , 0.1519 , 0.1511 ,\n",
       "            0.1508 , 0.1506 , 0.1504 , 0.15   , 0.1493 , 0.1483 , 0.1482 ,\n",
       "            0.147  , 0.1451 , 0.1442 , 0.1432 , 0.1415 , 0.1412 , 0.141  ,\n",
       "            0.1401 , 0.1392 , 0.139  , 0.1365 , 0.1348 , 0.1328 , 0.1327 ,\n",
       "            0.1326 , 0.1299 , 0.1298 , 0.129  , 0.1274 , 0.127  , 0.1263 ,\n",
       "            0.1252 , 0.121  , 0.1194 , 0.1188 , 0.1174 , 0.11615, 0.11597,\n",
       "            0.11395, 0.1138 , 0.1128 , 0.112  , 0.1101 , 0.1097 , 0.1084 ,\n",
       "            0.1069 , 0.1067 , 0.1063 , 0.10284, 0.10266, 0.1019 , 0.09845,\n",
       "            0.0932 , 0.0877 , 0.0854 , 0.0771 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.625    , 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6796875, 0.6796875, 0.6796875,\n",
       "            0.6875   , 0.6875   , 0.6953125, 0.6953125, 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.7109375, 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.71875  , 0.71875  , 0.71875  , 0.71875  , 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.734375 , 0.75     , 0.75     , 0.75     , 0.75     ,\n",
       "            0.75     , 0.75     , 0.75     , 0.75     , 0.75     , 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8046875, 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.8359375, 0.8359375,\n",
       "            0.84375  , 0.84375  , 0.84375  , 0.84375  , 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.875    , 0.875    , 0.8828125, 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.953125 , 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 ,\n",
       "            0.9921875, 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.1147541 ,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.27868852, 0.28688523, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.31967214, 0.32786885, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.37704918, 0.3852459 ,\n",
       "            0.3852459 , 0.39344263, 0.39344263, 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40163934, 0.40983605, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.74590164,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.367  , 0.3665 , 0.366  , 0.3655 , 0.3652 , 0.3638 ,\n",
       "            0.3613 , 0.3604 , 0.3586 , 0.3584 , 0.3572 , 0.356  , 0.3557 ,\n",
       "            0.3555 , 0.355  , 0.3533 , 0.351  , 0.35   , 0.3499 , 0.3494 ,\n",
       "            0.3481 , 0.3477 , 0.3462 , 0.346  , 0.3452 , 0.342  , 0.3408 ,\n",
       "            0.3406 , 0.3403 , 0.34   , 0.3386 , 0.3372 , 0.3345 , 0.3318 ,\n",
       "            0.3306 , 0.33   , 0.3286 , 0.3281 , 0.3264 , 0.3252 , 0.3235 ,\n",
       "            0.3186 , 0.3154 , 0.3127 , 0.31   , 0.3093 , 0.3062 , 0.3054 ,\n",
       "            0.3025 , 0.2993 , 0.2935 , 0.2913 , 0.29   , 0.287  , 0.2837 ,\n",
       "            0.2803 , 0.278  , 0.2778 , 0.2764 , 0.2717 , 0.2708 , 0.265  ,\n",
       "            0.2646 , 0.2634 , 0.2595 , 0.2534 , 0.2502 , 0.2467 , 0.2445 ,\n",
       "            0.2444 , 0.2433 , 0.241  , 0.2406 , 0.2391 , 0.2382 , 0.2328 ,\n",
       "            0.2306 , 0.2251 , 0.2242 , 0.2235 , 0.2233 , 0.2225 , 0.2212 ,\n",
       "            0.2207 , 0.2195 , 0.2194 , 0.2191 , 0.2189 , 0.218  , 0.2152 ,\n",
       "            0.2144 , 0.2134 , 0.213  , 0.2106 , 0.2098 , 0.2069 , 0.2058 ,\n",
       "            0.2    , 0.1998 , 0.1991 , 0.1965 , 0.195  , 0.1947 , 0.1898 ,\n",
       "            0.1879 , 0.1877 , 0.1871 , 0.187  , 0.1849 , 0.1816 , 0.1805 ,\n",
       "            0.1799 , 0.1797 , 0.1792 , 0.1781 , 0.1775 , 0.1774 , 0.1758 ,\n",
       "            0.1747 , 0.1738 , 0.1726 , 0.1724 , 0.1719 , 0.171  , 0.1709 ,\n",
       "            0.1708 , 0.1705 , 0.1687 , 0.1685 , 0.167  , 0.1669 , 0.1663 ,\n",
       "            0.1658 , 0.1643 , 0.163  , 0.1622 , 0.1608 , 0.1603 , 0.1597 ,\n",
       "            0.1594 , 0.1581 , 0.158  , 0.157  , 0.1567 , 0.1565 , 0.1558 ,\n",
       "            0.154  , 0.1539 , 0.1532 , 0.1526 , 0.1519 , 0.1505 , 0.1501 ,\n",
       "            0.1492 , 0.1488 , 0.1483 , 0.1482 , 0.148  , 0.1472 , 0.1466 ,\n",
       "            0.1462 , 0.146  , 0.1451 , 0.1439 , 0.1432 , 0.1422 , 0.1412 ,\n",
       "            0.141  , 0.1406 , 0.1403 , 0.1401 , 0.1399 , 0.139  , 0.1387 ,\n",
       "            0.1377 , 0.1373 , 0.1367 , 0.1353 , 0.1334 , 0.1327 , 0.1311 ,\n",
       "            0.1306 , 0.13   , 0.1294 , 0.1289 , 0.1287 , 0.1283 , 0.1282 ,\n",
       "            0.1256 , 0.1255 , 0.12494, 0.12305, 0.12177, 0.1217 , 0.1213 ,\n",
       "            0.1204 , 0.1198 , 0.1197 , 0.1192 , 0.118  , 0.1172 , 0.11554,\n",
       "            0.11395, 0.1134 , 0.1122 , 0.111  , 0.11084, 0.11066, 0.10913,\n",
       "            0.10895, 0.1074 , 0.10724, 0.10614, 0.1007 , 0.1    , 0.09845,\n",
       "            0.0972 , 0.09686, 0.0967 , 0.096  , 0.0959 , 0.0957 , 0.09283,\n",
       "            0.09125, 0.09106, 0.0901 , 0.0887 , 0.0882 , 0.0871 , 0.0865 ,\n",
       "            0.0856 , 0.08136, 0.07697, 0.07135, 0.0703 , 0.06256],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.359375 , 0.3671875, 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.703125 , 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.75     , 0.75     , 0.75     , 0.75     , 0.75     , 0.75     ,\n",
       "            0.75     , 0.75     , 0.7578125, 0.765625 , 0.765625 , 0.765625 ,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.796875 ,\n",
       "            0.8046875, 0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.8359375, 0.84375  , 0.84375  , 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.8828125, 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.09016393, 0.09836066, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.32786885,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.44262296, 0.45081967, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59016395, 0.59016395,\n",
       "            0.59016395, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6147541 , 0.6229508 , 0.6229508 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6639344 , 0.6639344 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3447 , 0.3442 , 0.344  , 0.3438 , 0.343  , 0.3423 ,\n",
       "            0.342  , 0.3408 , 0.3389 , 0.3386 , 0.3384 , 0.338  , 0.3364 ,\n",
       "            0.3345 , 0.3337 , 0.3335 , 0.3325 , 0.3323 , 0.3315 , 0.3303 ,\n",
       "            0.33   , 0.327  , 0.3267 , 0.3264 , 0.326  , 0.3213 , 0.3208 ,\n",
       "            0.32   , 0.3198 , 0.3179 , 0.317  , 0.3164 , 0.3162 , 0.316  ,\n",
       "            0.3132 , 0.312  , 0.311  , 0.3052 , 0.305  , 0.298  , 0.2961 ,\n",
       "            0.2925 , 0.2898 , 0.2883 , 0.2825 , 0.2815 , 0.2808 , 0.278  ,\n",
       "            0.276  , 0.2744 , 0.2727 , 0.2664 , 0.266  , 0.262  , 0.2605 ,\n",
       "            0.2573 , 0.257  , 0.2568 , 0.2473 , 0.2448 , 0.2434 , 0.2433 ,\n",
       "            0.243  , 0.2429 , 0.2424 , 0.2395 , 0.2334 , 0.2316 , 0.2301 ,\n",
       "            0.2255 , 0.2252 , 0.2246 , 0.2217 , 0.2207 , 0.218  , 0.2172 ,\n",
       "            0.2168 , 0.2152 , 0.2148 , 0.2134 , 0.2123 , 0.2114 , 0.2091 ,\n",
       "            0.2089 , 0.2059 , 0.2047 , 0.2007 , 0.1996 , 0.1985 , 0.1979 ,\n",
       "            0.1959 , 0.1947 , 0.1927 , 0.1923 , 0.1915 , 0.1898 , 0.1886 ,\n",
       "            0.1884 , 0.1866 , 0.1857 , 0.1855 , 0.1842 , 0.182  , 0.1785 ,\n",
       "            0.1764 , 0.174  , 0.1738 , 0.1733 , 0.173  , 0.1727 , 0.1724 ,\n",
       "            0.1708 , 0.1707 , 0.1693 , 0.169  , 0.1677 , 0.1666 , 0.1661 ,\n",
       "            0.1653 , 0.1648 , 0.1646 , 0.1644 , 0.1641 , 0.1635 , 0.1633 ,\n",
       "            0.1632 , 0.1616 , 0.1608 , 0.1605 , 0.1604 , 0.1594 , 0.1593 ,\n",
       "            0.1581 , 0.1571 , 0.1567 , 0.156  , 0.1549 , 0.1543 , 0.1542 ,\n",
       "            0.153  , 0.1504 , 0.1501 , 0.1498 , 0.1497 , 0.1495 , 0.1487 ,\n",
       "            0.1478 , 0.1476 , 0.1451 , 0.1449 , 0.1445 , 0.1442 , 0.1434 ,\n",
       "            0.1433 , 0.1431 , 0.1416 , 0.1414 , 0.1411 , 0.1384 , 0.1372 ,\n",
       "            0.137  , 0.1368 , 0.1367 , 0.1362 , 0.1361 , 0.1349 , 0.1348 ,\n",
       "            0.1334 , 0.1322 , 0.1316 , 0.1315 , 0.1312 , 0.1305 , 0.13   ,\n",
       "            0.1259 , 0.1256 , 0.1255 , 0.1251 , 0.12476, 0.1241 , 0.12335,\n",
       "            0.12317, 0.12274, 0.1188 , 0.1184 , 0.1174 , 0.11633, 0.11615,\n",
       "            0.11554, 0.115  , 0.11456, 0.11316, 0.1122 , 0.112  , 0.11127,\n",
       "            0.1103 , 0.1097 , 0.108  , 0.1058 , 0.1052 , 0.10504, 0.1032 ,\n",
       "            0.10144, 0.10016, 0.09827, 0.0957 , 0.0937 , 0.09283, 0.09235,\n",
       "            0.0922 , 0.09186, 0.0909 , 0.09076, 0.0906 , 0.0903 , 0.0898 ,\n",
       "            0.089  , 0.0862 , 0.08435, 0.08417, 0.08374, 0.08344, 0.0827 ,\n",
       "            0.08093, 0.0808 , 0.07574, 0.0716 , 0.0656 , 0.06476, 0.0577 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0546875,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.109375 , 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1796875, 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.5      , 0.5      , 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.75     , 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.765625 , 0.765625 , 0.7734375,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.796875 , 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.8671875, 0.875    , 0.875    , 0.875    , 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.953125 ,\n",
       "            0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.9609375,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.03278688, 0.04098361, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.31967214, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.60655737, 0.6147541 , 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.647541  , 0.6639344 ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.33   , 0.3298 , 0.3296 , 0.3284 , 0.3271 , 0.327  ,\n",
       "            0.326  , 0.3257 , 0.3254 , 0.3252 , 0.3242 , 0.3235 , 0.3232 ,\n",
       "            0.323  , 0.3228 , 0.3225 , 0.322  , 0.3218 , 0.3215 , 0.3203 ,\n",
       "            0.32   , 0.3193 , 0.3174 , 0.3154 , 0.315  , 0.3132 , 0.3123 ,\n",
       "            0.3115 , 0.3096 , 0.309  , 0.3086 , 0.3076 , 0.307  , 0.3064 ,\n",
       "            0.3027 , 0.2988 , 0.2986 , 0.2966 , 0.2954 , 0.2874 , 0.2856 ,\n",
       "            0.2854 , 0.2842 , 0.2832 , 0.28   , 0.279  , 0.2788 , 0.2786 ,\n",
       "            0.2773 , 0.276  , 0.2756 , 0.2734 , 0.2727 , 0.2715 , 0.2673 ,\n",
       "            0.266  , 0.2659 , 0.2644 , 0.2617 , 0.2612 , 0.261  , 0.2595 ,\n",
       "            0.2573 , 0.257  , 0.2527 , 0.2494 , 0.249  , 0.248  , 0.2471 ,\n",
       "            0.2462 , 0.2458 , 0.2456 , 0.2448 , 0.2426 , 0.2417 , 0.2401 ,\n",
       "            0.239  , 0.2386 , 0.235  , 0.2346 , 0.2339 , 0.2311 , 0.2292 ,\n",
       "            0.2269 , 0.2224 , 0.2216 , 0.2207 , 0.22   , 0.2179 , 0.2175 ,\n",
       "            0.2139 , 0.2128 , 0.2101 , 0.21   , 0.2094 , 0.209  , 0.2081 ,\n",
       "            0.208  , 0.2068 , 0.2053 , 0.205  , 0.2039 , 0.2031 , 0.2029 ,\n",
       "            0.2026 , 0.2012 , 0.1989 , 0.1967 , 0.196  , 0.1959 , 0.1947 ,\n",
       "            0.194  , 0.1912 , 0.1901 , 0.19   , 0.1893 , 0.1864 , 0.1848 ,\n",
       "            0.1835 , 0.1833 , 0.1831 , 0.1823 , 0.1814 , 0.1807 , 0.1803 ,\n",
       "            0.1788 , 0.1772 , 0.1764 , 0.1761 , 0.1758 , 0.1755 , 0.1753 ,\n",
       "            0.1752 , 0.1744 , 0.1743 , 0.1721 , 0.1714 , 0.1711 , 0.17   ,\n",
       "            0.1694 , 0.1687 , 0.1681 , 0.166  , 0.1656 , 0.1646 , 0.164  ,\n",
       "            0.1633 , 0.1627 , 0.1626 , 0.1616 , 0.1608 , 0.1584 , 0.1572 ,\n",
       "            0.157  , 0.1569 , 0.1561 , 0.1536 , 0.1531 , 0.152  , 0.1516 ,\n",
       "            0.1506 , 0.149  , 0.1488 , 0.1484 , 0.148  , 0.1444 , 0.1438 ,\n",
       "            0.1423 , 0.1418 , 0.1412 , 0.1407 , 0.1406 , 0.1405 , 0.1404 ,\n",
       "            0.1398 , 0.1349 , 0.1346 , 0.1342 , 0.1338 , 0.1323 , 0.1298 ,\n",
       "            0.1292 , 0.1273 , 0.1271 , 0.1255 , 0.12494, 0.1238 , 0.1232 ,\n",
       "            0.12305, 0.1226 , 0.1222 , 0.1214 , 0.121  , 0.1204 , 0.1195 ,\n",
       "            0.119  , 0.1188 , 0.11755, 0.11676, 0.1166 , 0.115  , 0.1134 ,\n",
       "            0.1095 , 0.10913, 0.1086 , 0.10706, 0.10614, 0.1058 , 0.1043 ,\n",
       "            0.10156, 0.10126, 0.1005 , 0.10034, 0.09894, 0.0979 , 0.0977 ,\n",
       "            0.0972 , 0.0967 , 0.0955 , 0.09186, 0.09106, 0.09076, 0.0901 ,\n",
       "            0.0873 , 0.08374, 0.0799 , 0.0741 , 0.07007, 0.0644 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0703125, 0.09375  , 0.109375 , 0.125    , 0.140625 , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.4765625, 0.4765625, 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.6015625, 0.609375 , 0.609375 , 0.6171875, 0.625    , 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.65625  , 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.703125 ,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.7109375, 0.71875  , 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  , 0.78125  ,\n",
       "            0.78125  , 0.78125  , 0.78125  , 0.78125  , 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.8671875, 0.8671875, 0.875    , 0.875    , 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.9453125, 0.953125 , 0.9609375, 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625,\n",
       "            0.9765625, 0.984375 , 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.03278688, 0.03278688, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09016393, 0.09016393, 0.09016393,\n",
       "            0.09016393, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.16393442, 0.18032786, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.3114754 ,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40163934, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.59016395, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.59836066, 0.60655737, 0.60655737,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.6393443 , 0.6393443 , 0.6393443 ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3223 , 0.322  , 0.3208 , 0.3196 , 0.3193 , 0.3188 ,\n",
       "            0.3186 , 0.3184 , 0.318  , 0.3179 , 0.3176 , 0.3171 , 0.317  ,\n",
       "            0.3164 , 0.3162 , 0.3154 , 0.3147 , 0.3137 , 0.3127 , 0.3123 ,\n",
       "            0.3118 , 0.3115 , 0.3098 , 0.309  , 0.3088 , 0.3086 , 0.3074 ,\n",
       "            0.3071 , 0.3064 , 0.3052 , 0.3042 , 0.3037 , 0.3032 , 0.303  ,\n",
       "            0.3025 , 0.3022 , 0.301  , 0.3008 , 0.3003 , 0.2976 , 0.297  ,\n",
       "            0.2954 , 0.2952 , 0.2944 , 0.293  , 0.2927 , 0.2925 , 0.2922 ,\n",
       "            0.2915 , 0.2905 , 0.288  , 0.2878 , 0.2861 , 0.2856 , 0.2854 ,\n",
       "            0.2847 , 0.2832 , 0.282  , 0.2812 , 0.281  , 0.2786 , 0.2776 ,\n",
       "            0.277  , 0.2747 , 0.2742 , 0.2725 , 0.271  , 0.2705 , 0.27   ,\n",
       "            0.2695 , 0.269  , 0.2664 , 0.2654 , 0.263  , 0.2615 , 0.2605 ,\n",
       "            0.259  , 0.256  , 0.2546 , 0.2542 , 0.2522 , 0.2517 , 0.251  ,\n",
       "            0.2478 , 0.247  , 0.2438 , 0.2433 , 0.2424 , 0.241  , 0.2401 ,\n",
       "            0.2382 , 0.2375 , 0.2372 , 0.2367 , 0.2303 , 0.2297 , 0.2295 ,\n",
       "            0.2292 , 0.2277 , 0.2274 , 0.2272 , 0.2257 , 0.2247 , 0.2242 ,\n",
       "            0.2217 , 0.2191 , 0.218  , 0.2179 , 0.2158 , 0.2157 , 0.2148 ,\n",
       "            0.214  , 0.2139 , 0.2133 , 0.2098 , 0.2094 , 0.2091 , 0.2085 ,\n",
       "            0.2059 , 0.2051 , 0.2047 , 0.2017 , 0.201  , 0.2009 , 0.2007 ,\n",
       "            0.2002 , 0.1998 , 0.199  , 0.1978 , 0.1974 , 0.1973 , 0.1925 ,\n",
       "            0.1924 , 0.1918 , 0.1904 , 0.1893 , 0.1892 , 0.1891 , 0.189  ,\n",
       "            0.1885 , 0.1876 , 0.1873 , 0.1864 , 0.1859 , 0.1858 , 0.1821 ,\n",
       "            0.1815 , 0.1813 , 0.1797 , 0.1788 , 0.1783 , 0.1763 , 0.1755 ,\n",
       "            0.1744 , 0.173  , 0.1708 , 0.1699 , 0.1696 , 0.169  , 0.1685 ,\n",
       "            0.1674 , 0.167  , 0.1649 , 0.1646 , 0.1627 , 0.1621 , 0.1617 ,\n",
       "            0.1606 , 0.1587 , 0.1572 , 0.1569 , 0.1559 , 0.1555 , 0.1545 ,\n",
       "            0.1517 , 0.151  , 0.1495 , 0.149  , 0.1487 , 0.1477 , 0.1466 ,\n",
       "            0.1462 , 0.1423 , 0.1421 , 0.1418 , 0.1414 , 0.1412 , 0.1411 ,\n",
       "            0.1405 , 0.1401 , 0.1389 , 0.1383 , 0.1376 , 0.1373 , 0.1362 ,\n",
       "            0.1335 , 0.1322 , 0.1318 , 0.1292 , 0.1278 , 0.1277 , 0.1274 ,\n",
       "            0.1272 , 0.1268 , 0.12305, 0.12286, 0.1223 , 0.1213 , 0.12085,\n",
       "            0.12067, 0.1204 , 0.1186 , 0.11816, 0.1174 , 0.1142 , 0.11163,\n",
       "            0.11066, 0.1093 , 0.10876, 0.1058 , 0.10266, 0.1011 , 0.09753,\n",
       "            0.09186, 0.0833 , 0.07965], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.078125 , 0.078125 , 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.109375 , 0.125    , 0.1328125, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.203125 , 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.234375 , 0.2421875, 0.265625 , 0.28125  ,\n",
       "            0.2890625, 0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.3203125,\n",
       "            0.328125 , 0.328125 , 0.34375  , 0.34375  , 0.34375  , 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.4765625, 0.4765625, 0.4765625, 0.4765625, 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.625    , 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.671875 ,\n",
       "            0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.6953125, 0.703125 , 0.703125 , 0.703125 , 0.703125 , 0.7109375,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.765625 , 0.765625 , 0.7734375,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.828125 , 0.828125 , 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.8828125, 0.8828125, 0.8828125, 0.8828125,\n",
       "            0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.9453125, 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.01639344, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.06557377, 0.06557377, 0.07377049,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.09836066,\n",
       "            0.09836066, 0.09836066, 0.09836066, 0.09836066, 0.10655738,\n",
       "            0.10655738, 0.10655738, 0.1147541 , 0.1147541 , 0.1147541 ,\n",
       "            0.1147541 , 0.1147541 , 0.12295082, 0.12295082, 0.12295082,\n",
       "            0.13114753, 0.13114753, 0.13114753, 0.13934426, 0.13934426,\n",
       "            0.13934426, 0.14754099, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.21311475, 0.21311475, 0.21311475,\n",
       "            0.21311475, 0.21311475, 0.21311475, 0.21311475, 0.22131148,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.24590164,\n",
       "            0.24590164, 0.24590164, 0.2704918 , 0.27868852, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.3442623 , 0.3442623 , 0.352459  ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59016395, 0.59836066, 0.59836066, 0.60655737,\n",
       "            0.60655737, 0.6147541 , 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3293 , 0.328  , 0.3242 , 0.3232 , 0.3228 , 0.322  ,\n",
       "            0.3218 , 0.3213 , 0.3203 , 0.32   , 0.319  , 0.3186 , 0.3184 ,\n",
       "            0.3176 , 0.3174 , 0.3162 , 0.316  , 0.3154 , 0.3152 , 0.315  ,\n",
       "            0.3147 , 0.3145 , 0.3142 , 0.314  , 0.3137 , 0.3135 , 0.3132 ,\n",
       "            0.313  , 0.3127 , 0.3125 , 0.3123 , 0.312  , 0.3115 , 0.311  ,\n",
       "            0.3108 , 0.3105 , 0.3088 , 0.308  , 0.3066 , 0.3062 , 0.3047 ,\n",
       "            0.3044 , 0.304  , 0.3037 , 0.3035 , 0.303  , 0.3022 , 0.2998 ,\n",
       "            0.2993 , 0.2988 , 0.298  , 0.2979 , 0.2976 , 0.2964 , 0.2961 ,\n",
       "            0.296  , 0.2954 , 0.295  , 0.2937 , 0.2917 , 0.2913 , 0.291  ,\n",
       "            0.2908 , 0.289  , 0.2876 , 0.2869 , 0.2866 , 0.286  , 0.2847 ,\n",
       "            0.2844 , 0.2827 , 0.2817 , 0.2815 , 0.2805 , 0.2786 , 0.2776 ,\n",
       "            0.277  , 0.2747 , 0.274  , 0.2737 , 0.2695 , 0.2673 , 0.2668 ,\n",
       "            0.2644 , 0.2634 , 0.263  , 0.2622 , 0.262  , 0.2607 , 0.2603 ,\n",
       "            0.26   , 0.2588 , 0.2585 , 0.258  , 0.2573 , 0.257  , 0.2556 ,\n",
       "            0.255  , 0.2534 , 0.2527 , 0.2522 , 0.252  , 0.246  , 0.2391 ,\n",
       "            0.2375 , 0.2355 , 0.2351 , 0.2344 , 0.2322 , 0.2318 , 0.2313 ,\n",
       "            0.2283 , 0.2272 , 0.2251 , 0.2234 , 0.2216 , 0.2207 , 0.2203 ,\n",
       "            0.2195 , 0.2194 , 0.2189 , 0.2186 , 0.2184 , 0.2177 , 0.2167 ,\n",
       "            0.2161 , 0.2145 , 0.2125 , 0.2114 , 0.2081 , 0.208  , 0.2068 ,\n",
       "            0.2065 , 0.2063 , 0.2056 , 0.2054 , 0.2047 , 0.2032 , 0.201  ,\n",
       "            0.2001 , 0.1981 , 0.1971 , 0.1946 , 0.1923 , 0.1904 , 0.1903 ,\n",
       "            0.1901 , 0.19   , 0.1896 , 0.1885 , 0.1824 , 0.1819 , 0.1788 ,\n",
       "            0.178  , 0.1768 , 0.1765 , 0.1763 , 0.1761 , 0.1743 , 0.1738 ,\n",
       "            0.1733 , 0.173  , 0.1725 , 0.1721 , 0.172  , 0.1714 , 0.1709 ,\n",
       "            0.1659 , 0.1647 , 0.1637 , 0.1636 , 0.1627 , 0.1622 , 0.161  ,\n",
       "            0.1608 , 0.1606 , 0.1598 , 0.158  , 0.1572 , 0.1567 , 0.1544 ,\n",
       "            0.1525 , 0.1514 , 0.151  , 0.15   , 0.1495 , 0.1492 , 0.1478 ,\n",
       "            0.1465 , 0.1443 , 0.144  , 0.1438 , 0.1436 , 0.1423 , 0.1409 ,\n",
       "            0.1383 , 0.1377 , 0.1345 , 0.1342 , 0.1305 , 0.1296 , 0.1289 ,\n",
       "            0.1266 , 0.126  , 0.1242 , 0.1196 , 0.11755, 0.11615, 0.1144 ,\n",
       "            0.10895, 0.09515, 0.0942 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.046875 ,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1484375, 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.2578125, 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.3203125,\n",
       "            0.3203125, 0.328125 , 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.3671875, 0.375    , 0.375    , 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.6953125, 0.703125 , 0.703125 , 0.703125 , 0.7109375,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.734375 , 0.7421875,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.7890625, 0.7890625, 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.8359375, 0.8359375,\n",
       "            0.84375  , 0.84375  , 0.84375  , 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.90625  , 0.9140625, 0.9140625, 0.9140625, 0.921875 ,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.1557377 , 0.16393442, 0.17213115, 0.19672132,\n",
       "            0.21311475, 0.21311475, 0.22131148, 0.22131148, 0.22950819,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.24590164, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.29508197,\n",
       "            0.29508197, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.31967214, 0.32786885, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.3442623 , 0.3442623 , 0.3442623 , 0.3442623 ,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.36885247, 0.36885247, 0.36885247, 0.36885247, 0.3852459 ,\n",
       "            0.3852459 , 0.3852459 , 0.3852459 , 0.3852459 , 0.3852459 ,\n",
       "            0.3852459 , 0.39344263, 0.39344263, 0.40163934, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.4262295 , 0.4262295 ,\n",
       "            0.4262295 , 0.4262295 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.46721312, 0.46721312,\n",
       "            0.46721312, 0.48360655, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59016395, 0.59016395, 0.59016395, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.7295082 , 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.76229507, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.358  , 0.3574 , 0.354  , 0.3538 , 0.3535 , 0.3525 ,\n",
       "            0.3516 , 0.3513 , 0.3508 , 0.3503 , 0.346  , 0.345  , 0.3445 ,\n",
       "            0.3442 , 0.344  , 0.3438 , 0.3413 , 0.3396 , 0.3394 , 0.339  ,\n",
       "            0.338  , 0.3376 , 0.3372 , 0.3364 , 0.3354 , 0.3333 , 0.3328 ,\n",
       "            0.3315 , 0.3306 , 0.328  , 0.327  , 0.3237 , 0.323  , 0.3228 ,\n",
       "            0.3223 , 0.3208 , 0.3206 , 0.3176 , 0.3174 , 0.3171 , 0.317  ,\n",
       "            0.3167 , 0.3162 , 0.3157 , 0.3154 , 0.3152 , 0.3147 , 0.3145 ,\n",
       "            0.314  , 0.3135 , 0.3125 , 0.3123 , 0.3118 , 0.311  , 0.3105 ,\n",
       "            0.3103 , 0.3098 , 0.3096 , 0.3093 , 0.309  , 0.3086 , 0.3079 ,\n",
       "            0.3076 , 0.3066 , 0.3062 , 0.3052 , 0.3044 , 0.304  , 0.3037 ,\n",
       "            0.3032 , 0.303  , 0.3025 , 0.302  , 0.301  , 0.3008 , 0.3005 ,\n",
       "            0.2996 , 0.298  , 0.2979 , 0.2976 , 0.2974 , 0.2961 , 0.2947 ,\n",
       "            0.2925 , 0.291  , 0.29   , 0.2896 , 0.289  , 0.2878 , 0.287  ,\n",
       "            0.2864 , 0.286  , 0.285  , 0.2847 , 0.283  , 0.2805 , 0.28   ,\n",
       "            0.279  , 0.2761 , 0.2747 , 0.2742 , 0.2734 , 0.2705 , 0.2695 ,\n",
       "            0.2693 , 0.269  , 0.2673 , 0.2668 , 0.2664 , 0.2642 , 0.2563 ,\n",
       "            0.2556 , 0.2544 , 0.2522 , 0.2489 , 0.2483 , 0.248  , 0.2467 ,\n",
       "            0.2452 , 0.244  , 0.2437 , 0.243  , 0.2426 , 0.2406 , 0.2402 ,\n",
       "            0.2394 , 0.2386 , 0.2362 , 0.2351 , 0.2335 , 0.233  , 0.2325 ,\n",
       "            0.2319 , 0.2318 , 0.2301 , 0.2297 , 0.2295 , 0.228  , 0.2269 ,\n",
       "            0.2268 , 0.2247 , 0.224  , 0.2227 , 0.2224 , 0.2217 , 0.2212 ,\n",
       "            0.2195 , 0.2162 , 0.2156 , 0.2153 , 0.2133 , 0.2119 , 0.2106 ,\n",
       "            0.2089 , 0.2073 , 0.2053 , 0.2047 , 0.2018 , 0.2017 , 0.2013 ,\n",
       "            0.1998 , 0.1982 , 0.1979 , 0.1971 , 0.197  , 0.1962 , 0.1958 ,\n",
       "            0.194  , 0.1936 , 0.1919 , 0.191  , 0.1901 , 0.1863 , 0.1859 ,\n",
       "            0.1858 , 0.1836 , 0.183  , 0.1824 , 0.1813 , 0.1796 , 0.1783 ,\n",
       "            0.1774 , 0.1765 , 0.1755 , 0.1744 , 0.1743 , 0.174  , 0.1737 ,\n",
       "            0.1725 , 0.1711 , 0.1707 , 0.1681 , 0.1666 , 0.1659 , 0.1656 ,\n",
       "            0.1615 , 0.1608 , 0.1606 , 0.1597 , 0.1567 , 0.1536 , 0.1519 ,\n",
       "            0.1514 , 0.1511 , 0.1501 , 0.1462 , 0.1451 , 0.1443 , 0.1398 ,\n",
       "            0.1396 , 0.138  , 0.1344 , 0.1333 , 0.1318 , 0.1298 , 0.1273 ,\n",
       "            0.1093 , 0.10706], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.109375 , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.359375 , 0.3671875, 0.375    , 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.625    , 0.625    , 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.71875  , 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.7421875, 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8046875,\n",
       "            0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.8203125, 0.828125 ,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.84375  , 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.875    , 0.875    ,\n",
       "            0.8828125, 0.8828125, 0.8828125, 0.8828125, 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.984375 , 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.1557377 , 0.16393442, 0.17213115, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.352459  , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.46721312,\n",
       "            0.46721312, 0.46721312, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.48360655, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5081967 , 0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.58196723, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.72131145, 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.74590164, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4187, 0.411 , 0.4016, 0.4   , 0.3992, 0.399 , 0.3972,\n",
       "            0.3965, 0.395 , 0.3923, 0.3909, 0.3892, 0.3867, 0.3865, 0.386 ,\n",
       "            0.385 , 0.383 , 0.3828, 0.382 , 0.38  , 0.3796, 0.3787, 0.3784,\n",
       "            0.3743, 0.3735, 0.3726, 0.372 , 0.3718, 0.3716, 0.3713, 0.3706,\n",
       "            0.3704, 0.3699, 0.3691, 0.3684, 0.3682, 0.367 , 0.3625, 0.3623,\n",
       "            0.3586, 0.3584, 0.358 , 0.3557, 0.3538, 0.3525, 0.3506, 0.349 ,\n",
       "            0.3477, 0.3472, 0.3464, 0.3438, 0.3428, 0.3418, 0.3416, 0.3408,\n",
       "            0.34  , 0.338 , 0.3357, 0.3342, 0.3335, 0.333 , 0.327 , 0.3267,\n",
       "            0.3245, 0.324 , 0.3237, 0.323 , 0.3228, 0.3223, 0.3198, 0.3193,\n",
       "            0.319 , 0.3186, 0.318 , 0.3176, 0.317 , 0.3162, 0.3152, 0.3132,\n",
       "            0.3123, 0.3118, 0.3115, 0.3098, 0.3088, 0.3076, 0.3074, 0.307 ,\n",
       "            0.3057, 0.3054, 0.305 , 0.3044, 0.3042, 0.3032, 0.3027, 0.3025,\n",
       "            0.3022, 0.3018, 0.3015, 0.301 , 0.2998, 0.2969, 0.2964, 0.2961,\n",
       "            0.2944, 0.2942, 0.2937, 0.2925, 0.2917, 0.2915, 0.2898, 0.288 ,\n",
       "            0.2876, 0.2869, 0.2864, 0.2834, 0.283 , 0.2825, 0.2815, 0.2808,\n",
       "            0.2803, 0.28  , 0.2778, 0.2756, 0.2737, 0.2725, 0.2712, 0.2695,\n",
       "            0.269 , 0.268 , 0.2676, 0.2668, 0.2644, 0.2625, 0.2617, 0.2612,\n",
       "            0.2605, 0.26  , 0.2593, 0.2588, 0.2583, 0.2554, 0.255 , 0.2546,\n",
       "            0.2502, 0.2498, 0.2494, 0.249 , 0.2466, 0.2452, 0.2433, 0.2415,\n",
       "            0.2397, 0.2378, 0.2367, 0.2355, 0.2346, 0.2338, 0.2335, 0.2334,\n",
       "            0.2332, 0.2316, 0.2302, 0.2297, 0.228 , 0.2278, 0.2272, 0.2266,\n",
       "            0.2252, 0.2251, 0.2249, 0.2246, 0.222 , 0.2186, 0.2179, 0.2177,\n",
       "            0.2172, 0.215 , 0.2144, 0.2125, 0.212 , 0.2104, 0.2086, 0.2081,\n",
       "            0.2069, 0.2068, 0.2063, 0.2058, 0.2043, 0.2029, 0.2015, 0.1993,\n",
       "            0.1991, 0.1974, 0.1967, 0.196 , 0.1958, 0.193 , 0.1925, 0.1923,\n",
       "            0.1918, 0.1865, 0.1863, 0.1859, 0.1842, 0.1816, 0.1783, 0.1781,\n",
       "            0.1772, 0.1748, 0.1709, 0.1688, 0.1677, 0.1637, 0.1621, 0.162 ,\n",
       "            0.1603, 0.1586, 0.155 , 0.1543, 0.1511, 0.1334, 0.1265],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.0625   , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1953125, 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.234375 , 0.2421875, 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.3515625, 0.359375 , 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.4140625, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.578125 , 0.578125 , 0.578125 , 0.59375  , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.640625 , 0.6484375, 0.6640625, 0.671875 ,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.7265625, 0.734375 , 0.734375 , 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.75     , 0.75     , 0.765625 , 0.7734375,\n",
       "            0.7734375, 0.7890625, 0.796875 , 0.796875 , 0.796875 , 0.8046875,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.8515625, 0.859375 , 0.859375 , 0.8671875, 0.875    , 0.875    ,\n",
       "            0.875    , 0.875    , 0.875    , 0.875    , 0.875    , 0.875    ,\n",
       "            0.875    , 0.875    , 0.8828125, 0.890625 , 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.921875 , 0.921875 , 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4262295 , 0.44262296,\n",
       "            0.45081967, 0.45081967, 0.45081967, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.4918033 , 0.4918033 , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.59836066, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.59836066, 0.59836066, 0.59836066,\n",
       "            0.60655737, 0.60655737, 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.6229508 , 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6639344 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6967213 , 0.6967213 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4783, 0.478 , 0.4602, 0.459 , 0.4573, 0.4556, 0.449 ,\n",
       "            0.4485, 0.4443, 0.4424, 0.44  , 0.4377, 0.4375, 0.4368, 0.4324,\n",
       "            0.4316, 0.43  , 0.4292, 0.429 , 0.4253, 0.4248, 0.424 , 0.4207,\n",
       "            0.4202, 0.4187, 0.4182, 0.4175, 0.4163, 0.414 , 0.4138, 0.4136,\n",
       "            0.4119, 0.4114, 0.411 , 0.4019, 0.401 , 0.4004, 0.4   , 0.398 ,\n",
       "            0.3977, 0.3975, 0.396 , 0.3953, 0.395 , 0.394 , 0.3894, 0.385 ,\n",
       "            0.3833, 0.3818, 0.3813, 0.379 , 0.3782, 0.3735, 0.356 , 0.353 ,\n",
       "            0.3513, 0.351 , 0.3508, 0.3506, 0.3472, 0.3464, 0.3433, 0.3428,\n",
       "            0.3425, 0.3403, 0.339 , 0.3386, 0.3364, 0.333 , 0.3328, 0.3315,\n",
       "            0.328 , 0.3271, 0.327 , 0.3264, 0.324 , 0.3235, 0.3225, 0.3223,\n",
       "            0.3218, 0.32  , 0.3196, 0.3193, 0.3176, 0.3171, 0.3167, 0.3164,\n",
       "            0.3147, 0.314 , 0.3135, 0.3132, 0.313 , 0.3123, 0.3108, 0.31  ,\n",
       "            0.3079, 0.3066, 0.3057, 0.305 , 0.3037, 0.3035, 0.303 , 0.3015,\n",
       "            0.3013, 0.3008, 0.2993, 0.298 , 0.2979, 0.2976, 0.2964, 0.2961,\n",
       "            0.295 , 0.2947, 0.2932, 0.293 , 0.2925, 0.2917, 0.2915, 0.2896,\n",
       "            0.2893, 0.289 , 0.2888, 0.2883, 0.2878, 0.2869, 0.2866, 0.2864,\n",
       "            0.286 , 0.2852, 0.2847, 0.2834, 0.2832, 0.2827, 0.2805, 0.2795,\n",
       "            0.2786, 0.277 , 0.2769, 0.2734, 0.2727, 0.2722, 0.267 , 0.2656,\n",
       "            0.2632, 0.2627, 0.2615, 0.2588, 0.2573, 0.2559, 0.2556, 0.255 ,\n",
       "            0.2542, 0.254 , 0.2534, 0.2532, 0.252 , 0.2517, 0.2512, 0.251 ,\n",
       "            0.2498, 0.2493, 0.2477, 0.2466, 0.2463, 0.2451, 0.2449, 0.243 ,\n",
       "            0.2418, 0.2415, 0.2401, 0.2399, 0.2391, 0.2388, 0.2375, 0.2374,\n",
       "            0.237 , 0.2318, 0.2314, 0.2307, 0.2278, 0.2273, 0.2269, 0.2251,\n",
       "            0.2244, 0.2218, 0.2205, 0.2195, 0.2185, 0.2179, 0.2167, 0.2163,\n",
       "            0.2142, 0.2124, 0.211 , 0.2109, 0.21  , 0.2096, 0.2089, 0.2048,\n",
       "            0.2024, 0.2009, 0.1985, 0.1973, 0.1959, 0.1941, 0.1907, 0.1858,\n",
       "            0.1849, 0.1843, 0.1824, 0.182 , 0.181 , 0.1749, 0.1748, 0.1707,\n",
       "            0.1682, 0.1565, 0.1445], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.06557377, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.2421875, 0.25     , 0.2578125,\n",
       "            0.2578125, 0.2734375, 0.28125  , 0.296875 , 0.3046875, 0.3203125,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5546875, 0.5703125, 0.5859375,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.75     , 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8046875, 0.8125   , 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.8359375,\n",
       "            0.8359375, 0.8359375, 0.8359375, 0.84375  , 0.84375  , 0.8515625,\n",
       "            0.8515625, 0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.984375 , 0.984375 , 0.984375 , 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59016395, 0.59016395, 0.59016395, 0.59016395,\n",
       "            0.59016395, 0.59016395, 0.59836066, 0.59836066, 0.59836066,\n",
       "            0.60655737, 0.60655737, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.63114756, 0.6393443 , 0.6393443 ,\n",
       "            0.6393443 , 0.6393443 , 0.6393443 , 0.6393443 , 0.6393443 ,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.73770493, 0.73770493,\n",
       "            0.73770493, 0.74590164, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.549 , 0.54  , 0.5317, 0.5273, 0.5244, 0.5225, 0.5186,\n",
       "            0.5044, 0.4922, 0.491 , 0.4897, 0.489 , 0.4888, 0.4883, 0.487 ,\n",
       "            0.4827, 0.4822, 0.4783, 0.477 , 0.474 , 0.472 , 0.4697, 0.469 ,\n",
       "            0.4688, 0.4683, 0.4678, 0.4656, 0.4617, 0.461 , 0.459 , 0.4587,\n",
       "            0.4573, 0.4553, 0.4521, 0.4512, 0.451 , 0.4502, 0.4485, 0.4478,\n",
       "            0.4475, 0.4465, 0.4434, 0.438 , 0.437 , 0.434 , 0.4326, 0.431 ,\n",
       "            0.4297, 0.429 , 0.428 , 0.4258, 0.425 , 0.4248, 0.4194, 0.4094,\n",
       "            0.4048, 0.403 , 0.4023, 0.3997, 0.3945, 0.3904, 0.3867, 0.386 ,\n",
       "            0.3772, 0.3767, 0.3748, 0.3699, 0.363 , 0.3625, 0.3618, 0.3606,\n",
       "            0.3574, 0.3555, 0.3552, 0.3538, 0.3535, 0.3518, 0.35  , 0.3489,\n",
       "            0.3484, 0.3457, 0.3445, 0.344 , 0.343 , 0.3403, 0.3396, 0.3374,\n",
       "            0.3367, 0.3364, 0.3362, 0.336 , 0.3345, 0.3342, 0.3313, 0.3286,\n",
       "            0.3284, 0.3271, 0.3264, 0.3254, 0.325 , 0.3218, 0.3213, 0.32  ,\n",
       "            0.3196, 0.3193, 0.3188, 0.3184, 0.318 , 0.3174, 0.3164, 0.3154,\n",
       "            0.3147, 0.3137, 0.3135, 0.3132, 0.3127, 0.3115, 0.3113, 0.3103,\n",
       "            0.3098, 0.3088, 0.3074, 0.306 , 0.3052, 0.3044, 0.3032, 0.303 ,\n",
       "            0.3022, 0.3005, 0.2998, 0.2996, 0.2993, 0.2969, 0.2966, 0.2952,\n",
       "            0.295 , 0.2942, 0.2935, 0.293 , 0.2922, 0.2915, 0.2913, 0.2903,\n",
       "            0.29  , 0.289 , 0.2869, 0.2864, 0.286 , 0.2852, 0.282 , 0.2815,\n",
       "            0.2812, 0.28  , 0.2795, 0.2793, 0.279 , 0.2783, 0.278 , 0.2769,\n",
       "            0.2766, 0.2761, 0.276 , 0.2742, 0.2737, 0.2717, 0.2712, 0.2708,\n",
       "            0.27  , 0.2683, 0.2673, 0.2666, 0.2656, 0.2654, 0.2646, 0.2637,\n",
       "            0.2632, 0.2605, 0.2568, 0.2551, 0.2546, 0.2537, 0.252 , 0.2483,\n",
       "            0.2482, 0.2478, 0.2467, 0.2451, 0.244 , 0.2438, 0.243 , 0.2422,\n",
       "            0.2406, 0.2402, 0.2386, 0.2379, 0.2375, 0.2374, 0.2352, 0.2344,\n",
       "            0.2339, 0.2325, 0.2313, 0.2307, 0.2299, 0.228 , 0.2256, 0.2251,\n",
       "            0.2244, 0.224 , 0.2235, 0.2211, 0.2197, 0.2181, 0.2179, 0.2119,\n",
       "            0.2109, 0.2089, 0.2086, 0.2081, 0.2075, 0.2068, 0.2064, 0.2   ,\n",
       "            0.1925, 0.1924, 0.1884, 0.1859, 0.1805, 0.1785, 0.1609],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.22950819, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.1640625, 0.1640625, 0.1640625, 0.1796875,\n",
       "            0.1875   , 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.359375 , 0.359375 , 0.3671875, 0.3671875,\n",
       "            0.3671875, 0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.65625  , 0.6640625, 0.6640625, 0.6796875, 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.796875 ,\n",
       "            0.8046875, 0.8046875, 0.8046875, 0.8046875, 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.828125 , 0.828125 , 0.828125 ,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.9140625, 0.9140625, 0.921875 , 0.921875 , 0.921875 , 0.9296875,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.984375 , 0.9921875, 0.9921875,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.24590164, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59016395, 0.59016395,\n",
       "            0.59016395, 0.59016395, 0.59016395, 0.59016395, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.647541  , 0.647541  ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.795082  , 0.795082  ,\n",
       "            0.795082  , 0.795082  , 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6157, 0.6006, 0.5977, 0.594 , 0.584 , 0.5825, 0.5566,\n",
       "            0.5454, 0.5435, 0.5415, 0.54  , 0.538 , 0.5356, 0.532 , 0.527 ,\n",
       "            0.5234, 0.523 , 0.52  , 0.5195, 0.519 , 0.5176, 0.5137, 0.5103,\n",
       "            0.5083, 0.505 , 0.5   , 0.4993, 0.4978, 0.4973, 0.4946, 0.4932,\n",
       "            0.4917, 0.4912, 0.49  , 0.4858, 0.4807, 0.478 , 0.4744, 0.47  ,\n",
       "            0.4695, 0.4656, 0.4644, 0.4626, 0.4607, 0.4595, 0.4573, 0.4553,\n",
       "            0.4507, 0.4497, 0.43  , 0.4285, 0.4253, 0.4175, 0.4172, 0.4158,\n",
       "            0.4119, 0.403 , 0.3972, 0.3962, 0.3882, 0.3826, 0.3809, 0.3792,\n",
       "            0.3782, 0.374 , 0.3738, 0.3723, 0.3706, 0.367 , 0.3665, 0.3647,\n",
       "            0.3635, 0.3628, 0.3564, 0.356 , 0.3542, 0.3538, 0.3494, 0.3462,\n",
       "            0.346 , 0.3457, 0.3442, 0.344 , 0.3438, 0.343 , 0.341 , 0.3396,\n",
       "            0.3386, 0.336 , 0.3342, 0.3337, 0.3335, 0.3315, 0.3308, 0.3306,\n",
       "            0.3303, 0.3296, 0.3289, 0.3274, 0.3271, 0.3262, 0.326 , 0.3257,\n",
       "            0.3235, 0.323 , 0.3225, 0.3215, 0.3184, 0.318 , 0.317 , 0.3157,\n",
       "            0.315 , 0.3147, 0.3145, 0.3142, 0.3127, 0.3125, 0.3103, 0.31  ,\n",
       "            0.3083, 0.308 , 0.3074, 0.3066, 0.306 , 0.3057, 0.3037, 0.303 ,\n",
       "            0.3005, 0.2988, 0.298 , 0.2976, 0.297 , 0.2944, 0.2932, 0.2922,\n",
       "            0.292 , 0.2917, 0.2903, 0.29  , 0.2898, 0.2896, 0.289 , 0.2874,\n",
       "            0.2869, 0.2866, 0.286 , 0.2854, 0.285 , 0.2825, 0.2815, 0.281 ,\n",
       "            0.2805, 0.2778, 0.2776, 0.2727, 0.2717, 0.2708, 0.27  , 0.2695,\n",
       "            0.2693, 0.269 , 0.268 , 0.2676, 0.2673, 0.2654, 0.2642, 0.2632,\n",
       "            0.2622, 0.2595, 0.258 , 0.2563, 0.2559, 0.2542, 0.252 , 0.2512,\n",
       "            0.248 , 0.2478, 0.2477, 0.2458, 0.2452, 0.2451, 0.2437, 0.2434,\n",
       "            0.2411, 0.2407, 0.239 , 0.2384, 0.2382, 0.2368, 0.2347, 0.2338,\n",
       "            0.2322, 0.2297, 0.229 , 0.2278, 0.2252, 0.2246, 0.2239, 0.2202,\n",
       "            0.2189, 0.2175, 0.2172, 0.2166, 0.2134, 0.2096, 0.2095, 0.208 ,\n",
       "            0.2075, 0.205 , 0.2037, 0.2004, 0.1978, 0.1934, 0.1871, 0.1863,\n",
       "            0.182 , 0.1652], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.39344263, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0546875, 0.0546875,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.25     , 0.2578125,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.3203125, 0.3203125, 0.3203125, 0.3359375,\n",
       "            0.3359375, 0.34375  , 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4296875, 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6875   , 0.6875   , 0.6875   , 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.71875  , 0.7265625, 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.75     , 0.75     , 0.75     ,\n",
       "            0.765625 , 0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.8671875, 0.8828125, 0.890625 ,\n",
       "            0.890625 , 0.890625 , 0.8984375, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.4918033 , 0.5       , 0.5081967 , 0.5081967 ,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6147541 , 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.63114756, 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 ,\n",
       "            0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 ,\n",
       "            0.6967213 , 0.71311474, 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.682 , 0.6733, 0.665 , 0.6577, 0.6514, 0.6465, 0.6445,\n",
       "            0.613 , 0.609 , 0.608 , 0.5986, 0.595 , 0.5913, 0.5845, 0.5806,\n",
       "            0.58  , 0.576 , 0.575 , 0.574 , 0.5737, 0.5723, 0.5693, 0.5674,\n",
       "            0.5664, 0.5635, 0.561 , 0.5576, 0.556 , 0.553 , 0.552 , 0.55  ,\n",
       "            0.5493, 0.547 , 0.5435, 0.54  , 0.539 , 0.5356, 0.5312, 0.5303,\n",
       "            0.528 , 0.523 , 0.522 , 0.5186, 0.516 , 0.515 , 0.5117, 0.51  ,\n",
       "            0.4995, 0.4958, 0.4949, 0.4934, 0.4924, 0.492 , 0.4805, 0.4785,\n",
       "            0.4656, 0.4612, 0.458 , 0.4578, 0.457 , 0.452 , 0.451 , 0.4448,\n",
       "            0.4412, 0.433 , 0.4294, 0.4275, 0.4236, 0.4224, 0.4143, 0.4136,\n",
       "            0.412 , 0.4114, 0.406 , 0.4043, 0.4011, 0.4001, 0.3972, 0.3967,\n",
       "            0.3965, 0.3936, 0.3933, 0.3923, 0.386 , 0.3835, 0.382 , 0.3818,\n",
       "            0.3782, 0.3765, 0.3733, 0.3718, 0.3682, 0.3677, 0.367 , 0.3645,\n",
       "            0.363 , 0.3628, 0.362 , 0.3604, 0.36  , 0.3584, 0.3577, 0.3572,\n",
       "            0.357 , 0.356 , 0.3557, 0.3552, 0.3542, 0.3538, 0.3533, 0.3496,\n",
       "            0.3494, 0.3464, 0.3462, 0.3452, 0.345 , 0.343 , 0.3418, 0.3408,\n",
       "            0.3406, 0.339 , 0.3345, 0.3335, 0.3325, 0.3318, 0.3306, 0.3303,\n",
       "            0.33  , 0.3296, 0.329 , 0.3289, 0.3262, 0.326 , 0.3245, 0.3228,\n",
       "            0.3225, 0.3218, 0.321 , 0.32  , 0.3193, 0.3186, 0.3176, 0.3164,\n",
       "            0.3162, 0.3154, 0.3137, 0.3125, 0.3096, 0.309 , 0.308 , 0.3071,\n",
       "            0.306 , 0.3044, 0.3027, 0.299 , 0.2983, 0.2961, 0.2947, 0.2944,\n",
       "            0.2937, 0.2922, 0.2915, 0.29  , 0.2898, 0.2896, 0.288 , 0.2874,\n",
       "            0.2861, 0.2847, 0.2832, 0.2825, 0.2822, 0.2798, 0.2769, 0.2761,\n",
       "            0.275 , 0.2747, 0.2742, 0.274 , 0.2712, 0.2703, 0.268 , 0.2673,\n",
       "            0.2656, 0.2654, 0.265 , 0.2646, 0.2644, 0.2642, 0.2634, 0.2627,\n",
       "            0.2625, 0.2622, 0.2615, 0.261 , 0.2607, 0.2603, 0.2593, 0.258 ,\n",
       "            0.257 , 0.2568, 0.2554, 0.255 , 0.2524, 0.2515, 0.2494, 0.2493,\n",
       "            0.2482, 0.2466, 0.244 , 0.2407, 0.2402, 0.2292, 0.2283, 0.2268,\n",
       "            0.223 , 0.2218, 0.2175, 0.2163, 0.2135, 0.2103, 0.2039, 0.202 ,\n",
       "            0.1995, 0.1959, 0.1958, 0.1948, 0.1934, 0.1882], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.45901638, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1953125, 0.203125 ,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.25     , 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.3203125, 0.328125 ,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.3984375,\n",
       "            0.40625  , 0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.59375  , 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6875   , 0.6953125, 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.859375 , 0.875    , 0.8828125, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.921875 , 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.9453125, 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5081967 , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.6229508 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.72131145, 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7354, 0.73  , 0.7207, 0.707 , 0.7056, 0.697 , 0.6943,\n",
       "            0.66  , 0.6597, 0.659 , 0.6465, 0.6396, 0.6367, 0.63  , 0.6265,\n",
       "            0.6235, 0.6206, 0.6196, 0.6167, 0.6157, 0.615 , 0.6113, 0.61  ,\n",
       "            0.6084, 0.607 , 0.6064, 0.6025, 0.5986, 0.598 , 0.5967, 0.595 ,\n",
       "            0.591 , 0.5894, 0.582 , 0.5806, 0.576 , 0.5713, 0.5654, 0.565 ,\n",
       "            0.563 , 0.56  , 0.5547, 0.5513, 0.551 , 0.548 , 0.542 , 0.5303,\n",
       "            0.527 , 0.5254, 0.525 , 0.5225, 0.5205, 0.5176, 0.5063, 0.4946,\n",
       "            0.4937, 0.4885, 0.4834, 0.4802, 0.479 , 0.4753, 0.475 , 0.4604,\n",
       "            0.459 , 0.454 , 0.4531, 0.4504, 0.4426, 0.4395, 0.439 , 0.434 ,\n",
       "            0.4338, 0.4333, 0.4287, 0.4277, 0.4255, 0.4214, 0.42  , 0.4197,\n",
       "            0.4172, 0.413 , 0.4124, 0.406 , 0.405 , 0.3955, 0.3928, 0.392 ,\n",
       "            0.3916, 0.3901, 0.3892, 0.3884, 0.3882, 0.3865, 0.3828, 0.3823,\n",
       "            0.382 , 0.3809, 0.3801, 0.3757, 0.3748, 0.3743, 0.374 , 0.371 ,\n",
       "            0.3699, 0.3687, 0.3667, 0.3662, 0.365 , 0.3647, 0.3596, 0.3594,\n",
       "            0.359 , 0.3574, 0.3572, 0.3564, 0.3557, 0.3552, 0.355 , 0.3547,\n",
       "            0.3538, 0.3528, 0.3506, 0.3496, 0.3486, 0.3481, 0.348 , 0.3462,\n",
       "            0.3445, 0.3442, 0.3418, 0.3403, 0.34  , 0.339 , 0.3364, 0.3357,\n",
       "            0.334 , 0.3333, 0.3325, 0.3318, 0.3306, 0.3293, 0.328 , 0.3247,\n",
       "            0.32  , 0.3198, 0.316 , 0.3152, 0.315 , 0.3142, 0.3135, 0.3132,\n",
       "            0.313 , 0.3108, 0.3088, 0.3083, 0.3079, 0.3074, 0.3057, 0.3047,\n",
       "            0.303 , 0.301 , 0.2998, 0.297 , 0.2966, 0.2947, 0.294 , 0.2922,\n",
       "            0.2915, 0.2898, 0.2896, 0.2893, 0.284 , 0.2837, 0.282 , 0.2808,\n",
       "            0.2798, 0.2788, 0.2783, 0.2776, 0.2766, 0.2761, 0.2756, 0.2742,\n",
       "            0.274 , 0.273 , 0.2712, 0.271 , 0.27  , 0.2695, 0.269 , 0.2686,\n",
       "            0.268 , 0.2678, 0.2673, 0.2668, 0.266 , 0.2656, 0.2654, 0.2632,\n",
       "            0.2625, 0.262 , 0.2578, 0.2566, 0.2563, 0.2556, 0.255 , 0.2537,\n",
       "            0.251 , 0.25  , 0.249 , 0.2471, 0.2462, 0.2413, 0.239 , 0.2382,\n",
       "            0.2362, 0.2344, 0.2339, 0.2294, 0.2166, 0.2161, 0.2147, 0.2144,\n",
       "            0.2076, 0.2063, 0.2037, 0.1993, 0.1904, 0.1869, 0.1821, 0.1812,\n",
       "            0.1792], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.5081967, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.140625 , 0.1484375, 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.171875 , 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.2421875, 0.25     , 0.2578125, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3125   , 0.3125   , 0.3125   ,\n",
       "            0.3125   , 0.3203125, 0.3203125, 0.328125 , 0.3359375, 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.3828125, 0.3828125,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.8359375,\n",
       "            0.84375  , 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.921875 , 0.9296875, 0.9296875, 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5081967 ,\n",
       "            0.5081967 , 0.5081967 , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.60655737, 0.60655737, 0.6147541 , 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.6229508 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.7295082 , 0.7295082 , 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7812, 0.7783, 0.769 , 0.753 , 0.751 , 0.741 , 0.739 ,\n",
       "            0.7065, 0.7056, 0.701 , 0.69  , 0.6807, 0.678 , 0.6743, 0.6665,\n",
       "            0.6646, 0.6606, 0.658 , 0.655 , 0.6543, 0.654 , 0.652 , 0.647 ,\n",
       "            0.6455, 0.6445, 0.643 , 0.6396, 0.637 , 0.6333, 0.6313, 0.6265,\n",
       "            0.624 , 0.6216, 0.615 , 0.61  , 0.6045, 0.6035, 0.5967, 0.5957,\n",
       "            0.595 , 0.5913, 0.587 , 0.581 , 0.5776, 0.5723, 0.5586, 0.5566,\n",
       "            0.5547, 0.552 , 0.55  , 0.547 , 0.5303, 0.527 , 0.5195, 0.5176,\n",
       "            0.508 , 0.5073, 0.504 , 0.499 , 0.496 , 0.4866, 0.483 , 0.4827,\n",
       "            0.482 , 0.4773, 0.4712, 0.4695, 0.4683, 0.4639, 0.463 , 0.462 ,\n",
       "            0.4587, 0.4548, 0.4526, 0.4492, 0.4473, 0.4456, 0.4395, 0.436 ,\n",
       "            0.433 , 0.4314, 0.428 , 0.4265, 0.421 , 0.4177, 0.4133, 0.4102,\n",
       "            0.4077, 0.4072, 0.407 , 0.4067, 0.4062, 0.406 , 0.4006, 0.4004,\n",
       "            0.3994, 0.3982, 0.3943, 0.3909, 0.3906, 0.39  , 0.3894, 0.3884,\n",
       "            0.386 , 0.3845, 0.3838, 0.381 , 0.3787, 0.3784, 0.378 , 0.3743,\n",
       "            0.373 , 0.372 , 0.371 , 0.3699, 0.3684, 0.368 , 0.3672, 0.366 ,\n",
       "            0.365 , 0.3645, 0.3638, 0.3635, 0.3633, 0.3623, 0.3594, 0.3582,\n",
       "            0.3574, 0.3567, 0.3564, 0.3552, 0.351 , 0.3499, 0.3494, 0.349 ,\n",
       "            0.3489, 0.347 , 0.3467, 0.3435, 0.343 , 0.338 , 0.336 , 0.3333,\n",
       "            0.33  , 0.3298, 0.3281, 0.327 , 0.3267, 0.3254, 0.3228, 0.322 ,\n",
       "            0.3174, 0.3162, 0.3142, 0.3113, 0.3103, 0.31  , 0.3086, 0.3079,\n",
       "            0.3064, 0.304 , 0.3032, 0.3027, 0.3022, 0.3013, 0.3008, 0.2998,\n",
       "            0.2966, 0.2954, 0.295 , 0.2942, 0.2932, 0.292 , 0.2915, 0.2898,\n",
       "            0.2886, 0.287 , 0.2852, 0.2832, 0.2822, 0.281 , 0.2808, 0.2803,\n",
       "            0.2795, 0.2788, 0.2766, 0.2761, 0.2747, 0.2742, 0.2737, 0.2727,\n",
       "            0.2717, 0.2705, 0.27  , 0.2695, 0.269 , 0.2678, 0.2651, 0.2644,\n",
       "            0.2622, 0.2612, 0.2605, 0.258 , 0.2563, 0.2559, 0.253 , 0.252 ,\n",
       "            0.2507, 0.25  , 0.2493, 0.2478, 0.2452, 0.2445, 0.2429, 0.2426,\n",
       "            0.2422, 0.2401, 0.2391, 0.236 , 0.2358, 0.2281, 0.2277, 0.2217,\n",
       "            0.214 , 0.2124, 0.212 , 0.2094, 0.207 , 0.2018, 0.1907, 0.1776,\n",
       "            0.1771, 0.1678, 0.1675, 0.1653], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.0390625, dtype=float32),\n",
       "    'tpr': array(0.5163934, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.015625 , 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1015625, 0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.140625 , 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.2421875,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.2890625, 0.296875 , 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3125   , 0.3203125, 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.3671875, 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.625    , 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5081967 , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.647541  , 0.647541  , 0.6557377 , 0.6639344 , 0.6639344 ,\n",
       "            0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.7295082 , 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.852459  , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8237, 0.823 , 0.814 , 0.798 , 0.7935, 0.7847, 0.782 ,\n",
       "            0.7524, 0.751 , 0.7437, 0.7334, 0.723 , 0.7217, 0.719 , 0.711 ,\n",
       "            0.7056, 0.703 , 0.6987, 0.6978, 0.6963, 0.696 , 0.695 , 0.694 ,\n",
       "            0.689 , 0.688 , 0.6836, 0.682 , 0.68  , 0.6777, 0.6733, 0.673 ,\n",
       "            0.6655, 0.663 , 0.6626, 0.653 , 0.646 , 0.645 , 0.6406, 0.6333,\n",
       "            0.633 , 0.6323, 0.6313, 0.63  , 0.625 , 0.615 , 0.6104, 0.6055,\n",
       "            0.5923, 0.592 , 0.5903, 0.59  , 0.582 , 0.5815, 0.5767, 0.56  ,\n",
       "            0.558 , 0.5483, 0.537 , 0.5337, 0.5317, 0.5225, 0.522 , 0.5137,\n",
       "            0.5103, 0.51  , 0.509 , 0.4995, 0.4976, 0.4956, 0.494 , 0.4922,\n",
       "            0.4883, 0.4863, 0.4832, 0.4763, 0.476 , 0.4722, 0.4714, 0.4695,\n",
       "            0.4636, 0.4568, 0.455 , 0.4495, 0.4485, 0.446 , 0.4429, 0.4424,\n",
       "            0.433 , 0.4287, 0.4265, 0.4248, 0.4243, 0.4238, 0.4233, 0.4224,\n",
       "            0.4172, 0.417 , 0.4119, 0.4114, 0.4082, 0.4077, 0.4062, 0.4058,\n",
       "            0.405 , 0.4038, 0.4004, 0.3994, 0.3992, 0.3982, 0.3967, 0.3958,\n",
       "            0.3936, 0.3909, 0.3906, 0.3884, 0.387 , 0.3862, 0.3838, 0.383 ,\n",
       "            0.3816, 0.3804, 0.38  , 0.378 , 0.377 , 0.3743, 0.3738, 0.373 ,\n",
       "            0.3706, 0.3694, 0.369 , 0.3682, 0.3677, 0.3665, 0.366 , 0.3638,\n",
       "            0.3625, 0.362 , 0.3604, 0.359 , 0.3582, 0.3508, 0.3503, 0.35  ,\n",
       "            0.3489, 0.3486, 0.3467, 0.3447, 0.3394, 0.3374, 0.3364, 0.3354,\n",
       "            0.3345, 0.334 , 0.3323, 0.329 , 0.3213, 0.3206, 0.3203, 0.3176,\n",
       "            0.3171, 0.3145, 0.3137, 0.3125, 0.3108, 0.3096, 0.308 , 0.307 ,\n",
       "            0.3064, 0.3062, 0.306 , 0.3032, 0.3018, 0.301 , 0.3005, 0.2969,\n",
       "            0.2966, 0.296 , 0.2937, 0.2932, 0.2925, 0.2903, 0.2898, 0.288 ,\n",
       "            0.2869, 0.2864, 0.2847, 0.283 , 0.2825, 0.2815, 0.281 , 0.2798,\n",
       "            0.2783, 0.2778, 0.277 , 0.2742, 0.2715, 0.271 , 0.2688, 0.2668,\n",
       "            0.2646, 0.263 , 0.2622, 0.2612, 0.26  , 0.2568, 0.2556, 0.2554,\n",
       "            0.2534, 0.2532, 0.2527, 0.2505, 0.2489, 0.2483, 0.2482, 0.2471,\n",
       "            0.2458, 0.2445, 0.2433, 0.2415, 0.2374, 0.2356, 0.2339, 0.2306,\n",
       "            0.2269, 0.2264, 0.2249, 0.2198, 0.2175, 0.2168, 0.2157, 0.215 ,\n",
       "            0.213 , 0.2002, 0.1909, 0.1794, 0.169 , 0.1654, 0.156 , 0.1558,\n",
       "            0.1536], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1171875, dtype=float32),\n",
       "    'tpr': array(0.55737704, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.125    , 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.1640625,\n",
       "            0.1640625, 0.1640625, 0.1796875, 0.1796875, 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.2421875, 0.2421875,\n",
       "            0.25     , 0.25     , 0.2578125, 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.2890625, 0.2890625, 0.3046875, 0.3125   ,\n",
       "            0.3125   , 0.3125   , 0.3125   , 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3671875, 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.78125  , 0.7890625, 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.6229508 , 0.63114756, 0.63114756, 0.6393443 , 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.647541  , 0.647541  ,\n",
       "            0.647541  , 0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8623, 0.86  , 0.853 , 0.8384, 0.8306, 0.823 , 0.821 ,\n",
       "            0.7954, 0.7935, 0.782 , 0.775 , 0.7637, 0.762 , 0.7607, 0.7544,\n",
       "            0.7456, 0.7446, 0.743 , 0.736 , 0.7354, 0.735 , 0.7344, 0.734 ,\n",
       "            0.7295, 0.7266, 0.7256, 0.72  , 0.719 , 0.7183, 0.718 , 0.711 ,\n",
       "            0.7065, 0.705 , 0.699 , 0.6904, 0.69  , 0.6816, 0.676 , 0.674 ,\n",
       "            0.673 , 0.668 , 0.6675, 0.667 , 0.649 , 0.643 , 0.6406, 0.6396,\n",
       "            0.6284, 0.6255, 0.623 , 0.6143, 0.6123, 0.6084, 0.605 , 0.587 ,\n",
       "            0.582 , 0.575 , 0.5737, 0.5645, 0.5547, 0.554 , 0.553 , 0.548 ,\n",
       "            0.547 , 0.5454, 0.545 , 0.538 , 0.5273, 0.5244, 0.524 , 0.523 ,\n",
       "            0.52  , 0.5166, 0.5137, 0.511 , 0.5107, 0.509 , 0.508 , 0.5044,\n",
       "            0.499 , 0.495 , 0.4893, 0.486 , 0.4749, 0.4731, 0.4702, 0.4695,\n",
       "            0.4663, 0.4656, 0.462 , 0.4612, 0.459 , 0.4546, 0.4543, 0.4526,\n",
       "            0.451 , 0.4495, 0.4465, 0.4438, 0.439 , 0.4375, 0.436 , 0.4358,\n",
       "            0.435 , 0.433 , 0.4307, 0.4302, 0.428 , 0.4233, 0.423 , 0.4229,\n",
       "            0.4224, 0.4219, 0.4202, 0.4192, 0.414 , 0.4136, 0.4119, 0.4111,\n",
       "            0.409 , 0.407 , 0.4062, 0.405 , 0.4045, 0.3992, 0.3982, 0.398 ,\n",
       "            0.3975, 0.397 , 0.3955, 0.3926, 0.3904, 0.39  , 0.3882, 0.3806,\n",
       "            0.3794, 0.3777, 0.3738, 0.3726, 0.37  , 0.3691, 0.3667, 0.3655,\n",
       "            0.365 , 0.3584, 0.357 , 0.3552, 0.355 , 0.3547, 0.3525, 0.3477,\n",
       "            0.3455, 0.3447, 0.3433, 0.3425, 0.342 , 0.3416, 0.3403, 0.3352,\n",
       "            0.3345, 0.3337, 0.3325, 0.3306, 0.329 , 0.3271, 0.3242, 0.3237,\n",
       "            0.3235, 0.3174, 0.315 , 0.3145, 0.3142, 0.3137, 0.313 , 0.3123,\n",
       "            0.3105, 0.31  , 0.3098, 0.3093, 0.3086, 0.3057, 0.3052, 0.3044,\n",
       "            0.303 , 0.2986, 0.2983, 0.2976, 0.2974, 0.2927, 0.2908, 0.2886,\n",
       "            0.288 , 0.2837, 0.2808, 0.2795, 0.2776, 0.274 , 0.273 , 0.2712,\n",
       "            0.2708, 0.268 , 0.2673, 0.2656, 0.261 , 0.2605, 0.2578, 0.2559,\n",
       "            0.2556, 0.2502, 0.2494, 0.2473, 0.2463, 0.2448, 0.2434, 0.2415,\n",
       "            0.2411, 0.2395, 0.2382, 0.2375, 0.2358, 0.2292, 0.2273, 0.2272,\n",
       "            0.2251, 0.2222, 0.2185, 0.218 , 0.211 , 0.2098, 0.1915, 0.1805,\n",
       "            0.1709, 0.1665, 0.1561, 0.1461, 0.1449, 0.1428], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1328125, dtype=float32),\n",
       "    'tpr': array(0.57377046, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.046875 , 0.0546875, 0.0546875, 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2421875, 0.25     , 0.25     , 0.25     , 0.2578125,\n",
       "            0.2578125, 0.2578125, 0.2578125, 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3125   , 0.328125 , 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.3515625, 0.359375 ,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.4140625, 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.421875 , 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.4921875, 0.4921875, 0.4921875, 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.796875 , 0.8046875, 0.8046875, 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.33606556, 0.3442623 ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.5       , 0.5081967 , 0.5081967 , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59836066, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.647541  , 0.647541  ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.74590164, 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8906, 0.8877, 0.883 , 0.869 , 0.86  , 0.8535, 0.8516,\n",
       "            0.8286, 0.8257, 0.8135, 0.808 , 0.799 , 0.795 , 0.7935, 0.789 ,\n",
       "            0.7812, 0.7783, 0.7754, 0.7695, 0.769 , 0.7686, 0.7676, 0.7666,\n",
       "            0.7627, 0.7617, 0.7603, 0.7524, 0.752 , 0.7515, 0.743 , 0.741 ,\n",
       "            0.7373, 0.731 , 0.725 , 0.7217, 0.7124, 0.707 , 0.7065, 0.701 ,\n",
       "            0.698 , 0.6978, 0.6787, 0.674 , 0.672 , 0.67  , 0.658 , 0.6543,\n",
       "            0.6523, 0.6416, 0.64  , 0.636 , 0.6353, 0.6157, 0.6123, 0.6084,\n",
       "            0.603 , 0.589 , 0.584 , 0.5806, 0.58  , 0.5747, 0.5703, 0.5693,\n",
       "            0.5635, 0.5513, 0.548 , 0.5464, 0.5454, 0.5405, 0.539 , 0.538 ,\n",
       "            0.5356, 0.533 , 0.5327, 0.5303, 0.5293, 0.5264, 0.5225, 0.511 ,\n",
       "            0.505 , 0.4968, 0.4941, 0.4917, 0.4856, 0.484 , 0.4812, 0.4807,\n",
       "            0.4792, 0.4763, 0.473 , 0.4707, 0.4705, 0.47  , 0.469 , 0.4683,\n",
       "            0.465 , 0.4548, 0.4546, 0.4521, 0.4504, 0.4497, 0.4492, 0.446 ,\n",
       "            0.4458, 0.4443, 0.4426, 0.4417, 0.441 , 0.4402, 0.4397, 0.434 ,\n",
       "            0.433 , 0.4329, 0.4324, 0.4272, 0.4263, 0.4258, 0.4246, 0.4236,\n",
       "            0.4224, 0.4202, 0.419 , 0.4177, 0.4126, 0.4124, 0.4094, 0.4092,\n",
       "            0.4082, 0.4067, 0.4062, 0.406 , 0.4043, 0.403 , 0.3848, 0.3835,\n",
       "            0.383 , 0.3823, 0.382 , 0.3813, 0.3801, 0.3782, 0.3772, 0.376 ,\n",
       "            0.3733, 0.373 , 0.367 , 0.3667, 0.3599, 0.3591, 0.358 , 0.3572,\n",
       "            0.3557, 0.3547, 0.3525, 0.3516, 0.347 , 0.3467, 0.343 , 0.337 ,\n",
       "            0.3367, 0.3352, 0.3345, 0.333 , 0.3315, 0.3252, 0.3242, 0.3237,\n",
       "            0.3223, 0.3218, 0.321 , 0.3176, 0.3171, 0.3157, 0.3115, 0.3064,\n",
       "            0.3057, 0.3025, 0.302 , 0.3018, 0.3005, 0.3003, 0.2961, 0.294 ,\n",
       "            0.2932, 0.293 , 0.2888, 0.2834, 0.2832, 0.2805, 0.2776, 0.2761,\n",
       "            0.2722, 0.2705, 0.2668, 0.2664, 0.262 , 0.2585, 0.256 , 0.2544,\n",
       "            0.2542, 0.254 , 0.2532, 0.251 , 0.2502, 0.2493, 0.2426, 0.2421,\n",
       "            0.2418, 0.2394, 0.2384, 0.2351, 0.2332, 0.2327, 0.2322, 0.2289,\n",
       "            0.2239, 0.2203, 0.2189, 0.2179, 0.213 , 0.2089, 0.2085, 0.2017,\n",
       "            0.2002, 0.1831, 0.1699, 0.1604, 0.1577, 0.1455, 0.1355, 0.134 ,\n",
       "            0.132 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1640625, dtype=float32),\n",
       "    'tpr': array(0.59836066, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0546875, 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.078125 , 0.078125 ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.25     , 0.25     , 0.25     , 0.25     ,\n",
       "            0.25     , 0.25     , 0.25     , 0.2578125, 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.296875 , 0.3046875, 0.3125   , 0.3125   , 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.375    , 0.375    , 0.3828125, 0.390625 , 0.390625 ,\n",
       "            0.390625 , 0.390625 , 0.390625 , 0.3984375, 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5      , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.75     , 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.20491803, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.4918033 , 0.5       , 0.5       , 0.5081967 , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.6229508 , 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.73770493, 0.73770493,\n",
       "            0.73770493, 0.74590164, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9116, 0.9077, 0.9043, 0.8916, 0.8813, 0.876 , 0.874 ,\n",
       "            0.854 , 0.8506, 0.837 , 0.833 , 0.8267, 0.8193, 0.8174, 0.8164,\n",
       "            0.811 , 0.805 , 0.8   , 0.799 , 0.7954, 0.792 , 0.7915, 0.79  ,\n",
       "            0.7896, 0.781 , 0.7783, 0.7764, 0.776 , 0.7695, 0.768 , 0.7637,\n",
       "            0.7544, 0.7456, 0.7363, 0.735 , 0.7334, 0.73  , 0.7295, 0.7227,\n",
       "            0.721 , 0.7207, 0.7056, 0.7007, 0.694 , 0.6934, 0.684 , 0.678 ,\n",
       "            0.673 , 0.666 , 0.6626, 0.66  , 0.6567, 0.641 , 0.6313, 0.631 ,\n",
       "            0.6284, 0.6187, 0.6094, 0.6084, 0.6074, 0.607 , 0.594 , 0.5903,\n",
       "            0.5854, 0.576 , 0.5737, 0.5684, 0.5664, 0.566 , 0.565 , 0.562 ,\n",
       "            0.561 , 0.56  , 0.5576, 0.556 , 0.553 , 0.55  , 0.536 , 0.525 ,\n",
       "            0.524 , 0.5205, 0.519 , 0.512 , 0.51  , 0.5044, 0.502 , 0.4998,\n",
       "            0.4983, 0.4976, 0.4966, 0.4956, 0.4954, 0.495 , 0.4941, 0.4922,\n",
       "            0.4897, 0.479 , 0.477 , 0.4753, 0.471 , 0.47  , 0.469 , 0.4685,\n",
       "            0.467 , 0.4663, 0.466 , 0.4658, 0.463 , 0.4565, 0.4556, 0.454 ,\n",
       "            0.452 , 0.4504, 0.447 , 0.4456, 0.444 , 0.4434, 0.4421, 0.438 ,\n",
       "            0.4363, 0.4358, 0.4353, 0.4346, 0.434 , 0.4338, 0.4275, 0.4272,\n",
       "            0.426 , 0.424 , 0.4233, 0.4219, 0.4158, 0.4045, 0.404 , 0.403 ,\n",
       "            0.3994, 0.3982, 0.3977, 0.394 , 0.3923, 0.3894, 0.3884, 0.3862,\n",
       "            0.385 , 0.383 , 0.382 , 0.3813, 0.3801, 0.3784, 0.375 , 0.3733,\n",
       "            0.3687, 0.3674, 0.3643, 0.3582, 0.3577, 0.356 , 0.352 , 0.3516,\n",
       "            0.3496, 0.3486, 0.3481, 0.347 , 0.3464, 0.346 , 0.3394, 0.339 ,\n",
       "            0.3367, 0.3352, 0.3347, 0.3328, 0.332 , 0.3315, 0.3298, 0.3267,\n",
       "            0.3232, 0.3208, 0.3196, 0.314 , 0.3137, 0.3096, 0.3093, 0.3062,\n",
       "            0.306 , 0.3005, 0.2993, 0.2966, 0.296 , 0.2908, 0.29  , 0.2893,\n",
       "            0.2854, 0.2808, 0.2769, 0.2766, 0.2751, 0.2737, 0.272 , 0.2644,\n",
       "            0.2632, 0.258 , 0.2563, 0.2551, 0.252 , 0.2489, 0.2487, 0.2456,\n",
       "            0.2452, 0.2438, 0.2426, 0.2355, 0.2347, 0.2319, 0.2301, 0.2268,\n",
       "            0.2247, 0.2225, 0.222 , 0.2189, 0.2091, 0.2085, 0.2068, 0.202 ,\n",
       "            0.1979, 0.1974, 0.1934, 0.1876, 0.1711, 0.1586, 0.1527, 0.1511,\n",
       "            0.1359, 0.1259, 0.1232, 0.1213], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.2109375, dtype=float32),\n",
       "    'tpr': array(0.6393443, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.1640625,\n",
       "            0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.2421875,\n",
       "            0.25     , 0.25     , 0.25     , 0.25     , 0.25     , 0.2578125,\n",
       "            0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.2890625, 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.3984375,\n",
       "            0.3984375, 0.3984375, 0.3984375, 0.40625  , 0.40625  , 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.5234375, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18852459, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.60655737, 0.6147541 , 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.6393443 , 0.6393443 ,\n",
       "            0.6393443 , 0.647541  , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9287 , 0.9243 , 0.922  , 0.9106 , 0.9    , 0.8955 ,\n",
       "            0.8936 , 0.876  , 0.8726 , 0.8584 , 0.8555 , 0.8506 , 0.842  ,\n",
       "            0.841  , 0.839  , 0.837  , 0.829  , 0.824  , 0.822  , 0.8193 ,\n",
       "            0.819  , 0.8154 , 0.8145 , 0.814  , 0.8115 , 0.8066 , 0.8027 ,\n",
       "            0.799  , 0.7954 , 0.791  , 0.7876 , 0.7817 , 0.777  , 0.7686 ,\n",
       "            0.761  , 0.759  , 0.7583 , 0.756  , 0.752  , 0.7456 , 0.743  ,\n",
       "            0.742  , 0.7344 , 0.722  , 0.716  , 0.7153 , 0.708  , 0.701  ,\n",
       "            0.6934 , 0.693  , 0.683  , 0.6797 , 0.6772 , 0.6655 , 0.657  ,\n",
       "            0.6523 , 0.652  , 0.6494 , 0.648  , 0.637  , 0.6333 , 0.6323 ,\n",
       "            0.6313 , 0.6294 , 0.617  , 0.6147 , 0.6016 , 0.601  , 0.598  ,\n",
       "            0.5967 , 0.589  , 0.5884 , 0.587  , 0.586  , 0.5854 , 0.585  ,\n",
       "            0.5796 , 0.5693 , 0.567  , 0.558  , 0.5493 , 0.543  , 0.542  ,\n",
       "            0.541  , 0.537  , 0.531  , 0.5254 , 0.525  , 0.522  , 0.519  ,\n",
       "            0.5186 , 0.517  , 0.5166 , 0.516  , 0.5107 , 0.507  , 0.5063 ,\n",
       "            0.5005 , 0.4958 , 0.4924 , 0.4922 , 0.4907 , 0.4868 , 0.4866 ,\n",
       "            0.486  , 0.4841 , 0.484  , 0.4836 , 0.4783 , 0.478  , 0.468  ,\n",
       "            0.4673 , 0.4646 , 0.464  , 0.4639 , 0.4617 , 0.4597 , 0.4595 ,\n",
       "            0.4583 , 0.4563 , 0.4558 , 0.4531 , 0.451  , 0.4468 , 0.4438 ,\n",
       "            0.4436 , 0.4424 , 0.4417 , 0.4404 , 0.4387 , 0.4363 , 0.4343 ,\n",
       "            0.4316 , 0.4292 , 0.4287 , 0.4246 , 0.4216 , 0.4192 , 0.4177 ,\n",
       "            0.4128 , 0.4114 , 0.4087 , 0.408  , 0.4055 , 0.405  , 0.4011 ,\n",
       "            0.3992 , 0.3945 , 0.394  , 0.3923 , 0.392  , 0.387  , 0.3855 ,\n",
       "            0.3835 , 0.3828 , 0.3792 , 0.375  , 0.37   , 0.3687 , 0.3645 ,\n",
       "            0.3633 , 0.3625 , 0.3618 , 0.3608 , 0.3586 , 0.3574 , 0.357  ,\n",
       "            0.3523 , 0.3489 , 0.348  , 0.3477 , 0.3474 , 0.3442 , 0.342  ,\n",
       "            0.3362 , 0.3354 , 0.3352 , 0.3298 , 0.329  , 0.3262 , 0.3257 ,\n",
       "            0.3218 , 0.3154 , 0.3127 , 0.3032 , 0.301  , 0.2998 , 0.2974 ,\n",
       "            0.297  , 0.2932 , 0.2927 , 0.2908 , 0.289  , 0.2874 , 0.2844 ,\n",
       "            0.284  , 0.2766 , 0.2742 , 0.2727 , 0.2722 , 0.269  , 0.2664 ,\n",
       "            0.2642 , 0.2605 , 0.2588 , 0.2563 , 0.2473 , 0.2463 , 0.2417 ,\n",
       "            0.239  , 0.2384 , 0.2368 , 0.2355 , 0.2325 , 0.2319 , 0.2299 ,\n",
       "            0.2263 , 0.2216 , 0.2195 , 0.214  , 0.2118 , 0.2113 , 0.2085 ,\n",
       "            0.1982 , 0.1979 , 0.1948 , 0.1907 , 0.1865 , 0.1863 , 0.1836 ,\n",
       "            0.1753 , 0.1598 , 0.1475 , 0.1458 , 0.1411 , 0.1257 , 0.11597,\n",
       "            0.1126 , 0.11066], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.25, dtype=float32),\n",
       "    'tpr': array(0.6885246, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1015625, 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.25     , 0.25     , 0.25     , 0.25     , 0.25     , 0.2578125,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.265625 , 0.265625 , 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.375    ,\n",
       "            0.375    , 0.375    , 0.3828125, 0.390625 , 0.390625 , 0.3984375,\n",
       "            0.3984375, 0.3984375, 0.3984375, 0.3984375, 0.40625  , 0.40625  ,\n",
       "            0.40625  , 0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4609375, 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.4765625, 0.484375 , 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.71875  , 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18852459, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.63114756, 0.6393443 ,\n",
       "            0.6393443 , 0.6393443 , 0.6393443 , 0.647541  , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.945  , 0.9404 , 0.939  , 0.929  , 0.919  , 0.915  ,\n",
       "            0.913  , 0.898  , 0.895  , 0.881  , 0.879  , 0.875  , 0.866  ,\n",
       "            0.865  , 0.8633 , 0.863  , 0.855  , 0.8516 , 0.846  , 0.8457 ,\n",
       "            0.8447 , 0.843  , 0.84   , 0.8394 , 0.836  , 0.8345 , 0.8296 ,\n",
       "            0.824  , 0.8237 , 0.817  , 0.8145 , 0.8105 , 0.8027 , 0.795  ,\n",
       "            0.7905 , 0.7866 , 0.785  , 0.7847 , 0.778  , 0.772  , 0.769  ,\n",
       "            0.768  , 0.766  , 0.7476 , 0.7427 , 0.741  , 0.736  , 0.728  ,\n",
       "            0.7246 , 0.7183 , 0.708  , 0.7046 , 0.702  , 0.6943 , 0.6875 ,\n",
       "            0.6807 , 0.6787 , 0.673  , 0.6694 , 0.6626 , 0.662  , 0.661  ,\n",
       "            0.6543 , 0.645  , 0.6426 , 0.625  , 0.624  , 0.6226 , 0.6196 ,\n",
       "            0.616  , 0.6157 , 0.615  , 0.6143 , 0.6133 , 0.61   , 0.6055 ,\n",
       "            0.5938 , 0.586  , 0.584  , 0.577  , 0.57   , 0.569  , 0.5645 ,\n",
       "            0.5625 , 0.556  , 0.5527 , 0.5503 , 0.5454 , 0.543  , 0.54   ,\n",
       "            0.5327 , 0.528  , 0.5244 , 0.5234 , 0.523  , 0.518  , 0.5166 ,\n",
       "            0.513  , 0.51   , 0.5083 , 0.505  , 0.503  , 0.502  , 0.4966 ,\n",
       "            0.4863 , 0.4841 , 0.484  , 0.4836 , 0.483  , 0.4822 , 0.4814 ,\n",
       "            0.4783 , 0.476  , 0.4739 , 0.4724 , 0.4705 , 0.4702 , 0.4631 ,\n",
       "            0.4626 , 0.4585 , 0.4565 , 0.4563 , 0.4524 , 0.452  , 0.4517 ,\n",
       "            0.4492 , 0.4485 , 0.4417 , 0.4404 , 0.4397 , 0.4395 , 0.4375 ,\n",
       "            0.437  , 0.4363 , 0.43   , 0.4292 , 0.4258 , 0.4255 , 0.423  ,\n",
       "            0.4216 , 0.4177 , 0.4163 , 0.4138 , 0.4124 , 0.411  , 0.4094 ,\n",
       "            0.4019 , 0.3982 , 0.3923 , 0.392  , 0.3914 , 0.389  , 0.3867 ,\n",
       "            0.384  , 0.381  , 0.3792 , 0.3767 , 0.3735 , 0.3684 , 0.3674 ,\n",
       "            0.3643 , 0.3599 , 0.3594 , 0.3591 , 0.3555 , 0.3525 , 0.35   ,\n",
       "            0.3489 , 0.347  , 0.3464 , 0.3438 , 0.3394 , 0.3352 , 0.3296 ,\n",
       "            0.3286 , 0.327  , 0.3242 , 0.319  , 0.3137 , 0.3096 , 0.3064 ,\n",
       "            0.3044 , 0.2998 , 0.2966 , 0.295  , 0.289  , 0.2876 , 0.2852 ,\n",
       "            0.2808 , 0.2803 , 0.279  , 0.2776 , 0.2754 , 0.274  , 0.267  ,\n",
       "            0.2666 , 0.264  , 0.2588 , 0.2573 , 0.2505 , 0.2411 , 0.2388 ,\n",
       "            0.2358 , 0.2335 , 0.233  , 0.2306 , 0.2302 , 0.229  , 0.2247 ,\n",
       "            0.2238 , 0.2195 , 0.213  , 0.2051 , 0.2029 , 0.2024 , 0.2    ,\n",
       "            0.1893 , 0.1886 , 0.1848 , 0.1813 , 0.177  , 0.1766 , 0.1748 ,\n",
       "            0.1649 , 0.15   , 0.1378 , 0.1318 , 0.11633, 0.1067 , 0.1032 ,\n",
       "            0.10126], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.265625, dtype=float32),\n",
       "    'tpr': array(0.73770493, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.25     , 0.25     , 0.25     , 0.25     , 0.25     ,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.2734375, 0.28125  , 0.28125  , 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.3828125, 0.390625 , 0.390625 ,\n",
       "            0.390625 , 0.390625 , 0.3984375, 0.3984375, 0.40625  , 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.17213115, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.47540984, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.72131145, 0.7295082 , 0.7295082 ,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.795082  , 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9556 , 0.951  , 0.95   , 0.942  , 0.931  , 0.928  ,\n",
       "            0.927  , 0.9136 , 0.9106 , 0.8965 , 0.895  , 0.8926 , 0.884  ,\n",
       "            0.883  , 0.882  , 0.8784 , 0.873  , 0.8716 , 0.8643 , 0.8633 ,\n",
       "            0.863  , 0.859  , 0.858  , 0.857  , 0.855  , 0.852  , 0.8486 ,\n",
       "            0.844  , 0.843  , 0.8423 , 0.836  , 0.8345 , 0.833  , 0.8203 ,\n",
       "            0.814  , 0.8125 , 0.8076 , 0.807  , 0.8037 , 0.7954 , 0.7915 ,\n",
       "            0.7866 , 0.786  , 0.7656 , 0.762  , 0.76   , 0.758  , 0.751  ,\n",
       "            0.749  , 0.735  , 0.7266 , 0.721  , 0.7207 , 0.7173 , 0.7134 ,\n",
       "            0.7124 , 0.704  , 0.701  , 0.699  , 0.69   , 0.6895 , 0.689  ,\n",
       "            0.6885 , 0.6733 , 0.669  , 0.6685 , 0.6533 , 0.65   , 0.6465 ,\n",
       "            0.6436 , 0.642  , 0.6416 , 0.64   , 0.639  , 0.637  , 0.6357 ,\n",
       "            0.6304 , 0.63   , 0.615  , 0.61   , 0.6074 , 0.5986 , 0.598  ,\n",
       "            0.597  , 0.596  , 0.586  , 0.5825 , 0.582  , 0.5776 , 0.576  ,\n",
       "            0.571  , 0.5703 , 0.568  , 0.567  , 0.564  , 0.557  , 0.554  ,\n",
       "            0.549  , 0.548  , 0.544  , 0.5405 , 0.539  , 0.5386 , 0.538  ,\n",
       "            0.536  , 0.5356 , 0.5337 , 0.5293 , 0.524  , 0.5176 , 0.5166 ,\n",
       "            0.51   , 0.5083 , 0.508  , 0.5073 , 0.502  , 0.4998 , 0.4978 ,\n",
       "            0.497  , 0.4949 , 0.4946 , 0.4888 , 0.487  , 0.4822 , 0.48   ,\n",
       "            0.4795 , 0.4727 , 0.471  , 0.4695 , 0.4675 , 0.4663 , 0.4658 ,\n",
       "            0.4656 , 0.4639 , 0.4604 , 0.4568 , 0.4534 , 0.4526 , 0.4524 ,\n",
       "            0.452  , 0.4514 , 0.4502 , 0.4478 , 0.447  , 0.446  , 0.4453 ,\n",
       "            0.445  , 0.4434 , 0.437  , 0.4368 , 0.429  , 0.4268 , 0.4243 ,\n",
       "            0.4194 , 0.4119 , 0.4102 , 0.408  , 0.407  , 0.4045 , 0.403  ,\n",
       "            0.3977 , 0.395  , 0.3948 , 0.3867 , 0.3857 , 0.3853 , 0.3845 ,\n",
       "            0.3823 , 0.3809 , 0.38   , 0.3765 , 0.376  , 0.3718 , 0.3708 ,\n",
       "            0.369  , 0.3667 , 0.3628 , 0.3613 , 0.3477 , 0.3457 , 0.3389 ,\n",
       "            0.3345 , 0.3335 , 0.3315 , 0.33   , 0.3296 , 0.3293 , 0.3208 ,\n",
       "            0.3186 , 0.3132 , 0.2974 , 0.297  , 0.2961 , 0.2935 , 0.293  ,\n",
       "            0.2917 , 0.2852 , 0.285  , 0.2847 , 0.284  , 0.283  , 0.2788 ,\n",
       "            0.2786 , 0.2783 , 0.2664 , 0.2583 , 0.2563 , 0.2473 , 0.2433 ,\n",
       "            0.243  , 0.2358 , 0.2328 , 0.2319 , 0.2294 , 0.2244 , 0.2234 ,\n",
       "            0.2233 , 0.2213 , 0.214  , 0.2135 , 0.2101 , 0.204  , 0.1958 ,\n",
       "            0.1934 , 0.1929 , 0.1917 , 0.1815 , 0.1783 , 0.1726 , 0.1715 ,\n",
       "            0.1686 , 0.1675 , 0.1672 , 0.1532 , 0.1381 , 0.1354 , 0.1288 ,\n",
       "            0.12494, 0.10913, 0.0995 , 0.09467, 0.093  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.296875, dtype=float32),\n",
       "    'tpr': array(0.7704918, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.15625  , 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.25     , 0.25     , 0.25     , 0.25     ,\n",
       "            0.25     , 0.2578125, 0.2578125, 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.359375 ,\n",
       "            0.359375 , 0.359375 , 0.3671875, 0.3671875, 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4296875, 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.625    , 0.625    , 0.6328125, 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.16393442,\n",
       "            0.17213115, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.44262296, 0.45081967, 0.46721312,\n",
       "            0.47540984, 0.47540984, 0.48360655, 0.4918033 , 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.965  , 0.9604 , 0.96   , 0.9526 , 0.943  , 0.94   ,\n",
       "            0.939  , 0.9277 , 0.925  , 0.911  , 0.91   , 0.908  , 0.9004 ,\n",
       "            0.9    , 0.897  , 0.894  , 0.89   , 0.8896 , 0.882  , 0.881  ,\n",
       "            0.88   , 0.877  , 0.8755 , 0.874  , 0.8735 , 0.8687 , 0.8667 ,\n",
       "            0.864  , 0.8604 , 0.8594 , 0.854  , 0.8535 , 0.853  , 0.8384 ,\n",
       "            0.833  , 0.8325 , 0.828  , 0.8276 , 0.8223 , 0.815  , 0.814  ,\n",
       "            0.8105 , 0.805  , 0.8047 , 0.784  , 0.7817 , 0.7783 , 0.775  ,\n",
       "            0.7686 , 0.753  , 0.745  , 0.741  , 0.7397 , 0.7393 , 0.738  ,\n",
       "            0.73   , 0.7266 , 0.7188 , 0.716  , 0.7153 , 0.715  , 0.7065 ,\n",
       "            0.6934 , 0.692  , 0.6904 , 0.6836 , 0.68   , 0.6743 , 0.674  ,\n",
       "            0.673  , 0.6685 , 0.6675 , 0.6655 , 0.665  , 0.6626 , 0.654  ,\n",
       "            0.653  , 0.651  , 0.649  , 0.6367 , 0.6353 , 0.634  , 0.6255 ,\n",
       "            0.625  , 0.622  , 0.6167 , 0.6123 , 0.607  , 0.6055 , 0.602  ,\n",
       "            0.6    , 0.597  , 0.5938 , 0.5933 , 0.591  , 0.586  , 0.5806 ,\n",
       "            0.5796 , 0.5757 , 0.569  , 0.567  , 0.566  , 0.565  , 0.5625 ,\n",
       "            0.561  , 0.5566 , 0.5513 , 0.549  , 0.547  , 0.5435 , 0.538  ,\n",
       "            0.5366 , 0.5337 , 0.5303 , 0.53   , 0.5283 , 0.5215 , 0.5205 ,\n",
       "            0.52   , 0.517  , 0.5156 , 0.5146 , 0.513  , 0.509  , 0.5005 ,\n",
       "            0.4995 , 0.498  , 0.4941 , 0.49   , 0.4893 , 0.4875 , 0.4849 ,\n",
       "            0.4822 , 0.4817 , 0.481  , 0.478  , 0.4749 , 0.4734 , 0.471  ,\n",
       "            0.4673 , 0.4644 , 0.464  , 0.4624 , 0.4622 , 0.4614 , 0.4597 ,\n",
       "            0.4575 , 0.4573 , 0.4568 , 0.4558 , 0.453  , 0.444  , 0.4397 ,\n",
       "            0.4355 , 0.4316 , 0.4292 , 0.429  , 0.4263 , 0.413  , 0.41   ,\n",
       "            0.4045 , 0.4019 , 0.3997 , 0.3994 , 0.3987 , 0.397  , 0.3943 ,\n",
       "            0.393  , 0.3906 , 0.3882 , 0.388  , 0.3867 , 0.362  , 0.3616 ,\n",
       "            0.3591 , 0.359  , 0.3462 , 0.3457 , 0.3447 , 0.3345 , 0.3342 ,\n",
       "            0.3289 , 0.3267 , 0.314  , 0.3125 , 0.311  , 0.31   , 0.3025 ,\n",
       "            0.2996 , 0.295  , 0.2903 , 0.2898 , 0.2869 , 0.2866 , 0.281  ,\n",
       "            0.2769 , 0.275  , 0.2747 , 0.2727 , 0.2703 , 0.252  , 0.249  ,\n",
       "            0.2483 , 0.2379 , 0.2358 , 0.2294 , 0.228  , 0.2277 , 0.2212 ,\n",
       "            0.22   , 0.2167 , 0.2158 , 0.2123 , 0.2075 , 0.205  , 0.2039 ,\n",
       "            0.1947 , 0.1863 , 0.1837 , 0.1831 , 0.1829 , 0.1731 , 0.1685 ,\n",
       "            0.1617 , 0.1614 , 0.1609 , 0.158  , 0.1577 , 0.1422 , 0.1305 ,\n",
       "            0.1279 , 0.1197 , 0.1172 , 0.10144, 0.09204, 0.0865 , 0.08496],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3203125, dtype=float32),\n",
       "    'tpr': array(0.8032787, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.25     , 0.25     , 0.25     , 0.25     ,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3046875, 0.3125   ,\n",
       "            0.3125   , 0.3203125, 0.3203125, 0.328125 , 0.3359375, 0.3359375,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3671875, 0.3671875, 0.375    , 0.3828125, 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4296875, 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.47540984, 0.47540984, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.60655737, 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.63114756, 0.647541  ,\n",
       "            0.647541  , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.72131145, 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.92622954, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.97   , 0.966  , 0.959  , 0.95   , 0.9478 , 0.9463 ,\n",
       "            0.9365 , 0.9336 , 0.9204 , 0.9194 , 0.918  , 0.9106 , 0.91   ,\n",
       "            0.907  , 0.9043 , 0.901  , 0.9004 , 0.893  , 0.8926 , 0.8906 ,\n",
       "            0.89   , 0.888  , 0.886  , 0.8853 , 0.885  , 0.8794 , 0.8784 ,\n",
       "            0.876  , 0.8716 , 0.8706 , 0.866  , 0.865  , 0.8647 , 0.8496 ,\n",
       "            0.8467 , 0.8447 , 0.8413 , 0.841  , 0.8345 , 0.83   , 0.8257 ,\n",
       "            0.8228 , 0.817  , 0.8164 , 0.796  , 0.794  , 0.792  , 0.7905 ,\n",
       "            0.79   , 0.7817 , 0.7646 , 0.7593 , 0.7573 , 0.7544 , 0.7534 ,\n",
       "            0.751  , 0.7476 , 0.741  , 0.7334 , 0.7324 , 0.732  , 0.7314 ,\n",
       "            0.718  , 0.71   , 0.705  , 0.7046 , 0.703  , 0.7    , 0.6924 ,\n",
       "            0.6895 , 0.685  , 0.684  , 0.6816 , 0.678  , 0.6685 , 0.6626 ,\n",
       "            0.6616 , 0.66   , 0.654  , 0.6504 , 0.645  , 0.6426 , 0.6387 ,\n",
       "            0.637  , 0.627  , 0.6216 , 0.6206 , 0.6157 , 0.615  , 0.6147 ,\n",
       "            0.6113 , 0.609  , 0.6064 , 0.601  , 0.599  , 0.596  , 0.5947 ,\n",
       "            0.5845 , 0.5835 , 0.583  , 0.5825 , 0.582  , 0.578  , 0.572  ,\n",
       "            0.5693 , 0.567  , 0.56   , 0.5596 , 0.5576 , 0.557  , 0.551  ,\n",
       "            0.5474 , 0.5464 , 0.546  , 0.543  , 0.5376 , 0.5337 , 0.533  ,\n",
       "            0.5293 , 0.527  , 0.525  , 0.518  , 0.517  , 0.515  , 0.512  ,\n",
       "            0.5083 , 0.5073 , 0.507  , 0.4998 , 0.499  , 0.4978 , 0.4944 ,\n",
       "            0.4922 , 0.4902 , 0.4895 , 0.489  , 0.4863 , 0.4817 , 0.481  ,\n",
       "            0.4795 , 0.478  , 0.4758 , 0.4736 , 0.4722 , 0.4692 , 0.4644 ,\n",
       "            0.4617 , 0.457  , 0.4568 , 0.4565 , 0.452  , 0.4492 , 0.446  ,\n",
       "            0.4453 , 0.4434 , 0.4285 , 0.4202 , 0.4194 , 0.418  , 0.4155 ,\n",
       "            0.4146 , 0.4128 , 0.412  , 0.4111 , 0.411  , 0.408  , 0.4043 ,\n",
       "            0.4038 , 0.402  , 0.3843 , 0.381  , 0.3706 , 0.3613 , 0.361  ,\n",
       "            0.3584 , 0.355  , 0.3467 , 0.3423 , 0.3367 , 0.3274 , 0.327  ,\n",
       "            0.326  , 0.3252 , 0.3208 , 0.3135 , 0.3086 , 0.3083 , 0.3074 ,\n",
       "            0.296  , 0.294  , 0.281  , 0.2798 , 0.277  , 0.275  , 0.2715 ,\n",
       "            0.2712 , 0.2703 , 0.2659 , 0.2573 , 0.2455 , 0.2375 , 0.2285 ,\n",
       "            0.2281 , 0.2252 , 0.2238 , 0.2235 , 0.2194 , 0.2108 , 0.2086 ,\n",
       "            0.2032 , 0.202  , 0.2012 , 0.1942 , 0.1863 , 0.1774 , 0.1752 ,\n",
       "            0.1747 , 0.1743 , 0.1658 , 0.1592 , 0.1548 , 0.1528 , 0.1504 ,\n",
       "            0.1497 , 0.149  , 0.1318 , 0.1276 , 0.1174 , 0.1118 , 0.11084,\n",
       "            0.09515, 0.0859 , 0.07947, 0.07825], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.359375, dtype=float32),\n",
       "    'tpr': array(0.8360656, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.2421875, 0.2421875, 0.25     , 0.25     ,\n",
       "            0.25     , 0.25     , 0.25     , 0.2578125, 0.2578125, 0.265625 ,\n",
       "            0.265625 , 0.2734375, 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.296875 , 0.296875 , 0.3046875, 0.3046875, 0.3125   , 0.3125   ,\n",
       "            0.3125   , 0.3203125, 0.3203125, 0.328125 , 0.3359375, 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.3671875,\n",
       "            0.3671875, 0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.47540984, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.74590164, 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9756 , 0.9717 , 0.966  , 0.9575 , 0.9556 , 0.954  ,\n",
       "            0.9453 , 0.9424 , 0.93   , 0.9297 , 0.928  , 0.9214 , 0.921  ,\n",
       "            0.918  , 0.915  , 0.912  , 0.9116 , 0.9053 , 0.905  , 0.9043 ,\n",
       "            0.903  , 0.9014 , 0.9004 , 0.8984 , 0.8975 , 0.897  , 0.891  ,\n",
       "            0.8887 , 0.8843 , 0.8833 , 0.8794 , 0.8784 , 0.878  , 0.863  ,\n",
       "            0.8604 , 0.858  , 0.8555 , 0.8545 , 0.848  , 0.8447 , 0.8394 ,\n",
       "            0.8364 , 0.8306 , 0.83   , 0.8096 , 0.808  , 0.806  , 0.804  ,\n",
       "            0.7964 , 0.7783 , 0.775  , 0.771  , 0.7695 , 0.769  , 0.7646 ,\n",
       "            0.764  , 0.763  , 0.7563 , 0.7505 , 0.7495 , 0.7476 , 0.746  ,\n",
       "            0.7305 , 0.7266 , 0.72   , 0.7183 , 0.717  , 0.7075 , 0.706  ,\n",
       "            0.704  , 0.6987 , 0.698  , 0.6963 , 0.6953 , 0.694  , 0.683  ,\n",
       "            0.675  , 0.6743 , 0.6714 , 0.669  , 0.665  , 0.664  , 0.6616 ,\n",
       "            0.6577 , 0.654  , 0.6523 , 0.6436 , 0.635  , 0.631  , 0.63   ,\n",
       "            0.629  , 0.628  , 0.6265 , 0.622  , 0.62   , 0.6143 , 0.6123 ,\n",
       "            0.609  , 0.6    , 0.5996 , 0.5977 , 0.5967 , 0.596  , 0.594  ,\n",
       "            0.5923 , 0.587  , 0.585  , 0.5796 , 0.5757 , 0.5693 , 0.569  ,\n",
       "            0.566  , 0.5654 , 0.564  , 0.5625 , 0.5605 , 0.558  , 0.555  ,\n",
       "            0.551  , 0.546  , 0.545  , 0.5405 , 0.538  , 0.5376 , 0.536  ,\n",
       "            0.534  , 0.5312 , 0.529  , 0.524  , 0.5234 , 0.5225 , 0.522  ,\n",
       "            0.5215 , 0.515  , 0.5117 , 0.5103 , 0.5024 , 0.5015 , 0.501  ,\n",
       "            0.5005 , 0.4973 , 0.4954 , 0.4917 , 0.4915 , 0.4863 , 0.4814 ,\n",
       "            0.4792 , 0.479  , 0.475  , 0.4724 , 0.4668 , 0.4658 , 0.4592 ,\n",
       "            0.4585 , 0.4583 , 0.457  , 0.4565 , 0.454  , 0.439  , 0.4333 ,\n",
       "            0.4312 , 0.4294 , 0.4292 , 0.4263 , 0.4258 , 0.422  , 0.4197 ,\n",
       "            0.4194 , 0.418  , 0.4155 , 0.415  , 0.412  , 0.4053 , 0.4038 ,\n",
       "            0.3967 , 0.382  , 0.3784 , 0.3708 , 0.3618 , 0.36   , 0.355  ,\n",
       "            0.3547 , 0.3389 , 0.3374 , 0.3357 , 0.3354 , 0.3247 , 0.3223 ,\n",
       "            0.3174 , 0.3147 , 0.3105 , 0.305  , 0.301  , 0.2986 , 0.2983 ,\n",
       "            0.2915 , 0.2766 , 0.2747 , 0.272  , 0.2717 , 0.2668 , 0.2664 ,\n",
       "            0.2632 , 0.2612 , 0.2585 , 0.2384 , 0.2268 , 0.2211 , 0.2194 ,\n",
       "            0.2181 , 0.218  , 0.2167 , 0.2158 , 0.2039 , 0.2012 , 0.2002 ,\n",
       "            0.1962 , 0.1954 , 0.194  , 0.1842 , 0.1771 , 0.1681 , 0.1665 ,\n",
       "            0.1653 , 0.1648 , 0.1577 , 0.1495 , 0.148  , 0.1433 , 0.1409 ,\n",
       "            0.1404 , 0.1393 , 0.1232 , 0.12146, 0.10724, 0.10394, 0.10376,\n",
       "            0.0883 , 0.07935, 0.0724 , 0.07135], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.390625, dtype=float32),\n",
       "    'tpr': array(0.8606557, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.234375 , 0.2421875, 0.2421875, 0.2421875,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.2578125, 0.265625 , 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.3515625, 0.3515625,\n",
       "            0.3515625, 0.359375 , 0.359375 , 0.3671875, 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.390625 , 0.390625 , 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7578125, 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.28688523, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.48360655, 0.4918033 , 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.60655737, 0.60655737, 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.7295082 , 0.73770493,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9805 , 0.977  , 0.972  , 0.9644 , 0.963  , 0.962  ,\n",
       "            0.954  , 0.9517 , 0.94   , 0.9395 , 0.939  , 0.9326 , 0.932  ,\n",
       "            0.9287 , 0.9253 , 0.9243 , 0.9233 , 0.9185 , 0.9175 , 0.917  ,\n",
       "            0.9146 , 0.913  , 0.911  , 0.9106 , 0.9087 , 0.9043 , 0.903  ,\n",
       "            0.897  , 0.896  , 0.8945 , 0.8916 , 0.876  , 0.872  , 0.8716 ,\n",
       "            0.87   , 0.863  , 0.8623 , 0.853  , 0.8516 , 0.8447 , 0.844  ,\n",
       "            0.8257 , 0.824  , 0.823  , 0.819  , 0.8125 , 0.7974 , 0.7925 ,\n",
       "            0.79   , 0.788  , 0.7866 , 0.786  , 0.7803 , 0.7783 , 0.7754 ,\n",
       "            0.7725 , 0.7715 , 0.7695 , 0.763  , 0.749  , 0.7456 , 0.7446 ,\n",
       "            0.742  , 0.7397 , 0.7344 , 0.7305 , 0.728  , 0.726  , 0.72   ,\n",
       "            0.7197 , 0.717  , 0.7163 , 0.715  , 0.703  , 0.693  , 0.692  ,\n",
       "            0.6875 , 0.687  , 0.6846 , 0.684  , 0.6826 , 0.6807 , 0.68   ,\n",
       "            0.674  , 0.6685 , 0.655  , 0.653  , 0.6494 , 0.649  , 0.6455 ,\n",
       "            0.6426 , 0.642  , 0.6406 , 0.638  , 0.637  , 0.635  , 0.6284 ,\n",
       "            0.6265 , 0.623  , 0.621  , 0.6187 , 0.617  , 0.615  , 0.6147 ,\n",
       "            0.6123 , 0.605  , 0.602  , 0.599  , 0.5967 , 0.588  , 0.5874 ,\n",
       "            0.5854 , 0.582  , 0.581  , 0.578  , 0.5767 , 0.574  , 0.5723 ,\n",
       "            0.5664 , 0.5654 , 0.5625 , 0.559  , 0.5576 , 0.556  , 0.5513 ,\n",
       "            0.548  , 0.545  , 0.544  , 0.5415 , 0.539  , 0.536  , 0.533  ,\n",
       "            0.5327 , 0.5264 , 0.5254 , 0.5244 , 0.521  , 0.52   , 0.516  ,\n",
       "            0.5146 , 0.5103 , 0.51   , 0.5083 , 0.5044 , 0.503  , 0.4988 ,\n",
       "            0.4937 , 0.4922 , 0.4844 , 0.483  , 0.4795 , 0.4792 , 0.472  ,\n",
       "            0.4717 , 0.4692 , 0.4592 , 0.4578 , 0.4575 , 0.4565 , 0.4543 ,\n",
       "            0.4512 , 0.4504 , 0.4492 , 0.4458 , 0.4397 , 0.4358 , 0.4355 ,\n",
       "            0.4343 , 0.434  , 0.429  , 0.424  , 0.4197 , 0.4084 , 0.4077 ,\n",
       "            0.3926 , 0.389  , 0.3796 , 0.374  , 0.3699 , 0.3596 , 0.3538 ,\n",
       "            0.3528 , 0.3513 , 0.34   , 0.3389 , 0.3357 , 0.3232 , 0.3167 ,\n",
       "            0.3074 , 0.3071 , 0.305  , 0.304  , 0.3018 , 0.2932 , 0.2898 ,\n",
       "            0.2812 , 0.2693 , 0.2678 , 0.267  , 0.263  , 0.2622 , 0.262  ,\n",
       "            0.2554 , 0.2505 , 0.231  , 0.2173 , 0.2152 , 0.2133 , 0.2098 ,\n",
       "            0.207  , 0.1968 , 0.1915 , 0.191  , 0.1887 , 0.1838 , 0.1738 ,\n",
       "            0.1676 , 0.1584 , 0.158  , 0.1555 , 0.1549 , 0.1494 , 0.141  ,\n",
       "            0.1395 , 0.1338 , 0.1322 , 0.1313 , 0.1279 , 0.1196 , 0.11084,\n",
       "            0.0974 , 0.09686, 0.0957 , 0.0818 , 0.0732 , 0.0656 , 0.0649 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3984375, dtype=float32),\n",
       "    'tpr': array(0.89344263, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.234375 , 0.2421875, 0.2421875,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.265625 , 0.265625 ,\n",
       "            0.265625 , 0.265625 , 0.2734375, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.2890625, 0.2890625, 0.296875 , 0.296875 , 0.3203125, 0.3203125,\n",
       "            0.3203125, 0.328125 , 0.328125 , 0.3359375, 0.34375  , 0.34375  ,\n",
       "            0.34375  , 0.34375  , 0.3515625, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.375    , 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.3984375, 0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.421875 ,\n",
       "            0.421875 , 0.421875 , 0.421875 , 0.4296875, 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5      , 0.5078125, 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.6229508 , 0.63114756, 0.63114756, 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.72131145, 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.984  , 0.981  , 0.9805 , 0.9766 , 0.969  , 0.9683 ,\n",
       "            0.9673 , 0.9604 , 0.9585 , 0.9473 , 0.947  , 0.942  , 0.9404 ,\n",
       "            0.9365 , 0.9336 , 0.932  , 0.928  , 0.9272 , 0.9263 , 0.924  ,\n",
       "            0.9224 , 0.9214 , 0.921  , 0.92   , 0.918  , 0.914  , 0.9136 ,\n",
       "            0.9106 , 0.907  , 0.9062 , 0.906  , 0.902  , 0.8887 , 0.8857 ,\n",
       "            0.8843 , 0.8833 , 0.8823 , 0.878  , 0.8735 , 0.8633 , 0.863  ,\n",
       "            0.8545 , 0.843  , 0.837  , 0.836  , 0.8345 , 0.8296 , 0.826  ,\n",
       "            0.8184 , 0.808  , 0.8076 , 0.804  , 0.802  , 0.798  , 0.7925 ,\n",
       "            0.792  , 0.7915 , 0.789  , 0.788  , 0.7773 , 0.7705 , 0.7695 ,\n",
       "            0.7676 , 0.7573 , 0.755  , 0.7534 , 0.7485 , 0.748  , 0.747  ,\n",
       "            0.741  , 0.74   , 0.737  , 0.7344 , 0.7236 , 0.7173 , 0.7134 ,\n",
       "            0.708  , 0.7075 , 0.7056 , 0.7046 , 0.702  , 0.6973 , 0.696  ,\n",
       "            0.6895 , 0.6777 , 0.6763 , 0.673  , 0.6714 , 0.6646 , 0.6636 ,\n",
       "            0.663  , 0.6553 , 0.655  , 0.651  , 0.65   , 0.6494 , 0.647  ,\n",
       "            0.6465 , 0.643  , 0.6396 , 0.632  , 0.626  , 0.621  , 0.6094 ,\n",
       "            0.6084 , 0.608  , 0.6064 , 0.601  , 0.6    , 0.5996 , 0.596  ,\n",
       "            0.595  , 0.594  , 0.59   , 0.588  , 0.5864 , 0.5835 , 0.582  ,\n",
       "            0.581  , 0.579  , 0.5776 , 0.5767 , 0.5723 , 0.571  , 0.567  ,\n",
       "            0.5635 , 0.562  , 0.558  , 0.5576 , 0.5527 , 0.5522 , 0.549  ,\n",
       "            0.5454 , 0.545  , 0.542  , 0.539  , 0.534  , 0.5337 , 0.532  ,\n",
       "            0.5303 , 0.5225 , 0.521  , 0.5117 , 0.5083 , 0.506  , 0.495  ,\n",
       "            0.4934 , 0.4878 , 0.485  , 0.4844 , 0.4824 , 0.4807 , 0.4785 ,\n",
       "            0.4746 , 0.4744 , 0.4702 , 0.4624 , 0.4607 , 0.4583 , 0.4578 ,\n",
       "            0.4534 , 0.4531 , 0.4521 , 0.4507 , 0.425  , 0.4126 , 0.4124 ,\n",
       "            0.4114 , 0.3906 , 0.3896 , 0.3782 , 0.3765 , 0.3752 , 0.3613 ,\n",
       "            0.3599 , 0.3474 , 0.3464 , 0.3328 , 0.3262 , 0.3237 , 0.3152 ,\n",
       "            0.313  , 0.3    , 0.298  , 0.2944 , 0.291  , 0.2898 , 0.285  ,\n",
       "            0.2815 , 0.2637 , 0.2617 , 0.2605 , 0.259  , 0.2517 , 0.248  ,\n",
       "            0.2428 , 0.2242 , 0.2162 , 0.2135 , 0.2103 , 0.2042 , 0.2015 ,\n",
       "            0.201  , 0.1956 , 0.1913 , 0.1891 , 0.1838 , 0.1813 , 0.1747 ,\n",
       "            0.1637 , 0.1592 , 0.1503 , 0.1497 , 0.1466 , 0.1461 , 0.1426 ,\n",
       "            0.1359 , 0.1304 , 0.1251 , 0.12445, 0.1236 , 0.11816, 0.1172 ,\n",
       "            0.10126, 0.0922 , 0.0888 , 0.0869 , 0.07666, 0.0683 , 0.05988,\n",
       "            0.05942], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3984375, dtype=float32),\n",
       "    'tpr': array(0.89344263, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.2421875, 0.25     , 0.25     , 0.2578125,\n",
       "            0.265625 , 0.265625 , 0.265625 , 0.265625 , 0.265625 , 0.2734375,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.34375  , 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.375    ,\n",
       "            0.375    , 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.4140625, 0.421875 , 0.421875 , 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4453125, 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.7295082 , 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9854 , 0.983  , 0.9824 , 0.9785 , 0.972  , 0.9707 ,\n",
       "            0.9697 , 0.963  , 0.961  , 0.9507 , 0.95   , 0.9497 , 0.9443 ,\n",
       "            0.9434 , 0.9404 , 0.9375 , 0.9365 , 0.9355 , 0.931  , 0.93   ,\n",
       "            0.9297 , 0.9277 , 0.926  , 0.9253 , 0.9243 , 0.924  , 0.922  ,\n",
       "            0.918  , 0.9165 , 0.916  , 0.911  , 0.9097 , 0.909  , 0.906  ,\n",
       "            0.8916 , 0.89   , 0.887  , 0.8853 , 0.8794 , 0.878  , 0.8677 ,\n",
       "            0.867  , 0.859  , 0.8438 , 0.84   , 0.8394 , 0.839  , 0.8335 ,\n",
       "            0.829  , 0.816  , 0.8086 , 0.8066 , 0.805  , 0.8047 , 0.801  ,\n",
       "            0.7954 , 0.7925 , 0.791  , 0.79   , 0.7886 , 0.7793 , 0.7676 ,\n",
       "            0.7666 , 0.7637 , 0.758  , 0.757  , 0.7495 , 0.7485 , 0.747  ,\n",
       "            0.744  , 0.7373 , 0.737  , 0.7334 , 0.7324 , 0.7207 , 0.7124 ,\n",
       "            0.71   , 0.7065 , 0.704  , 0.701  , 0.7    , 0.6978 , 0.693  ,\n",
       "            0.692  , 0.691  , 0.6733 , 0.6714 , 0.669  , 0.666  , 0.661  ,\n",
       "            0.6597 , 0.6587 , 0.658  , 0.652  , 0.6504 , 0.65   , 0.6455 ,\n",
       "            0.644  , 0.6426 , 0.6387 , 0.6353 , 0.63   , 0.629  , 0.627  ,\n",
       "            0.621  , 0.616  , 0.6055 , 0.6045 , 0.6035 , 0.602  , 0.598  ,\n",
       "            0.597  , 0.595  , 0.5923 , 0.591  , 0.5903 , 0.586  , 0.5854 ,\n",
       "            0.582  , 0.5815 , 0.5776 , 0.5767 , 0.5757 , 0.5747 , 0.5723 ,\n",
       "            0.57   , 0.569  , 0.5674 , 0.566  , 0.565  , 0.5586 , 0.557  ,\n",
       "            0.5537 , 0.55   , 0.549  , 0.546  , 0.541  , 0.5405 , 0.5386 ,\n",
       "            0.536  , 0.532  , 0.529  , 0.5283 , 0.528  , 0.5205 , 0.518  ,\n",
       "            0.516  , 0.51   , 0.503  , 0.4897 , 0.4893 , 0.486  , 0.4836 ,\n",
       "            0.4812 , 0.479  , 0.4773 , 0.4717 , 0.4714 , 0.4712 , 0.4673 ,\n",
       "            0.459  , 0.458  , 0.4573 , 0.455  , 0.4512 , 0.4495 , 0.4492 ,\n",
       "            0.447  , 0.4177 , 0.4104 , 0.4082 , 0.4053 , 0.405  , 0.3872 ,\n",
       "            0.377  , 0.3735 , 0.367  , 0.3596 , 0.3508 , 0.3396 , 0.3374 ,\n",
       "            0.3232 , 0.3225 , 0.3152 , 0.3123 , 0.3093 , 0.2915 , 0.288  ,\n",
       "            0.2864 , 0.2856 , 0.2832 , 0.2803 , 0.2756 , 0.2546 , 0.252  ,\n",
       "            0.2502 , 0.2411 , 0.2383 , 0.2332 , 0.2148 , 0.209  , 0.207  ,\n",
       "            0.2026 , 0.1956 , 0.1924 , 0.1907 , 0.1849 , 0.183  , 0.182  ,\n",
       "            0.1758 , 0.1744 , 0.1711 , 0.1648 , 0.1538 , 0.1501 , 0.1415 ,\n",
       "            0.1405 , 0.1373 , 0.1368 , 0.1342 , 0.1285 , 0.12146, 0.1166 ,\n",
       "            0.11615, 0.11536, 0.11316, 0.1082 , 0.093  , 0.0859 , 0.082  ,\n",
       "            0.0799 , 0.0709 , 0.0629 , 0.0545 , 0.0542 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.421875, dtype=float32),\n",
       "    'tpr': array(0.92622954, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.25     , 0.25     , 0.2578125,\n",
       "            0.265625 , 0.265625 , 0.265625 , 0.265625 , 0.265625 , 0.265625 ,\n",
       "            0.2734375, 0.2890625, 0.296875 , 0.296875 , 0.296875 , 0.296875 ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.34375  ,\n",
       "            0.34375  , 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.3671875,\n",
       "            0.3671875, 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.3984375, 0.3984375, 0.3984375, 0.40625  , 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.48360655, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.7295082 , 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.989  , 0.987  , 0.9863 , 0.983  , 0.9775 , 0.9766 ,\n",
       "            0.9756 , 0.97   , 0.9683 , 0.959  , 0.9585 , 0.954  , 0.953  ,\n",
       "            0.9497 , 0.9473 , 0.946  , 0.9424 , 0.9414 , 0.9404 , 0.9385 ,\n",
       "            0.9375 , 0.9365 , 0.936  , 0.935  , 0.9336 , 0.93   , 0.9297 ,\n",
       "            0.9277 , 0.924  , 0.9233 , 0.9224 , 0.9194 , 0.907  , 0.9043 ,\n",
       "            0.9033 , 0.902  , 0.9014 , 0.897  , 0.893  , 0.8833 , 0.883  ,\n",
       "            0.875  , 0.8643 , 0.8584 , 0.857  , 0.8555 , 0.8506 , 0.8477 ,\n",
       "            0.8403 , 0.831  , 0.829  , 0.8267 , 0.824  , 0.8193 , 0.815  ,\n",
       "            0.814  , 0.812  , 0.8105 , 0.8003 , 0.794  , 0.7925 , 0.791  ,\n",
       "            0.781  , 0.777  , 0.776  , 0.7725 , 0.77   , 0.7695 , 0.763  ,\n",
       "            0.7617 , 0.7593 , 0.7583 , 0.7466 , 0.74   , 0.7393 , 0.7344 ,\n",
       "            0.7295 , 0.728  , 0.7266 , 0.7256 , 0.7217 , 0.718  , 0.7173 ,\n",
       "            0.7104 , 0.701  , 0.6978 , 0.697  , 0.6924 , 0.6914 , 0.6885 ,\n",
       "            0.686  , 0.6855 , 0.684  , 0.683  , 0.6772 , 0.676  , 0.675  ,\n",
       "            0.672  , 0.669  , 0.667  , 0.6665 , 0.664  , 0.6626 , 0.6616 ,\n",
       "            0.653  , 0.647  , 0.6426 , 0.635  , 0.6333 , 0.6304 , 0.63   ,\n",
       "            0.623  , 0.622  , 0.6206 , 0.6187 , 0.616  , 0.6157 , 0.613  ,\n",
       "            0.612  , 0.61   , 0.6035 , 0.6006 , 0.6    , 0.599  , 0.598  ,\n",
       "            0.5977 , 0.5923 , 0.582  , 0.5815 , 0.581  , 0.579  , 0.578  ,\n",
       "            0.5693 , 0.5684 , 0.5654 , 0.565  , 0.563  , 0.554  , 0.5537 ,\n",
       "            0.5522 , 0.543  , 0.5415 , 0.5356 , 0.532  , 0.524  , 0.519  ,\n",
       "            0.5176 , 0.5156 , 0.514  , 0.5073 , 0.504  , 0.5005 , 0.5    ,\n",
       "            0.499  , 0.495  , 0.4941 , 0.4863 , 0.4858 , 0.4849 , 0.4812 ,\n",
       "            0.4795 , 0.473  , 0.4724 , 0.4717 , 0.4602 , 0.4546 , 0.437  ,\n",
       "            0.431  , 0.4294 , 0.4165 , 0.4155 , 0.41   , 0.408  , 0.4045 ,\n",
       "            0.3992 , 0.3853 , 0.3726 , 0.357  , 0.3496 , 0.341  , 0.3352 ,\n",
       "            0.327  , 0.3252 , 0.32   , 0.295  , 0.294  , 0.287  , 0.286  ,\n",
       "            0.2837 , 0.275  , 0.255  , 0.253  , 0.251  , 0.2375 , 0.2363 ,\n",
       "            0.2311 , 0.2128 , 0.2096 , 0.2084 , 0.2018 , 0.1934 , 0.1866 ,\n",
       "            0.1863 , 0.1812 , 0.1804 , 0.1792 , 0.1733 , 0.1704 , 0.1659 ,\n",
       "            0.1597 , 0.1482 , 0.1453 , 0.1368 , 0.1351 , 0.1318 , 0.1313 ,\n",
       "            0.1298 , 0.12476, 0.1158 , 0.1118 , 0.111  , 0.1101 , 0.10144,\n",
       "            0.0866 , 0.0818 , 0.0771 , 0.07385, 0.06696, 0.059  , 0.05032,\n",
       "            0.05014], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.4609375, dtype=float32),\n",
       "    'tpr': array(0.94262296, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.2421875,\n",
       "            0.25     , 0.25     , 0.25     , 0.2578125, 0.2734375, 0.2734375,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.2734375, 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.34375  ,\n",
       "            0.34375  , 0.3515625, 0.3515625, 0.359375 , 0.359375 , 0.359375 ,\n",
       "            0.3671875, 0.3671875, 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.390625 , 0.3984375, 0.3984375, 0.40625  , 0.40625  , 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6639344 , 0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8032787 , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.991  , 0.9893 , 0.989  , 0.9863 , 0.9814 , 0.9805 ,\n",
       "            0.98   , 0.975  , 0.9736 , 0.9653 , 0.965  , 0.9614 , 0.96   ,\n",
       "            0.957  , 0.955  , 0.9536 , 0.953  , 0.9507 , 0.9497 , 0.9487 ,\n",
       "            0.947  , 0.946  , 0.9453 , 0.944  , 0.9434 , 0.942  , 0.9395 ,\n",
       "            0.9355 , 0.934  , 0.933  , 0.931  , 0.929  , 0.9287 , 0.919  ,\n",
       "            0.915  , 0.914  , 0.913  , 0.9097 , 0.9043 , 0.8955 , 0.8936 ,\n",
       "            0.886  , 0.88   , 0.873  , 0.8706 , 0.8677 , 0.8633 , 0.8623 ,\n",
       "            0.861  , 0.85   , 0.8496 , 0.8438 , 0.8364 , 0.835  , 0.834  ,\n",
       "            0.833  , 0.8325 , 0.831  , 0.8276 , 0.823  , 0.8174 , 0.8164 ,\n",
       "            0.815  , 0.8135 , 0.8003 , 0.799  , 0.7935 , 0.7915 , 0.7905 ,\n",
       "            0.7866 , 0.785  , 0.783  , 0.7817 , 0.7803 , 0.78   , 0.7686 ,\n",
       "            0.7656 , 0.765  , 0.7617 , 0.753  , 0.7495 , 0.749  , 0.7485 ,\n",
       "            0.747  , 0.741  , 0.7314 , 0.727  , 0.7227 , 0.721  , 0.719  ,\n",
       "            0.717  , 0.716  , 0.7124 , 0.7104 , 0.709  , 0.7075 , 0.7026 ,\n",
       "            0.701  , 0.6997 , 0.6987 , 0.696  , 0.694  , 0.692  , 0.691  ,\n",
       "            0.6875 , 0.6826 , 0.676  , 0.671  , 0.67   , 0.6675 , 0.66   ,\n",
       "            0.6567 , 0.6533 , 0.653  , 0.651  , 0.65   , 0.649  , 0.6475 ,\n",
       "            0.647  , 0.646  , 0.6396 , 0.639  , 0.6313 , 0.63   , 0.6284 ,\n",
       "            0.627  , 0.6265 , 0.624  , 0.621  , 0.6177 , 0.6157 , 0.6123 ,\n",
       "            0.61   , 0.6094 , 0.609  , 0.606  , 0.603  , 0.6016 , 0.6    ,\n",
       "            0.5996 , 0.598  , 0.597  , 0.595  , 0.5894 , 0.588  , 0.579  ,\n",
       "            0.575  , 0.5737 , 0.5664 , 0.5615 , 0.5537 , 0.553  , 0.5522 ,\n",
       "            0.5513 , 0.5444 , 0.539  , 0.5327 , 0.5312 , 0.5293 , 0.5273 ,\n",
       "            0.5244 , 0.5234 , 0.5215 , 0.516  , 0.5117 , 0.5083 , 0.4983 ,\n",
       "            0.4976 , 0.497  , 0.496  , 0.482  , 0.4653 , 0.4644 , 0.4573 ,\n",
       "            0.4553 , 0.4407 , 0.4348 , 0.4343 , 0.4302 , 0.4272 , 0.427  ,\n",
       "            0.4253 , 0.4133 , 0.3752 , 0.3623 , 0.3608 , 0.3496 , 0.3423 ,\n",
       "            0.3403 , 0.3333 , 0.329  , 0.3252 , 0.3123 , 0.3074 , 0.2969 ,\n",
       "            0.2922 , 0.2805 , 0.2766 , 0.2715 , 0.2556 , 0.2546 , 0.2524 ,\n",
       "            0.2494 , 0.2334 , 0.2318 , 0.2278 , 0.2118 , 0.2103 , 0.2024 ,\n",
       "            0.1915 , 0.1819 , 0.1814 , 0.1783 , 0.1782 , 0.1724 , 0.1719 ,\n",
       "            0.1664 , 0.1602 , 0.154  , 0.142  , 0.1406 , 0.1324 , 0.1299 ,\n",
       "            0.1265 , 0.126  , 0.12213, 0.1126 , 0.1101 , 0.1063 , 0.10596,\n",
       "            0.1054 , 0.09436, 0.0804 , 0.0788 , 0.07275, 0.06744, 0.06384,\n",
       "            0.05603, 0.0469 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.4765625, dtype=float32),\n",
       "    'tpr': array(0.9590164, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.2421875,\n",
       "            0.25     , 0.2578125, 0.2578125, 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.2734375, 0.2734375, 0.28125  , 0.28125  , 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.328125 , 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.390625 , 0.3984375, 0.3984375,\n",
       "            0.40625  , 0.40625  , 0.421875 , 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45081967, 0.46721312, 0.47540984,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6639344 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.73770493, 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9927 , 0.991  , 0.989  , 0.985  , 0.984  , 0.9834 ,\n",
       "            0.979  , 0.978  , 0.9707 , 0.97   , 0.967  , 0.966  , 0.963  ,\n",
       "            0.9614 , 0.961  , 0.9595 , 0.9575 , 0.9565 , 0.9556 , 0.9536 ,\n",
       "            0.9526 , 0.951  , 0.9507 , 0.949  , 0.9473 , 0.9443 , 0.942  ,\n",
       "            0.9414 , 0.9395 , 0.9375 , 0.928  , 0.925  , 0.924  , 0.923  ,\n",
       "            0.9224 , 0.919  , 0.9146 , 0.9062 , 0.905  , 0.8975 , 0.8906 ,\n",
       "            0.885  , 0.8823 , 0.88   , 0.8755 , 0.8745 , 0.872  , 0.862  ,\n",
       "            0.8613 , 0.857  , 0.8496 , 0.8477 , 0.846  , 0.8457 , 0.8438 ,\n",
       "            0.841  , 0.8374 , 0.8296 , 0.827  , 0.8267 , 0.815  , 0.811  ,\n",
       "            0.8066 , 0.805  , 0.8047 , 0.8003 , 0.7974 , 0.796  , 0.795  ,\n",
       "            0.794  , 0.7925 , 0.7827 , 0.7793 , 0.7783 , 0.7754 , 0.766  ,\n",
       "            0.763  , 0.7617 , 0.7544 , 0.7456 , 0.74   , 0.738  , 0.736  ,\n",
       "            0.734  , 0.7295 , 0.727  , 0.724  , 0.7236 , 0.7227 , 0.72   ,\n",
       "            0.7183 , 0.717  , 0.7134 , 0.7114 , 0.7085 , 0.707  , 0.704  ,\n",
       "            0.7007 , 0.697  , 0.6875 , 0.687  , 0.6836 , 0.68   , 0.674  ,\n",
       "            0.6704 , 0.6675 , 0.6665 , 0.6655 , 0.665  , 0.664  , 0.661  ,\n",
       "            0.66   , 0.658  , 0.6523 , 0.6475 , 0.6436 , 0.643  , 0.6426 ,\n",
       "            0.6406 , 0.639  , 0.636  , 0.6333 , 0.6313 , 0.6284 , 0.6274 ,\n",
       "            0.6255 , 0.624  , 0.623  , 0.618  , 0.6157 , 0.6147 , 0.6143 ,\n",
       "            0.614  , 0.609  , 0.6045 , 0.601  , 0.592  , 0.59   , 0.588  ,\n",
       "            0.5786 , 0.5767 , 0.57   , 0.569  , 0.565  , 0.5557 , 0.552  ,\n",
       "            0.545  , 0.544  , 0.5415 , 0.5376 , 0.534  , 0.533  , 0.531  ,\n",
       "            0.525  , 0.5215 , 0.5103 , 0.509  , 0.5083 , 0.507  , 0.49   ,\n",
       "            0.4795 , 0.4707 , 0.4668 , 0.4636 , 0.4497 , 0.4475 , 0.4465 ,\n",
       "            0.4421 , 0.441  , 0.4333 , 0.4312 , 0.4272 , 0.3782 , 0.3667 ,\n",
       "            0.3645 , 0.3572 , 0.3481 , 0.3435 , 0.3398 , 0.3298 , 0.327  ,\n",
       "            0.3218 , 0.3135 , 0.2969 , 0.2937 , 0.278  , 0.2744 , 0.2698 ,\n",
       "            0.2542 , 0.2534 , 0.251  , 0.2473 , 0.2302 , 0.228  , 0.2246 ,\n",
       "            0.2118 , 0.2109 , 0.2073 , 0.2006 , 0.1882 , 0.18   , 0.1765 ,\n",
       "            0.1738 , 0.1735 , 0.1683 , 0.1669 , 0.1616 , 0.1545 , 0.1487 ,\n",
       "            0.1362 , 0.1354 , 0.1274 , 0.1245 , 0.12115, 0.121  , 0.12054,\n",
       "            0.11816, 0.11066, 0.1047 , 0.10126, 0.1007 , 0.10016, 0.0887 ,\n",
       "            0.075  , 0.0749 , 0.0683 , 0.0627 , 0.0601 , 0.05252, 0.04337],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.484375, dtype=float32),\n",
       "    'tpr': array(0.9590164, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.2421875, 0.2421875,\n",
       "            0.2421875, 0.25     , 0.265625 , 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.296875 , 0.3203125, 0.3203125, 0.3203125, 0.328125 , 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.34375  , 0.3515625, 0.359375 , 0.359375 ,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.375    , 0.375    ,\n",
       "            0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.40983605, 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.46721312, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.59016395, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6721311 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.74590164, 0.74590164,\n",
       "            0.74590164, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9946 , 0.993  , 0.991  , 0.988  , 0.987  , 0.9863 ,\n",
       "            0.983  , 0.982  , 0.9756 , 0.975  , 0.972  , 0.9717 , 0.9688 ,\n",
       "            0.968  , 0.9663 , 0.966  , 0.964  , 0.9634 , 0.9624 , 0.9604 ,\n",
       "            0.96   , 0.9595 , 0.958  , 0.9565 , 0.955  , 0.9546 , 0.9517 ,\n",
       "            0.951  , 0.9497 , 0.9478 , 0.9463 , 0.9385 , 0.935  , 0.9336 ,\n",
       "            0.933  , 0.9326 , 0.93   , 0.9253 , 0.9175 , 0.916  , 0.909  ,\n",
       "            0.9043 , 0.898  , 0.8955 , 0.892  , 0.89   , 0.888  , 0.8804 ,\n",
       "            0.8774 , 0.8726 , 0.865  , 0.8643 , 0.863  , 0.8613 , 0.8604 ,\n",
       "            0.8555 , 0.852  , 0.851  , 0.8496 , 0.8457 , 0.8335 , 0.833  ,\n",
       "            0.826  , 0.825  , 0.82   , 0.8174 , 0.817  , 0.816  , 0.814  ,\n",
       "            0.8057 , 0.8037 , 0.803  , 0.8027 , 0.7915 , 0.79   , 0.7847 ,\n",
       "            0.782  , 0.7783 , 0.767  , 0.7627 , 0.762  , 0.7617 , 0.7583 ,\n",
       "            0.7573 , 0.757  , 0.756  , 0.7554 , 0.7524 , 0.752  , 0.7495 ,\n",
       "            0.7456 , 0.744  , 0.742  , 0.7383 , 0.737  , 0.735  , 0.734  ,\n",
       "            0.7324 , 0.7275 , 0.7217 , 0.7124 , 0.7114 , 0.7095 , 0.707  ,\n",
       "            0.705  , 0.7026 , 0.7    , 0.699  , 0.691  , 0.69   , 0.6875 ,\n",
       "            0.6836 , 0.681  , 0.68   , 0.678  , 0.6733 , 0.672  , 0.664  ,\n",
       "            0.662  , 0.6616 , 0.659  , 0.658  , 0.655  , 0.653  , 0.6494 ,\n",
       "            0.6484 , 0.648  , 0.6465 , 0.646  , 0.6445 , 0.6396 , 0.6387 ,\n",
       "            0.6377 , 0.6367 , 0.626  , 0.623  , 0.62   , 0.613  , 0.6074 ,\n",
       "            0.605  , 0.6045 , 0.604  , 0.5894 , 0.5854 , 0.579  , 0.578  ,\n",
       "            0.574  , 0.5737 , 0.5713 , 0.568  , 0.5615 , 0.556  , 0.553  ,\n",
       "            0.55   , 0.538  , 0.534  , 0.533  , 0.522  , 0.5093 , 0.494  ,\n",
       "            0.4917 , 0.4805 , 0.4768 , 0.4722 , 0.47   , 0.4675 , 0.4656 ,\n",
       "            0.461  , 0.456  , 0.4463 , 0.443  , 0.382  , 0.3796 , 0.372  ,\n",
       "            0.3716 , 0.3635 , 0.3533 , 0.346  , 0.3386 , 0.334  , 0.333  ,\n",
       "            0.326  , 0.3    , 0.2996 , 0.273  , 0.2676 , 0.2656 , 0.2556 ,\n",
       "            0.2551 , 0.2527 , 0.2458 , 0.2274 , 0.2227 , 0.2216 , 0.215  ,\n",
       "            0.2129 , 0.2047 , 0.2012 , 0.1864 , 0.1804 , 0.1718 , 0.1708 ,\n",
       "            0.1659 , 0.1653 , 0.1602 , 0.1575 , 0.1488 , 0.1432 , 0.1306 ,\n",
       "            0.1301 , 0.1229 , 0.1195 , 0.1172 , 0.11554, 0.11536, 0.1152 ,\n",
       "            0.1105 , 0.0991 , 0.09656, 0.0957 , 0.09534, 0.0823 , 0.0717 ,\n",
       "            0.0689 , 0.06396, 0.05698, 0.05685, 0.0494 , 0.0401 , 0.04   ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.97540987, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.1640625,\n",
       "            0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.2421875, 0.2421875, 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.2734375, 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3125   , 0.3203125, 0.3203125,\n",
       "            0.3359375, 0.34375  , 0.34375  , 0.34375  , 0.3515625, 0.3515625,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.375    , 0.375    ,\n",
       "            0.3828125, 0.3828125, 0.3828125, 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.40983605, 0.4262295 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59836066, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6967213 , 0.71311474, 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.74590164, 0.74590164, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9956 , 0.9946 , 0.9927 , 0.9897 , 0.9893 , 0.989  ,\n",
       "            0.986  , 0.985  , 0.979  , 0.976  , 0.9756 , 0.9736 , 0.972  ,\n",
       "            0.9717 , 0.9707 , 0.969  , 0.9683 , 0.9673 , 0.966  , 0.9653 ,\n",
       "            0.964  , 0.9634 , 0.9624 , 0.961  , 0.958  , 0.9575 , 0.956  ,\n",
       "            0.9546 , 0.953  , 0.946  , 0.9434 , 0.9414 , 0.941  , 0.9385 ,\n",
       "            0.9336 , 0.927  , 0.9253 , 0.919  , 0.9146 , 0.9087 , 0.906  ,\n",
       "            0.9033 , 0.903  , 0.8994 , 0.894  , 0.8896 , 0.8853 , 0.879  ,\n",
       "            0.878  , 0.8765 , 0.875  , 0.8745 , 0.8726 , 0.868  , 0.866  ,\n",
       "            0.864  , 0.8604 , 0.8594 , 0.8496 , 0.8486 , 0.842  , 0.841  ,\n",
       "            0.8364 , 0.834  , 0.832  , 0.8315 , 0.8306 , 0.8296 , 0.825  ,\n",
       "            0.823  , 0.8228 , 0.82   , 0.811  , 0.8105 , 0.8022 , 0.8    ,\n",
       "            0.799  , 0.7974 , 0.788  , 0.786  , 0.7837 , 0.7812 , 0.7803 ,\n",
       "            0.78   , 0.7783 , 0.777  , 0.7754 , 0.7705 , 0.769  , 0.7656 ,\n",
       "            0.7637 , 0.763  , 0.758  , 0.757  , 0.7554 , 0.755  , 0.751  ,\n",
       "            0.7495 , 0.7383 , 0.731  , 0.7295 , 0.7285 , 0.728  , 0.727  ,\n",
       "            0.7266 , 0.7236 , 0.715  , 0.712  , 0.711  , 0.7104 , 0.71   ,\n",
       "            0.7056 , 0.705  , 0.7007 , 0.7    , 0.698  , 0.697  , 0.688  ,\n",
       "            0.6875 , 0.686  , 0.684  , 0.6836 , 0.6826 , 0.681  , 0.6797 ,\n",
       "            0.6787 , 0.6777 , 0.675  , 0.6704 , 0.6675 , 0.6636 , 0.6626 ,\n",
       "            0.662  , 0.657  , 0.654  , 0.6484 , 0.645  , 0.6387 , 0.638  ,\n",
       "            0.6377 , 0.6367 , 0.635  , 0.6284 , 0.6274 , 0.6055 , 0.6045 ,\n",
       "            0.604  , 0.6016 , 0.6    , 0.597  , 0.592  , 0.5815 , 0.579  ,\n",
       "            0.578  , 0.5723 , 0.5654 , 0.5586 , 0.5576 , 0.54   , 0.5366 ,\n",
       "            0.518  , 0.5137 , 0.502  , 0.5015 , 0.5    , 0.4917 , 0.488  ,\n",
       "            0.485  , 0.4758 , 0.4749 , 0.4604 , 0.4565 , 0.395  , 0.3906 ,\n",
       "            0.3882 , 0.3838 , 0.3804 , 0.3708 , 0.362  , 0.3503 , 0.3435 ,\n",
       "            0.343  , 0.3384 , 0.3083 , 0.3062 , 0.2715 , 0.2654 , 0.2644 ,\n",
       "            0.2603 , 0.2588 , 0.2568 , 0.2467 , 0.2272 , 0.2216 , 0.2208 ,\n",
       "            0.2205 , 0.2179 , 0.2051 , 0.2043 , 0.1869 , 0.1836 , 0.17   ,\n",
       "            0.169  , 0.166  , 0.1605 , 0.1558 , 0.145  , 0.1396 , 0.1277 ,\n",
       "            0.1259 , 0.12036, 0.11633, 0.115  , 0.1144 , 0.1126 , 0.1118 ,\n",
       "            0.11145, 0.09503, 0.0935 , 0.0922 , 0.0775 , 0.0698 , 0.0645 ,\n",
       "            0.0611 , 0.0548 , 0.05292, 0.04733, 0.0378 , 0.0376 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5078125, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.1484375, 0.15625  , 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.25     , 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.3203125, 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.34375  , 0.34375  , 0.34375  , 0.3515625, 0.3515625, 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.3671875, 0.375    , 0.3828125, 0.3828125,\n",
       "            0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09836066, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18852459,\n",
       "            0.19672132, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9966 , 0.9956 , 0.994  , 0.9917 , 0.991  , 0.9907 ,\n",
       "            0.9883 , 0.9873 , 0.9824 , 0.982  , 0.9795 , 0.977  , 0.976  ,\n",
       "            0.975  , 0.9746 , 0.973  , 0.9727 , 0.9717 , 0.97   , 0.9697 ,\n",
       "            0.9683 , 0.967  , 0.9663 , 0.966  , 0.963  , 0.9624 , 0.9614 ,\n",
       "            0.96   , 0.959  , 0.9585 , 0.9526 , 0.9497 , 0.9478 , 0.9473 ,\n",
       "            0.947  , 0.946  , 0.9404 , 0.9336 , 0.932  , 0.9263 , 0.924  ,\n",
       "            0.9175 , 0.9146 , 0.911  , 0.908  , 0.9062 , 0.9004 , 0.896  ,\n",
       "            0.891  , 0.89   , 0.887  , 0.8867 , 0.8833 , 0.8823 , 0.882  ,\n",
       "            0.881  , 0.8774 , 0.8735 , 0.873  , 0.8696 , 0.8643 , 0.861  ,\n",
       "            0.8555 , 0.855  , 0.8506 , 0.8486 , 0.8467 , 0.8457 , 0.844  ,\n",
       "            0.843  , 0.8423 , 0.841  , 0.839  , 0.8345 , 0.829  , 0.827  ,\n",
       "            0.8174 , 0.814  , 0.8135 , 0.812  , 0.8057 , 0.8047 , 0.8027 ,\n",
       "            0.802  , 0.8013 , 0.801  , 0.798  , 0.795  , 0.792  , 0.788  ,\n",
       "            0.7876 , 0.787  , 0.7847 , 0.784  , 0.782  , 0.7783 , 0.776  ,\n",
       "            0.7744 , 0.7734 , 0.7725 , 0.7715 , 0.767  , 0.764  , 0.7534 ,\n",
       "            0.753  , 0.7495 , 0.748  , 0.7466 , 0.7456 , 0.7427 , 0.7383 ,\n",
       "            0.734  , 0.7334 , 0.7295 , 0.729  , 0.728  , 0.7246 , 0.722  ,\n",
       "            0.7217 , 0.719  , 0.7183 , 0.716  , 0.7104 , 0.706  , 0.7046 ,\n",
       "            0.703  , 0.7026 , 0.701  , 0.7007 , 0.699  , 0.6987 , 0.697  ,\n",
       "            0.695  , 0.693  , 0.6855 , 0.6836 , 0.679  , 0.6777 , 0.674  ,\n",
       "            0.6724 , 0.6655 , 0.665  , 0.6646 , 0.663  , 0.659  , 0.657  ,\n",
       "            0.6514 , 0.647  , 0.6265 , 0.624  , 0.6226 , 0.622  , 0.6196 ,\n",
       "            0.6187 , 0.6147 , 0.602  , 0.5996 , 0.5947 , 0.5854 , 0.5845 ,\n",
       "            0.5767 , 0.5757 , 0.5635 , 0.5454 , 0.539  , 0.5366 , 0.525  ,\n",
       "            0.5205 , 0.5117 , 0.509  , 0.5015 , 0.4863 , 0.483  , 0.4744 ,\n",
       "            0.467  , 0.4622 , 0.402  , 0.4    , 0.393  , 0.3875 , 0.3813 ,\n",
       "            0.3782 , 0.376  , 0.3499 , 0.3484 , 0.345  , 0.3367 , 0.309  ,\n",
       "            0.3054 , 0.2634 , 0.258  , 0.2573 , 0.256  , 0.2544 , 0.2421 ,\n",
       "            0.2216 , 0.2213 , 0.2162 , 0.2144 , 0.2125 , 0.2015 , 0.2002 ,\n",
       "            0.1824 , 0.181  , 0.1648 , 0.1622 , 0.1614 , 0.1514 , 0.1498 ,\n",
       "            0.1477 , 0.138  , 0.1328 , 0.1217 , 0.1186 , 0.11475, 0.11084,\n",
       "            0.1103 , 0.1099 , 0.1097 , 0.1056 , 0.1052 , 0.089  , 0.088  ,\n",
       "            0.0868 , 0.0866 , 0.0709 , 0.0661 , 0.05878, 0.05664, 0.05127,\n",
       "            0.04752, 0.0441 , 0.0347 , 0.0345 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5078125, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.28125  , 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.2890625, 0.296875 , 0.296875 , 0.3046875, 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.3359375, 0.34375  ,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.3671875, 0.375    , 0.3828125, 0.3828125, 0.390625 ,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5      , 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.19672132, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6639344 , 0.6639344 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.997  , 0.9966 , 0.996  , 0.995  , 0.9927 , 0.992  ,\n",
       "            0.99   , 0.9893 , 0.985  , 0.9844 , 0.9824 , 0.982  , 0.98   ,\n",
       "            0.979  , 0.978  , 0.9766 , 0.976  , 0.975  , 0.974  , 0.9736 ,\n",
       "            0.9717 , 0.9707 , 0.97   , 0.9697 , 0.967  , 0.966  , 0.9644 ,\n",
       "            0.9634 , 0.963  , 0.958  , 0.9556 , 0.9536 , 0.9526 , 0.947  ,\n",
       "            0.9404 , 0.9385 , 0.933  , 0.932  , 0.926  , 0.9253 , 0.9224 ,\n",
       "            0.919  , 0.918  , 0.9165 , 0.9155 , 0.91   , 0.9062 , 0.903  ,\n",
       "            0.9014 , 0.898  , 0.896  , 0.8945 , 0.8916 , 0.891  , 0.8867 ,\n",
       "            0.886  , 0.882  , 0.8804 , 0.8784 , 0.873  , 0.8687 , 0.865  ,\n",
       "            0.8633 , 0.861  , 0.8604 , 0.8584 , 0.8574 , 0.8564 , 0.855  ,\n",
       "            0.8545 , 0.854  , 0.849  , 0.846  , 0.8438 , 0.8335 , 0.83   ,\n",
       "            0.8286 , 0.8257 , 0.8237 , 0.823  , 0.8223 , 0.82   , 0.819  ,\n",
       "            0.8164 , 0.8115 , 0.809  , 0.8066 , 0.8047 , 0.803  , 0.7993 ,\n",
       "            0.799  , 0.7974 , 0.7954 , 0.7944 , 0.7935 , 0.7905 , 0.7896 ,\n",
       "            0.789  , 0.785  , 0.781  , 0.7773 , 0.776  , 0.772  , 0.766  ,\n",
       "            0.7656 , 0.765  , 0.7637 , 0.7627 , 0.7563 , 0.7544 , 0.75   ,\n",
       "            0.7495 , 0.747  , 0.7456 , 0.7446 , 0.743  , 0.741  , 0.74   ,\n",
       "            0.7373 , 0.7363 , 0.734  , 0.7334 , 0.7314 , 0.7275 , 0.727  ,\n",
       "            0.7246 , 0.723  , 0.7217 , 0.7207 , 0.72   , 0.718  , 0.708  ,\n",
       "            0.705  , 0.703  , 0.698  , 0.693  , 0.6924 , 0.69   , 0.6895 ,\n",
       "            0.6875 , 0.687  , 0.686  , 0.685  , 0.683  , 0.67   , 0.667  ,\n",
       "            0.6514 , 0.646  , 0.6436 , 0.64   , 0.635  , 0.633  , 0.6255 ,\n",
       "            0.623  , 0.614  , 0.6084 , 0.6    , 0.598  , 0.596  , 0.5894 ,\n",
       "            0.567  , 0.558  , 0.557  , 0.552  , 0.5435 , 0.5386 , 0.53   ,\n",
       "            0.5044 , 0.4944 , 0.4917 , 0.4783 , 0.4775 , 0.4724 , 0.414  ,\n",
       "            0.4138 , 0.4067 , 0.3938 , 0.3914 , 0.39   , 0.3872 , 0.361  ,\n",
       "            0.3513 , 0.3396 , 0.3142 , 0.3093 , 0.2603 , 0.2595 , 0.2573 ,\n",
       "            0.256  , 0.2544 , 0.251  , 0.2415 , 0.2247 , 0.2198 , 0.2181 ,\n",
       "            0.2114 , 0.2085 , 0.2023 , 0.1991 , 0.1816 , 0.1804 , 0.1625 ,\n",
       "            0.1594 , 0.1588 , 0.147  , 0.1454 , 0.1428 , 0.1338 , 0.1289 ,\n",
       "            0.11816, 0.11395, 0.11145, 0.11084, 0.1076 , 0.1069 , 0.10156,\n",
       "            0.10144, 0.08496, 0.08466, 0.0833 , 0.083  , 0.06647, 0.0635 ,\n",
       "            0.0548 , 0.0537 , 0.04886, 0.04376, 0.04184, 0.03247, 0.03223],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.515625, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.109375 ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.2421875,\n",
       "            0.25     , 0.25     , 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.28125  , 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3125   , 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.359375 , 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.375    , 0.375    , 0.375    , 0.375    ,\n",
       "            0.375    , 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.484375 ,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09836066,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.19672132,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.3852459 ,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45081967, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9976 , 0.997  , 0.996  , 0.994  , 0.9937 , 0.9917 ,\n",
       "            0.9907 , 0.9873 , 0.987  , 0.985  , 0.983  , 0.982  , 0.9814 ,\n",
       "            0.981  , 0.98   , 0.9795 , 0.9785 , 0.9775 , 0.977  , 0.9756 ,\n",
       "            0.9746 , 0.974  , 0.9736 , 0.971  , 0.9707 , 0.9697 , 0.9688 ,\n",
       "            0.9683 , 0.968  , 0.9634 , 0.9614 , 0.9595 , 0.9585 , 0.958  ,\n",
       "            0.9526 , 0.9473 , 0.945  , 0.9404 , 0.94   , 0.9355 , 0.9336 ,\n",
       "            0.93   , 0.9287 , 0.927  , 0.9253 , 0.924  , 0.92   , 0.916  ,\n",
       "            0.9136 , 0.9126 , 0.9097 , 0.909  , 0.9087 , 0.908  , 0.901  ,\n",
       "            0.9004 , 0.8984 , 0.8965 , 0.8926 , 0.8916 , 0.8853 , 0.882  ,\n",
       "            0.88   , 0.8774 , 0.877  , 0.8765 , 0.8745 , 0.873  , 0.87   ,\n",
       "            0.866  , 0.8657 , 0.865  , 0.864  , 0.8623 , 0.85   , 0.849  ,\n",
       "            0.8486 , 0.8457 , 0.845  , 0.844  , 0.8433 , 0.84   , 0.8384 ,\n",
       "            0.8315 , 0.8296 , 0.829  , 0.826  , 0.8257 , 0.824  , 0.82   ,\n",
       "            0.818  , 0.8164 , 0.812  , 0.811  , 0.8105 , 0.81   , 0.8076 ,\n",
       "            0.806  , 0.8037 , 0.799  , 0.791  , 0.79   , 0.788  , 0.7876 ,\n",
       "            0.785  , 0.7847 , 0.78   , 0.7734 , 0.771  , 0.7705 , 0.7695 ,\n",
       "            0.7686 , 0.768  , 0.7637 , 0.763  , 0.7627 , 0.762  , 0.7607 ,\n",
       "            0.7583 , 0.7554 , 0.7544 , 0.7515 , 0.7495 , 0.748  , 0.7446 ,\n",
       "            0.744  , 0.7417 , 0.735  , 0.733  , 0.7305 , 0.7275 , 0.7266 ,\n",
       "            0.7256 , 0.725  , 0.7236 , 0.722  , 0.714  , 0.7134 , 0.712  ,\n",
       "            0.7095 , 0.703  , 0.6943 , 0.694  , 0.683  , 0.6772 , 0.6763 ,\n",
       "            0.6753 , 0.6743 , 0.673  , 0.657  , 0.6567 , 0.6562 , 0.6543 ,\n",
       "            0.639  , 0.6265 , 0.6245 , 0.6235 , 0.6216 , 0.604  , 0.588  ,\n",
       "            0.5874 , 0.5757 , 0.575  , 0.574  , 0.5586 , 0.5117 , 0.5103 ,\n",
       "            0.4993 , 0.495  , 0.4883 , 0.4832 , 0.437  , 0.4326 , 0.4287 ,\n",
       "            0.4207 , 0.4094 , 0.398  , 0.3977 , 0.3804 , 0.3625 , 0.3562 ,\n",
       "            0.3462 , 0.3245 , 0.3174 , 0.266  , 0.2622 , 0.2615 , 0.2573 ,\n",
       "            0.2527 , 0.2473 , 0.243  , 0.2323 , 0.224  , 0.22   , 0.2101 ,\n",
       "            0.2063 , 0.2056 , 0.2002 , 0.1855 , 0.1808 , 0.1626 , 0.1602 ,\n",
       "            0.1567 , 0.1456 , 0.1403 , 0.1388 , 0.1307 , 0.126  , 0.11597,\n",
       "            0.1134 , 0.1103 , 0.1095 , 0.1069 , 0.1052 , 0.1043 , 0.09894,\n",
       "            0.0986 , 0.0823 , 0.08167, 0.0808 , 0.0804 , 0.06256, 0.0621 ,\n",
       "            0.05145, 0.05127, 0.04724, 0.04037, 0.0403 , 0.03073, 0.03033],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.53125, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.078125 , 0.078125 , 0.078125 ,\n",
       "            0.09375  , 0.109375 , 0.1171875, 0.125    , 0.125    , 0.125    ,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2109375, 0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.25     , 0.2578125, 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.296875 , 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.375    , 0.375    , 0.375    , 0.375    , 0.3828125,\n",
       "            0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.09016393, 0.09836066,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.998  , 0.9976 , 0.9966 , 0.995  , 0.9946 , 0.993  ,\n",
       "            0.9927 , 0.9893 , 0.989  , 0.9873 , 0.9854 , 0.985  , 0.984  ,\n",
       "            0.983  , 0.9824 , 0.982  , 0.9805 , 0.979  , 0.9785 , 0.978  ,\n",
       "            0.9775 , 0.977  , 0.9756 , 0.974  , 0.9736 , 0.972  , 0.9717 ,\n",
       "            0.9683 , 0.9663 , 0.9644 , 0.9634 , 0.9624 , 0.958  , 0.953  ,\n",
       "            0.95   , 0.948  , 0.946  , 0.9453 , 0.9414 , 0.9395 , 0.9375 ,\n",
       "            0.933  , 0.931  , 0.9297 , 0.9253 , 0.925  , 0.924  , 0.9233 ,\n",
       "            0.9224 , 0.9204 , 0.9185 , 0.911  , 0.909  , 0.908  , 0.907  ,\n",
       "            0.9053 , 0.9014 , 0.899  , 0.897  , 0.896  , 0.895  , 0.894  ,\n",
       "            0.8936 , 0.892  , 0.8896 , 0.889  , 0.884  , 0.8794 , 0.879  ,\n",
       "            0.8774 , 0.874  , 0.8706 , 0.866  , 0.865  , 0.8647 , 0.8633 ,\n",
       "            0.8623 , 0.8584 , 0.858  , 0.8574 , 0.8535 , 0.851  , 0.8496 ,\n",
       "            0.8486 , 0.848  , 0.8467 , 0.846  , 0.8457 , 0.8438 , 0.838  ,\n",
       "            0.8374 , 0.837  , 0.831  , 0.829  , 0.8286 , 0.828  , 0.8276 ,\n",
       "            0.8267 , 0.8228 , 0.8223 , 0.812  , 0.8105 , 0.8096 , 0.808  ,\n",
       "            0.8076 , 0.8027 , 0.8022 , 0.798  , 0.7954 , 0.795  , 0.793  ,\n",
       "            0.7905 , 0.789  , 0.788  , 0.7876 , 0.785  , 0.783  , 0.7817 ,\n",
       "            0.781  , 0.7793 , 0.7754 , 0.775  , 0.7725 , 0.772  , 0.765  ,\n",
       "            0.763  , 0.7627 , 0.759  , 0.7583 , 0.7573 , 0.757  , 0.7534 ,\n",
       "            0.753  , 0.743  , 0.741  , 0.738  , 0.7314 , 0.7305 , 0.7173 ,\n",
       "            0.7153 , 0.712  , 0.7056 , 0.7036 , 0.702  , 0.6997 , 0.684  ,\n",
       "            0.682  , 0.677  , 0.6753 , 0.6665 , 0.6616 , 0.6543 , 0.652  ,\n",
       "            0.65   , 0.639  , 0.6377 , 0.619  , 0.6147 , 0.6074 , 0.6045 ,\n",
       "            0.588  , 0.5845 , 0.5254 , 0.5093 , 0.5083 , 0.5024 , 0.499  ,\n",
       "            0.4832 , 0.458  , 0.4487 , 0.4475 , 0.4443 , 0.427  , 0.4045 ,\n",
       "            0.4001 , 0.3975 , 0.3706 , 0.3577 , 0.3489 , 0.3318 , 0.322  ,\n",
       "            0.269  , 0.2637 , 0.2502 , 0.2463 , 0.2417 , 0.2382 , 0.2375 ,\n",
       "            0.2277 , 0.2158 , 0.2079 , 0.2056 , 0.199  , 0.1984 , 0.1871 ,\n",
       "            0.1785 , 0.1603 , 0.1587 , 0.152  , 0.1421 , 0.1321 , 0.1313 ,\n",
       "            0.1254 , 0.121  , 0.1152 , 0.1118 , 0.1058 , 0.10504, 0.1047 ,\n",
       "            0.1021 , 0.1    , 0.0945 , 0.09436, 0.0785 , 0.0771 , 0.07684,\n",
       "            0.0763 , 0.05988, 0.0572 , 0.0484 , 0.0469 , 0.045  , 0.03824,\n",
       "            0.03607, 0.02855, 0.02802], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5390625, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.125    , 0.125    ,\n",
       "            0.125    , 0.125    , 0.1328125, 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.2109375, 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.25     , 0.25     ,\n",
       "            0.25     , 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3046875, 0.3046875, 0.3046875,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.34375  , 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.3671875, 0.375    ,\n",
       "            0.375    , 0.375    , 0.375    , 0.375    , 0.3828125, 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.39344263, 0.40163934, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.44262296, 0.45901638, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.59836066, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.998  , 0.9976 , 0.996  , 0.9956 , 0.994  ,\n",
       "            0.9937 , 0.9907 , 0.99   , 0.9893 , 0.989  , 0.9873 , 0.987  ,\n",
       "            0.986  , 0.985  , 0.9844 , 0.984  , 0.983  , 0.9814 , 0.981  ,\n",
       "            0.9805 , 0.98   , 0.978  , 0.977  , 0.9766 , 0.9756 , 0.975  ,\n",
       "            0.9717 , 0.9697 , 0.9683 , 0.967  , 0.9663 , 0.9624 , 0.9575 ,\n",
       "            0.955  , 0.953  , 0.951  , 0.9507 , 0.95   , 0.947  , 0.9453 ,\n",
       "            0.9434 , 0.939  , 0.937  , 0.936  , 0.9316 , 0.9307 , 0.93   ,\n",
       "            0.927  , 0.925  , 0.9185 , 0.916  , 0.915  , 0.912  , 0.909  ,\n",
       "            0.9067 , 0.905  , 0.9043 , 0.904  , 0.9033 , 0.903  , 0.901  ,\n",
       "            0.899  , 0.8984 , 0.898  , 0.8945 , 0.892  , 0.8896 , 0.8877 ,\n",
       "            0.886  , 0.8843 , 0.882  , 0.879  , 0.877  , 0.876  , 0.8755 ,\n",
       "            0.874  , 0.87   , 0.867  , 0.8643 , 0.8633 , 0.8623 , 0.8604 ,\n",
       "            0.859  , 0.8584 , 0.8555 , 0.851  , 0.8496 , 0.849  , 0.847  ,\n",
       "            0.844  , 0.841  , 0.8403 , 0.8384 , 0.837  , 0.832  , 0.8267 ,\n",
       "            0.826  , 0.8237 , 0.822  , 0.8203 , 0.817  , 0.815  , 0.8105 ,\n",
       "            0.8096 , 0.809  , 0.8086 , 0.8076 , 0.806  , 0.805  , 0.8047 ,\n",
       "            0.803  , 0.8022 , 0.801  , 0.8003 , 0.7983 , 0.7974 , 0.7964 ,\n",
       "            0.796  , 0.7925 , 0.7886 , 0.7876 , 0.7847 , 0.7817 , 0.78   ,\n",
       "            0.7793 , 0.778  , 0.7773 , 0.774  , 0.7734 , 0.768  , 0.76   ,\n",
       "            0.758  , 0.755  , 0.753  , 0.7466 , 0.7446 , 0.7334 , 0.7314 ,\n",
       "            0.73   , 0.7285 , 0.725  , 0.7236 , 0.7227 , 0.718  , 0.7036 ,\n",
       "            0.7017 , 0.6924 , 0.6895 , 0.686  , 0.6772 , 0.6763 , 0.6694 ,\n",
       "            0.6675 , 0.662  , 0.653  , 0.6426 , 0.6343 , 0.632  , 0.6255 ,\n",
       "            0.6035 , 0.599  , 0.536  , 0.519  , 0.512  , 0.5073 , 0.5063 ,\n",
       "            0.4856 , 0.474  , 0.4648 , 0.4634 , 0.4587 , 0.4412 , 0.4111 ,\n",
       "            0.4102 , 0.4026 , 0.377  , 0.3591 , 0.3513 , 0.3374 , 0.326  ,\n",
       "            0.2712 , 0.2654 , 0.2651 , 0.2456 , 0.2426 , 0.2422 , 0.2406 ,\n",
       "            0.2319 , 0.2302 , 0.2124 , 0.2089 , 0.2018 , 0.1959 , 0.1942 ,\n",
       "            0.1884 , 0.1763 , 0.158  , 0.157  , 0.1482 , 0.139  , 0.127  ,\n",
       "            0.1255 , 0.121  , 0.11676, 0.11597, 0.1084 , 0.10284, 0.1025 ,\n",
       "            0.1    , 0.0991 , 0.0964 , 0.0909 , 0.0906 , 0.0752 , 0.07367,\n",
       "            0.0729 , 0.0576 , 0.0532 , 0.0457 , 0.04337, 0.04288, 0.0363 ,\n",
       "            0.0329 , 0.02666, 0.02606], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.546875, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.1015625, 0.1171875, 0.1171875,\n",
       "            0.125    , 0.125    , 0.125    , 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.234375 , 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.25     , 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.34375  , 0.3515625, 0.3671875, 0.3671875,\n",
       "            0.375    , 0.375    , 0.375    , 0.375    , 0.375    , 0.3828125,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.421875 , 0.4296875,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.03278688, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.09836066, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.19672132, 0.20491803, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.4180328 , 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.59016395, 0.59016395, 0.59836066, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.998  , 0.9966 , 0.996  , 0.995  , 0.9946 ,\n",
       "            0.992  , 0.9907 , 0.9893 , 0.989  , 0.9883 , 0.9873 , 0.987  ,\n",
       "            0.9863 , 0.986  , 0.9854 , 0.9844 , 0.984  , 0.9834 , 0.983  ,\n",
       "            0.9814 , 0.981  , 0.98   , 0.979  , 0.9785 , 0.9756 , 0.974  ,\n",
       "            0.9727 , 0.9717 , 0.971  , 0.9673 , 0.9634 , 0.9604 , 0.9595 ,\n",
       "            0.959  , 0.957  , 0.9565 , 0.954  , 0.9536 , 0.95   , 0.9463 ,\n",
       "            0.9443 , 0.942  , 0.9414 , 0.941  , 0.94   , 0.9395 , 0.9365 ,\n",
       "            0.934  , 0.9287 , 0.9272 , 0.9253 , 0.9243 , 0.922  , 0.9194 ,\n",
       "            0.9185 , 0.918  , 0.916  , 0.9155 , 0.915  , 0.9136 , 0.911  ,\n",
       "            0.91   , 0.905  , 0.903  , 0.901  , 0.8975 , 0.897  , 0.8945 ,\n",
       "            0.8936 , 0.892  , 0.891  , 0.8877 , 0.885  , 0.8843 , 0.884  ,\n",
       "            0.8813 , 0.881  , 0.878  , 0.877  , 0.876  , 0.8735 , 0.87   ,\n",
       "            0.8696 , 0.869  , 0.8667 , 0.866  , 0.8604 , 0.86   , 0.859  ,\n",
       "            0.853  , 0.85   , 0.8477 , 0.846  , 0.845  , 0.8423 , 0.8403 ,\n",
       "            0.839  , 0.835  , 0.8345 , 0.834  , 0.8325 , 0.8315 , 0.831  ,\n",
       "            0.83   , 0.829  , 0.8286 , 0.824  , 0.8237 , 0.823  , 0.8228 ,\n",
       "            0.8223 , 0.8213 , 0.819  , 0.818  , 0.8174 , 0.813  , 0.8125 ,\n",
       "            0.811  , 0.8086 , 0.8066 , 0.8022 , 0.801  , 0.8003 , 0.799  ,\n",
       "            0.7915 , 0.787  , 0.781  , 0.78   , 0.7715 , 0.7705 , 0.7666 ,\n",
       "            0.7603 , 0.759  , 0.754  , 0.753  , 0.752  , 0.751  , 0.747  ,\n",
       "            0.7446 , 0.733  , 0.7314 , 0.7163 , 0.716  , 0.712  , 0.7085 ,\n",
       "            0.7026 , 0.6973 , 0.6953 , 0.677  , 0.6753 , 0.667  , 0.6646 ,\n",
       "            0.657  , 0.633  , 0.619  , 0.5566 , 0.5386 , 0.5244 , 0.519  ,\n",
       "            0.5005 , 0.4973 , 0.4915 , 0.4907 , 0.4788 , 0.4626 , 0.432  ,\n",
       "            0.4236 , 0.4133 , 0.3909 , 0.3684 , 0.3608 , 0.3494 , 0.3372 ,\n",
       "            0.2786 , 0.2727 , 0.2717 , 0.2517 , 0.2473 , 0.2444 , 0.244  ,\n",
       "            0.2372 , 0.233  , 0.2139 , 0.2134 , 0.2026 , 0.1973 , 0.1947 ,\n",
       "            0.1929 , 0.1776 , 0.1588 , 0.1584 , 0.1477 , 0.1388 , 0.1255 ,\n",
       "            0.1238 , 0.1193 , 0.1188 , 0.11536, 0.10706, 0.10266, 0.10144,\n",
       "            0.09827, 0.0981 , 0.09467, 0.0891 , 0.0888 , 0.0734 , 0.07196,\n",
       "            0.0709 , 0.05655, 0.0511 , 0.044  , 0.04163, 0.04132, 0.035  ,\n",
       "            0.03108, 0.02533, 0.02466], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5703125, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.125    , 0.125    , 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.1640625, 0.171875 , 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.2421875, 0.2421875, 0.2578125,\n",
       "            0.265625 , 0.265625 , 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.296875 , 0.3046875, 0.3046875, 0.3046875, 0.3203125,\n",
       "            0.3203125, 0.34375  , 0.34375  , 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.375    , 0.375    , 0.375    , 0.3828125,\n",
       "            0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.03278688, 0.04098361, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.4180328 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.59836066, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.9985 , 0.9976 , 0.997  , 0.996  , 0.9956 ,\n",
       "            0.9937 , 0.9927 , 0.992  , 0.991  , 0.9907 , 0.99   , 0.9897 ,\n",
       "            0.9893 , 0.989  , 0.9883 , 0.988  , 0.987  , 0.9863 , 0.986  ,\n",
       "            0.9844 , 0.984  , 0.9834 , 0.9824 , 0.982  , 0.9795 , 0.978  ,\n",
       "            0.977  , 0.976  , 0.9756 , 0.972  , 0.9688 , 0.9663 , 0.966  ,\n",
       "            0.9653 , 0.9634 , 0.963  , 0.9614 , 0.9604 , 0.957  , 0.9536 ,\n",
       "            0.952  , 0.95   , 0.949  , 0.948  , 0.9478 , 0.9453 , 0.9424 ,\n",
       "            0.9385 , 0.9375 , 0.9346 , 0.9336 , 0.9316 , 0.9297 , 0.929  ,\n",
       "            0.927  , 0.9263 , 0.926  , 0.9253 , 0.9243 , 0.9224 , 0.922  ,\n",
       "            0.9175 , 0.917  , 0.916  , 0.913  , 0.9106 , 0.909  , 0.908  ,\n",
       "            0.907  , 0.9053 , 0.905  , 0.904  , 0.902  , 0.9014 , 0.9004 ,\n",
       "            0.8984 , 0.896  , 0.894  , 0.893  , 0.891  , 0.8906 , 0.89   ,\n",
       "            0.888  , 0.887  , 0.8857 , 0.885  , 0.884  , 0.8813 , 0.878  ,\n",
       "            0.8755 , 0.8745 , 0.874  , 0.8687 , 0.8677 , 0.8643 , 0.8623 ,\n",
       "            0.8604 , 0.859  , 0.857  , 0.8564 , 0.855  , 0.853  , 0.851  ,\n",
       "            0.8506 , 0.85   , 0.849  , 0.8486 , 0.848  , 0.845  , 0.8438 ,\n",
       "            0.842  , 0.84   , 0.8384 , 0.8374 , 0.837  , 0.836  , 0.8345 ,\n",
       "            0.8325 , 0.8315 , 0.83   , 0.825  , 0.821  , 0.8193 , 0.819  ,\n",
       "            0.8164 , 0.811  , 0.8086 , 0.801  , 0.8003 , 0.7905 , 0.7896 ,\n",
       "            0.785  , 0.7837 , 0.7793 , 0.7773 , 0.7764 , 0.7744 , 0.773  ,\n",
       "            0.767  , 0.7656 , 0.757  , 0.7554 , 0.74   , 0.7373 , 0.735  ,\n",
       "            0.7314 , 0.726  , 0.724  , 0.721  , 0.7188 , 0.705  , 0.696  ,\n",
       "            0.695  , 0.6895 , 0.6836 , 0.6577 , 0.6377 , 0.5747 , 0.556  ,\n",
       "            0.5396 , 0.5376 , 0.5327 , 0.5234 , 0.515  , 0.513  , 0.51   ,\n",
       "            0.4958 , 0.4822 , 0.45   , 0.4355 , 0.424  , 0.4028 , 0.3774 ,\n",
       "            0.3699 , 0.3599 , 0.3467 , 0.2844 , 0.278  , 0.2769 , 0.2588 ,\n",
       "            0.2482 , 0.2477 , 0.2455 , 0.2424 , 0.2339 , 0.2175 , 0.2139 ,\n",
       "            0.2026 , 0.1978 , 0.196  , 0.1943 , 0.178  , 0.1586 , 0.1584 ,\n",
       "            0.1465 , 0.1378 , 0.1232 , 0.1216 , 0.1201 , 0.1172 , 0.11316,\n",
       "            0.10504, 0.10156, 0.0995 , 0.09656, 0.0955 , 0.0927 , 0.0868 ,\n",
       "            0.0866 , 0.07135, 0.0698 , 0.06866, 0.0684 , 0.0549 , 0.04858,\n",
       "            0.04208, 0.04   , 0.0389 , 0.03354, 0.02908, 0.02377, 0.0231 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.578125, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1171875, 0.125    , 0.1328125, 0.1328125,\n",
       "            0.1328125, 0.1484375, 0.1640625, 0.171875 , 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.265625 ,\n",
       "            0.2734375, 0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.3359375, 0.34375  , 0.34375  , 0.34375  , 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.375    , 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.390625 , 0.390625 , 0.4140625, 0.421875 , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.03278688, 0.04098361, 0.05737705,\n",
       "            0.07377049, 0.09836066, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.14754099, 0.1557377 , 0.17213115, 0.19672132, 0.21311475,\n",
       "            0.22131148, 0.23770492, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59016395, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.6229508 , 0.63114756, 0.647541  , 0.6639344 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.9985 , 0.998  , 0.9976 , 0.9966 , 0.9946 ,\n",
       "            0.9937 , 0.9927 , 0.992  , 0.9917 , 0.991  , 0.9907 , 0.9897 ,\n",
       "            0.989  , 0.9883 , 0.988  , 0.9863 , 0.986  , 0.985  , 0.9844 ,\n",
       "            0.982  , 0.981  , 0.98   , 0.979  , 0.9785 , 0.9756 , 0.9727 ,\n",
       "            0.97   , 0.9673 , 0.967  , 0.965  , 0.962  , 0.959  , 0.9585 ,\n",
       "            0.958  , 0.9575 , 0.957  , 0.9556 , 0.9546 , 0.9536 , 0.9517 ,\n",
       "            0.9487 , 0.946  , 0.9453 , 0.941  , 0.94   , 0.9395 , 0.9385 ,\n",
       "            0.938  , 0.9365 , 0.935  , 0.9346 , 0.934  , 0.9336 , 0.933  ,\n",
       "            0.9326 , 0.931  , 0.9307 , 0.929  , 0.9277 , 0.925  , 0.923  ,\n",
       "            0.9224 , 0.9194 , 0.919  , 0.9175 , 0.916  , 0.914  , 0.9136 ,\n",
       "            0.913  , 0.9126 , 0.911  , 0.908  , 0.906  , 0.904  , 0.903  ,\n",
       "            0.902  , 0.9004 , 0.899  , 0.8984 , 0.898  , 0.894  , 0.8926 ,\n",
       "            0.889  , 0.887  , 0.886  , 0.8843 , 0.8794 , 0.879  , 0.877  ,\n",
       "            0.873  , 0.8726 , 0.871  , 0.8706 , 0.8696 , 0.8687 , 0.867  ,\n",
       "            0.8667 , 0.865  , 0.8643 , 0.8633 , 0.861  , 0.8584 , 0.858  ,\n",
       "            0.857  , 0.855  , 0.854  , 0.8525 , 0.8516 , 0.851  , 0.8496 ,\n",
       "            0.849  , 0.8486 , 0.846  , 0.845  , 0.841  , 0.837  , 0.8364 ,\n",
       "            0.835  , 0.8276 , 0.827  , 0.8184 , 0.817  , 0.807  , 0.804  ,\n",
       "            0.8027 , 0.8003 , 0.7974 , 0.797  , 0.7944 , 0.79   , 0.7866 ,\n",
       "            0.778  , 0.7764 , 0.7617 , 0.7583 , 0.7534 , 0.751  , 0.747  ,\n",
       "            0.742  , 0.741  , 0.739  , 0.73   , 0.7217 , 0.7114 , 0.7104 ,\n",
       "            0.707  , 0.6797 , 0.6514 , 0.588  , 0.567  , 0.5493 , 0.5415 ,\n",
       "            0.5396 , 0.5347 , 0.5327 , 0.515  , 0.5083 , 0.4976 , 0.4639 ,\n",
       "            0.4426 , 0.429  , 0.4104 , 0.381  , 0.3738 , 0.3665 , 0.352  ,\n",
       "            0.2869 , 0.28   , 0.2786 , 0.2632 , 0.2473 , 0.2452 , 0.2448 ,\n",
       "            0.2422 , 0.2297 , 0.2185 , 0.211  , 0.1996 , 0.1973 , 0.1954 ,\n",
       "            0.1904 , 0.1757 , 0.1567 , 0.1564 , 0.1431 , 0.1349 , 0.12067,\n",
       "            0.1188 , 0.11676, 0.1134 , 0.1095 , 0.10175, 0.0995 , 0.0964 ,\n",
       "            0.0939 , 0.09155, 0.0893 , 0.0836 , 0.0833 , 0.0684 , 0.06683,\n",
       "            0.06573, 0.065  , 0.05283, 0.04535, 0.0398 , 0.03812, 0.03616,\n",
       "            0.0318 , 0.02666, 0.02216, 0.02148], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5859375, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.2890625, 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.34375  , 0.34375  , 0.359375 , 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.375    , 0.375    , 0.3828125, 0.390625 , 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.4140625, 0.421875 , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.03278688, 0.04098361, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13934426, 0.14754099, 0.16393442, 0.17213115,\n",
       "            0.19672132, 0.21311475, 0.23770492, 0.25409836, 0.26229507,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.31967214, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.3852459 , 0.39344263, 0.40163934, 0.4180328 ,\n",
       "            0.4262295 , 0.44262296, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6967213 ,\n",
       "            0.6967213 , 0.6967213 , 0.6967213 , 0.704918  , 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9995 , 0.999  , 0.9985 , 0.998  , 0.9976 , 0.997  ,\n",
       "            0.9956 , 0.995  , 0.9946 , 0.994  , 0.9937 , 0.993  , 0.9927 ,\n",
       "            0.992  , 0.9917 , 0.9907 , 0.99   , 0.989  , 0.9883 , 0.9873 ,\n",
       "            0.985  , 0.984  , 0.9834 , 0.9824 , 0.9795 , 0.9766 , 0.975  ,\n",
       "            0.9746 , 0.9727 , 0.972  , 0.9717 , 0.97   , 0.9673 , 0.965  ,\n",
       "            0.964  , 0.9634 , 0.962  , 0.961  , 0.96   , 0.9585 , 0.9556 ,\n",
       "            0.953  , 0.9526 , 0.9487 , 0.948  , 0.9473 , 0.947  , 0.9463 ,\n",
       "            0.945  , 0.944  , 0.9434 , 0.9424 , 0.942  , 0.9414 , 0.9395 ,\n",
       "            0.9365 , 0.934  , 0.933  , 0.932  , 0.9297 , 0.929  , 0.928  ,\n",
       "            0.9272 , 0.9263 , 0.926  , 0.9243 , 0.924  , 0.9224 , 0.9194 ,\n",
       "            0.917  , 0.915  , 0.9146 , 0.914  , 0.9136 , 0.912  , 0.9116 ,\n",
       "            0.9106 , 0.9097 , 0.906  , 0.9014 , 0.8994 , 0.899  , 0.8984 ,\n",
       "            0.892  , 0.89   , 0.888  , 0.8867 , 0.8853 , 0.8843 , 0.884  ,\n",
       "            0.8833 , 0.883  , 0.8823 , 0.882  , 0.8804 , 0.88   , 0.8784 ,\n",
       "            0.878  , 0.877  , 0.8765 , 0.874  , 0.872  , 0.8706 , 0.869  ,\n",
       "            0.8687 , 0.8677 , 0.867  , 0.8657 , 0.865  , 0.8643 , 0.8633 ,\n",
       "            0.862  , 0.857  , 0.853  , 0.8525 , 0.8506 , 0.8457 , 0.844  ,\n",
       "            0.8433 , 0.836  , 0.8335 , 0.824  , 0.8237 , 0.82   , 0.8174 ,\n",
       "            0.817  , 0.8164 , 0.816  , 0.815  , 0.8135 , 0.807  , 0.8057 ,\n",
       "            0.798  , 0.7964 , 0.782  , 0.781  , 0.7754 , 0.772  , 0.7656 ,\n",
       "            0.7617 , 0.761  , 0.7593 , 0.7544 , 0.7466 , 0.734  , 0.73   ,\n",
       "            0.7295 , 0.7026 , 0.6714 , 0.6074 , 0.585  , 0.567  , 0.565  ,\n",
       "            0.562  , 0.5586 , 0.557  , 0.556  , 0.5356 , 0.5273 , 0.5176 ,\n",
       "            0.4824 , 0.4578 , 0.445  , 0.4248 , 0.3953 , 0.3867 , 0.3794 ,\n",
       "            0.3643 , 0.2954 , 0.2883 , 0.2864 , 0.2725 , 0.254  , 0.253  ,\n",
       "            0.252  , 0.2489 , 0.2388 , 0.2242 , 0.2148 , 0.2029 , 0.2024 ,\n",
       "            0.1985 , 0.1947 , 0.1782 , 0.1587 , 0.1582 , 0.1444 , 0.1359 ,\n",
       "            0.1229 , 0.1201 , 0.1195 , 0.1136 , 0.1097 , 0.10175, 0.0997 ,\n",
       "            0.0962 , 0.0937 , 0.0914 , 0.089  , 0.083  , 0.0827 , 0.06757,\n",
       "            0.066  , 0.06476, 0.0642 , 0.05212, 0.04477, 0.03876, 0.03732,\n",
       "            0.03528, 0.03091, 0.02615, 0.02129, 0.02065], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5859375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.1328125, 0.140625 , 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.2734375, 0.28125  , 0.28125  , 0.28125  , 0.28125  , 0.28125  ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.3359375, 0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3671875, 0.375    , 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.4140625, 0.4140625, 0.421875 , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.04098361, 0.05737705, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.1147541 , 0.12295082, 0.14754099,\n",
       "            0.1557377 , 0.17213115, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.47540984, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5081967 , 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59836066, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9995 , 0.999  , 0.9985 , 0.998  , 0.997  , 0.9966 ,\n",
       "            0.996  , 0.9956 , 0.995  , 0.9946 , 0.994  , 0.9937 , 0.993  ,\n",
       "            0.9927 , 0.992  , 0.9917 , 0.991  , 0.9907 , 0.99   , 0.9897 ,\n",
       "            0.9883 , 0.9873 , 0.987  , 0.9863 , 0.986  , 0.984  , 0.9814 ,\n",
       "            0.981  , 0.9805 , 0.98   , 0.9785 , 0.978  , 0.9775 , 0.976  ,\n",
       "            0.9736 , 0.972  , 0.9717 , 0.971  , 0.9707 , 0.97   , 0.9697 ,\n",
       "            0.9683 , 0.968  , 0.965  , 0.964  , 0.9634 , 0.9595 , 0.959  ,\n",
       "            0.958  , 0.957  , 0.956  , 0.9556 , 0.9546 , 0.9536 , 0.953  ,\n",
       "            0.9526 , 0.951  , 0.95   , 0.948  , 0.9473 , 0.946  , 0.945  ,\n",
       "            0.943  , 0.942  , 0.9414 , 0.9404 , 0.9395 , 0.939  , 0.936  ,\n",
       "            0.9355 , 0.934  , 0.931  , 0.9307 , 0.93   , 0.929  , 0.928  ,\n",
       "            0.9277 , 0.927  , 0.926  , 0.9233 , 0.9204 , 0.92   , 0.9185 ,\n",
       "            0.9175 , 0.9126 , 0.912  , 0.9106 , 0.9077 , 0.9062 , 0.906  ,\n",
       "            0.905  , 0.9043 , 0.904  , 0.9014 , 0.9004 , 0.9    , 0.8994 ,\n",
       "            0.898  , 0.897  , 0.8965 , 0.8955 , 0.895  , 0.892  , 0.8906 ,\n",
       "            0.889  , 0.8867 , 0.8857 , 0.8784 , 0.877  , 0.875  , 0.8745 ,\n",
       "            0.8735 , 0.8726 , 0.8696 , 0.8633 , 0.8623 , 0.8594 , 0.854  ,\n",
       "            0.851  , 0.8486 , 0.8477 , 0.844  , 0.8433 , 0.841  , 0.836  ,\n",
       "            0.835  , 0.8296 , 0.8286 , 0.8213 , 0.8164 , 0.815  , 0.813  ,\n",
       "            0.801  , 0.7954 , 0.794  , 0.793  , 0.792  , 0.786  , 0.7695 ,\n",
       "            0.767  , 0.7583 , 0.7397 , 0.7007 , 0.637  , 0.614  , 0.6025 ,\n",
       "            0.5947 , 0.594  , 0.5815 , 0.5796 , 0.559  , 0.5557 , 0.5547 ,\n",
       "            0.515  , 0.482  , 0.467  , 0.4495 , 0.415  , 0.4065 , 0.4026 ,\n",
       "            0.385  , 0.31   , 0.3022 , 0.2998 , 0.2896 , 0.2673 , 0.2637 ,\n",
       "            0.2578 , 0.2554 , 0.2428 , 0.2351 , 0.2205 , 0.2115 , 0.2079 ,\n",
       "            0.2043 , 0.1987 , 0.1835 , 0.1638 , 0.1625 , 0.147  , 0.1385 ,\n",
       "            0.1295 , 0.12054, 0.119  , 0.1142 , 0.1105 , 0.1025 , 0.1019 ,\n",
       "            0.09705, 0.09485, 0.09106, 0.0891 , 0.083  , 0.0827 , 0.0673 ,\n",
       "            0.06573, 0.0643 , 0.06335, 0.05225, 0.04346, 0.03802, 0.037  ,\n",
       "            0.03397, 0.0305 , 0.0248 , 0.0206 , 0.01991], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1875   , 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3203125, 0.3203125, 0.328125 , 0.328125 ,\n",
       "            0.3359375, 0.3359375, 0.3359375, 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.3671875, 0.375    , 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.4140625, 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.03278688, 0.05737705, 0.07377049, 0.10655738,\n",
       "            0.1147541 , 0.13934426, 0.1557377 , 0.17213115, 0.19672132,\n",
       "            0.21311475, 0.23770492, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.3114754 , 0.31967214, 0.33606556,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.47540984, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.52459013, 0.5327869 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59016395, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.75409836, 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.77868855, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9995 , 0.999  , 0.9985 , 0.9976 , 0.997  , 0.9966 ,\n",
       "            0.996  , 0.9956 , 0.995  , 0.9946 , 0.994  , 0.9937 , 0.993  ,\n",
       "            0.9927 , 0.992  , 0.991  , 0.9907 , 0.9897 , 0.9893 , 0.988  ,\n",
       "            0.9863 , 0.986  , 0.9854 , 0.9844 , 0.984  , 0.983  , 0.9824 ,\n",
       "            0.9814 , 0.9795 , 0.979  , 0.9785 , 0.978  , 0.9775 , 0.9766 ,\n",
       "            0.9756 , 0.9727 , 0.969  , 0.9688 , 0.967  , 0.9663 , 0.966  ,\n",
       "            0.9653 , 0.965  , 0.9644 , 0.9634 , 0.9614 , 0.961  , 0.9604 ,\n",
       "            0.9595 , 0.959  , 0.958  , 0.9575 , 0.9565 , 0.9546 , 0.954  ,\n",
       "            0.9536 , 0.953  , 0.9526 , 0.952  , 0.9517 , 0.95   , 0.9497 ,\n",
       "            0.948  , 0.9478 , 0.947  , 0.9453 , 0.945  , 0.944  , 0.9434 ,\n",
       "            0.9424 , 0.941  , 0.939  , 0.9375 , 0.9365 , 0.9346 , 0.9336 ,\n",
       "            0.9316 , 0.93   , 0.9287 , 0.9277 , 0.9263 , 0.926  , 0.9253 ,\n",
       "            0.925  , 0.924  , 0.9233 , 0.922  , 0.92   , 0.919  , 0.9185 ,\n",
       "            0.9175 , 0.9165 , 0.916  , 0.915  , 0.9146 , 0.914  , 0.9136 ,\n",
       "            0.91   , 0.9097 , 0.909  , 0.907  , 0.9062 , 0.901  , 0.8984 ,\n",
       "            0.8975 , 0.897  , 0.8965 , 0.8926 , 0.8916 , 0.8867 , 0.8833 ,\n",
       "            0.883  , 0.8804 , 0.8765 , 0.876  , 0.8745 , 0.8706 , 0.868  ,\n",
       "            0.8643 , 0.863  , 0.861  , 0.858  , 0.8574 , 0.8477 , 0.8467 ,\n",
       "            0.8447 , 0.828  , 0.8276 , 0.825  , 0.8228 , 0.8223 , 0.8213 ,\n",
       "            0.8022 , 0.8013 , 0.7876 , 0.774  , 0.733  , 0.6694 , 0.646  ,\n",
       "            0.641  , 0.633  , 0.632  , 0.626  , 0.6123 , 0.609  , 0.5933 ,\n",
       "            0.593  , 0.586  , 0.549  , 0.5107 , 0.4963 , 0.4783 , 0.4424 ,\n",
       "            0.4321 , 0.43   , 0.4102 , 0.3286 , 0.32   , 0.3171 , 0.309  ,\n",
       "            0.2842 , 0.2786 , 0.2712 , 0.268  , 0.2563 , 0.2482 , 0.2302 ,\n",
       "            0.2227 , 0.2168 , 0.2133 , 0.2076 , 0.1915 , 0.1707 , 0.1694 ,\n",
       "            0.1523 , 0.1436 , 0.1371 , 0.1243 , 0.1236 , 0.1172 , 0.11316,\n",
       "            0.1054 , 0.10504, 0.0993 , 0.09705, 0.09283, 0.09106, 0.08435,\n",
       "            0.08417, 0.0683 , 0.06647, 0.065  , 0.06396, 0.05292, 0.04346,\n",
       "            0.03796, 0.03705, 0.0336 , 0.03044, 0.02443, 0.02014, 0.01945],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.609375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   ,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.1171875, 0.125    , 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.1640625, 0.1640625, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.265625 ,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.3359375, 0.3359375, 0.3359375, 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.40625  , 0.4140625, 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.05737705, 0.07377049, 0.09836066,\n",
       "            0.1147541 , 0.14754099, 0.17213115, 0.19672132, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.28688523, 0.29508197, 0.3114754 ,\n",
       "            0.31967214, 0.33606556, 0.3442623 , 0.3442623 , 0.36065573,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40983605, 0.4180328 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.47540984, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5327869 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.7295082 , 0.7295082 ,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 1.     , 0.9995 , 0.999  , 0.9985 , 0.998  , 0.9976 ,\n",
       "            0.997  , 0.9966 , 0.996  , 0.9956 , 0.995  , 0.9946 , 0.9937 ,\n",
       "            0.993  , 0.9927 , 0.992  , 0.9907 , 0.99   , 0.9893 , 0.989  ,\n",
       "            0.9883 , 0.9873 , 0.987  , 0.9863 , 0.985  , 0.9844 , 0.984  ,\n",
       "            0.9834 , 0.983  , 0.9824 , 0.9814 , 0.9795 , 0.9775 , 0.977  ,\n",
       "            0.975  , 0.9746 , 0.974  , 0.9736 , 0.9727 , 0.972  , 0.971  ,\n",
       "            0.9707 , 0.969  , 0.9688 , 0.9683 , 0.968  , 0.9653 , 0.965  ,\n",
       "            0.9644 , 0.964  , 0.9624 , 0.962  , 0.961  , 0.96   , 0.9585 ,\n",
       "            0.9575 , 0.957  , 0.9565 , 0.956  , 0.953  , 0.9526 , 0.952  ,\n",
       "            0.9507 , 0.9487 , 0.9478 , 0.946  , 0.945  , 0.9443 , 0.9434 ,\n",
       "            0.943  , 0.9424 , 0.942  , 0.9414 , 0.941  , 0.9404 , 0.9395 ,\n",
       "            0.939  , 0.9385 , 0.937  , 0.9365 , 0.935  , 0.9336 , 0.9326 ,\n",
       "            0.932  , 0.9316 , 0.929  , 0.928  , 0.9277 , 0.9272 , 0.926  ,\n",
       "            0.9253 , 0.921  , 0.919  , 0.918  , 0.917  , 0.916  , 0.913  ,\n",
       "            0.9106 , 0.9087 , 0.905  , 0.903  , 0.9014 , 0.8994 , 0.8984 ,\n",
       "            0.8955 , 0.8916 , 0.8906 , 0.8877 , 0.886  , 0.885  , 0.8843 ,\n",
       "            0.878  , 0.877  , 0.8726 , 0.872  , 0.8604 , 0.8555 , 0.855  ,\n",
       "            0.854  , 0.852  , 0.849  , 0.8477 , 0.8345 , 0.834  , 0.8164 ,\n",
       "            0.807  , 0.7646 , 0.701  , 0.6787 , 0.6777 , 0.6704 , 0.669  ,\n",
       "            0.6577 , 0.646  , 0.642  , 0.63   , 0.6274 , 0.6206 , 0.5845 ,\n",
       "            0.5415 , 0.5293 , 0.509  , 0.4731 , 0.4604 , 0.4597 , 0.4373 ,\n",
       "            0.3484 , 0.3394 , 0.3364 , 0.3298 , 0.3025 , 0.2957 , 0.289  ,\n",
       "            0.2852 , 0.2747 , 0.2627 , 0.2424 , 0.2355 , 0.2281 , 0.2239 ,\n",
       "            0.2202 , 0.201  , 0.1787 , 0.1774 , 0.1592 , 0.1497 , 0.1456 ,\n",
       "            0.1309 , 0.1304 , 0.1217 , 0.1174 , 0.1097 , 0.1084 , 0.1025 ,\n",
       "            0.10016, 0.0959 , 0.0937 , 0.0868 , 0.0865 , 0.0698 , 0.06793,\n",
       "            0.06647, 0.06537, 0.0541 , 0.04443, 0.03824, 0.03754, 0.03384,\n",
       "            0.03067, 0.02475, 0.02002, 0.01927], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6171875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.109375 , 0.1171875, 0.140625 , 0.1484375, 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.25     , 0.2578125,\n",
       "            0.265625 , 0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.3359375, 0.3359375, 0.3359375, 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.375    ,\n",
       "            0.3828125, 0.40625  , 0.4140625, 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4296875, 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.03278688, 0.07377049, 0.09836066, 0.12295082,\n",
       "            0.16393442, 0.19672132, 0.23770492, 0.25409836, 0.27868852,\n",
       "            0.28688523, 0.30327868, 0.3114754 , 0.32786885, 0.33606556,\n",
       "            0.33606556, 0.3442623 , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.4180328 , 0.43442622,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5       , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6229508 , 0.63114756, 0.6393443 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.8032787 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 1.     , 0.9995 , 0.999  , 0.9985 , 0.998  , 0.9976 ,\n",
       "            0.997  , 0.9966 , 0.996  , 0.9956 , 0.995  , 0.9946 , 0.994  ,\n",
       "            0.9937 , 0.993  , 0.9927 , 0.9917 , 0.991  , 0.99   , 0.9897 ,\n",
       "            0.9893 , 0.989  , 0.988  , 0.9873 , 0.9863 , 0.986  , 0.985  ,\n",
       "            0.9844 , 0.983  , 0.9824 , 0.9814 , 0.981  , 0.9805 , 0.98   ,\n",
       "            0.9795 , 0.979  , 0.9785 , 0.978  , 0.976  , 0.9756 , 0.973  ,\n",
       "            0.9727 , 0.972  , 0.9717 , 0.971  , 0.9697 , 0.969  , 0.967  ,\n",
       "            0.9663 , 0.966  , 0.9634 , 0.963  , 0.9624 , 0.961  , 0.96   ,\n",
       "            0.9595 , 0.9585 , 0.9575 , 0.9565 , 0.956  , 0.955  , 0.9546 ,\n",
       "            0.954  , 0.9536 , 0.953  , 0.9526 , 0.952  , 0.951  , 0.9497 ,\n",
       "            0.948  , 0.9478 , 0.9463 , 0.9453 , 0.944  , 0.9434 , 0.942  ,\n",
       "            0.9414 , 0.941  , 0.9404 , 0.9395 , 0.936  , 0.935  , 0.933  ,\n",
       "            0.932  , 0.931  , 0.929  , 0.9253 , 0.9233 , 0.9214 , 0.9204 ,\n",
       "            0.9185 , 0.916  , 0.915  , 0.9106 , 0.909  , 0.907  , 0.9053 ,\n",
       "            0.905  , 0.9043 , 0.904  , 0.9014 , 0.9    , 0.8945 , 0.893  ,\n",
       "            0.8853 , 0.882  , 0.877  , 0.8765 , 0.875  , 0.872  , 0.869  ,\n",
       "            0.861  , 0.8594 , 0.8403 , 0.8345 , 0.7944 , 0.7334 , 0.7163 ,\n",
       "            0.7114 , 0.7104 , 0.7095 , 0.6924 , 0.681  , 0.675  , 0.6714 ,\n",
       "            0.665  , 0.656  , 0.6255 , 0.5767 , 0.5664 , 0.545  , 0.5093 ,\n",
       "            0.4958 , 0.4946 , 0.471  , 0.3757 , 0.3657 , 0.3638 , 0.3591 ,\n",
       "            0.3289 , 0.3198 , 0.3118 , 0.308  , 0.297  , 0.2847 , 0.2607 ,\n",
       "            0.2556 , 0.2452 , 0.241  , 0.2382 , 0.2167 , 0.1927 , 0.1913 ,\n",
       "            0.1715 , 0.161  , 0.1606 , 0.1415 , 0.1403 , 0.1302 , 0.1257 ,\n",
       "            0.1186 , 0.11615, 0.1099 , 0.1074 , 0.1025 , 0.10016, 0.0925 ,\n",
       "            0.09235, 0.0745 , 0.0725 , 0.0707 , 0.06964, 0.05792, 0.04724,\n",
       "            0.04053, 0.04   , 0.03574, 0.03265, 0.02606, 0.02109, 0.0203 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6328125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.203125 ,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.25     , 0.265625 , 0.2734375, 0.2734375, 0.28125  ,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.3203125, 0.3359375, 0.3359375, 0.3359375, 0.3359375,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.03278688, 0.07377049, 0.1147541 , 0.1557377 ,\n",
       "            0.19672132, 0.23770492, 0.25409836, 0.28688523, 0.30327868,\n",
       "            0.3114754 , 0.33606556, 0.33606556, 0.3442623 , 0.3442623 ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.39344263, 0.40163934,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5       , 0.5163934 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59016395, 0.59836066, 0.60655737, 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.7295082 , 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.8032787 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 1.     , 0.9995 , 0.999  , 0.9985 , 0.998  , 0.9976 ,\n",
       "            0.997  , 0.9966 , 0.996  , 0.9956 , 0.995  , 0.9946 , 0.994  ,\n",
       "            0.9937 , 0.993  , 0.9927 , 0.9917 , 0.991  , 0.9907 , 0.9897 ,\n",
       "            0.9893 , 0.989  , 0.9883 , 0.9873 , 0.987  , 0.986  , 0.9854 ,\n",
       "            0.985  , 0.9844 , 0.984  , 0.9834 , 0.983  , 0.9824 , 0.982  ,\n",
       "            0.9814 , 0.98   , 0.9795 , 0.979  , 0.9775 , 0.977  , 0.9766 ,\n",
       "            0.976  , 0.9756 , 0.9746 , 0.974  , 0.9717 , 0.971  , 0.9707 ,\n",
       "            0.9688 , 0.9683 , 0.968  , 0.9663 , 0.966  , 0.965  , 0.9644 ,\n",
       "            0.964  , 0.963  , 0.9624 , 0.962  , 0.961  , 0.9604 , 0.9595 ,\n",
       "            0.9585 , 0.9575 , 0.9565 , 0.9556 , 0.955  , 0.9536 , 0.9526 ,\n",
       "            0.951  , 0.9507 , 0.949  , 0.9487 , 0.948  , 0.947  , 0.9443 ,\n",
       "            0.944  , 0.9414 , 0.9404 , 0.9395 , 0.938  , 0.9346 , 0.933  ,\n",
       "            0.9307 , 0.9287 , 0.928  , 0.926  , 0.9253 , 0.9214 , 0.92   ,\n",
       "            0.918  , 0.9165 , 0.9146 , 0.914  , 0.912  , 0.9067 , 0.9053 ,\n",
       "            0.8994 , 0.896  , 0.89   , 0.8887 , 0.888  , 0.8853 , 0.882  ,\n",
       "            0.876  , 0.874  , 0.854  , 0.8506 , 0.813  , 0.7524 , 0.7373 ,\n",
       "            0.7314 , 0.731  , 0.7134 , 0.7026 , 0.6978 , 0.6934 , 0.686  ,\n",
       "            0.679  , 0.6475 , 0.598  , 0.59   , 0.566  , 0.5327 , 0.517  ,\n",
       "            0.516  , 0.4915 , 0.393  , 0.3826 , 0.3804 , 0.376  , 0.3442 ,\n",
       "            0.3357 , 0.3286 , 0.3242 , 0.315  , 0.2976 , 0.273  , 0.2673 ,\n",
       "            0.2566 , 0.2517 , 0.2505 , 0.2264 , 0.201  , 0.2    , 0.1796 ,\n",
       "            0.169  , 0.1683 , 0.1503 , 0.1475 , 0.1361 , 0.1312 , 0.12366,\n",
       "            0.121  , 0.11456, 0.1118 , 0.10724, 0.1043 , 0.0964 , 0.096  ,\n",
       "            0.0774 , 0.0753 , 0.07355, 0.07263, 0.0602 , 0.0494 , 0.04202,\n",
       "            0.04147, 0.0372 , 0.03378, 0.02711, 0.02174, 0.02092],\n",
       "           dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.30508474, 0.30508474,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.38135594, 0.3898305 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.58474576, 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.61864406, 0.62711865, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6864407 , 0.69491524, 0.7033898 , 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.7966102 , 0.7966102 , 0.80508476, 0.8135593 , 0.8305085 ,\n",
       "            0.83898306, 0.8559322 , 0.8559322 , 0.86440676, 0.86440676,\n",
       "            0.86440676, 0.86440676, 0.86440676, 0.87288135, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.9322034 , 0.94067794, 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.08333334, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.12878788, 0.12878788, 0.13636364,\n",
       "            0.13636364, 0.13636364, 0.13636364, 0.14393939, 0.14393939,\n",
       "            0.14393939, 0.15151516, 0.15151516, 0.15151516, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.20454545, 0.21212122, 0.23484848,\n",
       "            0.23484848, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28030303, 0.28787878, 0.29545453, 0.29545453,\n",
       "            0.3030303 , 0.3030303 , 0.31060606, 0.31060606, 0.32575756,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.3409091 , 0.3409091 ,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.36363637, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.3939394 , 0.40151516,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.70454544, 0.7121212 , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4612, 0.4602, 0.4595, 0.4587, 0.4563, 0.456 , 0.4543,\n",
       "            0.452 , 0.4512, 0.4497, 0.4492, 0.449 , 0.447 , 0.4468, 0.4465,\n",
       "            0.4463, 0.446 , 0.4458, 0.445 , 0.4446, 0.4438, 0.4436, 0.443 ,\n",
       "            0.4429, 0.4421, 0.442 , 0.4417, 0.4412, 0.441 , 0.4407, 0.4404,\n",
       "            0.4402, 0.44  , 0.4397, 0.4392, 0.4387, 0.4385, 0.438 , 0.4377,\n",
       "            0.4373, 0.4368, 0.4365, 0.4363, 0.436 , 0.4358, 0.4355, 0.4343,\n",
       "            0.4333, 0.4329, 0.4326, 0.4324, 0.4321, 0.432 , 0.4316, 0.4314,\n",
       "            0.4312, 0.431 , 0.4307, 0.4304, 0.4297, 0.4292, 0.4287, 0.4285,\n",
       "            0.4282, 0.428 , 0.4275, 0.4272, 0.4268, 0.4265, 0.4263, 0.426 ,\n",
       "            0.4258, 0.4255, 0.4253, 0.4248, 0.4246, 0.4243, 0.424 , 0.4238,\n",
       "            0.4236, 0.4233, 0.4226, 0.4224, 0.422 , 0.4216, 0.4214, 0.4211,\n",
       "            0.4207, 0.4204, 0.4202, 0.42  , 0.4194, 0.4192, 0.419 , 0.4187,\n",
       "            0.4185, 0.4182, 0.418 , 0.4177, 0.4172, 0.4165, 0.4163, 0.416 ,\n",
       "            0.4155, 0.4153, 0.4148, 0.4146, 0.414 , 0.413 , 0.4114, 0.4104,\n",
       "            0.4102, 0.41  , 0.4097, 0.4087, 0.4084, 0.4077, 0.4067, 0.4065,\n",
       "            0.406 , 0.4055, 0.405 , 0.4038, 0.4033, 0.4016, 0.4014, 0.401 ,\n",
       "            0.4004, 0.4   , 0.399 , 0.3982, 0.398 , 0.3958, 0.3928, 0.3916,\n",
       "            0.3909, 0.3901, 0.3882, 0.3877, 0.3857, 0.3853, 0.385 , 0.3843,\n",
       "            0.384 , 0.3835, 0.3823, 0.3818, 0.381 , 0.3801, 0.38  , 0.3784,\n",
       "            0.3772, 0.3757, 0.3745, 0.3738, 0.3726, 0.372 , 0.3696, 0.3691,\n",
       "            0.3672, 0.3652, 0.365 , 0.3645, 0.3594, 0.3586, 0.3574, 0.3564,\n",
       "            0.3552, 0.354 , 0.3538, 0.352 , 0.35  , 0.3345], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.47457626, 0.48305085, 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.61864406, 0.61864406, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.69491524, 0.69491524, 0.7118644 , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7711864 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.84745765, 0.86440676,\n",
       "            0.86440676, 0.86440676, 0.8898305 , 0.8898305 , 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06818182, 0.06818182,\n",
       "            0.07575758, 0.09090909, 0.09090909, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12121212, 0.12121212, 0.12878788, 0.12878788, 0.13636364,\n",
       "            0.13636364, 0.13636364, 0.14393939, 0.14393939, 0.15151516,\n",
       "            0.15151516, 0.15151516, 0.15151516, 0.15151516, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18181819, 0.18181819,\n",
       "            0.1969697 , 0.1969697 , 0.20454545, 0.21212122, 0.22727273,\n",
       "            0.22727273, 0.23484848, 0.23484848, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25      , 0.25757575, 0.28030303, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.31060606,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.34848484, 0.3560606 , 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.37121212, 0.37878788, 0.3939394 ,\n",
       "            0.40151516, 0.40151516, 0.4090909 , 0.4090909 , 0.4090909 ,\n",
       "            0.4090909 , 0.4090909 , 0.4090909 , 0.41666666, 0.41666666,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.780303  ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4478, 0.4375, 0.4358, 0.4355, 0.4321, 0.43  , 0.4294,\n",
       "            0.4282, 0.427 , 0.4265, 0.4263, 0.4248, 0.4238, 0.4219, 0.4216,\n",
       "            0.421 , 0.4204, 0.4202, 0.42  , 0.4194, 0.418 , 0.4177, 0.4175,\n",
       "            0.417 , 0.4167, 0.4165, 0.416 , 0.4158, 0.4153, 0.4143, 0.4138,\n",
       "            0.4136, 0.4133, 0.413 , 0.4111, 0.411 , 0.4106, 0.4104, 0.41  ,\n",
       "            0.4094, 0.4092, 0.4084, 0.4082, 0.4075, 0.4072, 0.4065, 0.4062,\n",
       "            0.406 , 0.4055, 0.4053, 0.405 , 0.4048, 0.4045, 0.4038, 0.4033,\n",
       "            0.4019, 0.4016, 0.401 , 0.4006, 0.4001, 0.3992, 0.399 , 0.3984,\n",
       "            0.3977, 0.397 , 0.3965, 0.3962, 0.396 , 0.3958, 0.3955, 0.3953,\n",
       "            0.395 , 0.3943, 0.3933, 0.393 , 0.3926, 0.3923, 0.392 , 0.3918,\n",
       "            0.3916, 0.3914, 0.391 , 0.3909, 0.3906, 0.3904, 0.3896, 0.3884,\n",
       "            0.388 , 0.3877, 0.3865, 0.3862, 0.386 , 0.3857, 0.3853, 0.385 ,\n",
       "            0.3845, 0.384 , 0.3838, 0.3826, 0.382 , 0.381 , 0.3796, 0.3794,\n",
       "            0.3792, 0.3784, 0.3782, 0.378 , 0.3777, 0.3774, 0.377 , 0.3767,\n",
       "            0.3765, 0.3757, 0.3755, 0.3752, 0.375 , 0.3743, 0.374 , 0.3735,\n",
       "            0.3726, 0.3718, 0.3716, 0.3713, 0.371 , 0.3708, 0.3691, 0.3682,\n",
       "            0.3677, 0.3674, 0.3665, 0.366 , 0.3645, 0.3635, 0.3633, 0.362 ,\n",
       "            0.3618, 0.361 , 0.3606, 0.3604, 0.3599, 0.359 , 0.3582, 0.358 ,\n",
       "            0.3564, 0.3555, 0.3552, 0.355 , 0.3547, 0.354 , 0.3533, 0.3525,\n",
       "            0.3496, 0.3481, 0.3462, 0.3457, 0.3452, 0.345 , 0.3418, 0.341 ,\n",
       "            0.3381, 0.3352, 0.3328, 0.3325, 0.3306, 0.3284, 0.3271, 0.327 ,\n",
       "            0.3264, 0.3254, 0.3252, 0.3213, 0.3206, 0.3198, 0.3188, 0.3186,\n",
       "            0.3171, 0.3164, 0.316 , 0.3147, 0.313 , 0.3123, 0.3108, 0.3103,\n",
       "            0.309 , 0.306 , 0.3013, 0.2993, 0.2986, 0.2979, 0.2966, 0.2944,\n",
       "            0.2915, 0.2903, 0.2878, 0.2852, 0.2837, 0.2822, 0.261 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11864407, 0.12711865, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.80508476, 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.83898306, 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.90677965, 0.90677965, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.06060606, 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06818182, 0.06818182, 0.06818182, 0.06818182, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12121212, 0.12121212, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.13636364, 0.13636364, 0.13636364, 0.13636364,\n",
       "            0.14393939, 0.14393939, 0.15151516, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.16666667, 0.17424242, 0.18181819, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28030303, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.31060606, 0.31060606, 0.31060606,\n",
       "            0.31060606, 0.31060606, 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.3560606 , 0.3560606 , 0.3560606 , 0.3560606 , 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.40151516, 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.49242425, 0.5       , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6515151 , 0.65909094, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4338, 0.4136, 0.4128, 0.4126, 0.4119, 0.4102, 0.4094,\n",
       "            0.4053, 0.4038, 0.4033, 0.4023, 0.4016, 0.4014, 0.3975, 0.3972,\n",
       "            0.3965, 0.3948, 0.3936, 0.3933, 0.3926, 0.3916, 0.3914, 0.391 ,\n",
       "            0.39  , 0.3894, 0.3892, 0.3887, 0.386 , 0.3857, 0.3855, 0.3848,\n",
       "            0.384 , 0.3838, 0.3826, 0.382 , 0.3816, 0.3804, 0.3801, 0.38  ,\n",
       "            0.3796, 0.3794, 0.3792, 0.379 , 0.3787, 0.3784, 0.3777, 0.377 ,\n",
       "            0.3767, 0.3762, 0.3755, 0.3743, 0.3735, 0.3733, 0.373 , 0.3728,\n",
       "            0.372 , 0.3718, 0.3716, 0.3713, 0.3706, 0.3704, 0.37  , 0.3696,\n",
       "            0.3694, 0.3687, 0.3684, 0.3677, 0.367 , 0.3662, 0.3655, 0.3652,\n",
       "            0.3645, 0.3643, 0.3616, 0.3606, 0.3596, 0.3594, 0.3586, 0.3582,\n",
       "            0.358 , 0.3572, 0.3564, 0.3562, 0.3555, 0.3552, 0.355 , 0.3545,\n",
       "            0.3535, 0.353 , 0.3528, 0.3525, 0.352 , 0.3513, 0.35  , 0.3499,\n",
       "            0.3496, 0.3494, 0.3489, 0.3484, 0.3477, 0.3474, 0.3467, 0.3464,\n",
       "            0.3457, 0.3455, 0.3452, 0.345 , 0.3447, 0.344 , 0.3435, 0.3433,\n",
       "            0.3428, 0.3423, 0.3408, 0.34  , 0.3376, 0.3374, 0.336 , 0.3352,\n",
       "            0.3347, 0.3345, 0.3342, 0.3333, 0.3328, 0.3325, 0.3315, 0.3308,\n",
       "            0.3306, 0.3298, 0.3296, 0.329 , 0.3286, 0.327 , 0.3262, 0.3257,\n",
       "            0.3252, 0.325 , 0.324 , 0.321 , 0.3206, 0.32  , 0.3198, 0.3193,\n",
       "            0.3186, 0.3176, 0.317 , 0.3162, 0.3157, 0.315 , 0.3142, 0.3132,\n",
       "            0.3115, 0.3113, 0.309 , 0.3086, 0.3083, 0.3079, 0.3042, 0.303 ,\n",
       "            0.3025, 0.302 , 0.3015, 0.3   , 0.2983, 0.2954, 0.2932, 0.2905,\n",
       "            0.2888, 0.2886, 0.288 , 0.2844, 0.2825, 0.282 , 0.2817, 0.281 ,\n",
       "            0.2808, 0.2805, 0.2788, 0.2778, 0.2776, 0.2742, 0.2725, 0.2717,\n",
       "            0.271 , 0.27  , 0.2698, 0.2683, 0.268 , 0.2673, 0.2664, 0.266 ,\n",
       "            0.2646, 0.2612, 0.261 , 0.2507, 0.2505, 0.2493, 0.2482, 0.2478,\n",
       "            0.247 , 0.2433, 0.2418, 0.239 , 0.2358, 0.2344, 0.2339, 0.2106],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.13559322, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.21186441, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.33898306, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.38135594, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.58474576, 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7118644 , 0.720339  , 0.720339  ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7627119 , 0.7627119 , 0.7711864 ,\n",
       "            0.7881356 , 0.7966102 , 0.7966102 , 0.7966102 , 0.7966102 ,\n",
       "            0.80508476, 0.80508476, 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8220339 , 0.8220339 , 0.8305085 , 0.83898306, 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.84745765, 0.8559322 , 0.8559322 ,\n",
       "            0.86440676, 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.89830506, 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.94067794, 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06818182, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.13636364, 0.13636364,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.16666667, 0.17424242, 0.17424242, 0.17424242, 0.18181819,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.1969697 , 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.24242425,\n",
       "            0.24242425, 0.25      , 0.2651515 , 0.27272728, 0.27272728,\n",
       "            0.28030303, 0.28030303, 0.28787878, 0.28787878, 0.28787878,\n",
       "            0.28787878, 0.29545453, 0.29545453, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.31060606, 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.3560606 , 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.49242425, 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.419 , 0.398 , 0.3965, 0.3923, 0.389 , 0.3867, 0.3835,\n",
       "            0.382 , 0.3813, 0.3796, 0.3777, 0.3748, 0.3743, 0.3726, 0.37  ,\n",
       "            0.3699, 0.3694, 0.3684, 0.3672, 0.3662, 0.365 , 0.364 , 0.3635,\n",
       "            0.3623, 0.3616, 0.3606, 0.36  , 0.3594, 0.3586, 0.358 , 0.3567,\n",
       "            0.3564, 0.355 , 0.3547, 0.3542, 0.354 , 0.353 , 0.3523, 0.3518,\n",
       "            0.3516, 0.3499, 0.349 , 0.3489, 0.3486, 0.3481, 0.348 , 0.3477,\n",
       "            0.3472, 0.347 , 0.3467, 0.3462, 0.3457, 0.345 , 0.3445, 0.3442,\n",
       "            0.343 , 0.341 , 0.3408, 0.3403, 0.3398, 0.3396, 0.3386, 0.338 ,\n",
       "            0.3376, 0.3354, 0.335 , 0.3342, 0.3337, 0.3333, 0.3313, 0.3306,\n",
       "            0.3293, 0.327 , 0.325 , 0.3237, 0.3235, 0.3228, 0.3225, 0.3223,\n",
       "            0.322 , 0.3215, 0.3203, 0.32  , 0.3198, 0.3196, 0.319 , 0.3188,\n",
       "            0.3186, 0.3184, 0.318 , 0.3176, 0.3167, 0.3162, 0.3154, 0.315 ,\n",
       "            0.3142, 0.3137, 0.3135, 0.3123, 0.312 , 0.3118, 0.3115, 0.3113,\n",
       "            0.311 , 0.3108, 0.3103, 0.3093, 0.3083, 0.308 , 0.3071, 0.307 ,\n",
       "            0.3057, 0.3054, 0.3052, 0.304 , 0.3015, 0.301 , 0.2996, 0.2983,\n",
       "            0.298 , 0.297 , 0.2966, 0.2964, 0.2947, 0.2944, 0.294 , 0.2937,\n",
       "            0.2935, 0.2917, 0.2913, 0.2908, 0.29  , 0.2893, 0.2886, 0.2878,\n",
       "            0.2876, 0.287 , 0.2869, 0.2866, 0.2856, 0.2852, 0.285 , 0.2847,\n",
       "            0.284 , 0.2834, 0.2832, 0.2825, 0.282 , 0.2815, 0.2812, 0.2798,\n",
       "            0.2764, 0.2761, 0.276 , 0.2756, 0.2747, 0.2744, 0.2737, 0.2727,\n",
       "            0.2725, 0.2715, 0.2703, 0.268 , 0.2673, 0.267 , 0.2654, 0.2646,\n",
       "            0.2625, 0.2593, 0.2588, 0.2563, 0.2559, 0.255 , 0.2542, 0.2527,\n",
       "            0.2502, 0.2496, 0.2463, 0.2451, 0.2445, 0.244 , 0.243 , 0.2428,\n",
       "            0.2422, 0.2394, 0.2388, 0.2384, 0.2378, 0.236 , 0.2347, 0.2338,\n",
       "            0.233 , 0.2316, 0.2306, 0.2301, 0.2286, 0.2281, 0.228 , 0.2273,\n",
       "            0.2242, 0.2211, 0.2115, 0.2114, 0.2109, 0.209 , 0.2086, 0.2084,\n",
       "            0.2051, 0.2037, 0.2012, 0.1976, 0.1967, 0.1964, 0.1731],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.1779661 , 0.18644068,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.62711865, 0.63559324,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.779661  , 0.7966102 ,\n",
       "            0.80508476, 0.80508476, 0.80508476, 0.80508476, 0.80508476,\n",
       "            0.8220339 , 0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.86440676,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.88135594, 0.88135594,\n",
       "            0.88135594, 0.88135594, 0.8898305 , 0.89830506, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.94067794, 0.94067794, 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06060606, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.13636364, 0.13636364,\n",
       "            0.14393939, 0.14393939, 0.15151516, 0.1590909 , 0.1590909 ,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.17424242, 0.17424242,\n",
       "            0.17424242, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.28787878, 0.29545453, 0.29545453,\n",
       "            0.29545453, 0.29545453, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.32575756, 0.3409091 , 0.3409091 ,\n",
       "            0.34848484, 0.34848484, 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.3560606 , 0.37121212, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.40151516, 0.4090909 , 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.5151515 , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.72727275, 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4023, 0.3809, 0.3801, 0.3743, 0.3638, 0.3628, 0.3623,\n",
       "            0.3594, 0.3574, 0.357 , 0.3525, 0.3523, 0.3518, 0.3508, 0.3503,\n",
       "            0.3496, 0.347 , 0.3457, 0.3455, 0.3442, 0.3438, 0.3433, 0.3413,\n",
       "            0.3394, 0.3384, 0.3381, 0.3364, 0.3357, 0.3354, 0.3347, 0.3306,\n",
       "            0.3296, 0.3293, 0.3289, 0.3286, 0.328 , 0.3271, 0.3264, 0.3262,\n",
       "            0.3237, 0.3223, 0.3218, 0.3213, 0.321 , 0.3208, 0.3206, 0.32  ,\n",
       "            0.3193, 0.3176, 0.3171, 0.3167, 0.3162, 0.3157, 0.3154, 0.3127,\n",
       "            0.3125, 0.312 , 0.3113, 0.311 , 0.31  , 0.308 , 0.3076, 0.3074,\n",
       "            0.3062, 0.3057, 0.3054, 0.305 , 0.3044, 0.3037, 0.3013, 0.3005,\n",
       "            0.2996, 0.299 , 0.2988, 0.2952, 0.2944, 0.2937, 0.2925, 0.2908,\n",
       "            0.2905, 0.2896, 0.2883, 0.288 , 0.2874, 0.287 , 0.2864, 0.286 ,\n",
       "            0.2852, 0.2837, 0.2834, 0.2832, 0.283 , 0.2822, 0.2815, 0.2812,\n",
       "            0.281 , 0.2805, 0.2803, 0.2795, 0.2788, 0.2786, 0.2778, 0.2754,\n",
       "            0.2751, 0.2747, 0.2742, 0.2732, 0.2727, 0.2722, 0.272 , 0.2712,\n",
       "            0.2708, 0.27  , 0.2686, 0.268 , 0.2673, 0.2668, 0.2664, 0.2656,\n",
       "            0.2654, 0.2646, 0.2632, 0.262 , 0.2605, 0.2603, 0.259 , 0.2585,\n",
       "            0.2583, 0.258 , 0.256 , 0.2551, 0.2544, 0.2542, 0.2527, 0.2524,\n",
       "            0.252 , 0.2507, 0.2502, 0.25  , 0.2494, 0.249 , 0.2487, 0.2478,\n",
       "            0.2474, 0.247 , 0.2438, 0.2437, 0.2429, 0.2418, 0.2417, 0.2394,\n",
       "            0.2379, 0.237 , 0.2363, 0.236 , 0.2358, 0.2356, 0.2355, 0.2347,\n",
       "            0.2338, 0.2328, 0.2316, 0.2303, 0.2281, 0.2269, 0.226 , 0.2252,\n",
       "            0.2249, 0.2244, 0.2233, 0.2207, 0.219 , 0.2185, 0.2172, 0.2148,\n",
       "            0.2144, 0.2137, 0.2134, 0.2133, 0.2115, 0.2113, 0.2104, 0.21  ,\n",
       "            0.2068, 0.206 , 0.2047, 0.2037, 0.2032, 0.2028, 0.1991, 0.1985,\n",
       "            0.1981, 0.1976, 0.1971, 0.1968, 0.1965, 0.1962, 0.1959, 0.1946,\n",
       "            0.1886, 0.1815, 0.1803, 0.1785, 0.1783, 0.1771, 0.1759, 0.1744,\n",
       "            0.1731, 0.1704, 0.1672, 0.1664, 0.1444], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.41525424, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.59322035, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.69491524, 0.69491524, 0.7033898 , 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.8135593 , 0.8135593 , 0.8135593 , 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.83898306, 0.83898306, 0.83898306, 0.8559322 ,\n",
       "            0.8559322 , 0.86440676, 0.86440676, 0.87288135, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.8898305 , 0.8898305 , 0.8898305 ,\n",
       "            0.89830506, 0.89830506, 0.90677965, 0.90677965, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9237288 , 0.9237288 , 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.01515152, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.06818182, 0.07575758, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.09848485, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.12121212, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.13636364, 0.13636364, 0.14393939, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.1590909 , 0.17424242, 0.18181819,\n",
       "            0.18181819, 0.18181819, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.1969697 , 0.20454545, 0.21969697, 0.21969697, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.2651515 , 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.29545453, 0.29545453,\n",
       "            0.3030303 , 0.3030303 , 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.34848484, 0.3560606 , 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.37878788, 0.38636363, 0.38636363,\n",
       "            0.38636363, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.4090909 , 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.4318182 , 0.4469697 , 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3845 , 0.3628 , 0.3623 , 0.3547 , 0.3418 , 0.3416 ,\n",
       "            0.3389 , 0.335  , 0.333  , 0.332  , 0.3298 , 0.3289 , 0.3281 ,\n",
       "            0.328  , 0.3247 , 0.3245 , 0.3237 , 0.3225 , 0.322  , 0.3218 ,\n",
       "            0.3215 , 0.3206 , 0.32   , 0.317  , 0.3157 , 0.3154 , 0.315  ,\n",
       "            0.3145 , 0.3118 , 0.3115 , 0.3108 , 0.3105 , 0.3103 , 0.3093 ,\n",
       "            0.3054 , 0.3047 , 0.3042 , 0.3027 , 0.302  , 0.3013 , 0.3008 ,\n",
       "            0.3005 , 0.2983 , 0.2976 , 0.297  , 0.2964 , 0.2961 , 0.296  ,\n",
       "            0.2954 , 0.294  , 0.2937 , 0.2922 , 0.292  , 0.2917 , 0.2913 ,\n",
       "            0.2908 , 0.2869 , 0.2864 , 0.2861 , 0.2854 , 0.2852 , 0.2844 ,\n",
       "            0.2834 , 0.2812 , 0.28   , 0.2788 , 0.278  , 0.2773 , 0.2764 ,\n",
       "            0.276  , 0.2756 , 0.275  , 0.2747 , 0.2737 , 0.273  , 0.272  ,\n",
       "            0.2695 , 0.2683 , 0.2676 , 0.267  , 0.2634 , 0.263  , 0.2627 ,\n",
       "            0.262  , 0.2612 , 0.2588 , 0.2583 , 0.2576 , 0.2573 , 0.2566 ,\n",
       "            0.256  , 0.2556 , 0.2551 , 0.2542 , 0.2537 , 0.253  , 0.2522 ,\n",
       "            0.251  , 0.25   , 0.2493 , 0.2487 , 0.2485 , 0.248  , 0.2477 ,\n",
       "            0.2474 , 0.2462 , 0.2438 , 0.2422 , 0.2406 , 0.2405 , 0.2395 ,\n",
       "            0.2386 , 0.2384 , 0.2383 , 0.2382 , 0.2378 , 0.2366 , 0.2362 ,\n",
       "            0.236  , 0.2356 , 0.2355 , 0.2339 , 0.2338 , 0.2335 , 0.2334 ,\n",
       "            0.2323 , 0.2318 , 0.2311 , 0.2302 , 0.2301 , 0.2292 , 0.2285 ,\n",
       "            0.2278 , 0.2273 , 0.2249 , 0.2247 , 0.2242 , 0.2238 , 0.2229 ,\n",
       "            0.2227 , 0.2224 , 0.2208 , 0.2207 , 0.22   , 0.2194 , 0.2189 ,\n",
       "            0.2179 , 0.2175 , 0.2167 , 0.2163 , 0.2162 , 0.2157 , 0.2156 ,\n",
       "            0.2152 , 0.215  , 0.2147 , 0.2144 , 0.2133 , 0.2113 , 0.2109 ,\n",
       "            0.2104 , 0.209  , 0.2085 , 0.2065 , 0.2042 , 0.2029 , 0.2028 ,\n",
       "            0.2024 , 0.202  , 0.2017 , 0.2009 , 0.1998 , 0.1996 , 0.1991 ,\n",
       "            0.1978 , 0.1971 , 0.1952 , 0.1937 , 0.1929 , 0.1925 , 0.1924 ,\n",
       "            0.1917 , 0.1907 , 0.1906 , 0.19   , 0.1898 , 0.1876 , 0.1871 ,\n",
       "            0.1866 , 0.185  , 0.183  , 0.1823 , 0.1815 , 0.1814 , 0.1807 ,\n",
       "            0.1805 , 0.1803 , 0.1799 , 0.1787 , 0.178  , 0.1755 , 0.1754 ,\n",
       "            0.1747 , 0.1741 , 0.174  , 0.173  , 0.1726 , 0.1724 , 0.1683 ,\n",
       "            0.1653 , 0.1636 , 0.16   , 0.1581 , 0.1567 , 0.1556 , 0.1548 ,\n",
       "            0.1531 , 0.153  , 0.1517 , 0.1489 , 0.1459 , 0.1455 , 0.1454 ,\n",
       "            0.12463], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.21186441, 0.23728813,\n",
       "            0.2457627 , 0.26271185, 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.34745762, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.37288135, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7033898 , 0.7033898 ,\n",
       "            0.7118644 , 0.7118644 , 0.7118644 , 0.7118644 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7288136 , 0.7288136 , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.779661  , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.7966102 , 0.7966102 , 0.7966102 ,\n",
       "            0.80508476, 0.80508476, 0.8220339 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.8305085 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.8559322 , 0.8559322 , 0.8559322 , 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.87288135, 0.88135594, 0.88135594,\n",
       "            0.8898305 , 0.8898305 , 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.91525424, 0.9237288 ,\n",
       "            0.9237288 , 0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.06818182, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.12121212, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.13636364, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.15151516, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.1969697 , 0.1969697 , 0.1969697 , 0.1969697 ,\n",
       "            0.1969697 , 0.20454545, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.34848484, 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.37878788, 0.38636363, 0.38636363,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.7651515 , 0.7651515 ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3665, 0.3452, 0.345 , 0.3367, 0.3267, 0.3245, 0.32  ,\n",
       "            0.3188, 0.3164, 0.315 , 0.3145, 0.313 , 0.31  , 0.3098, 0.3096,\n",
       "            0.3086, 0.308 , 0.3074, 0.3064, 0.3052, 0.305 , 0.3037, 0.3032,\n",
       "            0.302 , 0.2976, 0.2969, 0.2966, 0.2957, 0.2925, 0.292 , 0.2908,\n",
       "            0.2888, 0.288 , 0.2874, 0.287 , 0.2869, 0.286 , 0.2856, 0.285 ,\n",
       "            0.2837, 0.2793, 0.279 , 0.2788, 0.2786, 0.278 , 0.277 , 0.2769,\n",
       "            0.2766, 0.275 , 0.2742, 0.2727, 0.2698, 0.2695, 0.2688, 0.2686,\n",
       "            0.268 , 0.2676, 0.2651, 0.2622, 0.2612, 0.259 , 0.2583, 0.2576,\n",
       "            0.2573, 0.256 , 0.2559, 0.2556, 0.2544, 0.2542, 0.254 , 0.251 ,\n",
       "            0.2505, 0.2477, 0.2471, 0.2467, 0.2463, 0.2458, 0.2456, 0.2455,\n",
       "            0.2426, 0.2421, 0.2418, 0.2406, 0.2402, 0.2388, 0.2382, 0.2379,\n",
       "            0.2374, 0.2368, 0.2367, 0.2346, 0.2344, 0.2327, 0.2323, 0.2316,\n",
       "            0.2313, 0.2307, 0.2302, 0.2299, 0.2297, 0.2292, 0.2286, 0.2281,\n",
       "            0.2278, 0.2277, 0.2274, 0.2273, 0.2261, 0.2257, 0.2255, 0.2238,\n",
       "            0.2234, 0.2224, 0.2216, 0.2213, 0.2212, 0.2203, 0.2202, 0.2198,\n",
       "            0.2189, 0.2184, 0.218 , 0.2179, 0.2177, 0.2173, 0.2161, 0.2158,\n",
       "            0.2156, 0.215 , 0.2145, 0.2144, 0.213 , 0.2129, 0.2123, 0.2119,\n",
       "            0.2109, 0.2108, 0.2101, 0.2096, 0.2089, 0.2085, 0.2076, 0.2065,\n",
       "            0.2063, 0.206 , 0.2056, 0.2053, 0.205 , 0.2047, 0.2045, 0.2042,\n",
       "            0.2028, 0.2023, 0.202 , 0.2018, 0.2004, 0.2001, 0.2   , 0.1993,\n",
       "            0.1984, 0.1982, 0.1974, 0.1973, 0.1971, 0.1959, 0.1948, 0.1942,\n",
       "            0.1941, 0.194 , 0.1936, 0.1935, 0.1925, 0.1918, 0.1907, 0.189 ,\n",
       "            0.1887, 0.1879, 0.1873, 0.1866, 0.1865, 0.1863, 0.186 , 0.1859,\n",
       "            0.1841, 0.1827, 0.1819, 0.1814, 0.1813, 0.181 , 0.1803, 0.18  ,\n",
       "            0.1799, 0.1794, 0.1785, 0.1782, 0.1781, 0.1774, 0.1731, 0.1707,\n",
       "            0.17  , 0.1677, 0.1653, 0.1649, 0.1648, 0.1636, 0.1621, 0.1616,\n",
       "            0.161 , 0.16  , 0.1594, 0.1573, 0.1543, 0.1542, 0.1539, 0.1527,\n",
       "            0.1506, 0.1343], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.37288135, 0.38135594, 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.5       , 0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 , 0.5508475 ,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.66101694, 0.6694915 , 0.6694915 , 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7118644 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.7118644 , 0.7118644 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.720339  , 0.720339  ,\n",
       "            0.720339  , 0.720339  , 0.720339  , 0.720339  , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.80508476, 0.80508476, 0.80508476, 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8220339 , 0.8305085 , 0.8305085 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.84745765, 0.84745765,\n",
       "            0.84745765, 0.84745765, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.86440676, 0.86440676, 0.87288135, 0.88135594, 0.88135594,\n",
       "            0.8898305 , 0.8898305 , 0.8898305 , 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9237288 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.06818182, 0.07575758, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09090909, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.13636364, 0.13636364, 0.13636364, 0.13636364,\n",
       "            0.14393939, 0.14393939, 0.14393939, 0.15151516, 0.15151516,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.22727273, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.59090906, 0.6060606 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.79545456,\n",
       "            0.79545456, 0.79545456, 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3489, 0.3289, 0.3281, 0.3203, 0.314 , 0.3096, 0.309 ,\n",
       "            0.3042, 0.3032, 0.3013, 0.301 , 0.3008, 0.2996, 0.2986, 0.2969,\n",
       "            0.2954, 0.295 , 0.2947, 0.2937, 0.2905, 0.289 , 0.2883, 0.2864,\n",
       "            0.286 , 0.2854, 0.285 , 0.2837, 0.2825, 0.2805, 0.2803, 0.28  ,\n",
       "            0.2795, 0.2788, 0.2786, 0.277 , 0.2744, 0.2727, 0.2725, 0.272 ,\n",
       "            0.2717, 0.271 , 0.2698, 0.2686, 0.2678, 0.2666, 0.2664, 0.2646,\n",
       "            0.2644, 0.2637, 0.2627, 0.2615, 0.2605, 0.259 , 0.258 , 0.2573,\n",
       "            0.2556, 0.2542, 0.2527, 0.2522, 0.2512, 0.2498, 0.2494, 0.2478,\n",
       "            0.2477, 0.2473, 0.2467, 0.2458, 0.2445, 0.2438, 0.2437, 0.2428,\n",
       "            0.2422, 0.2402, 0.2395, 0.239 , 0.2388, 0.2383, 0.2375, 0.237 ,\n",
       "            0.2366, 0.2363, 0.236 , 0.235 , 0.2347, 0.2346, 0.2344, 0.2338,\n",
       "            0.2306, 0.2303, 0.2302, 0.2295, 0.2294, 0.229 , 0.2286, 0.2274,\n",
       "            0.2266, 0.2257, 0.2246, 0.2242, 0.2235, 0.223 , 0.2224, 0.2222,\n",
       "            0.222 , 0.2211, 0.2207, 0.2205, 0.2198, 0.2197, 0.2191, 0.219 ,\n",
       "            0.2189, 0.2185, 0.2177, 0.2173, 0.2168, 0.2166, 0.215 , 0.2148,\n",
       "            0.2144, 0.2137, 0.2133, 0.2129, 0.2125, 0.2123, 0.212 , 0.2118,\n",
       "            0.2114, 0.2108, 0.2104, 0.2101, 0.21  , 0.2098, 0.2096, 0.2095,\n",
       "            0.2091, 0.2085, 0.2079, 0.2076, 0.2074, 0.2073, 0.207 , 0.2065,\n",
       "            0.2063, 0.2056, 0.2054, 0.2053, 0.2039, 0.2035, 0.2032, 0.2031,\n",
       "            0.2024, 0.2021, 0.202 , 0.2009, 0.2007, 0.2004, 0.2001, 0.1998,\n",
       "            0.1996, 0.1993, 0.1991, 0.199 , 0.1989, 0.1987, 0.1985, 0.1984,\n",
       "            0.1979, 0.1976, 0.1974, 0.1967, 0.1965, 0.1958, 0.1954, 0.195 ,\n",
       "            0.1943, 0.1942, 0.1934, 0.1929, 0.1913, 0.1909, 0.1907, 0.19  ,\n",
       "            0.1892, 0.1887, 0.1885, 0.1859, 0.1858, 0.1846, 0.183 , 0.1827,\n",
       "            0.1826, 0.1823, 0.1819, 0.1816, 0.1805, 0.1791, 0.179 , 0.1788,\n",
       "            0.1776, 0.1771, 0.1766, 0.1764, 0.1759, 0.1758, 0.1757, 0.1753,\n",
       "            0.1733, 0.1707, 0.1687, 0.1664, 0.1663, 0.1578, 0.1567, 0.1562,\n",
       "            0.1449, 0.1427], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.21186441, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.43220338, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.59322035, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6694915 , 0.6694915 , 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.720339  ,\n",
       "            0.720339  , 0.720339  , 0.7288136 , 0.7288136 , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8220339 , 0.8305085 , 0.8305085 ,\n",
       "            0.83898306, 0.83898306, 0.86440676, 0.87288135, 0.89830506,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9915254 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.06818182, 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.14393939, 0.15151516, 0.15151516, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.18939394,\n",
       "            0.18939394, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.42424244, 0.42424244, 0.4318182 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.57575756, 0.5833333 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.7121212 , 0.719697  , 0.7348485 ,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.82575756, 0.8333333 , 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.334 , 0.3137, 0.3127, 0.305 , 0.3035, 0.3013, 0.2974,\n",
       "            0.297 , 0.2966, 0.2961, 0.2947, 0.2944, 0.2925, 0.2922, 0.2917,\n",
       "            0.2915, 0.2913, 0.289 , 0.2852, 0.2832, 0.282 , 0.2817, 0.2805,\n",
       "            0.279 , 0.2786, 0.2776, 0.277 , 0.2769, 0.2764, 0.2737, 0.2725,\n",
       "            0.2712, 0.271 , 0.2708, 0.2693, 0.2627, 0.2622, 0.2615, 0.2612,\n",
       "            0.26  , 0.2573, 0.257 , 0.2563, 0.256 , 0.2551, 0.255 , 0.2534,\n",
       "            0.2532, 0.2524, 0.2512, 0.251 , 0.2505, 0.25  , 0.2494, 0.2485,\n",
       "            0.2473, 0.2471, 0.2467, 0.2466, 0.2462, 0.2458, 0.2456, 0.2449,\n",
       "            0.2445, 0.2444, 0.2437, 0.2428, 0.2426, 0.2415, 0.2411, 0.241 ,\n",
       "            0.2407, 0.2406, 0.2401, 0.2394, 0.239 , 0.2386, 0.2378, 0.2372,\n",
       "            0.2363, 0.236 , 0.2358, 0.2355, 0.2346, 0.2344, 0.2338, 0.2332,\n",
       "            0.2328, 0.2325, 0.2323, 0.2318, 0.2314, 0.2313, 0.2311, 0.2306,\n",
       "            0.2302, 0.2301, 0.2295, 0.2294, 0.2292, 0.2281, 0.228 , 0.2278,\n",
       "            0.2274, 0.2273, 0.2272, 0.2266, 0.2264, 0.2263, 0.2261, 0.2244,\n",
       "            0.2239, 0.2234, 0.2233, 0.2229, 0.2225, 0.2224, 0.2218, 0.2217,\n",
       "            0.2216, 0.2211, 0.2208, 0.2202, 0.22  , 0.2179, 0.2175, 0.2173,\n",
       "            0.2172, 0.217 , 0.2168, 0.2167, 0.2161, 0.2158, 0.2152, 0.2142,\n",
       "            0.214 , 0.2135, 0.2123, 0.2119, 0.2113, 0.2109, 0.2101, 0.21  ,\n",
       "            0.2096, 0.2091, 0.2086, 0.2085, 0.2084, 0.208 , 0.2075, 0.2064,\n",
       "            0.2054, 0.2053, 0.2051, 0.2037, 0.2023, 0.2021, 0.2018, 0.2017,\n",
       "            0.2013, 0.2004, 0.2001, 0.2   , 0.1989, 0.1985, 0.1982, 0.1976,\n",
       "            0.1965, 0.1953, 0.1948, 0.1946, 0.1937, 0.1927, 0.1923, 0.1912,\n",
       "            0.1904, 0.189 , 0.1887, 0.1882, 0.1848, 0.1836, 0.1833, 0.183 ,\n",
       "            0.1819, 0.1814, 0.1804, 0.1803, 0.1796, 0.177 , 0.1763, 0.1758,\n",
       "            0.1752, 0.1719, 0.1716, 0.1692, 0.164 , 0.1587, 0.1573, 0.1486,\n",
       "            0.1342], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.2457627 , 0.2457627 ,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.2881356 , 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.2881356 , 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.37288135, 0.38135594, 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5508475 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7118644 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8135593 , 0.8135593 ,\n",
       "            0.8135593 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.8559322 , 0.87288135, 0.88135594, 0.88135594, 0.88135594,\n",
       "            0.88135594, 0.8898305 , 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.9237288 , 0.9237288 , 0.9237288 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.94067794, 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.04545455,\n",
       "            0.06060606, 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.15151516,\n",
       "            0.16666667, 0.18939394, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25757575, 0.2651515 ,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.3181818 , 0.3409091 , 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.40151516, 0.4090909 ,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6136364 , 0.6136364 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.75      , 0.75      , 0.75757575, 0.75757575,\n",
       "            0.75757575, 0.7651515 , 0.7651515 , 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3242, 0.3005, 0.3   , 0.2998, 0.2983, 0.298 , 0.2974,\n",
       "            0.295 , 0.2944, 0.2935, 0.2927, 0.2925, 0.2913, 0.2903, 0.29  ,\n",
       "            0.2874, 0.2869, 0.2864, 0.2847, 0.2844, 0.2837, 0.283 , 0.281 ,\n",
       "            0.28  , 0.2778, 0.2766, 0.2754, 0.2751, 0.2742, 0.274 , 0.2737,\n",
       "            0.2734, 0.2732, 0.2727, 0.2725, 0.2722, 0.272 , 0.2717, 0.2712,\n",
       "            0.271 , 0.2708, 0.2703, 0.27  , 0.2695, 0.2693, 0.2688, 0.2683,\n",
       "            0.268 , 0.2678, 0.2673, 0.267 , 0.2668, 0.2664, 0.266 , 0.2659,\n",
       "            0.2656, 0.2654, 0.2646, 0.2642, 0.264 , 0.2637, 0.2632, 0.263 ,\n",
       "            0.2627, 0.2625, 0.2622, 0.262 , 0.2605, 0.26  , 0.2595, 0.2588,\n",
       "            0.2573, 0.2563, 0.256 , 0.2551, 0.2544, 0.254 , 0.252 , 0.2515,\n",
       "            0.251 , 0.2507, 0.2502, 0.25  , 0.2498, 0.2496, 0.2493, 0.2489,\n",
       "            0.2487, 0.2478, 0.2474, 0.2473, 0.247 , 0.2463, 0.2462, 0.2456,\n",
       "            0.2452, 0.2433, 0.2426, 0.2417, 0.2397, 0.2394, 0.2391, 0.2386,\n",
       "            0.2383, 0.2382, 0.2379, 0.2368, 0.2355, 0.2343, 0.2339, 0.2334,\n",
       "            0.2323, 0.2322, 0.2319, 0.2311, 0.2306, 0.2302, 0.2301, 0.2297,\n",
       "            0.2281, 0.2278, 0.2277, 0.2274, 0.2272, 0.226 , 0.2257, 0.2251,\n",
       "            0.2239, 0.2234, 0.223 , 0.2229, 0.2224, 0.2222, 0.2218, 0.2208,\n",
       "            0.2205, 0.2203, 0.22  , 0.2197, 0.2191, 0.2189, 0.2177, 0.2168,\n",
       "            0.2167, 0.2161, 0.215 , 0.2148, 0.213 , 0.2129, 0.2128, 0.2125,\n",
       "            0.2124, 0.2123, 0.212 , 0.2106, 0.2101, 0.21  , 0.2098, 0.2086,\n",
       "            0.208 , 0.2076, 0.2073, 0.207 , 0.2069, 0.2068, 0.2056, 0.2047,\n",
       "            0.2043, 0.2028, 0.2012, 0.2004, 0.2001, 0.2   , 0.1995, 0.1987,\n",
       "            0.1985, 0.1968, 0.1967, 0.1962, 0.1958, 0.1953, 0.1952, 0.1948,\n",
       "            0.1943, 0.1942, 0.1934, 0.1927, 0.1912, 0.1907, 0.1904, 0.189 ,\n",
       "            0.1886, 0.1871, 0.1863, 0.1857, 0.1855, 0.1837, 0.1803, 0.173 ,\n",
       "            0.1699, 0.1698, 0.1647, 0.1608, 0.1277], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.2881356 , 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.40677965,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.4915254 , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.7033898 , 0.720339  , 0.720339  ,\n",
       "            0.720339  , 0.720339  , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.779661  , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8135593 , 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.83898306, 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.88135594, 0.8898305 , 0.8898305 ,\n",
       "            0.89830506, 0.89830506, 0.89830506, 0.89830506, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03787879, 0.04545455,\n",
       "            0.06060606, 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.11363637, 0.12121212, 0.15151516, 0.1590909 , 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.27272728,\n",
       "            0.28030303, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.4318182 , 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.47727272, 0.47727272, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.47727272, 0.47727272, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.74242425, 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3247 , 0.3245 , 0.3242 , 0.324  , 0.3237 , 0.3235 ,\n",
       "            0.3203 , 0.3196 , 0.319  , 0.3188 , 0.3179 , 0.3176 , 0.3174 ,\n",
       "            0.3171 , 0.3162 , 0.316  , 0.3157 , 0.3154 , 0.3152 , 0.315  ,\n",
       "            0.3147 , 0.3145 , 0.314  , 0.3137 , 0.3135 , 0.3108 , 0.31   ,\n",
       "            0.3086 , 0.3083 , 0.3074 , 0.306  , 0.3047 , 0.304  , 0.3037 ,\n",
       "            0.3035 , 0.3032 , 0.302  , 0.3018 , 0.3005 , 0.3003 , 0.2998 ,\n",
       "            0.2996 , 0.298  , 0.2969 , 0.2966 , 0.2957 , 0.2954 , 0.2942 ,\n",
       "            0.2922 , 0.292  , 0.2915 , 0.2913 , 0.2905 , 0.2903 , 0.2898 ,\n",
       "            0.2896 , 0.2893 , 0.288  , 0.2874 , 0.2864 , 0.2852 , 0.285  ,\n",
       "            0.2847 , 0.2837 , 0.2827 , 0.2825 , 0.2817 , 0.2815 , 0.2786 ,\n",
       "            0.2776 , 0.2751 , 0.2742 , 0.2737 , 0.2732 , 0.2727 , 0.27   ,\n",
       "            0.2698 , 0.269  , 0.2673 , 0.2646 , 0.2622 , 0.262  , 0.2595 ,\n",
       "            0.258  , 0.2576 , 0.2573 , 0.2568 , 0.256  , 0.254  , 0.2534 ,\n",
       "            0.2532 , 0.2527 , 0.2522 , 0.252  , 0.2517 , 0.25   , 0.2496 ,\n",
       "            0.2494 , 0.248  , 0.2478 , 0.2477 , 0.2474 , 0.246  , 0.2452 ,\n",
       "            0.2437 , 0.2434 , 0.243  , 0.2426 , 0.2422 , 0.2418 , 0.2415 ,\n",
       "            0.2411 , 0.2406 , 0.2402 , 0.2401 , 0.2395 , 0.2391 , 0.2382 ,\n",
       "            0.2372 , 0.2363 , 0.2362 , 0.236  , 0.2352 , 0.2344 , 0.234  ,\n",
       "            0.2334 , 0.233  , 0.2328 , 0.2325 , 0.2319 , 0.2314 , 0.231  ,\n",
       "            0.2307 , 0.2299 , 0.2285 , 0.2281 , 0.228  , 0.2278 , 0.2268 ,\n",
       "            0.2266 , 0.226  , 0.2256 , 0.2251 , 0.2249 , 0.2242 , 0.2238 ,\n",
       "            0.2234 , 0.223  , 0.2227 , 0.222  , 0.2208 , 0.2203 , 0.2198 ,\n",
       "            0.2197 , 0.2184 , 0.2177 , 0.2175 , 0.2173 , 0.2168 , 0.2166 ,\n",
       "            0.2162 , 0.2153 , 0.215  , 0.2148 , 0.2142 , 0.2133 , 0.2125 ,\n",
       "            0.2119 , 0.2118 , 0.2115 , 0.2114 , 0.211  , 0.2109 , 0.2104 ,\n",
       "            0.2091 , 0.209  , 0.2089 , 0.208  , 0.2075 , 0.2064 , 0.2051 ,\n",
       "            0.2045 , 0.2034 , 0.2032 , 0.2026 , 0.2018 , 0.2013 , 0.2004 ,\n",
       "            0.1993 , 0.199  , 0.1989 , 0.1984 , 0.1981 , 0.1978 , 0.1967 ,\n",
       "            0.1935 , 0.1901 , 0.1885 , 0.1869 , 0.1842 , 0.1821 , 0.177  ,\n",
       "            0.1735 , 0.1476 , 0.12146], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.38135594,\n",
       "            0.3983051 , 0.3983051 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5423729 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.63559324, 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6694915 , 0.6779661 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.80508476, 0.80508476, 0.8135593 ,\n",
       "            0.8135593 , 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.9237288 ,\n",
       "            0.9237288 , 0.94067794, 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.59090906, 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6060606 , 0.6060606 , 0.6212121 ,\n",
       "            0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.6818182 , 0.6818182 , 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.72727275, 0.74242425,\n",
       "            0.75      , 0.75      , 0.75      , 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3994, 0.3892, 0.3884, 0.3875, 0.387 , 0.3855, 0.385 ,\n",
       "            0.3826, 0.3813, 0.3806, 0.38  , 0.3772, 0.376 , 0.373 , 0.3713,\n",
       "            0.3704, 0.3699, 0.3696, 0.3684, 0.3667, 0.3662, 0.366 , 0.3655,\n",
       "            0.3652, 0.364 , 0.3618, 0.361 , 0.3606, 0.3596, 0.359 , 0.3577,\n",
       "            0.357 , 0.3564, 0.3562, 0.356 , 0.3535, 0.3496, 0.349 , 0.345 ,\n",
       "            0.3438, 0.3435, 0.343 , 0.3403, 0.3389, 0.3384, 0.3354, 0.3337,\n",
       "            0.333 , 0.3323, 0.3318, 0.328 , 0.327 , 0.3267, 0.3235, 0.3203,\n",
       "            0.3162, 0.3105, 0.31  , 0.3093, 0.309 , 0.308 , 0.304 , 0.3035,\n",
       "            0.301 , 0.2988, 0.2986, 0.2976, 0.2961, 0.294 , 0.2937, 0.2932,\n",
       "            0.2908, 0.2903, 0.2898, 0.2896, 0.2886, 0.2878, 0.2864, 0.285 ,\n",
       "            0.2847, 0.283 , 0.2815, 0.2808, 0.2805, 0.2795, 0.2783, 0.2769,\n",
       "            0.2756, 0.2754, 0.275 , 0.2742, 0.2737, 0.2722, 0.272 , 0.2712,\n",
       "            0.2705, 0.2693, 0.2683, 0.2673, 0.2651, 0.2646, 0.2612, 0.2607,\n",
       "            0.2603, 0.2598, 0.259 , 0.2563, 0.256 , 0.2542, 0.2537, 0.2522,\n",
       "            0.252 , 0.2517, 0.2515, 0.2512, 0.251 , 0.2494, 0.249 , 0.2485,\n",
       "            0.2482, 0.2477, 0.2473, 0.2471, 0.247 , 0.2467, 0.246 , 0.2458,\n",
       "            0.2456, 0.2452, 0.2451, 0.2438, 0.2422, 0.2418, 0.2407, 0.2397,\n",
       "            0.237 , 0.2363, 0.236 , 0.2356, 0.2351, 0.235 , 0.2347, 0.2339,\n",
       "            0.2338, 0.2335, 0.2332, 0.233 , 0.2327, 0.2325, 0.2323, 0.2318,\n",
       "            0.2316, 0.2313, 0.231 , 0.2301, 0.2299, 0.2297, 0.2294, 0.2292,\n",
       "            0.229 , 0.2289, 0.2286, 0.2285, 0.2281, 0.2277, 0.2273, 0.2268,\n",
       "            0.2264, 0.2249, 0.2244, 0.2235, 0.2233, 0.2225, 0.2218, 0.2208,\n",
       "            0.2207, 0.2198, 0.2197, 0.218 , 0.2179, 0.2177, 0.2173, 0.2168,\n",
       "            0.2166, 0.2142, 0.2133, 0.2124, 0.212 , 0.2118, 0.2115, 0.2113,\n",
       "            0.2096, 0.2095, 0.2094, 0.208 , 0.2079, 0.2063, 0.206 , 0.2045,\n",
       "            0.2042, 0.204 , 0.2039, 0.2023, 0.2021, 0.202 , 0.2018, 0.2006,\n",
       "            0.186 , 0.1826, 0.1622, 0.1371, 0.1172], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.3644068 ,\n",
       "            0.3644068 , 0.3644068 , 0.37288135, 0.38135594, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.40677965, 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6864407 ,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.88135594, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25757575, 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.4469697 , 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4822 , 0.4607 , 0.4604 , 0.4592 , 0.4568 , 0.4546 ,\n",
       "            0.4534 , 0.448  , 0.4478 , 0.4465 , 0.4458 , 0.4434 , 0.4353 ,\n",
       "            0.4294 , 0.4287 , 0.4282 , 0.426  , 0.4258 , 0.4255 , 0.4243 ,\n",
       "            0.4226 , 0.4204 , 0.42   , 0.4187 , 0.418  , 0.4163 , 0.416  ,\n",
       "            0.4124 , 0.412  , 0.4094 , 0.4077 , 0.4043 , 0.403  , 0.4028 ,\n",
       "            0.3923 , 0.3916 , 0.3914 , 0.3894 , 0.3887 , 0.3865 , 0.3813 ,\n",
       "            0.3787 , 0.3772 , 0.3767 , 0.3726 , 0.3691 , 0.3672 , 0.3665 ,\n",
       "            0.3662 , 0.3652 , 0.3564 , 0.353  , 0.347  , 0.3455 , 0.3442 ,\n",
       "            0.3257 , 0.3223 , 0.3213 , 0.3184 , 0.3176 , 0.3171 , 0.3167 ,\n",
       "            0.3115 , 0.311  , 0.3105 , 0.308  , 0.3076 , 0.3071 , 0.306  ,\n",
       "            0.3057 , 0.3027 , 0.3018 , 0.3013 , 0.3008 , 0.3    , 0.2988 ,\n",
       "            0.2983 , 0.2979 , 0.2976 , 0.2957 , 0.2952 , 0.2915 , 0.2913 ,\n",
       "            0.2903 , 0.2898 , 0.2869 , 0.286  , 0.2854 , 0.2844 , 0.2832 ,\n",
       "            0.281  , 0.2805 , 0.2798 , 0.2795 , 0.2783 , 0.2773 , 0.2769 ,\n",
       "            0.2764 , 0.2747 , 0.2744 , 0.2742 , 0.2722 , 0.2717 , 0.2715 ,\n",
       "            0.2712 , 0.2708 , 0.27   , 0.269  , 0.268  , 0.2676 , 0.2673 ,\n",
       "            0.267  , 0.2668 , 0.2666 , 0.2664 , 0.2659 , 0.2654 , 0.265  ,\n",
       "            0.2644 , 0.2637 , 0.2612 , 0.261  , 0.2605 , 0.26   , 0.2588 ,\n",
       "            0.2585 , 0.2576 , 0.2573 , 0.257  , 0.2568 , 0.256  , 0.2559 ,\n",
       "            0.2556 , 0.2554 , 0.2542 , 0.2537 , 0.2534 , 0.2532 , 0.2527 ,\n",
       "            0.252  , 0.251  , 0.2505 , 0.2496 , 0.2494 , 0.2489 , 0.2477 ,\n",
       "            0.2466 , 0.246  , 0.2451 , 0.2445 , 0.2441 , 0.244  , 0.2438 ,\n",
       "            0.2437 , 0.2433 , 0.243  , 0.2429 , 0.2428 , 0.2418 , 0.2417 ,\n",
       "            0.2415 , 0.2413 , 0.2411 , 0.2407 , 0.2402 , 0.2397 , 0.2395 ,\n",
       "            0.2384 , 0.2383 , 0.2382 , 0.2378 , 0.2375 , 0.2374 , 0.2372 ,\n",
       "            0.2367 , 0.2362 , 0.2356 , 0.2347 , 0.2339 , 0.2338 , 0.2335 ,\n",
       "            0.2332 , 0.2328 , 0.2325 , 0.2323 , 0.2322 , 0.2316 , 0.2297 ,\n",
       "            0.2292 , 0.2285 , 0.2278 , 0.2277 , 0.2272 , 0.2261 , 0.226  ,\n",
       "            0.2257 , 0.2255 , 0.2249 , 0.2244 , 0.223  , 0.2229 , 0.2225 ,\n",
       "            0.222  , 0.2217 , 0.2213 , 0.219  , 0.2186 , 0.2173 , 0.2167 ,\n",
       "            0.2161 , 0.2158 , 0.2147 , 0.2059 , 0.2047 , 0.2026 , 0.1981 ,\n",
       "            0.1954 , 0.1936 , 0.1907 , 0.1765 , 0.15   , 0.1254 , 0.11066],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.10606061, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.04237288, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3559322 , 0.37288135, 0.37288135, 0.38135594, 0.38135594,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.3983051 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.5677966 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6694915 , 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.720339  , 0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.7966102 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8220339 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.23484848, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.4848485 , 0.4848485 ,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.67424244, 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.7348485 , 0.7348485 , 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.74242425, 0.75      , 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.8030303 , 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8560606 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5684, 0.536 , 0.5347, 0.5303, 0.526 , 0.524 , 0.519 ,\n",
       "            0.5186, 0.5166, 0.5156, 0.5146, 0.51  , 0.5015, 0.4915, 0.4912,\n",
       "            0.4902, 0.488 , 0.4856, 0.4854, 0.4849, 0.4844, 0.4775, 0.4768,\n",
       "            0.475 , 0.474 , 0.4734, 0.4717, 0.467 , 0.4656, 0.462 , 0.4604,\n",
       "            0.4592, 0.455 , 0.454 , 0.453 , 0.4443, 0.4377, 0.4373, 0.4358,\n",
       "            0.435 , 0.4302, 0.43  , 0.421 , 0.416 , 0.415 , 0.4143, 0.4067,\n",
       "            0.4038, 0.4001, 0.3997, 0.3862, 0.3833, 0.3794, 0.3762, 0.3738,\n",
       "            0.3552, 0.3474, 0.3372, 0.3364, 0.3345, 0.3333, 0.333 , 0.3325,\n",
       "            0.3276, 0.324 , 0.323 , 0.3218, 0.321 , 0.317 , 0.3154, 0.3147,\n",
       "            0.3132, 0.313 , 0.3125, 0.311 , 0.31  , 0.3071, 0.306 , 0.3042,\n",
       "            0.3018, 0.2993, 0.2988, 0.298 , 0.2969, 0.295 , 0.2944, 0.2932,\n",
       "            0.292 , 0.2913, 0.2905, 0.289 , 0.2886, 0.288 , 0.2874, 0.2864,\n",
       "            0.286 , 0.2854, 0.285 , 0.2847, 0.2844, 0.2837, 0.2834, 0.2832,\n",
       "            0.2822, 0.2817, 0.2808, 0.2805, 0.2803, 0.28  , 0.278 , 0.2776,\n",
       "            0.2773, 0.277 , 0.2766, 0.2734, 0.2732, 0.2727, 0.2725, 0.2717,\n",
       "            0.2715, 0.2712, 0.271 , 0.2708, 0.27  , 0.269 , 0.2683, 0.2678,\n",
       "            0.2668, 0.2666, 0.2664, 0.2654, 0.2646, 0.2644, 0.264 , 0.2637,\n",
       "            0.2632, 0.263 , 0.2625, 0.2617, 0.2607, 0.2605, 0.2603, 0.2595,\n",
       "            0.2593, 0.259 , 0.258 , 0.257 , 0.2568, 0.2559, 0.255 , 0.2542,\n",
       "            0.2532, 0.253 , 0.2527, 0.2524, 0.252 , 0.2515, 0.251 , 0.2507,\n",
       "            0.2505, 0.2502, 0.2496, 0.2489, 0.2483, 0.248 , 0.2467, 0.2463,\n",
       "            0.2462, 0.2458, 0.2455, 0.2452, 0.2445, 0.244 , 0.2434, 0.2428,\n",
       "            0.2424, 0.2422, 0.2417, 0.2413, 0.2394, 0.2374, 0.2372, 0.2366,\n",
       "            0.2358, 0.2339, 0.2338, 0.2332, 0.2318, 0.2303, 0.2299, 0.2277,\n",
       "            0.2268, 0.2252, 0.2249, 0.2246, 0.2218, 0.219 , 0.2173, 0.2158,\n",
       "            0.2144, 0.2139, 0.2125, 0.2073, 0.2029, 0.1993, 0.1906, 0.1897,\n",
       "            0.188 , 0.178 , 0.1752, 0.1693, 0.1372, 0.1134, 0.1036],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.29545453, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.26271185, 0.26271185, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.34745762, 0.3559322 , 0.3644068 , 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.48305085, 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.60169494, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.65254235, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.779661  , 0.779661  ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.87288135, 0.88135594, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.15151516, 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.21212122,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.653  , 0.612  , 0.611  , 0.6045 , 0.5986 , 0.596  ,\n",
       "            0.5913 , 0.591  , 0.588  , 0.5864 , 0.586  , 0.579  , 0.5684 ,\n",
       "            0.556  , 0.5557 , 0.5537 , 0.5522 , 0.549  , 0.5483 , 0.5474 ,\n",
       "            0.5386 , 0.5366 , 0.5356 , 0.5337 , 0.5327 , 0.525  , 0.524  ,\n",
       "            0.5225 , 0.5176 , 0.5166 , 0.515  , 0.51   , 0.509  , 0.5063 ,\n",
       "            0.4985 , 0.4888 , 0.4883 , 0.4849 , 0.484  , 0.4812 , 0.4768 ,\n",
       "            0.4663 , 0.4614 , 0.459  , 0.4587 , 0.4575 , 0.45   , 0.4434 ,\n",
       "            0.4407 , 0.437  , 0.4214 , 0.4167 , 0.4165 , 0.4094 , 0.4058 ,\n",
       "            0.3926 , 0.3743 , 0.3643 , 0.3608 , 0.36   , 0.3574 , 0.3567 ,\n",
       "            0.3562 , 0.3503 , 0.3484 , 0.3457 , 0.345  , 0.3425 , 0.3396 ,\n",
       "            0.3315 , 0.3308 , 0.3306 , 0.3289 , 0.3264 , 0.3245 , 0.321  ,\n",
       "            0.3206 , 0.3203 , 0.318  , 0.3171 , 0.3152 , 0.3135 , 0.313  ,\n",
       "            0.3118 , 0.3083 , 0.3042 , 0.3032 , 0.3018 , 0.3015 , 0.3013 ,\n",
       "            0.3003 , 0.2998 , 0.2983 , 0.2976 , 0.2969 , 0.2966 , 0.2961 ,\n",
       "            0.2944 , 0.2935 , 0.2932 , 0.293  , 0.2925 , 0.292  , 0.2917 ,\n",
       "            0.2915 , 0.2903 , 0.2893 , 0.2888 , 0.288  , 0.2874 , 0.287  ,\n",
       "            0.2869 , 0.2856 , 0.2854 , 0.2852 , 0.2837 , 0.282  , 0.281  ,\n",
       "            0.2795 , 0.2793 , 0.2788 , 0.2786 , 0.278  , 0.2778 , 0.277  ,\n",
       "            0.2764 , 0.2751 , 0.2744 , 0.2725 , 0.2722 , 0.272  , 0.2708 ,\n",
       "            0.27   , 0.2695 , 0.269  , 0.2686 , 0.268  , 0.2676 , 0.2673 ,\n",
       "            0.2666 , 0.2664 , 0.2659 , 0.2644 , 0.2642 , 0.264  , 0.2637 ,\n",
       "            0.2625 , 0.2617 , 0.2612 , 0.2607 , 0.2605 , 0.26   , 0.2595 ,\n",
       "            0.259  , 0.2588 , 0.258  , 0.2578 , 0.2566 , 0.256  , 0.2559 ,\n",
       "            0.2556 , 0.255  , 0.2546 , 0.2542 , 0.2534 , 0.2532 , 0.2524 ,\n",
       "            0.2522 , 0.252  , 0.25   , 0.2493 , 0.2489 , 0.2485 , 0.2483 ,\n",
       "            0.2474 , 0.2471 , 0.247  , 0.2467 , 0.2466 , 0.2463 , 0.2451 ,\n",
       "            0.244  , 0.2429 , 0.2405 , 0.2395 , 0.2391 , 0.236  , 0.2328 ,\n",
       "            0.2323 , 0.2318 , 0.2313 , 0.229  , 0.2281 , 0.2218 , 0.2167 ,\n",
       "            0.2124 , 0.2109 , 0.2084 , 0.2042 , 0.202  , 0.1953 , 0.191  ,\n",
       "            0.1855 , 0.1831 , 0.1758 , 0.1646 , 0.1641 , 0.1605 , 0.1268 ,\n",
       "            0.10394, 0.0991 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.37121212, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.22881356, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.31355932, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.37288135, 0.3898305 , 0.3898305 ,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.4661017 , 0.47457626, 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.55932206, 0.5762712 , 0.5762712 , 0.59322035,\n",
       "            0.59322035, 0.59322035, 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.69491524,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.7288136 , 0.7288136 ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.5984849 , 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.8333333 , 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7246 , 0.6787 , 0.6777 , 0.67   , 0.6636 , 0.6606 ,\n",
       "            0.6567 , 0.6553 , 0.6514 , 0.651  , 0.649  , 0.6406 , 0.63   ,\n",
       "            0.6143 , 0.6113 , 0.611  , 0.6074 , 0.606  , 0.6055 , 0.6045 ,\n",
       "            0.5933 , 0.5923 , 0.5913 , 0.5903 , 0.59   , 0.5884 , 0.579  ,\n",
       "            0.5786 , 0.5757 , 0.5693 , 0.569  , 0.5664 , 0.562  , 0.5586 ,\n",
       "            0.556  , 0.551  , 0.538  , 0.5376 , 0.5312 , 0.5303 , 0.529  ,\n",
       "            0.5215 , 0.5103 , 0.5083 , 0.502  , 0.4998 , 0.497  , 0.4924 ,\n",
       "            0.4814 , 0.4775 , 0.472  , 0.4543 , 0.4536 , 0.449  , 0.4421 ,\n",
       "            0.4348 , 0.4338 , 0.3977 , 0.3928 , 0.3916 , 0.39   , 0.3884 ,\n",
       "            0.3865 , 0.3845 , 0.3801 , 0.3782 , 0.3704 , 0.37   , 0.3647 ,\n",
       "            0.3625 , 0.3567 , 0.3555 , 0.3464 , 0.3457 , 0.3455 , 0.3384 ,\n",
       "            0.338  , 0.3367 , 0.3357 , 0.3354 , 0.3345 , 0.3342 , 0.3323 ,\n",
       "            0.332  , 0.3306 , 0.3293 , 0.3289 , 0.3281 , 0.328  , 0.3247 ,\n",
       "            0.3228 , 0.3223 , 0.3215 , 0.32   , 0.319  , 0.3186 , 0.3174 ,\n",
       "            0.3171 , 0.3145 , 0.314  , 0.3125 , 0.311  , 0.3105 , 0.3098 ,\n",
       "            0.3093 , 0.307  , 0.3064 , 0.3062 , 0.3052 , 0.3047 , 0.304  ,\n",
       "            0.3022 , 0.3008 , 0.298  , 0.2976 , 0.2969 , 0.2961 , 0.296  ,\n",
       "            0.2944 , 0.2935 , 0.2927 , 0.2925 , 0.292  , 0.2917 , 0.2915 ,\n",
       "            0.2908 , 0.2903 , 0.29   , 0.2898 , 0.2896 , 0.289  , 0.2886 ,\n",
       "            0.2883 , 0.2878 , 0.287  , 0.2864 , 0.2861 , 0.285  , 0.2842 ,\n",
       "            0.284  , 0.2827 , 0.2825 , 0.2822 , 0.282  , 0.281  , 0.2805 ,\n",
       "            0.28   , 0.2795 , 0.2788 , 0.2776 , 0.2773 , 0.277  , 0.2769 ,\n",
       "            0.2766 , 0.276  , 0.2751 , 0.2744 , 0.2742 , 0.274  , 0.2737 ,\n",
       "            0.2734 , 0.2725 , 0.2722 , 0.2717 , 0.2715 , 0.2698 , 0.269  ,\n",
       "            0.268  , 0.2678 , 0.2673 , 0.2664 , 0.266  , 0.2659 , 0.2644 ,\n",
       "            0.2642 , 0.264  , 0.2632 , 0.263  , 0.2627 , 0.26   , 0.2578 ,\n",
       "            0.257  , 0.2566 , 0.256  , 0.2544 , 0.2542 , 0.2517 , 0.2515 ,\n",
       "            0.2512 , 0.249  , 0.248  , 0.2471 , 0.2466 , 0.2462 , 0.246  ,\n",
       "            0.2452 , 0.2417 , 0.2415 , 0.239  , 0.2384 , 0.2216 , 0.2133 ,\n",
       "            0.2101 , 0.2048 , 0.2039 , 0.2032 , 0.2006 , 0.1952 , 0.1948 ,\n",
       "            0.1942 , 0.1887 , 0.1794 , 0.1782 , 0.1759 , 0.1627 , 0.1572 ,\n",
       "            0.1509 , 0.1471 , 0.1158 , 0.0937 , 0.09235], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.4090909, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.19491525, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.2457627 , 0.2457627 ,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.37288135, 0.37288135,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5508475 , 0.5508475 , 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.720339  , 0.720339  , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.56060606, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 , 0.6136364 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.7878788 , 0.7878788 , 0.79545456,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7866 , 0.7397 , 0.739  , 0.7383 , 0.7305 , 0.7227 ,\n",
       "            0.7197 , 0.717  , 0.715  , 0.711  , 0.7095 , 0.7075 , 0.6987 ,\n",
       "            0.687  , 0.67   , 0.669  , 0.666  , 0.6655 , 0.662  , 0.661  ,\n",
       "            0.66   , 0.6597 , 0.647  , 0.646  , 0.6445 , 0.644  , 0.642  ,\n",
       "            0.6416 , 0.6323 , 0.6313 , 0.6274 , 0.62   , 0.6177 , 0.613  ,\n",
       "            0.6084 , 0.6055 , 0.601  , 0.586  , 0.5796 , 0.576  , 0.574  ,\n",
       "            0.566  , 0.5537 , 0.545  , 0.541  , 0.5376 , 0.534  , 0.52   ,\n",
       "            0.5156 , 0.508  , 0.491  , 0.4868 , 0.4817 , 0.475  , 0.4712 ,\n",
       "            0.4648 , 0.4214 , 0.42   , 0.4194 , 0.4192 , 0.418  , 0.4172 ,\n",
       "            0.4119 , 0.4065 , 0.4036 , 0.399  , 0.3975 , 0.386  , 0.3809 ,\n",
       "            0.377  , 0.3733 , 0.3708 , 0.3684 , 0.3635 , 0.3604 , 0.3599 ,\n",
       "            0.3591 , 0.3557 , 0.3555 , 0.355  , 0.3538 , 0.3477 , 0.3457 ,\n",
       "            0.345  , 0.343  , 0.3425 , 0.3396 , 0.3376 , 0.337  , 0.3357 ,\n",
       "            0.3345 , 0.334  , 0.3333 , 0.3328 , 0.3298 , 0.3293 , 0.3284 ,\n",
       "            0.3274 , 0.326  , 0.3254 , 0.3245 , 0.323  , 0.3228 , 0.321  ,\n",
       "            0.3186 , 0.3145 , 0.3142 , 0.3137 , 0.3125 , 0.312  , 0.3103 ,\n",
       "            0.31   , 0.3096 , 0.309  , 0.3083 , 0.3064 , 0.3047 , 0.3037 ,\n",
       "            0.3032 , 0.3022 , 0.302  , 0.3018 , 0.301  , 0.3    , 0.2998 ,\n",
       "            0.299  , 0.2986 , 0.2974 , 0.2969 , 0.2966 , 0.2957 , 0.2947 ,\n",
       "            0.2935 , 0.2932 , 0.293  , 0.2927 , 0.2925 , 0.2922 , 0.2917 ,\n",
       "            0.2905 , 0.2898 , 0.2893 , 0.2888 , 0.2886 , 0.2874 , 0.287  ,\n",
       "            0.2864 , 0.2844 , 0.2842 , 0.2832 , 0.283  , 0.282  , 0.2817 ,\n",
       "            0.2805 , 0.2803 , 0.28   , 0.2793 , 0.279  , 0.2788 , 0.2786 ,\n",
       "            0.2783 , 0.2776 , 0.277  , 0.2756 , 0.2751 , 0.275  , 0.2742 ,\n",
       "            0.274  , 0.2732 , 0.272  , 0.2715 , 0.2712 , 0.271  , 0.2708 ,\n",
       "            0.27   , 0.2688 , 0.2659 , 0.2654 , 0.2642 , 0.2637 , 0.2625 ,\n",
       "            0.2622 , 0.262  , 0.2612 , 0.259  , 0.2578 , 0.2576 , 0.2559 ,\n",
       "            0.2551 , 0.2546 , 0.2537 , 0.2534 , 0.2458 , 0.2452 , 0.2422 ,\n",
       "            0.2401 , 0.2379 , 0.2358 , 0.235  , 0.215  , 0.2051 , 0.2037 ,\n",
       "            0.1973 , 0.1967 , 0.1959 , 0.1925 , 0.1877 , 0.1865 , 0.1852 ,\n",
       "            0.1823 , 0.171  , 0.1688 , 0.1687 , 0.1511 , 0.1499 , 0.1393 ,\n",
       "            0.1354 , 0.1056 , 0.0857 , 0.08417], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.4469697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.37288135, 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.4661017 , 0.48305085, 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.59322035, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.63559324, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.720339  , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46212122, 0.46969697, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.5984849 ,\n",
       "            0.6060606 , 0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6287879 , 0.6287879 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.68939394, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.81060606, 0.8181818 , 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.84090906, 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8712121 ,\n",
       "            0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.9015151 , 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.838  , 0.792  , 0.791  , 0.7905 , 0.783  , 0.775  ,\n",
       "            0.772  , 0.7715 , 0.7686 , 0.7656 , 0.7607 , 0.76   , 0.7505 ,\n",
       "            0.7407 , 0.722  , 0.7207 , 0.718  , 0.716  , 0.715  , 0.714  ,\n",
       "            0.7104 , 0.709  , 0.7085 , 0.6987 , 0.697  , 0.6953 , 0.694  ,\n",
       "            0.6934 , 0.6904 , 0.6846 , 0.6807 , 0.677  , 0.669  , 0.668  ,\n",
       "            0.665  , 0.6626 , 0.655  , 0.653  , 0.6523 , 0.635  , 0.6294 ,\n",
       "            0.6196 , 0.6167 , 0.61   , 0.6016 , 0.598  , 0.589  , 0.5815 ,\n",
       "            0.578  , 0.5767 , 0.559  , 0.5503 , 0.5435 , 0.5317 , 0.5186 ,\n",
       "            0.5176 , 0.515  , 0.51   , 0.4932 , 0.4658 , 0.458  , 0.4553 ,\n",
       "            0.455  , 0.4524 , 0.4429 , 0.442  , 0.4414 , 0.4348 , 0.4214 ,\n",
       "            0.4165 , 0.4148 , 0.4116 , 0.406  , 0.3987 , 0.3977 , 0.396  ,\n",
       "            0.3926 , 0.391  , 0.3909 , 0.39   , 0.3877 , 0.3853 , 0.384  ,\n",
       "            0.3801 , 0.378  , 0.3718 , 0.3716 , 0.369  , 0.3657 , 0.363  ,\n",
       "            0.36   , 0.3591 , 0.3584 , 0.358  , 0.356  , 0.3538 , 0.3525 ,\n",
       "            0.35   , 0.3486 , 0.3484 , 0.3442 , 0.3428 , 0.3425 , 0.342  ,\n",
       "            0.3416 , 0.3406 , 0.34   , 0.3389 , 0.3364 , 0.335  , 0.3325 ,\n",
       "            0.3318 , 0.3315 , 0.3289 , 0.3284 , 0.3281 , 0.326  , 0.3252 ,\n",
       "            0.3247 , 0.324  , 0.3228 , 0.3218 , 0.3215 , 0.3213 , 0.3198 ,\n",
       "            0.3179 , 0.3174 , 0.3171 , 0.316  , 0.3154 , 0.315  , 0.3145 ,\n",
       "            0.3127 , 0.3125 , 0.3123 , 0.3115 , 0.3113 , 0.3108 , 0.3096 ,\n",
       "            0.3083 , 0.3062 , 0.3054 , 0.3052 , 0.305  , 0.3047 , 0.3042 ,\n",
       "            0.304  , 0.3035 , 0.3032 , 0.3022 , 0.302  , 0.3018 , 0.3005 ,\n",
       "            0.2993 , 0.299  , 0.2988 , 0.2986 , 0.2974 , 0.297  , 0.2966 ,\n",
       "            0.2964 , 0.2954 , 0.295  , 0.2925 , 0.2915 , 0.2913 , 0.291  ,\n",
       "            0.2908 , 0.2905 , 0.2903 , 0.2898 , 0.2893 , 0.289  , 0.288  ,\n",
       "            0.2876 , 0.2874 , 0.2861 , 0.286  , 0.2852 , 0.2844 , 0.283  ,\n",
       "            0.282  , 0.2803 , 0.2795 , 0.277  , 0.2769 , 0.2766 , 0.276  ,\n",
       "            0.2754 , 0.274  , 0.2725 , 0.2686 , 0.2683 , 0.267  , 0.2607 ,\n",
       "            0.256  , 0.254  , 0.2418 , 0.2402 , 0.2384 , 0.2358 , 0.234  ,\n",
       "            0.2299 , 0.2283 , 0.2074 , 0.1967 , 0.1958 , 0.1887 , 0.188  ,\n",
       "            0.1871 , 0.1833 , 0.1787 , 0.1766 , 0.1754 , 0.1736 , 0.1616 ,\n",
       "            0.1593 , 0.1581 , 0.1403 , 0.1393 , 0.1277 , 0.1236 , 0.0945 ,\n",
       "            0.0772 , 0.07385], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.46969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.58474576, 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.6101695 , 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7118644 , 0.720339  ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.7121212 , 0.7121212 , 0.7121212 ,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8794 , 0.838  , 0.837  , 0.836  , 0.829  , 0.822  ,\n",
       "            0.8193 , 0.819  , 0.816  , 0.8135 , 0.807  , 0.7974 , 0.7886 ,\n",
       "            0.7705 , 0.768  , 0.766  , 0.763  , 0.7627 , 0.7617 , 0.757  ,\n",
       "            0.756  , 0.7554 , 0.7476 , 0.744  , 0.743  , 0.7417 , 0.741  ,\n",
       "            0.738  , 0.733  , 0.728  , 0.724  , 0.7163 , 0.715  , 0.7114 ,\n",
       "            0.7104 , 0.7017 , 0.7007 , 0.6987 , 0.682  , 0.6816 , 0.6777 ,\n",
       "            0.6636 , 0.66   , 0.654  , 0.6484 , 0.642  , 0.633  , 0.6235 ,\n",
       "            0.6216 , 0.617  , 0.599  , 0.589  , 0.5806 , 0.5728 , 0.564  ,\n",
       "            0.5522 , 0.5503 , 0.546  , 0.525  , 0.512  , 0.5005 , 0.4973 ,\n",
       "            0.4934 , 0.4907 , 0.4858 , 0.4763 , 0.4727 , 0.4712 , 0.4688 ,\n",
       "            0.4636 , 0.455  , 0.4517 , 0.4456 , 0.4407 , 0.4385 , 0.4382 ,\n",
       "            0.436  , 0.4324 , 0.431  , 0.429  , 0.4272 , 0.4263 , 0.4211 ,\n",
       "            0.4143 , 0.412  , 0.4065 , 0.401  , 0.3997 , 0.3962 , 0.3933 ,\n",
       "            0.3894 , 0.389  , 0.3884 , 0.3877 , 0.3865 , 0.3816 , 0.3792 ,\n",
       "            0.3748 , 0.3696 , 0.3657 , 0.3655 , 0.3645 , 0.3608 , 0.3604 ,\n",
       "            0.3594 , 0.3586 , 0.3584 , 0.3582 , 0.3577 , 0.356  , 0.355  ,\n",
       "            0.3538 , 0.3525 , 0.3516 , 0.3503 , 0.3499 , 0.3484 , 0.3474 ,\n",
       "            0.344  , 0.3425 , 0.3416 , 0.3408 , 0.3398 , 0.339  , 0.337  ,\n",
       "            0.3367 , 0.3364 , 0.335  , 0.3335 , 0.3328 , 0.3325 , 0.3323 ,\n",
       "            0.3313 , 0.3286 , 0.3284 , 0.3281 , 0.3276 , 0.327  , 0.325  ,\n",
       "            0.3247 , 0.3242 , 0.3232 , 0.323  , 0.3228 , 0.321  , 0.3208 ,\n",
       "            0.32   , 0.3198 , 0.3196 , 0.3188 , 0.3186 , 0.3174 , 0.3171 ,\n",
       "            0.317  , 0.3167 , 0.3162 , 0.3154 , 0.315  , 0.314  , 0.3115 ,\n",
       "            0.3105 , 0.3098 , 0.308  , 0.3064 , 0.3054 , 0.3052 , 0.305  ,\n",
       "            0.3044 , 0.3042 , 0.3032 , 0.303  , 0.3027 , 0.3022 , 0.302  ,\n",
       "            0.3013 , 0.3003 , 0.2993 , 0.2979 , 0.2964 , 0.2961 , 0.296  ,\n",
       "            0.2952 , 0.295  , 0.2935 , 0.293  , 0.292  , 0.2913 , 0.2898 ,\n",
       "            0.2893 , 0.288  , 0.2861 , 0.2854 , 0.28   , 0.2795 , 0.277  ,\n",
       "            0.2708 , 0.2646 , 0.2585 , 0.255  , 0.2517 , 0.2406 , 0.2352 ,\n",
       "            0.2319 , 0.2301 , 0.2246 , 0.2222 , 0.2009 , 0.1891 , 0.1815 ,\n",
       "            0.181  , 0.1792 , 0.1754 , 0.1716 , 0.1676 , 0.167  , 0.1665 ,\n",
       "            0.1544 , 0.1521 , 0.1475 , 0.133  , 0.1284 , 0.1166 , 0.1126 ,\n",
       "            0.0854 , 0.07104, 0.0656 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.02542373, dtype=float32),\n",
       "    'tpr': array(0.4848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33898306, 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.66101694, 0.66101694, 0.6694915 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.50757575, 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6439394 , 0.6439394 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.7651515 , 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.77272725, 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.81060606, 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9043 , 0.866  , 0.8657 , 0.8647 , 0.858  , 0.851  ,\n",
       "            0.849  , 0.848  , 0.8457 , 0.8433 , 0.837  , 0.8276 , 0.8193 ,\n",
       "            0.801  , 0.799  , 0.797  , 0.7944 , 0.7935 , 0.7925 , 0.7876 ,\n",
       "            0.7866 , 0.7856 , 0.7783 , 0.7744 , 0.774  , 0.772  , 0.7686 ,\n",
       "            0.7637 , 0.7593 , 0.755  , 0.747  , 0.7456 , 0.7417 , 0.741  ,\n",
       "            0.7324 , 0.7305 , 0.7295 , 0.7124 , 0.712  , 0.708  , 0.6924 ,\n",
       "            0.6885 , 0.682  , 0.6772 , 0.6704 , 0.6606 , 0.6504 , 0.6484 ,\n",
       "            0.643  , 0.624  , 0.612  , 0.604  , 0.596  , 0.589  , 0.5728 ,\n",
       "            0.572  , 0.567  , 0.543  , 0.5356 , 0.524  , 0.5166 , 0.512  ,\n",
       "            0.5093 , 0.5034 , 0.4927 , 0.488  , 0.4856 , 0.4802 , 0.473  ,\n",
       "            0.4673 , 0.4568 , 0.456  , 0.4556 , 0.4524 , 0.4507 , 0.45   ,\n",
       "            0.4456 , 0.4443 , 0.4426 , 0.4424 , 0.4365 , 0.4287 , 0.4258 ,\n",
       "            0.4114 , 0.4111 , 0.41   , 0.408  , 0.4004 , 0.399  , 0.3987 ,\n",
       "            0.3982 , 0.3962 , 0.396  , 0.3936 , 0.3928 , 0.3865 , 0.3804 ,\n",
       "            0.3718 , 0.371  , 0.3674 , 0.3672 , 0.365  , 0.363  , 0.3616 ,\n",
       "            0.3613 , 0.3604 , 0.3586 , 0.3572 , 0.3567 , 0.354  , 0.3506 ,\n",
       "            0.35   , 0.3499 , 0.3486 , 0.3481 , 0.3464 , 0.3457 , 0.345  ,\n",
       "            0.3447 , 0.3442 , 0.3435 , 0.3408 , 0.3376 , 0.3372 , 0.3362 ,\n",
       "            0.3354 , 0.3352 , 0.335  , 0.333  , 0.3328 , 0.3325 , 0.3318 ,\n",
       "            0.3315 , 0.329  , 0.3289 , 0.3276 , 0.327  , 0.3264 , 0.3262 ,\n",
       "            0.326  , 0.3252 , 0.325  , 0.3245 , 0.3242 , 0.324  , 0.3235 ,\n",
       "            0.3215 , 0.321  , 0.3208 , 0.3206 , 0.3198 , 0.3196 , 0.3188 ,\n",
       "            0.318  , 0.3179 , 0.317  , 0.3167 , 0.3154 , 0.3118 , 0.3108 ,\n",
       "            0.3103 , 0.3086 , 0.3074 , 0.3066 , 0.306  , 0.3054 , 0.3052 ,\n",
       "            0.3044 , 0.3032 , 0.3027 , 0.3015 , 0.3013 , 0.3005 , 0.3    ,\n",
       "            0.2996 , 0.298  , 0.2961 , 0.2957 , 0.2947 , 0.2944 , 0.294  ,\n",
       "            0.2932 , 0.2925 , 0.2915 , 0.291  , 0.2908 , 0.2898 , 0.2878 ,\n",
       "            0.2864 , 0.2844 , 0.279  , 0.278  , 0.2747 , 0.2732 , 0.2722 ,\n",
       "            0.2625 , 0.2563 , 0.2502 , 0.2466 , 0.243  , 0.2335 , 0.2319 ,\n",
       "            0.2266 , 0.2224 , 0.22   , 0.215  , 0.213  , 0.1901 , 0.1781 ,\n",
       "            0.1775 , 0.1696 , 0.1694 , 0.1674 , 0.1636 , 0.16   , 0.1556 ,\n",
       "            0.155  , 0.1431 , 0.1409 , 0.1357 , 0.122  , 0.11694, 0.1056 ,\n",
       "            0.1019 , 0.0752 , 0.06244, 0.05676], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.05084746, dtype=float32),\n",
       "    'tpr': array(0.5151515, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.33050847, 0.33050847, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5423729 ,\n",
       "            0.5508475 , 0.5677966 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.6101695 , 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.929  , 0.896  , 0.8955 , 0.895  , 0.8887 , 0.8823 ,\n",
       "            0.882  , 0.88   , 0.8784 , 0.8765 , 0.87   , 0.8696 , 0.861  ,\n",
       "            0.8545 , 0.837  , 0.8345 , 0.833  , 0.8306 , 0.829  , 0.8286 ,\n",
       "            0.8228 , 0.8223 , 0.8213 , 0.816  , 0.8105 , 0.8086 , 0.808  ,\n",
       "            0.8047 , 0.801  , 0.7964 , 0.7925 , 0.7847 , 0.783  , 0.78   ,\n",
       "            0.779  , 0.7725 , 0.768  , 0.767  , 0.752  , 0.7515 , 0.7485 ,\n",
       "            0.7295 , 0.725  , 0.719  , 0.717  , 0.709  , 0.6987 , 0.687  ,\n",
       "            0.6865 , 0.678  , 0.66   , 0.6455 , 0.637  , 0.6333 , 0.63   ,\n",
       "            0.6035 , 0.5996 , 0.578  , 0.5713 , 0.5684 , 0.553  , 0.548  ,\n",
       "            0.5425 , 0.535  , 0.532  , 0.526  , 0.523  , 0.5176 , 0.5107 ,\n",
       "            0.5024 , 0.5005 , 0.4949 , 0.4912 , 0.4883 , 0.488  , 0.4792 ,\n",
       "            0.479  , 0.4785 , 0.4773 , 0.475  , 0.4722 , 0.468  , 0.4531 ,\n",
       "            0.4407 , 0.437  , 0.432  , 0.4302 , 0.427  , 0.4263 , 0.4255 ,\n",
       "            0.425  , 0.4238 , 0.4211 , 0.418  , 0.4102 , 0.4094 , 0.4082 ,\n",
       "            0.4062 , 0.3938 , 0.3936 , 0.393  , 0.392  , 0.3901 , 0.3882 ,\n",
       "            0.386  , 0.38   , 0.3792 , 0.378  , 0.3777 , 0.3713 , 0.3704 ,\n",
       "            0.3687 , 0.3682 , 0.3677 , 0.3674 , 0.3672 , 0.364  , 0.3623 ,\n",
       "            0.362  , 0.3616 , 0.3613 , 0.361  , 0.3599 , 0.3584 , 0.3577 ,\n",
       "            0.356  , 0.3547 , 0.3538 , 0.353  , 0.351  , 0.35   , 0.3499 ,\n",
       "            0.3496 , 0.349  , 0.3477 , 0.3452 , 0.3442 , 0.3435 , 0.3428 ,\n",
       "            0.3425 , 0.342  , 0.3413 , 0.3403 , 0.3394 , 0.339  , 0.3386 ,\n",
       "            0.3381 , 0.338  , 0.3367 , 0.336  , 0.3354 , 0.3345 , 0.3342 ,\n",
       "            0.3335 , 0.3308 , 0.3293 , 0.329  , 0.3281 , 0.328  , 0.3267 ,\n",
       "            0.3252 , 0.3242 , 0.3223 , 0.3215 , 0.3206 , 0.3198 , 0.319  ,\n",
       "            0.3188 , 0.3184 , 0.318  , 0.3171 , 0.3162 , 0.316  , 0.3137 ,\n",
       "            0.312  , 0.3108 , 0.31   , 0.3086 , 0.3076 , 0.3052 , 0.304  ,\n",
       "            0.3032 , 0.3018 , 0.3015 , 0.299  , 0.2935 , 0.2932 , 0.292  ,\n",
       "            0.2903 , 0.2896 , 0.2856 , 0.2837 , 0.2825 , 0.2764 , 0.2722 ,\n",
       "            0.2705 , 0.259  , 0.2534 , 0.247  , 0.2434 , 0.2397 , 0.2328 ,\n",
       "            0.2286 , 0.2217 , 0.2179 , 0.214  , 0.2084 , 0.2073 , 0.1831 ,\n",
       "            0.1705 , 0.1697 , 0.1616 , 0.1614 , 0.1589 , 0.1554 , 0.1521 ,\n",
       "            0.148  , 0.1467 , 0.1462 , 0.135  , 0.1329 , 0.126  , 0.1142 ,\n",
       "            0.10724, 0.0962 , 0.0925 , 0.0672 , 0.05624, 0.04968],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.07627118, dtype=float32),\n",
       "    'tpr': array(0.5378788, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.30508474, 0.30508474, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33898306, 0.34745762, 0.3644068 , 0.37288135, 0.37288135,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.42372882, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.74242425, 0.74242425,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.77272725,\n",
       "            0.77272725, 0.77272725, 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.7878788 , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.82575756, 0.82575756,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9434 , 0.914  , 0.9136 , 0.9126 , 0.907  , 0.9014 ,\n",
       "            0.901  , 0.899  , 0.898  , 0.8965 , 0.8896 , 0.8804 , 0.8755 ,\n",
       "            0.859  , 0.8564 , 0.855  , 0.8535 , 0.851  , 0.8506 , 0.844  ,\n",
       "            0.8438 , 0.843  , 0.839  , 0.833  , 0.8325 , 0.831  , 0.8296 ,\n",
       "            0.8267 , 0.824  , 0.8193 , 0.8154 , 0.808  , 0.806  , 0.8037 ,\n",
       "            0.802  , 0.797  , 0.7905 , 0.79   , 0.7764 , 0.7754 , 0.7734 ,\n",
       "            0.752  , 0.747  , 0.7427 , 0.742  , 0.7324 , 0.723  , 0.7104 ,\n",
       "            0.7095 , 0.6997 , 0.682  , 0.6636 , 0.657  , 0.656  , 0.6553 ,\n",
       "            0.6226 , 0.6196 , 0.6187 , 0.606  , 0.5977 , 0.586  , 0.5757 ,\n",
       "            0.57   , 0.564  , 0.5625 , 0.554  , 0.546  , 0.545  , 0.5356 ,\n",
       "            0.535  , 0.5205 , 0.52   , 0.518  , 0.5107 , 0.5103 , 0.5083 ,\n",
       "            0.5034 , 0.501  , 0.4993 , 0.499  , 0.4949 , 0.4941 , 0.4907 ,\n",
       "            0.4888 , 0.4692 , 0.4587 , 0.455  , 0.4487 , 0.446  , 0.4438 ,\n",
       "            0.4434 , 0.4382 , 0.4358 , 0.4292 , 0.4287 , 0.4224 , 0.4126 ,\n",
       "            0.4116 , 0.4097 , 0.4077 , 0.4055 , 0.4053 , 0.4036 , 0.403  ,\n",
       "            0.4011 , 0.3936 , 0.387  , 0.386  , 0.3855 , 0.384  , 0.3833 ,\n",
       "            0.383  , 0.382  , 0.3816 , 0.3801 , 0.3757 , 0.3752 , 0.3735 ,\n",
       "            0.372  , 0.3718 , 0.3708 , 0.3706 , 0.3704 , 0.37   , 0.3687 ,\n",
       "            0.3672 , 0.367  , 0.3647 , 0.3638 , 0.3635 , 0.362  , 0.3604 ,\n",
       "            0.3591 , 0.3564 , 0.356  , 0.3557 , 0.3552 , 0.355  , 0.3547 ,\n",
       "            0.3542 , 0.3535 , 0.352  , 0.35   , 0.3477 , 0.3467 , 0.3464 ,\n",
       "            0.3462 , 0.346  , 0.3452 , 0.3442 , 0.3438 , 0.3418 , 0.341  ,\n",
       "            0.3408 , 0.3384 , 0.338  , 0.3374 , 0.3367 , 0.336  , 0.3357 ,\n",
       "            0.3354 , 0.3335 , 0.332  , 0.3313 , 0.331  , 0.3306 , 0.3296 ,\n",
       "            0.329  , 0.3289 , 0.3286 , 0.3281 , 0.328  , 0.3271 , 0.3262 ,\n",
       "            0.326  , 0.3254 , 0.3237 , 0.32   , 0.3196 , 0.3186 , 0.3167 ,\n",
       "            0.3162 , 0.311  , 0.3105 , 0.3098 , 0.3093 , 0.3086 , 0.3083 ,\n",
       "            0.3066 , 0.3044 , 0.3025 , 0.2988 , 0.2969 , 0.2966 , 0.2954 ,\n",
       "            0.2913 , 0.2878 , 0.2844 , 0.2795 , 0.2773 , 0.27   , 0.265  ,\n",
       "            0.2637 , 0.2522 , 0.2462 , 0.2391 , 0.2346 , 0.2314 , 0.223  ,\n",
       "            0.2189 , 0.2156 , 0.2068 , 0.2059 , 0.2006 , 0.2004 , 0.1735 ,\n",
       "            0.161  , 0.1588 , 0.1505 , 0.1483 , 0.1447 , 0.1411 , 0.1367 ,\n",
       "            0.1361 , 0.136  , 0.1241 , 0.1219 , 0.11676, 0.1034 , 0.09845,\n",
       "            0.0876 , 0.0845 , 0.059  , 0.04858, 0.04263], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.11016949, dtype=float32),\n",
       "    'tpr': array(0.5530303, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33898306, 0.3559322 ,\n",
       "            0.3559322 , 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.59322035, 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75757575, 0.7651515 , 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.77272725, 0.77272725, 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.7878788 , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.81060606, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8939394 , 0.9015151 , 0.90909094, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9575 , 0.932  , 0.931  , 0.927  , 0.922  , 0.9214 ,\n",
       "            0.919  , 0.9185 , 0.9175 , 0.911  , 0.903  , 0.899  , 0.8833 ,\n",
       "            0.881  , 0.88   , 0.8784 , 0.876  , 0.875  , 0.8696 , 0.869  ,\n",
       "            0.868  , 0.865  , 0.8594 , 0.8584 , 0.8574 , 0.856  , 0.853  ,\n",
       "            0.851  , 0.8457 , 0.8423 , 0.8354 , 0.8335 , 0.8315 , 0.829  ,\n",
       "            0.8257 , 0.8184 , 0.8057 , 0.8047 , 0.803  , 0.7803 , 0.776  ,\n",
       "            0.7725 , 0.7715 , 0.7617 , 0.7524 , 0.74   , 0.7383 , 0.728  ,\n",
       "            0.7104 , 0.6914 , 0.687  , 0.6846 , 0.648  , 0.645  , 0.6396 ,\n",
       "            0.633  , 0.61   , 0.6045 , 0.602  , 0.5986 , 0.5894 , 0.5796 ,\n",
       "            0.5728 , 0.5723 , 0.567  , 0.559  , 0.5513 , 0.5474 , 0.54   ,\n",
       "            0.5347 , 0.533  , 0.529  , 0.5273 , 0.5264 , 0.526  , 0.524  ,\n",
       "            0.5093 , 0.5083 , 0.4915 , 0.4824 , 0.4788 , 0.473  , 0.4724 ,\n",
       "            0.4663 , 0.4658 , 0.4644 , 0.4607 , 0.458  , 0.4558 , 0.4536 ,\n",
       "            0.4407 , 0.4377 , 0.4312 , 0.4277 , 0.423  , 0.4219 , 0.4216 ,\n",
       "            0.4204 , 0.4192 , 0.417  , 0.4124 , 0.4048 , 0.4023 , 0.402  ,\n",
       "            0.4016 , 0.4011 , 0.3992 , 0.3984 , 0.3965 , 0.3936 , 0.3933 ,\n",
       "            0.393  , 0.3916 , 0.3896 , 0.3892 , 0.386  , 0.3843 , 0.38   ,\n",
       "            0.3792 , 0.379  , 0.378  , 0.3762 , 0.3755 , 0.375  , 0.3735 ,\n",
       "            0.3733 , 0.3728 , 0.37   , 0.3696 , 0.3694 , 0.3682 , 0.3677 ,\n",
       "            0.3672 , 0.365  , 0.3635 , 0.361  , 0.3606 , 0.3586 , 0.3582 ,\n",
       "            0.3577 , 0.357  , 0.3564 , 0.3552 , 0.3542 , 0.3528 , 0.3525 ,\n",
       "            0.352  , 0.3516 , 0.3494 , 0.3489 , 0.3481 , 0.3477 , 0.3462 ,\n",
       "            0.3457 , 0.3452 , 0.3435 , 0.3433 , 0.343  , 0.3423 , 0.341  ,\n",
       "            0.3406 , 0.3394 , 0.339  , 0.3386 , 0.3384 , 0.3381 , 0.3372 ,\n",
       "            0.3333 , 0.3325 , 0.3315 , 0.3313 , 0.3293 , 0.326  , 0.3254 ,\n",
       "            0.3252 , 0.3208 , 0.32   , 0.3196 , 0.317  , 0.3164 , 0.3162 ,\n",
       "            0.3086 , 0.3071 , 0.307  , 0.3066 , 0.304  , 0.2957 , 0.2954 ,\n",
       "            0.2935 , 0.2925 , 0.2844 , 0.281  , 0.2756 , 0.2734 , 0.2656 ,\n",
       "            0.2612 , 0.259  , 0.2466 , 0.2406 , 0.2335 , 0.229  , 0.2256 ,\n",
       "            0.2194 , 0.2129 , 0.2086 , 0.1998 , 0.1985 , 0.1934 , 0.1929 ,\n",
       "            0.165  , 0.1526 , 0.1499 , 0.1416 , 0.1412 , 0.139  , 0.1355 ,\n",
       "            0.1323 , 0.128  , 0.1267 , 0.11536, 0.1134 , 0.1076 , 0.09515,\n",
       "            0.0896 , 0.0792 , 0.0763 , 0.05203, 0.04312, 0.03683],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.12711865, dtype=float32),\n",
       "    'tpr': array(0.56060606, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22033899, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75757575, 0.75757575, 0.7651515 , 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.79545456, 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.82575756, 0.8333333 , 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.968  , 0.9463 , 0.9453 , 0.9414 , 0.9375 , 0.9365 ,\n",
       "            0.9346 , 0.9336 , 0.9277 , 0.9272 , 0.92   , 0.917  , 0.903  ,\n",
       "            0.9004 , 0.8994 , 0.8984 , 0.896  , 0.895  , 0.8896 , 0.889  ,\n",
       "            0.888  , 0.886  , 0.8804 , 0.8794 , 0.8784 , 0.8765 , 0.874  ,\n",
       "            0.873  , 0.8677 , 0.864  , 0.8584 , 0.856  , 0.8545 , 0.8516 ,\n",
       "            0.849  , 0.842  , 0.8413 , 0.83   , 0.8296 , 0.8286 , 0.8047 ,\n",
       "            0.8    , 0.799  , 0.7964 , 0.7876 , 0.7783 , 0.766  , 0.7637 ,\n",
       "            0.7524 , 0.736  , 0.7153 , 0.714  , 0.71   , 0.7085 , 0.6714 ,\n",
       "            0.67   , 0.6685 , 0.6665 , 0.6646 , 0.636  , 0.631  , 0.6294 ,\n",
       "            0.6245 , 0.6133 , 0.603  , 0.5986 , 0.596  , 0.5957 , 0.5815 ,\n",
       "            0.5806 , 0.5728 , 0.566  , 0.5605 , 0.5586 , 0.5557 , 0.5547 ,\n",
       "            0.5527 , 0.5503 , 0.54   , 0.5264 , 0.526  , 0.511  , 0.504  ,\n",
       "            0.5005 , 0.4963 , 0.495  , 0.488  , 0.4868 , 0.4866 , 0.4763 ,\n",
       "            0.476  , 0.474  , 0.4607 , 0.4573 , 0.4514 , 0.4485 , 0.4438 ,\n",
       "            0.4402 , 0.439  , 0.4338 , 0.4297 , 0.4268 , 0.4226 , 0.4224 ,\n",
       "            0.4204 , 0.42   , 0.4177 , 0.4175 , 0.4155 , 0.4124 , 0.4119 ,\n",
       "            0.4092 , 0.4072 , 0.4055 , 0.3992 , 0.3977 , 0.3965 , 0.3953 ,\n",
       "            0.3945 , 0.392  , 0.3918 , 0.3904 , 0.3896 , 0.3894 , 0.3892 ,\n",
       "            0.3884 , 0.3882 , 0.3862 , 0.3853 , 0.385  , 0.3833 , 0.3816 ,\n",
       "            0.3809 , 0.3806 , 0.377  , 0.375  , 0.3726 , 0.3723 , 0.3716 ,\n",
       "            0.3699 , 0.369  , 0.3684 , 0.3682 , 0.3674 , 0.3647 , 0.3645 ,\n",
       "            0.363  , 0.3623 , 0.3618 , 0.3608 , 0.3606 , 0.358  , 0.3562 ,\n",
       "            0.356  , 0.3547 , 0.3538 , 0.3535 , 0.3533 , 0.3518 , 0.351  ,\n",
       "            0.3499 , 0.3489 , 0.3486 , 0.3477 , 0.3472 , 0.3467 , 0.3464 ,\n",
       "            0.3455 , 0.3445 , 0.336  , 0.3352 , 0.3315 , 0.3313 , 0.3298 ,\n",
       "            0.3296 , 0.3293 , 0.3286 , 0.328  , 0.3271 , 0.3257 , 0.324  ,\n",
       "            0.3215 , 0.3186 , 0.3132 , 0.3123 , 0.312  , 0.3035 , 0.3005 ,\n",
       "            0.3003 , 0.2915 , 0.2898 , 0.2795 , 0.2761 , 0.2708 , 0.2683 ,\n",
       "            0.2603 , 0.2556 , 0.2534 , 0.2401 , 0.234  , 0.2266 , 0.2218 ,\n",
       "            0.2185 , 0.2125 , 0.2048 , 0.2009 , 0.191  , 0.1904 , 0.1852 ,\n",
       "            0.1846 , 0.1562 , 0.1436 , 0.1403 , 0.1321 , 0.1316 , 0.1294 ,\n",
       "            0.1259 , 0.12286, 0.1188 , 0.1172 , 0.1063 , 0.1043 , 0.0986 ,\n",
       "            0.0863 , 0.08124, 0.0712 , 0.06854, 0.04535, 0.03754, 0.03143],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1440678, dtype=float32),\n",
       "    'tpr': array(0.6060606, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.37288135, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.3983051 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.70454544, 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.72727275, 0.72727275, 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8636364 , 0.8636364 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.976  , 0.959  , 0.9585 , 0.9575 , 0.954  , 0.9517 ,\n",
       "            0.95   , 0.9487 , 0.948  , 0.943  , 0.942  , 0.936  , 0.9336 ,\n",
       "            0.9214 , 0.919  , 0.9185 , 0.9175 , 0.915  , 0.9136 , 0.9087 ,\n",
       "            0.908  , 0.907  , 0.901  , 0.8994 , 0.899  , 0.8965 , 0.8945 ,\n",
       "            0.894  , 0.889  , 0.8853 , 0.8804 , 0.8784 , 0.877  , 0.874  ,\n",
       "            0.873  , 0.8647 , 0.8643 , 0.856  , 0.855  , 0.8296 , 0.827  ,\n",
       "            0.824  , 0.8223 , 0.815  , 0.806  , 0.795  , 0.7905 , 0.779  ,\n",
       "            0.7637 , 0.7505 , 0.7407 , 0.7383 , 0.735  , 0.7104 , 0.7075 ,\n",
       "            0.6987 , 0.6963 , 0.6904 , 0.685  , 0.6665 , 0.659  , 0.6523 ,\n",
       "            0.646  , 0.6367 , 0.635  , 0.634  , 0.629  , 0.627  , 0.6235 ,\n",
       "            0.61   , 0.609  , 0.606  , 0.6016 , 0.6006 , 0.5947 , 0.5933 ,\n",
       "            0.5913 , 0.5903 , 0.5864 , 0.5566 , 0.5527 , 0.5483 , 0.5425 ,\n",
       "            0.538  , 0.535  , 0.5347 , 0.5303 , 0.5273 , 0.52   , 0.5127 ,\n",
       "            0.5054 , 0.504  , 0.5    , 0.4858 , 0.4849 , 0.4731 , 0.4683 ,\n",
       "            0.4668 , 0.4604 , 0.4592 , 0.4548 , 0.4543 , 0.4539 , 0.4521 ,\n",
       "            0.4517 , 0.4507 , 0.4473 , 0.4468 , 0.446  , 0.4404 , 0.4395 ,\n",
       "            0.4375 , 0.432  , 0.4302 , 0.4294 , 0.4287 , 0.4243 , 0.4229 ,\n",
       "            0.4211 , 0.421  , 0.4207 , 0.4194 , 0.419  , 0.4182 , 0.4165 ,\n",
       "            0.4163 , 0.4158 , 0.4146 , 0.4097 , 0.4082 , 0.408  , 0.4072 ,\n",
       "            0.4001 , 0.4    , 0.3997 , 0.3992 , 0.399  , 0.3975 , 0.395  ,\n",
       "            0.3936 , 0.393  , 0.3914 , 0.3909 , 0.3896 , 0.3887 , 0.3867 ,\n",
       "            0.3848 , 0.3843 , 0.3833 , 0.3828 , 0.3823 , 0.382  , 0.3818 ,\n",
       "            0.3813 , 0.3801 , 0.38   , 0.3782 , 0.377  , 0.376  , 0.3752 ,\n",
       "            0.3733 , 0.3726 , 0.3723 , 0.372  , 0.3718 , 0.37   , 0.3696 ,\n",
       "            0.3684 , 0.368  , 0.367  , 0.3667 , 0.362  , 0.355  , 0.351  ,\n",
       "            0.35   , 0.3499 , 0.3496 , 0.3494 , 0.3474 , 0.3455 , 0.345  ,\n",
       "            0.3442 , 0.3438 , 0.3384 , 0.334  , 0.3315 , 0.3313 , 0.3306 ,\n",
       "            0.33   , 0.3262 , 0.3176 , 0.304  , 0.3008 , 0.2976 , 0.2908 ,\n",
       "            0.2893 , 0.2788 , 0.2754 , 0.2695 , 0.267  , 0.2585 , 0.2534 ,\n",
       "            0.2512 , 0.2374 , 0.231  , 0.2234 , 0.2179 , 0.2148 , 0.209  ,\n",
       "            0.1991 , 0.1967 , 0.1858 , 0.1849 , 0.1808 , 0.1799 , 0.1503 ,\n",
       "            0.1375 , 0.1333 , 0.1251 , 0.12463, 0.12244, 0.1188 , 0.1158 ,\n",
       "            0.1118 , 0.1105 , 0.1101 , 0.0993 , 0.0972 , 0.09204, 0.07965,\n",
       "            0.0752 , 0.06525, 0.0628 , 0.0403 , 0.0334 , 0.02737],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.16101696, dtype=float32),\n",
       "    'tpr': array(0.6287879, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22033899, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.2881356 , 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.33898306, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.37288135, 0.37288135, 0.37288135, 0.37288135,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.17424242, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.5378788 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.981  , 0.966  , 0.9653 , 0.9644 , 0.962  , 0.9595 ,\n",
       "            0.958  , 0.957  , 0.9565 , 0.9517 , 0.9507 , 0.945  , 0.9434 ,\n",
       "            0.9316 , 0.9297 , 0.929  , 0.928  , 0.9263 , 0.9243 , 0.92   ,\n",
       "            0.919  , 0.918  , 0.913  , 0.911  , 0.9106 , 0.908  , 0.907  ,\n",
       "            0.906  , 0.9014 , 0.898  , 0.893  , 0.891  , 0.8906 , 0.887  ,\n",
       "            0.8867 , 0.8784 , 0.877  , 0.8706 , 0.87   , 0.8696 , 0.8438 ,\n",
       "            0.838  , 0.8374 , 0.8306 , 0.8228 , 0.812  , 0.806  , 0.7935 ,\n",
       "            0.78   , 0.77   , 0.7583 , 0.75   , 0.7495 , 0.7344 , 0.7324 ,\n",
       "            0.7144 , 0.712  , 0.702  , 0.6865 , 0.6787 , 0.6646 , 0.6616 ,\n",
       "            0.6553 , 0.6514 , 0.65   , 0.6475 , 0.6304 , 0.63   , 0.6284 ,\n",
       "            0.627  , 0.6265 , 0.6167 , 0.616  , 0.6147 , 0.6084 , 0.5674 ,\n",
       "            0.56   , 0.559  , 0.5586 , 0.555  , 0.552  , 0.5513 , 0.5396 ,\n",
       "            0.5356 , 0.5254 , 0.522  , 0.521  , 0.5127 , 0.509  , 0.5073 ,\n",
       "            0.5005 , 0.4944 , 0.4863 , 0.4834 , 0.48   , 0.479  , 0.476  ,\n",
       "            0.4753 , 0.4746 , 0.4744 , 0.4734 , 0.4692 , 0.4666 , 0.4656 ,\n",
       "            0.4626 , 0.4592 , 0.4565 , 0.4438 , 0.4434 , 0.4424 , 0.4421 ,\n",
       "            0.442  , 0.4402 , 0.4397 , 0.4392 , 0.4385 , 0.4373 , 0.4365 ,\n",
       "            0.4363 , 0.435  , 0.4343 , 0.4336 , 0.4302 , 0.427  , 0.426  ,\n",
       "            0.4248 , 0.4216 , 0.4211 , 0.4175 , 0.417  , 0.4146 , 0.4143 ,\n",
       "            0.4124 , 0.4106 , 0.4102 , 0.4097 , 0.4087 , 0.407  , 0.4053 ,\n",
       "            0.4028 , 0.4026 , 0.4023 , 0.401  , 0.4001 , 0.4    , 0.3972 ,\n",
       "            0.3967 , 0.3962 , 0.3955 , 0.395  , 0.3948 , 0.3938 , 0.3933 ,\n",
       "            0.3918 , 0.3892 , 0.3877 , 0.3865 , 0.386  , 0.385  , 0.3845 ,\n",
       "            0.3835 , 0.3816 , 0.3804 , 0.3784 , 0.3762 , 0.376  , 0.3757 ,\n",
       "            0.3677 , 0.367  , 0.366  , 0.3625 , 0.3618 , 0.3616 , 0.3599 ,\n",
       "            0.3577 , 0.357  , 0.3523 , 0.3513 , 0.35   , 0.3489 , 0.3452 ,\n",
       "            0.3438 , 0.3425 , 0.3381 , 0.3354 , 0.33   , 0.3274 , 0.3262 ,\n",
       "            0.3008 , 0.2983 , 0.293  , 0.283  , 0.2825 , 0.274  , 0.27   ,\n",
       "            0.2634 , 0.261  , 0.2527 , 0.2462 , 0.2448 , 0.2316 , 0.2242 ,\n",
       "            0.2162 , 0.2089 , 0.2068 , 0.1978 , 0.191  , 0.1882 , 0.1791 ,\n",
       "            0.1746 , 0.174  , 0.1738 , 0.1417 , 0.1296 , 0.1239 , 0.1158 ,\n",
       "            0.1134 , 0.1099 , 0.1065 , 0.1025 , 0.1021 , 0.10175, 0.0903 ,\n",
       "            0.0882 , 0.08527, 0.0712 , 0.0688 , 0.05942, 0.05728, 0.03516,\n",
       "            0.02827, 0.02324], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1779661, dtype=float32),\n",
       "    'tpr': array(0.6363636, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 , 0.3644068 ,\n",
       "            0.37288135, 0.37288135, 0.3898305 , 0.3898305 , 0.3983051 ,\n",
       "            0.3983051 , 0.3983051 , 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.41666666,\n",
       "            0.42424244, 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.70454544, 0.70454544, 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.79545456, 0.79545456, 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.985  , 0.9717 , 0.9707 , 0.9683 , 0.9663 , 0.965  ,\n",
       "            0.9644 , 0.964  , 0.9595 , 0.958  , 0.953  , 0.952  , 0.942  ,\n",
       "            0.9395 , 0.9385 , 0.9365 , 0.934  , 0.93   , 0.929  , 0.9277 ,\n",
       "            0.9243 , 0.9224 , 0.922  , 0.9194 , 0.919  , 0.9165 , 0.9136 ,\n",
       "            0.9097 , 0.906  , 0.9033 , 0.9004 , 0.899  , 0.8916 , 0.8896 ,\n",
       "            0.8853 , 0.8843 , 0.86   , 0.8574 , 0.8525 , 0.851  , 0.846  ,\n",
       "            0.839  , 0.8286 , 0.822  , 0.8076 , 0.7964 , 0.789  , 0.7754 ,\n",
       "            0.7646 , 0.76   , 0.757  , 0.742  , 0.73   , 0.7275 , 0.713  ,\n",
       "            0.706  , 0.698  , 0.6855 , 0.6826 , 0.682  , 0.676  , 0.6753 ,\n",
       "            0.67   , 0.669  , 0.666  , 0.655  , 0.6533 , 0.652  , 0.65   ,\n",
       "            0.642  , 0.639  , 0.6377 , 0.6367 , 0.63   , 0.5815 , 0.581  ,\n",
       "            0.5776 , 0.576  , 0.574  , 0.572  , 0.571  , 0.5615 , 0.558  ,\n",
       "            0.5576 , 0.557  , 0.5503 , 0.5376 , 0.5366 , 0.5317 , 0.528  ,\n",
       "            0.5244 , 0.5146 , 0.514  , 0.505  , 0.5034 , 0.499  , 0.4988 ,\n",
       "            0.4976 , 0.497  , 0.4954 , 0.4934 , 0.491  , 0.488  , 0.4846 ,\n",
       "            0.484  , 0.4832 , 0.4778 , 0.4624 , 0.4617 , 0.4573 , 0.457  ,\n",
       "            0.4563 , 0.456  , 0.4543 , 0.4531 , 0.453  , 0.4526 , 0.4524 ,\n",
       "            0.4504 , 0.4502 , 0.4497 , 0.449  , 0.444  , 0.4429 , 0.4414 ,\n",
       "            0.4402 , 0.4382 , 0.434  , 0.4333 , 0.4321 , 0.4314 , 0.4294 ,\n",
       "            0.4275 , 0.4265 , 0.4263 , 0.4253 , 0.4246 , 0.4219 , 0.4216 ,\n",
       "            0.4207 , 0.4197 , 0.4185 , 0.416  , 0.415  , 0.412  , 0.4106 ,\n",
       "            0.4092 , 0.4087 , 0.4084 , 0.4082 , 0.408  , 0.405  , 0.4043 ,\n",
       "            0.4036 , 0.4023 , 0.4    , 0.399  , 0.3972 , 0.3967 , 0.3945 ,\n",
       "            0.392  , 0.3877 , 0.3826 , 0.3806 , 0.3792 , 0.3782 , 0.3743 ,\n",
       "            0.3733 , 0.3728 , 0.3718 , 0.3672 , 0.3613 , 0.3594 , 0.3584 ,\n",
       "            0.355  , 0.3523 , 0.351  , 0.3435 , 0.3423 , 0.34   , 0.3389 ,\n",
       "            0.336  , 0.3215 , 0.3193 , 0.302  , 0.2908 , 0.2832 , 0.2742 ,\n",
       "            0.2737 , 0.267  , 0.263  , 0.2556 , 0.2534 , 0.2452 , 0.2372 ,\n",
       "            0.2366 , 0.224  , 0.2161 , 0.2074 , 0.1987 , 0.1973 , 0.1853 ,\n",
       "            0.1843 , 0.1765 , 0.171  , 0.1676 , 0.1672 , 0.162  , 0.1326 ,\n",
       "            0.1214 , 0.1142 , 0.1063 , 0.10596, 0.1041 , 0.1005 , 0.09686,\n",
       "            0.0942 , 0.093  , 0.0925 , 0.08124, 0.0792 , 0.07837, 0.0629 ,\n",
       "            0.0627 , 0.0538 , 0.05194, 0.03027, 0.0237 , 0.0195 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.21186441, dtype=float32),\n",
       "    'tpr': array(0.6969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.2881356 , 0.30508474, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.3983051 , 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.58474576, 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.10606061, 0.11363637, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.6969697 , 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.79545456,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8636364 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9883 , 0.9775 , 0.977  , 0.976  , 0.974  , 0.973  ,\n",
       "            0.971  , 0.9707 , 0.97   , 0.967  , 0.9653 , 0.9604 , 0.951  ,\n",
       "            0.949  , 0.9487 , 0.9463 , 0.9443 , 0.941  , 0.94   , 0.939  ,\n",
       "            0.938  , 0.9355 , 0.9336 , 0.9326 , 0.9307 , 0.93   , 0.9277 ,\n",
       "            0.9253 , 0.922  , 0.918  , 0.916  , 0.9155 , 0.914  , 0.912  ,\n",
       "            0.9053 , 0.903  , 0.8994 , 0.899  , 0.8774 , 0.873  , 0.8687 ,\n",
       "            0.866  , 0.864  , 0.857  , 0.847  , 0.8394 , 0.8247 , 0.815  ,\n",
       "            0.8115 , 0.796  , 0.785  , 0.784  , 0.783  , 0.7754 , 0.7744 ,\n",
       "            0.7495 , 0.7485 , 0.731  , 0.7285 , 0.7227 , 0.715  , 0.7065 ,\n",
       "            0.7017 , 0.692  , 0.69   , 0.6885 , 0.6846 , 0.683  , 0.677  ,\n",
       "            0.669  , 0.6685 , 0.667  , 0.6646 , 0.664  , 0.658  , 0.6123 ,\n",
       "            0.605  , 0.6045 , 0.6016 , 0.601  , 0.6    , 0.5996 , 0.5884 ,\n",
       "            0.587  , 0.5845 , 0.584  , 0.5815 , 0.571  , 0.561  , 0.5605 ,\n",
       "            0.5557 , 0.544  , 0.5415 , 0.5376 , 0.536  , 0.5273 , 0.527  ,\n",
       "            0.525  , 0.524  , 0.522  , 0.5215 , 0.52   , 0.5195 , 0.511  ,\n",
       "            0.5093 , 0.509  , 0.5073 , 0.503  , 0.4888 , 0.4885 , 0.4873 ,\n",
       "            0.4834 , 0.4827 , 0.4805 , 0.4775 , 0.4758 , 0.4753 , 0.4744 ,\n",
       "            0.4731 , 0.4724 , 0.471  , 0.469  , 0.468  , 0.4668 , 0.466  ,\n",
       "            0.4631 , 0.4583 , 0.4568 , 0.4531 , 0.4507 , 0.4504 , 0.4495 ,\n",
       "            0.449  , 0.4478 , 0.4465 , 0.446  , 0.444  , 0.4438 , 0.443  ,\n",
       "            0.4424 , 0.439  , 0.433  , 0.4329 , 0.4321 , 0.43   , 0.4297 ,\n",
       "            0.4292 , 0.4268 , 0.4265 , 0.4263 , 0.4246 , 0.424  , 0.4238 ,\n",
       "            0.423  , 0.4224 , 0.4211 , 0.4207 , 0.4204 , 0.4187 , 0.4163 ,\n",
       "            0.414  , 0.4138 , 0.4104 , 0.4094 , 0.4043 , 0.4028 , 0.4    ,\n",
       "            0.3984 , 0.395  , 0.3943 , 0.3916 , 0.3906 , 0.3884 , 0.3872 ,\n",
       "            0.383  , 0.3792 , 0.3774 , 0.3757 , 0.3743 , 0.37   , 0.3674 ,\n",
       "            0.364  , 0.3552 , 0.3542 , 0.354  , 0.351  , 0.3384 , 0.3352 ,\n",
       "            0.3208 , 0.318  , 0.3066 , 0.2886 , 0.2795 , 0.2708 , 0.2698 ,\n",
       "            0.2646 , 0.2603 , 0.2527 , 0.25   , 0.2418 , 0.2327 , 0.2325 ,\n",
       "            0.2203 , 0.2115 , 0.2028 , 0.1929 , 0.1917 , 0.1797 , 0.1779 ,\n",
       "            0.1688 , 0.166  , 0.1625 , 0.1621 , 0.1543 , 0.1263 , 0.11536,\n",
       "            0.10724, 0.0997 , 0.09894, 0.0974 , 0.0939 , 0.0901 , 0.088  ,\n",
       "            0.0866 , 0.0857 , 0.07465, 0.07275, 0.07263, 0.0575 , 0.05685,\n",
       "            0.04895, 0.04724, 0.0267 , 0.02042, 0.01672], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.21186441, dtype=float32),\n",
       "    'tpr': array(0.6969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.42372882, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.10606061, 0.11363637, 0.12121212, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.20454545, 0.21212122, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.65909094, 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.70454544, 0.70454544, 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9897 , 0.9795 , 0.9785 , 0.9766 , 0.9756 , 0.974  ,\n",
       "            0.9736 , 0.973  , 0.9697 , 0.9683 , 0.964  , 0.9546 , 0.953  ,\n",
       "            0.9526 , 0.95   , 0.948  , 0.9453 , 0.9443 , 0.9434 , 0.9424 ,\n",
       "            0.9395 , 0.938  , 0.937  , 0.935  , 0.9326 , 0.93   , 0.927  ,\n",
       "            0.923  , 0.921  , 0.9204 , 0.919  , 0.917  , 0.9106 , 0.908  ,\n",
       "            0.905  , 0.9043 , 0.883  , 0.879  , 0.8745 , 0.8716 , 0.869  ,\n",
       "            0.8623 , 0.8525 , 0.845  , 0.8306 , 0.821  , 0.8164 , 0.8013 ,\n",
       "            0.7905 , 0.789  , 0.7886 , 0.7803 , 0.7793 , 0.7544 , 0.753  ,\n",
       "            0.735  , 0.7314 , 0.7266 , 0.7197 , 0.719  , 0.711  , 0.71   ,\n",
       "            0.705  , 0.695  , 0.6934 , 0.687  , 0.685  , 0.68   , 0.6724 ,\n",
       "            0.671  , 0.667  , 0.661  , 0.6157 , 0.61   , 0.607  , 0.6035 ,\n",
       "            0.603  , 0.6025 , 0.6016 , 0.59   , 0.5894 , 0.587  , 0.586  ,\n",
       "            0.5684 , 0.567  , 0.562  , 0.5615 , 0.548  , 0.547  , 0.544  ,\n",
       "            0.5366 , 0.5347 , 0.5312 , 0.531  , 0.5293 , 0.528  , 0.527  ,\n",
       "            0.5264 , 0.5244 , 0.518  , 0.5146 , 0.512  , 0.5107 , 0.509  ,\n",
       "            0.4954 , 0.495  , 0.493  , 0.4897 , 0.4885 , 0.486  , 0.4832 ,\n",
       "            0.4797 , 0.479  , 0.478  , 0.4778 , 0.4775 , 0.4766 , 0.476  ,\n",
       "            0.4753 , 0.4746 , 0.4731 , 0.472  , 0.471  , 0.4678 , 0.4675 ,\n",
       "            0.4658 , 0.463  , 0.4587 , 0.4585 , 0.456  , 0.4558 , 0.4546 ,\n",
       "            0.454  , 0.4521 , 0.4512 , 0.4507 , 0.45   , 0.4497 , 0.449  ,\n",
       "            0.4424 , 0.441  , 0.4382 , 0.4373 , 0.437  , 0.4355 , 0.4314 ,\n",
       "            0.4304 , 0.4302 , 0.4297 , 0.429  , 0.4287 , 0.428  , 0.4263 ,\n",
       "            0.4243 , 0.4236 , 0.4214 , 0.4211 , 0.419  , 0.4177 , 0.4138 ,\n",
       "            0.4136 , 0.4062 , 0.4058 , 0.4045 , 0.4019 , 0.3987 , 0.3975 ,\n",
       "            0.3965 , 0.396  , 0.3928 , 0.3914 , 0.3877 , 0.3853 , 0.3784 ,\n",
       "            0.3723 , 0.3708 , 0.3687 , 0.3645 , 0.3606 , 0.3577 , 0.3562 ,\n",
       "            0.3408 , 0.3289 , 0.325  , 0.3115 , 0.308  , 0.3047 , 0.2786 ,\n",
       "            0.268  , 0.2598 , 0.2588 , 0.2556 , 0.251  , 0.2428 , 0.2405 ,\n",
       "            0.2323 , 0.2229 , 0.2218 , 0.211  , 0.2021 , 0.193  , 0.1821 ,\n",
       "            0.1815 , 0.1718 , 0.166  , 0.1575 , 0.1573 , 0.1545 , 0.1543 ,\n",
       "            0.143  , 0.1172 , 0.1074 , 0.09845, 0.0914 , 0.0904 , 0.0891 ,\n",
       "            0.0856 , 0.082  , 0.0805 , 0.07904, 0.07764, 0.0673 , 0.0662 ,\n",
       "            0.0655 , 0.05176, 0.0504 , 0.04385, 0.04233, 0.02324, 0.01738,\n",
       "            0.01423], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.27118644, dtype=float32),\n",
       "    'tpr': array(0.780303, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.21186441, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.33898306, 0.33898306, 0.33898306, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.70454544, 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.79545456, 0.8030303 , 0.8030303 , 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8636364 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.992  , 0.984  , 0.983  , 0.9814 , 0.9805 , 0.979  ,\n",
       "            0.9785 , 0.9756 , 0.974  , 0.9707 , 0.963  , 0.9614 , 0.961  ,\n",
       "            0.959  , 0.957  , 0.9546 , 0.953  , 0.9526 , 0.9517 , 0.9497 ,\n",
       "            0.948  , 0.9478 , 0.9473 , 0.9453 , 0.945  , 0.943  , 0.941  ,\n",
       "            0.9375 , 0.9346 , 0.9326 , 0.932  , 0.931  , 0.929  , 0.9233 ,\n",
       "            0.921  , 0.9185 , 0.918  , 0.9175 , 0.899  , 0.8936 , 0.89   ,\n",
       "            0.8867 , 0.8857 , 0.8794 , 0.8706 , 0.863  , 0.8477 , 0.8394 ,\n",
       "            0.8384 , 0.8228 , 0.818  , 0.815  , 0.8096 , 0.807  , 0.7954 ,\n",
       "            0.775  , 0.7744 , 0.76   , 0.753  , 0.7515 , 0.7495 , 0.7476 ,\n",
       "            0.7427 , 0.7344 , 0.7314 , 0.728  , 0.719  , 0.7188 , 0.7183 ,\n",
       "            0.7173 , 0.708  , 0.704  , 0.703  , 0.701  , 0.6997 , 0.6953 ,\n",
       "            0.6904 , 0.649  , 0.644  , 0.6357 , 0.633  , 0.6274 , 0.627  ,\n",
       "            0.6255 , 0.6235 , 0.6157 , 0.6147 , 0.6084 , 0.604  , 0.5957 ,\n",
       "            0.5874 , 0.587  , 0.5806 , 0.578  , 0.5713 , 0.566  , 0.5654 ,\n",
       "            0.5625 , 0.561  , 0.5605 , 0.5596 , 0.559  , 0.553  , 0.5513 ,\n",
       "            0.5454 , 0.5425 , 0.5405 , 0.5347 , 0.5293 , 0.525  , 0.524  ,\n",
       "            0.521  , 0.517  , 0.515  , 0.5117 , 0.509  , 0.5073 , 0.506  ,\n",
       "            0.505  , 0.504  , 0.5034 , 0.501  , 0.4998 , 0.497  , 0.494  ,\n",
       "            0.4937 , 0.4934 , 0.4893 , 0.4885 , 0.487  , 0.4868 , 0.486  ,\n",
       "            0.4846 , 0.4834 , 0.4824 , 0.4817 , 0.4812 , 0.4807 , 0.4736 ,\n",
       "            0.4705 , 0.4673 , 0.4653 , 0.4646 , 0.4624 , 0.4617 , 0.4578 ,\n",
       "            0.4573 , 0.457  , 0.455  , 0.4548 , 0.4546 , 0.4514 , 0.4504 ,\n",
       "            0.448  , 0.4465 , 0.4458 , 0.4453 , 0.4438 , 0.4434 , 0.4421 ,\n",
       "            0.4407 , 0.4385 , 0.4377 , 0.4353 , 0.4333 , 0.4316 , 0.4268 ,\n",
       "            0.4258 , 0.424  , 0.4214 , 0.4207 , 0.4153 , 0.4138 , 0.413  ,\n",
       "            0.4114 , 0.411  , 0.4102 , 0.4    , 0.3943 , 0.3887 , 0.3828 ,\n",
       "            0.378  , 0.3752 , 0.3748 , 0.3713 , 0.3708 , 0.341  , 0.3289 ,\n",
       "            0.3257 , 0.3115 , 0.311  , 0.3074 , 0.2766 , 0.2651 , 0.2566 ,\n",
       "            0.2551 , 0.2534 , 0.2485 , 0.2399 , 0.2374 , 0.2292 , 0.2194 ,\n",
       "            0.2177 , 0.2076 , 0.1981 , 0.1887 , 0.1768 , 0.1765 , 0.1677 ,\n",
       "            0.16   , 0.153  , 0.1508 , 0.1503 , 0.1499 , 0.1364 , 0.111  ,\n",
       "            0.1019 , 0.09235, 0.0854 , 0.0845 , 0.0833 , 0.0798 , 0.076  ,\n",
       "            0.0752 , 0.07355, 0.07184, 0.0619 , 0.06143, 0.0601 , 0.04742,\n",
       "            0.0457 , 0.03995, 0.03845, 0.0205 , 0.01513, 0.01219],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.34745762, dtype=float32),\n",
       "    'tpr': array(0.84090906, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.33898306, 0.34745762, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.10606061, 0.11363637, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.82575756, 0.8333333 ,\n",
       "            0.8333333 , 0.84090906, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9937 , 0.987  , 0.986  , 0.985  , 0.984  , 0.983  ,\n",
       "            0.9824 , 0.982  , 0.9795 , 0.9785 , 0.975  , 0.9683 , 0.967  ,\n",
       "            0.965  , 0.963  , 0.961  , 0.9595 , 0.959  , 0.958  , 0.9565 ,\n",
       "            0.955  , 0.9546 , 0.954  , 0.9526 , 0.9517 , 0.95   , 0.948  ,\n",
       "            0.9453 , 0.9424 , 0.941  , 0.94   , 0.9375 , 0.932  , 0.93   ,\n",
       "            0.928  , 0.9277 , 0.9272 , 0.91   , 0.9043 , 0.9014 , 0.8975 ,\n",
       "            0.892  , 0.884  , 0.8755 , 0.8604 , 0.8545 , 0.8535 , 0.839  ,\n",
       "            0.838  , 0.8345 , 0.8306 , 0.8213 , 0.8076 , 0.791  , 0.7905 ,\n",
       "            0.7793 , 0.7783 , 0.7725 , 0.771  , 0.767  , 0.7603 , 0.756  ,\n",
       "            0.7534 , 0.752  , 0.744  , 0.741  , 0.7383 , 0.738  , 0.729  ,\n",
       "            0.727  , 0.7256 , 0.718  , 0.7134 , 0.711  , 0.709  , 0.677  ,\n",
       "            0.672  , 0.6597 , 0.658  , 0.6577 , 0.6567 , 0.651  , 0.648  ,\n",
       "            0.643  , 0.639  , 0.638  , 0.634  , 0.624  , 0.6216 , 0.609  ,\n",
       "            0.6084 , 0.6074 , 0.602  , 0.5947 , 0.593  , 0.5884 , 0.588  ,\n",
       "            0.5874 , 0.5864 , 0.5835 , 0.5825 , 0.5815 , 0.574  , 0.572  ,\n",
       "            0.5684 , 0.5674 , 0.5586 , 0.558  , 0.555  , 0.5527 , 0.5522 ,\n",
       "            0.549  , 0.544  , 0.5425 , 0.542  , 0.5337 , 0.5327 , 0.5303 ,\n",
       "            0.529  , 0.528  , 0.527  , 0.5244 , 0.5234 , 0.5225 , 0.521  ,\n",
       "            0.5195 , 0.5166 , 0.5137 , 0.5127 , 0.5117 , 0.5107 , 0.5093 ,\n",
       "            0.5083 , 0.508  , 0.507  , 0.506  , 0.5024 , 0.4927 , 0.4897 ,\n",
       "            0.4893 , 0.4849 , 0.483  , 0.4824 , 0.4822 , 0.4797 , 0.4795 ,\n",
       "            0.4766 , 0.476  , 0.4753 , 0.4714 , 0.4702 , 0.4685 , 0.4663 ,\n",
       "            0.4653 , 0.4648 , 0.4636 , 0.461  , 0.459  , 0.4575 , 0.4556 ,\n",
       "            0.4548 , 0.4543 , 0.4517 , 0.4482 , 0.4475 , 0.445  , 0.4426 ,\n",
       "            0.4414 , 0.4353 , 0.4333 , 0.4326 , 0.4304 , 0.429  , 0.428  ,\n",
       "            0.4194 , 0.4192 , 0.4138 , 0.4033 , 0.4026 , 0.3906 , 0.39   ,\n",
       "            0.385  , 0.3777 , 0.372  , 0.3398 , 0.3276 , 0.3242 , 0.3171 ,\n",
       "            0.3093 , 0.3054 , 0.274  , 0.261  , 0.2524 , 0.251  , 0.2505 ,\n",
       "            0.2452 , 0.2363 , 0.2338 , 0.2252 , 0.2152 , 0.2125 , 0.2039 ,\n",
       "            0.1936 , 0.1838 , 0.1711 , 0.1709 , 0.1632 , 0.1532 , 0.1482 ,\n",
       "            0.1455 , 0.145  , 0.1438 , 0.1294 , 0.1047 , 0.0964 , 0.0863 ,\n",
       "            0.07965, 0.0786 , 0.0775 , 0.0741 , 0.07043, 0.0698 , 0.0683 ,\n",
       "            0.0662 , 0.05664, 0.055  , 0.04327, 0.04123, 0.03607, 0.03476,\n",
       "            0.01799, 0.01312, 0.01045], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3898305, dtype=float32),\n",
       "    'tpr': array(0.8712121, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3644068 , 0.38135594,\n",
       "            0.38135594, 0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.46969697, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.7121212 , 0.7121212 ,\n",
       "            0.72727275, 0.74242425, 0.75      , 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.8333333 , 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.995  , 0.9893 , 0.989  , 0.9883 , 0.9873 , 0.987  ,\n",
       "            0.9854 , 0.985  , 0.983  , 0.982  , 0.979  , 0.9785 , 0.973  ,\n",
       "            0.9717 , 0.9697 , 0.968  , 0.967  , 0.965  , 0.9644 , 0.9634 ,\n",
       "            0.9624 , 0.961  , 0.9604 , 0.96   , 0.959  , 0.958  , 0.956  ,\n",
       "            0.9546 , 0.952  , 0.9497 , 0.948  , 0.9478 , 0.9473 , 0.9443 ,\n",
       "            0.94   , 0.9375 , 0.9365 , 0.936  , 0.9204 , 0.914  , 0.9116 ,\n",
       "            0.9087 , 0.9067 , 0.904  , 0.896  , 0.887  , 0.872  , 0.8696 ,\n",
       "            0.8667 , 0.856  , 0.8545 , 0.8535 , 0.8516 , 0.834  , 0.8184 ,\n",
       "            0.807  , 0.8057 , 0.803  , 0.7983 , 0.7954 , 0.792  , 0.7905 ,\n",
       "            0.7827 , 0.7725 , 0.772  , 0.769  , 0.7656 , 0.7583 , 0.757  ,\n",
       "            0.7544 , 0.7515 , 0.7505 , 0.75   , 0.7397 , 0.7373 , 0.7275 ,\n",
       "            0.721  , 0.7046 , 0.7007 , 0.6895 , 0.6846 , 0.684  , 0.682  ,\n",
       "            0.679  , 0.6704 , 0.6646 , 0.664  , 0.6636 , 0.662  , 0.6553 ,\n",
       "            0.653  , 0.64   , 0.6367 , 0.634  , 0.6313 , 0.63   , 0.625  ,\n",
       "            0.6235 , 0.617  , 0.6167 , 0.6147 , 0.6133 , 0.6094 , 0.604  ,\n",
       "            0.6025 , 0.599  , 0.5977 , 0.595  , 0.5947 , 0.593  , 0.589  ,\n",
       "            0.5884 , 0.583  , 0.5806 , 0.578  , 0.5776 , 0.574  , 0.572  ,\n",
       "            0.5713 , 0.5596 , 0.558  , 0.5547 , 0.554  , 0.553  , 0.5527 ,\n",
       "            0.552  , 0.5503 , 0.5493 , 0.547  , 0.546  , 0.543  , 0.5405 ,\n",
       "            0.539  , 0.537  , 0.536  , 0.534  , 0.533  , 0.531  , 0.527  ,\n",
       "            0.5186 , 0.5156 , 0.5083 , 0.5073 , 0.505  , 0.5044 , 0.5024 ,\n",
       "            0.4995 , 0.4983 , 0.4976 , 0.495  , 0.4922 , 0.4897 , 0.4846 ,\n",
       "            0.4841 , 0.482  , 0.4817 , 0.4807 , 0.48   , 0.4797 , 0.4785 ,\n",
       "            0.4739 , 0.4712 , 0.4705 , 0.467  , 0.4656 , 0.4646 , 0.4634 ,\n",
       "            0.462  , 0.457  , 0.4553 , 0.453  , 0.4524 , 0.4507 , 0.4448 ,\n",
       "            0.4385 , 0.4338 , 0.4297 , 0.4277 , 0.4229 , 0.4182 , 0.4067 ,\n",
       "            0.402  , 0.399  , 0.3809 , 0.3733 , 0.339  , 0.3267 , 0.3232 ,\n",
       "            0.3225 , 0.3083 , 0.304  , 0.2715 , 0.257  , 0.2487 , 0.2482 ,\n",
       "            0.2471 , 0.2428 , 0.2334 , 0.2307 , 0.2222 , 0.2118 , 0.2084 ,\n",
       "            0.2007 , 0.1898 , 0.1797 , 0.1663 , 0.1661 , 0.1593 , 0.1469 ,\n",
       "            0.1443 , 0.1415 , 0.1409 , 0.1376 , 0.1232 , 0.0995 , 0.0914 ,\n",
       "            0.08124, 0.07477, 0.07367, 0.07275, 0.0694 , 0.06573, 0.06537,\n",
       "            0.06384, 0.06152, 0.0527 , 0.05234, 0.05072, 0.0398 , 0.03748,\n",
       "            0.03302, 0.0318 , 0.01602, 0.01147, 0.00909], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.44067797, dtype=float32),\n",
       "    'tpr': array(0.9166667, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.03389831, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.04545455,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84090906, 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.996   , 0.991   , 0.9907  , 0.9897  , 0.9883  ,\n",
       "            0.988   , 0.986   , 0.985   , 0.983   , 0.9824  , 0.978   ,\n",
       "            0.9766  , 0.975   , 0.973   , 0.9727  , 0.97    , 0.9697  ,\n",
       "            0.9688  , 0.9683  , 0.9673  , 0.967   , 0.966   , 0.964   ,\n",
       "            0.9624  , 0.9614  , 0.9595  , 0.957   , 0.956   , 0.9556  ,\n",
       "            0.9546  , 0.952   , 0.948   , 0.9463  , 0.946   , 0.945   ,\n",
       "            0.9316  , 0.9243  , 0.923   , 0.9204  , 0.917   , 0.916   ,\n",
       "            0.909   , 0.9004  , 0.886   , 0.885   , 0.8813  , 0.8755  ,\n",
       "            0.8735  , 0.872   , 0.871   , 0.8486  , 0.829   , 0.8286  ,\n",
       "            0.8247  , 0.8228  , 0.8203  , 0.82    , 0.8184  , 0.812   ,\n",
       "            0.797   , 0.7954  , 0.7944  , 0.792   , 0.783   , 0.782   ,\n",
       "            0.7803  , 0.7783  , 0.778   , 0.777   , 0.775   , 0.765   ,\n",
       "            0.7637  , 0.749   , 0.736   , 0.7324  , 0.7314  , 0.7236  ,\n",
       "            0.713   , 0.712   , 0.7104  , 0.71    , 0.6973  , 0.6953  ,\n",
       "            0.693   , 0.691   , 0.6846  , 0.6836  , 0.6685  , 0.6587  ,\n",
       "            0.658   , 0.6577  , 0.657   , 0.656   , 0.6494  , 0.649   ,\n",
       "            0.647   , 0.645   , 0.6377  , 0.63    , 0.6294  , 0.6265  ,\n",
       "            0.625   , 0.6226  , 0.622   , 0.616   , 0.613   , 0.611   ,\n",
       "            0.6094  , 0.6035  , 0.603   , 0.5996  , 0.5923  , 0.5894  ,\n",
       "            0.589   , 0.5845  , 0.584   , 0.583   , 0.582   , 0.5806  ,\n",
       "            0.58    , 0.579   , 0.577   , 0.5737  , 0.5728  , 0.5723  ,\n",
       "            0.57    , 0.568   , 0.566   , 0.564   , 0.5635  , 0.5605  ,\n",
       "            0.5566  , 0.55    , 0.549   , 0.546   , 0.537   , 0.5366  ,\n",
       "            0.534   , 0.532   , 0.5303  , 0.53    , 0.529   , 0.5283  ,\n",
       "            0.5244  , 0.5234  , 0.5205  , 0.5137  , 0.5107  , 0.5083  ,\n",
       "            0.508   , 0.5063  , 0.4998  , 0.4993  , 0.497   , 0.491   ,\n",
       "            0.4873  , 0.4858  , 0.4844  , 0.4824  , 0.4814  , 0.4795  ,\n",
       "            0.4758  , 0.4749  , 0.4746  , 0.4639  , 0.4617  , 0.4585  ,\n",
       "            0.4583  , 0.4468  , 0.4363  , 0.4358  , 0.4316  , 0.4265  ,\n",
       "            0.4172  , 0.4155  , 0.3848  , 0.3755  , 0.3381  , 0.3315  ,\n",
       "            0.326   , 0.3206  , 0.3074  , 0.3025  , 0.2693  , 0.2527  ,\n",
       "            0.2462  , 0.2451  , 0.243   , 0.2401  , 0.2303  , 0.2277  ,\n",
       "            0.2191  , 0.2084  , 0.204   , 0.1976  , 0.1859  , 0.1752  ,\n",
       "            0.1614  , 0.1609  , 0.156   , 0.1404  , 0.14    , 0.138   ,\n",
       "            0.1375  , 0.1312  , 0.1166  , 0.0942  , 0.0863  , 0.076   ,\n",
       "            0.06995 , 0.06866 , 0.06793 , 0.0645  , 0.06097 , 0.06085 ,\n",
       "            0.05933 , 0.05676 , 0.04895 , 0.04794 , 0.0464  , 0.03662 ,\n",
       "            0.03384 , 0.03021 , 0.02904 , 0.014114, 0.009895, 0.00784 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.47457626, dtype=float32),\n",
       "    'tpr': array(0.9469697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.33898306, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.3559322 , 0.3644068 , 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.57575756, 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6136364 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.997   , 0.9927  , 0.992   , 0.9917  , 0.991   ,\n",
       "            0.99    , 0.9897  , 0.9883  , 0.9873  , 0.986   , 0.985   ,\n",
       "            0.981   , 0.98    , 0.9785  , 0.977   , 0.976   , 0.974   ,\n",
       "            0.9736  , 0.9727  , 0.9717  , 0.971   , 0.97    , 0.9688  ,\n",
       "            0.967   , 0.9663  , 0.9644  , 0.9624  , 0.9614  , 0.96    ,\n",
       "            0.9575  , 0.954   , 0.9526  , 0.952   , 0.9517  , 0.951   ,\n",
       "            0.939   , 0.9316  , 0.931   , 0.9287  , 0.925   , 0.9185  ,\n",
       "            0.9097  , 0.897   , 0.894   , 0.8916  , 0.8877  , 0.8867  ,\n",
       "            0.8843  , 0.883   , 0.8594  , 0.844   , 0.838   , 0.8374  ,\n",
       "            0.836   , 0.8354  , 0.8345  , 0.834   , 0.829   , 0.8267  ,\n",
       "            0.8145  , 0.811   , 0.809   , 0.8003  , 0.796   , 0.7944  ,\n",
       "            0.793   , 0.7925  , 0.791   , 0.7817  , 0.781   , 0.764   ,\n",
       "            0.757   , 0.754   , 0.747   , 0.7407  , 0.733   , 0.7324  ,\n",
       "            0.73    , 0.728   , 0.7207  , 0.716   , 0.7124  , 0.711   ,\n",
       "            0.7095  , 0.707   , 0.699   , 0.6934  , 0.691   , 0.6826  ,\n",
       "            0.682   , 0.6753  , 0.6733  , 0.6724  , 0.672   , 0.6714  ,\n",
       "            0.6675  , 0.6577  , 0.652   , 0.65    , 0.648   , 0.647   ,\n",
       "            0.644   , 0.641   , 0.6406  , 0.636   , 0.6353  , 0.635   ,\n",
       "            0.6274  , 0.6265  , 0.6216  , 0.6187  , 0.6147  , 0.613   ,\n",
       "            0.612   , 0.6113  , 0.6104  , 0.6074  , 0.6064  , 0.6045  ,\n",
       "            0.604   , 0.602   , 0.6016  , 0.6     , 0.5996  , 0.599   ,\n",
       "            0.597   , 0.595   , 0.594   , 0.591   , 0.59    , 0.589   ,\n",
       "            0.587   , 0.5864  , 0.584   , 0.5737  , 0.573   , 0.57    ,\n",
       "            0.5664  , 0.561   , 0.5605  , 0.558   , 0.552   , 0.551   ,\n",
       "            0.5483  , 0.5464  , 0.545   , 0.544   , 0.543   , 0.5347  ,\n",
       "            0.5327  , 0.532   , 0.5273  , 0.527   , 0.5264  , 0.526   ,\n",
       "            0.523   , 0.517   , 0.516   , 0.5156  , 0.513   , 0.5083  ,\n",
       "            0.5073  , 0.5044  , 0.4998  , 0.4958  , 0.4956  , 0.4907  ,\n",
       "            0.4814  , 0.48    , 0.4797  , 0.4768  , 0.4668  , 0.46    ,\n",
       "            0.452   , 0.4443  , 0.439   , 0.4329  , 0.4304  , 0.4302  ,\n",
       "            0.3845  , 0.375   , 0.338   , 0.3362  , 0.3237  , 0.3176  ,\n",
       "            0.3047  , 0.2998  , 0.2659  , 0.2485  , 0.2428  , 0.2406  ,\n",
       "            0.2384  , 0.2362  , 0.2263  , 0.2235  , 0.2148  , 0.2039  ,\n",
       "            0.199   , 0.1935  , 0.1814  , 0.1699  , 0.1561  , 0.1556  ,\n",
       "            0.1517  , 0.136   , 0.1342  , 0.1338  , 0.133   , 0.1251  ,\n",
       "            0.11084 , 0.0888  , 0.08136 , 0.07135 , 0.06537 , 0.0641  ,\n",
       "            0.06335 , 0.0602  , 0.05676 , 0.05655 , 0.0552  , 0.0526  ,\n",
       "            0.04526 , 0.04428 , 0.04263 , 0.03354 , 0.03073 , 0.02748 ,\n",
       "            0.02641 , 0.01257 , 0.008675, 0.00685 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5084746, dtype=float32),\n",
       "    'tpr': array(0.9621212, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.22881356, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.3898305 , 0.3983051 , 0.41525424, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.13636364, 0.14393939,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.57575756, 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6515151 , 0.6515151 ,\n",
       "            0.6515151 , 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.81060606,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9976 , 0.994  , 0.9937 , 0.993  , 0.9927 , 0.992  ,\n",
       "            0.9917 , 0.99   , 0.9893 , 0.9883 , 0.9873 , 0.984  , 0.983  ,\n",
       "            0.982  , 0.98   , 0.978  , 0.977  , 0.9766 , 0.9756 , 0.975  ,\n",
       "            0.9746 , 0.974  , 0.9727 , 0.971  , 0.9707 , 0.9688 , 0.967  ,\n",
       "            0.9663 , 0.965  , 0.9624 , 0.9595 , 0.9585 , 0.958  , 0.9575 ,\n",
       "            0.957  , 0.9463 , 0.939  , 0.9385 , 0.937  , 0.933  , 0.932  ,\n",
       "            0.9277 , 0.919  , 0.908  , 0.904  , 0.902  , 0.9    , 0.896  ,\n",
       "            0.895  , 0.87   , 0.8604 , 0.8525 , 0.851  , 0.8506 , 0.8486 ,\n",
       "            0.848  , 0.8467 , 0.8447 , 0.8413 , 0.8325 , 0.8267 , 0.824  ,\n",
       "            0.819  , 0.814  , 0.813  , 0.8115 , 0.808  , 0.801  , 0.7993 ,\n",
       "            0.799  , 0.78   , 0.779  , 0.7764 , 0.7725 , 0.7573 , 0.7524 ,\n",
       "            0.7495 , 0.7485 , 0.7476 , 0.746  , 0.7437 , 0.732  , 0.731  ,\n",
       "            0.729  , 0.721  , 0.716  , 0.7153 , 0.71   , 0.7085 , 0.6987 ,\n",
       "            0.698  , 0.6943 , 0.692  , 0.6855 , 0.681  , 0.677  , 0.6753 ,\n",
       "            0.675  , 0.6743 , 0.6714 , 0.669  , 0.6685 , 0.6655 , 0.663  ,\n",
       "            0.6626 , 0.6616 , 0.657  , 0.6543 , 0.6523 , 0.6465 , 0.6436 ,\n",
       "            0.6416 , 0.6387 , 0.6367 , 0.6357 , 0.6353 , 0.6333 , 0.6284 ,\n",
       "            0.628  , 0.6274 , 0.627  , 0.6265 , 0.624  , 0.623  , 0.622  ,\n",
       "            0.618  , 0.6177 , 0.6167 , 0.614  , 0.6123 , 0.612  , 0.611  ,\n",
       "            0.609  , 0.608  , 0.599  , 0.596  , 0.593  , 0.587  , 0.586  ,\n",
       "            0.5854 , 0.584  , 0.5767 , 0.575  , 0.5728 , 0.571  , 0.5693 ,\n",
       "            0.5674 , 0.566  , 0.56   , 0.5576 , 0.5537 , 0.55   , 0.548  ,\n",
       "            0.5474 , 0.547  , 0.537  , 0.5366 , 0.5356 , 0.533  , 0.5312 ,\n",
       "            0.531  , 0.524  , 0.5215 , 0.5176 , 0.517  , 0.5103 , 0.5024 ,\n",
       "            0.5    , 0.497  , 0.4875 , 0.4783 , 0.4692 , 0.4626 , 0.461  ,\n",
       "            0.4463 , 0.444  , 0.443  , 0.4326 , 0.3848 , 0.3748 , 0.3433 ,\n",
       "            0.333  , 0.321  , 0.3125 , 0.302  , 0.2964 , 0.2622 , 0.2438 ,\n",
       "            0.2391 , 0.2355 , 0.2332 , 0.2323 , 0.222  , 0.2194 , 0.2106 ,\n",
       "            0.1993 , 0.1936 , 0.1892 , 0.1768 , 0.1647 , 0.1506 , 0.1499 ,\n",
       "            0.1476 , 0.1316 , 0.1295 , 0.1289 , 0.1271 , 0.1186 , 0.1043 ,\n",
       "            0.0836 , 0.07666, 0.06647, 0.06076, 0.05942, 0.0589 , 0.05573,\n",
       "            0.0527 , 0.05212, 0.0511 , 0.0483 , 0.04178, 0.04037, 0.03882,\n",
       "            0.03067, 0.02759, 0.02493, 0.02396, 0.01103, 0.00746, 0.00589],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5254237, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.04545455,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.13636364, 0.14393939, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.8030303 , 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.82575756, 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.998   , 0.995   , 0.9946  , 0.994   , 0.993   ,\n",
       "            0.9927  , 0.9917  , 0.9907  , 0.9897  , 0.989   , 0.986   ,\n",
       "            0.985   , 0.984   , 0.9824  , 0.98    , 0.9795  , 0.979   ,\n",
       "            0.9785  , 0.978   , 0.9775  , 0.977   , 0.9756  , 0.9736  ,\n",
       "            0.972   , 0.97    , 0.9697  , 0.9683  , 0.966   , 0.9634  ,\n",
       "            0.963   , 0.962   , 0.9614  , 0.961   , 0.951   , 0.944   ,\n",
       "            0.9424  , 0.9385  , 0.9365  , 0.9336  , 0.9253  , 0.916   ,\n",
       "            0.9097  , 0.909   , 0.9087  , 0.9043  , 0.903   , 0.8774  ,\n",
       "            0.8726  , 0.863   , 0.862   , 0.8604  , 0.8594  , 0.857   ,\n",
       "            0.852   , 0.8477  , 0.845   , 0.84    , 0.8384  , 0.835   ,\n",
       "            0.834   , 0.8276  , 0.8267  , 0.823   , 0.821   , 0.8193  ,\n",
       "            0.8125  , 0.812   , 0.8037  , 0.8003  , 0.8     , 0.7974  ,\n",
       "            0.791   , 0.7817  , 0.7715  , 0.7705  , 0.7695  , 0.7656  ,\n",
       "            0.764   , 0.7563  , 0.75    , 0.7495  , 0.7476  , 0.747   ,\n",
       "            0.746   , 0.7407  , 0.7373  , 0.735   , 0.7275  , 0.726   ,\n",
       "            0.7246  , 0.724   , 0.7163  , 0.714   , 0.7104  , 0.7046  ,\n",
       "            0.7026  , 0.702   , 0.7017  , 0.701   , 0.697   , 0.696   ,\n",
       "            0.695   , 0.6914  , 0.689   , 0.6885  , 0.686   , 0.6816  ,\n",
       "            0.679   , 0.6743  , 0.672   , 0.6714  , 0.6675  , 0.6655  ,\n",
       "            0.6646  , 0.6626  , 0.6616  , 0.661   , 0.6597  , 0.655   ,\n",
       "            0.6543  , 0.6533  , 0.653   , 0.6523  , 0.652   , 0.6514  ,\n",
       "            0.6475  , 0.6465  , 0.646   , 0.6455  , 0.64    , 0.6396  ,\n",
       "            0.6387  , 0.6377  , 0.6357  , 0.6304  , 0.6265  , 0.6235  ,\n",
       "            0.6143  , 0.613   , 0.6123  , 0.6113  , 0.609   , 0.604   ,\n",
       "            0.6035  , 0.5996  , 0.597   , 0.5967  , 0.5938  , 0.5923  ,\n",
       "            0.592   , 0.5913  , 0.59    , 0.5854  , 0.583   , 0.576   ,\n",
       "            0.5737  , 0.573   , 0.5703  , 0.5693  , 0.562   , 0.5586  ,\n",
       "            0.557   , 0.556   , 0.555   , 0.5527  , 0.546   , 0.5454  ,\n",
       "            0.541   , 0.5405  , 0.527   , 0.5254  , 0.525   , 0.516   ,\n",
       "            0.5093  , 0.5083  , 0.4888  , 0.4824  , 0.4753  , 0.4639  ,\n",
       "            0.4607  , 0.459   , 0.4475  , 0.4268  , 0.385   , 0.374   ,\n",
       "            0.3503  , 0.3271  , 0.3171  , 0.302   , 0.2988  , 0.2922  ,\n",
       "            0.2573  , 0.2363  , 0.2356  , 0.2295  , 0.2285  , 0.2266  ,\n",
       "            0.2179  , 0.2152  , 0.2068  , 0.195   , 0.1877  , 0.186   ,\n",
       "            0.1725  , 0.1597  , 0.1454  , 0.1445  , 0.1438  , 0.128   ,\n",
       "            0.1262  , 0.1259  , 0.11816 , 0.11145 , 0.09705 , 0.0789  ,\n",
       "            0.07263 , 0.0619  , 0.05664 , 0.055   , 0.0548  , 0.05176 ,\n",
       "            0.0494  , 0.04803 , 0.0476  , 0.0441  , 0.03897 , 0.03662 ,\n",
       "            0.03516 , 0.02834 , 0.02461 , 0.02298 , 0.02216 , 0.00974 ,\n",
       "            0.006363, 0.00508 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5338983, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.06779661, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.41525424, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.04545455,\n",
       "            0.0530303 , 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.13636364, 0.14393939, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.27272728, 0.28030303, 0.28787878, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.4848485 , 0.49242425, 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9985  , 0.996   , 0.9956  , 0.995   , 0.9946  ,\n",
       "            0.994   , 0.993   , 0.992   , 0.991   , 0.9907  , 0.9883  ,\n",
       "            0.9873  , 0.9863  , 0.985   , 0.983   , 0.9824  , 0.982   ,\n",
       "            0.9814  , 0.981   , 0.9805  , 0.98    , 0.9785  , 0.9775  ,\n",
       "            0.977   , 0.9756  , 0.974   , 0.9727  , 0.97    , 0.968   ,\n",
       "            0.967   , 0.9663  , 0.9653  , 0.957   , 0.95    , 0.9497  ,\n",
       "            0.9487  , 0.946   , 0.942   , 0.941   , 0.933   , 0.9253  ,\n",
       "            0.92    , 0.919   , 0.9185  , 0.9175  , 0.9146  , 0.913   ,\n",
       "            0.8867  , 0.886   , 0.876   , 0.8755  , 0.8726  , 0.8677  ,\n",
       "            0.865   , 0.86    , 0.854   , 0.8525  , 0.8486  , 0.8438  ,\n",
       "            0.843   , 0.8374  , 0.836   , 0.833   , 0.828   , 0.82    ,\n",
       "            0.8174  , 0.8105  , 0.8057  , 0.802   , 0.7935  , 0.793   ,\n",
       "            0.7896  , 0.7837  , 0.782   , 0.7773  , 0.77    , 0.7686  ,\n",
       "            0.7666  , 0.763   , 0.7617  , 0.76    , 0.7573  , 0.7563  ,\n",
       "            0.749   , 0.7466  , 0.746   , 0.7427  , 0.738   , 0.733   ,\n",
       "            0.729   , 0.726   , 0.7256  , 0.723   , 0.72    , 0.7173  ,\n",
       "            0.7153  , 0.712   , 0.7075  , 0.707   , 0.7065  , 0.7046  ,\n",
       "            0.7017  , 0.6973  , 0.6963  , 0.692   , 0.6885  , 0.6875  ,\n",
       "            0.6846  , 0.6826  , 0.682   , 0.6807  , 0.6777  , 0.6772  ,\n",
       "            0.6753  , 0.675   , 0.6743  , 0.674   , 0.6714  , 0.668   ,\n",
       "            0.6675  , 0.667   , 0.661   , 0.6606  , 0.659   , 0.657   ,\n",
       "            0.6504  , 0.649   , 0.646   , 0.6367  , 0.635   , 0.634   ,\n",
       "            0.6304  , 0.625   , 0.6216  , 0.6206  , 0.6187  , 0.616   ,\n",
       "            0.615   , 0.6123  , 0.6113  , 0.6104  , 0.6094  , 0.6074  ,\n",
       "            0.6045  , 0.5947  , 0.5938  , 0.5894  , 0.588   , 0.583   ,\n",
       "            0.579   , 0.577   , 0.5747  , 0.573   , 0.569   , 0.565   ,\n",
       "            0.564   , 0.5605  , 0.56    , 0.547   , 0.544   , 0.537   ,\n",
       "            0.5312  , 0.528   , 0.514   , 0.5044  , 0.499   , 0.478   ,\n",
       "            0.4758  , 0.4695  , 0.4607  , 0.45    , 0.4253  , 0.3838  ,\n",
       "            0.3723  , 0.3535  , 0.3223  , 0.3135  , 0.2961  , 0.295   ,\n",
       "            0.288   , 0.253   , 0.2319  , 0.2303  , 0.2239  , 0.2238  ,\n",
       "            0.2208  , 0.213   , 0.2103  , 0.2018  , 0.19    , 0.1821  ,\n",
       "            0.1814  , 0.1675  , 0.154   , 0.1404  , 0.1399  , 0.138   ,\n",
       "            0.12366 , 0.12213 , 0.12177 , 0.1118  , 0.1056  , 0.09125 ,\n",
       "            0.0742  , 0.06854 , 0.0577  , 0.05283 , 0.0511  , 0.0509  ,\n",
       "            0.04794 , 0.0461  , 0.04434 , 0.0442  , 0.04053 , 0.03622 ,\n",
       "            0.03348 , 0.0321  , 0.0262  , 0.0222  , 0.02116 , 0.02045 ,\n",
       "            0.008675, 0.005535, 0.004433], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5423729, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.2457627 , 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.2881356 , 0.2881356 , 0.29661018, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.04545455,\n",
       "            0.06060606, 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.74242425, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.8181818 , 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9985  , 0.9966  , 0.996   , 0.9956  , 0.995   ,\n",
       "            0.9946  , 0.9937  , 0.993   , 0.992   , 0.9917  , 0.9893  ,\n",
       "            0.989   , 0.9883  , 0.988   , 0.9863  , 0.9844  , 0.984   ,\n",
       "            0.9834  , 0.983   , 0.9824  , 0.982   , 0.9805  , 0.979   ,\n",
       "            0.9775  , 0.976   , 0.9756  , 0.9746  , 0.972   , 0.97    ,\n",
       "            0.9697  , 0.969   , 0.9688  , 0.9673  , 0.96    , 0.953   ,\n",
       "            0.9526  , 0.9517  , 0.9487  , 0.945   , 0.9443  , 0.9365  ,\n",
       "            0.929   , 0.9243  , 0.923   , 0.9224  , 0.921   , 0.918   ,\n",
       "            0.917   , 0.8916  , 0.8906  , 0.882   , 0.8804  , 0.88    ,\n",
       "            0.877   , 0.8726  , 0.87    , 0.8647  , 0.859   , 0.8574  ,\n",
       "            0.855   , 0.854   , 0.8535  , 0.849   , 0.848   , 0.8423  ,\n",
       "            0.841   , 0.838   , 0.834   , 0.8335  , 0.8296  , 0.829   ,\n",
       "            0.827   , 0.8115  , 0.811   , 0.8105  , 0.805   , 0.8037  ,\n",
       "            0.799   , 0.79    , 0.789   , 0.7876  , 0.7812  , 0.777   ,\n",
       "            0.775   , 0.772   , 0.771   , 0.769   , 0.761   , 0.7583  ,\n",
       "            0.757   , 0.7554  , 0.7485  , 0.748   , 0.7407  , 0.7383  ,\n",
       "            0.737   , 0.736   , 0.735   , 0.734   , 0.733   , 0.7285  ,\n",
       "            0.728   , 0.7246  , 0.724   , 0.7173  , 0.7163  , 0.715   ,\n",
       "            0.714   , 0.713   , 0.7124  , 0.71    , 0.7085  , 0.7056  ,\n",
       "            0.7007  , 0.6963  , 0.6943  , 0.6934  , 0.6924  , 0.6904  ,\n",
       "            0.6895  , 0.689   , 0.6885  , 0.6875  , 0.6855  , 0.685   ,\n",
       "            0.684   , 0.678   , 0.6777  , 0.6753  , 0.674   , 0.672   ,\n",
       "            0.6714  , 0.665   , 0.662   , 0.6606  , 0.653   , 0.651   ,\n",
       "            0.65    , 0.641   , 0.6396  , 0.635   , 0.6343  , 0.631   ,\n",
       "            0.63    , 0.625   , 0.6245  , 0.623   , 0.622   , 0.6123  ,\n",
       "            0.6084  , 0.608   , 0.603   , 0.6006  , 0.5977  , 0.5903  ,\n",
       "            0.59    , 0.5845  , 0.58    , 0.579   , 0.577   , 0.5767  ,\n",
       "            0.5747  , 0.5645  , 0.56    , 0.5464  , 0.5435  , 0.5425  ,\n",
       "            0.5166  , 0.515   , 0.514   , 0.4907  , 0.4773  , 0.469   ,\n",
       "            0.4556  , 0.4482  , 0.4167  , 0.3787  , 0.3667  , 0.3547  ,\n",
       "            0.313   , 0.3054  , 0.2878  , 0.2842  , 0.28    , 0.2451  ,\n",
       "            0.2257  , 0.2212  , 0.2172  , 0.215   , 0.2119  , 0.2059  ,\n",
       "            0.2034  , 0.1952  , 0.183   , 0.1755  , 0.1741  , 0.1609  ,\n",
       "            0.1472  , 0.1359  , 0.1329  , 0.1298  , 0.1188  , 0.1178  ,\n",
       "            0.11755 , 0.1034  , 0.0979  , 0.08417 , 0.06915 , 0.0641  ,\n",
       "            0.0531  , 0.04858 , 0.0468  , 0.044   , 0.04263 , 0.04062 ,\n",
       "            0.04037 , 0.03656 , 0.03348 , 0.0301  , 0.02881 , 0.02405 ,\n",
       "            0.01968 , 0.01935 , 0.01869 , 0.007607, 0.00472 , 0.003809],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5423729, dtype=float32),\n",
       "    'tpr': array(0.97727275, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.19491525, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33050847, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.03030303, 0.04545455, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.13636364, 0.14393939, 0.1590909 , 0.16666667,\n",
       "            0.18181819, 0.18939394, 0.20454545, 0.21969697, 0.22727273,\n",
       "            0.24242425, 0.25      , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.6969697 , 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.75      , 0.75757575, 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.7878788 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.999   , 0.997   , 0.9966  , 0.996   , 0.9956  ,\n",
       "            0.995   , 0.9946  , 0.9937  , 0.993   , 0.991   , 0.9907  ,\n",
       "            0.99    , 0.989   , 0.9873  , 0.987   , 0.9863  , 0.986   ,\n",
       "            0.9854  , 0.984   , 0.983   , 0.9814  , 0.98    , 0.979   ,\n",
       "            0.977   , 0.975   , 0.974   , 0.9736  , 0.973   , 0.9663  ,\n",
       "            0.96    , 0.959   , 0.956   , 0.953   , 0.952   , 0.9453  ,\n",
       "            0.939   , 0.935   , 0.9326  , 0.932   , 0.9287  , 0.928   ,\n",
       "            0.905   , 0.9043  , 0.8955  , 0.894   , 0.8916  , 0.891   ,\n",
       "            0.887   , 0.885   , 0.8804  , 0.8735  , 0.871   , 0.87    ,\n",
       "            0.869   , 0.8643  , 0.864   , 0.859   , 0.858   , 0.8545  ,\n",
       "            0.8516  , 0.851   , 0.849   , 0.8486  , 0.846   , 0.833   ,\n",
       "            0.829   , 0.8286  , 0.828   , 0.8257  , 0.821   , 0.81    ,\n",
       "            0.8037  , 0.799   , 0.7964  , 0.7954  , 0.7944  , 0.7925  ,\n",
       "            0.789   , 0.784   , 0.7817  , 0.781   , 0.775   , 0.772   ,\n",
       "            0.7676  , 0.7627  , 0.762   , 0.7593  , 0.759   , 0.758   ,\n",
       "            0.757   , 0.7534  , 0.752   , 0.7495  , 0.7485  , 0.742   ,\n",
       "            0.7397  , 0.7393  , 0.739   , 0.7373  , 0.736   , 0.7334  ,\n",
       "            0.73    , 0.726   , 0.721   , 0.72    , 0.719   , 0.7188  ,\n",
       "            0.7173  , 0.717   , 0.7163  , 0.715   , 0.7124  , 0.7114  ,\n",
       "            0.7104  , 0.71    , 0.7026  , 0.702   , 0.7017  , 0.7     ,\n",
       "            0.6987  , 0.696   , 0.6924  , 0.6895  , 0.6846  , 0.68    ,\n",
       "            0.678   , 0.6772  , 0.668   , 0.663   , 0.661   , 0.6606  ,\n",
       "            0.657   , 0.6553  , 0.653   , 0.6504  , 0.65    , 0.6484  ,\n",
       "            0.648   , 0.6475  , 0.6465  , 0.637   , 0.634   , 0.633   ,\n",
       "            0.6294  , 0.6284  , 0.6255  , 0.625   , 0.6235  , 0.615   ,\n",
       "            0.6147  , 0.608   , 0.6055  , 0.602   , 0.601   , 0.6006  ,\n",
       "            0.6     , 0.588   , 0.584   , 0.5703  , 0.5645  , 0.563   ,\n",
       "            0.538   , 0.5356  , 0.5327  , 0.5103  , 0.4944  , 0.4832  ,\n",
       "            0.4685  , 0.462   , 0.4314  , 0.3877  , 0.3755  , 0.3628  ,\n",
       "            0.32    , 0.3123  , 0.293   , 0.292   , 0.2856  , 0.2482  ,\n",
       "            0.2274  , 0.226   , 0.2186  , 0.2175  , 0.2145  , 0.2074  ,\n",
       "            0.2047  , 0.1959  , 0.1835  , 0.1755  , 0.1746  , 0.1606  ,\n",
       "            0.1461  , 0.1339  , 0.1318  , 0.1283  , 0.1172  , 0.11554 ,\n",
       "            0.1152  , 0.1036  , 0.0964  , 0.0825  , 0.06647 , 0.0613  ,\n",
       "            0.0508  , 0.0462  , 0.0446  , 0.04453 , 0.04178 , 0.04025 ,\n",
       "            0.0384  , 0.03833 , 0.03482 , 0.03102 , 0.02844 , 0.02718 ,\n",
       "            0.02203 , 0.01837 , 0.01758 , 0.01692 , 0.00685 , 0.0043  ,\n",
       "            0.003376], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5423729, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.1440678 , 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.16949153, 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.2542373 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.2881356 , 0.2881356 , 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3983051 , 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.03030303, 0.0530303 , 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.1590909 , 0.16666667, 0.18181819,\n",
       "            0.1969697 , 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.27272728, 0.28030303, 0.28787878, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.79545456, 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.999   , 0.9976  , 0.997   , 0.9966  , 0.996   ,\n",
       "            0.9956  , 0.995   , 0.9946  , 0.9927  , 0.992   , 0.9917  ,\n",
       "            0.9907  , 0.9893  , 0.989   , 0.9883  , 0.988   , 0.9873  ,\n",
       "            0.9863  , 0.9854  , 0.9844  , 0.983   , 0.982   , 0.9805  ,\n",
       "            0.9785  , 0.978   , 0.9775  , 0.9766  , 0.9707  , 0.9653  ,\n",
       "            0.964   , 0.962   , 0.9585  , 0.958   , 0.952   , 0.9463  ,\n",
       "            0.944   , 0.9414  , 0.9404  , 0.94    , 0.9375  , 0.9365  ,\n",
       "            0.916   , 0.914   , 0.9077  , 0.9062  , 0.9053  , 0.9023  ,\n",
       "            0.902   , 0.898   , 0.8965  , 0.893   , 0.8867  , 0.886   ,\n",
       "            0.8833  , 0.8823  , 0.881   , 0.8774  , 0.877   , 0.8726  ,\n",
       "            0.8687  , 0.8657  , 0.8647  , 0.8643  , 0.863   , 0.8506  ,\n",
       "            0.847   , 0.844   , 0.8433  , 0.84    , 0.8394  , 0.8296  ,\n",
       "            0.8286  , 0.828   , 0.8247  , 0.818   , 0.8154  , 0.8135  ,\n",
       "            0.806   , 0.8057  , 0.803   , 0.8022  , 0.7935  , 0.7866  ,\n",
       "            0.785   , 0.7847  , 0.782   , 0.7812  , 0.7803  , 0.78    ,\n",
       "            0.7783  , 0.774   , 0.773   , 0.772   , 0.766   , 0.765   ,\n",
       "            0.7637  , 0.7617  , 0.761   , 0.7593  , 0.757   , 0.75    ,\n",
       "            0.7456  , 0.7446  , 0.7437  , 0.743   , 0.742   , 0.741   ,\n",
       "            0.7407  , 0.7363  , 0.735   , 0.7334  , 0.733   , 0.726   ,\n",
       "            0.7256  , 0.725   , 0.7246  , 0.724   , 0.723   , 0.7183  ,\n",
       "            0.717   , 0.714   , 0.7065  , 0.7046  , 0.703   , 0.702   ,\n",
       "            0.693   , 0.6855  , 0.685   , 0.682   , 0.6787  , 0.6753  ,\n",
       "            0.6743  , 0.6724  , 0.672   , 0.6704  , 0.6685  , 0.6626  ,\n",
       "            0.6577  , 0.6553  , 0.6514  , 0.6494  , 0.648   , 0.64    ,\n",
       "            0.6396  , 0.6377  , 0.63    , 0.6294  , 0.625   , 0.624   ,\n",
       "            0.6235  , 0.623   , 0.612   , 0.6074  , 0.595   , 0.5854  ,\n",
       "            0.58    , 0.5596  , 0.5576  , 0.5454  , 0.5303  , 0.508   ,\n",
       "            0.491   , 0.4753  , 0.471   , 0.4375  , 0.3923  , 0.3796  ,\n",
       "            0.3691  , 0.321   , 0.3137  , 0.2937  , 0.2913  , 0.2856  ,\n",
       "            0.2473  , 0.2268  , 0.2255  , 0.2175  , 0.2157  , 0.2125  ,\n",
       "            0.2059  , 0.2032  , 0.1942  , 0.181   , 0.1737  , 0.172   ,\n",
       "            0.158   , 0.1432  , 0.1311  , 0.1287  , 0.1243  , 0.1144  ,\n",
       "            0.1126  , 0.1122  , 0.0998  , 0.09235 , 0.0786  , 0.06305 ,\n",
       "            0.05814 , 0.0478  , 0.04337 , 0.04178 , 0.0417  , 0.03906 ,\n",
       "            0.0377  , 0.03583 , 0.0323  , 0.02881 , 0.0262  , 0.025   ,\n",
       "            0.02022 , 0.01672 , 0.01602 , 0.01543 , 0.006073, 0.00378 ,\n",
       "            0.002947], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5508475, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.04545455, 0.06818182, 0.07575758,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.18181819,\n",
       "            0.1969697 , 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.27272728, 0.28030303, 0.28787878, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.5       , 0.50757575,\n",
       "            0.52272725, 0.52272725, 0.5378788 , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6439394 , 0.6515151 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.998   , 0.9976  , 0.997   , 0.9966  ,\n",
       "            0.996   , 0.9956  , 0.994   , 0.9937  , 0.993   , 0.9927  ,\n",
       "            0.992   , 0.991   , 0.9907  , 0.99    , 0.9897  , 0.9893  ,\n",
       "            0.989   , 0.988   , 0.987   , 0.986   , 0.985   , 0.9834  ,\n",
       "            0.982   , 0.9814  , 0.981   , 0.98    , 0.9756  , 0.9697  ,\n",
       "            0.969   , 0.9673  , 0.964   , 0.9585  , 0.9546  , 0.9536  ,\n",
       "            0.951   , 0.948   , 0.9473  , 0.947   , 0.945   , 0.9297  ,\n",
       "            0.9233  , 0.923   , 0.9204  , 0.919   , 0.9146  , 0.914   ,\n",
       "            0.9097  , 0.9023  , 0.901   , 0.9004  , 0.8975  , 0.8945  ,\n",
       "            0.894   , 0.889   , 0.888   , 0.885   , 0.884   , 0.883   ,\n",
       "            0.8823  , 0.8726  , 0.871   , 0.8667  , 0.8623  , 0.861   ,\n",
       "            0.8555  , 0.853   , 0.852   , 0.8516  , 0.85    , 0.8438  ,\n",
       "            0.8423  , 0.8413  , 0.8403  , 0.8335  , 0.8315  , 0.8306  ,\n",
       "            0.829   , 0.8213  , 0.8145  , 0.811   , 0.81    , 0.809   ,\n",
       "            0.8086  , 0.805   , 0.804   , 0.803   , 0.8027  , 0.8022  ,\n",
       "            0.798   , 0.7974  , 0.796   , 0.7954  , 0.794   , 0.793   ,\n",
       "            0.7915  , 0.79    , 0.784   , 0.782   , 0.7773  , 0.7764  ,\n",
       "            0.776   , 0.7754  , 0.775   , 0.7734  , 0.773   , 0.7725  ,\n",
       "            0.7686  , 0.766   , 0.7646  , 0.764   , 0.762   , 0.7593  ,\n",
       "            0.7583  , 0.758   , 0.7563  , 0.756   , 0.7554  , 0.7495  ,\n",
       "            0.7485  , 0.7456  , 0.7373  , 0.737   , 0.7354  , 0.734   ,\n",
       "            0.7256  , 0.719   , 0.718   , 0.716   , 0.715   , 0.7104  ,\n",
       "            0.7095  , 0.7065  , 0.706   , 0.704   , 0.7017  , 0.699   ,\n",
       "            0.695   , 0.6904  , 0.687   , 0.6836  , 0.6826  , 0.682   ,\n",
       "            0.679   , 0.673   , 0.6694  , 0.6636  , 0.659   , 0.658   ,\n",
       "            0.657   , 0.655   , 0.652   , 0.643   , 0.6387  , 0.627   ,\n",
       "            0.6143  , 0.604   , 0.589   , 0.587   , 0.565   , 0.557   ,\n",
       "            0.5283  , 0.502   , 0.4875  , 0.4863  , 0.445   , 0.402   ,\n",
       "            0.389   , 0.3801  , 0.325   , 0.3188  , 0.2986  , 0.2915  ,\n",
       "            0.289   , 0.2493  , 0.2295  , 0.2249  , 0.2194  , 0.2166  ,\n",
       "            0.2133  , 0.2074  , 0.2045  , 0.1953  , 0.181   , 0.1747  ,\n",
       "            0.1715  , 0.1573  , 0.1421  , 0.1301  , 0.1273  , 0.1219  ,\n",
       "            0.11316 , 0.111   , 0.11084 , 0.0967  , 0.0896  , 0.07574 ,\n",
       "            0.06064 , 0.05594 , 0.04553 , 0.04123 , 0.03964 , 0.037   ,\n",
       "            0.03568 , 0.03384 , 0.03372 , 0.03021 , 0.02707 , 0.02443 ,\n",
       "            0.02324 , 0.0188  , 0.015305, 0.01484 , 0.01428 , 0.00547 ,\n",
       "            0.003338, 0.00259 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5508475, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.22881356, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.29661018, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.5       , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.03030303, 0.06818182, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.12878788, 0.14393939,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.24242425, 0.25      , 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.52272725, 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.9985  , 0.998   , 0.9976  , 0.997   ,\n",
       "            0.9966  , 0.996   , 0.995   , 0.9946  , 0.9937  , 0.9927  ,\n",
       "            0.992   , 0.9917  , 0.991   , 0.99    , 0.9897  , 0.989   ,\n",
       "            0.9883  , 0.988   , 0.9873  , 0.986   , 0.985   , 0.9844  ,\n",
       "            0.984   , 0.983   , 0.979   , 0.974   , 0.9736  , 0.9717  ,\n",
       "            0.9688  , 0.964   , 0.9604  , 0.96    , 0.9575  , 0.955   ,\n",
       "            0.954   , 0.9536  , 0.951   , 0.9385  , 0.932   , 0.9316  ,\n",
       "            0.9297  , 0.9287  , 0.924   , 0.92    , 0.9194  , 0.919   ,\n",
       "            0.913   , 0.912   , 0.9106  , 0.908   , 0.906   , 0.9053  ,\n",
       "            0.9004  , 0.9     , 0.8994  , 0.8975  , 0.897   , 0.8965  ,\n",
       "            0.895   , 0.894   , 0.8857  , 0.8804  , 0.8765  , 0.8745  ,\n",
       "            0.87    , 0.868   , 0.867   , 0.8667  , 0.8623  , 0.8604  ,\n",
       "            0.86    , 0.8594  , 0.858   , 0.857   , 0.8516  , 0.849   ,\n",
       "            0.848   , 0.8447  , 0.8403  , 0.8335  , 0.8306  , 0.83    ,\n",
       "            0.8296  , 0.8286  , 0.8276  , 0.826   , 0.823   , 0.8223  ,\n",
       "            0.822   , 0.821   , 0.818   , 0.8174  , 0.816   , 0.8154  ,\n",
       "            0.813   , 0.812   , 0.8096  , 0.8027  , 0.8022  , 0.801   ,\n",
       "            0.7974  , 0.797   , 0.7964  , 0.7954  , 0.7944  , 0.7905  ,\n",
       "            0.7896  , 0.786   , 0.7856  , 0.782   , 0.7817  , 0.7812  ,\n",
       "            0.7803  , 0.779   , 0.7773  , 0.777   , 0.7725  , 0.771   ,\n",
       "            0.7695  , 0.761   , 0.7593  , 0.7583  , 0.75    , 0.743   ,\n",
       "            0.742   , 0.74    , 0.7363  , 0.7354  , 0.735   , 0.7324  ,\n",
       "            0.731   , 0.7285  , 0.7256  , 0.725   , 0.722   , 0.7197  ,\n",
       "            0.7153  , 0.711   , 0.7085  , 0.708   , 0.703   , 0.6987  ,\n",
       "            0.6934  , 0.6895  , 0.684   , 0.683   , 0.682   , 0.6787  ,\n",
       "            0.6743  , 0.668   , 0.6636  , 0.653   , 0.6367  , 0.6216  ,\n",
       "            0.6123  , 0.611   , 0.58    , 0.579   , 0.544   , 0.513   ,\n",
       "            0.4978  , 0.4966  , 0.4563  , 0.4094  , 0.3958  , 0.3875  ,\n",
       "            0.3303  , 0.3232  , 0.3022  , 0.2961  , 0.292   , 0.251   ,\n",
       "            0.2303  , 0.2264  , 0.2198  , 0.2175  , 0.2144  , 0.2075  ,\n",
       "            0.2045  , 0.195   , 0.1803  , 0.174   , 0.171   , 0.156   ,\n",
       "            0.1406  , 0.1279  , 0.1257  , 0.1198  , 0.111   , 0.1086  ,\n",
       "            0.1084  , 0.096   , 0.0874  , 0.074   , 0.05823 , 0.0535  ,\n",
       "            0.04346 , 0.03918 , 0.0377  , 0.0376  , 0.03506 , 0.03366 ,\n",
       "            0.03198 , 0.03192 , 0.0286  , 0.02518 , 0.02298 , 0.02187 ,\n",
       "            0.0173  , 0.01428 , 0.013535, 0.01297 , 0.004925, 0.003052,\n",
       "            0.002314], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5677966, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.18644068, 0.18644068, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.3983051 , 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.03030303, 0.07575758, 0.08333334,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.13636364, 0.14393939,\n",
       "            0.1590909 , 0.18181819, 0.1969697 , 0.21969697, 0.22727273,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.40151516, 0.4090909 , 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.65909094, 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.75757575, 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   , 0.994   ,\n",
       "            0.9937  , 0.993   , 0.992   , 0.9917  , 0.991   , 0.9907  ,\n",
       "            0.99    , 0.9897  , 0.989   , 0.988   , 0.9873  , 0.986   ,\n",
       "            0.983   , 0.9785  , 0.978   , 0.9766  , 0.974   , 0.9736  ,\n",
       "            0.9697  , 0.968   , 0.965   , 0.9624  , 0.961   , 0.9595  ,\n",
       "            0.949   , 0.944   , 0.9414  , 0.9404  , 0.936   , 0.935   ,\n",
       "            0.9326  , 0.9316  , 0.9307  , 0.927   , 0.926   , 0.9243  ,\n",
       "            0.922   , 0.9204  , 0.92    , 0.914   , 0.913   , 0.9126  ,\n",
       "            0.912   , 0.9106  , 0.91    , 0.9097  , 0.904   , 0.9023  ,\n",
       "            0.8975  , 0.8945  , 0.8916  , 0.8877  , 0.886   , 0.8853  ,\n",
       "            0.879   , 0.8784  , 0.877   , 0.876   , 0.8755  , 0.8716  ,\n",
       "            0.869   , 0.8687  , 0.865   , 0.863   , 0.857   , 0.8545  ,\n",
       "            0.853   , 0.852   , 0.8506  , 0.848   , 0.8467  , 0.8457  ,\n",
       "            0.845   , 0.844   , 0.843   , 0.8423  , 0.841   , 0.8403  ,\n",
       "            0.8374  , 0.8335  , 0.827   , 0.8267  , 0.8257  , 0.823   ,\n",
       "            0.822   , 0.8203  , 0.816   , 0.815   , 0.812   , 0.807   ,\n",
       "            0.8066  , 0.8057  , 0.804   , 0.803   , 0.8027  , 0.8022  ,\n",
       "            0.801   , 0.7983  , 0.797   , 0.796   , 0.7876  , 0.7856  ,\n",
       "            0.785   , 0.7847  , 0.7764  , 0.77    , 0.7695  , 0.7666  ,\n",
       "            0.7637  , 0.7627  , 0.7617  , 0.7603  , 0.7583  , 0.756   ,\n",
       "            0.752   , 0.7485  , 0.7437  , 0.7383  , 0.7363  , 0.736   ,\n",
       "            0.7305  , 0.727   , 0.721   , 0.718   , 0.712   , 0.7114  ,\n",
       "            0.709   , 0.7065  , 0.7007  , 0.6953  , 0.6914  , 0.685   ,\n",
       "            0.681   , 0.663   , 0.6455  , 0.639   , 0.6377  , 0.604   ,\n",
       "            0.602   , 0.5664  , 0.53    , 0.513   , 0.47    , 0.4226  ,\n",
       "            0.4082  , 0.4023  , 0.3381  , 0.331   , 0.3098  , 0.3005  ,\n",
       "            0.2979  , 0.255   , 0.235   , 0.2285  , 0.2235  , 0.22    ,\n",
       "            0.2167  , 0.2106  , 0.2075  , 0.1976  , 0.1816  , 0.1761  ,\n",
       "            0.172   , 0.1565  , 0.1407  , 0.1283  , 0.1251  , 0.1184  ,\n",
       "            0.1103  , 0.108   , 0.09436 , 0.0854  , 0.07196 , 0.05634 ,\n",
       "            0.05176 , 0.04163 , 0.03748 , 0.0359  , 0.0334  , 0.0321  ,\n",
       "            0.03033 , 0.02696 , 0.02382 , 0.02153 , 0.02045 , 0.01622 ,\n",
       "            0.01317 , 0.01263 , 0.0121  , 0.00445 , 0.002705, 0.002043],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5677966, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.16949153, 0.18644068,\n",
       "            0.18644068, 0.20338982, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.27966103, 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.06060606, 0.08333334, 0.09848485,\n",
       "            0.10606061, 0.12878788, 0.14393939, 0.1590909 , 0.18181819,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.24242425, 0.25      ,\n",
       "            0.27272728, 0.28030303, 0.29545453, 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.4469697 , 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.5530303 , 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6439394 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.995   , 0.9946  , 0.994   ,\n",
       "            0.9937  , 0.993   , 0.9927  , 0.992   , 0.991   , 0.99    ,\n",
       "            0.9897  , 0.9893  , 0.9883  , 0.986   , 0.982   , 0.9814  ,\n",
       "            0.9805  , 0.9785  , 0.977   , 0.974   , 0.973   , 0.971   ,\n",
       "            0.9688  , 0.9673  , 0.966   , 0.9653  , 0.9585  , 0.954   ,\n",
       "            0.951   , 0.9497  , 0.948   , 0.9453  , 0.944   , 0.9434  ,\n",
       "            0.9414  , 0.939   , 0.938   , 0.9375  , 0.935   , 0.9326  ,\n",
       "            0.932   , 0.9272  , 0.927   , 0.9263  , 0.926   , 0.9233  ,\n",
       "            0.9224  , 0.9204  , 0.9175  , 0.9136  , 0.91    , 0.9053  ,\n",
       "            0.9043  , 0.9033  , 0.9023  , 0.897   , 0.8965  , 0.8955  ,\n",
       "            0.895   , 0.8945  , 0.89    , 0.888   , 0.887   , 0.884   ,\n",
       "            0.8823  , 0.882   , 0.8774  , 0.8755  , 0.874   , 0.873   ,\n",
       "            0.872   , 0.869   , 0.8687  , 0.868   , 0.8677  , 0.8667  ,\n",
       "            0.8657  , 0.865   , 0.8633  , 0.8604  , 0.86    , 0.8564  ,\n",
       "            0.853   , 0.8516  , 0.851   , 0.848   , 0.847   , 0.8467  ,\n",
       "            0.846   , 0.8457  , 0.845   , 0.8447  , 0.8403  , 0.84    ,\n",
       "            0.8374  , 0.837   , 0.8315  , 0.8306  , 0.829   , 0.8286  ,\n",
       "            0.824   , 0.823   , 0.8228  , 0.822   , 0.8193  , 0.814   ,\n",
       "            0.8125  , 0.812   , 0.8105  , 0.8037  , 0.7974  , 0.797   ,\n",
       "            0.7944  , 0.7925  , 0.7896  , 0.789   , 0.786   , 0.784   ,\n",
       "            0.7793  , 0.779   , 0.7783  , 0.7754  , 0.7725  , 0.766   ,\n",
       "            0.765   , 0.7646  , 0.759   , 0.756   , 0.75    , 0.7466  ,\n",
       "            0.741   , 0.737   , 0.7354  , 0.7275  , 0.724   , 0.7207  ,\n",
       "            0.7114  , 0.6963  , 0.691   , 0.6685  , 0.668   , 0.667   ,\n",
       "            0.6323  , 0.62    , 0.5874  , 0.5415  , 0.5264  , 0.5254  ,\n",
       "            0.4778  , 0.4329  , 0.4177  , 0.414   , 0.342   , 0.336   ,\n",
       "            0.3152  , 0.3013  , 0.3005  , 0.257   , 0.2379  , 0.2274  ,\n",
       "            0.2256  , 0.2208  , 0.2173  , 0.212   , 0.2089  , 0.1987  ,\n",
       "            0.1815  , 0.1771  , 0.1715  , 0.1559  , 0.1396  , 0.1278  ,\n",
       "            0.1238  , 0.11597 , 0.10876 , 0.1067  , 0.09155 , 0.0827  ,\n",
       "            0.0694  , 0.0541  , 0.0496  , 0.03955 , 0.03555 , 0.03403 ,\n",
       "            0.03397 , 0.03162 , 0.03033 , 0.0286  , 0.02855 , 0.02527 ,\n",
       "            0.02237 , 0.02007 , 0.01901 , 0.015015, 0.0121  , 0.01164 ,\n",
       "            0.01116 , 0.00399 , 0.002398, 0.001803], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5677966, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.18644068, 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.03787879, 0.08333334, 0.09848485,\n",
       "            0.10606061, 0.14393939, 0.15151516, 0.1590909 , 0.18939394,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.25757575, 0.27272728,\n",
       "            0.28030303, 0.29545453, 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.74242425, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.7878788 , 0.7878788 , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 1.      , 0.9995  , 0.999   , 0.9985  , 0.998   ,\n",
       "            0.9976  , 0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   ,\n",
       "            0.9946  , 0.994   , 0.9937  , 0.993   , 0.992   , 0.9917  ,\n",
       "            0.991   , 0.99    , 0.989   , 0.985   , 0.9844  , 0.984   ,\n",
       "            0.982   , 0.98    , 0.9795  , 0.9785  , 0.978   , 0.9766  ,\n",
       "            0.9746  , 0.9727  , 0.971   , 0.97    , 0.966   , 0.963   ,\n",
       "            0.96    , 0.958   , 0.9546  , 0.953   , 0.952   , 0.951   ,\n",
       "            0.9478  , 0.9473  , 0.9453  , 0.9434  , 0.943   , 0.9424  ,\n",
       "            0.9395  , 0.939   , 0.9375  , 0.9365  , 0.935   , 0.934   ,\n",
       "            0.9307  , 0.9277  , 0.9253  , 0.924   , 0.919   , 0.9185  ,\n",
       "            0.918   , 0.917   , 0.9126  , 0.912   , 0.911   , 0.91    ,\n",
       "            0.9067  , 0.9043  , 0.9033  , 0.8984  , 0.898   , 0.895   ,\n",
       "            0.894   , 0.8936  , 0.892   , 0.891   , 0.89    , 0.8896  ,\n",
       "            0.8887  , 0.8867  , 0.886   , 0.8857  , 0.8853  , 0.8833  ,\n",
       "            0.8823  , 0.88    , 0.877   , 0.876   , 0.874   , 0.872   ,\n",
       "            0.869   , 0.868   , 0.867   , 0.866   , 0.863   , 0.8623  ,\n",
       "            0.8594  , 0.8545  , 0.8535  , 0.853   , 0.8525  , 0.851   ,\n",
       "            0.8486  , 0.848   , 0.8457  , 0.8438  , 0.839   , 0.837   ,\n",
       "            0.8364  , 0.834   , 0.8286  , 0.8228  , 0.822   , 0.82    ,\n",
       "            0.8193  , 0.817   , 0.815   , 0.8135  , 0.8125  , 0.81    ,\n",
       "            0.806   , 0.8047  , 0.803   , 0.801   , 0.7983  , 0.7935  ,\n",
       "            0.793   , 0.7925  , 0.7915  , 0.7856  , 0.785   , 0.7827  ,\n",
       "            0.777   , 0.774   , 0.769   , 0.7686  , 0.763   , 0.7627  ,\n",
       "            0.7534  , 0.752   , 0.7495  , 0.74    , 0.718   , 0.71    ,\n",
       "            0.696   , 0.695   , 0.6914  , 0.659   , 0.638   , 0.6084  ,\n",
       "            0.5547  , 0.54    , 0.538   , 0.4888  , 0.4436  , 0.4275  ,\n",
       "            0.424   , 0.3481  , 0.3413  , 0.3213  , 0.3057  , 0.3035  ,\n",
       "            0.2598  , 0.2413  , 0.2285  , 0.2283  , 0.2225  , 0.219   ,\n",
       "            0.2137  , 0.2108  , 0.2002  , 0.1821  , 0.1787  , 0.1719  ,\n",
       "            0.1558  , 0.1392  , 0.1279  , 0.1229  , 0.1142  , 0.1078  ,\n",
       "            0.1058  , 0.0898  , 0.0806  , 0.0677  , 0.05225 , 0.04788 ,\n",
       "            0.0379  , 0.03397 , 0.03247 , 0.0324  , 0.0301  , 0.02887 ,\n",
       "            0.02718 , 0.02711 , 0.02391 , 0.02121 , 0.01883 , 0.01785 ,\n",
       "            0.014114, 0.0112  , 0.0109  , 0.01049 , 0.003622, 0.00215 ,\n",
       "            0.001604], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5762712, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.07575758, 0.09848485, 0.11363637,\n",
       "            0.15151516, 0.1590909 , 0.18939394, 0.21969697, 0.23484848,\n",
       "            0.25757575, 0.27272728, 0.28030303, 0.28787878, 0.3030303 ,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.5833333 , 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 , 0.6666667 ,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.74242425,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.7878788 , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 1.      , 0.9995  , 0.999   , 0.9985  , 0.998   ,\n",
       "            0.9976  , 0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   ,\n",
       "            0.9946  , 0.994   , 0.9937  , 0.993   , 0.992   , 0.991   ,\n",
       "            0.9883  , 0.988   , 0.9873  , 0.986   , 0.9844  , 0.983   ,\n",
       "            0.9824  , 0.9814  , 0.98    , 0.978   , 0.977   , 0.976   ,\n",
       "            0.973   , 0.9707  , 0.968   , 0.9663  , 0.963   , 0.9624  ,\n",
       "            0.9604  , 0.96    , 0.958   , 0.9575  , 0.9565  , 0.955   ,\n",
       "            0.9536  , 0.953   , 0.9526  , 0.951   , 0.9507  , 0.95    ,\n",
       "            0.9487  , 0.9478  , 0.947   , 0.9463  , 0.946   , 0.9453  ,\n",
       "            0.9434  , 0.9404  , 0.937   , 0.933   , 0.9326  , 0.9316  ,\n",
       "            0.931   , 0.9277  , 0.9263  , 0.926   , 0.9253  , 0.9224  ,\n",
       "            0.92    , 0.919   , 0.914   , 0.9136  , 0.912   , 0.9116  ,\n",
       "            0.9097  , 0.909   , 0.908   , 0.907   , 0.9067  , 0.905   ,\n",
       "            0.9043  , 0.904   , 0.9033  , 0.9004  , 0.8975  , 0.8955  ,\n",
       "            0.895   , 0.8945  , 0.893   , 0.891   , 0.889   , 0.8877  ,\n",
       "            0.887   , 0.886   , 0.884   , 0.883   , 0.8804  , 0.88    ,\n",
       "            0.876   , 0.8755  , 0.8745  , 0.8735  , 0.873   , 0.8706  ,\n",
       "            0.868   , 0.8643  , 0.862   , 0.86    , 0.8574  , 0.857   ,\n",
       "            0.852   , 0.846   , 0.845   , 0.844   , 0.8438  , 0.842   ,\n",
       "            0.8394  , 0.8374  , 0.8364  , 0.8345  , 0.832   , 0.8296  ,\n",
       "            0.8276  , 0.825   , 0.823   , 0.8193  , 0.819   , 0.818   ,\n",
       "            0.817   , 0.811   , 0.8086  , 0.803   , 0.8003  , 0.796   ,\n",
       "            0.7944  , 0.7896  , 0.789   , 0.78    , 0.779   , 0.7764  ,\n",
       "            0.768   , 0.745   , 0.7373  , 0.724   , 0.721   , 0.7183  ,\n",
       "            0.687   , 0.663   , 0.634   , 0.581   , 0.5615  , 0.561   ,\n",
       "            0.515   , 0.4624  , 0.4458  , 0.4382  , 0.3655  , 0.356   ,\n",
       "            0.3345  , 0.3208  , 0.3184  , 0.2698  , 0.2493  , 0.239   ,\n",
       "            0.2362  , 0.2311  , 0.2277  , 0.22    , 0.2168  , 0.2059  ,\n",
       "            0.187   , 0.1835  , 0.177   , 0.1589  , 0.1418  , 0.1293  ,\n",
       "            0.1252  , 0.11597 , 0.1086  , 0.10614 , 0.10596 , 0.0937  ,\n",
       "            0.08154 , 0.06915 , 0.05154 , 0.0468  , 0.0372  , 0.03314 ,\n",
       "            0.03174 , 0.03162 , 0.02931 , 0.02791 , 0.02646 , 0.02626 ,\n",
       "            0.02333 , 0.02017 , 0.01826 , 0.0173  , 0.013275, 0.01082 ,\n",
       "            0.01017 , 0.00971 , 0.003351, 0.002058, 0.001467], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5762712, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.16949153, 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.09848485, 0.12878788, 0.1590909 ,\n",
       "            0.18939394, 0.21969697, 0.24242425, 0.27272728, 0.28030303,\n",
       "            0.3030303 , 0.3181818 , 0.32575756, 0.33333334, 0.34848484,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.6515151 , 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.7348485 , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.7878788 , 0.7878788 , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.       , 1.       , 0.9995   , 0.999    , 0.9985   , 0.998    ,\n",
       "            0.9976   , 0.997    , 0.9966   , 0.996    , 0.9956   , 0.995    ,\n",
       "            0.994    , 0.9937   , 0.991    , 0.9907   , 0.9897   , 0.989    ,\n",
       "            0.988    , 0.9873   , 0.987    , 0.9854   , 0.983    , 0.9824   ,\n",
       "            0.9814   , 0.9805   , 0.978    , 0.976    , 0.9746   , 0.9717   ,\n",
       "            0.9707   , 0.969    , 0.9688   , 0.968    , 0.966    , 0.9653   ,\n",
       "            0.9644   , 0.9634   , 0.9624   , 0.962    , 0.9604   , 0.9595   ,\n",
       "            0.959    , 0.9585   , 0.958    , 0.957    , 0.9556   , 0.9536   ,\n",
       "            0.95     , 0.9487   , 0.9473   , 0.947    , 0.946    , 0.9453   ,\n",
       "            0.943    , 0.941    , 0.94     , 0.9385   , 0.936    , 0.9355   ,\n",
       "            0.9307   , 0.93     , 0.9297   , 0.929    , 0.9272   , 0.926    ,\n",
       "            0.925    , 0.9243   , 0.924    , 0.923    , 0.9224   , 0.922    ,\n",
       "            0.919    , 0.9165   , 0.915    , 0.914    , 0.9136   , 0.913    ,\n",
       "            0.9106   , 0.909    , 0.9077   , 0.907    , 0.906    , 0.9043   ,\n",
       "            0.9033   , 0.901    , 0.8975   , 0.897    , 0.8965   , 0.896    ,\n",
       "            0.8955   , 0.893    , 0.891    , 0.888    , 0.8867   , 0.8853   ,\n",
       "            0.884    , 0.8833   , 0.881    , 0.88     , 0.8765   , 0.871    ,\n",
       "            0.87     , 0.8696   , 0.8687   , 0.8677   , 0.8643   , 0.863    ,\n",
       "            0.8613   , 0.86     , 0.859    , 0.8555   , 0.854    , 0.8516   ,\n",
       "            0.849    , 0.8467   , 0.846    , 0.8447   , 0.8438   , 0.8384   ,\n",
       "            0.8354   , 0.831    , 0.828    , 0.824    , 0.8228   , 0.818    ,\n",
       "            0.817    , 0.808    , 0.807    , 0.8057   , 0.7974   , 0.775    ,\n",
       "            0.7666   , 0.755    , 0.75     , 0.7485   , 0.7183   , 0.6943   ,\n",
       "            0.6655   , 0.614    , 0.592    , 0.5903   , 0.545    , 0.4893   ,\n",
       "            0.4714   , 0.463    , 0.3872   , 0.3762   , 0.354    , 0.3396   ,\n",
       "            0.3357   , 0.2837   , 0.263    , 0.2512   , 0.2487   , 0.2426   ,\n",
       "            0.2391   , 0.2303   , 0.2269   , 0.2161   , 0.1952   , 0.1921   ,\n",
       "            0.1846   , 0.165    , 0.147    , 0.1339   , 0.1294   , 0.119    ,\n",
       "            0.11145  , 0.10876  , 0.1086   , 0.09686  , 0.083    , 0.07056  ,\n",
       "            0.05154  , 0.04654  , 0.03677  , 0.03265  , 0.03125  , 0.03114  ,\n",
       "            0.02876  , 0.02722  , 0.02596  , 0.02567  , 0.02284  , 0.01945  ,\n",
       "            0.01778  , 0.01678  , 0.01263  , 0.01033  , 0.009636 , 0.00919  ,\n",
       "            0.003088 , 0.0019045, 0.00133  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.58474576, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.2457627 , 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.29661018, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.03787879, 0.10606061, 0.15151516, 0.1969697 ,\n",
       "            0.22727273, 0.2651515 , 0.28030303, 0.3030303 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.36363637, 0.37878788,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.5681818 , 0.5681818 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 , 0.6515151 ,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.7348485 , 0.75      , 0.7651515 , 0.7651515 , 0.77272725,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 1.      , 0.9995  , 0.999   , 0.9985  , 0.998   ,\n",
       "            0.9976  , 0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   ,\n",
       "            0.993   , 0.9927  , 0.9917  , 0.99    , 0.9897  , 0.9893  ,\n",
       "            0.989   , 0.9863  , 0.986   , 0.9844  , 0.983   , 0.981   ,\n",
       "            0.98    , 0.977   , 0.9756  , 0.975   , 0.974   , 0.9736  ,\n",
       "            0.9717  , 0.971   , 0.9707  , 0.9697  , 0.969   , 0.9688  ,\n",
       "            0.968   , 0.9673  , 0.9663  , 0.966   , 0.9653  , 0.9644  ,\n",
       "            0.964   , 0.962   , 0.959   , 0.957   , 0.956   , 0.9546  ,\n",
       "            0.954   , 0.9526  , 0.9507  , 0.9497  , 0.9487  , 0.9463  ,\n",
       "            0.946   , 0.942   , 0.9414  , 0.941   , 0.939   , 0.9375  ,\n",
       "            0.9365  , 0.936   , 0.9355  , 0.9346  , 0.934   , 0.9336  ,\n",
       "            0.9316  , 0.931   , 0.929   , 0.9272  , 0.927   , 0.9263  ,\n",
       "            0.925   , 0.9243  , 0.9214  , 0.921   , 0.9204  , 0.9194  ,\n",
       "            0.917   , 0.9165  , 0.9146  , 0.9106  , 0.91    , 0.9097  ,\n",
       "            0.909   , 0.907   , 0.9062  , 0.9053  , 0.902   , 0.9014  ,\n",
       "            0.9004  , 0.8984  , 0.8975  , 0.895   , 0.8916  , 0.8867  ,\n",
       "            0.8853  , 0.885   , 0.8843  , 0.881   , 0.8804  , 0.8774  ,\n",
       "            0.876   , 0.8726  , 0.8687  , 0.866   , 0.8647  , 0.864   ,\n",
       "            0.863   , 0.861   , 0.8564  , 0.8535  , 0.849   , 0.846   ,\n",
       "            0.8423  , 0.841   , 0.837   , 0.836   , 0.827   , 0.8267  ,\n",
       "            0.8247  , 0.816   , 0.795   , 0.786   , 0.7754  , 0.7695  ,\n",
       "            0.7397  , 0.713   , 0.6865  , 0.6357  , 0.6104  , 0.6094  ,\n",
       "            0.5654  , 0.5054  , 0.4868  , 0.4734  , 0.401   , 0.3884  ,\n",
       "            0.3652  , 0.3516  , 0.3455  , 0.291   , 0.2693  , 0.2583  ,\n",
       "            0.255   , 0.2485  , 0.2452  , 0.235   , 0.2313  , 0.2207  ,\n",
       "            0.1982  , 0.1956  , 0.1879  , 0.1669  , 0.1483  , 0.1342  ,\n",
       "            0.1299  , 0.1195  , 0.11127 , 0.1082  , 0.1076  , 0.0981  ,\n",
       "            0.0828  , 0.07043 , 0.0504  , 0.04526 , 0.03574 , 0.03162 ,\n",
       "            0.03033 , 0.03015 , 0.02785 , 0.02615 , 0.02509 , 0.02466 ,\n",
       "            0.02203 , 0.01851 , 0.01698 , 0.01602 , 0.01192 , 0.00978 ,\n",
       "            0.00902 , 0.00861 , 0.002846, 0.001755, 0.001211], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59322035, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.08474576, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.13559322, 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.07575758, 0.14393939, 0.1969697 , 0.25      ,\n",
       "            0.28030303, 0.31060606, 0.3181818 , 0.33333334, 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.40151516, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.47727272, 0.4848485 , 0.4848485 , 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.54545456, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.6060606 , 0.6060606 , 0.6136364 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6515151 , 0.6515151 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.7121212 , 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.7878788 , 0.79545456,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.81060606, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 1.      , 0.9995  , 0.999   , 0.9985  , 0.998   ,\n",
       "            0.9976  , 0.997   , 0.9966  , 0.9946  , 0.994   , 0.9937  ,\n",
       "            0.9927  , 0.9917  , 0.9897  , 0.9893  , 0.989   , 0.9883  ,\n",
       "            0.9873  , 0.986   , 0.985   , 0.983   , 0.9814  , 0.981   ,\n",
       "            0.9805  , 0.98    , 0.9785  , 0.978   , 0.9775  , 0.977   ,\n",
       "            0.9766  , 0.976   , 0.975   , 0.974   , 0.9736  , 0.972   ,\n",
       "            0.9717  , 0.97    , 0.968   , 0.9663  , 0.9653  , 0.964   ,\n",
       "            0.9634  , 0.963   , 0.961   , 0.9604  , 0.9595  , 0.9575  ,\n",
       "            0.957   , 0.953   , 0.9526  , 0.951   , 0.949   , 0.948   ,\n",
       "            0.9473  , 0.9463  , 0.946   , 0.9443  , 0.9424  , 0.9404  ,\n",
       "            0.94    , 0.9395  , 0.938   , 0.935   , 0.9336  , 0.933   ,\n",
       "            0.9316  , 0.9307  , 0.929   , 0.926   , 0.9253  , 0.925   ,\n",
       "            0.9243  , 0.924   , 0.922   , 0.921   , 0.9204  , 0.9185  ,\n",
       "            0.916   , 0.9146  , 0.9136  , 0.909   , 0.905   , 0.9043  ,\n",
       "            0.903   , 0.9023  , 0.9     , 0.898   , 0.8955  , 0.895   ,\n",
       "            0.894   , 0.8926  , 0.8916  , 0.888   , 0.8853  , 0.884   ,\n",
       "            0.882   , 0.8804  , 0.8765  , 0.8735  , 0.8696  , 0.8667  ,\n",
       "            0.864   , 0.862   , 0.8584  , 0.8574  , 0.8496  , 0.849   ,\n",
       "            0.847   , 0.838   , 0.8193  , 0.819   , 0.8003  , 0.795   ,\n",
       "            0.7944  , 0.765   , 0.74    , 0.713   , 0.674   , 0.644   ,\n",
       "            0.6387  , 0.6074  , 0.5337  , 0.516   , 0.4907  , 0.4336  ,\n",
       "            0.4163  , 0.3901  , 0.3865  , 0.3706  , 0.3118  , 0.2861  ,\n",
       "            0.2832  , 0.2712  , 0.2676  , 0.265   , 0.25    , 0.2463  ,\n",
       "            0.2347  , 0.2108  , 0.2063  , 0.2012  , 0.1765  , 0.1572  ,\n",
       "            0.1387  , 0.1371  , 0.1271  , 0.11554 , 0.11145 , 0.1103  ,\n",
       "            0.10876 , 0.0883  , 0.0764  , 0.05212 , 0.0461  , 0.03683 ,\n",
       "            0.0324  , 0.0313  , 0.03091 , 0.02855 , 0.02635 , 0.02586 ,\n",
       "            0.02504 , 0.02284 , 0.01834 , 0.01752 , 0.01653 , 0.01169 ,\n",
       "            0.01009 , 0.00878 , 0.00835 , 0.0028  , 0.001818, 0.001188],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59322035, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.18644068, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.08333334, 0.1590909 , 0.22727273, 0.27272728,\n",
       "            0.31060606, 0.32575756, 0.33333334, 0.37121212, 0.37878788,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.50757575, 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.6060606 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6515151 ,\n",
       "            0.6515151 , 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.74242425, 0.75      , 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 1.      , 0.9995  , 0.999   , 0.9985  , 0.998   ,\n",
       "            0.9976  , 0.997   , 0.9956  , 0.995   , 0.994   , 0.9937  ,\n",
       "            0.993   , 0.9917  , 0.991   , 0.9907  , 0.9897  , 0.989   ,\n",
       "            0.9883  , 0.9863  , 0.985   , 0.9844  , 0.984   , 0.983   ,\n",
       "            0.9824  , 0.982   , 0.981   , 0.9805  , 0.98    , 0.9795  ,\n",
       "            0.979   , 0.9785  , 0.978   , 0.977   , 0.976   , 0.975   ,\n",
       "            0.973   , 0.972   , 0.971   , 0.97    , 0.969   , 0.9688  ,\n",
       "            0.9683  , 0.967   , 0.9663  , 0.966   , 0.9653  , 0.9634  ,\n",
       "            0.963   , 0.9604  , 0.96    , 0.9595  , 0.958   , 0.956   ,\n",
       "            0.955   , 0.954   , 0.9536  , 0.953   , 0.9526  , 0.9517  ,\n",
       "            0.9497  , 0.948   , 0.9478  , 0.947   , 0.946   , 0.9453  ,\n",
       "            0.9434  , 0.943   , 0.9424  , 0.942   , 0.94    , 0.9385  ,\n",
       "            0.938   , 0.9346  , 0.934   , 0.9336  , 0.932   , 0.9307  ,\n",
       "            0.93    , 0.9287  , 0.928   , 0.9253  , 0.925   , 0.9243  ,\n",
       "            0.924   , 0.9233  , 0.9185  , 0.915   , 0.9146  , 0.913   ,\n",
       "            0.9126  , 0.9106  , 0.908   , 0.9062  , 0.906   , 0.905   ,\n",
       "            0.904   , 0.902   , 0.9     , 0.897   , 0.8965  , 0.895   ,\n",
       "            0.893   , 0.8916  , 0.888   , 0.8877  , 0.8853  , 0.8813  ,\n",
       "            0.879   , 0.876   , 0.8745  , 0.8706  , 0.87    , 0.863   ,\n",
       "            0.8623  , 0.8604  , 0.8516  , 0.8457  , 0.833   , 0.815   ,\n",
       "            0.8115  , 0.809   , 0.7812  , 0.761   , 0.7305  , 0.706   ,\n",
       "            0.673   , 0.6626  , 0.646   , 0.5596  , 0.5435  , 0.505   ,\n",
       "            0.4683  , 0.4458  , 0.4277  , 0.4158  , 0.3984  , 0.336   ,\n",
       "            0.3145  , 0.3052  , 0.2908  , 0.2903  , 0.2898  , 0.269   ,\n",
       "            0.2646  , 0.2515  , 0.2272  , 0.2197  , 0.2189  , 0.1898  ,\n",
       "            0.1699  , 0.1492  , 0.146   , 0.1399  , 0.1254  , 0.12305 ,\n",
       "            0.1174  , 0.11536 , 0.09845 , 0.0863  , 0.05646 , 0.04932 ,\n",
       "            0.0403  , 0.03516 , 0.03442 , 0.0336  , 0.03114 , 0.02855 ,\n",
       "            0.02817 , 0.02696 , 0.02547 , 0.0195  , 0.0193  , 0.01848 ,\n",
       "            0.01224 , 0.01133 , 0.00919 , 0.008675, 0.003052, 0.0021  ,\n",
       "            0.001315], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.06666667, 0.075     , 0.08333334,\n",
       "            0.1       , 0.10833333, 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.5416667 , 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.64166665, 0.65      , 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.68333334, 0.68333334, 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.71666664, 0.73333335, 0.7416667 , 0.7416667 , 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.81666666, 0.8333333 ,\n",
       "            0.8333333 , 0.8333333 , 0.8333333 , 0.8333333 , 0.84166664,\n",
       "            0.84166664, 0.85833335, 0.85833335, 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.89166665,\n",
       "            0.89166665, 0.89166665, 0.89166665, 0.9       , 0.90833336,\n",
       "            0.925     , 0.925     , 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.06153846, 0.06153846, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.08461539, 0.08461539, 0.09230769, 0.09230769, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.14615385, 0.14615385, 0.14615385,\n",
       "            0.14615385, 0.15384616, 0.15384616, 0.15384616, 0.16153847,\n",
       "            0.16153847, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.18461539, 0.18461539, 0.18461539, 0.1923077 , 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.20769231, 0.21538462, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.26923078, 0.26923078, 0.26923078, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4076923 , 0.4076923 , 0.41538462, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.45384616, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.61538464, 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.484 , 0.4832, 0.4814, 0.48  , 0.477 , 0.4768, 0.4734,\n",
       "            0.473 , 0.472 , 0.4702, 0.4692, 0.469 , 0.4688, 0.4646, 0.4636,\n",
       "            0.4612, 0.461 , 0.4607, 0.4604, 0.46  , 0.4595, 0.459 , 0.4587,\n",
       "            0.4563, 0.456 , 0.4548, 0.4536, 0.4521, 0.4517, 0.4507, 0.4504,\n",
       "            0.4502, 0.4482, 0.4475, 0.4473, 0.4465, 0.445 , 0.443 , 0.4421,\n",
       "            0.4402, 0.44  , 0.4375, 0.4373, 0.4353, 0.435 , 0.4348, 0.4338,\n",
       "            0.4336, 0.4329, 0.4321, 0.4307, 0.4302, 0.4297, 0.429 , 0.4285,\n",
       "            0.4277, 0.427 , 0.426 , 0.4253, 0.4248, 0.4243, 0.4233, 0.4226,\n",
       "            0.4214, 0.421 , 0.4182, 0.418 , 0.4175, 0.4163, 0.416 , 0.4155,\n",
       "            0.4153, 0.4136, 0.4124, 0.4119, 0.4116, 0.4102, 0.4097, 0.4075,\n",
       "            0.4067, 0.4065, 0.4053, 0.405 , 0.4045, 0.4043, 0.404 , 0.4038,\n",
       "            0.4036, 0.4033, 0.4026, 0.4023, 0.4016, 0.4011, 0.4006, 0.4001,\n",
       "            0.4   , 0.3994, 0.3977, 0.3972, 0.3962, 0.3958, 0.395 , 0.3938,\n",
       "            0.3923, 0.392 , 0.3909, 0.3901, 0.39  , 0.3894, 0.3892, 0.389 ,\n",
       "            0.3887, 0.3884, 0.3882, 0.3877, 0.3867, 0.3862, 0.3855, 0.3845,\n",
       "            0.384 , 0.3828, 0.382 , 0.3818, 0.3813, 0.3809, 0.3804, 0.3801,\n",
       "            0.38  , 0.379 , 0.3772, 0.377 , 0.3752, 0.3748, 0.3743, 0.3735,\n",
       "            0.3728, 0.372 , 0.3718, 0.3716, 0.3713, 0.3691, 0.369 , 0.3687,\n",
       "            0.3684, 0.3677, 0.3674, 0.3657, 0.3628, 0.3625, 0.3616, 0.3594,\n",
       "            0.3591, 0.3562, 0.3547, 0.3545, 0.3518, 0.3513, 0.348 , 0.3477,\n",
       "            0.347 , 0.3462, 0.3452, 0.3447, 0.3435, 0.3416, 0.3408, 0.3398,\n",
       "            0.3384, 0.338 , 0.3362, 0.333 , 0.3325, 0.3323, 0.3318, 0.3315,\n",
       "            0.3274, 0.3257, 0.3228, 0.322 , 0.3218, 0.3215, 0.3213, 0.321 ,\n",
       "            0.3206, 0.3196, 0.3193, 0.3188, 0.3186, 0.3184, 0.3171, 0.317 ,\n",
       "            0.3167, 0.3154, 0.313 , 0.3127, 0.3125, 0.3115, 0.3108, 0.3105,\n",
       "            0.309 , 0.3088, 0.3079, 0.3062, 0.304 , 0.3025, 0.301 , 0.2988,\n",
       "            0.2983, 0.2942, 0.2925, 0.292 , 0.28  , 0.2566], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.1       , 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.53333336, 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.575     , 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.65833336, 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.725     , 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.80833334, 0.81666666, 0.81666666,\n",
       "            0.825     , 0.825     , 0.825     , 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.84166664, 0.84166664, 0.85      , 0.85833335,\n",
       "            0.875     , 0.875     , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.90833336, 0.90833336, 0.9166667 , 0.9166667 , 0.925     ,\n",
       "            0.925     , 0.93333334, 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06923077, 0.07692308, 0.09230769,\n",
       "            0.1       , 0.1       , 0.10769231, 0.12307692, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.13846155, 0.13846155, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.16923077, 0.17692308, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.22307692, 0.22307692,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.26153848, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.32307693,\n",
       "            0.32307693, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.34615386, 0.36153847, 0.36923078, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.3923077 , 0.3923077 ,\n",
       "            0.4       , 0.41538462, 0.42307693, 0.42307693, 0.42307693,\n",
       "            0.42307693, 0.43076923, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.4923077 , 0.4923077 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.454 , 0.4524, 0.451 , 0.4492, 0.4465, 0.4456, 0.444 ,\n",
       "            0.4438, 0.4426, 0.4404, 0.44  , 0.4373, 0.4368, 0.4355, 0.435 ,\n",
       "            0.4348, 0.433 , 0.4326, 0.432 , 0.4316, 0.4314, 0.4312, 0.4307,\n",
       "            0.4294, 0.428 , 0.4277, 0.427 , 0.426 , 0.4238, 0.4224, 0.421 ,\n",
       "            0.4204, 0.4192, 0.4187, 0.4185, 0.4158, 0.4155, 0.4146, 0.4124,\n",
       "            0.4111, 0.408 , 0.4065, 0.4058, 0.405 , 0.4043, 0.404 , 0.4033,\n",
       "            0.4004, 0.3994, 0.3982, 0.395 , 0.3926, 0.3906, 0.3892, 0.3877,\n",
       "            0.3865, 0.386 , 0.3835, 0.3828, 0.3784, 0.3782, 0.3772, 0.377 ,\n",
       "            0.3767, 0.3762, 0.3755, 0.375 , 0.3745, 0.3743, 0.3735, 0.3726,\n",
       "            0.3723, 0.3713, 0.371 , 0.369 , 0.3687, 0.3684, 0.3677, 0.3674,\n",
       "            0.3672, 0.365 , 0.3647, 0.3591, 0.359 , 0.3586, 0.3582, 0.3564,\n",
       "            0.3555, 0.3552, 0.3545, 0.3538, 0.3528, 0.3523, 0.352 , 0.3508,\n",
       "            0.35  , 0.3481, 0.3477, 0.3472, 0.347 , 0.3464, 0.3455, 0.3445,\n",
       "            0.344 , 0.3433, 0.343 , 0.342 , 0.341 , 0.3386, 0.3384, 0.337 ,\n",
       "            0.3367, 0.3357, 0.3354, 0.335 , 0.3347, 0.3335, 0.3328, 0.3323,\n",
       "            0.3315, 0.3313, 0.331 , 0.3308, 0.3303, 0.33  , 0.3293, 0.329 ,\n",
       "            0.3289, 0.3284, 0.3281, 0.3271, 0.327 , 0.326 , 0.3254, 0.3252,\n",
       "            0.3247, 0.3245, 0.3242, 0.3235, 0.323 , 0.3203, 0.32  , 0.3186,\n",
       "            0.3174, 0.3171, 0.3162, 0.3137, 0.3135, 0.313 , 0.3115, 0.3103,\n",
       "            0.3086, 0.3083, 0.3064, 0.3047, 0.304 , 0.3032, 0.302 , 0.3015,\n",
       "            0.299 , 0.2983, 0.2966, 0.2947, 0.294 , 0.2935, 0.2922, 0.289 ,\n",
       "            0.288 , 0.2878, 0.2874, 0.287 , 0.281 , 0.278 , 0.2773, 0.277 ,\n",
       "            0.2766, 0.2756, 0.275 , 0.2742, 0.274 , 0.2737, 0.2734, 0.2732,\n",
       "            0.2717, 0.271 , 0.2695, 0.2693, 0.269 , 0.2659, 0.2646, 0.2644,\n",
       "            0.2642, 0.263 , 0.2627, 0.2622, 0.262 , 0.2615, 0.2598, 0.2573,\n",
       "            0.2568, 0.256 , 0.2532, 0.253 , 0.2505, 0.2493, 0.2462, 0.2429,\n",
       "            0.2428, 0.2303, 0.2058], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.04166667,\n",
       "            0.05      , 0.06666667, 0.075     , 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.3       ,\n",
       "            0.30833334, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.59166664, 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.64166665, 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.69166666, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.7416667 , 0.75      , 0.75      , 0.7583333 , 0.7583333 ,\n",
       "            0.7583333 , 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85      ,\n",
       "            0.85      , 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.03846154, 0.05384615, 0.05384615, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.17692308, 0.17692308, 0.17692308, 0.18461539, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.20769231, 0.20769231,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23076923,\n",
       "            0.23076923, 0.23076923, 0.24615385, 0.24615385, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.3846154 , 0.3846154 , 0.3846154 ,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.43076923, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.45384616, 0.45384616, 0.45384616,\n",
       "            0.45384616, 0.45384616, 0.46923077, 0.47692308, 0.47692308,\n",
       "            0.4846154 , 0.4846154 , 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.7692308 , 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8153846 , 0.8230769 , 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4236, 0.4226, 0.4214, 0.4211, 0.418 , 0.4158, 0.4138,\n",
       "            0.412 , 0.4116, 0.411 , 0.41  , 0.4087, 0.406 , 0.4055, 0.405 ,\n",
       "            0.4048, 0.4045, 0.4033, 0.4026, 0.402 , 0.4016, 0.4014, 0.4   ,\n",
       "            0.3997, 0.3994, 0.3987, 0.396 , 0.3945, 0.3914, 0.391 , 0.3909,\n",
       "            0.3904, 0.3867, 0.3853, 0.3838, 0.383 , 0.3818, 0.3794, 0.3774,\n",
       "            0.375 , 0.3748, 0.3735, 0.3733, 0.371 , 0.3699, 0.3677, 0.3662,\n",
       "            0.3635, 0.3608, 0.3586, 0.3564, 0.3562, 0.356 , 0.3552, 0.352 ,\n",
       "            0.3425, 0.3384, 0.3376, 0.3352, 0.3335, 0.333 , 0.3325, 0.3323,\n",
       "            0.3315, 0.3313, 0.3293, 0.329 , 0.3289, 0.3281, 0.327 , 0.3257,\n",
       "            0.3245, 0.324 , 0.3232, 0.3223, 0.3218, 0.32  , 0.3176, 0.3171,\n",
       "            0.3164, 0.3157, 0.3142, 0.3135, 0.313 , 0.3123, 0.3108, 0.3103,\n",
       "            0.3098, 0.3088, 0.3066, 0.306 , 0.3057, 0.3054, 0.303 , 0.3025,\n",
       "            0.3015, 0.3013, 0.2998, 0.299 , 0.2986, 0.297 , 0.2964, 0.2961,\n",
       "            0.296 , 0.2957, 0.2954, 0.2952, 0.295 , 0.2942, 0.2935, 0.2925,\n",
       "            0.2917, 0.2915, 0.291 , 0.2908, 0.2905, 0.2903, 0.2898, 0.2883,\n",
       "            0.288 , 0.2878, 0.286 , 0.2847, 0.2844, 0.2842, 0.2837, 0.2834,\n",
       "            0.2825, 0.282 , 0.2812, 0.2808, 0.2803, 0.2788, 0.2786, 0.2783,\n",
       "            0.2769, 0.2764, 0.2761, 0.276 , 0.2756, 0.2751, 0.2747, 0.2742,\n",
       "            0.2737, 0.2732, 0.273 , 0.272 , 0.271 , 0.2708, 0.2703, 0.2695,\n",
       "            0.269 , 0.268 , 0.2678, 0.2668, 0.2664, 0.2654, 0.2644, 0.2634,\n",
       "            0.262 , 0.2605, 0.26  , 0.2588, 0.2576, 0.2573, 0.2563, 0.2542,\n",
       "            0.254 , 0.2517, 0.2507, 0.2505, 0.2498, 0.249 , 0.2471, 0.2434,\n",
       "            0.2422, 0.2417, 0.2397, 0.2391, 0.239 , 0.2379, 0.237 , 0.2368,\n",
       "            0.2366, 0.236 , 0.2356, 0.2351, 0.2344, 0.2335, 0.2327, 0.2319,\n",
       "            0.2311, 0.2294, 0.2252, 0.2251, 0.2249, 0.2246, 0.2239, 0.2234,\n",
       "            0.2218, 0.2213, 0.2202, 0.22  , 0.2177, 0.2162, 0.2156, 0.213 ,\n",
       "            0.2124, 0.211 , 0.2094, 0.2068, 0.2032, 0.201 , 0.1907, 0.166 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.15      , 0.15833333, 0.16666667, 0.19166666,\n",
       "            0.2       , 0.21666667, 0.225     , 0.23333333, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.53333336,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.575     , 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.6       , 0.6       ,\n",
       "            0.6       , 0.60833335, 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.68333334, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.7083333 ,\n",
       "            0.7083333 , 0.7083333 , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.73333335, 0.7416667 , 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.775     , 0.775     ,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.81666666, 0.81666666,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.81666666, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.84166664, 0.84166664,\n",
       "            0.85      , 0.85833335, 0.85833335, 0.8666667 , 0.8666667 ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.89166665, 0.89166665,\n",
       "            0.9       , 0.90833336, 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.925     , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.06153846, 0.06923077, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.17692308, 0.17692308, 0.17692308, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23846154, 0.24615385, 0.26153848,\n",
       "            0.26923078, 0.26923078, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.35384616, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3846154 , 0.3923077 , 0.4       , 0.41538462,\n",
       "            0.42307693, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.6       , 0.6076923 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3943, 0.394 , 0.3928, 0.3914, 0.391 , 0.3884, 0.3865,\n",
       "            0.3853, 0.3848, 0.3845, 0.383 , 0.3823, 0.3813, 0.3809, 0.3787,\n",
       "            0.3784, 0.3782, 0.3772, 0.3752, 0.3745, 0.3733, 0.3728, 0.3726,\n",
       "            0.372 , 0.3704, 0.3691, 0.369 , 0.3677, 0.3645, 0.3643, 0.3638,\n",
       "            0.3625, 0.362 , 0.36  , 0.358 , 0.3567, 0.356 , 0.3525, 0.35  ,\n",
       "            0.3494, 0.3477, 0.3474, 0.3438, 0.3425, 0.3423, 0.3418, 0.3396,\n",
       "            0.3386, 0.3362, 0.3306, 0.3276, 0.3271, 0.3237, 0.3215, 0.32  ,\n",
       "            0.3196, 0.313 , 0.306 , 0.3003, 0.296 , 0.295 , 0.2932, 0.292 ,\n",
       "            0.2903, 0.29  , 0.288 , 0.2876, 0.285 , 0.2847, 0.2842, 0.2832,\n",
       "            0.2825, 0.2803, 0.279 , 0.2773, 0.2761, 0.2756, 0.2742, 0.274 ,\n",
       "            0.2737, 0.2734, 0.2732, 0.273 , 0.2717, 0.2712, 0.27  , 0.2673,\n",
       "            0.2668, 0.2654, 0.2651, 0.2646, 0.2642, 0.2634, 0.2632, 0.263 ,\n",
       "            0.2605, 0.2595, 0.259 , 0.2576, 0.2568, 0.2566, 0.256 , 0.2554,\n",
       "            0.255 , 0.2542, 0.2537, 0.253 , 0.2527, 0.2524, 0.251 , 0.2498,\n",
       "            0.2487, 0.2478, 0.2471, 0.2462, 0.2456, 0.2455, 0.2452, 0.2448,\n",
       "            0.2426, 0.2424, 0.2422, 0.2417, 0.241 , 0.2406, 0.2399, 0.2397,\n",
       "            0.2391, 0.239 , 0.2388, 0.2384, 0.2382, 0.237 , 0.2368, 0.2366,\n",
       "            0.236 , 0.2358, 0.2351, 0.2346, 0.2344, 0.234 , 0.2338, 0.2332,\n",
       "            0.2322, 0.2314, 0.2302, 0.2301, 0.2297, 0.2295, 0.2281, 0.228 ,\n",
       "            0.2272, 0.2269, 0.2261, 0.2255, 0.2239, 0.2238, 0.2229, 0.2227,\n",
       "            0.2222, 0.222 , 0.2207, 0.2205, 0.2195, 0.2189, 0.218 , 0.2177,\n",
       "            0.2163, 0.2158, 0.2152, 0.2134, 0.2114, 0.2085, 0.2081, 0.2079,\n",
       "            0.2076, 0.2068, 0.2053, 0.2051, 0.2047, 0.2043, 0.2042, 0.2039,\n",
       "            0.2037, 0.2023, 0.2002, 0.1998, 0.199 , 0.1981, 0.196 , 0.1941,\n",
       "            0.1937, 0.1936, 0.1931, 0.1927, 0.1923, 0.1921, 0.1907, 0.19  ,\n",
       "            0.189 , 0.1885, 0.1864, 0.185 , 0.1842, 0.1838, 0.1821, 0.1816,\n",
       "            0.1799, 0.1791, 0.1782, 0.1754, 0.1724, 0.167 , 0.1598, 0.1356],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.575     , 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.59166664, 0.6       , 0.60833335,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65      , 0.65      , 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.6666667 , 0.675     , 0.675     , 0.68333334,\n",
       "            0.68333334, 0.69166666, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.69166666, 0.69166666, 0.7       , 0.7       , 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.71666664, 0.71666664,\n",
       "            0.725     , 0.725     , 0.73333335, 0.7416667 , 0.7416667 ,\n",
       "            0.7416667 , 0.7416667 , 0.7416667 , 0.7416667 , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.775     , 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.80833334, 0.80833334, 0.81666666,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.81666666, 0.81666666,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85      , 0.85      , 0.85      , 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.8666667 , 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.925     , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.9916667 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.09230769, 0.1       , 0.1       , 0.1       ,\n",
       "            0.10769231, 0.13076924, 0.13846155, 0.14615385, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.25384617,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.33846155, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.42307693,\n",
       "            0.42307693, 0.42307693, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46923077, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.5       , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63076925, 0.63076925, 0.63076925,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.86153847, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3645, 0.363 , 0.3625, 0.362 , 0.3618, 0.3596, 0.3594,\n",
       "            0.356 , 0.3552, 0.355 , 0.3538, 0.3528, 0.3525, 0.3518, 0.3516,\n",
       "            0.3513, 0.3508, 0.3499, 0.3486, 0.3484, 0.3481, 0.3474, 0.3464,\n",
       "            0.3457, 0.3455, 0.3452, 0.3433, 0.3428, 0.341 , 0.3396, 0.3376,\n",
       "            0.3374, 0.337 , 0.3354, 0.334 , 0.3335, 0.3325, 0.3318, 0.3306,\n",
       "            0.3274, 0.3245, 0.323 , 0.3228, 0.319 , 0.3184, 0.3164, 0.3154,\n",
       "            0.3137, 0.3125, 0.3113, 0.3105, 0.3062, 0.3032, 0.3022, 0.2998,\n",
       "            0.2896, 0.288 , 0.285 , 0.2825, 0.2803, 0.2688, 0.2673, 0.2666,\n",
       "            0.2654, 0.2634, 0.2607, 0.2605, 0.2585, 0.2578, 0.2568, 0.2566,\n",
       "            0.255 , 0.2534, 0.2483, 0.2482, 0.2451, 0.2444, 0.2438, 0.2421,\n",
       "            0.2418, 0.2415, 0.2399, 0.2395, 0.2391, 0.239 , 0.2386, 0.2372,\n",
       "            0.235 , 0.2346, 0.2343, 0.2335, 0.2316, 0.2314, 0.2311, 0.2303,\n",
       "            0.2299, 0.2297, 0.2294, 0.2292, 0.2286, 0.2283, 0.2246, 0.2238,\n",
       "            0.2234, 0.223 , 0.2227, 0.2225, 0.222 , 0.2216, 0.2213, 0.2205,\n",
       "            0.2191, 0.2189, 0.2179, 0.2172, 0.2166, 0.2163, 0.2162, 0.2158,\n",
       "            0.2157, 0.2147, 0.2145, 0.2144, 0.2142, 0.2137, 0.2124, 0.212 ,\n",
       "            0.2118, 0.2115, 0.211 , 0.2104, 0.2103, 0.2095, 0.2091, 0.2076,\n",
       "            0.2069, 0.2059, 0.2053, 0.2051, 0.205 , 0.2048, 0.204 , 0.2039,\n",
       "            0.2037, 0.2034, 0.2032, 0.2029, 0.2028, 0.2026, 0.2023, 0.2013,\n",
       "            0.2009, 0.2004, 0.2002, 0.2001, 0.2   , 0.1991, 0.1989, 0.1987,\n",
       "            0.1985, 0.1984, 0.1978, 0.1962, 0.195 , 0.1925, 0.1904, 0.19  ,\n",
       "            0.1893, 0.1886, 0.1879, 0.1876, 0.1874, 0.1873, 0.1871, 0.1869,\n",
       "            0.1853, 0.185 , 0.1848, 0.1843, 0.1838, 0.1837, 0.183 , 0.1829,\n",
       "            0.1827, 0.182 , 0.181 , 0.1797, 0.1787, 0.1776, 0.1766, 0.1764,\n",
       "            0.1761, 0.1755, 0.1752, 0.1749, 0.1747, 0.1744, 0.1743, 0.174 ,\n",
       "            0.1733, 0.1727, 0.1725, 0.172 , 0.1719, 0.171 , 0.1698, 0.1669,\n",
       "            0.1666, 0.1654, 0.1632, 0.1631, 0.1611, 0.1594, 0.1565, 0.1564,\n",
       "            0.1561, 0.1542, 0.1538, 0.1473, 0.1448, 0.1415, 0.118 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.09166667, 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.575     , 0.575     , 0.59166664, 0.59166664,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.59166664, 0.59166664,\n",
       "            0.6       , 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.64166665, 0.65      , 0.65      , 0.65      ,\n",
       "            0.65      , 0.65      , 0.65      , 0.65833336, 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.675     , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.69166666, 0.69166666, 0.7       , 0.71666664, 0.71666664,\n",
       "            0.725     , 0.725     , 0.725     , 0.725     , 0.725     ,\n",
       "            0.73333335, 0.73333335, 0.73333335, 0.7416667 , 0.7416667 ,\n",
       "            0.75      , 0.75      , 0.75      , 0.7583333 , 0.7583333 ,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.81666666, 0.81666666,\n",
       "            0.81666666, 0.81666666, 0.825     , 0.8333333 , 0.8333333 ,\n",
       "            0.85      , 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "            0.85833335, 0.85833335, 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.8833333 , 0.8833333 ,\n",
       "            0.8833333 , 0.8833333 , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.90833336,\n",
       "            0.90833336, 0.90833336, 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.90833336, 0.9166667 , 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.05384615, 0.06153846,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.1       , 0.10769231, 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.17692308, 0.18461539,\n",
       "            0.18461539, 0.1923077 , 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26923078, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.4076923 , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.50769234, 0.5153846 ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5769231 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7076923 , 0.7076923 ,\n",
       "            0.7153846 , 0.73846155, 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3335, 0.3323, 0.332 , 0.3315, 0.3313, 0.3308, 0.3284,\n",
       "            0.3271, 0.3264, 0.3262, 0.326 , 0.3254, 0.3252, 0.325 , 0.324 ,\n",
       "            0.3237, 0.3235, 0.323 , 0.3228, 0.3215, 0.3213, 0.3206, 0.32  ,\n",
       "            0.3188, 0.318 , 0.317 , 0.3167, 0.3157, 0.314 , 0.3135, 0.3132,\n",
       "            0.313 , 0.311 , 0.31  , 0.3079, 0.306 , 0.3044, 0.3025, 0.302 ,\n",
       "            0.3015, 0.3013, 0.2998, 0.299 , 0.2976, 0.2957, 0.2927, 0.29  ,\n",
       "            0.2864, 0.2856, 0.2852, 0.2832, 0.2817, 0.2815, 0.2805, 0.268 ,\n",
       "            0.2642, 0.2612, 0.2542, 0.2515, 0.2498, 0.2452, 0.2451, 0.2444,\n",
       "            0.2438, 0.2379, 0.2375, 0.236 , 0.2316, 0.2285, 0.228 , 0.2274,\n",
       "            0.2266, 0.2255, 0.2249, 0.2239, 0.2235, 0.2233, 0.2224, 0.2207,\n",
       "            0.2189, 0.2179, 0.2162, 0.2156, 0.2153, 0.215 , 0.2148, 0.2124,\n",
       "            0.2123, 0.2119, 0.2114, 0.2108, 0.21  , 0.2085, 0.2079, 0.2063,\n",
       "            0.2059, 0.2053, 0.2045, 0.2037, 0.2034, 0.2021, 0.201 , 0.2006,\n",
       "            0.1996, 0.199 , 0.1981, 0.1974, 0.1973, 0.197 , 0.1967, 0.1965,\n",
       "            0.196 , 0.195 , 0.1943, 0.1942, 0.1936, 0.1935, 0.1934, 0.1923,\n",
       "            0.1921, 0.1913, 0.1909, 0.1906, 0.1903, 0.1893, 0.1886, 0.188 ,\n",
       "            0.1876, 0.1874, 0.1873, 0.1869, 0.1866, 0.186 , 0.1859, 0.1858,\n",
       "            0.1855, 0.1852, 0.1848, 0.1837, 0.1836, 0.1831, 0.1827, 0.1823,\n",
       "            0.1816, 0.1791, 0.1788, 0.1774, 0.1771, 0.177 , 0.1764, 0.1763,\n",
       "            0.1761, 0.1759, 0.1757, 0.1753, 0.1749, 0.1746, 0.1743, 0.1737,\n",
       "            0.1735, 0.1733, 0.1731, 0.1725, 0.172 , 0.1719, 0.1716, 0.1711,\n",
       "            0.1709, 0.17  , 0.1698, 0.1697, 0.1696, 0.1688, 0.1685, 0.1676,\n",
       "            0.1675, 0.1659, 0.1658, 0.1636, 0.1633, 0.1632, 0.163 , 0.1626,\n",
       "            0.1625, 0.1622, 0.1621, 0.1619, 0.1615, 0.1614, 0.161 , 0.1605,\n",
       "            0.1598, 0.1597, 0.1588, 0.1567, 0.1565, 0.1564, 0.1556, 0.1555,\n",
       "            0.1554, 0.1552, 0.155 , 0.1534, 0.1527, 0.1512, 0.1508, 0.1504,\n",
       "            0.1492, 0.1487, 0.1456, 0.1453, 0.1443, 0.1436, 0.1431, 0.1427,\n",
       "            0.1411, 0.1409, 0.1382, 0.1315, 0.13  , 0.127 , 0.1216, 0.1078],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.025     , 0.04166667, 0.05833333,\n",
       "            0.075     , 0.08333334, 0.10833333, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.16666667, 0.18333334, 0.2       , 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.525     , 0.53333336,\n",
       "            0.53333336, 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.575     , 0.575     ,\n",
       "            0.575     , 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.6       , 0.6       , 0.60833335, 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.65      , 0.65      , 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.65833336, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.675     , 0.675     , 0.675     , 0.68333334,\n",
       "            0.68333334, 0.68333334, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.69166666, 0.7       , 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.725     , 0.725     , 0.725     ,\n",
       "            0.725     , 0.725     , 0.725     , 0.73333335, 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.75      , 0.7583333 , 0.7583333 ,\n",
       "            0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 ,\n",
       "            0.7583333 , 0.76666665, 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84166664, 0.84166664, 0.84166664, 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.9       , 0.9       ,\n",
       "            0.90833336, 0.90833336, 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.01538462, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.10769231, 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.18461539,\n",
       "            0.18461539, 0.2       , 0.20769231, 0.21538462, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43076923,\n",
       "            0.43846154, 0.45384616, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.54615384, 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5769231 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.7       , 0.7       , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.74615383, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3042 , 0.3035 , 0.3032 , 0.303  , 0.3025 , 0.3022 ,\n",
       "            0.302  , 0.3018 , 0.3015 , 0.3008 , 0.2998 , 0.2986 , 0.2983 ,\n",
       "            0.298  , 0.2979 , 0.2976 , 0.2974 , 0.2957 , 0.2954 , 0.2937 ,\n",
       "            0.2935 , 0.2927 , 0.292  , 0.2893 , 0.289  , 0.2886 , 0.2878 ,\n",
       "            0.287  , 0.2864 , 0.286  , 0.2852 , 0.2847 , 0.2832 , 0.282  ,\n",
       "            0.281  , 0.278  , 0.2769 , 0.2737 , 0.273  , 0.2688 , 0.2676 ,\n",
       "            0.2673 , 0.2666 , 0.266  , 0.2605 , 0.2573 , 0.2559 , 0.254  ,\n",
       "            0.2532 , 0.2429 , 0.2418 , 0.2388 , 0.2384 , 0.2366 , 0.2301 ,\n",
       "            0.2264 , 0.2224 , 0.2197 , 0.2179 , 0.2163 , 0.2139 , 0.2134 ,\n",
       "            0.213  , 0.2124 , 0.2074 , 0.2073 , 0.207  , 0.2053 , 0.2047 ,\n",
       "            0.2045 , 0.2043 , 0.2028 , 0.2021 , 0.2012 , 0.201  , 0.2006 ,\n",
       "            0.2002 , 0.1968 , 0.1962 , 0.1959 , 0.1956 , 0.1953 , 0.1952 ,\n",
       "            0.1946 , 0.1942 , 0.1941 , 0.1936 , 0.1934 , 0.1918 , 0.191  ,\n",
       "            0.1903 , 0.1897 , 0.189  , 0.1879 , 0.1869 , 0.186  , 0.1859 ,\n",
       "            0.1848 , 0.1838 , 0.1835 , 0.1831 , 0.183  , 0.1821 , 0.182  ,\n",
       "            0.1816 , 0.1814 , 0.1813 , 0.1807 , 0.1779 , 0.1776 , 0.1775 ,\n",
       "            0.1772 , 0.1768 , 0.1766 , 0.1761 , 0.1752 , 0.1746 , 0.1744 ,\n",
       "            0.1731 , 0.1721 , 0.1719 , 0.1718 , 0.1709 , 0.1703 , 0.17   ,\n",
       "            0.1699 , 0.1698 , 0.1697 , 0.1687 , 0.1683 , 0.1678 , 0.1677 ,\n",
       "            0.1675 , 0.1663 , 0.1661 , 0.166  , 0.1656 , 0.1649 , 0.1644 ,\n",
       "            0.1641 , 0.164  , 0.1638 , 0.1636 , 0.1635 , 0.1622 , 0.1621 ,\n",
       "            0.1617 , 0.1615 , 0.161  , 0.1606 , 0.1599 , 0.1598 , 0.1593 ,\n",
       "            0.1587 , 0.1586 , 0.1584 , 0.158  , 0.1577 , 0.1569 , 0.1567 ,\n",
       "            0.1565 , 0.1561 , 0.156  , 0.1555 , 0.1554 , 0.1552 , 0.1545 ,\n",
       "            0.1544 , 0.1543 , 0.1539 , 0.1532 , 0.153  , 0.1519 , 0.1517 ,\n",
       "            0.1514 , 0.149  , 0.1487 , 0.1486 , 0.1481 , 0.1476 , 0.1467 ,\n",
       "            0.1465 , 0.1461 , 0.1459 , 0.1456 , 0.1447 , 0.1442 , 0.144  ,\n",
       "            0.1437 , 0.1434 , 0.1428 , 0.1426 , 0.142  , 0.1417 , 0.1398 ,\n",
       "            0.1394 , 0.1364 , 0.1353 , 0.1346 , 0.1334 , 0.1332 , 0.1313 ,\n",
       "            0.1312 , 0.1298 , 0.1294 , 0.1283 , 0.1272 , 0.127  , 0.1222 ,\n",
       "            0.1213 , 0.1204 , 0.11816, 0.11694, 0.1076 , 0.1052 , 0.1034 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.16666667,\n",
       "            0.175     , 0.19166666, 0.2       , 0.21666667, 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.33333334, 0.34166667, 0.35833332, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.5       , 0.51666665, 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.575     , 0.575     ,\n",
       "            0.575     , 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.6       ,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.64166665, 0.65      , 0.65      ,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.68333334, 0.69166666,\n",
       "            0.69166666, 0.7       , 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.7083333 , 0.7083333 , 0.7083333 , 0.7083333 , 0.7083333 ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.71666664, 0.725     ,\n",
       "            0.725     , 0.725     , 0.725     , 0.725     , 0.725     ,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.7583333 , 0.7583333 ,\n",
       "            0.7583333 , 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.775     , 0.78333336, 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.825     , 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85      , 0.85      , 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.875     , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.89166665, 0.89166665, 0.90833336, 0.90833336,\n",
       "            0.90833336, 0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.11538462, 0.12307692, 0.13076924, 0.14615385,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26923078, 0.2846154 , 0.2846154 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.32307693,\n",
       "            0.33076924, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.4846154 , 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.64615387, 0.65384614, 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.7       , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.74615383, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2937 , 0.292  , 0.2917 , 0.289  , 0.2888 , 0.2886 ,\n",
       "            0.2878 , 0.2876 , 0.2869 , 0.2861 , 0.286  , 0.2854 , 0.2852 ,\n",
       "            0.285  , 0.2847 , 0.2834 , 0.283  , 0.2827 , 0.2822 , 0.282  ,\n",
       "            0.2815 , 0.2812 , 0.2795 , 0.2788 , 0.2786 , 0.2783 , 0.2776 ,\n",
       "            0.2773 , 0.2766 , 0.2764 , 0.2756 , 0.2754 , 0.2751 , 0.2742 ,\n",
       "            0.2737 , 0.2727 , 0.2712 , 0.271  , 0.2705 , 0.27   , 0.2686 ,\n",
       "            0.268  , 0.2656 , 0.2654 , 0.2644 , 0.263  , 0.2595 , 0.2566 ,\n",
       "            0.2542 , 0.2517 , 0.2487 , 0.2456 , 0.2451 , 0.2445 , 0.2399 ,\n",
       "            0.2375 , 0.2368 , 0.2355 , 0.2306 , 0.2266 , 0.2256 , 0.2252 ,\n",
       "            0.2238 , 0.2218 , 0.2211 , 0.2184 , 0.2147 , 0.2142 , 0.2124 ,\n",
       "            0.211  , 0.2106 , 0.2084 , 0.2064 , 0.206  , 0.2058 , 0.2047 ,\n",
       "            0.2045 , 0.2042 , 0.2035 , 0.2031 , 0.2028 , 0.2004 , 0.1982 ,\n",
       "            0.1979 , 0.1968 , 0.1965 , 0.1952 , 0.194  , 0.1936 , 0.1931 ,\n",
       "            0.1929 , 0.1921 , 0.1919 , 0.1918 , 0.1904 , 0.1903 , 0.1897 ,\n",
       "            0.1879 , 0.1873 , 0.1864 , 0.185  , 0.1843 , 0.1842 , 0.1838 ,\n",
       "            0.1835 , 0.1831 , 0.1824 , 0.182  , 0.1805 , 0.1798 , 0.1796 ,\n",
       "            0.1787 , 0.1785 , 0.1783 , 0.1772 , 0.1763 , 0.1758 , 0.1753 ,\n",
       "            0.1752 , 0.1748 , 0.1747 , 0.1744 , 0.1743 , 0.1738 , 0.173  ,\n",
       "            0.1727 , 0.1726 , 0.1724 , 0.172  , 0.171  , 0.1709 , 0.1707 ,\n",
       "            0.1705 , 0.1704 , 0.17   , 0.1698 , 0.1696 , 0.1688 , 0.1687 ,\n",
       "            0.1685 , 0.1681 , 0.1676 , 0.1675 , 0.167  , 0.1665 , 0.166  ,\n",
       "            0.1659 , 0.165  , 0.1649 , 0.1643 , 0.1637 , 0.1635 , 0.1632 ,\n",
       "            0.163  , 0.162  , 0.161  , 0.1608 , 0.1606 , 0.1604 , 0.1598 ,\n",
       "            0.1584 , 0.1577 , 0.1556 , 0.1547 , 0.1543 , 0.1533 , 0.1528 ,\n",
       "            0.1526 , 0.1517 , 0.1516 , 0.1512 , 0.1511 , 0.151  , 0.1505 ,\n",
       "            0.1503 , 0.1493 , 0.1492 , 0.1488 , 0.1484 , 0.1481 , 0.1471 ,\n",
       "            0.1466 , 0.1459 , 0.1455 , 0.1453 , 0.1448 , 0.1432 , 0.1426 ,\n",
       "            0.1425 , 0.1418 , 0.1406 , 0.1398 , 0.1396 , 0.1392 , 0.1384 ,\n",
       "            0.1377 , 0.1366 , 0.1359 , 0.1354 , 0.135  , 0.1346 , 0.1333 ,\n",
       "            0.1312 , 0.1311 , 0.1302 , 0.1296 , 0.1292 , 0.1265 , 0.126  ,\n",
       "            0.12335, 0.1201 , 0.1188 , 0.1166 , 0.115  , 0.11475, 0.11066,\n",
       "            0.1101 , 0.1043 , 0.10126], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.11666667, 0.125     , 0.13333334,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.18333334, 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.575     , 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.60833335, 0.60833335,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65      , 0.65      , 0.65      ,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7       , 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.7083333 , 0.7083333 , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.725     , 0.73333335, 0.73333335, 0.73333335,\n",
       "            0.73333335, 0.7416667 , 0.7416667 , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.7583333 , 0.7583333 , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.825     , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.8666667 , 0.875     , 0.875     , 0.8833333 ,\n",
       "            0.8833333 , 0.8833333 , 0.8833333 , 0.8833333 , 0.8833333 ,\n",
       "            0.89166665, 0.89166665, 0.89166665, 0.9       , 0.90833336,\n",
       "            0.90833336, 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06923077, 0.06923077, 0.06923077, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.10769231, 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.2       , 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.26923078, 0.2769231 , 0.2923077 , 0.3       , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.34615386, 0.36153847, 0.37692308,\n",
       "            0.3846154 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.45384616, 0.46153846, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.6615385 , 0.6615385 , 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.72307694,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8153846 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.8230769 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.293 , 0.2925, 0.291 , 0.2886, 0.2864, 0.2837, 0.2832,\n",
       "            0.2827, 0.2822, 0.2812, 0.2803, 0.28  , 0.2795, 0.279 , 0.278 ,\n",
       "            0.2776, 0.2773, 0.2766, 0.276 , 0.2756, 0.2751, 0.275 , 0.2747,\n",
       "            0.2744, 0.2742, 0.2737, 0.2732, 0.2727, 0.272 , 0.2703, 0.2698,\n",
       "            0.268 , 0.2676, 0.265 , 0.2637, 0.263 , 0.2622, 0.2612, 0.2605,\n",
       "            0.2603, 0.2598, 0.2595, 0.2578, 0.2573, 0.2556, 0.2554, 0.255 ,\n",
       "            0.2542, 0.2527, 0.252 , 0.2515, 0.2512, 0.2494, 0.249 , 0.2482,\n",
       "            0.244 , 0.2437, 0.243 , 0.2426, 0.2399, 0.236 , 0.2355, 0.2346,\n",
       "            0.2343, 0.2322, 0.2318, 0.231 , 0.2303, 0.2301, 0.2283, 0.2272,\n",
       "            0.2269, 0.2266, 0.2252, 0.2251, 0.2246, 0.224 , 0.2239, 0.2216,\n",
       "            0.2203, 0.2197, 0.2195, 0.2184, 0.2168, 0.2166, 0.2156, 0.2152,\n",
       "            0.215 , 0.2144, 0.2134, 0.2118, 0.2113, 0.211 , 0.2103, 0.2096,\n",
       "            0.2073, 0.2065, 0.2059, 0.2053, 0.2032, 0.2029, 0.2021, 0.202 ,\n",
       "            0.2018, 0.2015, 0.2006, 0.2002, 0.1995, 0.199 , 0.1989, 0.1985,\n",
       "            0.1984, 0.1982, 0.1981, 0.1979, 0.1976, 0.1971, 0.1967, 0.1965,\n",
       "            0.1964, 0.1959, 0.1958, 0.1948, 0.1942, 0.1941, 0.1934, 0.1931,\n",
       "            0.193 , 0.1923, 0.1918, 0.1903, 0.19  , 0.1886, 0.1884, 0.1882,\n",
       "            0.1874, 0.1871, 0.1869, 0.1863, 0.1858, 0.1853, 0.185 , 0.1843,\n",
       "            0.1842, 0.1836, 0.1835, 0.1833, 0.1821, 0.1813, 0.1808, 0.1807,\n",
       "            0.1804, 0.1798, 0.1796, 0.1794, 0.179 , 0.1788, 0.1772, 0.177 ,\n",
       "            0.1768, 0.1744, 0.1741, 0.174 , 0.1735, 0.1726, 0.1718, 0.1714,\n",
       "            0.1708, 0.1697, 0.1693, 0.1687, 0.1685, 0.1683, 0.1676, 0.1652,\n",
       "            0.1641, 0.1635, 0.1631, 0.1625, 0.1619, 0.1615, 0.161 , 0.1605,\n",
       "            0.1604, 0.1602, 0.16  , 0.1598, 0.1578, 0.1577, 0.1572, 0.1549,\n",
       "            0.1547, 0.1545, 0.1517, 0.1516, 0.1514, 0.1497, 0.1494, 0.149 ,\n",
       "            0.1487, 0.1484, 0.148 , 0.1478, 0.1473, 0.1471, 0.1462, 0.146 ,\n",
       "            0.1459, 0.1449, 0.1445, 0.144 , 0.1432, 0.142 , 0.1409, 0.1405,\n",
       "            0.1392, 0.139 , 0.1368, 0.1328, 0.1323, 0.13  , 0.126 , 0.1254,\n",
       "            0.1251, 0.1197, 0.1196, 0.1166, 0.1142], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.09166667,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.3       , 0.31666666, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.40833333, 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.46666667, 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.49166667, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.49166667, 0.5       ,\n",
       "            0.5       , 0.5       , 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.6       , 0.6       , 0.6       , 0.6       , 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65833336, 0.65833336, 0.68333334, 0.69166666,\n",
       "            0.69166666, 0.69166666, 0.7       , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.725     , 0.725     , 0.7416667 , 0.75      , 0.75      ,\n",
       "            0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 ,\n",
       "            0.7583333 , 0.7583333 , 0.76666665, 0.775     , 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.80833334, 0.81666666, 0.81666666,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.84166664, 0.84166664,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.8666667 ,\n",
       "            0.8666667 , 0.8666667 , 0.875     , 0.875     , 0.875     ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.89166665, 0.9       , 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.975     , 0.975     , 0.98333335, 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.03846154, 0.05384615,\n",
       "            0.06153846, 0.06153846, 0.06923077, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.22307692, 0.23076923,\n",
       "            0.23076923, 0.23076923, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.26153848, 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.2846154 , 0.2923077 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.4       , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43846154, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.72307694, 0.7307692 , 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.75384617, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.294 , 0.2932, 0.2917, 0.2898, 0.2888, 0.2866, 0.2842,\n",
       "            0.2837, 0.282 , 0.2803, 0.28  , 0.2795, 0.2778, 0.2776, 0.277 ,\n",
       "            0.2769, 0.2766, 0.2754, 0.2747, 0.274 , 0.2727, 0.2715, 0.2708,\n",
       "            0.2703, 0.27  , 0.2698, 0.2693, 0.269 , 0.2678, 0.2673, 0.267 ,\n",
       "            0.2666, 0.2659, 0.2646, 0.2642, 0.263 , 0.2622, 0.2617, 0.258 ,\n",
       "            0.2559, 0.2556, 0.2554, 0.2551, 0.2532, 0.2524, 0.252 , 0.2512,\n",
       "            0.251 , 0.2505, 0.2494, 0.2493, 0.2487, 0.2485, 0.2474, 0.2458,\n",
       "            0.2456, 0.2441, 0.2438, 0.2429, 0.2417, 0.2413, 0.2411, 0.2395,\n",
       "            0.2391, 0.239 , 0.2384, 0.2379, 0.2375, 0.237 , 0.2363, 0.2358,\n",
       "            0.2356, 0.2351, 0.2347, 0.234 , 0.2338, 0.2318, 0.2314, 0.231 ,\n",
       "            0.2297, 0.2292, 0.229 , 0.2285, 0.2283, 0.2281, 0.2274, 0.2268,\n",
       "            0.2263, 0.226 , 0.2252, 0.2251, 0.2249, 0.2246, 0.2244, 0.2239,\n",
       "            0.2222, 0.222 , 0.2212, 0.2203, 0.2202, 0.2181, 0.2177, 0.2166,\n",
       "            0.2163, 0.2156, 0.2128, 0.2123, 0.2115, 0.2113, 0.2109, 0.2106,\n",
       "            0.2104, 0.2103, 0.2101, 0.21  , 0.2091, 0.2079, 0.2069, 0.2068,\n",
       "            0.2059, 0.2058, 0.2035, 0.2029, 0.2023, 0.2018, 0.2017, 0.2007,\n",
       "            0.2004, 0.1996, 0.1984, 0.1981, 0.1976, 0.1965, 0.1958, 0.1953,\n",
       "            0.195 , 0.1943, 0.193 , 0.1927, 0.1912, 0.191 , 0.1901, 0.1898,\n",
       "            0.1891, 0.1879, 0.1876, 0.1866, 0.1863, 0.1852, 0.1837, 0.1833,\n",
       "            0.1816, 0.1814, 0.18  , 0.1792, 0.1791, 0.1788, 0.1783, 0.1768,\n",
       "            0.1766, 0.1763, 0.1761, 0.1758, 0.1748, 0.1747, 0.1736, 0.173 ,\n",
       "            0.1729, 0.1726, 0.171 , 0.1704, 0.17  , 0.1698, 0.1686, 0.1682,\n",
       "            0.1678, 0.1659, 0.1658, 0.1643, 0.1641, 0.1624, 0.1622, 0.162 ,\n",
       "            0.1619, 0.1614, 0.161 , 0.1602, 0.1588, 0.1583, 0.1569, 0.1566,\n",
       "            0.1561, 0.1555, 0.1554, 0.155 , 0.1534, 0.1531, 0.1512, 0.151 ,\n",
       "            0.1501, 0.1462, 0.1445, 0.1431, 0.1395, 0.1389, 0.1368, 0.1361,\n",
       "            0.1354, 0.1328, 0.1321, 0.1313], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.05833333, 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.175     , 0.175     ,\n",
       "            0.175     , 0.175     , 0.175     , 0.175     , 0.175     ,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.2       ,\n",
       "            0.2       , 0.20833333, 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.275     , 0.275     , 0.275     , 0.275     , 0.29166666,\n",
       "            0.29166666, 0.29166666, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.325     , 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.375     , 0.375     , 0.39166668, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.49166667, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65      , 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.725     , 0.725     ,\n",
       "            0.73333335, 0.73333335, 0.73333335, 0.73333335, 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.825     , 0.825     , 0.825     , 0.825     ,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85      , 0.85833335, 0.8666667 , 0.8666667 ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.90833336, 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.94166666, 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.06923077, 0.06923077, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.11538462, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.22307692, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.25384617, 0.25384617, 0.26923078, 0.26923078, 0.26923078,\n",
       "            0.26923078, 0.2769231 , 0.2769231 , 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.31538463, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.44615385, 0.44615385,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46153846, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.5       , 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.6615385 , 0.6615385 , 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7076923 ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.72307694, 0.73846155,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.304 , 0.3013, 0.3003, 0.299 , 0.2988, 0.2983, 0.298 ,\n",
       "            0.2961, 0.296 , 0.2954, 0.2944, 0.2932, 0.2927, 0.2925, 0.2917,\n",
       "            0.2915, 0.2913, 0.2903, 0.29  , 0.2898, 0.289 , 0.2886, 0.2878,\n",
       "            0.2876, 0.2869, 0.2854, 0.2844, 0.2842, 0.2827, 0.2817, 0.281 ,\n",
       "            0.2803, 0.28  , 0.2798, 0.279 , 0.2788, 0.2786, 0.278 , 0.2776,\n",
       "            0.2773, 0.2761, 0.2751, 0.275 , 0.2744, 0.2737, 0.2727, 0.2725,\n",
       "            0.2715, 0.2712, 0.2703, 0.27  , 0.2698, 0.269 , 0.2688, 0.2686,\n",
       "            0.2676, 0.2673, 0.2668, 0.2666, 0.2659, 0.2651, 0.265 , 0.2646,\n",
       "            0.2637, 0.2634, 0.2632, 0.263 , 0.2625, 0.2622, 0.262 , 0.2615,\n",
       "            0.2607, 0.2605, 0.2595, 0.2585, 0.2583, 0.2578, 0.2568, 0.2556,\n",
       "            0.2554, 0.255 , 0.2534, 0.253 , 0.2527, 0.2515, 0.2512, 0.2498,\n",
       "            0.249 , 0.2485, 0.2473, 0.2471, 0.247 , 0.2417, 0.2415, 0.2406,\n",
       "            0.2399, 0.2397, 0.2395, 0.2382, 0.2372, 0.2363, 0.2314, 0.2313,\n",
       "            0.231 , 0.2307, 0.2301, 0.2297, 0.2286, 0.2281, 0.2277, 0.2269,\n",
       "            0.2261, 0.2252, 0.2244, 0.2239, 0.2229, 0.2224, 0.2213, 0.2207,\n",
       "            0.2202, 0.22  , 0.2197, 0.2195, 0.2194, 0.2191, 0.219 , 0.2189,\n",
       "            0.2186, 0.2177, 0.2166, 0.2163, 0.2158, 0.215 , 0.2147, 0.2145,\n",
       "            0.2142, 0.2137, 0.213 , 0.2129, 0.212 , 0.2114, 0.2113, 0.2109,\n",
       "            0.2108, 0.2096, 0.2089, 0.2086, 0.2075, 0.207 , 0.2068, 0.206 ,\n",
       "            0.2056, 0.2051, 0.2048, 0.2047, 0.2039, 0.2037, 0.2015, 0.2009,\n",
       "            0.1996, 0.1984, 0.1965, 0.1964, 0.1958, 0.1954, 0.1953, 0.195 ,\n",
       "            0.194 , 0.1931, 0.1923, 0.1915, 0.1907, 0.1886, 0.1864, 0.1853,\n",
       "            0.1848, 0.1844, 0.1842, 0.1837, 0.1835, 0.1833, 0.1829, 0.1826,\n",
       "            0.1824, 0.1821, 0.1813, 0.1807, 0.18  , 0.1781, 0.1775, 0.1771,\n",
       "            0.1758, 0.1753, 0.1738, 0.1737, 0.172 , 0.171 , 0.1707, 0.169 ,\n",
       "            0.1646, 0.1643, 0.1622, 0.162 , 0.1604, 0.1597, 0.1589, 0.1584,\n",
       "            0.1575, 0.1559, 0.1554, 0.1549, 0.1525, 0.1517, 0.1504, 0.1461,\n",
       "            0.1362], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.075     , 0.075     , 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.1       , 0.1       , 0.1       , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15833333, 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.175     , 0.175     , 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.21666667, 0.225     , 0.23333333, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.31666666, 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.33333334, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.4       , 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55833334, 0.56666666, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.56666666, 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.6       , 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65      , 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.73333335, 0.7416667 , 0.7416667 , 0.75      ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85      , 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.875     , 0.8833333 , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.93333334, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.09230769, 0.1       , 0.1       , 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.18461539, 0.18461539, 0.18461539,\n",
       "            0.1923077 , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.3       , 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.34615386, 0.35384616, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.3846154 , 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.5       , 0.50769234,\n",
       "            0.52307695, 0.5307692 , 0.54615384, 0.54615384, 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.54615384, 0.54615384, 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.54615384, 0.54615384, 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.64615387, 0.65384614, 0.65384614,\n",
       "            0.65384614, 0.66923076, 0.66923076, 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7076923 , 0.7076923 , 0.7076923 , 0.7076923 ,\n",
       "            0.7076923 , 0.7076923 , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.8769231 , 0.8769231 , 0.88461536, 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3247, 0.3245, 0.3235, 0.323 , 0.32  , 0.3193, 0.318 ,\n",
       "            0.3176, 0.3171, 0.3162, 0.316 , 0.3147, 0.3145, 0.314 , 0.3135,\n",
       "            0.3132, 0.3127, 0.3125, 0.3123, 0.312 , 0.3108, 0.3105, 0.31  ,\n",
       "            0.3096, 0.3093, 0.309 , 0.3086, 0.3083, 0.3079, 0.3076, 0.3074,\n",
       "            0.3071, 0.3066, 0.3064, 0.3062, 0.306 , 0.3054, 0.3052, 0.3042,\n",
       "            0.3037, 0.3035, 0.303 , 0.3027, 0.3013, 0.3008, 0.3005, 0.3003,\n",
       "            0.2998, 0.2996, 0.2988, 0.298 , 0.2979, 0.2969, 0.2966, 0.2964,\n",
       "            0.2957, 0.2954, 0.295 , 0.294 , 0.2932, 0.293 , 0.2927, 0.2903,\n",
       "            0.2896, 0.2888, 0.287 , 0.2847, 0.2832, 0.2793, 0.276 , 0.274 ,\n",
       "            0.272 , 0.2712, 0.27  , 0.2695, 0.268 , 0.2676, 0.2673, 0.2664,\n",
       "            0.2656, 0.2646, 0.2637, 0.2625, 0.2615, 0.2605, 0.2585, 0.2566,\n",
       "            0.255 , 0.2546, 0.2522, 0.252 , 0.2493, 0.2489, 0.2483, 0.248 ,\n",
       "            0.2474, 0.247 , 0.2451, 0.2449, 0.2445, 0.2434, 0.243 , 0.2429,\n",
       "            0.2415, 0.2411, 0.2402, 0.2399, 0.2391, 0.2383, 0.2374, 0.237 ,\n",
       "            0.2367, 0.2366, 0.236 , 0.2356, 0.2352, 0.235 , 0.2347, 0.2344,\n",
       "            0.2334, 0.2332, 0.2323, 0.2319, 0.2316, 0.2314, 0.2307, 0.2303,\n",
       "            0.2301, 0.2297, 0.2283, 0.2281, 0.2268, 0.2263, 0.2261, 0.2257,\n",
       "            0.2255, 0.2247, 0.2244, 0.223 , 0.2229, 0.2218, 0.2216, 0.2195,\n",
       "            0.2191, 0.2184, 0.2177, 0.2168, 0.2163, 0.2158, 0.2157, 0.2153,\n",
       "            0.2152, 0.215 , 0.2147, 0.2145, 0.2139, 0.213 , 0.2119, 0.2113,\n",
       "            0.209 , 0.2076, 0.2074, 0.206 , 0.2056, 0.2054, 0.2048, 0.2043,\n",
       "            0.2042, 0.202 , 0.2006, 0.2002, 0.2001, 0.1989, 0.1985, 0.197 ,\n",
       "            0.1954, 0.1953, 0.1948, 0.1946, 0.1941, 0.1934, 0.1925, 0.1924,\n",
       "            0.1915, 0.1912, 0.1906, 0.1904, 0.1898, 0.1885, 0.1879, 0.1866,\n",
       "            0.1841, 0.1831, 0.1823, 0.1807, 0.1797, 0.1792, 0.1785, 0.1781,\n",
       "            0.178 , 0.1736, 0.1724, 0.1707, 0.1681, 0.1678, 0.1661, 0.1654,\n",
       "            0.1641, 0.1635, 0.1592, 0.1539, 0.1355], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.1       , 0.10833333,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.23333333, 0.23333333, 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.73333335,\n",
       "            0.7416667 , 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.8833333 , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.90833336, 0.9166667 , 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.06153846, 0.08461539, 0.11538462, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.16153847, 0.17692308, 0.1923077 ,\n",
       "            0.21538462, 0.23076923, 0.24615385, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.4923077 , 0.4923077 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.50769234, 0.50769234, 0.5153846 , 0.52307695, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.5538462 , 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5692308 , 0.5692308 , 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63076925, 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.64615387, 0.64615387,\n",
       "            0.65384614, 0.65384614, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.73846155, 0.75384617, 0.75384617,\n",
       "            0.75384617, 0.75384617, 0.75384617, 0.75384617, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.77692306, 0.77692306, 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3516, 0.3513, 0.351 , 0.3508, 0.3506, 0.3499, 0.3496,\n",
       "            0.3494, 0.349 , 0.3489, 0.3486, 0.3484, 0.3481, 0.348 , 0.3477,\n",
       "            0.3474, 0.3472, 0.3462, 0.346 , 0.3457, 0.3455, 0.3452, 0.345 ,\n",
       "            0.3447, 0.3433, 0.3418, 0.3403, 0.34  , 0.3394, 0.339 , 0.3386,\n",
       "            0.3381, 0.338 , 0.3376, 0.336 , 0.3357, 0.335 , 0.333 , 0.3325,\n",
       "            0.3318, 0.33  , 0.3296, 0.3271, 0.327 , 0.3262, 0.3254, 0.3252,\n",
       "            0.3225, 0.3218, 0.321 , 0.3206, 0.317 , 0.3164, 0.3147, 0.312 ,\n",
       "            0.3118, 0.309 , 0.3083, 0.3079, 0.3062, 0.306 , 0.3052, 0.3047,\n",
       "            0.3035, 0.3032, 0.3027, 0.3   , 0.2998, 0.2993, 0.2937, 0.2927,\n",
       "            0.289 , 0.286 , 0.2856, 0.2825, 0.2815, 0.2747, 0.2708, 0.2705,\n",
       "            0.2703, 0.2698, 0.2695, 0.269 , 0.2688, 0.2683, 0.268 , 0.2673,\n",
       "            0.2666, 0.2654, 0.2634, 0.2632, 0.2627, 0.2617, 0.2615, 0.2612,\n",
       "            0.2605, 0.26  , 0.2588, 0.2585, 0.2583, 0.258 , 0.2578, 0.2576,\n",
       "            0.2573, 0.256 , 0.2556, 0.2542, 0.253 , 0.2527, 0.2522, 0.252 ,\n",
       "            0.2517, 0.2512, 0.2498, 0.2482, 0.2477, 0.2467, 0.2466, 0.2463,\n",
       "            0.2462, 0.2452, 0.2451, 0.2448, 0.2434, 0.243 , 0.2428, 0.2422,\n",
       "            0.2421, 0.2413, 0.241 , 0.2407, 0.2401, 0.2397, 0.239 , 0.2388,\n",
       "            0.2386, 0.2384, 0.2383, 0.2379, 0.2372, 0.2362, 0.2358, 0.2344,\n",
       "            0.2343, 0.2332, 0.2323, 0.2314, 0.2292, 0.229 , 0.2289, 0.2285,\n",
       "            0.2261, 0.2256, 0.2234, 0.2216, 0.2208, 0.22  , 0.2198, 0.2191,\n",
       "            0.219 , 0.2181, 0.218 , 0.2166, 0.2157, 0.2147, 0.2144, 0.2129,\n",
       "            0.2124, 0.2114, 0.2109, 0.2108, 0.2084, 0.2079, 0.2058, 0.2053,\n",
       "            0.2051, 0.2047, 0.2037, 0.2034, 0.2032, 0.2031, 0.2029, 0.2024,\n",
       "            0.2021, 0.2012, 0.2002, 0.2   , 0.1993, 0.1964, 0.1935, 0.1931,\n",
       "            0.1921, 0.1915, 0.1897, 0.1882, 0.187 , 0.1855, 0.1838, 0.1819,\n",
       "            0.1764, 0.1757, 0.1741, 0.1733, 0.1704, 0.166 , 0.1638, 0.156 ,\n",
       "            0.1458, 0.1381], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.24166666, 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.28333333, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.325     , 0.33333334, 0.35      ,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45833334, 0.475     , 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.69166666, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.7583333 , 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.81666666, 0.825     , 0.84166664,\n",
       "            0.85      , 0.85      , 0.85833335, 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.925     , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.07692308,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.20769231, 0.21538462, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.2769231 ,\n",
       "            0.2846154 , 0.3       , 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5538462 , 0.5538462 ,\n",
       "            0.5538462 , 0.5538462 , 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.56153846, 0.56153846, 0.5692308 , 0.5692308 , 0.5692308 ,\n",
       "            0.5692308 , 0.5692308 , 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5769231 , 0.5769231 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.6230769 , 0.63076925, 0.63076925, 0.63076925,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7076923 , 0.7076923 , 0.7153846 , 0.7153846 , 0.7153846 ,\n",
       "            0.7153846 , 0.7307692 , 0.73846155, 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8076923 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.88461536, 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9307692 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4016, 0.4011, 0.4004, 0.3994, 0.3992, 0.3987, 0.3984,\n",
       "            0.398 , 0.3977, 0.3962, 0.3958, 0.3943, 0.394 , 0.3938, 0.3926,\n",
       "            0.392 , 0.3918, 0.3916, 0.391 , 0.3909, 0.3904, 0.3901, 0.39  ,\n",
       "            0.3892, 0.3884, 0.3882, 0.3872, 0.3865, 0.3862, 0.386 , 0.3857,\n",
       "            0.385 , 0.3848, 0.3843, 0.384 , 0.3833, 0.3826, 0.3823, 0.3804,\n",
       "            0.3782, 0.3774, 0.3772, 0.375 , 0.3745, 0.3743, 0.3728, 0.3723,\n",
       "            0.372 , 0.3696, 0.3657, 0.3645, 0.363 , 0.3608, 0.359 , 0.3577,\n",
       "            0.3545, 0.3533, 0.3513, 0.351 , 0.3464, 0.3418, 0.3384, 0.3374,\n",
       "            0.3364, 0.336 , 0.3352, 0.3335, 0.3318, 0.33  , 0.3298, 0.3274,\n",
       "            0.327 , 0.3257, 0.3242, 0.3193, 0.3147, 0.3145, 0.3142, 0.3108,\n",
       "            0.3105, 0.3086, 0.308 , 0.3027, 0.3025, 0.2974, 0.297 , 0.2961,\n",
       "            0.295 , 0.2937, 0.2935, 0.2915, 0.2908, 0.29  , 0.2883, 0.288 ,\n",
       "            0.2876, 0.287 , 0.2864, 0.286 , 0.2856, 0.2847, 0.2842, 0.2815,\n",
       "            0.279 , 0.2776, 0.2751, 0.2737, 0.2732, 0.273 , 0.2708, 0.2705,\n",
       "            0.2703, 0.27  , 0.2695, 0.2693, 0.269 , 0.2688, 0.2678, 0.2666,\n",
       "            0.2659, 0.2654, 0.2646, 0.264 , 0.2637, 0.2634, 0.263 , 0.262 ,\n",
       "            0.2615, 0.2605, 0.2603, 0.2595, 0.2588, 0.258 , 0.2578, 0.2573,\n",
       "            0.2554, 0.2551, 0.2542, 0.2532, 0.2527, 0.2522, 0.252 , 0.2483,\n",
       "            0.248 , 0.2471, 0.2466, 0.2444, 0.2429, 0.2424, 0.2417, 0.2415,\n",
       "            0.2401, 0.239 , 0.2384, 0.2379, 0.237 , 0.2367, 0.2363, 0.2356,\n",
       "            0.2351, 0.2343, 0.234 , 0.2332, 0.2322, 0.2302, 0.2299, 0.2297,\n",
       "            0.2273, 0.2269, 0.2263, 0.2244, 0.224 , 0.2239, 0.2218, 0.2205,\n",
       "            0.2198, 0.215 , 0.2148, 0.2139, 0.2134, 0.213 , 0.2103, 0.2091,\n",
       "            0.2086, 0.2074, 0.2069, 0.2059, 0.2024, 0.1971, 0.1959, 0.1929,\n",
       "            0.1921, 0.1913, 0.1896, 0.188 , 0.1852, 0.1837, 0.1824, 0.1823,\n",
       "            0.1816, 0.1796, 0.1782, 0.1774, 0.1744, 0.1705, 0.1664, 0.1582,\n",
       "            0.1537, 0.1486, 0.1427, 0.1368, 0.1311], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.2       , 0.2       ,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.35833332,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.44166666, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.5083333 , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65      ,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.7416667 , 0.75      , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.80833334, 0.81666666,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.875     , 0.875     , 0.875     , 0.8833333 , 0.8833333 ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.22307692, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.45384616, 0.46153846, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5692308 , 0.5692308 , 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5769231 , 0.5769231 , 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.6230769 , 0.6230769 , 0.63076925, 0.63076925,\n",
       "            0.64615387, 0.64615387, 0.64615387, 0.64615387, 0.64615387,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7076923 , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.86923075, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.88461536, 0.88461536, 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.45   , 0.449  , 0.4482 , 0.4465 , 0.4453 , 0.445  ,\n",
       "            0.4443 , 0.4436 , 0.4434 , 0.443  , 0.4424 , 0.442  , 0.441  ,\n",
       "            0.4407 , 0.4397 , 0.4392 , 0.439  , 0.4355 , 0.4343 , 0.434  ,\n",
       "            0.4329 , 0.4304 , 0.4302 , 0.43   , 0.4282 , 0.428  , 0.427  ,\n",
       "            0.4268 , 0.4253 , 0.4238 , 0.4229 , 0.4219 , 0.4216 , 0.421  ,\n",
       "            0.4204 , 0.4202 , 0.4197 , 0.4185 , 0.4177 , 0.4138 , 0.413  ,\n",
       "            0.4128 , 0.4097 , 0.4077 , 0.4067 , 0.406  , 0.402  , 0.4019 ,\n",
       "            0.3992 , 0.3987 , 0.3984 , 0.395  , 0.392  , 0.389  , 0.3882 ,\n",
       "            0.3835 , 0.3823 , 0.382  , 0.3796 , 0.3728 , 0.3713 , 0.363  ,\n",
       "            0.3555 , 0.3552 , 0.3528 , 0.35   , 0.3481 , 0.348  , 0.3467 ,\n",
       "            0.343  , 0.342  , 0.335  , 0.3335 , 0.3323 , 0.3284 , 0.3262 ,\n",
       "            0.3218 , 0.3213 , 0.3203 , 0.32   , 0.3176 , 0.315  , 0.3142 ,\n",
       "            0.3137 , 0.3127 , 0.3123 , 0.31   , 0.3093 , 0.309  , 0.3088 ,\n",
       "            0.3083 , 0.3076 , 0.3066 , 0.3064 , 0.3062 , 0.3044 , 0.3035 ,\n",
       "            0.3032 , 0.3015 , 0.2998 , 0.298  , 0.297  , 0.2954 , 0.2944 ,\n",
       "            0.2935 , 0.2925 , 0.2922 , 0.292  , 0.2893 , 0.2886 , 0.288  ,\n",
       "            0.2876 , 0.2852 , 0.285  , 0.2847 , 0.2842 , 0.2837 , 0.2834 ,\n",
       "            0.2822 , 0.282  , 0.2817 , 0.2815 , 0.2812 , 0.281  , 0.2803 ,\n",
       "            0.2798 , 0.2793 , 0.2788 , 0.2776 , 0.2773 , 0.277  , 0.2764 ,\n",
       "            0.2751 , 0.2747 , 0.2727 , 0.2725 , 0.2688 , 0.268  , 0.2673 ,\n",
       "            0.267  , 0.2668 , 0.2659 , 0.2654 , 0.2642 , 0.264  , 0.2637 ,\n",
       "            0.2632 , 0.2612 , 0.2603 , 0.26   , 0.2593 , 0.2588 , 0.2568 ,\n",
       "            0.2566 , 0.255  , 0.2542 , 0.2534 , 0.2532 , 0.2524 , 0.2517 ,\n",
       "            0.2505 , 0.2493 , 0.2483 , 0.2482 , 0.248  , 0.2474 , 0.2473 ,\n",
       "            0.2463 , 0.2458 , 0.2451 , 0.2449 , 0.2444 , 0.2422 , 0.2411 ,\n",
       "            0.2401 , 0.2388 , 0.2372 , 0.237  , 0.2367 , 0.2358 , 0.2307 ,\n",
       "            0.2301 , 0.2286 , 0.2277 , 0.2266 , 0.2257 , 0.2244 , 0.2242 ,\n",
       "            0.2239 , 0.2238 , 0.2208 , 0.2185 , 0.2173 , 0.217  , 0.2147 ,\n",
       "            0.2142 , 0.2139 , 0.2118 , 0.2073 , 0.2047 , 0.2002 , 0.2001 ,\n",
       "            0.1958 , 0.1942 , 0.1893 , 0.1877 , 0.186  , 0.1835 , 0.1833 ,\n",
       "            0.181  , 0.1803 , 0.1794 , 0.1764 , 0.1757 , 0.1714 , 0.1643 ,\n",
       "            0.1636 , 0.1558 , 0.1514 , 0.1428 , 0.1381 , 0.1364 , 0.1342 ,\n",
       "            0.1305 , 0.11755], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.00769231, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.1       , 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.24166666, 0.25      , 0.26666668, 0.26666668, 0.26666668,\n",
       "            0.275     , 0.275     , 0.28333333, 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.31666666, 0.33333334,\n",
       "            0.35833332, 0.36666667, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.525     , 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.775     , 0.775     , 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.85833335, 0.85833335, 0.85833335, 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5846154 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6       , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.63076925, 0.63076925, 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.64615387, 0.64615387,\n",
       "            0.64615387, 0.64615387, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.72307694, 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.501 , 0.4995, 0.499 , 0.4983, 0.4963, 0.4944, 0.4937,\n",
       "            0.4927, 0.4922, 0.492 , 0.4915, 0.4902, 0.4893, 0.489 , 0.488 ,\n",
       "            0.4858, 0.4854, 0.4841, 0.4802, 0.4792, 0.479 , 0.477 , 0.4734,\n",
       "            0.4724, 0.4722, 0.4712, 0.471 , 0.4685, 0.4675, 0.467 , 0.4658,\n",
       "            0.4656, 0.465 , 0.4646, 0.4644, 0.4631, 0.4622, 0.462 , 0.4604,\n",
       "            0.46  , 0.4575, 0.4568, 0.4565, 0.4563, 0.4548, 0.4546, 0.451 ,\n",
       "            0.4504, 0.449 , 0.4453, 0.4446, 0.4434, 0.4426, 0.44  , 0.437 ,\n",
       "            0.4343, 0.4336, 0.4302, 0.429 , 0.4277, 0.427 , 0.4255, 0.425 ,\n",
       "            0.4238, 0.4229, 0.4214, 0.4207, 0.4119, 0.4072, 0.405 , 0.4036,\n",
       "            0.3906, 0.3875, 0.3833, 0.3816, 0.373 , 0.369 , 0.3665, 0.361 ,\n",
       "            0.36  , 0.3557, 0.3552, 0.3525, 0.348 , 0.3462, 0.345 , 0.3433,\n",
       "            0.3425, 0.3386, 0.334 , 0.3337, 0.3333, 0.3328, 0.3323, 0.331 ,\n",
       "            0.3303, 0.33  , 0.3296, 0.3293, 0.329 , 0.3286, 0.3267, 0.3242,\n",
       "            0.3237, 0.3235, 0.32  , 0.3193, 0.3171, 0.3162, 0.3154, 0.3147,\n",
       "            0.3137, 0.3127, 0.3118, 0.3098, 0.3088, 0.3086, 0.3071, 0.3066,\n",
       "            0.3064, 0.306 , 0.3057, 0.3044, 0.304 , 0.3032, 0.3018, 0.3013,\n",
       "            0.301 , 0.3008, 0.3005, 0.3003, 0.2993, 0.2986, 0.298 , 0.2976,\n",
       "            0.2974, 0.297 , 0.2961, 0.2944, 0.2908, 0.2905, 0.2898, 0.2896,\n",
       "            0.2874, 0.286 , 0.2854, 0.283 , 0.2805, 0.2795, 0.2778, 0.2769,\n",
       "            0.2756, 0.275 , 0.2744, 0.274 , 0.273 , 0.2722, 0.2717, 0.27  ,\n",
       "            0.2688, 0.2686, 0.2678, 0.2673, 0.267 , 0.2668, 0.2666, 0.2646,\n",
       "            0.264 , 0.2607, 0.26  , 0.2598, 0.2593, 0.257 , 0.2566, 0.2563,\n",
       "            0.2554, 0.2527, 0.2507, 0.2489, 0.2463, 0.246 , 0.2444, 0.2434,\n",
       "            0.2433, 0.2421, 0.2413, 0.2394, 0.2368, 0.235 , 0.2328, 0.2323,\n",
       "            0.2301, 0.2299, 0.2297, 0.2264, 0.2256, 0.2227, 0.2224, 0.2207,\n",
       "            0.2202, 0.219 , 0.218 , 0.2168, 0.2134, 0.21  , 0.2079, 0.2048,\n",
       "            0.2039, 0.2007, 0.1976, 0.1948, 0.1937, 0.1936, 0.1921, 0.1842,\n",
       "            0.1803, 0.1707, 0.1681, 0.1643, 0.1632, 0.1598, 0.1504, 0.1503,\n",
       "            0.1412, 0.137 , 0.1367, 0.1279, 0.1232, 0.121 , 0.1193, 0.1054],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.32307693, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.13333334, 0.13333334, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.175     , 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.225     , 0.225     , 0.23333333, 0.24166666, 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.3       , 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.31666666, 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.46666667, 0.475     , 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.5083333 , 0.525     ,\n",
       "            0.525     , 0.53333336, 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.725     , 0.725     ,\n",
       "            0.73333335, 0.73333335, 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.05384615, 0.06153846, 0.06923077, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.12307692, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.2769231 , 0.2846154 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.5846154 , 0.5846154 , 0.5846154 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.6230769 , 0.6230769 ,\n",
       "            0.6230769 , 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.64615387, 0.64615387, 0.65384614, 0.65384614,\n",
       "            0.65384614, 0.6615385 , 0.6615385 , 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.7692308 , 0.7692308 ,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.5586 , 0.5557 , 0.554  , 0.5522 , 0.551  , 0.5454 ,\n",
       "            0.544  , 0.5435 , 0.543  , 0.5425 , 0.5405 , 0.5396 , 0.5386 ,\n",
       "            0.536  , 0.533  , 0.532  , 0.531  , 0.5264 , 0.523  , 0.522  ,\n",
       "            0.52   , 0.515  , 0.514  , 0.513  , 0.512  , 0.5117 , 0.51   ,\n",
       "            0.5093 , 0.5073 , 0.507  , 0.506  , 0.505  , 0.504  , 0.4998 ,\n",
       "            0.4988 , 0.4973 , 0.497  , 0.4963 , 0.4946 , 0.4941 , 0.4937 ,\n",
       "            0.4927 , 0.487  , 0.4868 , 0.4795 , 0.479  , 0.4773 , 0.4763 ,\n",
       "            0.4758 , 0.4753 , 0.4739 , 0.4734 , 0.4702 , 0.4695 , 0.4688 ,\n",
       "            0.465  , 0.462  , 0.4558 , 0.4553 , 0.4512 , 0.4495 , 0.4485 ,\n",
       "            0.4456 , 0.443  , 0.4333 , 0.4304 , 0.4202 , 0.4175 , 0.412  ,\n",
       "            0.4111 , 0.39   , 0.385  , 0.3848 , 0.38   , 0.3782 , 0.3762 ,\n",
       "            0.374  , 0.3704 , 0.3691 , 0.3667 , 0.364  , 0.3625 , 0.3606 ,\n",
       "            0.3594 , 0.3591 , 0.359  , 0.358  , 0.3574 , 0.3562 , 0.3552 ,\n",
       "            0.355  , 0.3545 , 0.3538 , 0.3523 , 0.3516 , 0.3506 , 0.3503 ,\n",
       "            0.35   , 0.3489 , 0.3455 , 0.344  , 0.3403 , 0.3386 , 0.3376 ,\n",
       "            0.3374 , 0.337  , 0.3354 , 0.335  , 0.3347 , 0.3342 , 0.334  ,\n",
       "            0.3335 , 0.3323 , 0.3313 , 0.3306 , 0.3286 , 0.3284 , 0.3274 ,\n",
       "            0.3262 , 0.3254 , 0.3252 , 0.3242 , 0.3235 , 0.323  , 0.3228 ,\n",
       "            0.321  , 0.3203 , 0.32   , 0.3198 , 0.319  , 0.318  , 0.3174 ,\n",
       "            0.3147 , 0.3103 , 0.31   , 0.3098 , 0.308  , 0.3071 , 0.3066 ,\n",
       "            0.3044 , 0.304  , 0.3037 , 0.3025 , 0.3022 , 0.3013 , 0.299  ,\n",
       "            0.2966 , 0.2944 , 0.2942 , 0.2935 , 0.2932 , 0.293  , 0.2922 ,\n",
       "            0.2908 , 0.2905 , 0.2896 , 0.287  , 0.2869 , 0.2847 , 0.2812 ,\n",
       "            0.279  , 0.2786 , 0.2769 , 0.2761 , 0.2683 , 0.268  , 0.2666 ,\n",
       "            0.2664 , 0.264  , 0.2627 , 0.2622 , 0.259  , 0.2527 , 0.2522 ,\n",
       "            0.248  , 0.2456 , 0.2445 , 0.2434 , 0.2422 , 0.2413 , 0.2395 ,\n",
       "            0.2358 , 0.2356 , 0.2352 , 0.2334 , 0.2332 , 0.2306 , 0.2292 ,\n",
       "            0.2285 , 0.2266 , 0.2233 , 0.2218 , 0.2177 , 0.2137 , 0.2103 ,\n",
       "            0.2094 , 0.2089 , 0.2079 , 0.2063 , 0.204  , 0.2034 , 0.2    ,\n",
       "            0.1979 , 0.194  , 0.1849 , 0.1808 , 0.1736 , 0.1587 , 0.158  ,\n",
       "            0.157  , 0.1537 , 0.1511 , 0.1494 , 0.1383 , 0.1381 , 0.1378 ,\n",
       "            0.1283 , 0.124  , 0.11475, 0.1101 , 0.1095 , 0.10913, 0.09467],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00833333, dtype=float32),\n",
       "    'tpr': array(0.5, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.15      , 0.15833333,\n",
       "            0.175     , 0.175     , 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.29166666, 0.29166666, 0.3       , 0.3       , 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.41666666, 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.625     , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.675     , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.7916667 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.35384616, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4       ,\n",
       "            0.4076923 , 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.6230769 , 0.63076925, 0.63076925, 0.63076925,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.6615385 , 0.6615385 , 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.7076923 , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.74615383, 0.74615383, 0.75384617, 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 , 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.86923075, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.8769231 , 0.8769231 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.614  , 0.606  , 0.6045 , 0.6006 , 0.595  , 0.594  ,\n",
       "            0.5938 , 0.5933 , 0.593  , 0.592  , 0.591  , 0.5903 , 0.59   ,\n",
       "            0.588  , 0.586  , 0.585  , 0.583  , 0.579  , 0.578  , 0.577  ,\n",
       "            0.5703 , 0.5674 , 0.5645 , 0.558  , 0.5566 , 0.556  , 0.555  ,\n",
       "            0.5537 , 0.5522 , 0.55   , 0.5493 , 0.5464 , 0.546  , 0.5444 ,\n",
       "            0.543  , 0.5415 , 0.536  , 0.5356 , 0.534  , 0.5337 , 0.5303 ,\n",
       "            0.5293 , 0.5283 , 0.523  , 0.522  , 0.521  , 0.518  , 0.5146 ,\n",
       "            0.512  , 0.5117 , 0.511  , 0.508  , 0.5054 , 0.5044 , 0.502  ,\n",
       "            0.501  , 0.4941 , 0.4902 , 0.483  , 0.4824 , 0.4807 , 0.4773 ,\n",
       "            0.4756 , 0.4749 , 0.4712 , 0.4631 , 0.4534 , 0.4485 , 0.4377 ,\n",
       "            0.4312 , 0.425  , 0.4102 , 0.4045 , 0.4001 , 0.398  , 0.3882 ,\n",
       "            0.3875 , 0.3853 , 0.384  , 0.383  , 0.3823 , 0.381  , 0.3806 ,\n",
       "            0.3804 , 0.38   , 0.3782 , 0.378  , 0.3767 , 0.3757 , 0.3755 ,\n",
       "            0.3748 , 0.3743 , 0.3733 , 0.3708 , 0.3694 , 0.3667 , 0.3662 ,\n",
       "            0.3635 , 0.363  , 0.3628 , 0.3613 , 0.3608 , 0.3591 , 0.358  ,\n",
       "            0.3574 , 0.3564 , 0.356  , 0.3557 , 0.3535 , 0.3533 , 0.3525 ,\n",
       "            0.352  , 0.3513 , 0.3506 , 0.349  , 0.348  , 0.3467 , 0.3464 ,\n",
       "            0.3452 , 0.3445 , 0.3425 , 0.3423 , 0.3403 , 0.3398 , 0.3394 ,\n",
       "            0.3386 , 0.3381 , 0.338  , 0.3374 , 0.3372 , 0.3362 , 0.3354 ,\n",
       "            0.334  , 0.333  , 0.3281 , 0.3262 , 0.3257 , 0.325  , 0.3237 ,\n",
       "            0.3232 , 0.3218 , 0.3208 , 0.3196 , 0.3186 , 0.3152 , 0.314  ,\n",
       "            0.3118 , 0.3113 , 0.311  , 0.3108 , 0.3103 , 0.3096 , 0.3093 ,\n",
       "            0.3079 , 0.3076 , 0.306  , 0.3047 , 0.3025 , 0.302  , 0.3008 ,\n",
       "            0.3003 , 0.2961 , 0.2952 , 0.2903 , 0.289  , 0.2876 , 0.2766 ,\n",
       "            0.2761 , 0.2651 , 0.263  , 0.2627 , 0.26   , 0.257  , 0.2566 ,\n",
       "            0.2542 , 0.2485 , 0.2466 , 0.2438 , 0.2429 , 0.2418 , 0.2413 ,\n",
       "            0.2397 , 0.2386 , 0.2374 , 0.2356 , 0.234  , 0.2328 , 0.2325 ,\n",
       "            0.231  , 0.2294 , 0.2278 , 0.2277 , 0.2263 , 0.2255 , 0.2233 ,\n",
       "            0.218  , 0.2145 , 0.2144 , 0.2139 , 0.209  , 0.2089 , 0.2039 ,\n",
       "            0.2024 , 0.2004 , 0.1991 , 0.1919 , 0.1896 , 0.1833 , 0.1776 ,\n",
       "            0.1752 , 0.1615 , 0.1464 , 0.1459 , 0.1448 , 0.1415 , 0.1384 ,\n",
       "            0.1372 , 0.1362 , 0.1256 , 0.1249 , 0.1152 , 0.11084, 0.10156,\n",
       "            0.09875, 0.09686, 0.0836 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.01666667, dtype=float32),\n",
       "    'tpr': array(0.5692308, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.16666667, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.26666668,\n",
       "            0.275     , 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.38333333, 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5       , 0.51666665,\n",
       "            0.525     , 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.6       , 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.75      , 0.7583333 ,\n",
       "            0.7583333 , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.3846154 , 0.3923077 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5692308 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63076925, 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.66923076, 0.6769231 ,\n",
       "            0.6769231 , 0.6769231 , 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.86153847, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.8769231 , 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.669  , 0.6577 , 0.6567 , 0.6562 , 0.656  , 0.6504 ,\n",
       "            0.646  , 0.643  , 0.6426 , 0.642  , 0.639  , 0.6387 , 0.6377 ,\n",
       "            0.636  , 0.635  , 0.6323 , 0.632  , 0.629  , 0.627  , 0.6245 ,\n",
       "            0.623  , 0.616  , 0.6147 , 0.613  , 0.6113 , 0.6064 , 0.6016 ,\n",
       "            0.6    , 0.5996 , 0.5977 , 0.5967 , 0.595  , 0.593  , 0.592  ,\n",
       "            0.5913 , 0.5894 , 0.588  , 0.5874 , 0.587  , 0.5864 , 0.583  ,\n",
       "            0.5806 , 0.58   , 0.578  , 0.575  , 0.5747 , 0.574  , 0.5737 ,\n",
       "            0.573  , 0.568  , 0.5674 , 0.565  , 0.5605 , 0.557  , 0.5513 ,\n",
       "            0.55   , 0.547  , 0.5454 , 0.5444 , 0.541  , 0.5386 , 0.535  ,\n",
       "            0.53   , 0.526  , 0.5215 , 0.5156 , 0.5137 , 0.5107 , 0.505  ,\n",
       "            0.503  , 0.502  , 0.4858 , 0.4795 , 0.4697 , 0.4695 , 0.4534 ,\n",
       "            0.4512 , 0.4404 , 0.4219 , 0.419  , 0.417  , 0.4167 , 0.4155 ,\n",
       "            0.4146 , 0.4138 , 0.4126 , 0.4119 , 0.4116 , 0.4106 , 0.409  ,\n",
       "            0.4084 , 0.408  , 0.4062 , 0.4033 , 0.403  , 0.4026 , 0.4    ,\n",
       "            0.3997 , 0.3994 , 0.399  , 0.3984 , 0.398  , 0.3975 , 0.3955 ,\n",
       "            0.3945 , 0.3914 , 0.3882 , 0.3877 , 0.3857 , 0.3848 , 0.3843 ,\n",
       "            0.3838 , 0.3835 , 0.382  , 0.3813 , 0.38   , 0.377  , 0.3762 ,\n",
       "            0.3752 , 0.3748 , 0.3723 , 0.3713 , 0.3708 , 0.3704 , 0.3699 ,\n",
       "            0.3682 , 0.3677 , 0.3667 , 0.3662 , 0.366  , 0.3655 , 0.3652 ,\n",
       "            0.363  , 0.3604 , 0.3591 , 0.3584 , 0.3557 , 0.3545 , 0.3538 ,\n",
       "            0.3528 , 0.35   , 0.3494 , 0.346  , 0.3455 , 0.3418 , 0.3403 ,\n",
       "            0.34   , 0.3396 , 0.3386 , 0.338  , 0.3376 , 0.3374 , 0.337  ,\n",
       "            0.3362 , 0.3333 , 0.333  , 0.3271 , 0.3257 , 0.3252 , 0.3193 ,\n",
       "            0.3188 , 0.317  , 0.3147 , 0.3118 , 0.3105 , 0.31   , 0.3066 ,\n",
       "            0.305  , 0.302  , 0.3018 , 0.3005 , 0.2925 , 0.2825 , 0.2737 ,\n",
       "            0.2722 , 0.2632 , 0.2622 , 0.262  , 0.2612 , 0.261  , 0.258  ,\n",
       "            0.2554 , 0.2537 , 0.2534 , 0.2515 , 0.2456 , 0.2441 , 0.2434 ,\n",
       "            0.2428 , 0.2415 , 0.2366 , 0.2325 , 0.2322 , 0.2318 , 0.2311 ,\n",
       "            0.2285 , 0.2281 , 0.228  , 0.2277 , 0.2224 , 0.222  , 0.2211 ,\n",
       "            0.2197 , 0.2181 , 0.2108 , 0.2073 , 0.1982 , 0.1962 , 0.1919 ,\n",
       "            0.1904 , 0.1896 , 0.1814 , 0.1797 , 0.173  , 0.1681 , 0.1508 ,\n",
       "            0.1401 , 0.136  , 0.1348 , 0.1343 , 0.1315 , 0.1272 , 0.127  ,\n",
       "            0.11475, 0.11316, 0.1036 , 0.0991 , 0.0899 , 0.0898 , 0.0868 ,\n",
       "            0.0856 , 0.07465], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.03333334, dtype=float32),\n",
       "    'tpr': array(0.5769231, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15      , 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25      , 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.6       , 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65833336, 0.675     , 0.68333334, 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.7083333 ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.42307693, 0.43076923, 0.44615385,\n",
       "            0.45384616, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5692308 , 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.6076923 , 0.6230769 ,\n",
       "            0.6230769 , 0.6230769 , 0.6230769 , 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6769231 , 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.7       , 0.7       , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.8769231 , 0.88461536, 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7144 , 0.7056 , 0.7026 , 0.7    , 0.6943 , 0.69   ,\n",
       "            0.687  , 0.686  , 0.6855 , 0.6816 , 0.681  , 0.6797 , 0.679  ,\n",
       "            0.677  , 0.674  , 0.6714 , 0.6694 , 0.666  , 0.664  , 0.6562 ,\n",
       "            0.6533 , 0.652  , 0.6475 , 0.64   , 0.638  , 0.6377 , 0.6353 ,\n",
       "            0.635  , 0.6304 , 0.6294 , 0.6284 , 0.627  , 0.626  , 0.6255 ,\n",
       "            0.6245 , 0.6235 , 0.623  , 0.6196 , 0.619  , 0.618  , 0.6123 ,\n",
       "            0.6104 , 0.61   , 0.6084 , 0.6074 , 0.605  , 0.602  , 0.599  ,\n",
       "            0.5894 , 0.5825 , 0.5786 , 0.578  , 0.576  , 0.5713 , 0.5693 ,\n",
       "            0.567  , 0.5645 , 0.56   , 0.558  , 0.555  , 0.54   , 0.5366 ,\n",
       "            0.5303 , 0.53   , 0.5264 , 0.5166 , 0.506  , 0.502  , 0.4958 ,\n",
       "            0.4844 , 0.4722 , 0.4683 , 0.4475 , 0.445  , 0.4448 , 0.4414 ,\n",
       "            0.4402 , 0.4375 , 0.4355 , 0.4348 , 0.4338 , 0.4329 , 0.4314 ,\n",
       "            0.4312 , 0.4297 , 0.4282 , 0.4272 , 0.426  , 0.4258 , 0.424  ,\n",
       "            0.4236 , 0.4224 , 0.4214 , 0.419  , 0.4182 , 0.4172 , 0.415  ,\n",
       "            0.4136 , 0.411  , 0.409  , 0.4084 , 0.408  , 0.4065 , 0.406  ,\n",
       "            0.4053 , 0.405  , 0.4045 , 0.4026 , 0.4023 , 0.402  , 0.4014 ,\n",
       "            0.3975 , 0.3967 , 0.3958 , 0.395  , 0.3948 , 0.393  , 0.392  ,\n",
       "            0.391  , 0.3904 , 0.3882 , 0.388  , 0.3872 , 0.3867 , 0.3853 ,\n",
       "            0.3843 , 0.3838 , 0.383  , 0.3816 , 0.3801 , 0.3782 , 0.375  ,\n",
       "            0.3743 , 0.374  , 0.3738 , 0.3733 , 0.3723 , 0.3713 , 0.37   ,\n",
       "            0.3699 , 0.366  , 0.3616 , 0.3594 , 0.3591 , 0.3586 , 0.3582 ,\n",
       "            0.357  , 0.3562 , 0.3552 , 0.3489 , 0.3486 , 0.3484 , 0.3442 ,\n",
       "            0.3438 , 0.3403 , 0.3372 , 0.3345 , 0.3293 , 0.3286 , 0.3271 ,\n",
       "            0.3257 , 0.3254 , 0.323  , 0.3176 , 0.3152 , 0.3118 , 0.3042 ,\n",
       "            0.3003 , 0.299  , 0.2988 , 0.2935 , 0.2822 , 0.2737 , 0.2722 ,\n",
       "            0.27   , 0.261  , 0.2598 , 0.2573 , 0.256  , 0.2534 , 0.2532 ,\n",
       "            0.2471 , 0.2458 , 0.2415 , 0.2397 , 0.2362 , 0.2344 , 0.2343 ,\n",
       "            0.228  , 0.2269 , 0.2249 , 0.2242 , 0.224  , 0.2208 , 0.2197 ,\n",
       "            0.2128 , 0.2125 , 0.2096 , 0.2018 , 0.1979 , 0.191  , 0.1864 ,\n",
       "            0.1833 , 0.182  , 0.1805 , 0.1763 , 0.171  , 0.1626 , 0.1586 ,\n",
       "            0.1395 , 0.1383 , 0.1251 , 0.1235 , 0.12317, 0.12054, 0.11633,\n",
       "            0.11554, 0.1036 , 0.10175, 0.09235, 0.088  , 0.0804 , 0.0792 ,\n",
       "            0.07684, 0.075  , 0.0656 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04166667, dtype=float32),\n",
       "    'tpr': array(0.5923077, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.13333334, 0.13333334, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "            0.2       , 0.2       , 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.28333333, 0.28333333,\n",
       "            0.29166666, 0.29166666, 0.29166666, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.56153846, 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5846154 , 0.5923077 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63076925, 0.63076925, 0.63076925,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.7307692 , 0.7307692 ,\n",
       "            0.7307692 , 0.7307692 , 0.7307692 , 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.74615383, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.88461536, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7603 , 0.758  , 0.7495 , 0.7456 , 0.7446 , 0.7397 ,\n",
       "            0.7363 , 0.7324 , 0.7314 , 0.7305 , 0.73   , 0.7266 , 0.7256 ,\n",
       "            0.724  , 0.723  , 0.7217 , 0.7188 , 0.7183 , 0.7163 , 0.7153 ,\n",
       "            0.7095 , 0.7075 , 0.7    , 0.699  , 0.6963 , 0.693  , 0.683  ,\n",
       "            0.68   , 0.6797 , 0.6787 , 0.678  , 0.6772 , 0.6763 , 0.6753 ,\n",
       "            0.6724 , 0.671  , 0.6694 , 0.668  , 0.6675 , 0.6655 , 0.664  ,\n",
       "            0.6636 , 0.6616 , 0.659  , 0.657  , 0.654  , 0.6514 , 0.65   ,\n",
       "            0.6494 , 0.6484 , 0.648  , 0.645  , 0.6406 , 0.6343 , 0.627  ,\n",
       "            0.626  , 0.6206 , 0.6187 , 0.6177 , 0.6143 , 0.6113 , 0.61   ,\n",
       "            0.6064 , 0.606  , 0.5996 , 0.597  , 0.596  , 0.5723 , 0.567  ,\n",
       "            0.5635 , 0.5586 , 0.5557 , 0.555  , 0.5537 , 0.53   , 0.508  ,\n",
       "            0.4963 , 0.4915 , 0.4846 , 0.4841 , 0.4766 , 0.4756 , 0.4739 ,\n",
       "            0.47   , 0.4695 , 0.4688 , 0.4675 , 0.4666 , 0.4648 , 0.4644 ,\n",
       "            0.4636 , 0.4634 , 0.4607 , 0.4602 , 0.4558 , 0.455  , 0.4548 ,\n",
       "            0.4526 , 0.4502 , 0.4495 , 0.4492 , 0.446  , 0.4443 , 0.4434 ,\n",
       "            0.4429 , 0.439  , 0.4385 , 0.4375 , 0.4373 , 0.4333 , 0.432  ,\n",
       "            0.4312 , 0.4307 , 0.4304 , 0.43   , 0.4294 , 0.4292 , 0.4287 ,\n",
       "            0.4275 , 0.427  , 0.4263 , 0.426  , 0.4238 , 0.4175 , 0.416  ,\n",
       "            0.4146 , 0.413  , 0.412  , 0.4119 , 0.4111 , 0.4106 , 0.4097 ,\n",
       "            0.4082 , 0.408  , 0.4053 , 0.4048 , 0.4043 , 0.4036 , 0.402  ,\n",
       "            0.4016 , 0.3992 , 0.398  , 0.3972 , 0.3967 , 0.3965 , 0.3936 ,\n",
       "            0.3933 , 0.3926 , 0.391  , 0.3904 , 0.3896 , 0.3875 , 0.3865 ,\n",
       "            0.3833 , 0.383  , 0.3804 , 0.3743 , 0.3682 , 0.3667 , 0.3657 ,\n",
       "            0.3643 , 0.3577 , 0.3555 , 0.3552 , 0.3472 , 0.3455 , 0.343  ,\n",
       "            0.3418 , 0.3396 , 0.3328 , 0.3318 , 0.3298 , 0.3293 , 0.317  ,\n",
       "            0.316  , 0.3147 , 0.3074 , 0.3    , 0.2986 , 0.298  , 0.2932 ,\n",
       "            0.2883 , 0.2856 , 0.2805 , 0.2751 , 0.2747 , 0.2727 , 0.2705 ,\n",
       "            0.2612 , 0.2585 , 0.2563 , 0.255  , 0.2517 , 0.2494 , 0.2438 ,\n",
       "            0.2433 , 0.2426 , 0.2415 , 0.241  , 0.2407 , 0.2297 , 0.2255 ,\n",
       "            0.2197 , 0.2189 , 0.2181 , 0.2167 , 0.2139 , 0.2086 , 0.2063 ,\n",
       "            0.2028 , 0.1952 , 0.191  , 0.1866 , 0.1807 , 0.179  , 0.1781 ,\n",
       "            0.1738 , 0.1725 , 0.1631 , 0.1531 , 0.1514 , 0.1423 , 0.13   ,\n",
       "            0.11615, 0.1138 , 0.11316, 0.11163, 0.1074 , 0.1056 , 0.0942 ,\n",
       "            0.09186, 0.0827 , 0.0785 , 0.07275, 0.0698 , 0.0684 , 0.0661 ,\n",
       "            0.058  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.08333334, dtype=float32),\n",
       "    'tpr': array(0.61538464, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.175     , 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.325     , 0.325     , 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.4       , 0.41666666,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.44166666, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.64166665, 0.65      , 0.65833336, 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.56153846, 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6       , 0.61538464, 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6769231 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.7153846 , 0.72307694, 0.72307694,\n",
       "            0.72307694, 0.72307694, 0.7307692 , 0.73846155, 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.75384617, 0.75384617,\n",
       "            0.75384617, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.8769231 , 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7993 , 0.798  , 0.7866 , 0.782  , 0.781  , 0.7773 ,\n",
       "            0.774  , 0.77   , 0.7686 , 0.7676 , 0.766  , 0.7627 , 0.761  ,\n",
       "            0.76   , 0.7583 , 0.756  , 0.755  , 0.7534 , 0.7515 , 0.746  ,\n",
       "            0.7437 , 0.737  , 0.7354 , 0.7324 , 0.73   , 0.7188 , 0.7173 ,\n",
       "            0.7153 , 0.715  , 0.7144 , 0.7124 , 0.711  , 0.7085 , 0.7075 ,\n",
       "            0.706  , 0.705  , 0.7046 , 0.7036 , 0.702  , 0.701  , 0.6997 ,\n",
       "            0.698  , 0.6973 , 0.694  , 0.6924 , 0.6914 , 0.6895 , 0.683  ,\n",
       "            0.6826 , 0.682  , 0.681  , 0.673  , 0.6724 , 0.6714 , 0.666  ,\n",
       "            0.6587 , 0.6562 , 0.6523 , 0.652  , 0.644  , 0.6406 , 0.6367 ,\n",
       "            0.635  , 0.6313 , 0.6284 , 0.626  , 0.5986 , 0.5923 , 0.592  ,\n",
       "            0.591  , 0.5874 , 0.5815 , 0.579  , 0.567  , 0.5576 , 0.5522 ,\n",
       "            0.5396 , 0.5283 , 0.516  , 0.5146 , 0.514  , 0.5044 , 0.5034 ,\n",
       "            0.503  , 0.4983 , 0.4966 , 0.495  , 0.494  , 0.4937 , 0.4915 ,\n",
       "            0.4902 , 0.4858 , 0.4856 , 0.482  , 0.48   , 0.479  , 0.4783 ,\n",
       "            0.4778 , 0.4727 , 0.4724 , 0.4717 , 0.4707 , 0.468  , 0.4673 ,\n",
       "            0.4653 , 0.4648 , 0.4626 , 0.4614 , 0.4585 , 0.4575 , 0.456  ,\n",
       "            0.4558 , 0.455  , 0.4548 , 0.4543 , 0.4536 , 0.4534 , 0.4521 ,\n",
       "            0.4512 , 0.4504 , 0.4465 , 0.4402 , 0.4377 , 0.4355 , 0.4343 ,\n",
       "            0.4338 , 0.4333 , 0.433  , 0.4326 , 0.4324 , 0.4316 , 0.4297 ,\n",
       "            0.4294 , 0.4287 , 0.4285 , 0.426  , 0.4253 , 0.424  , 0.4187 ,\n",
       "            0.418  , 0.4177 , 0.4172 , 0.4155 , 0.4146 , 0.4143 , 0.414  ,\n",
       "            0.4124 , 0.4102 , 0.41   , 0.4097 , 0.4094 , 0.4048 , 0.404  ,\n",
       "            0.4    , 0.3975 , 0.397  , 0.3845 , 0.3818 , 0.3792 , 0.3782 ,\n",
       "            0.374  , 0.372  , 0.3696 , 0.3616 , 0.3608 , 0.3599 , 0.358  ,\n",
       "            0.3542 , 0.343  , 0.3428 , 0.3398 , 0.3293 , 0.3284 , 0.328  ,\n",
       "            0.3274 , 0.3162 , 0.312  , 0.3074 , 0.3062 , 0.3008 , 0.2957 ,\n",
       "            0.294  , 0.2935 , 0.286  , 0.2842 , 0.284  , 0.2837 , 0.282  ,\n",
       "            0.2747 , 0.265  , 0.2595 , 0.252  , 0.2498 , 0.2494 , 0.2466 ,\n",
       "            0.243  , 0.2388 , 0.2374 , 0.237  , 0.223  , 0.2217 , 0.2119 ,\n",
       "            0.2108 , 0.2095 , 0.2091 , 0.2051 , 0.2024 , 0.1973 , 0.1935 ,\n",
       "            0.1859 , 0.1816 , 0.1805 , 0.1766 , 0.1758 , 0.1699 , 0.164  ,\n",
       "            0.1621 , 0.1539 , 0.1433 , 0.1432 , 0.1421 , 0.1197 , 0.1069 ,\n",
       "            0.1041 , 0.10266, 0.1023 , 0.09827, 0.09534, 0.08496, 0.082  ,\n",
       "            0.0733 , 0.0693 , 0.06537, 0.06085, 0.06064, 0.0577 , 0.0511 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.15, dtype=float32),\n",
       "    'tpr': array(0.65384614, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15      , 0.15833333,\n",
       "            0.175     , 0.175     , 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.225     , 0.225     , 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.23333333, 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.38333333, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45833334, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.49166667, 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.575     , 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.56153846, 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.6076923 , 0.61538464, 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.66923076, 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.7076923 , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.75384617, 0.75384617,\n",
       "            0.75384617, 0.75384617, 0.75384617, 0.75384617, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.77692306, 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8354 , 0.8315 , 0.8203 , 0.8164 , 0.8145 , 0.8115 ,\n",
       "            0.807  , 0.804  , 0.8022 , 0.8003 , 0.7974 , 0.797  , 0.7964 ,\n",
       "            0.7935 , 0.7925 , 0.7896 , 0.7876 , 0.7856 , 0.781  , 0.7783 ,\n",
       "            0.7705 , 0.7695 , 0.768  , 0.766  , 0.7646 , 0.756  , 0.753  ,\n",
       "            0.749  , 0.7485 , 0.748  , 0.747  , 0.7456 , 0.7446 , 0.741  ,\n",
       "            0.7407 , 0.7397 , 0.7373 , 0.737  , 0.736  , 0.735  , 0.7334 ,\n",
       "            0.7324 , 0.7305 , 0.7285 , 0.7266 , 0.726  , 0.7246 , 0.7173 ,\n",
       "            0.7153 , 0.714  , 0.7134 , 0.706  , 0.7056 , 0.705  , 0.7017 ,\n",
       "            0.695  , 0.69   , 0.6875 , 0.6836 , 0.682  , 0.675  , 0.6694 ,\n",
       "            0.6665 , 0.6646 , 0.6636 , 0.6567 , 0.6553 , 0.6265 , 0.6245 ,\n",
       "            0.6177 , 0.617  , 0.6064 , 0.6025 , 0.5996 , 0.584  , 0.575  ,\n",
       "            0.5684 , 0.56   , 0.5425 , 0.533  , 0.532  , 0.5312 , 0.5293 ,\n",
       "            0.528  , 0.525  , 0.521  , 0.52   , 0.5195 , 0.518  , 0.514  ,\n",
       "            0.5137 , 0.5083 , 0.5063 , 0.504  , 0.5034 , 0.5015 , 0.5    ,\n",
       "            0.496  , 0.4932 , 0.493  , 0.4888 , 0.4875 , 0.4868 , 0.484  ,\n",
       "            0.4824 , 0.4817 , 0.4814 , 0.4807 , 0.4797 , 0.4792 , 0.479  ,\n",
       "            0.4749 , 0.4746 , 0.4731 , 0.4722 , 0.472  , 0.4712 , 0.4705 ,\n",
       "            0.4688 , 0.4653 , 0.4636 , 0.4597 , 0.4563 , 0.4524 , 0.4514 ,\n",
       "            0.4504 , 0.45   , 0.4492 , 0.449  , 0.4473 , 0.447  , 0.4468 ,\n",
       "            0.4436 , 0.4434 , 0.4424 , 0.4414 , 0.4385 , 0.435  , 0.4338 ,\n",
       "            0.4326 , 0.43   , 0.4297 , 0.4294 , 0.429  , 0.4287 , 0.426  ,\n",
       "            0.423  , 0.4224 , 0.422  , 0.4165 , 0.4158 , 0.4053 , 0.403  ,\n",
       "            0.3918 , 0.3882 , 0.388  , 0.3828 , 0.3752 , 0.3733 , 0.3716 ,\n",
       "            0.369  , 0.362  , 0.3586 , 0.3508 , 0.349  , 0.3398 , 0.3394 ,\n",
       "            0.3352 , 0.3267 , 0.3245 , 0.3206 , 0.3176 , 0.3147 , 0.3096 ,\n",
       "            0.3035 , 0.3022 , 0.295  , 0.29   , 0.2898 , 0.2893 , 0.2886 ,\n",
       "            0.2842 , 0.284  , 0.2683 , 0.2659 , 0.2578 , 0.2546 , 0.2458 ,\n",
       "            0.2434 , 0.2421 , 0.2401 , 0.2347 , 0.2302 , 0.2294 , 0.2185 ,\n",
       "            0.2134 , 0.2029 , 0.2018 , 0.2009 , 0.2002 , 0.196  , 0.1947 ,\n",
       "            0.1879 , 0.1841 , 0.1761 , 0.1735 , 0.1731 , 0.1716 , 0.1697 ,\n",
       "            0.1602 , 0.1536 , 0.1519 , 0.1442 , 0.1421 , 0.1343 , 0.132  ,\n",
       "            0.1097 , 0.0977 , 0.09467, 0.0933 , 0.0927 , 0.0895 , 0.0856 ,\n",
       "            0.0761 , 0.07275, 0.06464, 0.06085, 0.05844, 0.0533 , 0.053  ,\n",
       "            0.05014, 0.04468], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.21666667, dtype=float32),\n",
       "    'tpr': array(0.72307694, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15      , 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.2       ,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.225     , 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.60833335, 0.60833335, 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.64166665, 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.21538462, 0.23076923, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.30769232, 0.31538463, 0.32307693, 0.33846155,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6769231 , 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.7       , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.75384617, 0.75384617, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.76153845, 0.76153845, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8677 , 0.862  , 0.85   , 0.8467 , 0.8447 , 0.843  ,\n",
       "            0.838  , 0.836  , 0.8354 , 0.8335 , 0.831  , 0.8286 , 0.827  ,\n",
       "            0.824  , 0.8237 , 0.821  , 0.819  , 0.817  , 0.8125 , 0.81   ,\n",
       "            0.802  , 0.801  , 0.8    , 0.798  , 0.7974 , 0.792  , 0.7847 ,\n",
       "            0.781  , 0.7803 , 0.78   , 0.7793 , 0.776  , 0.7734 , 0.773  ,\n",
       "            0.7715 , 0.7686 , 0.768  , 0.7666 , 0.765  , 0.7617 , 0.7603 ,\n",
       "            0.759  , 0.757  , 0.751  , 0.7466 , 0.746  , 0.7446 , 0.744  ,\n",
       "            0.7397 , 0.737  , 0.7363 , 0.7354 , 0.7314 , 0.7275 , 0.7163 ,\n",
       "            0.7153 , 0.712  , 0.704  , 0.6978 , 0.696  , 0.6924 , 0.6846 ,\n",
       "            0.684  , 0.662  , 0.6504 , 0.6484 , 0.6445 , 0.6416 , 0.634  ,\n",
       "            0.63   , 0.625  , 0.611  , 0.599  , 0.5977 , 0.5947 , 0.573  ,\n",
       "            0.5723 , 0.566  , 0.5605 , 0.5586 , 0.556  , 0.554  , 0.5493 ,\n",
       "            0.549  , 0.5483 , 0.548  , 0.5454 , 0.5405 , 0.54   , 0.534  ,\n",
       "            0.533  , 0.53   , 0.529  , 0.5283 , 0.525  , 0.5244 , 0.5234 ,\n",
       "            0.5186 , 0.5166 , 0.5156 , 0.512  , 0.5117 , 0.5103 , 0.509  ,\n",
       "            0.5083 , 0.5073 , 0.5054 , 0.5044 , 0.501  , 0.4988 , 0.4973 ,\n",
       "            0.4968 , 0.495  , 0.4944 , 0.4934 , 0.493  , 0.4915 , 0.4883 ,\n",
       "            0.487  , 0.479  , 0.4775 , 0.4763 , 0.4744 , 0.474  , 0.473  ,\n",
       "            0.4727 , 0.4712 , 0.4697 , 0.4678 , 0.4673 , 0.4668 , 0.465  ,\n",
       "            0.4646 , 0.4622 , 0.4607 , 0.4597 , 0.4585 , 0.4553 , 0.4534 ,\n",
       "            0.4526 , 0.4524 , 0.451  , 0.4504 , 0.4475 , 0.4468 , 0.4465 ,\n",
       "            0.4463 , 0.4443 , 0.444  , 0.4429 , 0.4414 , 0.439  , 0.421  ,\n",
       "            0.4204 , 0.4102 , 0.4087 , 0.406  , 0.4045 , 0.4011 , 0.3994 ,\n",
       "            0.3962 , 0.3936 , 0.3909 , 0.3882 , 0.3806 , 0.3735 , 0.3726 ,\n",
       "            0.3608 , 0.359  , 0.358  , 0.3535 , 0.345  , 0.338  , 0.3315 ,\n",
       "            0.3308 , 0.324  , 0.321  , 0.3203 , 0.313  , 0.311  , 0.3071 ,\n",
       "            0.3005 , 0.298  , 0.297  , 0.2964 , 0.2856 , 0.2832 , 0.2822 ,\n",
       "            0.2744 , 0.2737 , 0.2656 , 0.262  , 0.2422 , 0.2395 , 0.2367 ,\n",
       "            0.2332 , 0.2314 , 0.2229 , 0.2211 , 0.2145 , 0.2042 , 0.1934 ,\n",
       "            0.1924 , 0.1913 , 0.1903 , 0.1871 , 0.1863 , 0.1779 , 0.1738 ,\n",
       "            0.1709 , 0.1663 , 0.1656 , 0.1638 , 0.1611 , 0.1505 , 0.1428 ,\n",
       "            0.1416 , 0.141  , 0.1346 , 0.1256 , 0.12085, 0.0998 , 0.089  ,\n",
       "            0.0857 , 0.08466, 0.0828 , 0.08093, 0.076  , 0.0677 , 0.06396,\n",
       "            0.05646, 0.053  , 0.05194, 0.04654, 0.0456 , 0.0432 , 0.03876],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3, dtype=float32),\n",
       "    'tpr': array(0.7846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.15      , 0.15      ,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.23333333, 0.23333333, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.6       , 0.6       , 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.20769231, 0.22307692, 0.23076923, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.72307694, 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.76153845, 0.76153845,\n",
       "            0.76153845, 0.77692306, 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.8769231 , 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.893  , 0.886  , 0.875  , 0.872  , 0.8706 , 0.869  ,\n",
       "            0.8633 , 0.862  , 0.8604 , 0.8574 , 0.856  , 0.8535 , 0.851  ,\n",
       "            0.8506 , 0.848  , 0.8477 , 0.846  , 0.8438 , 0.8403 , 0.838  ,\n",
       "            0.8296 , 0.8286 , 0.826  , 0.8247 , 0.823  , 0.8125 , 0.8096 ,\n",
       "            0.8086 , 0.808  , 0.805  , 0.8022 , 0.802  , 0.8003 , 0.798  ,\n",
       "            0.797  , 0.7964 , 0.7954 , 0.7944 , 0.7915 , 0.791  , 0.7905 ,\n",
       "            0.7896 , 0.786  , 0.7817 , 0.7754 , 0.775  , 0.7734 , 0.7725 ,\n",
       "            0.77   , 0.7686 , 0.7656 , 0.764  , 0.7627 , 0.745  , 0.7446 ,\n",
       "            0.74   , 0.7324 , 0.727  , 0.7256 , 0.7236 , 0.7197 , 0.7124 ,\n",
       "            0.712  , 0.697  , 0.679  , 0.677  , 0.6714 , 0.6685 , 0.666  ,\n",
       "            0.6533 , 0.649  , 0.639  , 0.6343 , 0.631  , 0.6216 , 0.6055 ,\n",
       "            0.6045 , 0.5923 , 0.591  , 0.589  , 0.5874 , 0.581  , 0.5806 ,\n",
       "            0.578  , 0.576  , 0.571  , 0.5674 , 0.5635 , 0.5615 , 0.561  ,\n",
       "            0.56   , 0.556  , 0.5537 , 0.553  , 0.5522 , 0.55   , 0.548  ,\n",
       "            0.544  , 0.543  , 0.5425 , 0.5415 , 0.541  , 0.5386 , 0.537  ,\n",
       "            0.5366 , 0.534  , 0.5337 , 0.5303 , 0.529  , 0.527  , 0.5254 ,\n",
       "            0.525  , 0.523  , 0.52   , 0.5176 , 0.5166 , 0.5127 , 0.5107 ,\n",
       "            0.506  , 0.505  , 0.5034 , 0.5024 , 0.502  , 0.5005 , 0.496  ,\n",
       "            0.4958 , 0.4946 , 0.494  , 0.4927 , 0.4924 , 0.4907 , 0.4902 ,\n",
       "            0.487  , 0.4863 , 0.4844 , 0.4834 , 0.483  , 0.4805 , 0.4768 ,\n",
       "            0.4734 , 0.4722 , 0.4717 , 0.471  , 0.4695 , 0.4692 , 0.469  ,\n",
       "            0.4658 , 0.4624 , 0.4585 , 0.4329 , 0.429  , 0.4275 , 0.4236 ,\n",
       "            0.4219 , 0.421  , 0.4187 , 0.4172 , 0.417  , 0.4167 , 0.4114 ,\n",
       "            0.3992 , 0.3965 , 0.39   , 0.379  , 0.3782 , 0.3767 , 0.3733 ,\n",
       "            0.3625 , 0.3623 , 0.3542 , 0.3513 , 0.3418 , 0.3398 , 0.3298 ,\n",
       "            0.3289 , 0.3247 , 0.3208 , 0.32   , 0.3186 , 0.3154 , 0.3152 ,\n",
       "            0.3135 , 0.301  , 0.2932 , 0.293  , 0.2869 , 0.284  , 0.2803 ,\n",
       "            0.279  , 0.2786 , 0.2487 , 0.2375 , 0.2343 , 0.233  , 0.2307 ,\n",
       "            0.2194 , 0.2163 , 0.2157 , 0.1984 , 0.1877 , 0.1865 , 0.1858 ,\n",
       "            0.1835 , 0.1833 , 0.1797 , 0.1748 , 0.1709 , 0.1669 , 0.1636 ,\n",
       "            0.163  , 0.1587 , 0.1545 , 0.1492 , 0.1445 , 0.1356 , 0.1335 ,\n",
       "            0.1288 , 0.12054, 0.1124 , 0.09283, 0.0833 , 0.07947, 0.07904,\n",
       "            0.07556, 0.07544, 0.06903, 0.0619 , 0.05737, 0.0505 , 0.04794,\n",
       "            0.04742, 0.04208, 0.04025, 0.03818, 0.035  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.34166667, dtype=float32),\n",
       "    'tpr': array(0.8230769, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.15      , 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.2       , 0.20833333, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.225     , 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.275     , 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35833332, 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.6       , 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.6076923 , 0.61538464, 0.61538464, 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.6846154 , 0.6923077 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.72307694,\n",
       "            0.7307692 , 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.76153845, 0.76153845, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.88461536, 0.9       , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.91   , 0.9023 , 0.8916 , 0.889  , 0.887  , 0.8857 ,\n",
       "            0.8804 , 0.88   , 0.8794 , 0.8774 , 0.8745 , 0.8735 , 0.873  ,\n",
       "            0.871  , 0.868  , 0.8677 , 0.865  , 0.8643 , 0.8613 , 0.858  ,\n",
       "            0.8555 , 0.8477 , 0.8467 , 0.846  , 0.845  , 0.844  , 0.843  ,\n",
       "            0.833  , 0.831  , 0.8286 , 0.827  , 0.8267 , 0.826  , 0.823  ,\n",
       "            0.8213 , 0.82   , 0.819  , 0.8174 , 0.8154 , 0.815  , 0.814  ,\n",
       "            0.8135 , 0.8125 , 0.811  , 0.8105 , 0.8096 , 0.809  , 0.804  ,\n",
       "            0.802  , 0.794  , 0.793  , 0.792  , 0.7915 , 0.7905 , 0.7896 ,\n",
       "            0.7876 , 0.7856 , 0.7837 , 0.782  , 0.764  , 0.761  , 0.7583 ,\n",
       "            0.7495 , 0.7466 , 0.7417 , 0.7407 , 0.736  , 0.73   , 0.728  ,\n",
       "            0.7197 , 0.6987 , 0.6914 , 0.691  , 0.6875 , 0.678  , 0.6646 ,\n",
       "            0.66   , 0.658  , 0.6562 , 0.6504 , 0.633  , 0.6274 , 0.626  ,\n",
       "            0.6255 , 0.6113 , 0.61   , 0.6084 , 0.606  , 0.6    , 0.5996 ,\n",
       "            0.5967 , 0.5947 , 0.5894 , 0.589  , 0.5815 , 0.578  , 0.577  ,\n",
       "            0.576  , 0.5747 , 0.574  , 0.5703 , 0.5693 , 0.569  , 0.568  ,\n",
       "            0.5664 , 0.566  , 0.561  , 0.5605 , 0.56   , 0.5596 , 0.5586 ,\n",
       "            0.5566 , 0.556  , 0.555  , 0.5522 , 0.552  , 0.5513 , 0.5493 ,\n",
       "            0.546  , 0.5435 , 0.543  , 0.5415 , 0.5405 , 0.5386 , 0.5337 ,\n",
       "            0.5312 , 0.5254 , 0.5234 , 0.523  , 0.5215 , 0.521  , 0.5195 ,\n",
       "            0.517  , 0.5166 , 0.515  , 0.513  , 0.51   , 0.5093 , 0.509  ,\n",
       "            0.5063 , 0.505  , 0.504  , 0.5024 , 0.498  , 0.497  , 0.494  ,\n",
       "            0.4927 , 0.4895 , 0.4893 , 0.489  , 0.4875 , 0.4824 , 0.4805 ,\n",
       "            0.4802 , 0.4795 , 0.4739 , 0.4673 , 0.465  , 0.4622 , 0.4478 ,\n",
       "            0.438  , 0.4314 , 0.4292 , 0.4263 , 0.426  , 0.4238 , 0.4233 ,\n",
       "            0.4165 , 0.4146 , 0.407  , 0.3962 , 0.3914 , 0.3884 , 0.3845 ,\n",
       "            0.378  , 0.3735 , 0.3691 , 0.3667 , 0.3604 , 0.3562 , 0.3518 ,\n",
       "            0.3416 , 0.3357 , 0.3325 , 0.3318 , 0.3306 , 0.3218 , 0.3193 ,\n",
       "            0.316  , 0.3076 , 0.3071 , 0.3015 , 0.2925 , 0.2917 , 0.2915 ,\n",
       "            0.2903 , 0.2861 , 0.2683 , 0.266  , 0.247  , 0.2278 , 0.2272 ,\n",
       "            0.224  , 0.2207 , 0.2096 , 0.2089 , 0.2045 , 0.1859 , 0.1761 ,\n",
       "            0.1746 , 0.1743 , 0.1737 , 0.172  , 0.1705 , 0.1672 , 0.1582 ,\n",
       "            0.1562 , 0.1554 , 0.1542 , 0.1499 , 0.1466 , 0.1427 , 0.1339 ,\n",
       "            0.1241 , 0.1217 , 0.1188 , 0.1118 , 0.1007 , 0.08344, 0.0752 ,\n",
       "            0.0712 , 0.0678 , 0.0662 , 0.06052, 0.0546 , 0.04968, 0.04385,\n",
       "            0.0424 , 0.041  , 0.0367 , 0.03424, 0.03265, 0.03044],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.375, dtype=float32),\n",
       "    'tpr': array(0.84615386, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.225     , 0.225     , 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.275     , 0.275     ,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.525     , 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.6       , 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.72307694, 0.72307694, 0.7307692 , 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9253 , 0.918  , 0.9077 , 0.906  , 0.9043 , 0.904  ,\n",
       "            0.8994 , 0.8975 , 0.897  , 0.896  , 0.893  , 0.8926 , 0.8916 ,\n",
       "            0.889  , 0.8867 , 0.886  , 0.8843 , 0.8833 , 0.8823 , 0.8794 ,\n",
       "            0.878  , 0.8745 , 0.868  , 0.866  , 0.8657 , 0.8643 , 0.8623 ,\n",
       "            0.853  , 0.8506 , 0.849  , 0.848  , 0.847  , 0.8467 , 0.846  ,\n",
       "            0.844  , 0.842  , 0.841  , 0.84   , 0.8374 , 0.8354 , 0.835  ,\n",
       "            0.834  , 0.8335 , 0.8315 , 0.831  , 0.83   , 0.8257 , 0.8223 ,\n",
       "            0.815  , 0.8145 , 0.813  , 0.8125 , 0.811  , 0.8105 , 0.809  ,\n",
       "            0.8076 , 0.8066 , 0.804  , 0.785  , 0.7827 , 0.779  , 0.7725 ,\n",
       "            0.7676 , 0.763  , 0.761  , 0.7573 , 0.75   , 0.749  , 0.741  ,\n",
       "            0.7197 , 0.712  , 0.7114 , 0.707  , 0.698  , 0.6846 , 0.6797 ,\n",
       "            0.679  , 0.675  , 0.6694 , 0.649  , 0.6475 , 0.6445 , 0.644  ,\n",
       "            0.629  , 0.628  , 0.627  , 0.624  , 0.6177 , 0.6167 , 0.614  ,\n",
       "            0.612  , 0.606  , 0.5986 , 0.5947 , 0.594  , 0.5938 , 0.592  ,\n",
       "            0.5913 , 0.5874 , 0.587  , 0.5864 , 0.5854 , 0.5825 , 0.582  ,\n",
       "            0.578  , 0.5776 , 0.5767 , 0.575  , 0.5728 , 0.572  , 0.5703 ,\n",
       "            0.567  , 0.5664 , 0.5645 , 0.5605 , 0.56   , 0.5586 , 0.5566 ,\n",
       "            0.555  , 0.5483 , 0.5454 , 0.5396 , 0.5386 , 0.537  , 0.536  ,\n",
       "            0.5337 , 0.5317 , 0.5293 , 0.5254 , 0.525  , 0.5244 , 0.5234 ,\n",
       "            0.5225 , 0.522  , 0.5195 , 0.518  , 0.5176 , 0.512  , 0.51   ,\n",
       "            0.5054 , 0.505  , 0.504  , 0.5015 , 0.501  , 0.4998 , 0.4949 ,\n",
       "            0.4917 , 0.4915 , 0.4905 , 0.4792 , 0.4727 , 0.472  , 0.467  ,\n",
       "            0.4595 , 0.4502 , 0.4382 , 0.4363 , 0.4338 , 0.4326 , 0.429  ,\n",
       "            0.4285 , 0.4272 , 0.4177 , 0.4148 , 0.413  , 0.4014 , 0.3972 ,\n",
       "            0.391  , 0.3896 , 0.3818 , 0.3752 , 0.3743 , 0.3718 , 0.3667 ,\n",
       "            0.3591 , 0.3538 , 0.3496 , 0.341  , 0.3403 , 0.3367 , 0.3286 ,\n",
       "            0.326  , 0.3228 , 0.312  , 0.3064 , 0.303  , 0.3025 , 0.296  ,\n",
       "            0.2915 , 0.2896 , 0.2893 , 0.287  , 0.262  , 0.2598 , 0.2437 ,\n",
       "            0.2213 , 0.2205 , 0.2166 , 0.213  , 0.2037 , 0.2009 , 0.1958 ,\n",
       "            0.1771 , 0.1676 , 0.1666 , 0.1654 , 0.1652 , 0.1648 , 0.1617 ,\n",
       "            0.158  , 0.1498 , 0.1489 , 0.148  , 0.1476 , 0.145  , 0.1375 ,\n",
       "            0.1335 , 0.12494, 0.1152 , 0.1128 , 0.1103 , 0.10376, 0.0925 ,\n",
       "            0.076  , 0.0682 , 0.0643 , 0.0612 , 0.05933, 0.0539 , 0.04858,\n",
       "            0.04385, 0.03845, 0.03754, 0.0359 , 0.0321 , 0.02965, 0.02834,\n",
       "            0.0265 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.40833333, dtype=float32),\n",
       "    'tpr': array(0.85384613, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.14166667, 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.225     , 0.23333333,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.29166666, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.525     , 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.6076923 , 0.61538464, 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.76153845, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.939  , 0.9316 , 0.922  , 0.9204 , 0.919  , 0.915  ,\n",
       "            0.9126 , 0.912  , 0.9116 , 0.909  , 0.908  , 0.9077 , 0.905  ,\n",
       "            0.903  , 0.902  , 0.9    , 0.8994 , 0.8984 , 0.8955 , 0.8945 ,\n",
       "            0.891  , 0.8857 , 0.8833 , 0.883  , 0.882  , 0.879  , 0.872  ,\n",
       "            0.868  , 0.867  , 0.866  , 0.8647 , 0.8643 , 0.8623 , 0.86   ,\n",
       "            0.8594 , 0.8574 , 0.8564 , 0.8535 , 0.853  , 0.8525 , 0.8516 ,\n",
       "            0.8506 , 0.8496 , 0.849  , 0.844  , 0.842  , 0.834  , 0.833  ,\n",
       "            0.831  , 0.83   , 0.829  , 0.8257 , 0.823  , 0.804  , 0.801  ,\n",
       "            0.797  , 0.7905 , 0.787  , 0.7812 , 0.7793 , 0.775  , 0.7686 ,\n",
       "            0.7666 , 0.7637 , 0.7397 , 0.7344 , 0.728  , 0.725  , 0.713  ,\n",
       "            0.703  , 0.699  , 0.694  , 0.693  , 0.6895 , 0.673  , 0.666  ,\n",
       "            0.6646 , 0.662  , 0.649  , 0.6484 , 0.648  , 0.644  , 0.638  ,\n",
       "            0.636  , 0.633  , 0.631  , 0.626  , 0.625  , 0.617  , 0.6133 ,\n",
       "            0.613  , 0.6123 , 0.6113 , 0.6104 , 0.605  , 0.6035 , 0.602  ,\n",
       "            0.6016 , 0.6006 , 0.6    , 0.598  , 0.596  , 0.5957 , 0.594  ,\n",
       "            0.5938 , 0.592  , 0.588  , 0.5845 , 0.584  , 0.583  , 0.5815 ,\n",
       "            0.5786 , 0.576  , 0.5747 , 0.572  , 0.5645 , 0.5635 , 0.5615 ,\n",
       "            0.5596 , 0.5586 , 0.5566 , 0.5527 , 0.5513 , 0.551  , 0.5503 ,\n",
       "            0.548  , 0.5474 , 0.547  , 0.544  , 0.541  , 0.54   , 0.5386 ,\n",
       "            0.536  , 0.533  , 0.532  , 0.528  , 0.5244 , 0.523  , 0.5215 ,\n",
       "            0.5186 , 0.517  , 0.511  , 0.506  , 0.5044 , 0.5034 , 0.4822 ,\n",
       "            0.481  , 0.4797 , 0.475  , 0.472  , 0.4688 , 0.4502 , 0.4492 ,\n",
       "            0.449  , 0.4478 , 0.4392 , 0.4275 , 0.4253 , 0.425  , 0.4163 ,\n",
       "            0.414  , 0.4136 , 0.4116 , 0.4001 , 0.393  , 0.3904 , 0.3865 ,\n",
       "            0.3853 , 0.3806 , 0.3743 , 0.368  , 0.367  , 0.3599 , 0.352  ,\n",
       "            0.3518 , 0.3486 , 0.3372 , 0.3333 , 0.3218 , 0.32   , 0.3093 ,\n",
       "            0.3042 , 0.3018 , 0.2986 , 0.2969 , 0.2917 , 0.2903 , 0.2795 ,\n",
       "            0.251  , 0.2483 , 0.2444 , 0.2173 , 0.2119 , 0.2075 , 0.204  ,\n",
       "            0.2001 , 0.1907 , 0.185  , 0.1674 , 0.1658 , 0.1573 , 0.1562 ,\n",
       "            0.1545 , 0.1544 , 0.1514 , 0.1499 , 0.1464 , 0.1453 , 0.1416 ,\n",
       "            0.1375 , 0.1335 , 0.1268 , 0.1232 , 0.11597, 0.1052 , 0.10266,\n",
       "            0.1021 , 0.0964 , 0.0825 , 0.0684 , 0.0619 , 0.05814, 0.0577 ,\n",
       "            0.0552 , 0.05176, 0.047  , 0.04297, 0.03775, 0.03348, 0.03333,\n",
       "            0.03096, 0.0281 , 0.02513, 0.02419, 0.0232 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.40833333, dtype=float32),\n",
       "    'tpr': array(0.85384613, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.20833333, 0.20833333, 0.225     , 0.23333333,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.30833334, 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.36666667, 0.36666667,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.56666666, 0.56666666,\n",
       "            0.575     , 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.3       ,\n",
       "            0.31538463, 0.33076924, 0.33846155, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4076923 , 0.43076923,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.6076923 , 0.61538464, 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7076923 ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.95   , 0.943  , 0.934  , 0.932  , 0.9316 , 0.931  ,\n",
       "            0.9277 , 0.9253 , 0.9243 , 0.922  , 0.921  , 0.9185 , 0.9165 ,\n",
       "            0.9155 , 0.914  , 0.913  , 0.9126 , 0.9097 , 0.9087 , 0.9053 ,\n",
       "            0.9    , 0.898  , 0.8975 , 0.894  , 0.889  , 0.884  , 0.8823 ,\n",
       "            0.881  , 0.8804 , 0.88   , 0.8784 , 0.8765 , 0.875  , 0.873  ,\n",
       "            0.8696 , 0.869  , 0.868  , 0.8677 , 0.865  , 0.8604 , 0.86   ,\n",
       "            0.8506 , 0.85   , 0.8496 , 0.8477 , 0.842  , 0.84   , 0.8223 ,\n",
       "            0.8174 , 0.8145 , 0.8066 , 0.8057 , 0.7974 , 0.7964 , 0.7905 ,\n",
       "            0.7866 , 0.786  , 0.7837 , 0.76   , 0.7573 , 0.743  , 0.7427 ,\n",
       "            0.7275 , 0.727  , 0.7114 , 0.711  , 0.707  , 0.6973 , 0.69   ,\n",
       "            0.687  , 0.675  , 0.671  , 0.67   , 0.6694 , 0.667  , 0.6587 ,\n",
       "            0.6577 , 0.654  , 0.6523 , 0.648  , 0.646  , 0.6377 , 0.6357 ,\n",
       "            0.633  , 0.6323 , 0.632  , 0.629  , 0.625  , 0.623  , 0.6226 ,\n",
       "            0.6216 , 0.6206 , 0.619  , 0.615  , 0.6147 , 0.6123 , 0.6074 ,\n",
       "            0.6064 , 0.6045 , 0.6025 , 0.5986 , 0.597  , 0.594  , 0.593  ,\n",
       "            0.5884 , 0.586  , 0.5806 , 0.579  , 0.5786 , 0.5776 , 0.576  ,\n",
       "            0.5713 , 0.571  , 0.5693 , 0.568  , 0.5674 , 0.565  , 0.5615 ,\n",
       "            0.5605 , 0.56   , 0.5576 , 0.554  , 0.5527 , 0.5522 , 0.5483 ,\n",
       "            0.5474 , 0.5435 , 0.5405 , 0.5366 , 0.532  , 0.5317 , 0.527  ,\n",
       "            0.52   , 0.5166 , 0.509  , 0.4978 , 0.4917 , 0.4907 , 0.4854 ,\n",
       "            0.479  , 0.4707 , 0.4646 , 0.4607 , 0.4602 , 0.4485 , 0.4355 ,\n",
       "            0.4294 , 0.4263 , 0.4233 , 0.421  , 0.415  , 0.413  , 0.4097 ,\n",
       "            0.4094 , 0.398  , 0.395  , 0.3928 , 0.388  , 0.383  , 0.382  ,\n",
       "            0.377  , 0.3652 , 0.3645 , 0.3623 , 0.3474 , 0.344  , 0.3425 ,\n",
       "            0.3325 , 0.3206 , 0.3157 , 0.3123 , 0.3047 , 0.2969 , 0.291  ,\n",
       "            0.2908 , 0.2808 , 0.2722 , 0.2441 , 0.2401 , 0.2367 , 0.213  ,\n",
       "            0.2039 , 0.199  , 0.1962 , 0.1953 , 0.181  , 0.1748 , 0.1663 ,\n",
       "            0.155  , 0.1542 , 0.1498 , 0.1466 , 0.1451 , 0.1445 , 0.1407 ,\n",
       "            0.1389 , 0.1359 , 0.1357 , 0.127  , 0.1229 , 0.1172 , 0.1138 ,\n",
       "            0.1078 , 0.0964 , 0.09467, 0.0935 , 0.0896 , 0.0734 , 0.06177,\n",
       "            0.05624, 0.0527 , 0.05185, 0.05005, 0.04526, 0.04108, 0.03812,\n",
       "            0.0326 , 0.02992, 0.02893, 0.02681, 0.0247 , 0.02141, 0.02077,\n",
       "            0.02037], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.425, dtype=float32),\n",
       "    'tpr': array(0.86153847, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.225     ,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.35833332, 0.375     ,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.525     , 0.525     ,\n",
       "            0.53333336, 0.55      , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.16923077, 0.17692308, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.33076924,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.5153846 ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6       , 0.6       , 0.6076923 ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.6923077 , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.7307692 , 0.73846155, 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.83076924, 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9595 , 0.9526 , 0.9443 , 0.943  , 0.9424 , 0.942  ,\n",
       "            0.939  , 0.9365 , 0.936  , 0.9336 , 0.933  , 0.9326 , 0.93   ,\n",
       "            0.9287 , 0.9272 , 0.9263 , 0.9253 , 0.9224 , 0.9214 , 0.9185 ,\n",
       "            0.915  , 0.9136 , 0.9116 , 0.911  , 0.9077 , 0.905  , 0.8984 ,\n",
       "            0.8975 , 0.897  , 0.8955 , 0.895  , 0.8945 , 0.893  , 0.892  ,\n",
       "            0.89   , 0.889  , 0.888  , 0.8857 , 0.885  , 0.8843 , 0.8833 ,\n",
       "            0.881  , 0.877  , 0.8765 , 0.8696 , 0.869  , 0.8687 , 0.867  ,\n",
       "            0.8667 , 0.8657 , 0.8643 , 0.858  , 0.8564 , 0.841  , 0.835  ,\n",
       "            0.833  , 0.8267 , 0.8223 , 0.8154 , 0.8105 , 0.807  , 0.8057 ,\n",
       "            0.802  , 0.782  , 0.7812 , 0.7627 , 0.7607 , 0.757  , 0.7437 ,\n",
       "            0.736  , 0.7334 , 0.727  , 0.7266 , 0.7236 , 0.7183 , 0.713  ,\n",
       "            0.6973 , 0.697  , 0.6963 , 0.695  , 0.692  , 0.6855 , 0.6836 ,\n",
       "            0.679  , 0.678  , 0.6753 , 0.672  , 0.6665 , 0.663  , 0.659  ,\n",
       "            0.6587 , 0.658  , 0.657  , 0.6562 , 0.6543 , 0.653  , 0.6514 ,\n",
       "            0.65   , 0.6494 , 0.648  , 0.645  , 0.642  , 0.64   , 0.638  ,\n",
       "            0.6377 , 0.6313 , 0.6304 , 0.628  , 0.6274 , 0.623  , 0.6226 ,\n",
       "            0.62   , 0.6187 , 0.618  , 0.616  , 0.613  , 0.607  , 0.6064 ,\n",
       "            0.604  , 0.6035 , 0.603  , 0.6006 , 0.6    , 0.5957 , 0.5933 ,\n",
       "            0.592  , 0.5913 , 0.589  , 0.5884 , 0.5874 , 0.581  , 0.579  ,\n",
       "            0.578  , 0.5776 , 0.576  , 0.5703 , 0.567  , 0.558  , 0.5547 ,\n",
       "            0.553  , 0.551  , 0.541  , 0.5376 , 0.5264 , 0.5225 , 0.519  ,\n",
       "            0.5083 , 0.4944 , 0.4895 , 0.4885 , 0.4817 , 0.4805 , 0.48   ,\n",
       "            0.4783 , 0.4658 , 0.4553 , 0.4387 , 0.4368 , 0.431  , 0.428  ,\n",
       "            0.4263 , 0.4197 , 0.4182 , 0.4155 , 0.414  , 0.4138 , 0.4126 ,\n",
       "            0.4104 , 0.406  , 0.3896 , 0.3826 , 0.367  , 0.3667 , 0.3613 ,\n",
       "            0.3555 , 0.3445 , 0.343  , 0.3335 , 0.3196 , 0.3147 , 0.2983 ,\n",
       "            0.2942 , 0.291  , 0.2742 , 0.2705 , 0.251  , 0.2338 , 0.2294 ,\n",
       "            0.2142 , 0.2004 , 0.1974 , 0.195  , 0.1913 , 0.1755 , 0.1711 ,\n",
       "            0.1688 , 0.1641 , 0.1482 , 0.1459 , 0.141  , 0.1404 , 0.1396 ,\n",
       "            0.1384 , 0.1335 , 0.1311 , 0.1288 , 0.1197 , 0.11554, 0.11066,\n",
       "            0.108  , 0.10266, 0.0903 , 0.0899 , 0.0871 , 0.0856 , 0.0667 ,\n",
       "            0.05698, 0.05243, 0.04904, 0.0478 , 0.04648, 0.04047, 0.03677,\n",
       "            0.03455, 0.02881, 0.02759, 0.02576, 0.02377, 0.0223 , 0.01869,\n",
       "            0.01843, 0.01826], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.425, dtype=float32),\n",
       "    'tpr': array(0.86923075, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.15      , 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.175     ,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.225     , 0.225     , 0.23333333,\n",
       "            0.24166666, 0.24166666, 0.24166666, 0.25      , 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.26666668, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.35      , 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.69166666, 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.14615385, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33846155, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.65384614, 0.65384614,\n",
       "            0.65384614, 0.6615385 , 0.6615385 , 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7846154 , 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.966  , 0.96   , 0.9526 , 0.951  , 0.948  , 0.946  ,\n",
       "            0.9453 , 0.944  , 0.9424 , 0.942  , 0.94   , 0.9385 , 0.937  ,\n",
       "            0.936  , 0.935  , 0.932  , 0.9287 , 0.9253 , 0.9224 , 0.922  ,\n",
       "            0.9185 , 0.916  , 0.91   , 0.9097 , 0.9087 , 0.907  , 0.9062 ,\n",
       "            0.9053 , 0.904  , 0.9033 , 0.901  , 0.8994 , 0.898  , 0.8975 ,\n",
       "            0.897  , 0.8965 , 0.896  , 0.895  , 0.8945 , 0.89   , 0.889  ,\n",
       "            0.882  , 0.8813 , 0.8804 , 0.8794 , 0.878  , 0.877  , 0.8765 ,\n",
       "            0.872  , 0.8706 , 0.854  , 0.849  , 0.846  , 0.84   , 0.837  ,\n",
       "            0.83   , 0.829  , 0.823  , 0.8213 , 0.8193 , 0.816  , 0.7954 ,\n",
       "            0.7944 , 0.7764 , 0.7744 , 0.7695 , 0.758  , 0.748  , 0.7466 ,\n",
       "            0.741  , 0.7397 , 0.737  , 0.731  , 0.7256 , 0.709  , 0.7085 ,\n",
       "            0.708  , 0.707  , 0.7036 , 0.6973 , 0.6953 , 0.691  , 0.6895 ,\n",
       "            0.6865 , 0.683  , 0.6797 , 0.6743 , 0.67   , 0.6694 , 0.669  ,\n",
       "            0.668  , 0.667  , 0.666  , 0.664  , 0.662  , 0.6606 , 0.66   ,\n",
       "            0.6587 , 0.6553 , 0.655  , 0.654  , 0.651  , 0.649  , 0.6484 ,\n",
       "            0.648  , 0.6416 , 0.638  , 0.637  , 0.633  , 0.6304 , 0.63   ,\n",
       "            0.6284 , 0.6265 , 0.622  , 0.6187 , 0.6177 , 0.6147 , 0.6133 ,\n",
       "            0.613  , 0.61   , 0.6084 , 0.6025 , 0.602  , 0.601  , 0.6006 ,\n",
       "            0.599  , 0.598  , 0.591  , 0.5903 , 0.5864 , 0.5854 , 0.582  ,\n",
       "            0.579  , 0.5786 , 0.5664 , 0.5645 , 0.5615 , 0.561  , 0.5605 ,\n",
       "            0.5503 , 0.546  , 0.54   , 0.5366 , 0.5225 , 0.513  , 0.5005 ,\n",
       "            0.496  , 0.4902 , 0.488  , 0.487  , 0.4792 , 0.4717 , 0.467  ,\n",
       "            0.4624 , 0.4497 , 0.4448 , 0.4346 , 0.4297 , 0.425  , 0.4233 ,\n",
       "            0.4211 , 0.4202 , 0.4185 , 0.4177 , 0.4165 , 0.4006 , 0.3906 ,\n",
       "            0.3787 , 0.375  , 0.3684 , 0.3657 , 0.363  , 0.3523 , 0.3416 ,\n",
       "            0.3398 , 0.3245 , 0.3088 , 0.2979 , 0.2864 , 0.285  , 0.2656 ,\n",
       "            0.2637 , 0.2502 , 0.2249 , 0.2205 , 0.2101 , 0.1937 , 0.1927 ,\n",
       "            0.1871 , 0.1836 , 0.1703 , 0.167  , 0.1666 , 0.1599 , 0.1393 ,\n",
       "            0.1365 , 0.1327 , 0.1313 , 0.13   , 0.1285 , 0.12244, 0.1201 ,\n",
       "            0.11145, 0.10724, 0.10284, 0.10016, 0.0959 , 0.08374, 0.0831 ,\n",
       "            0.0801 , 0.0799 , 0.0602 , 0.05185, 0.04803, 0.04486, 0.04337,\n",
       "            0.0424 , 0.03583, 0.03253, 0.03096, 0.02522, 0.02493, 0.02263,\n",
       "            0.02084, 0.01984, 0.0164 , 0.01616, 0.0159 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.425, dtype=float32),\n",
       "    'tpr': array(0.86923075, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15833333, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.225     , 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.375     , 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.425     , 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.07692308, 0.08461539, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.5153846 , 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.74615383, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9707 , 0.9653 , 0.959  , 0.9575 , 0.957  , 0.955  ,\n",
       "            0.952  , 0.9507 , 0.949  , 0.9473 , 0.9453 , 0.9443 , 0.9434 ,\n",
       "            0.9424 , 0.94   , 0.9395 , 0.9365 , 0.933  , 0.93   , 0.9297 ,\n",
       "            0.927  , 0.9243 , 0.919  , 0.9185 , 0.9175 , 0.916  , 0.9155 ,\n",
       "            0.915  , 0.914  , 0.9126 , 0.912  , 0.9097 , 0.9087 , 0.907  ,\n",
       "            0.9067 , 0.9062 , 0.906  , 0.9053 , 0.9043 , 0.9033 , 0.899  ,\n",
       "            0.8984 , 0.891  , 0.8906 , 0.89   , 0.889  , 0.8877 , 0.886  ,\n",
       "            0.8813 , 0.8804 , 0.864  , 0.8584 , 0.856  , 0.85   , 0.846  ,\n",
       "            0.839  , 0.8335 , 0.83   , 0.8296 , 0.825  , 0.805  , 0.8047 ,\n",
       "            0.786  , 0.7827 , 0.7783 , 0.7656 , 0.758  , 0.7563 , 0.749  ,\n",
       "            0.7485 , 0.7446 , 0.7397 , 0.7344 , 0.7173 , 0.717  , 0.7153 ,\n",
       "            0.7095 , 0.705  , 0.7036 , 0.699  , 0.6978 , 0.695  , 0.6914 ,\n",
       "            0.6885 , 0.682  , 0.6787 , 0.6777 , 0.677  , 0.6763 , 0.676  ,\n",
       "            0.6733 , 0.672  , 0.67   , 0.6685 , 0.6675 , 0.666  , 0.664  ,\n",
       "            0.6626 , 0.6616 , 0.659  , 0.6562 , 0.656  , 0.655  , 0.6484 ,\n",
       "            0.645  , 0.644  , 0.639  , 0.6387 , 0.636  , 0.635  , 0.6294 ,\n",
       "            0.6284 , 0.627  , 0.626  , 0.6255 , 0.622  , 0.6206 , 0.619  ,\n",
       "            0.616  , 0.615  , 0.6084 , 0.608  , 0.607  , 0.605  , 0.6045 ,\n",
       "            0.5986 , 0.598  , 0.596  , 0.592  , 0.591  , 0.589  , 0.5854 ,\n",
       "            0.584  , 0.5713 , 0.57   , 0.567  , 0.5664 , 0.562  , 0.555  ,\n",
       "            0.5547 , 0.551  , 0.547  , 0.544  , 0.5205 , 0.515  , 0.5063 ,\n",
       "            0.4941 , 0.4934 , 0.491  , 0.4895 , 0.4873 , 0.4758 , 0.4731 ,\n",
       "            0.465  , 0.4563 , 0.4465 , 0.4365 , 0.4302 , 0.4294 , 0.4287 ,\n",
       "            0.428  , 0.424  , 0.4233 , 0.4192 , 0.4182 , 0.4114 , 0.4104 ,\n",
       "            0.406  , 0.3938 , 0.378  , 0.3708 , 0.3706 , 0.3704 , 0.3567 ,\n",
       "            0.3552 , 0.3455 , 0.3313 , 0.3245 , 0.2996 , 0.2942 , 0.2761 ,\n",
       "            0.2756 , 0.2542 , 0.2534 , 0.2467 , 0.2134 , 0.2084 , 0.2043 ,\n",
       "            0.1882 , 0.1837 , 0.178  , 0.1744 , 0.1671 , 0.1663 , 0.1571 ,\n",
       "            0.1497 , 0.1321 , 0.1315 , 0.1293 , 0.1238 , 0.12286, 0.1223 ,\n",
       "            0.121  , 0.1124 , 0.11066, 0.1021 , 0.09827, 0.0945 , 0.0922 ,\n",
       "            0.0888 , 0.0775 , 0.07587, 0.0745 , 0.0724 , 0.0534 , 0.0469 ,\n",
       "            0.04376, 0.04077, 0.03912, 0.03854, 0.03125, 0.02844, 0.02759,\n",
       "            0.0225 , 0.02187, 0.01979, 0.01819, 0.01758, 0.01456, 0.0139 ,\n",
       "            0.01374], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.45, dtype=float32),\n",
       "    'tpr': array(0.9, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.10833333, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "            0.175     , 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.24166666, 0.25      ,\n",
       "            0.25      , 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.425     ,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.6666667 , 0.675     , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.16153847, 0.16923077, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.32307693, 0.33076924, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.6       , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.64615387, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6923077 , 0.6923077 , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7       , 0.7076923 , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7846154 , 0.7846154 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.86923075, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9775 , 0.9727 , 0.967  , 0.966  , 0.9653 , 0.9634 ,\n",
       "            0.961  , 0.96   , 0.9585 , 0.958  , 0.9565 , 0.955  , 0.954  ,\n",
       "            0.953  , 0.9526 , 0.952  , 0.95   , 0.9473 , 0.9463 , 0.9443 ,\n",
       "            0.9424 , 0.942  , 0.941  , 0.9385 , 0.938  , 0.9316 , 0.931  ,\n",
       "            0.9307 , 0.929  , 0.928  , 0.9277 , 0.9272 , 0.927  , 0.9253 ,\n",
       "            0.924  , 0.922  , 0.921  , 0.9204 , 0.92   , 0.9194 , 0.9185 ,\n",
       "            0.9175 , 0.9146 , 0.9136 , 0.9097 , 0.909  , 0.908  , 0.906  ,\n",
       "            0.9053 , 0.903  , 0.9014 , 0.896  , 0.8955 , 0.8823 , 0.8755 ,\n",
       "            0.874  , 0.8706 , 0.863  , 0.859  , 0.8584 , 0.8564 , 0.8496 ,\n",
       "            0.8477 , 0.8438 , 0.8325 , 0.8286 , 0.813  , 0.8086 , 0.8022 ,\n",
       "            0.7866 , 0.785  , 0.7847 , 0.7812 , 0.7744 , 0.7676 , 0.766  ,\n",
       "            0.7637 , 0.7524 , 0.7505 , 0.749  , 0.74   , 0.736  , 0.731  ,\n",
       "            0.73   , 0.7295 , 0.729  , 0.7236 , 0.7197 , 0.7188 , 0.7144 ,\n",
       "            0.714  , 0.7114 , 0.711  , 0.7104 , 0.7085 , 0.708  , 0.7075 ,\n",
       "            0.7065 , 0.7036 , 0.7007 , 0.7    , 0.6987 , 0.6978 , 0.697  ,\n",
       "            0.6895 , 0.6855 , 0.6826 , 0.6807 , 0.6797 , 0.6787 , 0.676  ,\n",
       "            0.6743 , 0.673  , 0.6714 , 0.67   , 0.665  , 0.6646 , 0.661  ,\n",
       "            0.6606 , 0.66   , 0.6562 , 0.6514 , 0.649  , 0.6484 , 0.6475 ,\n",
       "            0.643  , 0.641  , 0.6406 , 0.64   , 0.6396 , 0.639  , 0.6367 ,\n",
       "            0.63   , 0.627  , 0.6245 , 0.623  , 0.6157 , 0.6025 , 0.602  ,\n",
       "            0.6006 , 0.597  , 0.5884 , 0.587  , 0.582  , 0.545  , 0.541  ,\n",
       "            0.536  , 0.529  , 0.524  , 0.5215 , 0.5137 , 0.509  , 0.5034 ,\n",
       "            0.5024 , 0.4995 , 0.4978 , 0.4895 , 0.477  , 0.474  , 0.4739 ,\n",
       "            0.468  , 0.4675 , 0.4668 , 0.4558 , 0.4456 , 0.445  , 0.4336 ,\n",
       "            0.4282 , 0.4277 , 0.422  , 0.412  , 0.4094 , 0.4033 , 0.395  ,\n",
       "            0.3818 , 0.3772 , 0.3638 , 0.3516 , 0.3376 , 0.3103 , 0.3037 ,\n",
       "            0.2815 , 0.277  , 0.2622 , 0.2573 , 0.252  , 0.2118 , 0.2113 ,\n",
       "            0.2053 , 0.1954 , 0.1859 , 0.1844 , 0.179  , 0.178  , 0.1746 ,\n",
       "            0.1556 , 0.1475 , 0.1357 , 0.132  , 0.126  , 0.12317, 0.1216 ,\n",
       "            0.12103, 0.1184 , 0.1082 , 0.10706, 0.09827, 0.094  , 0.0914 ,\n",
       "            0.0893 , 0.0868 , 0.07544, 0.0732 , 0.0725 , 0.0688 , 0.0495 ,\n",
       "            0.04428, 0.04193, 0.03897, 0.037  , 0.03683, 0.0286 , 0.02606,\n",
       "            0.02571, 0.02141, 0.01976, 0.01805, 0.01653, 0.0164 , 0.01363,\n",
       "            0.01248, 0.01243], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.45833334, dtype=float32),\n",
       "    'tpr': array(0.9230769, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.23333333, 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "            0.25      , 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.21538462,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.4846154 ,\n",
       "            0.4923077 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5923077 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.6615385 , 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6923077 , 0.6923077 , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7       , 0.7076923 , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.982   , 0.977   , 0.972   , 0.971   , 0.9707  ,\n",
       "            0.969   , 0.9673  , 0.967   , 0.966   , 0.9644  , 0.963   ,\n",
       "            0.962   , 0.9604  , 0.96    , 0.9595  , 0.959   , 0.9575  ,\n",
       "            0.957   , 0.9546  , 0.9517  , 0.95    , 0.9497  , 0.9487  ,\n",
       "            0.947   , 0.94    , 0.9395  , 0.9385  , 0.937   , 0.9365  ,\n",
       "            0.936   , 0.934   , 0.9336  , 0.9316  , 0.931   , 0.9307  ,\n",
       "            0.93    , 0.9297  , 0.929   , 0.9287  , 0.928   , 0.927   ,\n",
       "            0.9253  , 0.9233  , 0.922   , 0.921   , 0.92    , 0.9175  ,\n",
       "            0.9146  , 0.9136  , 0.912   , 0.906   , 0.9053  , 0.895   ,\n",
       "            0.8867  , 0.8843  , 0.875   , 0.874   , 0.8716  , 0.868   ,\n",
       "            0.864   , 0.8594  , 0.856   , 0.8506  , 0.844   , 0.8354  ,\n",
       "            0.8237  , 0.8154  , 0.809   , 0.8057  , 0.7983  , 0.797   ,\n",
       "            0.7866  , 0.7773  , 0.776   , 0.773   , 0.77    , 0.7637  ,\n",
       "            0.7573  , 0.756   , 0.752   , 0.7515  , 0.747   , 0.7446  ,\n",
       "            0.7417  , 0.7383  , 0.737   , 0.7363  , 0.736   , 0.7354  ,\n",
       "            0.734   , 0.732   , 0.7285  , 0.728   , 0.727   , 0.7246  ,\n",
       "            0.7217  , 0.7207  , 0.7188  , 0.714   , 0.7114  , 0.7085  ,\n",
       "            0.706   , 0.705   , 0.7036  , 0.7007  , 0.6987  , 0.6963  ,\n",
       "            0.696   , 0.6953  , 0.6943  , 0.692   , 0.6904  , 0.6875  ,\n",
       "            0.686   , 0.6846  , 0.683   , 0.6753  , 0.674   , 0.67    ,\n",
       "            0.668   , 0.6675  , 0.6665  , 0.6646  , 0.6636  , 0.6626  ,\n",
       "            0.6606  , 0.66    , 0.6533  , 0.649   , 0.6475  , 0.6377  ,\n",
       "            0.6255  , 0.624   , 0.6235  , 0.6187  , 0.615   , 0.614   ,\n",
       "            0.6094  , 0.609   , 0.604   , 0.594   , 0.569   , 0.5566  ,\n",
       "            0.55    , 0.544   , 0.5405  , 0.5396  , 0.527   , 0.52    ,\n",
       "            0.5176  , 0.5156  , 0.5107  , 0.504   , 0.502   , 0.4956  ,\n",
       "            0.4954  , 0.4932  , 0.4905  , 0.4868  , 0.476   , 0.4712  ,\n",
       "            0.4617  , 0.45    , 0.4355  , 0.435   , 0.4338  , 0.4282  ,\n",
       "            0.4263  , 0.4255  , 0.4243  , 0.4204  , 0.406   , 0.3772  ,\n",
       "            0.369   , 0.3655  , 0.3376  , 0.3196  , 0.3025  , 0.2815  ,\n",
       "            0.2734  , 0.2712  , 0.2556  , 0.2456  , 0.2153  , 0.2056  ,\n",
       "            0.1996  , 0.199   , 0.1987  , 0.1864  , 0.1826  , 0.1755  ,\n",
       "            0.1721  , 0.152   , 0.143   , 0.1376  , 0.1302  , 0.1223  ,\n",
       "            0.12103 , 0.118   , 0.1178  , 0.1144  , 0.1025  , 0.1021  ,\n",
       "            0.0933  , 0.089   , 0.0873  , 0.0856  , 0.08374 , 0.0729  ,\n",
       "            0.07135 , 0.06866 , 0.06476 , 0.04526 , 0.04163 , 0.04    ,\n",
       "            0.0371  , 0.03506 , 0.03482 , 0.02596 , 0.02396 , 0.02377 ,\n",
       "            0.02034 , 0.01785 , 0.01646 , 0.01525 , 0.015015, 0.01277 ,\n",
       "            0.011246], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.48333332, dtype=float32),\n",
       "    'tpr': array(0.93846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.09166667, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.21666667, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25      , 0.25      ,\n",
       "            0.25      , 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06923077, 0.07692308, 0.08461539,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.2769231 , 0.2923077 , 0.32307693,\n",
       "            0.33076924, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.44615385, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7       , 0.7       , 0.7076923 , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.7153846 , 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.86923075, 0.8769231 ,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.985   , 0.981   , 0.9766  , 0.9756  , 0.975   ,\n",
       "            0.974   , 0.972   , 0.9717  , 0.9707  , 0.9697  , 0.9683  ,\n",
       "            0.9673  , 0.9663  , 0.966   , 0.9653  , 0.965   , 0.9634  ,\n",
       "            0.9614  , 0.961   , 0.958   , 0.957   , 0.9565  , 0.9556  ,\n",
       "            0.9546  , 0.9536  , 0.9478  , 0.9473  , 0.947   , 0.9463  ,\n",
       "            0.945   , 0.9443  , 0.944   , 0.942   , 0.9395  , 0.939   ,\n",
       "            0.9375  , 0.937   , 0.9365  , 0.9355  , 0.934   , 0.932   ,\n",
       "            0.931   , 0.93    , 0.9272  , 0.924   , 0.923   , 0.9214  ,\n",
       "            0.915   , 0.9062  , 0.8975  , 0.897   , 0.896   , 0.889   ,\n",
       "            0.8843  , 0.8833  , 0.8794  , 0.8765  , 0.8706  , 0.8677  ,\n",
       "            0.866   , 0.859   , 0.8535  , 0.838   , 0.8286  , 0.8276  ,\n",
       "            0.8228  , 0.816   , 0.814   , 0.8086  , 0.8057  , 0.796   ,\n",
       "            0.7925  , 0.7896  , 0.7886  , 0.7876  , 0.7866  , 0.7837  ,\n",
       "            0.7773  , 0.777   , 0.7715  , 0.771   , 0.7695  , 0.769   ,\n",
       "            0.7646  , 0.76    , 0.7583  , 0.758   , 0.7554  , 0.755   ,\n",
       "            0.7544  , 0.7534  , 0.752   , 0.7505  , 0.7485  , 0.746   ,\n",
       "            0.745   , 0.741   , 0.74    , 0.738   , 0.7334  , 0.7314  ,\n",
       "            0.7256  , 0.725   , 0.7236  , 0.723   , 0.7188  , 0.7173  ,\n",
       "            0.7153  , 0.715   , 0.7144  , 0.7134  , 0.712   , 0.7095  ,\n",
       "            0.7075  , 0.7056  , 0.7036  , 0.6978  , 0.6963  , 0.6924  ,\n",
       "            0.691   , 0.6885  , 0.687   , 0.6846  , 0.684   , 0.683   ,\n",
       "            0.68    , 0.675   , 0.6724  , 0.6714  , 0.6704  , 0.6665  ,\n",
       "            0.656   , 0.6445  , 0.643   , 0.6406  , 0.6377  , 0.636   ,\n",
       "            0.6274  , 0.627   , 0.622   , 0.6064  , 0.592   , 0.5723  ,\n",
       "            0.5703  , 0.5645  , 0.563   , 0.559   , 0.553   , 0.5513  ,\n",
       "            0.537   , 0.5366  , 0.532   , 0.5293  , 0.523   , 0.5186  ,\n",
       "            0.5176  , 0.513   , 0.505   , 0.501   , 0.496   , 0.495   ,\n",
       "            0.477   , 0.4707  , 0.459   , 0.4546  , 0.444   , 0.4434  ,\n",
       "            0.437   , 0.43    , 0.4287  , 0.4285  , 0.4265  , 0.3848  ,\n",
       "            0.3765  , 0.3665  , 0.337   , 0.3274  , 0.2998  , 0.2803  ,\n",
       "            0.2783  , 0.2686  , 0.253   , 0.2383  , 0.2167  , 0.211   ,\n",
       "            0.2004  , 0.1987  , 0.1915  , 0.1909  , 0.1787  , 0.1711  ,\n",
       "            0.1678  , 0.1466  , 0.1373  , 0.137   , 0.1266  , 0.1193  ,\n",
       "            0.11475 , 0.1128  , 0.10895 , 0.096   , 0.0957  , 0.0874  ,\n",
       "            0.083   , 0.082   , 0.0805  , 0.07935 , 0.06903 , 0.06793 ,\n",
       "            0.06396 , 0.05988 , 0.04062 , 0.03824 , 0.03726 , 0.03442 ,\n",
       "            0.03253 , 0.03198 , 0.02303 , 0.0217  , 0.02116 , 0.01877 ,\n",
       "            0.01572 , 0.01456 , 0.013794, 0.013275, 0.0116  , 0.00986 ,\n",
       "            0.00978 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.93846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.1       , 0.10833333,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.175     , 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.275     , 0.28333333, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.31666666, 0.325     , 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.16153847, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.24615385, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.32307693, 0.33076924,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4923077 , 0.4923077 , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.6230769 , 0.63076925, 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.65384614, 0.65384614, 0.65384614,\n",
       "            0.66923076, 0.6769231 , 0.6769231 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.7153846 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9873  , 0.984   , 0.9795  , 0.979   , 0.9785  ,\n",
       "            0.9775  , 0.976   , 0.9756  , 0.975   , 0.9736  , 0.9727  ,\n",
       "            0.971   , 0.97    , 0.9697  , 0.969   , 0.968   , 0.9663  ,\n",
       "            0.966   , 0.9634  , 0.9624  , 0.9614  , 0.961   , 0.96    ,\n",
       "            0.959   , 0.9536  , 0.953   , 0.952   , 0.95    , 0.9497  ,\n",
       "            0.948   , 0.9478  , 0.9463  , 0.946   , 0.9453  , 0.944   ,\n",
       "            0.9434  , 0.943   , 0.942   , 0.941   , 0.9395  , 0.9385  ,\n",
       "            0.937   , 0.934   , 0.9307  , 0.9297  , 0.9287  , 0.9224  ,\n",
       "            0.922   , 0.9146  , 0.9062  , 0.9053  , 0.899   , 0.8926  ,\n",
       "            0.888   , 0.886   , 0.879   , 0.8774  , 0.8765  , 0.869   ,\n",
       "            0.8667  , 0.8486  , 0.844   , 0.8374  , 0.835   , 0.8296  ,\n",
       "            0.825   , 0.8184  , 0.818   , 0.8105  , 0.806   , 0.8027  ,\n",
       "            0.802   , 0.7983  , 0.796   , 0.7954  , 0.7905  , 0.789   ,\n",
       "            0.788   , 0.785   , 0.784   , 0.78    , 0.7783  , 0.776   ,\n",
       "            0.775   , 0.772   , 0.7705  , 0.77    , 0.769   , 0.7686  ,\n",
       "            0.7656  , 0.7637  , 0.7627  , 0.7593  , 0.756   , 0.755   ,\n",
       "            0.752   , 0.751   , 0.7495  , 0.7466  , 0.7456  , 0.7417  ,\n",
       "            0.7393  , 0.737   , 0.735   , 0.733   , 0.732   , 0.731   ,\n",
       "            0.7305  , 0.729   , 0.7285  , 0.7266  , 0.725   , 0.7188  ,\n",
       "            0.7173  , 0.7153  , 0.7114  , 0.7075  , 0.7056  , 0.7046  ,\n",
       "            0.7036  , 0.7007  , 0.7     , 0.694   , 0.6934  , 0.6895  ,\n",
       "            0.689   , 0.683   , 0.6826  , 0.6797  , 0.6714  , 0.665   ,\n",
       "            0.661   , 0.66    , 0.6553  , 0.6504  , 0.6436  , 0.643   ,\n",
       "            0.6377  , 0.6157  , 0.6133  , 0.59    , 0.5874  , 0.584   ,\n",
       "            0.582   , 0.5776  , 0.5767  , 0.559   , 0.556   , 0.5557  ,\n",
       "            0.5547  , 0.5537  , 0.5415  , 0.535   , 0.531   , 0.5273  ,\n",
       "            0.5234  , 0.523   , 0.521   , 0.5146  , 0.504   , 0.493   ,\n",
       "            0.4922  , 0.4836  , 0.476   , 0.4692  , 0.4634  , 0.453   ,\n",
       "            0.437   , 0.432   , 0.4297  , 0.423   , 0.4019  , 0.3743  ,\n",
       "            0.3657  , 0.3354  , 0.3347  , 0.2964  , 0.2866  , 0.278   ,\n",
       "            0.2627  , 0.2493  , 0.2301  , 0.2251  , 0.2189  , 0.2028  ,\n",
       "            0.1982  , 0.1912  , 0.1827  , 0.1752  , 0.1671  , 0.1638  ,\n",
       "            0.1415  , 0.1381  , 0.1312  , 0.12366 , 0.1172  , 0.10876 ,\n",
       "            0.1086  , 0.108   , 0.10376 , 0.0903  , 0.0895  , 0.0818  ,\n",
       "            0.0772  , 0.0771  , 0.076   , 0.07556 , 0.06573 , 0.06537 ,\n",
       "            0.05966 , 0.05542 , 0.0365  , 0.0354  , 0.035   , 0.0323  ,\n",
       "            0.0305  , 0.02959 , 0.0205  , 0.01984 , 0.01894 , 0.01752 ,\n",
       "            0.0139  , 0.01302 , 0.01257 , 0.011826, 0.01061 , 0.00871 ,\n",
       "            0.00861 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5083333, dtype=float32),\n",
       "    'tpr': array(0.95384616, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.1       , 0.1       , 0.10833333,\n",
       "            0.125     , 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.275     , 0.275     , 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06923077, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.23076923, 0.23846154, 0.24615385, 0.26923078,\n",
       "            0.2769231 , 0.2923077 , 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.35384616, 0.36923078, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.5307692 , 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.65384614, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6769231 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.7307692 ,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.989   , 0.9854  , 0.9814  , 0.981   , 0.9805  ,\n",
       "            0.98    , 0.978   , 0.9775  , 0.976   , 0.9756  , 0.9746  ,\n",
       "            0.9736  , 0.9727  , 0.972   , 0.9717  , 0.9707  , 0.97    ,\n",
       "            0.9688  , 0.9683  , 0.9663  , 0.965   , 0.9644  , 0.9634  ,\n",
       "            0.9624  , 0.962   , 0.9565  , 0.956   , 0.955   , 0.9536  ,\n",
       "            0.953   , 0.9517  , 0.949   , 0.9487  , 0.9478  , 0.9473  ,\n",
       "            0.9463  , 0.9443  , 0.943   , 0.942   , 0.941   , 0.938   ,\n",
       "            0.935   , 0.9336  , 0.9326  , 0.9272  , 0.927   , 0.9185  ,\n",
       "            0.9106  , 0.9097  , 0.904   , 0.898   , 0.8975  , 0.893   ,\n",
       "            0.891   , 0.8843  , 0.8823  , 0.882   , 0.8755  , 0.8745  ,\n",
       "            0.856   , 0.8545  , 0.843   , 0.8403  , 0.837   , 0.831   ,\n",
       "            0.8247  , 0.8237  , 0.8203  , 0.8135  , 0.811   , 0.809   ,\n",
       "            0.8086  , 0.808   , 0.8066  , 0.804   , 0.8003  , 0.799   ,\n",
       "            0.797   , 0.792   , 0.791   , 0.7905  , 0.787   , 0.7866  ,\n",
       "            0.7847  , 0.7817  , 0.7793  , 0.779   , 0.777   , 0.7754  ,\n",
       "            0.774   , 0.771   , 0.768   , 0.7676  , 0.7666  , 0.7656  ,\n",
       "            0.7617  , 0.7607  , 0.758   , 0.753   , 0.7524  , 0.751   ,\n",
       "            0.7495  , 0.7476  , 0.747   , 0.7446  , 0.744   , 0.743   ,\n",
       "            0.742   , 0.741   , 0.737   , 0.7363  , 0.735   , 0.734   ,\n",
       "            0.732   , 0.73    , 0.722   , 0.721   , 0.7183  , 0.7144  ,\n",
       "            0.714   , 0.7124  , 0.708   , 0.7026  , 0.7007  , 0.697   ,\n",
       "            0.696   , 0.689   , 0.683   , 0.6826  , 0.682   , 0.6763  ,\n",
       "            0.6753  , 0.6655  , 0.661   , 0.657   , 0.6567  , 0.651   ,\n",
       "            0.634   , 0.6196  , 0.6104  , 0.6084  , 0.6035  , 0.5996  ,\n",
       "            0.5933  , 0.5903  , 0.589   , 0.5825  , 0.5737  , 0.568   ,\n",
       "            0.5664  , 0.558   , 0.556   , 0.5474  , 0.5464  , 0.5405  ,\n",
       "            0.5337  , 0.527   , 0.5234  , 0.5146  , 0.5107  , 0.5073  ,\n",
       "            0.503   , 0.499   , 0.4963  , 0.4846  , 0.4797  , 0.4333  ,\n",
       "            0.4297  , 0.427   , 0.42    , 0.417   , 0.3696  , 0.362   ,\n",
       "            0.3435  , 0.3303  , 0.2954  , 0.291   , 0.274   , 0.2556  ,\n",
       "            0.2444  , 0.243   , 0.2216  , 0.2211  , 0.2068  , 0.2053  ,\n",
       "            0.1836  , 0.1747  , 0.1708  , 0.1625  , 0.1593  , 0.1396  ,\n",
       "            0.1361  , 0.1252  , 0.12085 , 0.11536 , 0.1045  , 0.1032  ,\n",
       "            0.103   , 0.09875 , 0.0848  , 0.0836  , 0.07666 , 0.07263 ,\n",
       "            0.07227 , 0.0721  , 0.0717  , 0.0631  , 0.0628  , 0.05582 ,\n",
       "            0.05136 , 0.03308 , 0.03302 , 0.03284 , 0.03038 , 0.0287  ,\n",
       "            0.02753 , 0.0184  , 0.01823 , 0.01704 , 0.01659 , 0.01238 ,\n",
       "            0.011734, 0.0116  , 0.01061 , 0.00986 , 0.007786, 0.007607],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5083333, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.09166667, 0.09166667,\n",
       "            0.1       , 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25      , 0.25      , 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.49166667, 0.49166667, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.05384615, 0.06153846, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23846154, 0.24615385, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.30769232, 0.32307693, 0.33846155, 0.34615386,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.4846154 ,\n",
       "            0.4923077 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.6615385 , 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.7307692 , 0.7307692 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.86923075, 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9907  , 0.988   , 0.985   , 0.9844  , 0.984   ,\n",
       "            0.982   , 0.9814  , 0.98    , 0.9795  , 0.979   , 0.978   ,\n",
       "            0.977   , 0.9766  , 0.976   , 0.9756  , 0.9746  , 0.973   ,\n",
       "            0.972   , 0.97    , 0.9697  , 0.9688  , 0.968   , 0.9673  ,\n",
       "            0.963   , 0.9624  , 0.9614  , 0.96    , 0.9595  , 0.959   ,\n",
       "            0.958   , 0.956   , 0.9556  , 0.955   , 0.954   , 0.9536  ,\n",
       "            0.953   , 0.951   , 0.9507  , 0.9497  , 0.9487  , 0.9478  ,\n",
       "            0.9453  , 0.9434  , 0.9414  , 0.9404  , 0.9365  , 0.936   ,\n",
       "            0.9272  , 0.9194  , 0.9185  , 0.913   , 0.909   , 0.9077  ,\n",
       "            0.904   , 0.9014  , 0.8955  , 0.8926  , 0.8867  , 0.8853  ,\n",
       "            0.8687  , 0.8657  , 0.855   , 0.852   , 0.8486  , 0.843   ,\n",
       "            0.837   , 0.8335  , 0.826   , 0.8257  , 0.8223  , 0.822   ,\n",
       "            0.821   , 0.82    , 0.816   , 0.814   , 0.8135  , 0.8096  ,\n",
       "            0.806   , 0.8047  , 0.8037  , 0.803   , 0.8027  , 0.802   ,\n",
       "            0.8013  , 0.7974  , 0.7954  , 0.7935  , 0.793   , 0.792   ,\n",
       "            0.7886  , 0.788   , 0.787   , 0.7856  , 0.781   , 0.7803  ,\n",
       "            0.7783  , 0.7744  , 0.7705  , 0.7666  , 0.7656  , 0.765   ,\n",
       "            0.7646  , 0.763   , 0.7627  , 0.761   , 0.76    , 0.7593  ,\n",
       "            0.7583  , 0.756   , 0.755   , 0.7534  , 0.7515  , 0.75    ,\n",
       "            0.7476  , 0.744   , 0.7393  , 0.737   , 0.734   , 0.732   ,\n",
       "            0.7295  , 0.729   , 0.7275  , 0.725   , 0.718   , 0.7134  ,\n",
       "            0.712   , 0.7104  , 0.709   , 0.7007  , 0.6963  , 0.695   ,\n",
       "            0.6924  , 0.69    , 0.678   , 0.6743  , 0.672   , 0.671   ,\n",
       "            0.665   , 0.6523  , 0.631   , 0.6304  , 0.6255  , 0.6157  ,\n",
       "            0.613   , 0.609   , 0.605   , 0.601   , 0.591   , 0.5874  ,\n",
       "            0.5825  , 0.5776  , 0.569   , 0.5645  , 0.562   , 0.556   ,\n",
       "            0.551   , 0.5337  , 0.5327  , 0.53    , 0.5215  , 0.5186  ,\n",
       "            0.518   , 0.5093  , 0.502   , 0.5015  , 0.4368  , 0.4348  ,\n",
       "            0.433   , 0.4302  , 0.4185  , 0.3708  , 0.3633  , 0.351   ,\n",
       "            0.3303  , 0.3027  , 0.2898  , 0.2725  , 0.2556  , 0.2522  ,\n",
       "            0.2418  , 0.223   , 0.2177  , 0.2125  , 0.2074  , 0.1791  ,\n",
       "            0.1703  , 0.1674  , 0.1588  , 0.1556  , 0.1401  , 0.1317  ,\n",
       "            0.12067 , 0.118   , 0.11316 , 0.1009  , 0.0991  , 0.09845 ,\n",
       "            0.0945  , 0.0805  , 0.07935 , 0.0724  , 0.0689  , 0.0688  ,\n",
       "            0.06805 , 0.06793 , 0.06064 , 0.05988 , 0.05234 , 0.04794 ,\n",
       "            0.03108 , 0.0305  , 0.03044 , 0.02855 , 0.02692 , 0.02556 ,\n",
       "            0.01672 , 0.01659 , 0.01549 , 0.015366, 0.01107 , 0.01065 ,\n",
       "            0.01057 , 0.00956 , 0.009056, 0.006958, 0.00677 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5083333, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.09166667, 0.09166667,\n",
       "            0.1       , 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.15833333, 0.175     , 0.18333334,\n",
       "            0.2       , 0.2       , 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.23333333, 0.25      , 0.25      , 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.49166667, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.05384615,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.6615385 , 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.72307694, 0.72307694,\n",
       "            0.7307692 , 0.7307692 , 0.7307692 , 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9927  , 0.99    , 0.9873  , 0.987   , 0.985   ,\n",
       "            0.9844  , 0.9834  , 0.983   , 0.9824  , 0.9814  , 0.981   ,\n",
       "            0.9805  , 0.98    , 0.9795  , 0.979   , 0.9775  , 0.9766  ,\n",
       "            0.9746  , 0.974   , 0.9736  , 0.9727  , 0.972   , 0.9688  ,\n",
       "            0.968   , 0.967   , 0.966   , 0.9653  , 0.965   , 0.964   ,\n",
       "            0.962   , 0.9614  , 0.9604  , 0.96    , 0.9595  , 0.958   ,\n",
       "            0.9575  , 0.9565  , 0.9556  , 0.9546  , 0.952   , 0.951   ,\n",
       "            0.9487  , 0.9478  , 0.945   , 0.9443  , 0.936   , 0.929   ,\n",
       "            0.9287  , 0.9277  , 0.923   , 0.9194  , 0.9175  , 0.914   ,\n",
       "            0.9116  , 0.9067  , 0.904   , 0.9033  , 0.898   , 0.8965  ,\n",
       "            0.8813  , 0.8784  , 0.8677  , 0.865   , 0.862   , 0.856   ,\n",
       "            0.8506  , 0.847   , 0.841   , 0.84    , 0.8384  , 0.8354  ,\n",
       "            0.835   , 0.8345  , 0.832   , 0.8286  , 0.8276  , 0.8237  ,\n",
       "            0.8213  , 0.8193  , 0.819   , 0.818   , 0.8174  , 0.817   ,\n",
       "            0.816   , 0.812   , 0.8096  , 0.8086  , 0.807   , 0.8047  ,\n",
       "            0.803   , 0.802   , 0.7954  , 0.795   , 0.793   , 0.7896  ,\n",
       "            0.7856  , 0.783   , 0.7817  , 0.7803  , 0.78    , 0.7793  ,\n",
       "            0.7783  , 0.775   , 0.7744  , 0.771   , 0.7705  , 0.77    ,\n",
       "            0.768   , 0.7676  , 0.7646  , 0.763   , 0.759   , 0.7563  ,\n",
       "            0.7534  , 0.7495  , 0.747   , 0.7466  , 0.7456  , 0.745   ,\n",
       "            0.742   , 0.7334  , 0.73    , 0.7285  , 0.7275  , 0.726   ,\n",
       "            0.719   , 0.7114  , 0.709   , 0.7085  , 0.706   , 0.6934  ,\n",
       "            0.689   , 0.6875  , 0.6865  , 0.6807  , 0.672   , 0.652   ,\n",
       "            0.648   , 0.645   , 0.643   , 0.638   , 0.634   , 0.629   ,\n",
       "            0.627   , 0.616   , 0.6094  , 0.609   , 0.5996  , 0.599   ,\n",
       "            0.5913  , 0.5796  , 0.576   , 0.5747  , 0.57    , 0.557   ,\n",
       "            0.5547  , 0.5444  , 0.5425  , 0.5405  , 0.5396  , 0.538   ,\n",
       "            0.525   , 0.523   , 0.519   , 0.4531  , 0.4434  , 0.44    ,\n",
       "            0.437   , 0.4229  , 0.3752  , 0.3677  , 0.3616  , 0.3335  ,\n",
       "            0.313   , 0.2915  , 0.274   , 0.2717  , 0.2517  , 0.2421  ,\n",
       "            0.2274  , 0.2211  , 0.2161  , 0.2118  , 0.1765  , 0.1672  ,\n",
       "            0.1663  , 0.1567  , 0.154   , 0.1426  , 0.1292  , 0.11755 ,\n",
       "            0.1166  , 0.1124  , 0.09845 , 0.09656 , 0.09515 , 0.09174 ,\n",
       "            0.0774  , 0.076   , 0.0694  , 0.0667  , 0.066   , 0.06525 ,\n",
       "            0.0649  , 0.0591  , 0.05792 , 0.04977 , 0.04535 , 0.02965 ,\n",
       "            0.02876 , 0.02834 , 0.02718 , 0.02562 , 0.02414 , 0.0156  ,\n",
       "            0.01519 , 0.01473 , 0.014114, 0.010056, 0.009895, 0.009674,\n",
       "            0.00871 , 0.00848 , 0.006313, 0.006123], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5083333, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.21666667, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.25      , 0.25      , 0.25      , 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.05384615,\n",
       "            0.06923077, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.13076924, 0.13846155, 0.15384616, 0.16153847,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.33076924, 0.33846155, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.6615385 , 0.6615385 , 0.6615385 , 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7153846 , 0.72307694, 0.72307694, 0.7307692 ,\n",
       "            0.7307692 , 0.73846155, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.994   , 0.992   , 0.9897  , 0.9893  , 0.988   ,\n",
       "            0.9873  , 0.9863  , 0.986   , 0.9854  , 0.9844  , 0.984   ,\n",
       "            0.9834  , 0.983   , 0.9824  , 0.981   , 0.9785  , 0.978   ,\n",
       "            0.9775  , 0.977   , 0.9766  , 0.9736  , 0.9727  , 0.972   ,\n",
       "            0.9717  , 0.9707  , 0.97    , 0.9688  , 0.968   , 0.9673  ,\n",
       "            0.967   , 0.9663  , 0.966   , 0.9653  , 0.965   , 0.9634  ,\n",
       "            0.962   , 0.9614  , 0.9604  , 0.9585  , 0.9575  , 0.955   ,\n",
       "            0.954   , 0.9526  , 0.9517  , 0.9434  , 0.9375  , 0.9365  ,\n",
       "            0.936   , 0.931   , 0.929   , 0.9263  , 0.924   , 0.9204  ,\n",
       "            0.917   , 0.9136  , 0.909   , 0.9062  , 0.8945  , 0.889   ,\n",
       "            0.8794  , 0.877   , 0.8745  , 0.8677  , 0.8633  , 0.863   ,\n",
       "            0.8613  , 0.8564  , 0.8545  , 0.854   , 0.851   , 0.8496  ,\n",
       "            0.849   , 0.8486  , 0.848   , 0.843   , 0.841   , 0.8374  ,\n",
       "            0.8354  , 0.8335  , 0.833   , 0.832   , 0.8315  , 0.831   ,\n",
       "            0.8257  , 0.8247  , 0.8237  , 0.8228  , 0.822   , 0.817   ,\n",
       "            0.811   , 0.808   , 0.8066  , 0.805   , 0.8037  , 0.801   ,\n",
       "            0.8     , 0.798   , 0.797   , 0.7964  , 0.795   , 0.7925  ,\n",
       "            0.792   , 0.7896  , 0.7866  , 0.786   , 0.7847  , 0.779   ,\n",
       "            0.7773  , 0.775   , 0.7715  , 0.7676  , 0.7656  , 0.763   ,\n",
       "            0.7627  , 0.762   , 0.761   , 0.7583  , 0.7515  , 0.751   ,\n",
       "            0.745   , 0.7437  , 0.743   , 0.7397  , 0.7275  , 0.7266  ,\n",
       "            0.7236  , 0.7227  , 0.709   , 0.705   , 0.7046  , 0.7036  ,\n",
       "            0.6978  , 0.694   , 0.676   , 0.6733  , 0.666   , 0.6636  ,\n",
       "            0.658   , 0.656   , 0.6533  , 0.646   , 0.634   , 0.63    ,\n",
       "            0.6226  , 0.618   , 0.617   , 0.6     , 0.5957  , 0.5923  ,\n",
       "            0.5874  , 0.5835  , 0.579   , 0.5703  , 0.564   , 0.557   ,\n",
       "            0.555   , 0.5527  , 0.551   , 0.547   , 0.5293  , 0.4753  ,\n",
       "            0.4514  , 0.447   , 0.444   , 0.43    , 0.381   , 0.3752  ,\n",
       "            0.3728  , 0.3376  , 0.3271  , 0.2947  , 0.2942  , 0.2761  ,\n",
       "            0.2532  , 0.2434  , 0.2346  , 0.2338  , 0.2189  , 0.2173  ,\n",
       "            0.1764  , 0.1671  , 0.167   , 0.1562  , 0.1538  , 0.1475  ,\n",
       "            0.128   , 0.11694 , 0.11633 , 0.1138  , 0.0979  , 0.0955  ,\n",
       "            0.0935  , 0.0903  , 0.07574 , 0.07434 , 0.0677  , 0.066   ,\n",
       "            0.0644  , 0.06384 , 0.06323 , 0.0589  , 0.0572  , 0.0483  ,\n",
       "            0.04385 , 0.02908 , 0.02791 , 0.02711 , 0.02661 , 0.02513 ,\n",
       "            0.02342 , 0.015076, 0.01445 , 0.01439 , 0.01333 , 0.00956 ,\n",
       "            0.00945 , 0.00916 , 0.008286, 0.008255, 0.00596 , 0.005753],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.51666665, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.10833333,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.15833333, 0.15833333, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.26666668,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.35      , 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03846154, 0.05384615,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.13846155, 0.15384616, 0.16153847, 0.16153847, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.32307693, 0.33846155, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.4923077 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.6230769 , 0.6230769 , 0.6230769 , 0.63076925,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.6615385 , 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7       , 0.7       , 0.72307694, 0.7307692 , 0.7307692 ,\n",
       "            0.73846155, 0.73846155, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9956  , 0.9937  , 0.9917  , 0.991   , 0.99    ,\n",
       "            0.9897  , 0.989   , 0.9883  , 0.9873  , 0.987   , 0.9863  ,\n",
       "            0.9854  , 0.985   , 0.9844  , 0.9824  , 0.982   , 0.9814  ,\n",
       "            0.9805  , 0.978   , 0.9775  , 0.977   , 0.9766  , 0.9756  ,\n",
       "            0.975   , 0.974   , 0.973   , 0.9727  , 0.972   , 0.971   ,\n",
       "            0.9707  , 0.9697  , 0.969   , 0.9683  , 0.968   , 0.9653  ,\n",
       "            0.964   , 0.962   , 0.961   , 0.9595  , 0.9585  , 0.952   ,\n",
       "            0.946   , 0.9434  , 0.938   , 0.936   , 0.933   , 0.9316  ,\n",
       "            0.9277  , 0.927   , 0.9243  , 0.92    , 0.914   , 0.903   ,\n",
       "            0.8955  , 0.8945  , 0.892   , 0.8843  , 0.8833  , 0.8813  ,\n",
       "            0.88    , 0.8765  , 0.876   , 0.8755  , 0.8726  , 0.8706  ,\n",
       "            0.8696  , 0.8633  , 0.863   , 0.86    , 0.859   , 0.857   ,\n",
       "            0.8564  , 0.856   , 0.855   , 0.8545  , 0.854   , 0.851   ,\n",
       "            0.8506  , 0.85    , 0.849   , 0.8477  , 0.8423  , 0.841   ,\n",
       "            0.837   , 0.8315  , 0.83    , 0.8296  , 0.829   , 0.828   ,\n",
       "            0.826   , 0.8257  , 0.824   , 0.8237  , 0.8223  , 0.8213  ,\n",
       "            0.821   , 0.8193  , 0.8174  , 0.8164  , 0.8125  , 0.8076  ,\n",
       "            0.805   , 0.803   , 0.8027  , 0.8022  , 0.801   , 0.7964  ,\n",
       "            0.796   , 0.792   , 0.791   , 0.79    , 0.786   , 0.7856  ,\n",
       "            0.78    , 0.7744  , 0.7725  , 0.7705  , 0.757   , 0.7563  ,\n",
       "            0.7534  , 0.7417  , 0.7373  , 0.7344  , 0.734   , 0.7334  ,\n",
       "            0.7305  , 0.727   , 0.716   , 0.7153  , 0.712   , 0.7007  ,\n",
       "            0.698   , 0.686   , 0.679   , 0.6787  , 0.6763  , 0.6655  ,\n",
       "            0.663   , 0.6616  , 0.657   , 0.651   , 0.6353  , 0.6323  ,\n",
       "            0.6304  , 0.63    , 0.621   , 0.617   , 0.607   , 0.606   ,\n",
       "            0.6     , 0.592   , 0.589   , 0.5737  , 0.57    , 0.5464  ,\n",
       "            0.515   , 0.465   , 0.463   , 0.4597  , 0.4412  , 0.4014  ,\n",
       "            0.3923  , 0.3855  , 0.3538  , 0.3484  , 0.334   , 0.303   ,\n",
       "            0.2856  , 0.2588  , 0.2573  , 0.2502  , 0.2494  , 0.2338  ,\n",
       "            0.22    , 0.1782  , 0.1715  , 0.1681  , 0.1592  , 0.1575  ,\n",
       "            0.1571  , 0.13    , 0.1198  , 0.118   , 0.1172  , 0.0991  ,\n",
       "            0.0964  , 0.0935  , 0.0906  , 0.0752  , 0.0734  , 0.06696 ,\n",
       "            0.0662  , 0.0641  , 0.0635  , 0.06223 , 0.05975 , 0.0576  ,\n",
       "            0.0477  , 0.04288 , 0.02893 , 0.02727 , 0.02646 , 0.02591 ,\n",
       "            0.02493 , 0.02298 , 0.01462 , 0.01439 , 0.01359 , 0.01267 ,\n",
       "            0.0093  , 0.00888 , 0.00871 , 0.008095, 0.00784 , 0.00562 ,\n",
       "            0.005386], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.51666665, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.14166667, 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.375     , 0.375     , 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03846154, 0.05384615,\n",
       "            0.08461539, 0.09230769, 0.10769231, 0.12307692, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.2769231 , 0.2923077 ,\n",
       "            0.31538463, 0.33846155, 0.34615386, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.52307695, 0.52307695, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5769231 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.6230769 , 0.6230769 , 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.65384614, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.66923076, 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.72307694, 0.72307694, 0.72307694, 0.72307694,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.77692306, 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.86923075, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9966  , 0.995   , 0.993   , 0.9927  , 0.9917  ,\n",
       "            0.9907  , 0.99    , 0.9893  , 0.989   , 0.9883  , 0.988   ,\n",
       "            0.987   , 0.9863  , 0.9854  , 0.985   , 0.9844  , 0.984   ,\n",
       "            0.9834  , 0.981   , 0.9805  , 0.98    , 0.979   , 0.9785  ,\n",
       "            0.978   , 0.9766  , 0.976   , 0.975   , 0.9746  , 0.974   ,\n",
       "            0.9736  , 0.973   , 0.9727  , 0.972   , 0.9697  , 0.968   ,\n",
       "            0.9663  , 0.966   , 0.9634  , 0.9624  , 0.958   , 0.9526  ,\n",
       "            0.952   , 0.951   , 0.9507  , 0.9434  , 0.943   , 0.939   ,\n",
       "            0.938   , 0.9365  , 0.933   , 0.9307  , 0.929   , 0.9277  ,\n",
       "            0.9116  , 0.908   , 0.906   , 0.9004  , 0.8984  , 0.898   ,\n",
       "            0.896   , 0.895   , 0.8945  , 0.894   , 0.8896  , 0.888   ,\n",
       "            0.884   , 0.883   , 0.882   , 0.8774  , 0.875   , 0.874   ,\n",
       "            0.872   , 0.871   , 0.869   , 0.868   , 0.867   , 0.8647  ,\n",
       "            0.864   , 0.8633  , 0.863   , 0.858   , 0.856   , 0.855   ,\n",
       "            0.8506  , 0.85    , 0.8477  , 0.847   , 0.8447  , 0.8438  ,\n",
       "            0.8433  , 0.843   , 0.8423  , 0.8413  , 0.8403  , 0.84    ,\n",
       "            0.8384  , 0.837   , 0.8345  , 0.8315  , 0.8276  , 0.8228  ,\n",
       "            0.8223  , 0.822   , 0.8193  , 0.819   , 0.8174  , 0.815   ,\n",
       "            0.8135  , 0.812   , 0.8105  , 0.8096  , 0.805   , 0.802   ,\n",
       "            0.7964  , 0.796   , 0.7944  , 0.7886  , 0.78    , 0.7783  ,\n",
       "            0.776   , 0.758   , 0.7573  , 0.757   , 0.7563  , 0.7544  ,\n",
       "            0.7524  , 0.75    , 0.7476  , 0.747   , 0.7456  , 0.735   ,\n",
       "            0.724   , 0.711   , 0.709   , 0.703   , 0.6963  , 0.6943  ,\n",
       "            0.693   , 0.6924  , 0.676   , 0.6753  , 0.666   , 0.662   ,\n",
       "            0.6606  , 0.66    , 0.6543  , 0.654   , 0.641   , 0.6367  ,\n",
       "            0.623   , 0.6187  , 0.6157  , 0.5835  , 0.58    , 0.5557  ,\n",
       "            0.548   , 0.4712  , 0.471   , 0.4673  , 0.4436  , 0.4229  ,\n",
       "            0.395   , 0.3914  , 0.3772  , 0.3723  , 0.3525  , 0.3057  ,\n",
       "            0.2898  , 0.2795  , 0.2622  , 0.2585  , 0.253   , 0.2466  ,\n",
       "            0.2173  , 0.1761  , 0.1743  , 0.1669  , 0.1649  , 0.16    ,\n",
       "            0.1581  , 0.13    , 0.1222  , 0.11615 , 0.0995  , 0.0964  ,\n",
       "            0.09174 , 0.0898  , 0.0733  , 0.0709  , 0.06635 , 0.065   ,\n",
       "            0.0629  , 0.06256 , 0.06097 , 0.0602  , 0.05792 , 0.04654 ,\n",
       "            0.04138 , 0.02898 , 0.02661 , 0.02646 , 0.025   , 0.02438 ,\n",
       "            0.02263 , 0.01462 , 0.01423 , 0.01277 , 0.01201 , 0.00919 ,\n",
       "            0.00835 , 0.008286, 0.008095, 0.00746 , 0.005344, 0.005062],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.51666665, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.08333334, 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.1       , 0.10833333, 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03846154, 0.05384615,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.10769231, 0.11538462,\n",
       "            0.13846155, 0.15384616, 0.16153847, 0.17692308, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.24615385, 0.2769231 , 0.2923077 , 0.30769232, 0.33076924,\n",
       "            0.33846155, 0.36923078, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5692308 , 0.5692308 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.6230769 , 0.6230769 , 0.63076925,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.66923076, 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.7692308 , 0.7692308 ,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86923075, 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.88461536, 0.88461536, 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.997   , 0.996   , 0.9946  , 0.994   , 0.9937  ,\n",
       "            0.993   , 0.9927  , 0.992   , 0.9917  , 0.991   , 0.9907  ,\n",
       "            0.99    , 0.9893  , 0.988   , 0.9873  , 0.987   , 0.9863  ,\n",
       "            0.9844  , 0.984   , 0.9834  , 0.9824  , 0.982   , 0.981   ,\n",
       "            0.9805  , 0.98    , 0.979   , 0.9785  , 0.978   , 0.9775  ,\n",
       "            0.977   , 0.975   , 0.973   , 0.9717  , 0.971   , 0.9697  ,\n",
       "            0.9688  , 0.9644  , 0.96    , 0.9595  , 0.959   , 0.9585  ,\n",
       "            0.952   , 0.951   , 0.949   , 0.948   , 0.9473  , 0.947   ,\n",
       "            0.943   , 0.941   , 0.9404  , 0.9395  , 0.9233  , 0.9224  ,\n",
       "            0.919   , 0.916   , 0.915   , 0.9126  , 0.912   , 0.9106  ,\n",
       "            0.908   , 0.906   , 0.9053  , 0.901   , 0.9004  , 0.9     ,\n",
       "            0.899   , 0.8984  , 0.8965  , 0.894   , 0.893   , 0.892   ,\n",
       "            0.8906  , 0.8887  , 0.888   , 0.886   , 0.8853  , 0.884   ,\n",
       "            0.8813  , 0.88    , 0.8794  , 0.877   , 0.875   , 0.874   ,\n",
       "            0.8726  , 0.8706  , 0.87    , 0.8687  , 0.8647  , 0.864   ,\n",
       "            0.8633  , 0.863   , 0.862   , 0.8613  , 0.861   , 0.859   ,\n",
       "            0.8564  , 0.853   , 0.8516  , 0.846   , 0.8438  , 0.8413  ,\n",
       "            0.841   , 0.8394  , 0.8384  , 0.837   , 0.8364  , 0.8354  ,\n",
       "            0.8325  , 0.828   , 0.8257  , 0.8228  , 0.82    , 0.8184  ,\n",
       "            0.8105  , 0.805   , 0.8027  , 0.8013  , 0.7876  , 0.784   ,\n",
       "            0.7827  , 0.782   , 0.7817  , 0.7793  , 0.7783  , 0.7754  ,\n",
       "            0.7734  , 0.771   , 0.7534  , 0.7446  , 0.74    , 0.734   ,\n",
       "            0.732   , 0.729   , 0.723   , 0.7153  , 0.706   , 0.7046  ,\n",
       "            0.7007  , 0.695   , 0.694   , 0.6934  , 0.693   , 0.6904  ,\n",
       "            0.678   , 0.6777  , 0.66    , 0.6504  , 0.6387  , 0.606   ,\n",
       "            0.6025  , 0.5854  , 0.5776  , 0.492   , 0.4912  , 0.4878  ,\n",
       "            0.4644  , 0.451   , 0.4155  , 0.4136  , 0.4094  , 0.4065  ,\n",
       "            0.3691  , 0.3203  , 0.3071  , 0.3037  , 0.2805  , 0.2708  ,\n",
       "            0.2651  , 0.2646  , 0.2286  , 0.1842  , 0.1824  , 0.1804  ,\n",
       "            0.1727  , 0.1671  , 0.1652  , 0.1355  , 0.1295  , 0.1283  ,\n",
       "            0.1207  , 0.1036  , 0.10016 , 0.09503 , 0.0932  , 0.07574 ,\n",
       "            0.0733  , 0.0688  , 0.0671  , 0.06476 , 0.06464 , 0.06396 ,\n",
       "            0.0619  , 0.0603  , 0.0478  , 0.04224 , 0.02992 , 0.02727 ,\n",
       "            0.02711 , 0.0258  , 0.0248  , 0.0231  , 0.01519 , 0.01445 ,\n",
       "            0.012825, 0.012054, 0.009415, 0.00835 , 0.008316, 0.00749 ,\n",
       "            0.005344, 0.00504 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5416667, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.19166666, 0.2       ,\n",
       "            0.2       , 0.21666667, 0.225     , 0.23333333, 0.23333333,\n",
       "            0.25      , 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.3       , 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.375     , 0.375     , 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.05384615,\n",
       "            0.06153846, 0.08461539, 0.1       , 0.10769231, 0.12307692,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.2       ,\n",
       "            0.21538462, 0.22307692, 0.23846154, 0.24615385, 0.26153848,\n",
       "            0.2846154 , 0.2923077 , 0.30769232, 0.33076924, 0.33846155,\n",
       "            0.35384616, 0.3846154 , 0.3923077 , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.56153846, 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.6076923 , 0.61538464, 0.61538464,\n",
       "            0.61538464, 0.63076925, 0.63076925, 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.66923076, 0.66923076,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.7307692 ,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.998   , 0.997   , 0.996   , 0.9956  , 0.995   ,\n",
       "            0.9946  , 0.994   , 0.9937  , 0.993   , 0.9927  , 0.992   ,\n",
       "            0.9917  , 0.991   , 0.99    , 0.9893  , 0.988   , 0.987   ,\n",
       "            0.9863  , 0.986   , 0.9854  , 0.985   , 0.9844  , 0.984   ,\n",
       "            0.9834  , 0.983   , 0.9824  , 0.982   , 0.9814  , 0.9795  ,\n",
       "            0.978   , 0.976   , 0.9756  , 0.975   , 0.974   , 0.97    ,\n",
       "            0.9663  , 0.966   , 0.9653  , 0.965   , 0.9595  , 0.9585  ,\n",
       "            0.956   , 0.9556  , 0.955   , 0.9526  , 0.951   , 0.9487  ,\n",
       "            0.948   , 0.9355  , 0.9336  , 0.9316  , 0.931   , 0.9307  ,\n",
       "            0.929   , 0.9287  , 0.928   , 0.9243  , 0.921   , 0.9204  ,\n",
       "            0.92    , 0.9185  , 0.9175  , 0.914   , 0.913   , 0.912   ,\n",
       "            0.911   , 0.9106  , 0.9067  , 0.9062  , 0.906   , 0.9043  ,\n",
       "            0.904   , 0.9014  , 0.901   , 0.8975  , 0.895   , 0.8945  ,\n",
       "            0.894   , 0.8936  , 0.8926  , 0.8906  , 0.8896  , 0.889   ,\n",
       "            0.8857  , 0.8853  , 0.8843  , 0.8833  , 0.883   , 0.8813  ,\n",
       "            0.8804  , 0.8765  , 0.875   , 0.8735  , 0.873   , 0.868   ,\n",
       "            0.8677  , 0.866   , 0.8647  , 0.863   , 0.8623  , 0.8604  ,\n",
       "            0.859   , 0.8584  , 0.8574  , 0.857   , 0.854   , 0.8496  ,\n",
       "            0.848   , 0.8467  , 0.8433  , 0.8413  , 0.832   , 0.829   ,\n",
       "            0.826   , 0.825   , 0.82    , 0.816   , 0.8154  , 0.8105  ,\n",
       "            0.8076  , 0.8066  , 0.806   , 0.8057  , 0.803   , 0.8003  ,\n",
       "            0.794   , 0.7817  , 0.7803  , 0.7715  , 0.768   , 0.764   ,\n",
       "            0.76    , 0.755   , 0.746   , 0.738   , 0.7363  , 0.7354  ,\n",
       "            0.729   , 0.7275  , 0.719   , 0.718   , 0.7     , 0.685   ,\n",
       "            0.6626  , 0.63    , 0.6265  , 0.626   , 0.6016  , 0.5146  ,\n",
       "            0.5137  , 0.5103  , 0.4854  , 0.4832  , 0.4656  , 0.4404  ,\n",
       "            0.433   , 0.429   , 0.387   , 0.34    , 0.3357  , 0.3188  ,\n",
       "            0.3025  , 0.2869  , 0.2837  , 0.278   , 0.2397  , 0.1965  ,\n",
       "            0.1924  , 0.1919  , 0.1803  , 0.1748  , 0.1727  , 0.1411  ,\n",
       "            0.1383  , 0.1355  , 0.1255  , 0.1082  , 0.1045  , 0.09827 ,\n",
       "            0.09656 , 0.07794 , 0.0753  , 0.0716  , 0.0689  , 0.06757 ,\n",
       "            0.0667  , 0.06335 , 0.0629  , 0.04895 , 0.04297 , 0.03091 ,\n",
       "            0.02817 , 0.02759 , 0.02661 , 0.02493 , 0.0236  , 0.01578 ,\n",
       "            0.01467 , 0.012726, 0.01196 , 0.0096  , 0.008575, 0.008286,\n",
       "            0.00822 , 0.00743 , 0.005302, 0.004963], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.55833334, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.225     , 0.23333333, 0.25      , 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.275     , 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.3       , 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.43333334, 0.44166666,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.05384615, 0.06923077,\n",
       "            0.08461539, 0.1       , 0.11538462, 0.14615385, 0.16153847,\n",
       "            0.17692308, 0.1923077 , 0.2       , 0.21538462, 0.22307692,\n",
       "            0.23846154, 0.24615385, 0.26153848, 0.2923077 , 0.30769232,\n",
       "            0.33076924, 0.34615386, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.4923077 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.5538462 , 0.56153846,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.64615387, 0.64615387, 0.64615387, 0.64615387,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 , 0.7076923 ,\n",
       "            0.7153846 , 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9985  , 0.9976  , 0.9966  , 0.996   , 0.9956  ,\n",
       "            0.995   , 0.9946  , 0.994   , 0.9937  , 0.993   , 0.992   ,\n",
       "            0.9917  , 0.991   , 0.9897  , 0.9893  , 0.989   , 0.9883  ,\n",
       "            0.988   , 0.9873  , 0.987   , 0.9863  , 0.986   , 0.9854  ,\n",
       "            0.985   , 0.9844  , 0.9834  , 0.9814  , 0.98    , 0.9795  ,\n",
       "            0.979   , 0.978   , 0.9746  , 0.972   , 0.9707  , 0.97    ,\n",
       "            0.9683  , 0.9653  , 0.9644  , 0.964   , 0.963   , 0.9624  ,\n",
       "            0.9614  , 0.958   , 0.9565  , 0.956   , 0.948   , 0.946   ,\n",
       "            0.9453  , 0.9434  , 0.943   , 0.942   , 0.9375  , 0.9355  ,\n",
       "            0.9346  , 0.934   , 0.933   , 0.931   , 0.9297  , 0.929   ,\n",
       "            0.9287  , 0.9277  , 0.9272  , 0.927   , 0.9233  , 0.9224  ,\n",
       "            0.922   , 0.9204  , 0.918   , 0.9175  , 0.9165  , 0.914   ,\n",
       "            0.912   , 0.911   , 0.9097  , 0.908   , 0.9077  , 0.9062  ,\n",
       "            0.905   , 0.9023  , 0.902   , 0.9     , 0.8984  , 0.8975  ,\n",
       "            0.895   , 0.8945  , 0.8936  , 0.8926  , 0.889   , 0.887   ,\n",
       "            0.885   , 0.8833  , 0.883   , 0.8823  , 0.88    , 0.878   ,\n",
       "            0.8765  , 0.876   , 0.8745  , 0.8706  , 0.8696  , 0.8647  ,\n",
       "            0.863   , 0.854   , 0.853   , 0.852   , 0.8486  , 0.848   ,\n",
       "            0.8467  , 0.842   , 0.841   , 0.8403  , 0.831   , 0.83    ,\n",
       "            0.8296  , 0.827   , 0.824   , 0.814   , 0.813   , 0.8086  ,\n",
       "            0.807   , 0.798   , 0.795   , 0.787   , 0.785   , 0.7847  ,\n",
       "            0.776   , 0.765   , 0.7637  , 0.763   , 0.761   , 0.7603  ,\n",
       "            0.757   , 0.755   , 0.7407  , 0.721   , 0.686   , 0.671   ,\n",
       "            0.6543  , 0.6514  , 0.6255  , 0.5396  , 0.5376  , 0.5347  ,\n",
       "            0.5254  , 0.519   , 0.507   , 0.4797  , 0.454   , 0.4514  ,\n",
       "            0.4075  , 0.3806  , 0.3535  , 0.3376  , 0.3281  , 0.313   ,\n",
       "            0.2986  , 0.2937  , 0.2507  , 0.2167  , 0.2037  , 0.2017  ,\n",
       "            0.1885  , 0.185   , 0.183   , 0.1497  , 0.1492  , 0.1449  ,\n",
       "            0.132   , 0.1142  , 0.1101  , 0.10284 , 0.10156 , 0.08124 ,\n",
       "            0.07806 , 0.07556 , 0.07263 , 0.0716  , 0.0698  , 0.0695  ,\n",
       "            0.0667  , 0.0656  , 0.0509  , 0.04443 , 0.03265 , 0.02971 ,\n",
       "            0.02855 , 0.0281  , 0.02538 , 0.02457 , 0.01692 , 0.01519 ,\n",
       "            0.01287 , 0.012146, 0.010056, 0.00909 , 0.008415, 0.008286,\n",
       "            0.007576, 0.005386, 0.005   ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.56666666, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.15833333, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.275     , 0.275     , 0.275     , 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03846154, 0.06923077,\n",
       "            0.09230769, 0.10769231, 0.13846155, 0.16153847, 0.17692308,\n",
       "            0.1923077 , 0.2       , 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.24615385, 0.26153848, 0.30769232, 0.33846155, 0.34615386,\n",
       "            0.37692308, 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.6230769 , 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.6615385 , 0.6769231 , 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7153846 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.88461536, 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.999   , 0.998   , 0.9976  , 0.997   , 0.9966  ,\n",
       "            0.996   , 0.9956  , 0.995   , 0.9946  , 0.994   , 0.9937  ,\n",
       "            0.993   , 0.992   , 0.9917  , 0.991   , 0.9907  , 0.99    ,\n",
       "            0.9897  , 0.9893  , 0.989   , 0.9883  , 0.988   , 0.987   ,\n",
       "            0.9854  , 0.984   , 0.9834  , 0.983   , 0.9824  , 0.9795  ,\n",
       "            0.978   , 0.977   , 0.976   , 0.9756  , 0.9717  , 0.9707  ,\n",
       "            0.9688  , 0.9683  , 0.9653  , 0.9644  , 0.9634  , 0.9595  ,\n",
       "            0.958   , 0.957   , 0.956   , 0.955   , 0.9526  , 0.952   ,\n",
       "            0.949   , 0.9487  , 0.948   , 0.947   , 0.9443  , 0.944   ,\n",
       "            0.9424  , 0.942   , 0.9414  , 0.941   , 0.9385  , 0.9375  ,\n",
       "            0.936   , 0.9355  , 0.9336  , 0.932   , 0.931   , 0.929   ,\n",
       "            0.9287  , 0.928   , 0.9277  , 0.927   , 0.9253  , 0.9243  ,\n",
       "            0.924   , 0.923   , 0.9204  , 0.92    , 0.9194  , 0.9175  ,\n",
       "            0.9155  , 0.914   , 0.9126  , 0.912   , 0.911   , 0.908   ,\n",
       "            0.9067  , 0.9043  , 0.904   , 0.9033  , 0.903   , 0.8994  ,\n",
       "            0.8984  , 0.898   , 0.897   , 0.895   , 0.8945  , 0.894   ,\n",
       "            0.8916  , 0.891   , 0.89    , 0.886   , 0.8843  , 0.883   ,\n",
       "            0.8755  , 0.8745  , 0.871   , 0.8706  , 0.869   , 0.866   ,\n",
       "            0.855   , 0.854   , 0.853   , 0.851   , 0.848   , 0.846   ,\n",
       "            0.841   , 0.836   , 0.834   , 0.8306  , 0.8228  , 0.8223  ,\n",
       "            0.815   , 0.8145  , 0.814   , 0.7993  , 0.799   , 0.7964  ,\n",
       "            0.794   , 0.793   , 0.7915  , 0.786   , 0.7856  , 0.7783  ,\n",
       "            0.756   , 0.7134  , 0.7124  , 0.681   , 0.6797  , 0.653   ,\n",
       "            0.582   , 0.5684  , 0.5645  , 0.5625  , 0.556   , 0.533   ,\n",
       "            0.52    , 0.4792  , 0.4766  , 0.431   , 0.4216  , 0.3743  ,\n",
       "            0.358   , 0.3557  , 0.3408  , 0.3162  , 0.311   , 0.2656  ,\n",
       "            0.2378  , 0.2162  , 0.2129  , 0.1993  , 0.1958  , 0.1936  ,\n",
       "            0.1609  , 0.1572  , 0.1542  , 0.1389  , 0.1201  , 0.1158  ,\n",
       "            0.1076  , 0.1063  , 0.08466 , 0.08124 , 0.0792  , 0.0772  ,\n",
       "            0.07434 , 0.07275 , 0.0724  , 0.07007 , 0.06793 , 0.0526  ,\n",
       "            0.0457  , 0.0339  , 0.03079 , 0.0292  , 0.02914 , 0.02571 ,\n",
       "            0.02518 , 0.01764 , 0.01543 , 0.01287 , 0.012146, 0.01025 ,\n",
       "            0.00934 , 0.008415, 0.00822 , 0.00755 , 0.005344, 0.004944],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.56666666, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.125     , 0.13333334, 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15833333, 0.15833333,\n",
       "            0.16666667, 0.175     , 0.175     , 0.175     , 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.225     , 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25      , 0.26666668, 0.26666668,\n",
       "            0.26666668, 0.28333333, 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.3       , 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.7       , 0.7083333 , 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.05384615, 0.08461539,\n",
       "            0.10769231, 0.14615385, 0.16153847, 0.1923077 , 0.2       ,\n",
       "            0.21538462, 0.23846154, 0.24615385, 0.2769231 , 0.31538463,\n",
       "            0.33846155, 0.36923078, 0.4       , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.66923076, 0.66923076, 0.6769231 ,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 , 0.7076923 ,\n",
       "            0.7076923 , 0.72307694, 0.7307692 , 0.73846155, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.88461536, 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.999   , 0.9985  , 0.998   , 0.9976  , 0.997   ,\n",
       "            0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  , 0.9937  ,\n",
       "            0.993   , 0.9927  , 0.992   , 0.9917  , 0.991   , 0.9907  ,\n",
       "            0.9897  , 0.988   , 0.987   , 0.9863  , 0.986   , 0.985   ,\n",
       "            0.9834  , 0.983   , 0.982   , 0.9805  , 0.9795  , 0.979   ,\n",
       "            0.9785  , 0.976   , 0.9756  , 0.974   , 0.9736  , 0.9717  ,\n",
       "            0.97    , 0.9697  , 0.969   , 0.9688  , 0.9683  , 0.9673  ,\n",
       "            0.967   , 0.966   , 0.963   , 0.961   , 0.9604  , 0.9595  ,\n",
       "            0.9575  , 0.957   , 0.956   , 0.955   , 0.9546  , 0.954   ,\n",
       "            0.9526  , 0.952   , 0.9517  , 0.951   , 0.95    , 0.9497  ,\n",
       "            0.948   , 0.947   , 0.946   , 0.945   , 0.9443  , 0.944   ,\n",
       "            0.9434  , 0.943   , 0.942   , 0.9414  , 0.941   , 0.94    ,\n",
       "            0.9395  , 0.9375  , 0.9365  , 0.936   , 0.9346  , 0.932   ,\n",
       "            0.9307  , 0.929   , 0.928   , 0.9272  , 0.926   , 0.9233  ,\n",
       "            0.923   , 0.922   , 0.919   , 0.9175  , 0.916   , 0.9146  ,\n",
       "            0.9136  , 0.9126  , 0.9116  , 0.9106  , 0.91    , 0.9097  ,\n",
       "            0.907   , 0.9053  , 0.9023  , 0.899   , 0.898   , 0.897   ,\n",
       "            0.895   , 0.894   , 0.8936  , 0.8896  , 0.8794  , 0.8784  ,\n",
       "            0.877   , 0.8755  , 0.8726  , 0.8623  , 0.862   , 0.857   ,\n",
       "            0.851   , 0.8506  , 0.8496  , 0.8433  , 0.8423  , 0.8374  ,\n",
       "            0.8335  , 0.8296  , 0.8276  , 0.8257  , 0.8247  , 0.8228  ,\n",
       "            0.815   , 0.8086  , 0.7905  , 0.7563  , 0.7344  , 0.7046  ,\n",
       "            0.704   , 0.676   , 0.644   , 0.5967  , 0.5947  , 0.587   ,\n",
       "            0.586   , 0.564   , 0.55    , 0.4993  , 0.497   , 0.4695  ,\n",
       "            0.4512  , 0.3901  , 0.387   , 0.3782  , 0.3726  , 0.3289  ,\n",
       "            0.3271  , 0.2727  , 0.2622  , 0.2292  , 0.2191  , 0.2056  ,\n",
       "            0.2037  , 0.1746  , 0.1647  , 0.1444  , 0.126   , 0.12103 ,\n",
       "            0.11084 , 0.11066 , 0.0865  , 0.0831  , 0.083   , 0.0821  ,\n",
       "            0.07574 , 0.0753  , 0.0745  , 0.074   , 0.0688  , 0.0539  ,\n",
       "            0.0462  , 0.0356  , 0.0323  , 0.03062 , 0.02982 , 0.02591 ,\n",
       "            0.02513 , 0.0188  , 0.01578 , 0.01257 , 0.012054, 0.01061 ,\n",
       "            0.00986 , 0.008415, 0.008095, 0.00752 , 0.00532 , 0.004868],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5833333, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.075     , 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.125     , 0.125     ,\n",
       "            0.14166667, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.175     , 0.175     , 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25      , 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.05384615, 0.08461539,\n",
       "            0.13076924, 0.16153847, 0.1923077 , 0.2       , 0.21538462,\n",
       "            0.22307692, 0.24615385, 0.2846154 , 0.33846155, 0.36923078,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.56153846, 0.5692308 ,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.6076923 , 0.61538464, 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.65384614, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6769231 , 0.6769231 ,\n",
       "            0.6846154 , 0.7       , 0.7076923 , 0.72307694, 0.7307692 ,\n",
       "            0.7307692 , 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.9       , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  ,\n",
       "            0.994   , 0.9937  , 0.993   , 0.9927  , 0.992   , 0.9917  ,\n",
       "            0.9897  , 0.9893  , 0.989   , 0.9883  , 0.988   , 0.9873  ,\n",
       "            0.987   , 0.9854  , 0.985   , 0.984   , 0.9834  , 0.983   ,\n",
       "            0.98    , 0.9795  , 0.9785  , 0.978   , 0.977   , 0.9766  ,\n",
       "            0.976   , 0.9756  , 0.975   , 0.974   , 0.9707  , 0.97    ,\n",
       "            0.9697  , 0.969   , 0.9688  , 0.968   , 0.967   , 0.9663  ,\n",
       "            0.9644  , 0.964   , 0.963   , 0.962   , 0.961   , 0.9604  ,\n",
       "            0.9595  , 0.9585  , 0.957   , 0.9565  , 0.956   , 0.955   ,\n",
       "            0.9546  , 0.953   , 0.9526  , 0.952   , 0.951   , 0.95    ,\n",
       "            0.9497  , 0.949   , 0.9478  , 0.945   , 0.944   , 0.943   ,\n",
       "            0.942   , 0.9404  , 0.9385  , 0.938   , 0.9375  , 0.937   ,\n",
       "            0.936   , 0.9346  , 0.933   , 0.93    , 0.929   , 0.9277  ,\n",
       "            0.9272  , 0.925   , 0.924   , 0.9224  , 0.922   , 0.92    ,\n",
       "            0.915   , 0.9146  , 0.914   , 0.912   , 0.9116  , 0.9087  ,\n",
       "            0.9     , 0.899   , 0.898   , 0.897   , 0.8965  , 0.895   ,\n",
       "            0.893   , 0.886   , 0.8843  , 0.8784  , 0.8726  , 0.8667  ,\n",
       "            0.865   , 0.861   , 0.856   , 0.8555  , 0.8516  , 0.8496  ,\n",
       "            0.847   , 0.844   , 0.8384  , 0.828   , 0.8193  , 0.792   ,\n",
       "            0.7554  , 0.727   , 0.7266  , 0.6978  , 0.696   , 0.6323  ,\n",
       "            0.6187  , 0.6104  , 0.608   , 0.603   , 0.57    , 0.521   ,\n",
       "            0.5166  , 0.5127  , 0.4712  , 0.4163  , 0.4065  , 0.4026  ,\n",
       "            0.3972  , 0.3428  , 0.3425  , 0.285   , 0.283   , 0.2415  ,\n",
       "            0.2273  , 0.2148  , 0.2129  , 0.2109  , 0.187   , 0.1743  ,\n",
       "            0.1715  , 0.1497  , 0.1313  , 0.126   , 0.1144  , 0.11395 ,\n",
       "            0.0887  , 0.0879  , 0.0863  , 0.08386 , 0.07764 , 0.0774  ,\n",
       "            0.0772  , 0.0764  , 0.0702  , 0.055   , 0.0468  , 0.03677 ,\n",
       "            0.03333 , 0.03162 , 0.03021 , 0.02641 , 0.02509 , 0.01953 ,\n",
       "            0.0159  , 0.01243 , 0.01196 , 0.01082 , 0.01013 , 0.008316,\n",
       "            0.007965, 0.00746 , 0.00526 , 0.00479 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59166664, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.1       , 0.10833333, 0.125     ,\n",
       "            0.125     , 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.15833333, 0.16666667, 0.16666667, 0.175     ,\n",
       "            0.175     , 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.24166666, 0.24166666, 0.24166666, 0.25      ,\n",
       "            0.25      , 0.25      , 0.25      , 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.26666668, 0.26666668, 0.275     , 0.275     ,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01538462, 0.05384615, 0.1       , 0.15384616,\n",
       "            0.1923077 , 0.21538462, 0.26923078, 0.3       , 0.35384616,\n",
       "            0.3846154 , 0.4076923 , 0.41538462, 0.42307693, 0.43846154,\n",
       "            0.44615385, 0.46153846, 0.46923077, 0.4846154 , 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.52307695, 0.53846157,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5846154 , 0.5846154 ,\n",
       "            0.6       , 0.6076923 , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.6230769 , 0.63076925, 0.63076925,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.7       , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8153846 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.996   , 0.9956  , 0.995   , 0.9946  , 0.994   ,\n",
       "            0.9937  , 0.992   , 0.9917  , 0.991   , 0.9907  , 0.9897  ,\n",
       "            0.9893  , 0.9883  , 0.9873  , 0.987   , 0.9844  , 0.984   ,\n",
       "            0.983   , 0.9824  , 0.9814  , 0.9805  , 0.9795  , 0.979   ,\n",
       "            0.9785  , 0.978   , 0.9775  , 0.9766  , 0.9756  , 0.974   ,\n",
       "            0.9736  , 0.973   , 0.9727  , 0.9717  , 0.971   , 0.9707  ,\n",
       "            0.97    , 0.969   , 0.9688  , 0.968   , 0.967   , 0.9663  ,\n",
       "            0.966   , 0.965   , 0.9644  , 0.964   , 0.963   , 0.962   ,\n",
       "            0.9614  , 0.9604  , 0.96    , 0.959   , 0.9585  , 0.958   ,\n",
       "            0.957   , 0.9565  , 0.956   , 0.9556  , 0.954   , 0.9526  ,\n",
       "            0.952   , 0.951   , 0.949   , 0.9487  , 0.9478  , 0.947   ,\n",
       "            0.946   , 0.945   , 0.944   , 0.9434  , 0.943   , 0.941   ,\n",
       "            0.94    , 0.939   , 0.9385  , 0.9375  , 0.935   , 0.9346  ,\n",
       "            0.933   , 0.932   , 0.93    , 0.9272  , 0.9204  , 0.9185  ,\n",
       "            0.918   , 0.9165  , 0.916   , 0.913   , 0.908   , 0.9077  ,\n",
       "            0.905   , 0.903   , 0.8945  , 0.8926  , 0.889   , 0.8877  ,\n",
       "            0.887   , 0.886   , 0.882   , 0.8804  , 0.876   , 0.874   ,\n",
       "            0.8716  , 0.871   , 0.867   , 0.853   , 0.847   , 0.8237  ,\n",
       "            0.784   , 0.759   , 0.757   , 0.7373  , 0.7285  , 0.668   ,\n",
       "            0.654   , 0.6436  , 0.6396  , 0.5996  , 0.5537  , 0.551   ,\n",
       "            0.546   , 0.5015  , 0.444   , 0.432   , 0.4304  , 0.424   ,\n",
       "            0.3652  , 0.3643  , 0.3044  , 0.3     , 0.2556  , 0.2407  ,\n",
       "            0.2269  , 0.2247  , 0.2233  , 0.1978  , 0.1835  , 0.1804  ,\n",
       "            0.1575  , 0.1366  , 0.1312  , 0.1194  , 0.1192  , 0.09204 ,\n",
       "            0.09125 , 0.089   , 0.0869  , 0.0799  , 0.07947 , 0.0789  ,\n",
       "            0.07227 , 0.05634 , 0.0477  , 0.037   , 0.03348 , 0.03168 ,\n",
       "            0.03021 , 0.02635 , 0.02509 , 0.01942 , 0.01567 , 0.01219 ,\n",
       "            0.011734, 0.01057 , 0.009895, 0.008095, 0.007725, 0.007233,\n",
       "            0.00504 , 0.004593], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59166664, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.08333334, 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.125     , 0.125     , 0.125     , 0.13333334,\n",
       "            0.15      , 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.175     , 0.175     , 0.18333334, 0.2       , 0.20833333,\n",
       "            0.20833333, 0.21666667, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.30833334, 0.325     , 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.01538462, 0.08461539, 0.15384616, 0.1923077 ,\n",
       "            0.21538462, 0.23846154, 0.2923077 , 0.35384616, 0.3846154 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.44615385,\n",
       "            0.46153846, 0.46923077, 0.4846154 , 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.50769234, 0.52307695, 0.53846157,\n",
       "            0.5538462 , 0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.6230769 , 0.6230769 ,\n",
       "            0.63846153, 0.6615385 , 0.6615385 , 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.7       , 0.7       , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.86923075, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  ,\n",
       "            0.9937  , 0.993   , 0.9927  , 0.992   , 0.9917  , 0.991   ,\n",
       "            0.99    , 0.9893  , 0.989   , 0.9873  , 0.987   , 0.9863  ,\n",
       "            0.986   , 0.9854  , 0.983   , 0.9824  , 0.982   , 0.9814  ,\n",
       "            0.9805  , 0.98    , 0.979   , 0.9785  , 0.978   , 0.977   ,\n",
       "            0.9766  , 0.976   , 0.9756  , 0.974   , 0.9736  , 0.973   ,\n",
       "            0.9727  , 0.972   , 0.9717  , 0.971   , 0.9707  , 0.97    ,\n",
       "            0.9697  , 0.9688  , 0.9683  , 0.968   , 0.967   , 0.966   ,\n",
       "            0.9644  , 0.964   , 0.9634  , 0.9624  , 0.961   , 0.96    ,\n",
       "            0.9595  , 0.9585  , 0.9565  , 0.9556  , 0.955   , 0.9546  ,\n",
       "            0.954   , 0.9526  , 0.952   , 0.9507  , 0.9487  , 0.948   ,\n",
       "            0.9478  , 0.9473  , 0.945   , 0.944   , 0.942   , 0.94    ,\n",
       "            0.9395  , 0.9365  , 0.932   , 0.9307  , 0.9287  , 0.928   ,\n",
       "            0.9277  , 0.927   , 0.924   , 0.9214  , 0.921   , 0.917   ,\n",
       "            0.916   , 0.908   , 0.9062  , 0.9023  , 0.9014  , 0.9004  ,\n",
       "            0.9     , 0.8975  , 0.895   , 0.891   , 0.888   , 0.885   ,\n",
       "            0.8843  , 0.869   , 0.865   , 0.8457  , 0.805   , 0.7817  ,\n",
       "            0.7793  , 0.77    , 0.753   , 0.696   , 0.6816  , 0.6714  ,\n",
       "            0.67    , 0.667   , 0.6284  , 0.585   , 0.5825  , 0.575   ,\n",
       "            0.53    , 0.4717  , 0.4592  , 0.4583  , 0.451   , 0.39    ,\n",
       "            0.3894  , 0.328   , 0.324   , 0.274   , 0.2605  , 0.2441  ,\n",
       "            0.2422  , 0.2418  , 0.2137  , 0.1981  , 0.1947  , 0.1707  ,\n",
       "            0.1471  , 0.1415  , 0.1294  , 0.1293  , 0.1     , 0.0991  ,\n",
       "            0.096   , 0.09467 , 0.0869  , 0.0865  , 0.086   , 0.0856  ,\n",
       "            0.0786  , 0.06097 , 0.05176 , 0.04    , 0.03616 , 0.0343  ,\n",
       "            0.0326  , 0.02838 , 0.02733 , 0.02112 , 0.01692 , 0.01317 ,\n",
       "            0.01263 , 0.01142 , 0.010735, 0.00871 , 0.008316, 0.007786,\n",
       "            0.005447, 0.004963], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.1641791 , 0.1716418 , 0.18656716, 0.20895523, 0.21641791,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3880597 , 0.40298507, 0.40298507,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.69402987, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7089552 , 0.7089552 , 0.7164179 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.76865673, 0.76865673, 0.7761194 , 0.7835821 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.85820895, 0.86567163, 0.86567163, 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9328358 , 0.9402985 , 0.9402985 ,\n",
       "            0.9477612 , 0.9477612 , 0.95522386, 0.95522386, 0.95522386,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.97761196, 0.97761196,\n",
       "            0.98507464, 0.98507464, 0.9925373 , 0.9925373 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.04310345,\n",
       "            0.04310345, 0.06034483, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.09482758, 0.10344828,\n",
       "            0.10344828, 0.10344828, 0.11206897, 0.12931034, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.19827586, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.31896552,\n",
       "            0.31896552, 0.3275862 , 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5258621 , 0.5258621 , 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.5689655 , 0.57758623, 0.57758623,\n",
       "            0.57758623, 0.57758623, 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.6810345 , 0.6810345 , 0.6810345 , 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4675, 0.4668, 0.4666, 0.4663, 0.4648, 0.4639, 0.4634,\n",
       "            0.4622, 0.462 , 0.4614, 0.4602, 0.4587, 0.4585, 0.4575, 0.457 ,\n",
       "            0.4565, 0.4563, 0.456 , 0.4558, 0.4556, 0.455 , 0.4548, 0.4546,\n",
       "            0.4524, 0.4512, 0.45  , 0.4492, 0.4485, 0.448 , 0.4473, 0.447 ,\n",
       "            0.446 , 0.4412, 0.4377, 0.4375, 0.4363, 0.435 , 0.4336, 0.433 ,\n",
       "            0.4324, 0.4297, 0.429 , 0.425 , 0.423 , 0.4224, 0.4158, 0.4133,\n",
       "            0.4104, 0.4087, 0.4084, 0.408 , 0.4072, 0.4016, 0.4011, 0.401 ,\n",
       "            0.398 , 0.3977, 0.3958, 0.391 , 0.39  , 0.3884, 0.386 , 0.3848,\n",
       "            0.384 , 0.3835, 0.3826, 0.3816, 0.378 , 0.3767, 0.3762, 0.3755,\n",
       "            0.374 , 0.3738, 0.3735, 0.371 , 0.3704, 0.3645, 0.364 , 0.3633,\n",
       "            0.3604, 0.3596, 0.3594, 0.357 , 0.3562, 0.3555, 0.3545, 0.3528,\n",
       "            0.3506, 0.3477, 0.3462, 0.3447, 0.3433, 0.3423, 0.341 , 0.3406,\n",
       "            0.3376, 0.3364, 0.3362, 0.3352, 0.3345, 0.3333, 0.3315, 0.3289,\n",
       "            0.3274, 0.3257, 0.3218, 0.32  , 0.3174, 0.316 , 0.3118, 0.3103,\n",
       "            0.3062, 0.3052, 0.3044, 0.3008, 0.3   , 0.2954, 0.2942, 0.294 ,\n",
       "            0.2927, 0.2915, 0.2908, 0.2896, 0.2842, 0.2805, 0.2786, 0.2761,\n",
       "            0.2754, 0.2676, 0.267 , 0.2668, 0.2664, 0.2656, 0.2646, 0.2632,\n",
       "            0.263 , 0.2612, 0.259 , 0.2588, 0.2585, 0.2542, 0.2537, 0.252 ,\n",
       "            0.2502, 0.2463, 0.2462, 0.2458, 0.2456, 0.2455, 0.2452, 0.2434,\n",
       "            0.2426, 0.2422, 0.2418, 0.2413, 0.2405, 0.2402, 0.2379, 0.2378,\n",
       "            0.2366, 0.2356, 0.2346, 0.234 , 0.2322, 0.2314, 0.2313, 0.2307,\n",
       "            0.2297, 0.2294, 0.2286, 0.2264, 0.2263, 0.2256, 0.2255, 0.2249,\n",
       "            0.2246, 0.2238, 0.2229, 0.2217, 0.2205, 0.219 , 0.2186, 0.218 ,\n",
       "            0.2177, 0.2152, 0.2148, 0.214 , 0.2128, 0.2109, 0.2094, 0.2081,\n",
       "            0.2076, 0.2074, 0.2045, 0.2031, 0.2024, 0.2013, 0.1996, 0.1974,\n",
       "            0.1946, 0.1906, 0.1884, 0.1865, 0.1859, 0.1799, 0.1785, 0.1782,\n",
       "            0.1774, 0.1761, 0.1738, 0.1725, 0.171 , 0.1709, 0.1683, 0.1669,\n",
       "            0.1633, 0.1586, 0.1583, 0.155 , 0.1467], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.14179105, 0.14925373, 0.1641791 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.40298507, 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6567164 , 0.6641791 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.70149255, 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73134327, 0.73880595, 0.73880595, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.76865673, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.7910448 , 0.7910448 , 0.79850745, 0.79850745,\n",
       "            0.79850745, 0.80597013, 0.80597013, 0.8208955 , 0.82835823,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.86567163, 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.880597  , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9328358 , 0.9402985 , 0.9402985 , 0.9402985 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.95522386, 0.95522386, 0.96268654,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.97761196, 0.97761196, 0.97761196, 0.98507464, 0.98507464,\n",
       "            0.98507464, 0.9925373 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06034483, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.27586207, 0.27586207, 0.27586207,\n",
       "            0.27586207, 0.28448275, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.62068963, 0.62068963, 0.62068963, 0.62068963,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4473 , 0.446  , 0.4456 , 0.4436 , 0.4426 , 0.4424 ,\n",
       "            0.4417 , 0.4412 , 0.4397 , 0.438  , 0.4373 , 0.437  , 0.4358 ,\n",
       "            0.4355 , 0.4353 , 0.4338 , 0.4333 , 0.433  , 0.4329 , 0.4326 ,\n",
       "            0.4316 , 0.4312 , 0.4307 , 0.4304 , 0.429  , 0.4275 , 0.4268 ,\n",
       "            0.4265 , 0.4258 , 0.4248 , 0.422  , 0.4214 , 0.4211 , 0.418  ,\n",
       "            0.4126 , 0.4119 , 0.4111 , 0.4082 , 0.4062 , 0.4055 , 0.405  ,\n",
       "            0.4045 , 0.4028 , 0.3982 , 0.3977 , 0.395  , 0.3901 , 0.3843 ,\n",
       "            0.3796 , 0.3794 , 0.3792 , 0.3784 , 0.3782 , 0.373  , 0.3704 ,\n",
       "            0.37   , 0.3638 , 0.3618 , 0.3616 , 0.361  , 0.3562 , 0.3533 ,\n",
       "            0.352  , 0.3503 , 0.3489 , 0.3474 , 0.3464 , 0.3457 , 0.3452 ,\n",
       "            0.3442 , 0.3376 , 0.335  , 0.3347 , 0.3342 , 0.3325 , 0.332  ,\n",
       "            0.3318 , 0.3308 , 0.3303 , 0.3293 , 0.3289 , 0.3203 , 0.3188 ,\n",
       "            0.3167 , 0.3157 , 0.3147 , 0.313  , 0.3088 , 0.3086 , 0.308  ,\n",
       "            0.3057 , 0.3054 , 0.3042 , 0.3018 , 0.3015 , 0.3003 , 0.2996 ,\n",
       "            0.299  , 0.2986 , 0.2947 , 0.2917 , 0.2883 , 0.2861 , 0.2856 ,\n",
       "            0.2854 , 0.2847 , 0.2825 , 0.2793 , 0.2786 , 0.278  , 0.2776 ,\n",
       "            0.2766 , 0.2725 , 0.2693 , 0.258  , 0.257  , 0.2554 , 0.2551 ,\n",
       "            0.2544 , 0.2542 , 0.253  , 0.2512 , 0.251  , 0.2507 , 0.2477 ,\n",
       "            0.2449 , 0.2433 , 0.2418 , 0.2375 , 0.2368 , 0.235  , 0.2325 ,\n",
       "            0.2314 , 0.2292 , 0.2286 , 0.2255 , 0.2235 , 0.2198 , 0.2166 ,\n",
       "            0.2163 , 0.2152 , 0.2145 , 0.2139 , 0.2133 , 0.2119 , 0.2104 ,\n",
       "            0.2096 , 0.2089 , 0.2085 , 0.2053 , 0.2007 , 0.2004 , 0.1995 ,\n",
       "            0.1989 , 0.1985 , 0.1976 , 0.1974 , 0.1971 , 0.197  , 0.1956 ,\n",
       "            0.1946 , 0.1941 , 0.1931 , 0.1929 , 0.1924 , 0.1918 , 0.1917 ,\n",
       "            0.1912 , 0.1892 , 0.189  , 0.1873 , 0.1863 , 0.1855 , 0.1842 ,\n",
       "            0.1838 , 0.1835 , 0.1813 , 0.1808 , 0.1804 , 0.1796 , 0.179  ,\n",
       "            0.1772 , 0.1771 , 0.1758 , 0.1754 , 0.1748 , 0.1738 , 0.1737 ,\n",
       "            0.1736 , 0.1726 , 0.1718 , 0.1699 , 0.1685 , 0.1677 , 0.1649 ,\n",
       "            0.1643 , 0.1638 , 0.1636 , 0.1617 , 0.1611 , 0.1608 , 0.1593 ,\n",
       "            0.1566 , 0.1562 , 0.1555 , 0.1537 , 0.1519 , 0.1515 , 0.1488 ,\n",
       "            0.1467 , 0.1425 , 0.1406 , 0.1346 , 0.134  , 0.133  , 0.1324 ,\n",
       "            0.1315 , 0.1257 , 0.1255 , 0.1254 , 0.1249 , 0.1204 , 0.1196 ,\n",
       "            0.1188 , 0.1152 , 0.1136 , 0.1122 , 0.10394], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.17910448, 0.18656716, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.63432837, 0.64179105, 0.64179105, 0.64179105,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73134327,\n",
       "            0.73134327, 0.73880595, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76119405, 0.76865673, 0.7761194 , 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.7910448 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.7910448 , 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.8134328 , 0.8134328 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8880597 , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9328358 , 0.9328358 , 0.9328358 , 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.9477612 , 0.95522386,\n",
       "            0.95522386, 0.96268654, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.97761196, 0.97761196, 0.97761196,\n",
       "            0.98507464, 0.98507464, 0.98507464, 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.05172414, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.14655173, 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.25862068, 0.2672414 , 0.2672414 , 0.27586207,\n",
       "            0.27586207, 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.38793105, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.44827586, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 0.9913793 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4263 , 0.4248 , 0.4243 , 0.424  , 0.423  , 0.421  ,\n",
       "            0.4207 , 0.42   , 0.4177 , 0.4158 , 0.4153 , 0.415  , 0.4136 ,\n",
       "            0.4119 , 0.4111 , 0.411  , 0.4106 , 0.4104 , 0.4102 , 0.409  ,\n",
       "            0.4084 , 0.4067 , 0.4065 , 0.405  , 0.4045 , 0.4036 , 0.402  ,\n",
       "            0.4014 , 0.4011 , 0.397  , 0.3962 , 0.3958 , 0.394  , 0.3877 ,\n",
       "            0.3862 , 0.385  , 0.3838 , 0.3801 , 0.3796 , 0.3784 , 0.3767 ,\n",
       "            0.3765 , 0.3723 , 0.3713 , 0.368  , 0.3643 , 0.3582 , 0.358  ,\n",
       "            0.3513 , 0.35   , 0.3489 , 0.3486 , 0.3435 , 0.3423 , 0.3398 ,\n",
       "            0.339  , 0.3315 , 0.329  , 0.3289 , 0.3245 , 0.3225 , 0.3188 ,\n",
       "            0.3186 , 0.3154 , 0.3123 , 0.3115 , 0.3108 , 0.3105 , 0.3018 ,\n",
       "            0.299  , 0.2988 , 0.2983 , 0.2964 , 0.2944 , 0.2937 , 0.2913 ,\n",
       "            0.2827 , 0.2817 , 0.28   , 0.279  , 0.2766 , 0.2751 , 0.2737 ,\n",
       "            0.2695 , 0.269  , 0.2686 , 0.2683 , 0.2666 , 0.266  , 0.2637 ,\n",
       "            0.2612 , 0.2588 , 0.258  , 0.2573 , 0.2537 , 0.2494 , 0.2456 ,\n",
       "            0.2444 , 0.2429 , 0.2426 , 0.2422 , 0.2421 , 0.2395 , 0.2388 ,\n",
       "            0.2367 , 0.2355 , 0.235  , 0.233  , 0.2274 , 0.2256 , 0.218  ,\n",
       "            0.2177 , 0.2156 , 0.2135 , 0.2129 , 0.2124 , 0.2119 , 0.2115 ,\n",
       "            0.2101 , 0.2095 , 0.2064 , 0.2028 , 0.2017 , 0.2015 , 0.1993 ,\n",
       "            0.1981 , 0.196  , 0.1953 , 0.189  , 0.1887 , 0.1886 , 0.1877 ,\n",
       "            0.1855 , 0.1814 , 0.1797 , 0.1787 , 0.174  , 0.1738 , 0.1737 ,\n",
       "            0.173  , 0.1726 , 0.1711 , 0.1705 , 0.1698 , 0.1696 , 0.1676 ,\n",
       "            0.166  , 0.1641 , 0.1636 , 0.1622 , 0.162  , 0.1616 , 0.1594 ,\n",
       "            0.159  , 0.1583 , 0.1572 , 0.1562 , 0.1558 , 0.1554 , 0.1545 ,\n",
       "            0.1544 , 0.1538 , 0.1532 , 0.1526 , 0.1521 , 0.1505 , 0.15   ,\n",
       "            0.1499 , 0.1492 , 0.1489 , 0.1483 , 0.145  , 0.1447 , 0.1438 ,\n",
       "            0.1436 , 0.1427 , 0.1426 , 0.1421 , 0.1415 , 0.1405 , 0.1398 ,\n",
       "            0.1368 , 0.1367 , 0.1366 , 0.1354 , 0.1349 , 0.1348 , 0.1345 ,\n",
       "            0.1342 , 0.1338 , 0.133  , 0.132  , 0.131  , 0.1305 , 0.1294 ,\n",
       "            0.128  , 0.1277 , 0.1272 , 0.1261 , 0.12366, 0.1232 , 0.12085,\n",
       "            0.12067, 0.1198 , 0.1197 , 0.1186 , 0.11755, 0.115  , 0.1138 ,\n",
       "            0.1124 , 0.1118 , 0.11163, 0.108  , 0.1025 , 0.10034, 0.09845,\n",
       "            0.09705, 0.0964 , 0.0933 , 0.09204, 0.0909 , 0.0887 , 0.0882 ,\n",
       "            0.0877 , 0.08344, 0.0827 , 0.0824 , 0.0802 , 0.07275],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.33582088,\n",
       "            0.35074627, 0.35820895, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.63432837, 0.63432837, 0.64179105, 0.6492537 , 0.6492537 ,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.6865672 , 0.69402987, 0.70149255, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73134327,\n",
       "            0.73134327, 0.74626863, 0.74626863, 0.75373137, 0.75373137,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7835821 , 0.7910448 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.80597013, 0.8134328 , 0.8134328 , 0.8134328 ,\n",
       "            0.8134328 , 0.82835823, 0.82835823, 0.82835823, 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.9328358 , 0.9328358 , 0.9328358 ,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.95522386, 0.95522386, 0.96268654, 0.96268654,\n",
       "            0.96268654, 0.96268654, 0.9701493 , 0.9701493 , 0.97761196,\n",
       "            0.97761196, 0.97761196, 0.97761196, 0.98507464, 0.98507464,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.21551724, 0.22413793,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.27586207, 0.27586207, 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.39655173, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.7241379 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4045 , 0.4026 , 0.402  , 0.4019 , 0.4016 , 0.399  ,\n",
       "            0.3982 , 0.398  , 0.3965 , 0.396  , 0.3943 , 0.3933 , 0.393  ,\n",
       "            0.3918 , 0.3914 , 0.391  , 0.3901 , 0.389  , 0.3884 , 0.3882 ,\n",
       "            0.388  , 0.3872 , 0.387  , 0.3862 , 0.3848 , 0.3826 , 0.3813 ,\n",
       "            0.381  , 0.3806 , 0.3792 , 0.3782 , 0.377  , 0.3748 , 0.3745 ,\n",
       "            0.3743 , 0.3733 , 0.3696 , 0.364  , 0.3628 , 0.362  , 0.3591 ,\n",
       "            0.3582 , 0.356  , 0.3557 , 0.3547 , 0.3523 , 0.3464 , 0.3428 ,\n",
       "            0.3381 , 0.3315 , 0.327  , 0.3245 , 0.3232 , 0.3228 , 0.3225 ,\n",
       "            0.321  , 0.316  , 0.313  , 0.3125 , 0.3096 , 0.307  , 0.306  ,\n",
       "            0.3022 , 0.2964 , 0.2957 , 0.2954 , 0.2903 , 0.29   , 0.2886 ,\n",
       "            0.2883 , 0.2876 , 0.287  , 0.2827 , 0.2751 , 0.2744 , 0.272  ,\n",
       "            0.2695 , 0.2686 , 0.2678 , 0.2664 , 0.2637 , 0.255  , 0.2534 ,\n",
       "            0.251  , 0.2494 , 0.2477 , 0.2466 , 0.2426 , 0.2424 , 0.2411 ,\n",
       "            0.2386 , 0.2384 , 0.2379 , 0.2351 , 0.2323 , 0.2303 , 0.2299 ,\n",
       "            0.2269 , 0.2256 , 0.2218 , 0.2157 , 0.2148 , 0.2147 , 0.2145 ,\n",
       "            0.2137 , 0.2128 , 0.2085 , 0.2075 , 0.2068 , 0.2059 , 0.2054 ,\n",
       "            0.2043 , 0.1989 , 0.1965 , 0.187  , 0.1863 , 0.1844 , 0.1829 ,\n",
       "            0.182  , 0.181  , 0.1803 , 0.1798 , 0.177  , 0.1768 , 0.1763 ,\n",
       "            0.1708 , 0.169  , 0.1688 , 0.1678 , 0.1666 , 0.1631 , 0.163  ,\n",
       "            0.1578 , 0.1566 , 0.1562 , 0.1548 , 0.153  , 0.1503 , 0.1489 ,\n",
       "            0.1461 , 0.1421 , 0.142  , 0.1417 , 0.1416 , 0.1412 , 0.139  ,\n",
       "            0.1385 , 0.1383 , 0.1376 , 0.1359 , 0.1356 , 0.1343 , 0.1342 ,\n",
       "            0.1326 , 0.1322 , 0.1316 , 0.1315 , 0.1292 , 0.1288 , 0.1279 ,\n",
       "            0.1259 , 0.1251 , 0.12476, 0.12445, 0.1241 , 0.1238 , 0.12335,\n",
       "            0.1232 , 0.12286, 0.12115, 0.12054, 0.1196 , 0.1192 , 0.118  ,\n",
       "            0.1178 , 0.11554, 0.11475, 0.1144 , 0.1128 , 0.1124 , 0.112  ,\n",
       "            0.11127, 0.11084, 0.1076 , 0.1069 , 0.1065 , 0.10504, 0.10486,\n",
       "            0.1047 , 0.10376, 0.1034 , 0.1025 , 0.1023 , 0.1011 , 0.1009 ,\n",
       "            0.10034, 0.09827, 0.0979 , 0.09534, 0.09503, 0.0933 , 0.0922 ,\n",
       "            0.09106, 0.0891 , 0.0879 , 0.086  , 0.0857 , 0.0854 , 0.08435,\n",
       "            0.082  , 0.0761 , 0.0752 , 0.0734 , 0.07227, 0.0717 , 0.06793,\n",
       "            0.0677 , 0.06696, 0.0643 , 0.0642 , 0.06396, 0.05997, 0.05988,\n",
       "            0.0589 , 0.0578 , 0.05167], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08955224, 0.09701493, 0.1119403 , 0.11940298,\n",
       "            0.13432837, 0.14179105, 0.15671642, 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.6492537 , 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.73880595, 0.73880595, 0.73880595,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7835821 , 0.7910448 , 0.7910448 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.7910448 , 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8432836 , 0.8432836 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.85820895, 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.880597  , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.92537314, 0.92537314, 0.9328358 , 0.9328358 ,\n",
       "            0.9402985 , 0.9402985 , 0.9477612 , 0.9477612 , 0.9477612 ,\n",
       "            0.95522386, 0.95522386, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.96268654, 0.9701493 , 0.9701493 , 0.97761196, 0.97761196,\n",
       "            0.97761196, 0.98507464, 0.98507464, 0.98507464, 0.9925373 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.04310345, 0.04310345,\n",
       "            0.05172414, 0.05172414, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06034483, 0.06896552, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12068965, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31034482, 0.31034482, 0.31896552,\n",
       "            0.31896552, 0.31896552, 0.3275862 , 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 ,\n",
       "            0.57758623, 0.57758623, 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.62068963, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.8189655 , 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.38   , 0.3784 , 0.3774 , 0.3772 , 0.3765 , 0.3752 ,\n",
       "            0.3745 , 0.3743 , 0.3735 , 0.3726 , 0.37   , 0.3687 , 0.3684 ,\n",
       "            0.3674 , 0.3667 , 0.3662 , 0.3655 , 0.3652 , 0.3643 , 0.3638 ,\n",
       "            0.3633 , 0.363  , 0.3625 , 0.362  , 0.3606 , 0.3586 , 0.3577 ,\n",
       "            0.3552 , 0.3547 , 0.354  , 0.352  , 0.3503 , 0.348  , 0.3457 ,\n",
       "            0.3447 , 0.344  , 0.343  , 0.3428 , 0.3384 , 0.3376 , 0.3315 ,\n",
       "            0.3313 , 0.3276 , 0.3257 , 0.3218 , 0.3193 , 0.3186 , 0.3147 ,\n",
       "            0.3113 , 0.306  , 0.3054 , 0.3047 , 0.3044 , 0.3013 , 0.3008 ,\n",
       "            0.2993 , 0.2988 , 0.2952 , 0.2942 , 0.2903 , 0.289  , 0.2874 ,\n",
       "            0.2844 , 0.283  , 0.2825 , 0.282  , 0.281  , 0.2722 , 0.2717 ,\n",
       "            0.2715 , 0.271  , 0.2695 , 0.2686 , 0.2664 , 0.2646 , 0.264  ,\n",
       "            0.2627 , 0.2612 , 0.2563 , 0.2556 , 0.25   , 0.2493 , 0.248  ,\n",
       "            0.2473 , 0.2451 , 0.2405 , 0.2401 , 0.2395 , 0.2378 , 0.2362 ,\n",
       "            0.236  , 0.2339 , 0.2313 , 0.2268 , 0.2205 , 0.22   , 0.2198 ,\n",
       "            0.2186 , 0.218  , 0.2158 , 0.2152 , 0.2135 , 0.2134 , 0.2114 ,\n",
       "            0.2109 , 0.2101 , 0.2076 , 0.2069 , 0.2063 , 0.2018 , 0.2013 ,\n",
       "            0.1998 , 0.1981 , 0.1947 , 0.193  , 0.1906 , 0.1886 , 0.1827 ,\n",
       "            0.1752 , 0.1736 , 0.1731 , 0.1677 , 0.1665 , 0.1658 , 0.1654 ,\n",
       "            0.1649 , 0.1644 , 0.162  , 0.156  , 0.1548 , 0.1533 , 0.1511 ,\n",
       "            0.1487 , 0.1486 , 0.1432 , 0.143  , 0.1414 , 0.1403 , 0.14   ,\n",
       "            0.1348 , 0.1342 , 0.1316 , 0.1289 , 0.1282 , 0.1273 , 0.127  ,\n",
       "            0.1265 , 0.126  , 0.1259 , 0.1242 , 0.1239 , 0.12286, 0.1217 ,\n",
       "            0.119  , 0.1172 , 0.11694, 0.11633, 0.1158 , 0.11536, 0.1144 ,\n",
       "            0.1142 , 0.11395, 0.1138 , 0.1126 , 0.1122 , 0.1118 , 0.1105 ,\n",
       "            0.1103 , 0.1095 , 0.1093 , 0.1074 , 0.10724, 0.1067 , 0.1054 ,\n",
       "            0.10504, 0.1036 , 0.1021 , 0.10126, 0.1005 , 0.10034, 0.1    ,\n",
       "            0.0991 , 0.0977 , 0.09705, 0.0959 , 0.09503, 0.0945 , 0.09436,\n",
       "            0.0942 , 0.0933 , 0.0932 , 0.09283, 0.0925 , 0.09174, 0.0903 ,\n",
       "            0.0898 , 0.0885 , 0.0873 , 0.0869 , 0.0857 , 0.08435, 0.08374,\n",
       "            0.0818 , 0.08167, 0.0804 , 0.0801 , 0.07935, 0.0789 , 0.0764 ,\n",
       "            0.0761 , 0.07477, 0.07434, 0.0733 , 0.06903, 0.0667 , 0.0642 ,\n",
       "            0.0635 , 0.06232, 0.06177, 0.06064, 0.058  , 0.0576 , 0.05603,\n",
       "            0.0556 , 0.0534 , 0.05203, 0.05145, 0.05032, 0.0495 , 0.0483 ,\n",
       "            0.04337], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.09701493, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.14179105, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.31343284, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3880597 , 0.3880597 , 0.3880597 ,\n",
       "            0.3955224 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.6268657 , 0.63432837, 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6641791 , 0.67164177, 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7089552 , 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.7238806 , 0.73134327, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76119405, 0.76865673, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7835821 , 0.7835821 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.79850745, 0.79850745, 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8134328 , 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8358209 , 0.8358209 , 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.92537314, 0.92537314, 0.9328358 , 0.9328358 , 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.9477612 , 0.95522386, 0.95522386,\n",
       "            0.95522386, 0.96268654, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.97761196, 0.98507464,\n",
       "            0.98507464, 0.98507464, 0.9925373 , 0.9925373 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.05172414, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.0862069 , 0.10344828, 0.10344828, 0.10344828, 0.10344828,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.12068965, 0.12068965,\n",
       "            0.12931034, 0.12931034, 0.13793103, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.20689656, 0.21551724, 0.22413793, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.29310346,\n",
       "            0.29310346, 0.30172414, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6551724 , 0.6551724 , 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3545 , 0.354  , 0.3525 , 0.3523 , 0.352  , 0.3516 ,\n",
       "            0.3513 , 0.351  , 0.35   , 0.3494 , 0.3484 , 0.3481 , 0.348  ,\n",
       "            0.3477 , 0.3474 , 0.347  , 0.3455 , 0.3447 , 0.344  , 0.3433 ,\n",
       "            0.3425 , 0.3416 , 0.3413 , 0.3408 , 0.3396 , 0.3386 , 0.338  ,\n",
       "            0.3376 , 0.3374 , 0.336  , 0.335  , 0.3328 , 0.3296 , 0.3289 ,\n",
       "            0.3281 , 0.328  , 0.3245 , 0.3225 , 0.321  , 0.3196 , 0.3179 ,\n",
       "            0.3176 , 0.313  , 0.3115 , 0.3098 , 0.309  , 0.3074 , 0.306  ,\n",
       "            0.3044 , 0.298  , 0.2966 , 0.2964 , 0.2947 , 0.292  , 0.2915 ,\n",
       "            0.2898 , 0.2893 , 0.2888 , 0.2878 , 0.287  , 0.2869 , 0.2861 ,\n",
       "            0.2847 , 0.2844 , 0.28   , 0.2795 , 0.2788 , 0.2742 , 0.2727 ,\n",
       "            0.2703 , 0.2686 , 0.2683 , 0.268  , 0.2664 , 0.2651 , 0.2605 ,\n",
       "            0.2603 , 0.2595 , 0.2566 , 0.2556 , 0.2507 , 0.2502 , 0.2498 ,\n",
       "            0.249  , 0.2487 , 0.2474 , 0.2433 , 0.2421 , 0.2388 , 0.2382 ,\n",
       "            0.2378 , 0.2358 , 0.2344 , 0.2319 , 0.2285 , 0.228  , 0.2269 ,\n",
       "            0.2263 , 0.2255 , 0.2222 , 0.2213 , 0.2186 , 0.2181 , 0.2177 ,\n",
       "            0.2175 , 0.2158 , 0.215  , 0.2139 , 0.2108 , 0.21   , 0.2075 ,\n",
       "            0.204  , 0.202  , 0.1913 , 0.191  , 0.1897 , 0.188  , 0.187  ,\n",
       "            0.1738 , 0.1735 , 0.1727 , 0.1698 , 0.167  , 0.1644 , 0.1633 ,\n",
       "            0.1624 , 0.1619 , 0.1606 , 0.1593 , 0.153  , 0.1525 , 0.1508 ,\n",
       "            0.1484 , 0.1483 , 0.1461 , 0.1445 , 0.1426 , 0.1396 , 0.1359 ,\n",
       "            0.1346 , 0.1344 , 0.1343 , 0.1326 , 0.1318 , 0.1317 , 0.131  ,\n",
       "            0.128  , 0.1276 , 0.1272 , 0.1241 , 0.12085, 0.12024, 0.1194 ,\n",
       "            0.11816, 0.1174 , 0.1172 , 0.11694, 0.11676, 0.1166 , 0.1158 ,\n",
       "            0.11554, 0.1152 , 0.11456, 0.1134 , 0.11316, 0.1124 , 0.1118 ,\n",
       "            0.1099 , 0.1097 , 0.10876, 0.1084 , 0.1076 , 0.1067 , 0.1065 ,\n",
       "            0.1058 , 0.1054 , 0.1034 , 0.103  , 0.10266, 0.1023 , 0.1021 ,\n",
       "            0.1019 , 0.10156, 0.10144, 0.1009 , 0.0997 , 0.0991 , 0.09894,\n",
       "            0.09845, 0.0977 , 0.0974 , 0.09656, 0.0964 , 0.0959 , 0.09515,\n",
       "            0.0933 , 0.093  , 0.0904 , 0.0896 , 0.0895 , 0.0891 , 0.0882 ,\n",
       "            0.0876 , 0.08405, 0.0833 , 0.0831 , 0.0824 , 0.08124, 0.0804 ,\n",
       "            0.0798 , 0.07825, 0.076  , 0.0724 , 0.07056, 0.0683 , 0.06793,\n",
       "            0.0673 , 0.0667 , 0.0661 , 0.0651 , 0.06198, 0.0619 , 0.0613 ,\n",
       "            0.0577 , 0.0575 , 0.05542, 0.0539 , 0.0532 , 0.05118, 0.0468 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.04477612, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1716418 , 0.17910448, 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.2238806 , 0.23880596,\n",
       "            0.23880596, 0.25373134, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.29850745, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.3283582 , 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6567164 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.70149255,\n",
       "            0.7089552 , 0.7089552 , 0.7089552 , 0.7089552 , 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.75373137, 0.76865673, 0.76865673,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.79850745, 0.79850745, 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.82835823,\n",
       "            0.82835823, 0.82835823, 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.85820895, 0.85820895,\n",
       "            0.85820895, 0.85820895, 0.86567163, 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8880597 , 0.8880597 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9328358 , 0.9328358 , 0.9328358 ,\n",
       "            0.9402985 , 0.9402985 , 0.9477612 , 0.9477612 , 0.95522386,\n",
       "            0.95522386, 0.96268654, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.96268654, 0.9701493 , 0.9701493 , 0.9701493 , 0.97761196,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 0.9925373 , 0.9925373 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.04310345, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.04310345, 0.04310345, 0.04310345,\n",
       "            0.05172414, 0.05172414, 0.05172414, 0.05172414, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.0862069 , 0.09482758, 0.11206897,\n",
       "            0.11206897, 0.12068965, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.13793103, 0.13793103, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.15517241, 0.15517241, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.20689656, 0.21551724, 0.21551724, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.36206895, 0.36206895,\n",
       "            0.36206895, 0.37068966, 0.38793105, 0.39655173, 0.39655173,\n",
       "            0.39655173, 0.4051724 , 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43965518, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.51724136, 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.54310346, 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.57758623, 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.7241379 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.8534483 , 0.8534483 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.92241377, 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3516 , 0.3484 , 0.3457 , 0.3394 , 0.3372 , 0.3337 ,\n",
       "            0.3335 , 0.333  , 0.3315 , 0.3308 , 0.3306 , 0.33   , 0.3296 ,\n",
       "            0.3293 , 0.329  , 0.3289 , 0.3286 , 0.3281 , 0.328  , 0.3271 ,\n",
       "            0.326  , 0.3252 , 0.325  , 0.324  , 0.3237 , 0.3223 , 0.322  ,\n",
       "            0.3218 , 0.321  , 0.3203 , 0.32   , 0.3188 , 0.3186 , 0.317  ,\n",
       "            0.3142 , 0.3127 , 0.3125 , 0.3115 , 0.3105 , 0.31   , 0.3093 ,\n",
       "            0.308  , 0.3052 , 0.305  , 0.3047 , 0.3037 , 0.3013 , 0.2998 ,\n",
       "            0.298  , 0.2944 , 0.2937 , 0.2925 , 0.2915 , 0.2903 , 0.289  ,\n",
       "            0.2888 , 0.2878 , 0.287  , 0.2844 , 0.2837 , 0.2834 , 0.283  ,\n",
       "            0.2817 , 0.2815 , 0.2803 , 0.28   , 0.279  , 0.2786 , 0.2773 ,\n",
       "            0.2766 , 0.2754 , 0.274  , 0.2732 , 0.2727 , 0.2722 , 0.2717 ,\n",
       "            0.27   , 0.2693 , 0.2678 , 0.2664 , 0.2646 , 0.2637 , 0.2605 ,\n",
       "            0.2573 , 0.2542 , 0.2532 , 0.252  , 0.249  , 0.2487 , 0.2482 ,\n",
       "            0.2471 , 0.246  , 0.243  , 0.2426 , 0.2375 , 0.2372 , 0.2368 ,\n",
       "            0.2311 , 0.2306 , 0.2299 , 0.223  , 0.2212 , 0.2198 , 0.2181 ,\n",
       "            0.2173 , 0.214  , 0.2104 , 0.207  , 0.1989 , 0.1946 , 0.1937 ,\n",
       "            0.1906 , 0.1903 , 0.1824 , 0.1815 , 0.1757 , 0.1733 , 0.1719 ,\n",
       "            0.1715 , 0.1665 , 0.1658 , 0.1648 , 0.1643 , 0.1617 , 0.1614 ,\n",
       "            0.16   , 0.1587 , 0.1552 , 0.155  , 0.1505 , 0.1493 , 0.1484 ,\n",
       "            0.1475 , 0.1473 , 0.1466 , 0.1455 , 0.1451 , 0.1448 , 0.1423 ,\n",
       "            0.141  , 0.1409 , 0.1395 , 0.138  , 0.1367 , 0.1355 , 0.134  ,\n",
       "            0.1311 , 0.1309 , 0.1295 , 0.1294 , 0.1292 , 0.1289 , 0.1278 ,\n",
       "            0.1277 , 0.127  , 0.1267 , 0.1265 , 0.126  , 0.1245 , 0.124  ,\n",
       "            0.12366, 0.1232 , 0.12305, 0.1223 , 0.1222 , 0.12213, 0.12115,\n",
       "            0.1198 , 0.1195 , 0.118  , 0.1174 , 0.11694, 0.11676, 0.11633,\n",
       "            0.11597, 0.11554, 0.1136 , 0.1134 , 0.1126 , 0.1122 , 0.112  ,\n",
       "            0.11145, 0.11084, 0.1103 , 0.1097 , 0.1095 , 0.10895, 0.10876,\n",
       "            0.1076 , 0.1067 , 0.10596, 0.1047 , 0.1041 , 0.10376, 0.10284,\n",
       "            0.1025 , 0.1005 , 0.0997 , 0.0986 , 0.0957 , 0.09485, 0.09467,\n",
       "            0.0942 , 0.09125, 0.089  , 0.0885 , 0.0873 , 0.0854 , 0.0848 ,\n",
       "            0.0833 , 0.0789 , 0.0786 , 0.0775 , 0.07684, 0.07434, 0.0741 ,\n",
       "            0.0734 , 0.07263, 0.0721 , 0.07007, 0.0695 , 0.0645 , 0.0635 ,\n",
       "            0.0621 , 0.05988, 0.05603], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.1641791 , 0.1716418 ,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.23880596, 0.23880596,\n",
       "            0.23880596, 0.26119402, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29104477, 0.29104477, 0.29850745,\n",
       "            0.29850745, 0.29850745, 0.30597016, 0.30597016, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6119403 ,\n",
       "            0.6119403 , 0.619403  , 0.619403  , 0.6268657 , 0.6268657 ,\n",
       "            0.6268657 , 0.6268657 , 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 , 0.73134327,\n",
       "            0.73134327, 0.74626863, 0.75373137, 0.75373137, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7761194 , 0.7835821 ,\n",
       "            0.7835821 , 0.7835821 , 0.7910448 , 0.7910448 , 0.79850745,\n",
       "            0.79850745, 0.80597013, 0.80597013, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.8208955 , 0.82835823, 0.8358209 , 0.8358209 ,\n",
       "            0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 , 0.8507463 ,\n",
       "            0.8507463 , 0.8507463 , 0.85820895, 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.880597  , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.91791046, 0.91791046, 0.92537314, 0.9328358 , 0.9328358 ,\n",
       "            0.9328358 , 0.9328358 , 0.9402985 , 0.9477612 , 0.9477612 ,\n",
       "            0.95522386, 0.95522386, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.98507464, 0.9925373 , 0.9925373 ,\n",
       "            0.9925373 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.03448276, 0.04310345, 0.05172414, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.0862069 , 0.09482758, 0.10344828, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.14655173, 0.14655173, 0.14655173,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.15517241, 0.15517241,\n",
       "            0.1637931 , 0.1637931 , 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18103448, 0.18103448, 0.18103448, 0.18965517, 0.18965517,\n",
       "            0.18965517, 0.18965517, 0.18965517, 0.18965517, 0.18965517,\n",
       "            0.18965517, 0.18965517, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.21551724, 0.21551724, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.23275863, 0.25      , 0.25862068, 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.27586207, 0.28448275, 0.28448275,\n",
       "            0.28448275, 0.28448275, 0.29310346, 0.29310346, 0.30172414,\n",
       "            0.30172414, 0.31896552, 0.3275862 , 0.3275862 , 0.33620688,\n",
       "            0.33620688, 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.38793105, 0.38793105, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.41379312, 0.41379312, 0.41379312, 0.41379312,\n",
       "            0.41379312, 0.4224138 , 0.4224138 , 0.4224138 , 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.44827586, 0.44827586, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.46551725, 0.46551725,\n",
       "            0.46551725, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.54310346, 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.6034483 , 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.62068963, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.8189655 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.86206895, 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3606 , 0.3538 , 0.3489 , 0.3481 , 0.345  , 0.3433 ,\n",
       "            0.3394 , 0.3374 , 0.3357 , 0.335  , 0.3335 , 0.3328 , 0.331  ,\n",
       "            0.33   , 0.328  , 0.3262 , 0.325  , 0.3245 , 0.3235 , 0.3232 ,\n",
       "            0.3225 , 0.3218 , 0.3215 , 0.3208 , 0.3196 , 0.3171 , 0.3162 ,\n",
       "            0.315  , 0.3147 , 0.3145 , 0.3142 , 0.3137 , 0.3127 , 0.3123 ,\n",
       "            0.312  , 0.3118 , 0.3113 , 0.3103 , 0.3096 , 0.3093 , 0.3086 ,\n",
       "            0.3079 , 0.3076 , 0.3074 , 0.3064 , 0.3062 , 0.306  , 0.3057 ,\n",
       "            0.3052 , 0.304  , 0.3025 , 0.3022 , 0.3018 , 0.3013 , 0.3003 ,\n",
       "            0.2993 , 0.2986 , 0.2983 , 0.298  , 0.2979 , 0.2976 , 0.297  ,\n",
       "            0.2969 , 0.295  , 0.2944 , 0.293  , 0.2925 , 0.2922 , 0.2908 ,\n",
       "            0.2903 , 0.2886 , 0.2874 , 0.2866 , 0.2856 , 0.2854 , 0.285  ,\n",
       "            0.2832 , 0.2817 , 0.2805 , 0.28   , 0.279  , 0.2786 , 0.277  ,\n",
       "            0.2766 , 0.275  , 0.2747 , 0.2744 , 0.2725 , 0.2722 , 0.2688 ,\n",
       "            0.2683 , 0.2678 , 0.2664 , 0.266  , 0.2642 , 0.264  , 0.2637 ,\n",
       "            0.2625 , 0.2573 , 0.2566 , 0.2466 , 0.244  , 0.2437 , 0.2418 ,\n",
       "            0.241  , 0.2394 , 0.2382 , 0.235  , 0.2335 , 0.2297 , 0.2255 ,\n",
       "            0.222  , 0.2139 , 0.2115 , 0.2103 , 0.2098 , 0.2056 , 0.1987 ,\n",
       "            0.1953 , 0.1892 , 0.1886 , 0.1842 , 0.1841 , 0.1823 , 0.1813 ,\n",
       "            0.1808 , 0.1798 , 0.1748 , 0.1731 , 0.1727 , 0.1716 , 0.1708 ,\n",
       "            0.1707 , 0.1693 , 0.1677 , 0.1666 , 0.1663 , 0.1649 , 0.1622 ,\n",
       "            0.1605 , 0.1594 , 0.159  , 0.1589 , 0.158  , 0.1561 , 0.1549 ,\n",
       "            0.1539 , 0.1534 , 0.1512 , 0.1504 , 0.1493 , 0.1477 , 0.1475 ,\n",
       "            0.1471 , 0.1465 , 0.1458 , 0.1447 , 0.1433 , 0.1428 , 0.1426 ,\n",
       "            0.1416 , 0.1415 , 0.141  , 0.1409 , 0.1403 , 0.1394 , 0.1392 ,\n",
       "            0.1389 , 0.1384 , 0.1377 , 0.1373 , 0.137  , 0.1351 , 0.1349 ,\n",
       "            0.1337 , 0.1334 , 0.1332 , 0.1328 , 0.1326 , 0.131  , 0.13   ,\n",
       "            0.129  , 0.1284 , 0.1278 , 0.127  , 0.1267 , 0.1251 , 0.1249 ,\n",
       "            0.12305, 0.1226 , 0.1225 , 0.12146, 0.12115, 0.1201 , 0.1195 ,\n",
       "            0.1194 , 0.11633, 0.11615, 0.1152 , 0.11456, 0.11395, 0.1124 ,\n",
       "            0.1103 , 0.1097 , 0.1069 , 0.1054 , 0.1045 , 0.1025 , 0.0995 ,\n",
       "            0.09894, 0.0977 , 0.09485, 0.0933 , 0.0925 , 0.09204, 0.09106,\n",
       "            0.0909 , 0.09076, 0.0888 , 0.0883 , 0.088  , 0.0871 , 0.0802 ,\n",
       "            0.07556, 0.07544, 0.0729 , 0.0698 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.13432837, 0.14179105,\n",
       "            0.14179105, 0.15671642, 0.1641791 , 0.17910448, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23880596,\n",
       "            0.23880596, 0.24626866, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2761194 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.6641791 ,\n",
       "            0.6641791 , 0.6641791 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.75373137, 0.76119405, 0.76119405, 0.76119405, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7761194 , 0.7761194 , 0.7835821 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.8731343 , 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.91791046, 0.91791046, 0.9328358 ,\n",
       "            0.9328358 , 0.9328358 , 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 , 0.97761196,\n",
       "            0.97761196, 0.97761196, 0.98507464, 0.98507464, 0.98507464,\n",
       "            0.9925373 , 0.9925373 , 0.9925373 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.25      , 0.25862068, 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.3275862 ,\n",
       "            0.33620688, 0.33620688, 0.33620688, 0.3448276 , 0.3448276 ,\n",
       "            0.3448276 , 0.3448276 , 0.35344827, 0.36206895, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.38793105, 0.38793105,\n",
       "            0.38793105, 0.38793105, 0.38793105, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.41379312, 0.41379312, 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.4224138 , 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43103448, 0.43103448,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.44827586, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.45689654, 0.45689654, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.46551725, 0.46551725,\n",
       "            0.46551725, 0.46551725, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.4827586 , 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.54310346, 0.54310346,\n",
       "            0.54310346, 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.57758623, 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 0.9913793 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3762 , 0.372  , 0.3691 , 0.3687 , 0.3677 , 0.3672 ,\n",
       "            0.3665 , 0.3645 , 0.3638 , 0.3628 , 0.3584 , 0.3572 , 0.357  ,\n",
       "            0.3552 , 0.3542 , 0.3538 , 0.3528 , 0.3516 , 0.3486 , 0.3452 ,\n",
       "            0.3435 , 0.343  , 0.3428 , 0.3386 , 0.3374 , 0.337  , 0.3367 ,\n",
       "            0.3362 , 0.336  , 0.3335 , 0.3323 , 0.3315 , 0.3313 , 0.3298 ,\n",
       "            0.3271 , 0.326  , 0.3247 , 0.3232 , 0.3225 , 0.322  , 0.3215 ,\n",
       "            0.3203 , 0.32   , 0.3196 , 0.3186 , 0.318  , 0.3176 , 0.3167 ,\n",
       "            0.3152 , 0.3147 , 0.314  , 0.3137 , 0.3135 , 0.3115 , 0.3093 ,\n",
       "            0.307  , 0.3054 , 0.3047 , 0.3022 , 0.302  , 0.2993 , 0.299  ,\n",
       "            0.2988 , 0.2983 , 0.2976 , 0.2974 , 0.2961 , 0.296  , 0.2954 ,\n",
       "            0.2952 , 0.295  , 0.2947 , 0.2915 , 0.2908 , 0.2888 , 0.2886 ,\n",
       "            0.2883 , 0.2878 , 0.2874 , 0.2869 , 0.2852 , 0.2847 , 0.284  ,\n",
       "            0.2822 , 0.282  , 0.281  , 0.28   , 0.2786 , 0.278  , 0.2732 ,\n",
       "            0.273  , 0.2715 , 0.2708 , 0.2664 , 0.2659 , 0.2654 , 0.263  ,\n",
       "            0.2627 , 0.2595 , 0.2588 , 0.2576 , 0.2566 , 0.256  , 0.255  ,\n",
       "            0.251  , 0.2483 , 0.2477 , 0.2452 , 0.2445 , 0.2422 , 0.2418 ,\n",
       "            0.2413 , 0.2405 , 0.2397 , 0.2346 , 0.2338 , 0.2292 , 0.2255 ,\n",
       "            0.2173 , 0.2172 , 0.2139 , 0.2134 , 0.2085 , 0.2064 , 0.2017 ,\n",
       "            0.2015 , 0.2012 , 0.1985 , 0.197  , 0.1953 , 0.1942 , 0.194  ,\n",
       "            0.1891 , 0.189  , 0.1873 , 0.1866 , 0.1863 , 0.1816 , 0.1808 ,\n",
       "            0.1799 , 0.1794 , 0.1792 , 0.179  , 0.1785 , 0.1783 , 0.178  ,\n",
       "            0.1766 , 0.1744 , 0.1733 , 0.1725 , 0.171  , 0.1705 , 0.1696 ,\n",
       "            0.1682 , 0.1678 , 0.1665 , 0.1664 , 0.1663 , 0.1647 , 0.1643 ,\n",
       "            0.1635 , 0.1626 , 0.1624 , 0.1614 , 0.1602 , 0.1599 , 0.1598 ,\n",
       "            0.1592 , 0.1567 , 0.1561 , 0.156  , 0.1559 , 0.1558 , 0.1555 ,\n",
       "            0.1545 , 0.1528 , 0.1517 , 0.1515 , 0.1514 , 0.1512 , 0.1499 ,\n",
       "            0.1497 , 0.1462 , 0.1455 , 0.1454 , 0.1448 , 0.144  , 0.1439 ,\n",
       "            0.1422 , 0.1411 , 0.1403 , 0.1394 , 0.1382 , 0.1372 , 0.1368 ,\n",
       "            0.1366 , 0.1365 , 0.1357 , 0.1342 , 0.1338 , 0.1327 , 0.1313 ,\n",
       "            0.1309 , 0.1268 , 0.1265 , 0.1256 , 0.1236 , 0.12213, 0.12115,\n",
       "            0.1144 , 0.1122 , 0.112  , 0.111  , 0.11066, 0.1105 , 0.1103 ,\n",
       "            0.1095 , 0.1069 , 0.1065 , 0.10614, 0.1058 , 0.10376, 0.1034 ,\n",
       "            0.10266, 0.0979 , 0.0899 , 0.0885 , 0.0871 , 0.08527],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.64179105, 0.6567164 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.6641791 , 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.69402987, 0.70149255, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.74626863, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.76865673, 0.76865673, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7835821 , 0.7835821 , 0.7910448 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.80597013, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.8208955 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8432836 , 0.8507463 , 0.8507463 , 0.8507463 , 0.85820895,\n",
       "            0.85820895, 0.85820895, 0.86567163, 0.86567163, 0.86567163,\n",
       "            0.8731343 , 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9402985 , 0.9402985 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.95522386, 0.95522386,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.98507464, 0.98507464,\n",
       "            0.9925373 , 0.9925373 , 0.9925373 , 0.9925373 , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43965518, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.45689654, 0.45689654, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.45689654, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.47413793, 0.47413793,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.47413793, 0.47413793,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.4827586 , 0.4827586 ,\n",
       "            0.4827586 , 0.4827586 , 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.5344828 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5603448 , 0.5603448 ,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7155172 , 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.8534483 , 0.8534483 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4104 , 0.4062 , 0.4043 , 0.4038 , 0.4014 , 0.4004 ,\n",
       "            0.3994 , 0.3972 , 0.397  , 0.3962 , 0.3953 , 0.3933 , 0.3926 ,\n",
       "            0.3909 , 0.3887 , 0.388  , 0.387  , 0.3857 , 0.384  , 0.3828 ,\n",
       "            0.381  , 0.3801 , 0.3782 , 0.374  , 0.3738 , 0.3735 , 0.3726 ,\n",
       "            0.3704 , 0.3699 , 0.3694 , 0.3687 , 0.368  , 0.361  , 0.36   ,\n",
       "            0.3599 , 0.3596 , 0.3591 , 0.357  , 0.353  , 0.3525 , 0.3508 ,\n",
       "            0.3428 , 0.3367 , 0.3362 , 0.3333 , 0.328  , 0.3254 , 0.3245 ,\n",
       "            0.3235 , 0.3218 , 0.321  , 0.3208 , 0.3179 , 0.3176 , 0.3157 ,\n",
       "            0.3142 , 0.314  , 0.3127 , 0.3093 , 0.3083 , 0.308  , 0.307  ,\n",
       "            0.3066 , 0.3057 , 0.3018 , 0.3013 , 0.3008 , 0.2993 , 0.2974 ,\n",
       "            0.2966 , 0.2954 , 0.295  , 0.2927 , 0.2913 , 0.2898 , 0.288  ,\n",
       "            0.2864 , 0.2861 , 0.2856 , 0.2852 , 0.2842 , 0.283  , 0.2815 ,\n",
       "            0.2795 , 0.279  , 0.278  , 0.275  , 0.2747 , 0.2737 , 0.2734 ,\n",
       "            0.2722 , 0.2717 , 0.2708 , 0.2695 , 0.269  , 0.268  , 0.2673 ,\n",
       "            0.2646 , 0.2622 , 0.261  , 0.2605 , 0.257  , 0.2546 , 0.2537 ,\n",
       "            0.252  , 0.2502 , 0.2498 , 0.2478 , 0.2467 , 0.2462 , 0.2451 ,\n",
       "            0.2441 , 0.2406 , 0.2399 , 0.2395 , 0.2386 , 0.2382 , 0.2351 ,\n",
       "            0.2332 , 0.2294 , 0.2278 , 0.2269 , 0.2266 , 0.2247 , 0.2229 ,\n",
       "            0.2224 , 0.222  , 0.219  , 0.2186 , 0.2179 , 0.2152 , 0.21   ,\n",
       "            0.208  , 0.207  , 0.2065 , 0.2048 , 0.2042 , 0.2026 , 0.2018 ,\n",
       "            0.2017 , 0.2012 , 0.1989 , 0.1987 , 0.1934 , 0.1927 , 0.1923 ,\n",
       "            0.1885 , 0.1877 , 0.1871 , 0.1869 , 0.1863 , 0.186  , 0.1855 ,\n",
       "            0.185  , 0.1849 , 0.1848 , 0.1837 , 0.1827 , 0.1816 , 0.1815 ,\n",
       "            0.1804 , 0.1792 , 0.1788 , 0.1787 , 0.1779 , 0.1776 , 0.1772 ,\n",
       "            0.1771 , 0.1768 , 0.1761 , 0.1748 , 0.1738 , 0.1736 , 0.1716 ,\n",
       "            0.1705 , 0.1703 , 0.1698 , 0.1694 , 0.1687 , 0.1665 , 0.1659 ,\n",
       "            0.1654 , 0.1653 , 0.1649 , 0.1635 , 0.161  , 0.1603 , 0.1592 ,\n",
       "            0.1586 , 0.1583 , 0.1566 , 0.1556 , 0.1544 , 0.153  , 0.1525 ,\n",
       "            0.1517 , 0.1515 , 0.1514 , 0.1511 , 0.1509 , 0.1499 , 0.1487 ,\n",
       "            0.1448 , 0.1426 , 0.1425 , 0.1418 , 0.14   , 0.1399 , 0.1398 ,\n",
       "            0.1375 , 0.1356 , 0.133  , 0.1326 , 0.131  , 0.1296 , 0.1283 ,\n",
       "            0.1279 , 0.1272 , 0.1268 , 0.12335, 0.12146, 0.1207 , 0.12054,\n",
       "            0.11676, 0.11615, 0.115  , 0.1142 , 0.1041 , 0.10126, 0.1011 ,\n",
       "            0.1009 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.64179105, 0.6492537 , 0.6641791 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6791045 , 0.6791045 , 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.70149255, 0.70149255,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.74626863, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.79850745, 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.8208955 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.85820895, 0.85820895,\n",
       "            0.86567163, 0.86567163, 0.8731343 , 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.91791046, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.97761196, 0.98507464, 0.98507464,\n",
       "            0.9925373 , 0.9925373 , 0.9925373 , 0.9925373 , 0.9925373 ,\n",
       "            0.9925373 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.4051724 ,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.47413793, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.4827586 , 0.4827586 , 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5086207 , 0.5086207 ,\n",
       "            0.5086207 , 0.51724136, 0.51724136, 0.51724136, 0.51724136,\n",
       "            0.51724136, 0.51724136, 0.51724136, 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.54310346, 0.54310346,\n",
       "            0.54310346, 0.54310346, 0.54310346, 0.54310346, 0.54310346,\n",
       "            0.54310346, 0.54310346, 0.54310346, 0.54310346, 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.55172414, 0.55172414, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.5603448 , 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.5689655 , 0.5689655 , 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.57758623, 0.57758623, 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4607 , 0.4575 , 0.4563 , 0.451  , 0.4492 , 0.4473 ,\n",
       "            0.4465 , 0.4463 , 0.4434 , 0.4414 , 0.4412 , 0.4397 , 0.434  ,\n",
       "            0.4321 , 0.427  , 0.4248 , 0.4243 , 0.4236 , 0.4233 , 0.422  ,\n",
       "            0.4185 , 0.4158 , 0.415  , 0.4133 , 0.413  , 0.4128 , 0.4126 ,\n",
       "            0.412  , 0.4094 , 0.4087 , 0.4084 , 0.4077 , 0.4075 , 0.407  ,\n",
       "            0.4055 , 0.4043 , 0.403  , 0.4023 , 0.399  , 0.398  , 0.3936 ,\n",
       "            0.3894 , 0.3735 , 0.37   , 0.368  , 0.367  , 0.3647 , 0.3645 ,\n",
       "            0.3608 , 0.3396 , 0.3347 , 0.3323 , 0.3313 , 0.3276 , 0.3274 ,\n",
       "            0.3271 , 0.3262 , 0.3257 , 0.3242 , 0.323  , 0.3157 , 0.314  ,\n",
       "            0.3125 , 0.3096 , 0.3086 , 0.3079 , 0.3076 , 0.307  , 0.3044 ,\n",
       "            0.303  , 0.3015 , 0.297  , 0.2969 , 0.2954 , 0.2944 , 0.2927 ,\n",
       "            0.2883 , 0.287  , 0.2798 , 0.2795 , 0.2786 , 0.278  , 0.2773 ,\n",
       "            0.277  , 0.2754 , 0.2742 , 0.274  , 0.2737 , 0.2727 , 0.2725 ,\n",
       "            0.27   , 0.2695 , 0.2688 , 0.2664 , 0.266  , 0.2659 , 0.2654 ,\n",
       "            0.2634 , 0.263  , 0.261  , 0.2598 , 0.2588 , 0.2583 , 0.2573 ,\n",
       "            0.2554 , 0.2542 , 0.254  , 0.2512 , 0.251  , 0.2507 , 0.2502 ,\n",
       "            0.25   , 0.2487 , 0.2483 , 0.248  , 0.2448 , 0.2444 , 0.2438 ,\n",
       "            0.2429 , 0.2426 , 0.2411 , 0.2406 , 0.2402 , 0.2401 , 0.2388 ,\n",
       "            0.2383 , 0.2379 , 0.2375 , 0.2368 , 0.2356 , 0.2346 , 0.2343 ,\n",
       "            0.2332 , 0.2325 , 0.2313 , 0.2311 , 0.2295 , 0.228  , 0.2277 ,\n",
       "            0.2274 , 0.2242 , 0.2239 , 0.2234 , 0.2233 , 0.2224 , 0.2208 ,\n",
       "            0.2205 , 0.2194 , 0.219  , 0.2181 , 0.217  , 0.2153 , 0.2147 ,\n",
       "            0.2145 , 0.2139 , 0.2137 , 0.2125 , 0.212  , 0.2109 , 0.2096 ,\n",
       "            0.2094 , 0.209  , 0.2085 , 0.2075 , 0.207  , 0.2042 , 0.2031 ,\n",
       "            0.2028 , 0.2026 , 0.2012 , 0.2002 , 0.1993 , 0.1985 , 0.1984 ,\n",
       "            0.1954 , 0.195  , 0.1946 , 0.1942 , 0.1941 , 0.1936 , 0.1929 ,\n",
       "            0.1907 , 0.19   , 0.1898 , 0.1893 , 0.1892 , 0.1891 , 0.188  ,\n",
       "            0.1876 , 0.1871 , 0.187  , 0.1823 , 0.1782 , 0.1765 , 0.1754 ,\n",
       "            0.1735 , 0.1726 , 0.1724 , 0.1708 , 0.1707 , 0.1699 , 0.1692 ,\n",
       "            0.1688 , 0.1685 , 0.1669 , 0.1649 , 0.1648 , 0.1647 , 0.1625 ,\n",
       "            0.1611 , 0.1608 , 0.1602 , 0.1592 , 0.159  , 0.1559 , 0.154  ,\n",
       "            0.1534 , 0.1523 , 0.1509 , 0.1505 , 0.1482 , 0.144  , 0.1421 ,\n",
       "            0.1414 , 0.1372 , 0.1367 , 0.1318 , 0.1261 , 0.12476, 0.1236 ,\n",
       "            0.1216 , 0.1188 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.05172414, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.33582088,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 , 0.7238806 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.75373137, 0.76119405, 0.76119405, 0.76865673,\n",
       "            0.76865673, 0.7761194 , 0.7910448 , 0.7910448 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.82835823, 0.8358209 , 0.8507463 , 0.8507463 , 0.85820895,\n",
       "            0.85820895, 0.85820895, 0.86567163, 0.86567163, 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.880597  , 0.8880597 , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.92537314, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.95522386, 0.96268654, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.97761196, 0.98507464, 0.98507464,\n",
       "            0.98507464, 0.98507464, 0.98507464, 0.98507464, 0.9925373 ,\n",
       "            0.9925373 , 0.9925373 , 0.9925373 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.5       , 0.5       , 0.5086207 ,\n",
       "            0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 ,\n",
       "            0.5086207 , 0.5086207 , 0.5086207 , 0.51724136, 0.51724136,\n",
       "            0.51724136, 0.51724136, 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.5258621 , 0.5344828 , 0.5344828 , 0.5344828 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.55172414, 0.55172414, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.57758623, 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.57758623, 0.57758623, 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.57758623, 0.57758623, 0.5862069 , 0.6034483 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6551724 , 0.6551724 , 0.6551724 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6551724 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.70689654, 0.70689654,\n",
       "            0.70689654, 0.70689654, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.70689654, 0.70689654, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7155172 , 0.7155172 , 0.7155172 ,\n",
       "            0.7155172 , 0.7155172 , 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.76724136, 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5146, 0.514 , 0.51  , 0.5093, 0.5054, 0.501 , 0.493 ,\n",
       "            0.4907, 0.4897, 0.488 , 0.487 , 0.4822, 0.4766, 0.476 , 0.4746,\n",
       "            0.471 , 0.468 , 0.4678, 0.4666, 0.4658, 0.4648, 0.4597, 0.4583,\n",
       "            0.457 , 0.456 , 0.4558, 0.4524, 0.4507, 0.4495, 0.4492, 0.4465,\n",
       "            0.4453, 0.4443, 0.444 , 0.4436, 0.4404, 0.4365, 0.434 , 0.432 ,\n",
       "            0.4302, 0.427 , 0.4258, 0.4226, 0.4148, 0.4126, 0.407 , 0.4067,\n",
       "            0.4011, 0.3975, 0.3928, 0.3765, 0.3752, 0.36  , 0.358 , 0.3562,\n",
       "            0.3513, 0.3503, 0.346 , 0.3452, 0.3442, 0.3428, 0.3418, 0.3303,\n",
       "            0.3264, 0.3242, 0.3237, 0.321 , 0.316 , 0.314 , 0.3132, 0.3113,\n",
       "            0.3108, 0.3098, 0.3066, 0.3064, 0.304 , 0.3027, 0.3022, 0.298 ,\n",
       "            0.2969, 0.296 , 0.2957, 0.2954, 0.2952, 0.2947, 0.2935, 0.2925,\n",
       "            0.2922, 0.2869, 0.285 , 0.2822, 0.2817, 0.2803, 0.2795, 0.2793,\n",
       "            0.2783, 0.2761, 0.276 , 0.2727, 0.2708, 0.2698, 0.2688, 0.2683,\n",
       "            0.2678, 0.267 , 0.2654, 0.2646, 0.2642, 0.2632, 0.263 , 0.2622,\n",
       "            0.262 , 0.261 , 0.2605, 0.2598, 0.2595, 0.2593, 0.2585, 0.258 ,\n",
       "            0.2576, 0.254 , 0.2522, 0.2517, 0.2515, 0.2512, 0.2502, 0.2494,\n",
       "            0.2485, 0.2478, 0.2473, 0.2466, 0.2452, 0.2448, 0.2445, 0.2438,\n",
       "            0.2428, 0.2421, 0.2411, 0.241 , 0.2401, 0.2386, 0.2384, 0.2383,\n",
       "            0.2375, 0.237 , 0.236 , 0.2356, 0.2343, 0.2339, 0.2338, 0.2335,\n",
       "            0.2334, 0.233 , 0.231 , 0.2306, 0.2295, 0.2294, 0.228 , 0.2274,\n",
       "            0.2272, 0.2263, 0.2256, 0.2251, 0.2249, 0.2246, 0.2234, 0.223 ,\n",
       "            0.2227, 0.222 , 0.2203, 0.22  , 0.2198, 0.219 , 0.2184, 0.218 ,\n",
       "            0.2179, 0.217 , 0.2142, 0.214 , 0.2129, 0.2124, 0.2108, 0.2104,\n",
       "            0.2098, 0.2096, 0.2094, 0.2065, 0.2054, 0.2043, 0.2035, 0.202 ,\n",
       "            0.2007, 0.2004, 0.2002, 0.2001, 0.1984, 0.1964, 0.1959, 0.1952,\n",
       "            0.1947, 0.1942, 0.1919, 0.1909, 0.1898, 0.1893, 0.189 , 0.1886,\n",
       "            0.1877, 0.1855, 0.185 , 0.1842, 0.1837, 0.1835, 0.183 , 0.1819,\n",
       "            0.1803, 0.1799, 0.1788, 0.1785, 0.1782, 0.1765, 0.1718, 0.171 ,\n",
       "            0.1707, 0.1681, 0.1666, 0.1653, 0.1594, 0.1543, 0.1508, 0.15  ,\n",
       "            0.1478, 0.1444, 0.139 , 0.1389], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.20689656, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20895523, 0.21641791,\n",
       "            0.21641791, 0.2238806 , 0.2238806 , 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.2835821 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.619403  , 0.619403  , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6567164 ,\n",
       "            0.67164177, 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.8134328 , 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8358209 , 0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8880597 , 0.8880597 , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.95522386, 0.96268654,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.4827586 , 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5       , 0.5086207 , 0.5086207 ,\n",
       "            0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.51724136, 0.5258621 , 0.5258621 ,\n",
       "            0.5258621 , 0.5258621 , 0.5344828 , 0.5344828 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.5344828 , 0.5344828 ,\n",
       "            0.54310346, 0.54310346, 0.54310346, 0.54310346, 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6637931 , 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.69827586, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.70689654, 0.70689654, 0.7155172 , 0.7155172 , 0.7241379 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 ,\n",
       "            0.8103448 , 0.8103448 , 0.8189655 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.579 , 0.5747, 0.566 , 0.5645, 0.56  , 0.557 , 0.547 ,\n",
       "            0.538 , 0.537 , 0.534 , 0.5312, 0.5303, 0.5264, 0.5254, 0.5244,\n",
       "            0.521 , 0.5195, 0.519 , 0.515 , 0.51  , 0.5054, 0.501 , 0.5005,\n",
       "            0.4983, 0.4973, 0.4956, 0.494 , 0.4912, 0.487 , 0.4868, 0.4849,\n",
       "            0.4802, 0.4792, 0.4778, 0.4736, 0.4724, 0.4707, 0.4656, 0.4636,\n",
       "            0.4626, 0.462 , 0.455 , 0.453 , 0.4473, 0.4456, 0.4424, 0.4321,\n",
       "            0.426 , 0.422 , 0.4219, 0.4016, 0.395 , 0.3843, 0.3833, 0.3823,\n",
       "            0.3816, 0.3755, 0.3684, 0.3638, 0.3564, 0.3481, 0.3457, 0.3452,\n",
       "            0.3374, 0.333 , 0.3325, 0.332 , 0.3303, 0.328 , 0.325 , 0.3247,\n",
       "            0.3235, 0.3228, 0.3223, 0.3176, 0.3154, 0.3142, 0.3123, 0.311 ,\n",
       "            0.3108, 0.3086, 0.3079, 0.3064, 0.3062, 0.3052, 0.3042, 0.3025,\n",
       "            0.3   , 0.2986, 0.2966, 0.2957, 0.295 , 0.2935, 0.2932, 0.293 ,\n",
       "            0.2913, 0.2908, 0.2905, 0.2903, 0.29  , 0.2898, 0.2893, 0.2888,\n",
       "            0.288 , 0.2866, 0.2864, 0.2834, 0.282 , 0.2812, 0.2795, 0.278 ,\n",
       "            0.2776, 0.2754, 0.2737, 0.2715, 0.271 , 0.2705, 0.27  , 0.2695,\n",
       "            0.2693, 0.2676, 0.2664, 0.266 , 0.2644, 0.2632, 0.2612, 0.261 ,\n",
       "            0.2607, 0.2605, 0.258 , 0.2573, 0.2568, 0.2563, 0.2559, 0.2554,\n",
       "            0.255 , 0.2544, 0.253 , 0.2524, 0.2522, 0.2515, 0.251 , 0.2507,\n",
       "            0.2498, 0.2487, 0.2483, 0.2478, 0.247 , 0.2462, 0.2448, 0.2437,\n",
       "            0.2417, 0.241 , 0.2406, 0.2395, 0.2382, 0.2378, 0.2372, 0.2347,\n",
       "            0.2344, 0.2339, 0.2327, 0.2322, 0.2319, 0.2318, 0.2313, 0.2306,\n",
       "            0.2301, 0.2297, 0.2285, 0.2281, 0.2268, 0.2266, 0.2261, 0.2255,\n",
       "            0.2252, 0.2247, 0.2235, 0.2233, 0.2225, 0.222 , 0.2213, 0.2211,\n",
       "            0.2207, 0.2195, 0.2194, 0.2185, 0.2184, 0.2177, 0.2172, 0.2167,\n",
       "            0.2163, 0.2162, 0.215 , 0.2148, 0.2139, 0.213 , 0.2129, 0.2113,\n",
       "            0.2109, 0.2101, 0.2098, 0.2084, 0.2081, 0.2079, 0.206 , 0.2051,\n",
       "            0.2029, 0.2028, 0.2007, 0.2004, 0.1998, 0.1996, 0.1991, 0.1985,\n",
       "            0.1981, 0.1947, 0.1931, 0.1919, 0.1891, 0.1821, 0.182 , 0.1819,\n",
       "            0.1779, 0.1716, 0.1709, 0.1694, 0.1682, 0.1653, 0.1602, 0.1592,\n",
       "            0.1511], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.33620688, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.1716418 , 0.17910448, 0.17910448,\n",
       "            0.18656716, 0.18656716, 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23880596,\n",
       "            0.24626866, 0.26119402, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.3283582 , 0.33582088, 0.35074627,\n",
       "            0.35820895, 0.35820895, 0.36567163, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.48507464, 0.49253732, 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.6641791 , 0.6641791 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.7238806 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.880597  , 0.8880597 , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.9328358 , 0.9328358 , 0.9328358 , 0.9402985 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.9701493 ,\n",
       "            0.97761196, 0.97761196, 0.98507464, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.4827586 , 0.4827586 , 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.5258621 , 0.5344828 , 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.54310346, 0.54310346,\n",
       "            0.54310346, 0.5603448 , 0.5603448 , 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.62931037, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7155172 , 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.8189655 , 0.82758623, 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6323, 0.6245, 0.6157, 0.6104, 0.6045, 0.603 , 0.592 ,\n",
       "            0.5796, 0.579 , 0.5767, 0.5737, 0.5728, 0.57  , 0.568 , 0.5664,\n",
       "            0.5625, 0.5596, 0.553 , 0.5493, 0.5386, 0.5376, 0.537 , 0.534 ,\n",
       "            0.5317, 0.5312, 0.531 , 0.5303, 0.5205, 0.518 , 0.515 , 0.514 ,\n",
       "            0.5127, 0.511 , 0.5073, 0.507 , 0.503 , 0.5024, 0.4963, 0.4954,\n",
       "            0.4922, 0.4912, 0.481 , 0.4773, 0.4768, 0.476 , 0.4707, 0.4587,\n",
       "            0.4495, 0.4468, 0.4456, 0.4363, 0.4229, 0.4143, 0.4119, 0.4014,\n",
       "            0.3953, 0.3887, 0.3813, 0.3782, 0.3767, 0.375 , 0.3674, 0.3672,\n",
       "            0.3652, 0.351 , 0.3472, 0.3464, 0.3435, 0.34  , 0.3381, 0.3325,\n",
       "            0.332 , 0.3298, 0.327 , 0.325 , 0.3237, 0.3228, 0.322 , 0.3213,\n",
       "            0.321 , 0.3206, 0.3193, 0.3188, 0.3186, 0.3162, 0.3147, 0.313 ,\n",
       "            0.3108, 0.3093, 0.307 , 0.306 , 0.3044, 0.3025, 0.3018, 0.3005,\n",
       "            0.2996, 0.2986, 0.297 , 0.2954, 0.295 , 0.2915, 0.29  , 0.2888,\n",
       "            0.2876, 0.2874, 0.2864, 0.2856, 0.285 , 0.2834, 0.2827, 0.2795,\n",
       "            0.2786, 0.278 , 0.2776, 0.2773, 0.2766, 0.2761, 0.275 , 0.2744,\n",
       "            0.2742, 0.2708, 0.2703, 0.2688, 0.2686, 0.2642, 0.2637, 0.263 ,\n",
       "            0.2615, 0.2612, 0.2605, 0.2595, 0.2578, 0.2556, 0.2542, 0.2527,\n",
       "            0.2524, 0.252 , 0.2505, 0.25  , 0.2478, 0.2477, 0.2471, 0.2467,\n",
       "            0.2462, 0.246 , 0.2458, 0.2452, 0.243 , 0.2421, 0.2418, 0.241 ,\n",
       "            0.2399, 0.2397, 0.2391, 0.2372, 0.2356, 0.2352, 0.2351, 0.2339,\n",
       "            0.2335, 0.2323, 0.2318, 0.2316, 0.2306, 0.2303, 0.2301, 0.2294,\n",
       "            0.2286, 0.2285, 0.2278, 0.2273, 0.2268, 0.2264, 0.2252, 0.2251,\n",
       "            0.224 , 0.2234, 0.2233, 0.223 , 0.2229, 0.2224, 0.2222, 0.2213,\n",
       "            0.2208, 0.2202, 0.219 , 0.2168, 0.2156, 0.215 , 0.2145, 0.2135,\n",
       "            0.2133, 0.2124, 0.212 , 0.2106, 0.209 , 0.2089, 0.2079, 0.2065,\n",
       "            0.2064, 0.206 , 0.2059, 0.2054, 0.2034, 0.2031, 0.2021, 0.1998,\n",
       "            0.1953, 0.195 , 0.1913, 0.19  , 0.1882, 0.1865, 0.1858, 0.1831,\n",
       "            0.183 , 0.1821, 0.1792, 0.179 , 0.1749, 0.1705, 0.164 , 0.1562,\n",
       "            0.1483, 0.143 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.4051724, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.11940298, 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.26119402, 0.26865673, 0.26865673,\n",
       "            0.2761194 , 0.2761194 , 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.47014925, 0.48507464, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76119405, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7761194 , 0.7910448 , 0.79850745, 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8134328 , 0.82835823, 0.8358209 , 0.8507463 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.91791046, 0.92537314,\n",
       "            0.9402985 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.0775862 , 0.09482758,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.4827586 , 0.49137932, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.54310346, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.62068963, 0.62068963, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6865, 0.677 , 0.6675, 0.659 , 0.6543, 0.65  , 0.6396,\n",
       "            0.624 , 0.6235, 0.615 , 0.614 , 0.61  , 0.607 , 0.6035, 0.603 ,\n",
       "            0.5977, 0.588 , 0.579 , 0.5767, 0.5757, 0.5747, 0.5723, 0.5684,\n",
       "            0.567 , 0.5566, 0.556 , 0.5537, 0.5464, 0.545 , 0.543 , 0.539 ,\n",
       "            0.5386, 0.534 , 0.5283, 0.526 , 0.5225, 0.5215, 0.5146, 0.51  ,\n",
       "            0.502 , 0.4946, 0.493 , 0.4744, 0.4702, 0.4697, 0.4644, 0.4502,\n",
       "            0.4434, 0.4404, 0.4214, 0.4148, 0.403 , 0.402 , 0.3975, 0.396 ,\n",
       "            0.3953, 0.3948, 0.3926, 0.3772, 0.3762, 0.3728, 0.3704, 0.3662,\n",
       "            0.3657, 0.362 , 0.36  , 0.3503, 0.35  , 0.3486, 0.3484, 0.344 ,\n",
       "            0.3433, 0.3423, 0.34  , 0.3394, 0.338 , 0.334 , 0.3315, 0.3313,\n",
       "            0.331 , 0.3306, 0.3298, 0.3293, 0.3284, 0.3267, 0.325 , 0.323 ,\n",
       "            0.3228, 0.3208, 0.3203, 0.32  , 0.3193, 0.3188, 0.3186, 0.3176,\n",
       "            0.3093, 0.306 , 0.3025, 0.3018, 0.301 , 0.2998, 0.2986, 0.2964,\n",
       "            0.2944, 0.2942, 0.294 , 0.2932, 0.292 , 0.2908, 0.2905, 0.2893,\n",
       "            0.2878, 0.2876, 0.286 , 0.285 , 0.284 , 0.2834, 0.2832, 0.282 ,\n",
       "            0.281 , 0.2788, 0.2776, 0.2764, 0.2737, 0.2734, 0.272 , 0.2712,\n",
       "            0.2708, 0.27  , 0.268 , 0.2673, 0.2668, 0.2646, 0.2627, 0.2603,\n",
       "            0.2593, 0.2578, 0.2573, 0.2568, 0.2563, 0.255 , 0.2532, 0.251 ,\n",
       "            0.2496, 0.249 , 0.2485, 0.2483, 0.246 , 0.2449, 0.2433, 0.2424,\n",
       "            0.2422, 0.2413, 0.2411, 0.241 , 0.2406, 0.2401, 0.2397, 0.239 ,\n",
       "            0.2383, 0.2379, 0.2352, 0.2346, 0.234 , 0.2335, 0.2313, 0.2306,\n",
       "            0.2294, 0.2289, 0.2273, 0.2244, 0.223 , 0.2227, 0.222 , 0.2213,\n",
       "            0.2203, 0.2181, 0.2162, 0.2157, 0.2156, 0.2145, 0.2135, 0.2133,\n",
       "            0.213 , 0.2128, 0.2123, 0.2115, 0.2106, 0.2101, 0.21  , 0.2098,\n",
       "            0.209 , 0.2086, 0.2064, 0.2056, 0.2009, 0.1984, 0.1979, 0.1974,\n",
       "            0.195 , 0.1948, 0.1941, 0.194 , 0.1937, 0.1919, 0.1912, 0.1877,\n",
       "            0.1863, 0.1849, 0.1837, 0.1796, 0.1748, 0.1714, 0.1678, 0.1663,\n",
       "            0.1592, 0.1587, 0.1472, 0.1326, 0.1274], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.44827586, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.10447761, 0.10447761, 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.19402985, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.20895523, 0.21641791,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.31343284, 0.32089552, 0.32089552, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.6492537 , 0.6492537 , 0.6567164 , 0.6567164 , 0.6567164 ,\n",
       "            0.6641791 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7835821 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.31034482,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5086207 , 0.5086207 , 0.51724136, 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62068963, 0.62068963, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 , 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.743  , 0.731  , 0.7227 , 0.7104 , 0.707  , 0.6987 ,\n",
       "            0.6914 , 0.68   , 0.6763 , 0.6724 , 0.672  , 0.6675 , 0.6665 ,\n",
       "            0.66   , 0.6577 , 0.6543 , 0.6514 , 0.649  , 0.6475 , 0.629  ,\n",
       "            0.6284 , 0.622  , 0.6216 , 0.621  , 0.616  , 0.613  , 0.6094 ,\n",
       "            0.609  , 0.604  , 0.598  , 0.5947 , 0.594  , 0.584  , 0.58   ,\n",
       "            0.5747 , 0.5723 , 0.569  , 0.56   , 0.559  , 0.5586 , 0.5557 ,\n",
       "            0.5537 , 0.5513 , 0.5435 , 0.531  , 0.5176 , 0.517  , 0.506  ,\n",
       "            0.502  , 0.4888 , 0.4858 , 0.4841 , 0.4824 , 0.4497 , 0.4492 ,\n",
       "            0.4463 , 0.4453 , 0.4429 , 0.4397 , 0.4258 , 0.4219 , 0.4194 ,\n",
       "            0.4167 , 0.415  , 0.4136 , 0.4048 , 0.4019 , 0.4    , 0.3987 ,\n",
       "            0.3977 , 0.393  , 0.388  , 0.3843 , 0.383  , 0.3826 , 0.3818 ,\n",
       "            0.3804 , 0.3792 , 0.3733 , 0.3718 , 0.3667 , 0.3647 , 0.3628 ,\n",
       "            0.3613 , 0.3586 , 0.3574 , 0.357  , 0.3516 , 0.3513 , 0.3496 ,\n",
       "            0.3472 , 0.3457 , 0.344  , 0.3425 , 0.3403 , 0.34   , 0.3381 ,\n",
       "            0.3367 , 0.3352 , 0.3335 , 0.3328 , 0.3315 , 0.3313 , 0.327  ,\n",
       "            0.326  , 0.3257 , 0.324  , 0.3235 , 0.3232 , 0.323  , 0.321  ,\n",
       "            0.32   , 0.3198 , 0.3152 , 0.3135 , 0.3123 , 0.3115 , 0.311  ,\n",
       "            0.31   , 0.3096 , 0.3093 , 0.305  , 0.3025 , 0.2993 , 0.298  ,\n",
       "            0.292  , 0.291  , 0.2908 , 0.2905 , 0.2898 , 0.2893 , 0.288  ,\n",
       "            0.2856 , 0.285  , 0.2842 , 0.2837 , 0.282  , 0.2812 , 0.2795 ,\n",
       "            0.279  , 0.2788 , 0.278  , 0.2776 , 0.2769 , 0.2761 , 0.2756 ,\n",
       "            0.2754 , 0.2742 , 0.274  , 0.2732 , 0.2727 , 0.2725 , 0.2715 ,\n",
       "            0.271  , 0.2708 , 0.2698 , 0.2695 , 0.2683 , 0.268  , 0.2673 ,\n",
       "            0.2664 , 0.2651 , 0.2642 , 0.2595 , 0.2563 , 0.2532 , 0.2524 ,\n",
       "            0.252  , 0.2512 , 0.251  , 0.2487 , 0.2474 , 0.2458 , 0.2451 ,\n",
       "            0.2449 , 0.2444 , 0.2388 , 0.2352 , 0.2338 , 0.2303 , 0.2295 ,\n",
       "            0.2294 , 0.2283 , 0.2274 , 0.2273 , 0.2263 , 0.2257 , 0.2255 ,\n",
       "            0.2251 , 0.2235 , 0.222  , 0.2216 , 0.2197 , 0.2158 , 0.2147 ,\n",
       "            0.2144 , 0.2125 , 0.2104 , 0.2103 , 0.2098 , 0.2096 , 0.209  ,\n",
       "            0.2084 , 0.2076 , 0.2064 , 0.206  , 0.2059 , 0.2053 , 0.2028 ,\n",
       "            0.201  , 0.199  , 0.1967 , 0.1964 , 0.1956 , 0.1924 , 0.1879 ,\n",
       "            0.1843 , 0.1841 , 0.1816 , 0.181  , 0.179  , 0.1741 , 0.1731 ,\n",
       "            0.1686 , 0.1685 , 0.159  , 0.1562 , 0.1527 , 0.1504 , 0.1439 ,\n",
       "            0.1315 , 0.11816, 0.1124 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00746269, dtype=float32),\n",
       "    'tpr': array(0.46551725, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1641791 , 0.1641791 , 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.25373134, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.29850745, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3880597 , 0.3955224 , 0.3955224 ,\n",
       "            0.3955224 , 0.3955224 , 0.40298507, 0.41044775, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.64179105, 0.6492537 , 0.6567164 , 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.70149255, 0.70149255, 0.70149255, 0.70149255, 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5       ,\n",
       "            0.5086207 , 0.5086207 , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5862069 , 0.5862069 , 0.5948276 , 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.62068963, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6551724 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.8189655 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7847 , 0.7715 , 0.763  , 0.7495 , 0.747  , 0.737  ,\n",
       "            0.7305 , 0.7217 , 0.716  , 0.71   , 0.7095 , 0.707  , 0.705  ,\n",
       "            0.696  , 0.6895 , 0.6885 , 0.6875 , 0.6826 , 0.665  , 0.662  ,\n",
       "            0.6577 , 0.657  , 0.6562 , 0.6484 , 0.6475 , 0.647  , 0.641  ,\n",
       "            0.634  , 0.6313 , 0.6304 , 0.627  , 0.6147 , 0.6084 , 0.6074 ,\n",
       "            0.6035 , 0.603  , 0.6016 , 0.5996 , 0.5903 , 0.589  , 0.586  ,\n",
       "            0.5854 , 0.5825 , 0.5815 , 0.578  , 0.553  , 0.551  , 0.5356 ,\n",
       "            0.529  , 0.5254 , 0.5156 , 0.514  , 0.5107 , 0.498  , 0.482  ,\n",
       "            0.4746 , 0.4727 , 0.4688 , 0.4683 , 0.4626 , 0.462  , 0.4524 ,\n",
       "            0.4463 , 0.445  , 0.4285 , 0.427  , 0.4268 , 0.4211 , 0.4143 ,\n",
       "            0.409  , 0.4084 , 0.405  , 0.4048 , 0.4028 , 0.4023 , 0.4014 ,\n",
       "            0.397  , 0.395  , 0.39   , 0.389  , 0.3853 , 0.384  , 0.3835 ,\n",
       "            0.3818 , 0.3796 , 0.378  , 0.3765 , 0.376  , 0.374  , 0.3687 ,\n",
       "            0.3665 , 0.3662 , 0.365  , 0.3628 , 0.3591 , 0.358  , 0.356  ,\n",
       "            0.3557 , 0.3545 , 0.3542 , 0.3518 , 0.3513 , 0.3508 , 0.3464 ,\n",
       "            0.3435 , 0.3425 , 0.342  , 0.3403 , 0.3396 , 0.339  , 0.3372 ,\n",
       "            0.3357 , 0.3354 , 0.335  , 0.333  , 0.3313 , 0.331  , 0.3289 ,\n",
       "            0.323  , 0.3225 , 0.3218 , 0.3208 , 0.3193 , 0.3167 , 0.3162 ,\n",
       "            0.3157 , 0.311  , 0.3076 , 0.3074 , 0.304  , 0.3022 , 0.302  ,\n",
       "            0.3013 , 0.301  , 0.2983 , 0.2961 , 0.296  , 0.2954 , 0.2952 ,\n",
       "            0.2942 , 0.2915 , 0.2903 , 0.2898 , 0.2876 , 0.2874 , 0.2869 ,\n",
       "            0.286  , 0.2856 , 0.2852 , 0.2842 , 0.284  , 0.2827 , 0.2817 ,\n",
       "            0.2808 , 0.28   , 0.2798 , 0.2793 , 0.279  , 0.278  , 0.2751 ,\n",
       "            0.2747 , 0.272  , 0.2683 , 0.268  , 0.2651 , 0.2646 , 0.2642 ,\n",
       "            0.2634 , 0.2627 , 0.2625 , 0.2615 , 0.261  , 0.259  , 0.258  ,\n",
       "            0.2568 , 0.2566 , 0.2556 , 0.2485 , 0.2449 , 0.2406 , 0.2405 ,\n",
       "            0.2368 , 0.2367 , 0.2366 , 0.2325 , 0.2323 , 0.2272 , 0.2257 ,\n",
       "            0.2222 , 0.2218 , 0.2207 , 0.2189 , 0.218  , 0.2162 , 0.2137 ,\n",
       "            0.2135 , 0.2129 , 0.211  , 0.2109 , 0.2079 , 0.2073 , 0.2028 ,\n",
       "            0.1998 , 0.1993 , 0.1982 , 0.1981 , 0.1974 , 0.1965 , 0.195  ,\n",
       "            0.1943 , 0.1924 , 0.1887 , 0.1885 , 0.183  , 0.1829 , 0.1815 ,\n",
       "            0.181  , 0.1779 , 0.1755 , 0.1718 , 0.1699 , 0.1672 , 0.1644 ,\n",
       "            0.1589 , 0.1534 , 0.1533 , 0.1439 , 0.1417 , 0.1382 , 0.1353 ,\n",
       "            0.1294 , 0.11676, 0.1047 , 0.09894], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.02985075, dtype=float32),\n",
       "    'tpr': array(0.5, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.18656716, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.26865673, 0.2761194 ,\n",
       "            0.2761194 , 0.2761194 , 0.2835821 , 0.2835821 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6567164 , 0.6567164 ,\n",
       "            0.6567164 , 0.6641791 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62068963, 0.62068963, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 , 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.829  , 0.8145 , 0.8076 , 0.792  , 0.791  , 0.778  ,\n",
       "            0.7744 , 0.7695 , 0.7607 , 0.753  , 0.752  , 0.751  , 0.7495 ,\n",
       "            0.74   , 0.736  , 0.733  , 0.7314 , 0.7295 , 0.722  , 0.709  ,\n",
       "            0.701  , 0.7007 , 0.7    , 0.6987 , 0.6973 , 0.695  , 0.688  ,\n",
       "            0.6855 , 0.679  , 0.678  , 0.67   , 0.668  , 0.6655 , 0.6514 ,\n",
       "            0.642  , 0.639  , 0.6387 , 0.6377 , 0.637  , 0.631  , 0.627  ,\n",
       "            0.6245 , 0.6206 , 0.6167 , 0.6157 , 0.596  , 0.58   , 0.5586 ,\n",
       "            0.557  , 0.556  , 0.5557 , 0.5527 , 0.552  , 0.5327 , 0.522  ,\n",
       "            0.518  , 0.515  , 0.5146 , 0.5127 , 0.5015 , 0.4963 , 0.4902 ,\n",
       "            0.4893 , 0.489  , 0.478  , 0.4756 , 0.4675 , 0.459  , 0.456  ,\n",
       "            0.4497 , 0.4475 , 0.4463 , 0.4446 , 0.4434 , 0.4397 , 0.4385 ,\n",
       "            0.437  , 0.4282 , 0.4246 , 0.424  , 0.422  , 0.419  , 0.4185 ,\n",
       "            0.418  , 0.4175 , 0.4165 , 0.4163 , 0.4148 , 0.414  , 0.4111 ,\n",
       "            0.4094 , 0.403  , 0.4026 , 0.4011 , 0.3972 , 0.3916 , 0.39   ,\n",
       "            0.3884 , 0.3875 , 0.387  , 0.385  , 0.3843 , 0.3838 , 0.3801 ,\n",
       "            0.3796 , 0.3777 , 0.3767 , 0.3757 , 0.3745 , 0.3716 , 0.371  ,\n",
       "            0.3706 , 0.368  , 0.3657 , 0.3586 , 0.3525 , 0.3513 , 0.3489 ,\n",
       "            0.348  , 0.3472 , 0.3445 , 0.3423 , 0.34   , 0.3376 , 0.3367 ,\n",
       "            0.3347 , 0.333  , 0.3315 , 0.331  , 0.3289 , 0.3284 , 0.3276 ,\n",
       "            0.327  , 0.3242 , 0.3228 , 0.322  , 0.3213 , 0.321  , 0.3193 ,\n",
       "            0.319  , 0.3184 , 0.3176 , 0.317  , 0.3162 , 0.3154 , 0.3152 ,\n",
       "            0.3142 , 0.314  , 0.3093 , 0.3086 , 0.3079 , 0.3064 , 0.3062 ,\n",
       "            0.3054 , 0.3044 , 0.3    , 0.2974 , 0.2905 , 0.288  , 0.2874 ,\n",
       "            0.2861 , 0.2854 , 0.285  , 0.2847 , 0.283  , 0.2798 , 0.2788 ,\n",
       "            0.2786 , 0.2773 , 0.2751 , 0.2744 , 0.2742 , 0.2725 , 0.2715 ,\n",
       "            0.2703 , 0.268  , 0.2632 , 0.263  , 0.2607 , 0.2605 , 0.2595 ,\n",
       "            0.258  , 0.2576 , 0.2563 , 0.2554 , 0.2551 , 0.2494 , 0.249  ,\n",
       "            0.246  , 0.2424 , 0.2411 , 0.2399 , 0.2347 , 0.234  , 0.2323 ,\n",
       "            0.2303 , 0.2278 , 0.224  , 0.2163 , 0.2058 , 0.2056 , 0.2021 ,\n",
       "            0.2006 , 0.2002 , 0.1952 , 0.195  , 0.1934 , 0.1921 , 0.1909 ,\n",
       "            0.1898 , 0.1876 , 0.1874 , 0.1871 , 0.1848 , 0.1842 , 0.1807 ,\n",
       "            0.18   , 0.1771 , 0.1721 , 0.1697 , 0.1685 , 0.1654 , 0.162  ,\n",
       "            0.1608 , 0.1566 , 0.1533 , 0.1504 , 0.145  , 0.1393 , 0.139  ,\n",
       "            0.1296 , 0.1279 , 0.1243 , 0.12103, 0.11554, 0.1032 , 0.0927 ,\n",
       "            0.0863 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04477612, dtype=float32),\n",
       "    'tpr': array(0.54310346, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.20149253, 0.20149253, 0.20149253,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.2835821 , 0.2835821 , 0.2835821 , 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.6641791 , 0.67164177, 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43103448, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.54310346,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.70689654, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8189655 , 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87931037, 0.87931037, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8604 , 0.8467 , 0.8403 , 0.824  , 0.81   , 0.808  ,\n",
       "            0.8047 , 0.796  , 0.789  , 0.7856 , 0.7847 , 0.784  , 0.7754 ,\n",
       "            0.769  , 0.7686 , 0.766  , 0.762  , 0.755  , 0.7446 , 0.7373 ,\n",
       "            0.736  , 0.733  , 0.7324 , 0.7314 , 0.722  , 0.7173 , 0.717  ,\n",
       "            0.7114 , 0.7026 , 0.698  , 0.683  , 0.672  , 0.6704 , 0.6694 ,\n",
       "            0.669  , 0.668  , 0.667  , 0.6665 , 0.664  , 0.663  , 0.656  ,\n",
       "            0.655  , 0.6455 , 0.645  , 0.6353 , 0.6055 , 0.5933 , 0.589  ,\n",
       "            0.587  , 0.5845 , 0.5776 , 0.5757 , 0.5713 , 0.556  , 0.5522 ,\n",
       "            0.5513 , 0.543  , 0.533  , 0.5303 , 0.527  , 0.523  , 0.521  ,\n",
       "            0.518  , 0.5156 , 0.5034 , 0.4978 , 0.4895 , 0.4863 , 0.4846 ,\n",
       "            0.4788 , 0.4749 , 0.4744 , 0.47   , 0.4663 , 0.4648 , 0.4634 ,\n",
       "            0.4631 , 0.4602 , 0.46   , 0.4543 , 0.4539 , 0.45   , 0.4487 ,\n",
       "            0.4482 , 0.447  , 0.4429 , 0.439  , 0.4387 , 0.435  , 0.4336 ,\n",
       "            0.432  , 0.4312 , 0.4302 , 0.428  , 0.4272 , 0.4253 , 0.4229 ,\n",
       "            0.4219 , 0.4207 , 0.4177 , 0.415  , 0.4143 , 0.4138 , 0.4104 ,\n",
       "            0.4092 , 0.4084 , 0.4045 , 0.3992 , 0.3953 , 0.3933 , 0.39   ,\n",
       "            0.388  , 0.3872 , 0.3867 , 0.3826 , 0.3752 , 0.371  , 0.3708 ,\n",
       "            0.3677 , 0.3662 , 0.3657 , 0.363  , 0.3623 , 0.3552 , 0.3542 ,\n",
       "            0.354  , 0.3525 , 0.352  , 0.3494 , 0.3484 , 0.3481 , 0.3477 ,\n",
       "            0.3474 , 0.3462 , 0.346  , 0.3455 , 0.3445 , 0.3423 , 0.338  ,\n",
       "            0.3345 , 0.3333 , 0.332  , 0.3318 , 0.3315 , 0.3313 , 0.3306 ,\n",
       "            0.3293 , 0.3242 , 0.3237 , 0.3225 , 0.321  , 0.3206 , 0.3154 ,\n",
       "            0.3145 , 0.3142 , 0.3127 , 0.3115 , 0.3093 , 0.3086 , 0.308  ,\n",
       "            0.3076 , 0.307  , 0.3042 , 0.2974 , 0.2932 , 0.2896 , 0.2808 ,\n",
       "            0.2773 , 0.277  , 0.2751 , 0.2742 , 0.272  , 0.2703 , 0.2695 ,\n",
       "            0.2686 , 0.2678 , 0.2673 , 0.2664 , 0.2617 , 0.2612 , 0.2598 ,\n",
       "            0.2559 , 0.2551 , 0.254  , 0.2534 , 0.252  , 0.2487 , 0.2466 ,\n",
       "            0.2411 , 0.241  , 0.2314 , 0.2294 , 0.222  , 0.2101 , 0.2096 ,\n",
       "            0.2069 , 0.1989 , 0.1954 , 0.194  , 0.1935 , 0.1934 , 0.1896 ,\n",
       "            0.1886 , 0.1864 , 0.1836 , 0.1829 , 0.1807 , 0.179  , 0.1766 ,\n",
       "            0.1759 , 0.1758 , 0.1719 , 0.1688 , 0.1671 , 0.1608 , 0.16   ,\n",
       "            0.1594 , 0.1592 , 0.1559 , 0.1552 , 0.1475 , 0.1432 , 0.1407 ,\n",
       "            0.1346 , 0.1292 , 0.1289 , 0.1193 , 0.11755, 0.11395, 0.11084,\n",
       "            0.1054 , 0.0935 , 0.08386, 0.07684], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04477612, dtype=float32),\n",
       "    'tpr': array(0.5603448, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.18656716, 0.19402985, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.25373134, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.2835821 , 0.2835821 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3283582 , 0.3283582 ,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.3880597 , 0.3880597 ,\n",
       "            0.3880597 , 0.3880597 , 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.67164177, 0.67164177, 0.6791045 , 0.69402987,\n",
       "            0.70149255, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.70689654, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87931037, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.883  , 0.8716 , 0.8647 , 0.8506 , 0.85   , 0.837  ,\n",
       "            0.8345 , 0.8296 , 0.8223 , 0.8145 , 0.8125 , 0.811  , 0.8105 ,\n",
       "            0.802  , 0.7964 , 0.795  , 0.793  , 0.7896 , 0.7817 , 0.771  ,\n",
       "            0.763  , 0.7617 , 0.76   , 0.7593 , 0.758  , 0.757  , 0.748  ,\n",
       "            0.743  , 0.74   , 0.7373 , 0.728  , 0.725  , 0.7236 , 0.708  ,\n",
       "            0.6973 , 0.694  , 0.6934 , 0.693  , 0.6914 , 0.689  , 0.686  ,\n",
       "            0.6855 , 0.6787 , 0.677  , 0.6685 , 0.6675 , 0.6562 , 0.6255 ,\n",
       "            0.6123 , 0.6074 , 0.606  , 0.605  , 0.6025 , 0.596  , 0.5938 ,\n",
       "            0.5903 , 0.5723 , 0.568  , 0.5674 , 0.559  , 0.546  , 0.545  ,\n",
       "            0.5415 , 0.537  , 0.536  , 0.533  , 0.5293 , 0.516  , 0.5103 ,\n",
       "            0.502  , 0.4976 , 0.4958 , 0.489  , 0.4856 , 0.4844 , 0.4792 ,\n",
       "            0.4768 , 0.4749 , 0.4727 , 0.4717 , 0.4697 , 0.4695 , 0.4636 ,\n",
       "            0.4622 , 0.458  , 0.4578 , 0.4563 , 0.455  , 0.4504 , 0.4468 ,\n",
       "            0.4458 , 0.4434 , 0.4397 , 0.4385 , 0.4382 , 0.4375 , 0.4368 ,\n",
       "            0.4365 , 0.4324 , 0.431  , 0.4292 , 0.427  , 0.4253 , 0.4233 ,\n",
       "            0.421  , 0.4194 , 0.4163 , 0.415  , 0.4146 , 0.4092 , 0.4023 ,\n",
       "            0.398  , 0.3977 , 0.396  , 0.3958 , 0.3928 , 0.392  , 0.3894 ,\n",
       "            0.3892 , 0.3853 , 0.3762 , 0.3752 , 0.3733 , 0.372  , 0.371  ,\n",
       "            0.3691 , 0.3667 , 0.3665 , 0.366  , 0.3628 , 0.3574 , 0.356  ,\n",
       "            0.3525 , 0.352  , 0.351  , 0.3508 , 0.3506 , 0.35   , 0.349  ,\n",
       "            0.3486 , 0.3484 , 0.3462 , 0.3457 , 0.3455 , 0.343  , 0.3428 ,\n",
       "            0.3367 , 0.3323 , 0.3315 , 0.3308 , 0.3306 , 0.329  , 0.3289 ,\n",
       "            0.324  , 0.3215 , 0.3213 , 0.321  , 0.3186 , 0.318  , 0.3125 ,\n",
       "            0.3123 , 0.3088 , 0.3086 , 0.308  , 0.3079 , 0.3074 , 0.3071 ,\n",
       "            0.3066 , 0.3047 , 0.3005 , 0.2937 , 0.2913 , 0.29   , 0.2856 ,\n",
       "            0.277  , 0.2744 , 0.2732 , 0.2725 , 0.2666 , 0.2646 , 0.2644 ,\n",
       "            0.2637 , 0.2612 , 0.2603 , 0.2598 , 0.2595 , 0.258  , 0.2563 ,\n",
       "            0.252  , 0.2517 , 0.251  , 0.2449 , 0.2448 , 0.2445 , 0.2444 ,\n",
       "            0.2399 , 0.2338 , 0.2301 , 0.22   , 0.2123 , 0.2053 , 0.1965 ,\n",
       "            0.196  , 0.1853 , 0.183  , 0.1826 , 0.1819 , 0.1797 , 0.1779 ,\n",
       "            0.1775 , 0.1737 , 0.1715 , 0.1694 , 0.167  , 0.1654 , 0.1646 ,\n",
       "            0.1631 , 0.1625 , 0.1582 , 0.1575 , 0.1549 , 0.1477 , 0.1473 ,\n",
       "            0.1464 , 0.146  , 0.1436 , 0.143  , 0.1338 , 0.1302 , 0.1271 ,\n",
       "            0.122  , 0.11554, 0.10614, 0.10504, 0.10156, 0.0981 , 0.0933 ,\n",
       "            0.08167, 0.07306, 0.0666 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.05970149, dtype=float32),\n",
       "    'tpr': array(0.5862069, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.1716418 , 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.24626866,\n",
       "            0.25373134, 0.25373134, 0.26119402, 0.26865673, 0.26865673,\n",
       "            0.2761194 , 0.2761194 , 0.2835821 , 0.2835821 , 0.29850745,\n",
       "            0.29850745, 0.29850745, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.32089552, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3880597 , 0.3880597 , 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6551724 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.899  , 0.888  , 0.8823 , 0.869  , 0.8687 , 0.856  ,\n",
       "            0.854  , 0.8486 , 0.8413 , 0.834  , 0.8325 , 0.8315 , 0.831  ,\n",
       "            0.8223 , 0.817  , 0.8154 , 0.8135 , 0.81   , 0.8027 , 0.792  ,\n",
       "            0.7847 , 0.783  , 0.781  , 0.7803 , 0.779  , 0.7773 , 0.769  ,\n",
       "            0.764  , 0.761  , 0.7583 , 0.749  , 0.746  , 0.7446 , 0.7285 ,\n",
       "            0.7173 , 0.715  , 0.7134 , 0.713  , 0.7114 , 0.7104 , 0.7075 ,\n",
       "            0.707  , 0.6987 , 0.6978 , 0.688  , 0.687  , 0.6772 , 0.643  ,\n",
       "            0.632  , 0.6274 , 0.626  , 0.6235 , 0.621  , 0.6157 , 0.6147 ,\n",
       "            0.611  , 0.5923 , 0.588  , 0.5874 , 0.5806 , 0.565  , 0.561  ,\n",
       "            0.5586 , 0.5576 , 0.554  , 0.553  , 0.5454 , 0.5347 , 0.5303 ,\n",
       "            0.519  , 0.5146 , 0.5137 , 0.5054 , 0.503  , 0.5005 , 0.498  ,\n",
       "            0.4946 , 0.4893 , 0.4866 , 0.486  , 0.4827 , 0.4802 , 0.4768 ,\n",
       "            0.476  , 0.473  , 0.4712 , 0.4705 , 0.465  , 0.4634 , 0.461  ,\n",
       "            0.4585 , 0.458  , 0.4563 , 0.4526 , 0.4521 , 0.4504 , 0.4487 ,\n",
       "            0.4434 , 0.442  , 0.437  , 0.4363 , 0.434  , 0.433  , 0.4321 ,\n",
       "            0.432  , 0.43   , 0.4275 , 0.4216 , 0.4155 , 0.412  , 0.4094 ,\n",
       "            0.4084 , 0.4072 , 0.402  , 0.401  , 0.3992 , 0.3953 , 0.3923 ,\n",
       "            0.3875 , 0.3872 , 0.3855 , 0.3843 , 0.3826 , 0.3774 , 0.3743 ,\n",
       "            0.3735 , 0.3691 , 0.368  , 0.365  , 0.364  , 0.3635 , 0.3633 ,\n",
       "            0.363  , 0.3616 , 0.3599 , 0.359  , 0.3574 , 0.357  , 0.3552 ,\n",
       "            0.3489 , 0.3462 , 0.345  , 0.3433 , 0.3428 , 0.3418 , 0.341  ,\n",
       "            0.3398 , 0.339  , 0.3354 , 0.3306 , 0.3289 , 0.3284 , 0.328  ,\n",
       "            0.3276 , 0.3252 , 0.324  , 0.3237 , 0.3223 , 0.3179 , 0.3176 ,\n",
       "            0.3174 , 0.316  , 0.314  , 0.3076 , 0.3071 , 0.306  , 0.3042 ,\n",
       "            0.3013 , 0.2983 , 0.2937 , 0.2932 , 0.286  , 0.2832 , 0.281  ,\n",
       "            0.2751 , 0.2727 , 0.2717 , 0.265  , 0.2612 , 0.261  , 0.2598 ,\n",
       "            0.2573 , 0.2559 , 0.255  , 0.2542 , 0.2537 , 0.2527 , 0.2483 ,\n",
       "            0.2463 , 0.243  , 0.2379 , 0.2375 , 0.2374 , 0.2366 , 0.2335 ,\n",
       "            0.226  , 0.2197 , 0.2157 , 0.2124 , 0.2042 , 0.193  , 0.1882 ,\n",
       "            0.1782 , 0.1772 , 0.1743 , 0.1737 , 0.1733 , 0.1726 , 0.1715 ,\n",
       "            0.1656 , 0.1643 , 0.1605 , 0.1588 , 0.1586 , 0.1566 , 0.1536 ,\n",
       "            0.1494 , 0.1486 , 0.1484 , 0.1392 , 0.1381 , 0.138  , 0.1367 ,\n",
       "            0.1365 , 0.1361 , 0.12476, 0.12036, 0.1174 , 0.112  , 0.10614,\n",
       "            0.10596, 0.09686, 0.0955 , 0.0922 , 0.089  , 0.08417, 0.0733 ,\n",
       "            0.0655 , 0.05856], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.14925373, dtype=float32),\n",
       "    'tpr': array(0.6465517, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.17910448, 0.17910448,\n",
       "            0.19402985, 0.20149253, 0.20149253, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.25373134, 0.25373134,\n",
       "            0.25373134, 0.25373134, 0.26119402, 0.26119402, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.36567163, 0.36567163, 0.36567163, 0.36567163,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.49253732, 0.5074627 ,\n",
       "            0.5074627 , 0.52238804, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6119403 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.6034483 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.73275864, 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.75      , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.921  , 0.9106 , 0.906  , 0.8936 , 0.893  , 0.881  ,\n",
       "            0.88   , 0.877  , 0.8687 , 0.8623 , 0.8604 , 0.859  , 0.851  ,\n",
       "            0.8447 , 0.8438 , 0.843  , 0.837  , 0.8306 , 0.8228 , 0.8154 ,\n",
       "            0.814  , 0.8105 , 0.809  , 0.8086 , 0.8    , 0.7954 , 0.7925 ,\n",
       "            0.7876 , 0.7793 , 0.775  , 0.774  , 0.7583 , 0.746  , 0.745  ,\n",
       "            0.744  , 0.7427 , 0.742  , 0.7417 , 0.7397 , 0.7305 , 0.7285 ,\n",
       "            0.7153 , 0.715  , 0.6704 , 0.669  , 0.666  , 0.664  , 0.662  ,\n",
       "            0.6606 , 0.651  , 0.6494 , 0.6333 , 0.6294 , 0.6274 , 0.627  ,\n",
       "            0.609  , 0.6074 , 0.6035 , 0.602  , 0.581  , 0.5776 , 0.575  ,\n",
       "            0.573  , 0.558  , 0.5576 , 0.556  , 0.5547 , 0.5464 , 0.5454 ,\n",
       "            0.54   , 0.5312 , 0.531  , 0.529  , 0.525  , 0.524  , 0.5146 ,\n",
       "            0.511  , 0.5093 , 0.509  , 0.5083 , 0.5073 , 0.5063 , 0.5054 ,\n",
       "            0.5015 , 0.501  , 0.4934 , 0.4873 , 0.4832 , 0.4822 , 0.4817 ,\n",
       "            0.4814 , 0.4805 , 0.4749 , 0.4712 , 0.4707 , 0.4702 , 0.466  ,\n",
       "            0.4648 , 0.4644 , 0.4558 , 0.453  , 0.4434 , 0.443  , 0.4414 ,\n",
       "            0.4407 , 0.4382 , 0.4338 , 0.4321 , 0.4316 , 0.4292 , 0.428  ,\n",
       "            0.4275 , 0.4226 , 0.421  , 0.4207 , 0.4182 , 0.4175 , 0.4082 ,\n",
       "            0.4053 , 0.405  , 0.4048 , 0.404  , 0.4023 , 0.3992 , 0.3977 ,\n",
       "            0.3948 , 0.3943 , 0.3928 , 0.3914 , 0.3892 , 0.3887 , 0.3772 ,\n",
       "            0.3767 , 0.374  , 0.3738 , 0.3723 , 0.372  , 0.371  , 0.3704 ,\n",
       "            0.3652 , 0.363  , 0.3628 , 0.357  , 0.3562 , 0.3528 , 0.3513 ,\n",
       "            0.351  , 0.3499 , 0.3481 , 0.348  , 0.3477 , 0.3406 , 0.328  ,\n",
       "            0.3267 , 0.3257 , 0.3254 , 0.322  , 0.3213 , 0.3147 , 0.3113 ,\n",
       "            0.31   , 0.3086 , 0.306  , 0.304  , 0.3035 , 0.2996 , 0.296  ,\n",
       "            0.2947 , 0.2908 , 0.2905 , 0.2761 , 0.264  , 0.2556 , 0.2554 ,\n",
       "            0.2527 , 0.251  , 0.2483 , 0.2482 , 0.2477 , 0.247  , 0.2421 ,\n",
       "            0.2351 , 0.2299 , 0.2297 , 0.2295 , 0.2268 , 0.2244 , 0.2235 ,\n",
       "            0.2125 , 0.1943 , 0.1927 , 0.1787 , 0.1754 , 0.1707 , 0.1683 ,\n",
       "            0.1682 , 0.1648 , 0.164  , 0.1624 , 0.1602 , 0.1534 , 0.1528 ,\n",
       "            0.1505 , 0.1503 , 0.1465 , 0.1434 , 0.1423 , 0.1422 , 0.1396 ,\n",
       "            0.1377 , 0.1317 , 0.1295 , 0.1278 , 0.1265 , 0.1263 , 0.11475,\n",
       "            0.10913, 0.1065 , 0.1011 , 0.0959 , 0.0957 , 0.0866 , 0.0851 ,\n",
       "            0.082  , 0.07904, 0.0742 , 0.0645 , 0.05792, 0.05023],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.21641791, dtype=float32),\n",
       "    'tpr': array(0.67241377, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.1119403 , 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.17910448, 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.25373134, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26119402, 0.26119402, 0.26119402, 0.26119402, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.35820895, 0.35820895, 0.36567163, 0.36567163, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.37313432, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.5948276 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6551724 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8189655 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9355 , 0.9263 , 0.922  , 0.91   , 0.899  , 0.898  ,\n",
       "            0.896  , 0.888  , 0.8823 , 0.8804 , 0.879  , 0.8716 , 0.8657 ,\n",
       "            0.8643 , 0.864  , 0.858  , 0.852  , 0.8447 , 0.8384 , 0.8364 ,\n",
       "            0.8345 , 0.8335 , 0.832  , 0.831  , 0.8228 , 0.8203 , 0.8145 ,\n",
       "            0.8105 , 0.803  , 0.799  , 0.7974 , 0.782  , 0.772  , 0.771  ,\n",
       "            0.7705 , 0.7686 , 0.7676 , 0.7666 , 0.7656 , 0.7637 , 0.763  ,\n",
       "            0.7563 , 0.753  , 0.7446 , 0.739  , 0.7383 , 0.7095 , 0.6978 ,\n",
       "            0.696  , 0.693  , 0.6885 , 0.687  , 0.6753 , 0.674  , 0.664  ,\n",
       "            0.6616 , 0.66   , 0.6577 , 0.6475 , 0.6436 , 0.642  , 0.6396 ,\n",
       "            0.6333 , 0.6123 , 0.6055 , 0.6045 , 0.598  , 0.597  , 0.591  ,\n",
       "            0.5884 , 0.583  , 0.5796 , 0.576  , 0.5703 , 0.5645 , 0.563  ,\n",
       "            0.561  , 0.5596 , 0.557  , 0.5566 , 0.552  , 0.546  , 0.544  ,\n",
       "            0.5405 , 0.5396 , 0.538  , 0.5366 , 0.535  , 0.53   , 0.5273 ,\n",
       "            0.525  , 0.519  , 0.518  , 0.516  , 0.514  , 0.513  , 0.5117 ,\n",
       "            0.5083 , 0.508  , 0.507  , 0.505  , 0.504  , 0.503  , 0.4995 ,\n",
       "            0.4978 , 0.4897 , 0.4834 , 0.482  , 0.4792 , 0.479  , 0.4707 ,\n",
       "            0.4705 , 0.4697 , 0.469  , 0.4683 , 0.4668 , 0.4658 , 0.4653 ,\n",
       "            0.4636 , 0.4595 , 0.4578 , 0.4453 , 0.445  , 0.4424 , 0.4382 ,\n",
       "            0.4375 , 0.4373 , 0.437  , 0.4333 , 0.4297 , 0.429  , 0.4287 ,\n",
       "            0.4285 , 0.4275 , 0.4202 , 0.4194 , 0.415  , 0.414  , 0.4111 ,\n",
       "            0.4102 , 0.407  , 0.4043 , 0.404  , 0.4001 , 0.3984 , 0.3962 ,\n",
       "            0.3955 , 0.3945 , 0.3928 , 0.3914 , 0.3867 , 0.3794 , 0.379  ,\n",
       "            0.3782 , 0.3733 , 0.3726 , 0.3672 , 0.367  , 0.3628 , 0.3584 ,\n",
       "            0.3574 , 0.349  , 0.3408 , 0.3396 , 0.3389 , 0.3357 , 0.3328 ,\n",
       "            0.3323 , 0.332  , 0.3306 , 0.3264 , 0.3154 , 0.3147 , 0.313  ,\n",
       "            0.3125 , 0.303  , 0.2986 , 0.2952 , 0.268  , 0.2656 , 0.2576 ,\n",
       "            0.2537 , 0.252  , 0.2512 , 0.2498 , 0.2477 , 0.2463 , 0.2441 ,\n",
       "            0.244  , 0.2395 , 0.2283 , 0.2256 , 0.2255 , 0.2247 , 0.2224 ,\n",
       "            0.2222 , 0.2106 , 0.1924 , 0.1886 , 0.1731 , 0.172  , 0.1686 ,\n",
       "            0.165  , 0.1617 , 0.1583 , 0.1575 , 0.1561 , 0.1559 , 0.1484 ,\n",
       "            0.146  , 0.1439 , 0.1436 , 0.1393 , 0.1373 , 0.1361 , 0.1349 ,\n",
       "            0.1324 , 0.1304 , 0.1256 , 0.1241 , 0.12366, 0.12036, 0.119  ,\n",
       "            0.1188 , 0.10724, 0.10126, 0.09875, 0.0933 , 0.0883 , 0.088  ,\n",
       "            0.0792 , 0.07764, 0.07465, 0.07184, 0.0672 , 0.05792, 0.05194,\n",
       "            0.04443], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.24626866, dtype=float32),\n",
       "    'tpr': array(0.69827586, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23134328,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.24626866, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.25373134, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.37313432, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.37313432, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.55172414, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9478 , 0.9395 , 0.9355 , 0.9253 , 0.915  , 0.914  ,\n",
       "            0.9126 , 0.905  , 0.9    , 0.8975 , 0.8965 , 0.8896 , 0.8843 ,\n",
       "            0.883  , 0.8823 , 0.877  , 0.871  , 0.8647 , 0.8584 , 0.8564 ,\n",
       "            0.855  , 0.854  , 0.8525 , 0.8516 , 0.844  , 0.842  , 0.8354 ,\n",
       "            0.832  , 0.8247 , 0.8203 , 0.8193 , 0.8037 , 0.796  , 0.7935 ,\n",
       "            0.793  , 0.791  , 0.7905 , 0.789  , 0.787  , 0.786  , 0.785  ,\n",
       "            0.78   , 0.7754 , 0.7695 , 0.7607 , 0.76   , 0.741  , 0.724  ,\n",
       "            0.723  , 0.7183 , 0.713  , 0.707  , 0.6973 , 0.6963 , 0.691  ,\n",
       "            0.69   , 0.687  , 0.6836 , 0.6743 , 0.6694 , 0.664  , 0.66   ,\n",
       "            0.6416 , 0.633  , 0.632  , 0.6265 , 0.619  , 0.6187 , 0.608  ,\n",
       "            0.607  , 0.603  , 0.602  , 0.596  , 0.5923 , 0.5913 , 0.59   ,\n",
       "            0.589  , 0.5854 , 0.584  , 0.5796 , 0.574  , 0.5684 , 0.565  ,\n",
       "            0.561  , 0.56   , 0.559  , 0.5557 , 0.5537 , 0.5503 , 0.545  ,\n",
       "            0.5425 , 0.5415 , 0.539  , 0.537  , 0.5366 , 0.5356 , 0.534  ,\n",
       "            0.5303 , 0.53   , 0.5264 , 0.524  , 0.523  , 0.5205 , 0.5117 ,\n",
       "            0.5107 , 0.5063 , 0.501  , 0.4998 , 0.4993 , 0.4968 , 0.4956 ,\n",
       "            0.495  , 0.4946 , 0.493  , 0.4917 , 0.4895 , 0.4875 , 0.4873 ,\n",
       "            0.469  , 0.4653 , 0.4648 , 0.464  , 0.4604 , 0.455  , 0.4536 ,\n",
       "            0.4521 , 0.4502 , 0.447  , 0.4453 , 0.4426 , 0.4424 , 0.4417 ,\n",
       "            0.4414 , 0.4387 , 0.4375 , 0.4363 , 0.4312 , 0.4282 , 0.428  ,\n",
       "            0.4265 , 0.4238 , 0.4229 , 0.4214 , 0.4192 , 0.4175 , 0.4155 ,\n",
       "            0.41   , 0.4053 , 0.4016 , 0.3992 , 0.398  , 0.395  , 0.3938 ,\n",
       "            0.385  , 0.3826 , 0.3818 , 0.3801 , 0.364  , 0.3591 , 0.356  ,\n",
       "            0.3545 , 0.354  , 0.3513 , 0.3486 , 0.347  , 0.3438 , 0.3352 ,\n",
       "            0.3325 , 0.331  , 0.3308 , 0.3289 , 0.32   , 0.315  , 0.3147 ,\n",
       "            0.3115 , 0.3    , 0.2952 , 0.2744 , 0.271  , 0.2695 , 0.2654 ,\n",
       "            0.2485 , 0.2473 , 0.2471 , 0.2448 , 0.2424 , 0.239  , 0.2388 ,\n",
       "            0.236  , 0.231  , 0.2197 , 0.2194 , 0.2191 , 0.2185 , 0.2166 ,\n",
       "            0.2075 , 0.1912 , 0.181  , 0.17   , 0.1659 , 0.1643 , 0.161  ,\n",
       "            0.1542 , 0.1512 , 0.1509 , 0.1492 , 0.1483 , 0.1432 , 0.1373 ,\n",
       "            0.1367 , 0.1355 , 0.1317 , 0.1312 , 0.1279 , 0.1261 , 0.1245 ,\n",
       "            0.1217 , 0.119  , 0.1184 , 0.1172 , 0.1122 , 0.11066, 0.1097 ,\n",
       "            0.0993 , 0.0925 , 0.0904 , 0.0848 , 0.0804 , 0.0801 , 0.0715 ,\n",
       "            0.06964, 0.0667 , 0.0644 , 0.05975, 0.05136, 0.0461 , 0.03845],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.24626866, dtype=float32),\n",
       "    'tpr': array(0.7241379, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1716418 , 0.1716418 , 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.24626866, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26119402, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.3432836 , 0.35074627, 0.35074627,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.35820895, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.37313432, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.5298507 , 0.53731346, 0.53731346, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.62068963, 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6551724 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.79310346, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.955  , 0.9478 , 0.944  , 0.9346 , 0.926  , 0.924  ,\n",
       "            0.9224 , 0.9155 , 0.91   , 0.909  , 0.908  , 0.907  , 0.901  ,\n",
       "            0.896  , 0.8955 , 0.894  , 0.89   , 0.885  , 0.8765 , 0.87   ,\n",
       "            0.8687 , 0.8667 , 0.866  , 0.865  , 0.857  , 0.853  , 0.8506 ,\n",
       "            0.846  , 0.839  , 0.836  , 0.8345 , 0.8184 , 0.807  , 0.8066 ,\n",
       "            0.8047 , 0.8037 , 0.803  , 0.8022 , 0.8003 , 0.7925 , 0.7896 ,\n",
       "            0.7793 , 0.7754 , 0.775  , 0.7495 , 0.7334 , 0.733  , 0.7285 ,\n",
       "            0.724  , 0.722  , 0.71   , 0.709  , 0.6987 , 0.6953 , 0.6924 ,\n",
       "            0.6816 , 0.6777 , 0.6772 , 0.677  , 0.668  , 0.6484 , 0.6387 ,\n",
       "            0.638  , 0.636  , 0.6284 , 0.625  , 0.6147 , 0.6123 , 0.612  ,\n",
       "            0.609  , 0.601  , 0.597  , 0.5957 , 0.595  , 0.594  , 0.5933 ,\n",
       "            0.59   , 0.5835 , 0.578  , 0.572  , 0.569  , 0.5654 , 0.5645 ,\n",
       "            0.5635 , 0.559  , 0.5576 , 0.554  , 0.5483 , 0.548  , 0.5474 ,\n",
       "            0.542  , 0.5405 , 0.54   , 0.5386 , 0.534  , 0.532  , 0.5303 ,\n",
       "            0.5273 , 0.527  , 0.5234 , 0.516  , 0.5137 , 0.509  , 0.505  ,\n",
       "            0.5034 , 0.5005 , 0.4988 , 0.498  , 0.4978 , 0.4973 , 0.4946 ,\n",
       "            0.4932 , 0.4902 , 0.4897 , 0.4714 , 0.468  , 0.4675 , 0.466  ,\n",
       "            0.4631 , 0.4614 , 0.4575 , 0.4573 , 0.4558 , 0.453  , 0.4521 ,\n",
       "            0.4487 , 0.4473 , 0.4446 , 0.4443 , 0.444  , 0.443  , 0.4412 ,\n",
       "            0.441  , 0.439  , 0.438  , 0.4321 , 0.4297 , 0.4294 , 0.4263 ,\n",
       "            0.4258 , 0.4243 , 0.4229 , 0.421  , 0.4185 , 0.4165 , 0.4094 ,\n",
       "            0.406  , 0.4028 , 0.4    , 0.3984 , 0.3958 , 0.3945 , 0.3867 ,\n",
       "            0.382  , 0.3809 , 0.3782 , 0.3606 , 0.3599 , 0.354  , 0.352  ,\n",
       "            0.3518 , 0.3513 , 0.3508 , 0.3452 , 0.3445 , 0.3428 , 0.3354 ,\n",
       "            0.3303 , 0.3286 , 0.3271 , 0.3267 , 0.315  , 0.309  , 0.3088 ,\n",
       "            0.293  , 0.29   , 0.2686 , 0.2668 , 0.2646 , 0.2598 , 0.2407 ,\n",
       "            0.2394 , 0.2384 , 0.2368 , 0.2339 , 0.2302 , 0.2299 , 0.2281 ,\n",
       "            0.224  , 0.212  , 0.2119 , 0.2114 , 0.2096 , 0.2073 , 0.1993 ,\n",
       "            0.183  , 0.1736 , 0.1619 , 0.158  , 0.1549 , 0.1528 , 0.1448 ,\n",
       "            0.143  , 0.1416 , 0.1415 , 0.1388 , 0.1348 , 0.1287 , 0.1274 ,\n",
       "            0.1263 , 0.1235 , 0.1222 , 0.119  , 0.1174 , 0.11554, 0.1138 ,\n",
       "            0.1103 , 0.1086 , 0.1036 , 0.1021 , 0.10175, 0.09106, 0.0845 ,\n",
       "            0.0823 , 0.07697, 0.0725 , 0.07227, 0.0641 , 0.0627 , 0.05988,\n",
       "            0.05737, 0.0531 , 0.04526, 0.04037, 0.03348], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.26865673, dtype=float32),\n",
       "    'tpr': array(0.75, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.1119403 , 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.1716418 , 0.1716418 , 0.17910448, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23134328, 0.23134328, 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.24626866, 0.24626866, 0.24626866,\n",
       "            0.24626866, 0.25373134, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2761194 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35074627, 0.35074627,\n",
       "            0.35820895, 0.35820895, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.37313432, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9614 , 0.955  , 0.9517 , 0.9434 , 0.943  , 0.935  ,\n",
       "            0.933  , 0.9307 , 0.9253 , 0.9204 , 0.9194 , 0.9185 , 0.9175 ,\n",
       "            0.911  , 0.9077 , 0.9062 , 0.905  , 0.9023 , 0.897  , 0.888  ,\n",
       "            0.8823 , 0.881  , 0.88   , 0.879  , 0.8774 , 0.8696 , 0.8643 ,\n",
       "            0.864  , 0.86   , 0.8525 , 0.8496 , 0.8486 , 0.8325 , 0.821  ,\n",
       "            0.8203 , 0.819  , 0.818  , 0.8174 , 0.817  , 0.8154 , 0.8145 ,\n",
       "            0.8057 , 0.8037 , 0.7915 , 0.7896 , 0.7876 , 0.7617 , 0.7456 ,\n",
       "            0.745  , 0.7407 , 0.737  , 0.7344 , 0.723  , 0.7227 , 0.711  ,\n",
       "            0.7104 , 0.7075 , 0.7036 , 0.6934 , 0.689  , 0.6885 , 0.685  ,\n",
       "            0.679  , 0.6597 , 0.6494 , 0.649  , 0.648  , 0.6396 , 0.6357 ,\n",
       "            0.6353 , 0.625  , 0.622  , 0.619  , 0.6167 , 0.6113 , 0.6064 ,\n",
       "            0.6055 , 0.605  , 0.6035 , 0.6025 , 0.5996 , 0.599  , 0.5986 ,\n",
       "            0.5938 , 0.587  , 0.5806 , 0.577  , 0.5737 , 0.5723 , 0.5713 ,\n",
       "            0.5674 , 0.5654 , 0.563  , 0.557  , 0.556  , 0.555  , 0.55   ,\n",
       "            0.548  , 0.5474 , 0.5464 , 0.541  , 0.54   , 0.538  , 0.535  ,\n",
       "            0.5337 , 0.5303 , 0.525  , 0.52   , 0.5156 , 0.515  , 0.513  ,\n",
       "            0.5127 , 0.5117 , 0.509  , 0.506  , 0.5044 , 0.504  , 0.503  ,\n",
       "            0.5015 , 0.4976 , 0.4956 , 0.4773 , 0.475  , 0.4746 , 0.4714 ,\n",
       "            0.47   , 0.4663 , 0.464  , 0.4636 , 0.4617 , 0.4575 , 0.4573 ,\n",
       "            0.4534 , 0.4521 , 0.4497 , 0.4495 , 0.4492 , 0.4482 , 0.448  ,\n",
       "            0.4443 , 0.443  , 0.4424 , 0.4353 , 0.435  , 0.4326 , 0.43   ,\n",
       "            0.4294 , 0.428  , 0.4268 , 0.423  , 0.4211 , 0.4133 , 0.41   ,\n",
       "            0.408  , 0.404  , 0.4023 , 0.4004 , 0.3992 , 0.3936 , 0.386  ,\n",
       "            0.3838 , 0.3804 , 0.3652 , 0.3586 , 0.3572 , 0.3552 , 0.3545 ,\n",
       "            0.354  , 0.3472 , 0.3464 , 0.3396 , 0.3394 , 0.3345 , 0.3323 ,\n",
       "            0.33   , 0.3235 , 0.3223 , 0.3137 , 0.3125 , 0.3047 , 0.304  ,\n",
       "            0.286  , 0.2825 , 0.27   , 0.2678 , 0.2612 , 0.259  , 0.2344 ,\n",
       "            0.233  , 0.231  , 0.2302 , 0.2255 , 0.2218 , 0.2217 , 0.2213 ,\n",
       "            0.2205 , 0.2051 , 0.2032 , 0.2031 , 0.2009 , 0.1989 , 0.1929 ,\n",
       "            0.178  , 0.1644 , 0.1561 , 0.1525 , 0.1466 , 0.1461 , 0.1365 ,\n",
       "            0.1364 , 0.1333 , 0.1327 , 0.1306 , 0.1283 , 0.1197 , 0.1196 ,\n",
       "            0.11816, 0.11694, 0.11395, 0.111  , 0.10876, 0.1076 , 0.10504,\n",
       "            0.10376, 0.1034 , 0.10175, 0.0957 , 0.09436, 0.0935 , 0.08344,\n",
       "            0.07654, 0.07477, 0.0695 , 0.0656 , 0.06537, 0.0575 , 0.05594,\n",
       "            0.0533 , 0.05118, 0.0471 , 0.04   , 0.03583, 0.02893],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.2835821, dtype=float32),\n",
       "    'tpr': array(0.7586207, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.12686567, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.23880596, 0.23880596,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26119402, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.2835821 , 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.35820895, 0.36567163,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.79850745,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62068963, 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9683 , 0.963  , 0.96   , 0.9526 , 0.952  , 0.9453 ,\n",
       "            0.944  , 0.9414 , 0.9365 , 0.9316 , 0.931  , 0.93   , 0.929  ,\n",
       "            0.924  , 0.921  , 0.9194 , 0.918  , 0.916  , 0.9106 , 0.9023 ,\n",
       "            0.897  , 0.8955 , 0.895  , 0.8936 , 0.8926 , 0.892  , 0.885  ,\n",
       "            0.8804 , 0.88   , 0.8765 , 0.8687 , 0.8677 , 0.8647 , 0.85   ,\n",
       "            0.84   , 0.8384 , 0.8374 , 0.8364 , 0.836  , 0.8354 , 0.835  ,\n",
       "            0.8335 , 0.833  , 0.824  , 0.8223 , 0.811  , 0.8086 , 0.807  ,\n",
       "            0.787  , 0.768  , 0.766  , 0.7617 , 0.758  , 0.755  , 0.7437 ,\n",
       "            0.7427 , 0.735  , 0.733  , 0.73   , 0.726  , 0.7183 , 0.714  ,\n",
       "            0.713  , 0.7056 , 0.702  , 0.6846 , 0.6787 , 0.673  , 0.6694 ,\n",
       "            0.661  , 0.66   , 0.6465 , 0.6426 , 0.6357 , 0.6343 , 0.632  ,\n",
       "            0.6313 , 0.6294 , 0.6274 , 0.627  , 0.6235 , 0.623  , 0.621  ,\n",
       "            0.614  , 0.6055 , 0.5996 , 0.594  , 0.5938 , 0.5933 , 0.5913 ,\n",
       "            0.5884 , 0.5874 , 0.582  , 0.573  , 0.572  , 0.5703 , 0.569  ,\n",
       "            0.565  , 0.5645 , 0.5605 , 0.557  , 0.556  , 0.5547 , 0.554  ,\n",
       "            0.5513 , 0.545  , 0.5415 , 0.5405 , 0.539  , 0.5386 , 0.537  ,\n",
       "            0.5366 , 0.531  , 0.5303 , 0.5264 , 0.5244 , 0.523  , 0.518  ,\n",
       "            0.516  , 0.501  , 0.5    , 0.4993 , 0.4949 , 0.4915 , 0.489  ,\n",
       "            0.4878 , 0.484  , 0.4824 , 0.4814 , 0.4788 , 0.4773 , 0.4766 ,\n",
       "            0.4746 , 0.4731 , 0.4717 , 0.4714 , 0.4702 , 0.4688 , 0.4653 ,\n",
       "            0.464  , 0.459  , 0.4575 , 0.4517 , 0.4512 , 0.451  , 0.4495 ,\n",
       "            0.4478 , 0.4456 , 0.4429 , 0.4412 , 0.4316 , 0.4302 , 0.4277 ,\n",
       "            0.423  , 0.421  , 0.4204 , 0.4197 , 0.4194 , 0.4043 , 0.3997 ,\n",
       "            0.3938 , 0.3877 , 0.3745 , 0.3735 , 0.3718 , 0.3696 , 0.3677 ,\n",
       "            0.3645 , 0.363  , 0.3596 , 0.3523 , 0.3494 , 0.347  , 0.3416 ,\n",
       "            0.3298 , 0.327  , 0.3247 , 0.321  , 0.3066 , 0.3052 , 0.2869 ,\n",
       "            0.2856 , 0.282  , 0.2761 , 0.2664 , 0.2642 , 0.2323 , 0.231  ,\n",
       "            0.2295 , 0.2261 , 0.2225 , 0.2216 , 0.2184 , 0.2179 , 0.2173 ,\n",
       "            0.2028 , 0.1995 , 0.1993 , 0.1962 , 0.1937 , 0.1901 , 0.1765 ,\n",
       "            0.1597 , 0.153  , 0.1494 , 0.1426 , 0.1399 , 0.1313 , 0.13   ,\n",
       "            0.1273 , 0.127  , 0.1242 , 0.12317, 0.1134 , 0.11163, 0.1074 ,\n",
       "            0.1043 , 0.1023 , 0.1011 , 0.0991 , 0.0977 , 0.0972 , 0.0957 ,\n",
       "            0.0893 , 0.0879 , 0.0876 , 0.07684, 0.0703 , 0.0683 , 0.06335,\n",
       "            0.05954, 0.0592 , 0.05176, 0.05032, 0.04788, 0.04578, 0.04193,\n",
       "            0.03528, 0.03143, 0.02513], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.30597016, dtype=float32),\n",
       "    'tpr': array(0.7844828, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23134328, 0.23880596, 0.23880596,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26119402, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2761194 , 0.2835821 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 , 0.5948276 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.6465517 , 0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9736 , 0.969  , 0.9663 , 0.96   , 0.9536 , 0.952  ,\n",
       "            0.949  , 0.9453 , 0.941  , 0.94   , 0.939  , 0.9336 , 0.931  ,\n",
       "            0.929  , 0.9287 , 0.927  , 0.922  , 0.914  , 0.9087 , 0.9077 ,\n",
       "            0.906  , 0.905  , 0.904  , 0.8975 , 0.894  , 0.8926 , 0.89   ,\n",
       "            0.8823 , 0.879  , 0.865  , 0.856  , 0.853  , 0.8525 , 0.852  ,\n",
       "            0.851  , 0.8506 , 0.849  , 0.848  , 0.8394 , 0.838  , 0.8267 ,\n",
       "            0.8247 , 0.823  , 0.8047 , 0.7856 , 0.7827 , 0.778  , 0.775  ,\n",
       "            0.7725 , 0.761  , 0.7603 , 0.753  , 0.75   , 0.747  , 0.7427 ,\n",
       "            0.7373 , 0.7324 , 0.7305 , 0.72   , 0.7197 , 0.7026 , 0.6978 ,\n",
       "            0.69   , 0.6865 , 0.6787 , 0.678  , 0.6777 , 0.664  , 0.663  ,\n",
       "            0.6597 , 0.655  , 0.6514 , 0.6494 , 0.6484 , 0.648  , 0.6465 ,\n",
       "            0.644  , 0.642  , 0.6406 , 0.6377 , 0.6313 , 0.6226 , 0.6157 ,\n",
       "            0.6104 , 0.6094 , 0.6084 , 0.605  , 0.603  , 0.599  , 0.5894 ,\n",
       "            0.588  , 0.586  , 0.584  , 0.5806 , 0.5786 , 0.5747 , 0.572  ,\n",
       "            0.571  , 0.5703 , 0.57   , 0.566  , 0.562  , 0.5566 , 0.5557 ,\n",
       "            0.5527 , 0.5522 , 0.5513 , 0.546  , 0.544  , 0.5396 , 0.539  ,\n",
       "            0.537  , 0.5366 , 0.5303 , 0.5293 , 0.5146 , 0.5137 , 0.511  ,\n",
       "            0.5083 , 0.503  , 0.502  , 0.5005 , 0.496  , 0.4944 , 0.4937 ,\n",
       "            0.4888 , 0.4885 , 0.4883 , 0.4846 , 0.483  , 0.4822 , 0.4814 ,\n",
       "            0.4795 , 0.4766 , 0.4753 , 0.4722 , 0.469  , 0.4639 , 0.462  ,\n",
       "            0.4604 , 0.457  , 0.4553 , 0.455  , 0.4531 , 0.4512 , 0.441  ,\n",
       "            0.4368 , 0.4326 , 0.4321 , 0.4312 , 0.4297 , 0.4294 , 0.413  ,\n",
       "            0.408  , 0.4011 , 0.3982 , 0.382  , 0.3818 , 0.38   , 0.3772 ,\n",
       "            0.3748 , 0.3723 , 0.37   , 0.3687 , 0.3677 , 0.3604 , 0.3564 ,\n",
       "            0.354  , 0.3408 , 0.3367 , 0.328  , 0.3245 , 0.324  , 0.3064 ,\n",
       "            0.3035 , 0.2927 , 0.283  , 0.279  , 0.2783 , 0.2686 , 0.2632 ,\n",
       "            0.2285 , 0.2269 , 0.2261 , 0.2207 , 0.2203 , 0.2163 , 0.2129 ,\n",
       "            0.2125 , 0.2113 , 0.1987 , 0.194  , 0.1937 , 0.1904 , 0.1873 ,\n",
       "            0.1858 , 0.1729 , 0.1534 , 0.1484 , 0.1453 , 0.1378 , 0.1328 ,\n",
       "            0.1259 , 0.1232 , 0.12054, 0.1201 , 0.1178 , 0.1174 , 0.1069 ,\n",
       "            0.1063 , 0.10486, 0.1007 , 0.0977 , 0.0957 , 0.0945 , 0.0925 ,\n",
       "            0.09186, 0.09125, 0.0898 , 0.0828 , 0.08167, 0.08136, 0.07056,\n",
       "            0.0642 , 0.06244, 0.0576 , 0.054  , 0.0537 , 0.04663, 0.0452 ,\n",
       "            0.04282, 0.04092, 0.03732, 0.0312 , 0.0278 , 0.02177],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.35820895, dtype=float32),\n",
       "    'tpr': array(0.87068963, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.08208955, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.1119403 , 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.19402985, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23880596, 0.23880596,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.26865673, 0.26865673,\n",
       "            0.2761194 , 0.2761194 , 0.2835821 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.35820895, 0.35820895, 0.36567163, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.54310346, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.69827586, 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9785 , 0.9746 , 0.972  , 0.967  , 0.9663 , 0.961  ,\n",
       "            0.9595 , 0.9575 , 0.953  , 0.9497 , 0.9487 , 0.9478 , 0.943  ,\n",
       "            0.941  , 0.939  , 0.9385 , 0.9365 , 0.932  , 0.9253 , 0.9204 ,\n",
       "            0.92   , 0.9194 , 0.918  , 0.917  , 0.9165 , 0.91   , 0.9067 ,\n",
       "            0.9062 , 0.903  , 0.896  , 0.8955 , 0.8926 , 0.88   , 0.8706 ,\n",
       "            0.8687 , 0.8677 , 0.867  , 0.8667 , 0.8657 , 0.865  , 0.864  ,\n",
       "            0.8564 , 0.855  , 0.8457 , 0.842  , 0.84   , 0.831  , 0.81   ,\n",
       "            0.8037 , 0.799  , 0.795  , 0.7896 , 0.781  , 0.7803 , 0.779  ,\n",
       "            0.774  , 0.7715 , 0.7666 , 0.766  , 0.761  , 0.757  , 0.745  ,\n",
       "            0.735  , 0.733  , 0.7324 , 0.716  , 0.7085 , 0.707  , 0.706  ,\n",
       "            0.7007 , 0.694  , 0.692  , 0.6875 , 0.6846 , 0.6826 , 0.679  ,\n",
       "            0.6787 , 0.6743 , 0.674  , 0.6714 , 0.6646 , 0.6636 , 0.66   ,\n",
       "            0.654  , 0.6465 , 0.645  , 0.6445 , 0.6426 , 0.6357 , 0.6353 ,\n",
       "            0.635  , 0.6323 , 0.63   , 0.6206 , 0.62   , 0.6157 , 0.612  ,\n",
       "            0.6104 , 0.61   , 0.607  , 0.6055 , 0.601  , 0.599  , 0.5967 ,\n",
       "            0.595  , 0.594  , 0.5938 , 0.593  , 0.5913 , 0.586  , 0.583  ,\n",
       "            0.5796 , 0.5776 , 0.577  , 0.5713 , 0.57   , 0.5693 , 0.5684 ,\n",
       "            0.5566 , 0.551  , 0.5493 , 0.547  , 0.5435 , 0.542  , 0.538  ,\n",
       "            0.537  , 0.536  , 0.5347 , 0.5312 , 0.5273 , 0.5264 , 0.522  ,\n",
       "            0.517  , 0.5156 , 0.5137 , 0.511  , 0.5107 , 0.509  , 0.5083 ,\n",
       "            0.507  , 0.505  , 0.5044 , 0.501  , 0.4995 , 0.493  , 0.4917 ,\n",
       "            0.4822 , 0.48   , 0.477  , 0.4736 , 0.4722 , 0.4712 , 0.4656 ,\n",
       "            0.463  , 0.462  , 0.4612 , 0.4607 , 0.4595 , 0.4563 , 0.4404 ,\n",
       "            0.4321 , 0.4216 , 0.41   , 0.4082 , 0.4072 , 0.4006 , 0.3997 ,\n",
       "            0.3987 , 0.3967 , 0.3943 , 0.388  , 0.3826 , 0.3801 , 0.3757 ,\n",
       "            0.3633 , 0.342  , 0.3372 , 0.334  , 0.327  , 0.3196 , 0.3123 ,\n",
       "            0.305  , 0.2942 , 0.2832 , 0.2776 , 0.2708 , 0.2286 , 0.2281 ,\n",
       "            0.2277 , 0.2274 , 0.2177 , 0.2134 , 0.211  , 0.2095 , 0.2085 ,\n",
       "            0.1996 , 0.1898 , 0.1897 , 0.1865 , 0.186  , 0.1841 , 0.1758 ,\n",
       "            0.1486 , 0.1483 , 0.1458 , 0.1368 , 0.1279 , 0.1235 , 0.1188 ,\n",
       "            0.1158 , 0.11536, 0.11475, 0.1128 , 0.1036 , 0.10266, 0.10156,\n",
       "            0.0998 , 0.0959 , 0.0927 , 0.0901 , 0.0896 , 0.0883 , 0.0874 ,\n",
       "            0.0869 , 0.086  , 0.07794, 0.07654, 0.076  , 0.06573, 0.0589 ,\n",
       "            0.0575 , 0.0526 , 0.0496 , 0.04922, 0.0424 , 0.04083, 0.0386 ,\n",
       "            0.0369 , 0.0334 , 0.02791, 0.02489, 0.01898], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.36567163, dtype=float32),\n",
       "    'tpr': array(0.8965517, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.1716418 , 0.1716418 ,\n",
       "            0.1716418 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20149253, 0.20895523, 0.20895523, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.24626866, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2761194 , 0.2761194 , 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.3283582 , 0.33582088, 0.33582088,\n",
       "            0.33582088, 0.33582088, 0.3432836 , 0.35074627, 0.35074627,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.62068963, 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.69827586, 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8362069 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.982  , 0.978  , 0.976  , 0.971  , 0.9707 , 0.966  ,\n",
       "            0.965  , 0.9624 , 0.959  , 0.9556 , 0.955  , 0.954  , 0.9497 ,\n",
       "            0.9478 , 0.946  , 0.9453 , 0.944  , 0.94   , 0.9326 , 0.928  ,\n",
       "            0.9272 , 0.9263 , 0.9253 , 0.9243 , 0.919  , 0.916  , 0.9146 ,\n",
       "            0.912  , 0.9062 , 0.9053 , 0.902  , 0.89   , 0.882  , 0.879  ,\n",
       "            0.8784 , 0.877  , 0.8765 , 0.875  , 0.8745 , 0.867  , 0.865  ,\n",
       "            0.857  , 0.8525 , 0.85   , 0.846  , 0.8237 , 0.8154 , 0.811  ,\n",
       "            0.8066 , 0.8013 , 0.794  , 0.793  , 0.7925 , 0.787  , 0.785  ,\n",
       "            0.7827 , 0.78   , 0.778  , 0.7715 , 0.76   , 0.754  , 0.749  ,\n",
       "            0.745  , 0.7305 , 0.724  , 0.7217 , 0.721  , 0.715  , 0.7134 ,\n",
       "            0.711  , 0.707  , 0.7026 , 0.702  , 0.701  , 0.697  , 0.6943 ,\n",
       "            0.692  , 0.691  , 0.689  , 0.6846 , 0.6777 , 0.674  , 0.6724 ,\n",
       "            0.669  , 0.667  , 0.662  , 0.6616 , 0.652  , 0.651  , 0.65   ,\n",
       "            0.649  , 0.645  , 0.64   , 0.6377 , 0.636  , 0.6357 , 0.6333 ,\n",
       "            0.631  , 0.625  , 0.621  , 0.6206 , 0.618  , 0.6177 , 0.616  ,\n",
       "            0.613  , 0.6123 , 0.61   , 0.607  , 0.606  , 0.604  , 0.6025 ,\n",
       "            0.5986 , 0.596  , 0.594  , 0.591  , 0.589  , 0.5884 , 0.575  ,\n",
       "            0.574  , 0.5737 , 0.5674 , 0.567  , 0.5654 , 0.562  , 0.5605 ,\n",
       "            0.5576 , 0.554  , 0.5527 , 0.549  , 0.5483 , 0.5444 , 0.537  ,\n",
       "            0.5356 , 0.534  , 0.5303 , 0.528  , 0.5264 , 0.5254 , 0.525  ,\n",
       "            0.5244 , 0.523  , 0.5225 , 0.5137 , 0.513  , 0.5127 , 0.501  ,\n",
       "            0.4995 , 0.4993 , 0.496  , 0.4888 , 0.4827 , 0.481  , 0.48   ,\n",
       "            0.4797 , 0.4792 , 0.4778 , 0.4739 , 0.4604 , 0.459  , 0.457  ,\n",
       "            0.446  , 0.4321 , 0.4297 , 0.426  , 0.425  , 0.422  , 0.417  ,\n",
       "            0.4158 , 0.4102 , 0.4092 , 0.408  , 0.4006 , 0.398  , 0.382  ,\n",
       "            0.3757 , 0.3423 , 0.3396 , 0.337  , 0.3325 , 0.322  , 0.3115 ,\n",
       "            0.3025 , 0.2996 , 0.2913 , 0.277  , 0.271  , 0.2295 , 0.2242 ,\n",
       "            0.224  , 0.223  , 0.2108 , 0.2058 , 0.2048 , 0.202  , 0.2017 ,\n",
       "            0.1959 , 0.1821 , 0.182  , 0.1788 , 0.1771 , 0.1741 , 0.1453 ,\n",
       "            0.1431 , 0.1407 , 0.1328 , 0.1207 , 0.1188 , 0.112  , 0.11084,\n",
       "            0.10913, 0.10706, 0.1063 , 0.0986 , 0.0967 , 0.0945 , 0.0933 ,\n",
       "            0.0893 , 0.0863 , 0.08344, 0.0823 , 0.08093, 0.0802 , 0.07184,\n",
       "            0.0703 , 0.06964, 0.0602 , 0.0533 , 0.05203, 0.04733, 0.04468,\n",
       "            0.04428, 0.03796, 0.0363 , 0.03424, 0.03284, 0.02942, 0.02461,\n",
       "            0.02199, 0.01634], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3880597, dtype=float32),\n",
       "    'tpr': array(0.92241377, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.1716418 , 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23134328, 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2761194 , 0.2835821 ,\n",
       "            0.2835821 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35074627, 0.35074627,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5597015 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.35344827, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43965518, 0.44827586, 0.44827586,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.4827586 , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.55172414, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.69827586, 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.7241379 , 0.7241379 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.985  , 0.982  , 0.98   , 0.976  , 0.9756 , 0.9717 ,\n",
       "            0.97   , 0.9683 , 0.965  , 0.962  , 0.9604 , 0.9565 , 0.9556 ,\n",
       "            0.953  , 0.9526 , 0.952  , 0.948  , 0.941  , 0.9375 , 0.937  ,\n",
       "            0.936  , 0.935  , 0.9346 , 0.933  , 0.9287 , 0.9263 , 0.9243 ,\n",
       "            0.923  , 0.9175 , 0.916  , 0.913  , 0.9014 , 0.894  , 0.891  ,\n",
       "            0.8906 , 0.889  , 0.887  , 0.8794 , 0.8774 , 0.87   , 0.866  ,\n",
       "            0.8633 , 0.8623 , 0.8394 , 0.83   , 0.826  , 0.822  , 0.8154 ,\n",
       "            0.8105 , 0.8076 , 0.8037 , 0.802  , 0.8003 , 0.796  , 0.789  ,\n",
       "            0.777  , 0.7754 , 0.7676 , 0.758  , 0.748  , 0.743  , 0.74   ,\n",
       "            0.739  , 0.7373 , 0.7305 , 0.73   , 0.7266 , 0.7227 , 0.721  ,\n",
       "            0.7183 , 0.7163 , 0.713  , 0.711  , 0.71   , 0.7085 , 0.7056 ,\n",
       "            0.6997 , 0.6953 , 0.693  , 0.6924 , 0.6826 , 0.6807 , 0.6777 ,\n",
       "            0.6743 , 0.6685 , 0.668  , 0.666  , 0.664  , 0.663  , 0.6626 ,\n",
       "            0.6577 , 0.6523 , 0.646  , 0.6455 , 0.643  , 0.6426 , 0.639  ,\n",
       "            0.637  , 0.631  , 0.629  , 0.628  , 0.623  , 0.621  , 0.6206 ,\n",
       "            0.6196 , 0.617  , 0.615  , 0.6094 , 0.6084 , 0.6074 , 0.5996 ,\n",
       "            0.5977 , 0.595  , 0.5938 , 0.593  , 0.591  , 0.584  , 0.582  ,\n",
       "            0.58   , 0.5786 , 0.5693 , 0.568  , 0.567  , 0.563  , 0.5547 ,\n",
       "            0.5503 , 0.549  , 0.5474 , 0.547  , 0.545  , 0.5444 , 0.5425 ,\n",
       "            0.54   , 0.5347 , 0.5337 , 0.5273 , 0.5205 , 0.5186 , 0.518  ,\n",
       "            0.504  , 0.5034 , 0.5005 , 0.4983 , 0.4973 , 0.4922 , 0.4888 ,\n",
       "            0.4814 , 0.4778 , 0.4636 , 0.4626 , 0.4495 , 0.446  , 0.4448 ,\n",
       "            0.4446 , 0.4429 , 0.4358 , 0.4324 , 0.4282 , 0.4275 , 0.4243 ,\n",
       "            0.42   , 0.4167 , 0.4023 , 0.3801 , 0.361  , 0.351  , 0.3354 ,\n",
       "            0.3347 , 0.3213 , 0.3142 , 0.3137 , 0.3022 , 0.298  , 0.2744 ,\n",
       "            0.2673 , 0.2334 , 0.2233 , 0.2218 , 0.2211 , 0.206  , 0.2009 ,\n",
       "            0.2007 , 0.197  , 0.1968 , 0.1943 , 0.1803 , 0.1765 , 0.1764 ,\n",
       "            0.1744 , 0.1733 , 0.172  , 0.1437 , 0.1422 , 0.1346 , 0.1305 ,\n",
       "            0.11536, 0.115  , 0.1076 , 0.1067 , 0.10394, 0.1011 , 0.1007 ,\n",
       "            0.09485, 0.09186, 0.0888 , 0.088  , 0.08405, 0.08105, 0.07965,\n",
       "            0.0785 , 0.07825, 0.0775 , 0.0771 , 0.0745 , 0.0666 , 0.0651 ,\n",
       "            0.0643 , 0.0555 , 0.0484 , 0.04752, 0.04282, 0.04062, 0.04016,\n",
       "            0.03418, 0.03247, 0.0305 , 0.02937, 0.02606, 0.02182, 0.0196 ,\n",
       "            0.01406], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.41044775, dtype=float32),\n",
       "    'tpr': array(0.9310345, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23134328, 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.26119402, 0.26119402, 0.26865673, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.32089552, 0.32089552, 0.3283582 ,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.4224138 , 0.43103448, 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.55172414, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.7241379 , 0.7241379 , 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8534483 , 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9873 , 0.985  , 0.983  , 0.9795 , 0.979  , 0.9756 ,\n",
       "            0.9746 , 0.9727 , 0.9697 , 0.9673 , 0.967  , 0.966  , 0.962  ,\n",
       "            0.9614 , 0.959  , 0.9585 , 0.9546 , 0.9478 , 0.9453 , 0.944  ,\n",
       "            0.9434 , 0.9424 , 0.942  , 0.94   , 0.936  , 0.9346 , 0.9316 ,\n",
       "            0.931  , 0.927  , 0.925  , 0.922  , 0.911  , 0.9043 , 0.902  ,\n",
       "            0.901  , 0.9004 , 0.899  , 0.8984 , 0.8975 , 0.897  , 0.889  ,\n",
       "            0.888  , 0.8804 , 0.877  , 0.874  , 0.8735 , 0.851  , 0.842  ,\n",
       "            0.838  , 0.8335 , 0.828  , 0.823  , 0.8203 , 0.82   , 0.816  ,\n",
       "            0.8145 , 0.814  , 0.809  , 0.8086 , 0.802  , 0.7905 , 0.7896 ,\n",
       "            0.7812 , 0.771  , 0.761  , 0.757  , 0.754  , 0.75   , 0.7485 ,\n",
       "            0.7446 , 0.744  , 0.7427 , 0.7383 , 0.7344 , 0.7314 , 0.731  ,\n",
       "            0.7266 , 0.7256 , 0.7246 , 0.7236 , 0.721  , 0.719  , 0.711  ,\n",
       "            0.7085 , 0.7075 , 0.698  , 0.695  , 0.692  , 0.689  , 0.684  ,\n",
       "            0.6816 , 0.6797 , 0.679  , 0.677  , 0.6724 , 0.6694 , 0.667  ,\n",
       "            0.665  , 0.6646 , 0.662  , 0.6587 , 0.6562 , 0.652  , 0.642  ,\n",
       "            0.6416 , 0.639  , 0.6377 , 0.6357 , 0.635  , 0.632  , 0.6304 ,\n",
       "            0.626  , 0.625  , 0.6245 , 0.62   , 0.6177 , 0.615  , 0.6147 ,\n",
       "            0.6084 , 0.6074 , 0.6016 , 0.598  , 0.5977 , 0.597  , 0.5854 ,\n",
       "            0.5835 , 0.583  , 0.582  , 0.5757 , 0.5703 , 0.5693 , 0.5664 ,\n",
       "            0.5654 , 0.5625 , 0.562  , 0.561  , 0.5605 , 0.556  , 0.5503 ,\n",
       "            0.5493 , 0.549  , 0.5474 , 0.5356 , 0.5347 , 0.5337 , 0.519  ,\n",
       "            0.5156 , 0.5137 , 0.5127 , 0.5107 , 0.5103 , 0.506  , 0.4993 ,\n",
       "            0.4956 , 0.4917 , 0.473  , 0.468  , 0.4644 , 0.4607 , 0.4587 ,\n",
       "            0.455  , 0.4536 , 0.4495 , 0.4426 , 0.438  , 0.433  , 0.4297 ,\n",
       "            0.4158 , 0.3813 , 0.3745 , 0.3542 , 0.3347 , 0.3345 , 0.319  ,\n",
       "            0.3186 , 0.313  , 0.306  , 0.295  , 0.2732 , 0.271  , 0.2644 ,\n",
       "            0.2322 , 0.2195 , 0.2175 , 0.217  , 0.2007 , 0.1954 , 0.1953 ,\n",
       "            0.1915 , 0.1913 , 0.1901 , 0.1758 , 0.1719 , 0.1718 , 0.171  ,\n",
       "            0.1676 , 0.1663 , 0.1395 , 0.1383 , 0.13   , 0.126  , 0.1103 ,\n",
       "            0.1095 , 0.10284, 0.1011 , 0.09845, 0.0959 , 0.0955 , 0.0898 ,\n",
       "            0.0866 , 0.08386, 0.0828 , 0.0789 , 0.076  , 0.07477, 0.0734 ,\n",
       "            0.0725 , 0.07227, 0.07007, 0.06165, 0.0602 , 0.0601 , 0.051  ,\n",
       "            0.04434, 0.04337, 0.03906, 0.03683, 0.03644, 0.03079, 0.02925,\n",
       "            0.02744, 0.02626, 0.02328, 0.01935, 0.0173 , 0.01234],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.42537314, dtype=float32),\n",
       "    'tpr': array(0.9396552, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.10447761, 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.21641791, 0.21641791, 0.21641791, 0.23134328, 0.23880596,\n",
       "            0.23880596, 0.24626866, 0.24626866, 0.24626866, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2761194 , 0.2835821 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.3283582 , 0.3283582 ,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.47761193, 0.47761193, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.7758621 , 0.7758621 , 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9897 , 0.9873 , 0.986  , 0.9824 , 0.979  , 0.978  ,\n",
       "            0.9766 , 0.974  , 0.9717 , 0.971  , 0.97   , 0.9673 , 0.967  ,\n",
       "            0.9644 , 0.964  , 0.9604 , 0.954  , 0.9517 , 0.9507 , 0.9497 ,\n",
       "            0.949  , 0.9487 , 0.9473 , 0.9434 , 0.9424 , 0.9395 , 0.939  ,\n",
       "            0.9355 , 0.9326 , 0.93   , 0.9204 , 0.914  , 0.912  , 0.911  ,\n",
       "            0.9097 , 0.909  , 0.9087 , 0.9077 , 0.907  , 0.8994 , 0.8984 ,\n",
       "            0.8926 , 0.8896 , 0.888  , 0.8857 , 0.8667 , 0.856  , 0.852  ,\n",
       "            0.8477 , 0.8413 , 0.841  , 0.8345 , 0.834  , 0.833  , 0.832  ,\n",
       "            0.831  , 0.8286 , 0.825  , 0.82   , 0.816  , 0.8076 , 0.8022 ,\n",
       "            0.7866 , 0.7847 , 0.7803 , 0.7783 , 0.775  , 0.767  , 0.7666 ,\n",
       "            0.7637 , 0.76   , 0.755  , 0.7524 , 0.75   , 0.7495 , 0.7476 ,\n",
       "            0.747  , 0.741  , 0.7324 , 0.7285 , 0.726  , 0.7207 , 0.7183 ,\n",
       "            0.7153 , 0.708  , 0.703  , 0.701  , 0.7    , 0.699  , 0.698  ,\n",
       "            0.6973 , 0.6963 , 0.6934 , 0.6914 , 0.678  , 0.668  , 0.667  ,\n",
       "            0.666  , 0.662  , 0.658  , 0.6567 , 0.656  , 0.6543 , 0.654  ,\n",
       "            0.6533 , 0.6523 , 0.652  , 0.651  , 0.65   , 0.6484 , 0.646  ,\n",
       "            0.641  , 0.6343 , 0.6333 , 0.6294 , 0.6265 , 0.6187 , 0.615  ,\n",
       "            0.6094 , 0.601  , 0.6    , 0.5967 , 0.594  , 0.5923 , 0.592  ,\n",
       "            0.5913 , 0.591  , 0.5894 , 0.589  , 0.5874 , 0.5815 , 0.581  ,\n",
       "            0.58   , 0.5674 , 0.567  , 0.564  , 0.562  , 0.5537 , 0.55   ,\n",
       "            0.5464 , 0.541  , 0.5366 , 0.5356 , 0.5347 , 0.534  , 0.5327 ,\n",
       "            0.52   , 0.509  , 0.496  , 0.4949 , 0.4878 , 0.4814 , 0.4785 ,\n",
       "            0.4739 , 0.4731 , 0.4666 , 0.463  , 0.461  , 0.4575 , 0.4548 ,\n",
       "            0.4453 , 0.406  , 0.3884 , 0.3677 , 0.3396 , 0.3357 , 0.3345 ,\n",
       "            0.3225 , 0.32   , 0.3184 , 0.2952 , 0.2803 , 0.2703 , 0.2622 ,\n",
       "            0.2399 , 0.2207 , 0.217  , 0.2167 , 0.1979 , 0.193  , 0.1918 ,\n",
       "            0.1907 , 0.1884 , 0.1879 , 0.1759 , 0.1738 , 0.1676 , 0.1675 ,\n",
       "            0.1635 , 0.1627 , 0.1403 , 0.139  , 0.1252 , 0.12494, 0.108  ,\n",
       "            0.10504, 0.1005 , 0.09686, 0.09436, 0.0914 , 0.09076, 0.0866 ,\n",
       "            0.0828 , 0.0792 , 0.0786 , 0.07477, 0.07184, 0.0716 , 0.07007,\n",
       "            0.0693 , 0.0689 , 0.0678 , 0.06537, 0.05737, 0.05603, 0.05573,\n",
       "            0.04715, 0.04053, 0.0397 , 0.0355 , 0.0336 , 0.03314, 0.0278 ,\n",
       "            0.02626, 0.02457, 0.02356, 0.02069, 0.0171 , 0.01543, 0.01065],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.47014925, dtype=float32),\n",
       "    'tpr': array(0.9655172, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.1119403 , 0.1119403 , 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.15671642, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.26865673, 0.26865673,\n",
       "            0.26865673, 0.26865673, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3448276 , 0.35344827, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.57758623, 0.5862069 , 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.62931037, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7155172 , 0.7155172 ,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.991  , 0.9893 , 0.9883 , 0.9854 , 0.985  , 0.982  ,\n",
       "            0.9814 , 0.98   , 0.9775 , 0.9756 , 0.975  , 0.974  , 0.971  ,\n",
       "            0.9707 , 0.9688 , 0.9683 , 0.9653 , 0.9595 , 0.9575 , 0.9565 ,\n",
       "            0.9556 , 0.955  , 0.9546 , 0.9536 , 0.9497 , 0.9487 , 0.947  ,\n",
       "            0.946  , 0.9424 , 0.9395 , 0.937  , 0.928  , 0.9224 , 0.921  ,\n",
       "            0.9204 , 0.9185 , 0.918  , 0.9175 , 0.9165 , 0.9097 , 0.908  ,\n",
       "            0.9053 , 0.904  , 0.898  , 0.8955 , 0.8823 , 0.87   , 0.866  ,\n",
       "            0.861  , 0.859  , 0.8535 , 0.852  , 0.849  , 0.8486 , 0.848  ,\n",
       "            0.8477 , 0.843  , 0.842  , 0.839  , 0.826  , 0.824  , 0.8184 ,\n",
       "            0.81   , 0.807  , 0.802  , 0.8003 , 0.7974 , 0.794  , 0.7925 ,\n",
       "            0.792  , 0.788  , 0.784  , 0.7817 , 0.7783 , 0.7773 , 0.776  ,\n",
       "            0.775  , 0.7734 , 0.77   , 0.7695 , 0.761  , 0.7573 , 0.753  ,\n",
       "            0.75   , 0.745  , 0.7407 , 0.737  , 0.7363 , 0.735  , 0.733  ,\n",
       "            0.7295 , 0.7285 , 0.7275 , 0.7256 , 0.723  , 0.7207 , 0.711  ,\n",
       "            0.708  , 0.7046 , 0.702  , 0.6987 , 0.6978 , 0.6943 , 0.69   ,\n",
       "            0.687  , 0.6855 , 0.684  , 0.6836 , 0.679  , 0.678  , 0.6763 ,\n",
       "            0.676  , 0.673  , 0.672  , 0.667  , 0.6655 , 0.663  , 0.6626 ,\n",
       "            0.66   , 0.6523 , 0.6504 , 0.643  , 0.6406 , 0.6353 , 0.635  ,\n",
       "            0.63   , 0.6294 , 0.629  , 0.6284 , 0.6265 , 0.6245 , 0.6177 ,\n",
       "            0.617  , 0.612  , 0.6074 , 0.6045 , 0.5986 , 0.597  , 0.591  ,\n",
       "            0.5884 , 0.584  , 0.5815 , 0.577  , 0.576  , 0.5693 , 0.5664 ,\n",
       "            0.5645 , 0.562  , 0.555  , 0.5386 , 0.5337 , 0.5283 , 0.526  ,\n",
       "            0.5254 , 0.517  , 0.5156 , 0.514  , 0.5024 , 0.501  , 0.4993 ,\n",
       "            0.4988 , 0.4958 , 0.487  , 0.486  , 0.477  , 0.452  , 0.4    ,\n",
       "            0.3896 , 0.365  , 0.3506 , 0.3489 , 0.3352 , 0.3289 , 0.3232 ,\n",
       "            0.2976 , 0.295  , 0.2717 , 0.2605 , 0.256  , 0.2268 , 0.2211 ,\n",
       "            0.2189 , 0.1981 , 0.1962 , 0.1942 , 0.1904 , 0.1882 , 0.1865 ,\n",
       "            0.1827 , 0.1805 , 0.1641 , 0.1622 , 0.1614 , 0.146  , 0.1448 ,\n",
       "            0.1279 , 0.121  , 0.1093 , 0.1025 , 0.10126, 0.09503, 0.0927 ,\n",
       "            0.0896 , 0.0866 , 0.0859 , 0.08154, 0.0761 , 0.07544, 0.07227,\n",
       "            0.0712 , 0.0693 , 0.0683 , 0.0671 , 0.0642 , 0.0613 , 0.0546 ,\n",
       "            0.0533 , 0.05203, 0.04486, 0.03748, 0.0371 , 0.0326 , 0.03143,\n",
       "            0.03091, 0.02576, 0.02391, 0.0223 , 0.0217 , 0.01869, 0.01567,\n",
       "            0.01428, 0.00938], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.49253732, dtype=float32),\n",
       "    'tpr': array(0.98275864, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.15671642, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.17910448, 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23134328, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2761194 , 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41044775, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.33620688, 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.43965518, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.6034483 , 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.7155172 , 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.992   , 0.9907  , 0.9893  , 0.987   , 0.984   ,\n",
       "            0.9834  , 0.982   , 0.98    , 0.978   , 0.9775  , 0.977   ,\n",
       "            0.974   , 0.9736  , 0.9717  , 0.971   , 0.9688  , 0.963   ,\n",
       "            0.9614  , 0.96    , 0.9595  , 0.959   , 0.958   , 0.9575  ,\n",
       "            0.9536  , 0.953   , 0.951   , 0.95    , 0.9478  , 0.9443  ,\n",
       "            0.942   , 0.933   , 0.929   , 0.9277  , 0.927   , 0.9243  ,\n",
       "            0.9233  , 0.923   , 0.9224  , 0.9155  , 0.914   , 0.9116  ,\n",
       "            0.91    , 0.9053  , 0.9033  , 0.8896  , 0.8774  , 0.8735  ,\n",
       "            0.8687  , 0.8667  , 0.862   , 0.8613  , 0.8574  , 0.857   ,\n",
       "            0.856   , 0.854   , 0.8496  , 0.847   , 0.835   , 0.833   ,\n",
       "            0.832   , 0.824   , 0.8213  , 0.812   , 0.809   , 0.807   ,\n",
       "            0.806   , 0.804   , 0.8037  , 0.803   , 0.7954  , 0.793   ,\n",
       "            0.7905  , 0.788   , 0.787   , 0.7866  , 0.786   , 0.785   ,\n",
       "            0.78    , 0.7793  , 0.7734  , 0.772   , 0.77    , 0.768   ,\n",
       "            0.76    , 0.757   , 0.756   , 0.7544  , 0.754   , 0.752   ,\n",
       "            0.751   , 0.7446  , 0.743   , 0.739   , 0.7383  , 0.7373  ,\n",
       "            0.735   , 0.734   , 0.7227  , 0.7188  , 0.7183  , 0.718   ,\n",
       "            0.7163  , 0.714   , 0.708   , 0.705   , 0.7026  , 0.701   ,\n",
       "            0.699   , 0.6987  , 0.6973  , 0.6963  , 0.6953  , 0.6904  ,\n",
       "            0.689   , 0.688   , 0.6846  , 0.6826  , 0.6772  , 0.677   ,\n",
       "            0.6763  , 0.675   , 0.6704  , 0.6675  , 0.6626  , 0.6567  ,\n",
       "            0.656   , 0.652   , 0.648   , 0.647   , 0.645   , 0.6445  ,\n",
       "            0.643   , 0.641   , 0.6406  , 0.635   , 0.6265  , 0.6157  ,\n",
       "            0.615   , 0.614   , 0.6064  , 0.6035  , 0.603   , 0.602   ,\n",
       "            0.593   , 0.59    , 0.585   , 0.583   , 0.579   , 0.5767  ,\n",
       "            0.5723  , 0.5596  , 0.5522  , 0.545   , 0.5435  , 0.5356  ,\n",
       "            0.5337  , 0.533   , 0.5186  , 0.5176  , 0.5166  , 0.516   ,\n",
       "            0.5137  , 0.505   , 0.5034  , 0.4844  , 0.474   , 0.4058  ,\n",
       "            0.4004  , 0.3794  , 0.3643  , 0.353   , 0.3374  , 0.3333  ,\n",
       "            0.3247  , 0.3005  , 0.2986  , 0.272   , 0.2622  , 0.2605  ,\n",
       "            0.2281  , 0.2213  , 0.2179  , 0.197   , 0.1964  , 0.1925  ,\n",
       "            0.1884  , 0.1863  , 0.1852  , 0.1843  , 0.1808  , 0.162   ,\n",
       "            0.1597  , 0.1587  , 0.1467  , 0.1455  , 0.1274  , 0.1184  ,\n",
       "            0.10706 , 0.0993  , 0.09875 , 0.09204 , 0.0896  , 0.0866  ,\n",
       "            0.08417 , 0.0828  , 0.0786  , 0.0732  , 0.0721  , 0.06915 ,\n",
       "            0.06866 , 0.0667  , 0.06635 , 0.06573 , 0.0642  , 0.06085 ,\n",
       "            0.05844 , 0.05167 , 0.05023 , 0.0494  , 0.04218 , 0.03488 ,\n",
       "            0.03455 , 0.03015 , 0.02908 , 0.0286  , 0.0237  , 0.02191 ,\n",
       "            0.02037 , 0.01979 , 0.01698 , 0.014175, 0.01287 , 0.008316],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.49253732, dtype=float32),\n",
       "    'tpr': array(0.98275864, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05970149, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.1119403 , 0.1119403 , 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.25373134, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.33582088, 0.33582088, 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.45689654, 0.46551725,\n",
       "            0.4827586 , 0.5       , 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.57758623, 0.5862069 , 0.5862069 , 0.5862069 ,\n",
       "            0.5862069 , 0.6034483 , 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.993  , 0.9917 , 0.9907 , 0.9883 , 0.986  , 0.985  ,\n",
       "            0.984  , 0.982  , 0.98   , 0.979  , 0.9766 , 0.976  , 0.974  ,\n",
       "            0.9717 , 0.9663 , 0.965  , 0.9634 , 0.963  , 0.9624 , 0.962  ,\n",
       "            0.961  , 0.9575 , 0.957  , 0.955  , 0.954  , 0.9526 , 0.948  ,\n",
       "            0.9463 , 0.938  , 0.9346 , 0.9336 , 0.9316 , 0.9297 , 0.929  ,\n",
       "            0.9287 , 0.9277 , 0.921  , 0.92   , 0.918  , 0.916  , 0.912  ,\n",
       "            0.91   , 0.8965 , 0.8843 , 0.881  , 0.876  , 0.8745 , 0.8696 ,\n",
       "            0.8657 , 0.865  , 0.8647 , 0.864  , 0.858  , 0.855  , 0.8447 ,\n",
       "            0.8433 , 0.8423 , 0.837  , 0.8345 , 0.822  , 0.8184 , 0.817  ,\n",
       "            0.8164 , 0.8135 , 0.806  , 0.8047 , 0.804  , 0.8037 , 0.798  ,\n",
       "            0.7974 , 0.7964 , 0.796  , 0.79   , 0.7886 , 0.786  , 0.7856 ,\n",
       "            0.782  , 0.7705 , 0.77   , 0.769  , 0.7686 , 0.768  , 0.7676 ,\n",
       "            0.759  , 0.757  , 0.75   , 0.7485 , 0.748  , 0.744  , 0.7383 ,\n",
       "            0.7373 , 0.736  , 0.735  , 0.7334 , 0.7314 , 0.728  , 0.725  ,\n",
       "            0.722  , 0.721  , 0.7173 , 0.715  , 0.7144 , 0.714  , 0.713  ,\n",
       "            0.708  , 0.7065 , 0.702  , 0.7017 , 0.699  , 0.6973 , 0.694  ,\n",
       "            0.6914 , 0.6885 , 0.6875 , 0.6836 , 0.6816 , 0.6787 , 0.6704 ,\n",
       "            0.6685 , 0.6655 , 0.6646 , 0.6606 , 0.66   , 0.659  , 0.657  ,\n",
       "            0.6562 , 0.6523 , 0.652  , 0.645  , 0.6406 , 0.632  , 0.6304 ,\n",
       "            0.6245 , 0.622  , 0.62   , 0.6123 , 0.6094 , 0.6006 , 0.599  ,\n",
       "            0.5986 , 0.5938 , 0.5894 , 0.5874 , 0.581  , 0.5713 , 0.5615 ,\n",
       "            0.558  , 0.553  , 0.552  , 0.5493 , 0.5405 , 0.5347 , 0.5327 ,\n",
       "            0.5317 , 0.5312 , 0.529  , 0.5244 , 0.5156 , 0.4949 , 0.4883 ,\n",
       "            0.4075 , 0.4067 , 0.3887 , 0.373  , 0.3535 , 0.3362 , 0.3337 ,\n",
       "            0.323  , 0.302  , 0.2961 , 0.269  , 0.2644 , 0.2578 , 0.2264 ,\n",
       "            0.218  , 0.2137 , 0.1948 , 0.1918 , 0.1882 , 0.1846 , 0.1837 ,\n",
       "            0.1816 , 0.1797 , 0.1783 , 0.1578 , 0.1577 , 0.1548 , 0.1539 ,\n",
       "            0.145  , 0.1438 , 0.1249 , 0.1144 , 0.10284, 0.09485, 0.09467,\n",
       "            0.0877 , 0.08527, 0.0823 , 0.0802 , 0.0788 , 0.07465, 0.06915,\n",
       "            0.06793, 0.06537, 0.065  , 0.06305, 0.06244, 0.0621 , 0.0603 ,\n",
       "            0.05698, 0.0548 , 0.04794, 0.04663, 0.0461 , 0.03882, 0.03192,\n",
       "            0.03156, 0.02753, 0.0265 , 0.026  , 0.02141, 0.01976, 0.01834,\n",
       "            0.01778, 0.01519, 0.01257, 0.01142, 0.00726], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14179105, 0.14925373, 0.14925373, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.26119402, 0.26119402, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.2835821 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12931034, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.21551724,\n",
       "            0.22413793, 0.2413793 , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.51724136, 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.5689655 , 0.57758623, 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.5948276 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.6896552 , 0.6896552 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.75      , 0.75      , 0.7586207 , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8189655 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.994   , 0.9927  , 0.9917  , 0.9897  , 0.988   ,\n",
       "            0.987   , 0.986   , 0.984   , 0.9824  , 0.982   , 0.9814  ,\n",
       "            0.979   , 0.977   , 0.9746  , 0.9697  , 0.9688  , 0.967   ,\n",
       "            0.9663  , 0.966   , 0.9644  , 0.9614  , 0.959   , 0.9585  ,\n",
       "            0.953   , 0.951   , 0.9434  , 0.942   , 0.9375  , 0.936   ,\n",
       "            0.9355  , 0.9346  , 0.9336  , 0.9277  , 0.9263  , 0.925   ,\n",
       "            0.923   , 0.92    , 0.9194  , 0.9043  , 0.8926  , 0.889   ,\n",
       "            0.885   , 0.8833  , 0.882   , 0.88    , 0.879   , 0.876   ,\n",
       "            0.8745  , 0.874   , 0.8735  , 0.867   , 0.865   , 0.861   ,\n",
       "            0.8535  , 0.853   , 0.851   , 0.8374  , 0.834   , 0.833   ,\n",
       "            0.8325  , 0.8296  , 0.8286  , 0.826   , 0.8228  , 0.8223  ,\n",
       "            0.818   , 0.8174  , 0.817   , 0.8115  , 0.811   , 0.81    ,\n",
       "            0.809   , 0.806   , 0.803   , 0.8027  , 0.801   , 0.8003  ,\n",
       "            0.791   , 0.7905  , 0.7896  , 0.789   , 0.7886  , 0.782   ,\n",
       "            0.7773  , 0.7744  , 0.7656  , 0.764   , 0.7637  , 0.763   ,\n",
       "            0.7627  , 0.7573  , 0.7563  , 0.7544  , 0.7495  , 0.7485  ,\n",
       "            0.7476  , 0.745   , 0.744   , 0.7393  , 0.739   , 0.738   ,\n",
       "            0.7334  , 0.733   , 0.7314  , 0.728   , 0.725   , 0.7207  ,\n",
       "            0.716   , 0.713   , 0.7124  , 0.7114  , 0.711   , 0.7104  ,\n",
       "            0.709   , 0.7075  , 0.706   , 0.7056  , 0.702   , 0.6914  ,\n",
       "            0.691   , 0.69    , 0.6885  , 0.6826  , 0.682   , 0.6816  ,\n",
       "            0.6797  , 0.6787  , 0.6763  , 0.6714  , 0.661   , 0.6553  ,\n",
       "            0.654   , 0.65    , 0.6455  , 0.6406  , 0.634   , 0.632   ,\n",
       "            0.623   , 0.6226  , 0.6187  , 0.615   , 0.6143  , 0.613   ,\n",
       "            0.6094  , 0.5996  , 0.5894  , 0.583   , 0.5825  , 0.5796  ,\n",
       "            0.5737  , 0.562   , 0.5596  , 0.559   , 0.5576  , 0.5537  ,\n",
       "            0.553   , 0.542   , 0.531   , 0.505   , 0.4282  , 0.4224  ,\n",
       "            0.4155  , 0.3994  , 0.3665  , 0.3477  , 0.3467  , 0.3337  ,\n",
       "            0.318   , 0.3052  , 0.282   , 0.2769  , 0.265   , 0.236   ,\n",
       "            0.2246  , 0.2198  , 0.2031  , 0.1967  , 0.1958  , 0.1931  ,\n",
       "            0.1873  , 0.186   , 0.1857  , 0.1831  , 0.1608  , 0.1606  ,\n",
       "            0.1581  , 0.1564  , 0.1528  , 0.1515  , 0.1299  , 0.1158  ,\n",
       "            0.1056  , 0.09686 , 0.0955  , 0.0883  , 0.086   , 0.0827  ,\n",
       "            0.0818  , 0.0785  , 0.0752  , 0.06915 , 0.0672  , 0.06586 ,\n",
       "            0.06525 , 0.0636  , 0.0627  , 0.06223 , 0.0601  , 0.05612 ,\n",
       "            0.0542  , 0.0471  , 0.04578 , 0.04526 , 0.03802 , 0.03085 ,\n",
       "            0.03056 , 0.02646 , 0.02556 , 0.02504 , 0.02052 , 0.01877 ,\n",
       "            0.01738 , 0.01692 , 0.014336, 0.01187 , 0.01086 , 0.006718],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.1119403 , 0.1119403 , 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14179105, 0.14925373, 0.14925373, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20149253, 0.21641791, 0.2238806 , 0.23134328, 0.23134328,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.24626866, 0.24626866,\n",
       "            0.26119402, 0.26119402, 0.26865673, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.2835821 , 0.2835821 , 0.29104477, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41044775,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12931034, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.2413793 , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.7155172 ,\n",
       "            0.7241379 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.76724136, 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.995   , 0.994   , 0.993   , 0.991   , 0.9893  ,\n",
       "            0.989   , 0.988   , 0.9863  , 0.985   , 0.9844  , 0.984   ,\n",
       "            0.982   , 0.98    , 0.978   , 0.973   , 0.9727  , 0.9707  ,\n",
       "            0.97    , 0.9697  , 0.969   , 0.9683  , 0.966   , 0.9634  ,\n",
       "            0.963   , 0.958   , 0.956   , 0.9487  , 0.9473  , 0.9434  ,\n",
       "            0.942   , 0.9414  , 0.941   , 0.9404  , 0.9395  , 0.9336  ,\n",
       "            0.933   , 0.931   , 0.929   , 0.927   , 0.9263  , 0.9116  ,\n",
       "            0.9004  , 0.8975  , 0.893   , 0.8916  , 0.889   , 0.888   ,\n",
       "            0.8867  , 0.885   , 0.8843  , 0.884   , 0.883   , 0.882   ,\n",
       "            0.876   , 0.874   , 0.869   , 0.863   , 0.862   , 0.86    ,\n",
       "            0.8467  , 0.8433  , 0.8423  , 0.8403  , 0.8394  , 0.8384  ,\n",
       "            0.8354  , 0.8325  , 0.8315  , 0.8286  , 0.8276  , 0.8267  ,\n",
       "            0.8213  , 0.821   , 0.8203  , 0.8193  , 0.819   , 0.8164  ,\n",
       "            0.8135  , 0.813   , 0.8125  , 0.811   , 0.8105  , 0.802   ,\n",
       "            0.8013  , 0.8003  , 0.8     , 0.799   , 0.7925  , 0.788   ,\n",
       "            0.785   , 0.776   , 0.7754  , 0.7744  , 0.7734  , 0.773   ,\n",
       "            0.7676  , 0.7646  , 0.7593  , 0.758   , 0.7563  , 0.7544  ,\n",
       "            0.75    , 0.749   , 0.7485  , 0.744   , 0.7437  , 0.7427  ,\n",
       "            0.7393  , 0.7363  , 0.731   , 0.726   , 0.7236  , 0.723   ,\n",
       "            0.722   , 0.7217  , 0.721   , 0.719   , 0.717   , 0.7163  ,\n",
       "            0.711   , 0.702   , 0.7017  , 0.7007  , 0.6997  , 0.694   ,\n",
       "            0.693   , 0.692   , 0.691   , 0.6895  , 0.6875  , 0.6826  ,\n",
       "            0.6714  , 0.6675  , 0.6665  , 0.6646  , 0.661   , 0.6567  ,\n",
       "            0.6484  , 0.6445  , 0.641   , 0.6333  , 0.633   , 0.628   ,\n",
       "            0.625   , 0.6245  , 0.6187  , 0.611   , 0.6     , 0.594   ,\n",
       "            0.5923  , 0.5903  , 0.584   , 0.5723  , 0.5693  , 0.569   ,\n",
       "            0.568   , 0.566   , 0.5645  , 0.5625  , 0.5513  , 0.5425  ,\n",
       "            0.508   , 0.4338  , 0.425   , 0.4229  , 0.406   , 0.3674  ,\n",
       "            0.3484  , 0.3452  , 0.3325  , 0.3193  , 0.3032  , 0.2834  ,\n",
       "            0.2742  , 0.262   , 0.234   , 0.2205  , 0.2158  , 0.2009  ,\n",
       "            0.1948  , 0.1921  , 0.1887  , 0.1833  , 0.1827  , 0.1815  ,\n",
       "            0.1787  , 0.1566  , 0.1565  , 0.1536  , 0.1516  , 0.1509  ,\n",
       "            0.1497  , 0.1268  , 0.111   , 0.10175 , 0.0933  , 0.09125 ,\n",
       "            0.08435 , 0.0821  , 0.0788  , 0.07837 , 0.0745  , 0.0715  ,\n",
       "            0.0655  , 0.06323 , 0.0627  , 0.06165 , 0.0603  , 0.05954 ,\n",
       "            0.05844 , 0.05646 , 0.05234 , 0.05072 , 0.04376 , 0.04248 ,\n",
       "            0.04218 , 0.03516 , 0.02821 , 0.02806 , 0.02405 , 0.02338 ,\n",
       "            0.02284 , 0.01862 , 0.01692 , 0.01567 , 0.01525 , 0.012825,\n",
       "            0.01065 , 0.00971 , 0.005867], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.10447761, 0.10447761, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23134328, 0.23134328, 0.23134328, 0.23134328, 0.23880596,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26865673, 0.26865673, 0.2761194 , 0.2761194 , 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.31343284, 0.31343284,\n",
       "            0.31343284, 0.31343284, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.33620688,\n",
       "            0.35344827, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43103448, 0.43965518, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.54310346, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.996   , 0.995   , 0.9946  , 0.9927  , 0.991   ,\n",
       "            0.9907  , 0.9897  , 0.9883  , 0.9873  , 0.987   , 0.9863  ,\n",
       "            0.985   , 0.9844  , 0.983   , 0.981   , 0.977   , 0.976   ,\n",
       "            0.975   , 0.9746  , 0.974   , 0.9736  , 0.973   , 0.9707  ,\n",
       "            0.97    , 0.9688  , 0.9683  , 0.968   , 0.9634  , 0.962   ,\n",
       "            0.955   , 0.954   , 0.9536  , 0.951   , 0.9487  , 0.948   ,\n",
       "            0.9478  , 0.9434  , 0.9424  , 0.941   , 0.939   , 0.935   ,\n",
       "            0.9346  , 0.925   , 0.913   , 0.91    , 0.9077  , 0.9067  ,\n",
       "            0.9053  , 0.902   , 0.9     , 0.8975  , 0.8965  , 0.8955  ,\n",
       "            0.892   , 0.8916  , 0.8906  , 0.8853  , 0.8833  , 0.8823  ,\n",
       "            0.88    , 0.873   , 0.8657  , 0.8647  , 0.86    , 0.8584  ,\n",
       "            0.858   , 0.8574  , 0.857   , 0.8525  , 0.85    , 0.8457  ,\n",
       "            0.8447  , 0.8438  , 0.8423  , 0.8413  , 0.839   , 0.8384  ,\n",
       "            0.837   , 0.8364  , 0.8354  , 0.8315  , 0.831   , 0.8306  ,\n",
       "            0.826   , 0.8174  , 0.8154  , 0.814   , 0.812   , 0.811   ,\n",
       "            0.81    , 0.8027  , 0.7993  , 0.799   , 0.798   , 0.7974  ,\n",
       "            0.795   , 0.7925  , 0.7915  , 0.7905  , 0.7886  , 0.7866  ,\n",
       "            0.785   , 0.7817  , 0.7803  , 0.778   , 0.7773  , 0.776   ,\n",
       "            0.773   , 0.7725  , 0.772   , 0.7715  , 0.769   , 0.761   ,\n",
       "            0.756   , 0.7554  , 0.755   , 0.7544  , 0.7495  , 0.747   ,\n",
       "            0.746   , 0.7437  , 0.7427  , 0.736   , 0.735   , 0.7344  ,\n",
       "            0.7314  , 0.7305  , 0.726   , 0.7236  , 0.723   , 0.722   ,\n",
       "            0.7217  , 0.719   , 0.7075  , 0.701   , 0.6997  , 0.698   ,\n",
       "            0.6978  , 0.693   , 0.678   , 0.6685  , 0.6665  , 0.666   ,\n",
       "            0.6655  , 0.6646  , 0.6597  , 0.656   , 0.6533  , 0.648   ,\n",
       "            0.6455  , 0.6367  , 0.6333  , 0.6265  , 0.623   , 0.6177  ,\n",
       "            0.6084  , 0.605   , 0.6025  , 0.602   , 0.5923  , 0.5874  ,\n",
       "            0.585   , 0.583   , 0.5195  , 0.4592  , 0.4539  , 0.4412  ,\n",
       "            0.4363  , 0.381   , 0.3623  , 0.3518  , 0.3416  , 0.337   ,\n",
       "            0.3105  , 0.3027  , 0.28    , 0.2654  , 0.2428  , 0.2251  ,\n",
       "            0.22    , 0.2081  , 0.2053  , 0.1943  , 0.1918  , 0.1897  ,\n",
       "            0.1838  , 0.1836  , 0.1798  , 0.1575  , 0.1565  , 0.1547  ,\n",
       "            0.1517  , 0.1301  , 0.10913 , 0.10284 , 0.094   , 0.0901  ,\n",
       "            0.08344 , 0.08136 , 0.0786  , 0.07794 , 0.07227 , 0.0708  ,\n",
       "            0.0641  , 0.06256 , 0.0611  , 0.05988 , 0.0591  , 0.05676 ,\n",
       "            0.0549  , 0.05023 , 0.04868 , 0.04208 , 0.04077 , 0.04025 ,\n",
       "            0.03372 , 0.02646 , 0.02246 , 0.02208 , 0.02153 , 0.01744 ,\n",
       "            0.01567 , 0.01445 , 0.01423 , 0.011734, 0.00982 , 0.00902 ,\n",
       "            0.00526 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.07462686, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.14925373, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.17910448, 0.17910448, 0.18656716,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.20895523, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23134328, 0.23880596, 0.23880596,\n",
       "            0.23880596, 0.25373134, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.31343284, 0.31343284, 0.31343284,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3283582 , 0.33582088,\n",
       "            0.33582088, 0.33582088, 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.11206897, 0.12931034, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.49137932, 0.5       ,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.5862069 , 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.7241379 , 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9966 , 0.9956 , 0.995  , 0.9937 , 0.992  , 0.9917 ,\n",
       "            0.991  , 0.9897 , 0.989  , 0.9883 , 0.9863 , 0.985  , 0.9834 ,\n",
       "            0.9795 , 0.979  , 0.9775 , 0.977  , 0.9766 , 0.9756 , 0.9736 ,\n",
       "            0.973  , 0.9717 , 0.971  , 0.967  , 0.9653 , 0.9595 , 0.959  ,\n",
       "            0.958  , 0.955  , 0.953  , 0.9526 , 0.952  , 0.9517 , 0.947  ,\n",
       "            0.946  , 0.9434 , 0.9404 , 0.94   , 0.9297 , 0.9185 , 0.916  ,\n",
       "            0.913  , 0.912  , 0.9116 , 0.91   , 0.9077 , 0.907  , 0.9033 ,\n",
       "            0.9023 , 0.8984 , 0.8975 , 0.8965 , 0.8916 , 0.89   , 0.888  ,\n",
       "            0.886  , 0.8804 , 0.8726 , 0.871  , 0.8667 , 0.865  , 0.8643 ,\n",
       "            0.864  , 0.8564 , 0.854  , 0.852  , 0.8516 , 0.849  , 0.8486 ,\n",
       "            0.8467 , 0.8457 , 0.845  , 0.8447 , 0.8423 , 0.8403 , 0.84   ,\n",
       "            0.8394 , 0.8384 , 0.834  , 0.8257 , 0.8237 , 0.822  , 0.8203 ,\n",
       "            0.8115 , 0.807  , 0.8066 , 0.8057 , 0.8037 , 0.8013 , 0.7983 ,\n",
       "            0.796  , 0.7915 , 0.7896 , 0.7876 , 0.787  , 0.786  , 0.7847 ,\n",
       "            0.7827 , 0.7817 , 0.7812 , 0.7793 , 0.7744 , 0.766  , 0.7646 ,\n",
       "            0.763  , 0.76   , 0.7593 , 0.757  , 0.7554 , 0.753  , 0.752  ,\n",
       "            0.747  , 0.746  , 0.7456 , 0.7417 , 0.7407 , 0.737  , 0.735  ,\n",
       "            0.734  , 0.7334 , 0.7324 , 0.731  , 0.7217 , 0.7114 , 0.71   ,\n",
       "            0.705  , 0.6904 , 0.679  , 0.678  , 0.6772 , 0.675  , 0.672  ,\n",
       "            0.6665 , 0.6626 , 0.662  , 0.6553 , 0.651  , 0.648  , 0.6406 ,\n",
       "            0.6343 , 0.63   , 0.622  , 0.6187 , 0.6177 , 0.6147 , 0.6143 ,\n",
       "            0.6025 , 0.601  , 0.596  , 0.594  , 0.5317 , 0.4683 , 0.4658 ,\n",
       "            0.448  , 0.4468 , 0.3855 , 0.3665 , 0.3574 , 0.3457 , 0.3416 ,\n",
       "            0.314  , 0.3083 , 0.2822 , 0.2688 , 0.2441 , 0.2242 , 0.219  ,\n",
       "            0.2091 , 0.208  , 0.1935 , 0.1906 , 0.1901 , 0.183  , 0.1824 ,\n",
       "            0.1788 , 0.1589 , 0.1581 , 0.157  , 0.1567 , 0.1532 , 0.1506 ,\n",
       "            0.1298 , 0.1086 , 0.10126, 0.0927 , 0.088  , 0.08136, 0.07935,\n",
       "            0.0772 , 0.076  , 0.0712 , 0.0689 , 0.06223, 0.0611 , 0.05933,\n",
       "            0.05814, 0.0578 , 0.0575 , 0.0547 , 0.05283, 0.0485 , 0.04742,\n",
       "            0.04016, 0.03897, 0.0321 , 0.02513, 0.02504, 0.02121, 0.0208 ,\n",
       "            0.02025, 0.01634, 0.01462, 0.01348, 0.01322, 0.0109 , 0.00909,\n",
       "            0.00835, 0.00479], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.21641791, 0.2238806 , 0.2238806 , 0.2238806 , 0.23134328,\n",
       "            0.23134328, 0.23880596, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26119402, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.3283582 , 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.09482758, 0.11206897, 0.12931034, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.21551724,\n",
       "            0.22413793, 0.2413793 , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.35344827, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.43965518, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.51724136, 0.51724136, 0.5258621 , 0.5344828 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9976  , 0.9966  , 0.996   , 0.995   , 0.9946  ,\n",
       "            0.9937  , 0.993   , 0.9927  , 0.9917  , 0.9907  , 0.99    ,\n",
       "            0.989   , 0.9873  , 0.986   , 0.9824  , 0.982   , 0.981   ,\n",
       "            0.9805  , 0.98    , 0.9795  , 0.977   , 0.976   , 0.975   ,\n",
       "            0.971   , 0.97    , 0.965   , 0.9644  , 0.964   , 0.9614  ,\n",
       "            0.959   , 0.958   , 0.956   , 0.9536  , 0.9526  , 0.951   ,\n",
       "            0.948   , 0.9473  , 0.9395  , 0.9287  , 0.9277  , 0.9263  ,\n",
       "            0.9253  , 0.9233  , 0.922   , 0.9204  , 0.919   , 0.9155  ,\n",
       "            0.914   , 0.913   , 0.91    , 0.9097  , 0.908   , 0.904   ,\n",
       "            0.901   , 0.9004  , 0.891   , 0.8896  , 0.888   , 0.8853  ,\n",
       "            0.884   , 0.8833  , 0.8823  , 0.881   , 0.879   , 0.8765  ,\n",
       "            0.8755  , 0.8716  , 0.8706  , 0.868   , 0.867   , 0.866   ,\n",
       "            0.8657  , 0.8643  , 0.8633  , 0.862   , 0.8594  , 0.856   ,\n",
       "            0.8555  , 0.8496  , 0.848   , 0.8467  , 0.846   , 0.8423  ,\n",
       "            0.8403  , 0.834   , 0.832   , 0.8286  , 0.828   , 0.8267  ,\n",
       "            0.8247  , 0.824   , 0.82    , 0.8184  , 0.818   , 0.8164  ,\n",
       "            0.813   , 0.8125  , 0.812   , 0.8096  , 0.807   , 0.8066  ,\n",
       "            0.806   , 0.805   , 0.8037  , 0.7964  , 0.794   , 0.7905  ,\n",
       "            0.787   , 0.7847  , 0.784   , 0.7783  , 0.7764  , 0.7754  ,\n",
       "            0.7744  , 0.774   , 0.772   , 0.768   , 0.765   , 0.7646  ,\n",
       "            0.763   , 0.7627  , 0.762   , 0.7617  , 0.7607  , 0.76    ,\n",
       "            0.755   , 0.7407  , 0.7393  , 0.7383  , 0.736   , 0.72    ,\n",
       "            0.714   , 0.7075  , 0.7056  , 0.703   , 0.7026  , 0.6997  ,\n",
       "            0.6943  , 0.6875  , 0.6826  , 0.6816  , 0.68    , 0.673   ,\n",
       "            0.662   , 0.6606  , 0.6543  , 0.6514  , 0.6504  , 0.645   ,\n",
       "            0.638   , 0.632   , 0.626   , 0.6216  , 0.5527  , 0.4988  ,\n",
       "            0.4963  , 0.4805  , 0.468   , 0.404   , 0.3848  , 0.372   ,\n",
       "            0.3635  , 0.3613  , 0.331   , 0.328   , 0.294   , 0.2786  ,\n",
       "            0.2563  , 0.2327  , 0.2272  , 0.2212  , 0.2194  , 0.1996  ,\n",
       "            0.1993  , 0.197   , 0.1886  , 0.1882  , 0.1842  , 0.1676  ,\n",
       "            0.1671  , 0.1615  , 0.161   , 0.1573  , 0.1543  , 0.1348  ,\n",
       "            0.1101  , 0.10376 , 0.09503 , 0.089   , 0.0823  , 0.0804  ,\n",
       "            0.0788  , 0.07666 , 0.07135 , 0.0695  , 0.0621  , 0.0619  ,\n",
       "            0.0589  , 0.05856 , 0.0578  , 0.05737 , 0.0542  , 0.05243 ,\n",
       "            0.04788 , 0.0469  , 0.03943 , 0.0384  , 0.03818 , 0.0313  ,\n",
       "            0.02428 , 0.02419 , 0.02034 , 0.02002 , 0.01945 , 0.0156  ,\n",
       "            0.0139  , 0.012726, 0.01257 , 0.01025 , 0.008545, 0.00787 ,\n",
       "            0.0044  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.51492536, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20149253, 0.20149253, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.2238806 , 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.23880596, 0.23880596, 0.24626866, 0.26119402,\n",
       "            0.26865673, 0.26865673, 0.2761194 , 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.10344828, 0.11206897,\n",
       "            0.12931034, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.20689656, 0.22413793, 0.2413793 , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.33620688, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.4051724 , 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.46551725, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.51724136, 0.5258621 ,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.61206895, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.88793105, 0.88793105, 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.998  , 0.997  , 0.996  , 0.995  , 0.9946 , 0.994  ,\n",
       "            0.993  , 0.992  , 0.9917 , 0.9907 , 0.9893 , 0.9883 , 0.9854 ,\n",
       "            0.985  , 0.984  , 0.9834 , 0.983  , 0.9805 , 0.98   , 0.9785 ,\n",
       "            0.9756 , 0.974  , 0.97   , 0.9697 , 0.9688 , 0.9673 , 0.965  ,\n",
       "            0.9644 , 0.964  , 0.96   , 0.9585 , 0.955  , 0.954  , 0.949  ,\n",
       "            0.941  , 0.9385 , 0.9365 , 0.936  , 0.933  , 0.932  , 0.931  ,\n",
       "            0.929  , 0.9277 , 0.9272 , 0.9253 , 0.9243 , 0.924  , 0.923  ,\n",
       "            0.9224 , 0.9185 , 0.918  , 0.914  , 0.9097 , 0.908  , 0.9043 ,\n",
       "            0.904  , 0.9014 , 0.9004 , 0.899  , 0.897  , 0.8965 , 0.893  ,\n",
       "            0.8926 , 0.8896 , 0.888  , 0.8867 , 0.886  , 0.8857 , 0.8853 ,\n",
       "            0.885  , 0.88   , 0.8794 , 0.876  , 0.875  , 0.874  , 0.873  ,\n",
       "            0.872  , 0.867  , 0.866  , 0.8633 , 0.8584 , 0.8555 , 0.855  ,\n",
       "            0.8525 , 0.851  , 0.8506 , 0.8496 , 0.849  , 0.847  , 0.846  ,\n",
       "            0.8438 , 0.8433 , 0.8423 , 0.8384 , 0.838  , 0.8354 , 0.835  ,\n",
       "            0.834  , 0.832  , 0.8306 , 0.83   , 0.8286 , 0.824  , 0.8213 ,\n",
       "            0.8203 , 0.8154 , 0.8125 , 0.808  , 0.806  , 0.8027 , 0.802  ,\n",
       "            0.8003 , 0.799  , 0.7983 , 0.797  , 0.7935 , 0.792  , 0.7915 ,\n",
       "            0.791  , 0.7905 , 0.79   , 0.787  , 0.7866 , 0.783  , 0.77   ,\n",
       "            0.7686 , 0.7676 , 0.765  , 0.764  , 0.7495 , 0.747  , 0.7363 ,\n",
       "            0.734  , 0.7334 , 0.7256 , 0.7246 , 0.722  , 0.7217 , 0.714  ,\n",
       "            0.711  , 0.7046 , 0.704  , 0.6904 , 0.6895 , 0.6855 , 0.684  ,\n",
       "            0.682  , 0.675  , 0.6743 , 0.659  , 0.655  , 0.645  , 0.572  ,\n",
       "            0.529  , 0.522  , 0.5093 , 0.4873 , 0.4207 , 0.4011 , 0.3848 ,\n",
       "            0.3833 , 0.3745 , 0.351  , 0.3396 , 0.3035 , 0.287  , 0.266  ,\n",
       "            0.2384 , 0.2327 , 0.2319 , 0.2273 , 0.206  , 0.2037 , 0.201  ,\n",
       "            0.1923 , 0.1917 , 0.1877 , 0.1741 , 0.1738 , 0.1644 , 0.1641 ,\n",
       "            0.1598 , 0.1565 , 0.1381 , 0.1105 , 0.1043 , 0.0955 , 0.0887 ,\n",
       "            0.08167, 0.0799 , 0.0786 , 0.0761 , 0.0708 , 0.0688 , 0.0613 ,\n",
       "            0.06085, 0.0578 , 0.0577 , 0.05685, 0.05624, 0.053  , 0.05118,\n",
       "            0.0468 , 0.04596, 0.03812, 0.03732, 0.03683, 0.03004, 0.0232 ,\n",
       "            0.02298, 0.0192 , 0.01894, 0.0184 , 0.01467, 0.01297, 0.01187,\n",
       "            0.01169, 0.00952, 0.00787, 0.00726, 0.00399], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.52238804, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.09701493, 0.1119403 , 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.13432837, 0.13432837,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.1641791 , 0.1716418 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.20149253, 0.20149253, 0.20149253,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.2238806 , 0.23134328, 0.23134328,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.26865673, 0.2761194 , 0.2761194 , 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.04310345, 0.06034483,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.19827586, 0.22413793, 0.2413793 , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.33620688, 0.3448276 , 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.4051724 , 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.51724136, 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.5689655 , 0.5862069 , 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.6465517 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.70689654, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.87068963, 0.87931037, 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9985  , 0.9976  , 0.9966  , 0.9956  , 0.995   ,\n",
       "            0.994   , 0.9937  , 0.993   , 0.9917  , 0.991   , 0.9907  ,\n",
       "            0.9897  , 0.9873  , 0.987   , 0.986   , 0.9854  , 0.983   ,\n",
       "            0.9824  , 0.9814  , 0.9785  , 0.9775  , 0.974   , 0.973   ,\n",
       "            0.9727  , 0.9717  , 0.969   , 0.9688  , 0.9683  , 0.968   ,\n",
       "            0.965   , 0.9634  , 0.96    , 0.959   , 0.955   , 0.9487  ,\n",
       "            0.9453  , 0.944   , 0.9434  , 0.941   , 0.94    , 0.939   ,\n",
       "            0.9365  , 0.9355  , 0.935   , 0.934   , 0.931   , 0.9307  ,\n",
       "            0.93    , 0.929   , 0.9272  , 0.923   , 0.922   , 0.9185  ,\n",
       "            0.9155  , 0.914   , 0.9126  , 0.9106  , 0.9097  , 0.9067  ,\n",
       "            0.9043  , 0.904   , 0.901   , 0.9     , 0.8994  , 0.899   ,\n",
       "            0.8984  , 0.898   , 0.8975  , 0.897   , 0.896   , 0.891   ,\n",
       "            0.8906  , 0.8896  , 0.889   , 0.8843  , 0.884   , 0.8804  ,\n",
       "            0.879   , 0.876   , 0.871   , 0.87    , 0.868   , 0.867   ,\n",
       "            0.8657  , 0.865   , 0.863   , 0.8623  , 0.8613  , 0.861   ,\n",
       "            0.86    , 0.8594  , 0.8564  , 0.855   , 0.854   , 0.8516  ,\n",
       "            0.8506  , 0.8486  , 0.848   , 0.846   , 0.8457  , 0.8447  ,\n",
       "            0.843   , 0.8423  , 0.8374  , 0.836   , 0.8315  , 0.8296  ,\n",
       "            0.8237  , 0.821   , 0.82    , 0.8174  , 0.814   , 0.8125  ,\n",
       "            0.812   , 0.81    , 0.8096  , 0.8086  , 0.808   , 0.8076  ,\n",
       "            0.805   , 0.804   , 0.7983  , 0.7896  , 0.787   , 0.786   ,\n",
       "            0.785   , 0.7817  , 0.7695  , 0.7686  , 0.7563  , 0.7534  ,\n",
       "            0.747   , 0.7407  , 0.74    , 0.7383  , 0.737   , 0.7354  ,\n",
       "            0.728   , 0.7256  , 0.721   , 0.7114  , 0.708   , 0.7075  ,\n",
       "            0.707   , 0.704   , 0.7     , 0.696   , 0.695   , 0.679   ,\n",
       "            0.676   , 0.663   , 0.591   , 0.553   , 0.5425  , 0.5337  ,\n",
       "            0.503   , 0.4348  , 0.4148  , 0.3997  , 0.3984  , 0.3877  ,\n",
       "            0.3684  , 0.3516  , 0.3142  , 0.2976  , 0.276   , 0.2452  ,\n",
       "            0.2426  , 0.239   , 0.2352  , 0.2133  , 0.209   , 0.206   ,\n",
       "            0.1974  , 0.1965  , 0.1927  , 0.1814  , 0.1813  , 0.1697  ,\n",
       "            0.1694  , 0.1635  , 0.1603  , 0.1423  , 0.11316 , 0.1067  ,\n",
       "            0.0977  , 0.0899  , 0.0828  , 0.08093 , 0.0802  , 0.0772  ,\n",
       "            0.07196 , 0.0695  , 0.06232 , 0.0611  , 0.05814 , 0.058   ,\n",
       "            0.05737 , 0.05624 , 0.053   , 0.0511  , 0.0468  , 0.0463  ,\n",
       "            0.0378  , 0.03748 , 0.03656 , 0.02975 , 0.02293 , 0.02258 ,\n",
       "            0.01883 , 0.01859 , 0.01805 , 0.014336, 0.01263 , 0.01155 ,\n",
       "            0.011375, 0.00919 , 0.007607, 0.00704 , 0.003809], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.52238804, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.07462686, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.13432837, 0.14179105, 0.14179105,\n",
       "            0.14179105, 0.14179105, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20149253,\n",
       "            0.20149253, 0.20149253, 0.20895523, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.26865673, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.29850745,\n",
       "            0.29850745, 0.29850745, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.36567163, 0.36567163, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41044775,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.46268657, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.04310345, 0.05172414,\n",
       "            0.06896552, 0.0775862 , 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.21551724, 0.22413793, 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.35344827,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.44827586, 0.45689654, 0.45689654, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.54310346, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9985  , 0.998   , 0.997   , 0.9966  , 0.996   ,\n",
       "            0.995   , 0.9946  , 0.994   , 0.993   , 0.9927  , 0.992   ,\n",
       "            0.991   , 0.9893  , 0.989   , 0.9883  , 0.988   , 0.9873  ,\n",
       "            0.9854  , 0.985   , 0.984   , 0.9814  , 0.9805  , 0.9775  ,\n",
       "            0.9766  , 0.976   , 0.9756  , 0.975   , 0.9736  , 0.973   ,\n",
       "            0.972   , 0.969   , 0.9688  , 0.968   , 0.965   , 0.964   ,\n",
       "            0.9624  , 0.959   , 0.953   , 0.9526  , 0.9517  , 0.951   ,\n",
       "            0.9473  , 0.947   , 0.9443  , 0.9434  , 0.943   , 0.9414  ,\n",
       "            0.94    , 0.939   , 0.9385  , 0.938   , 0.9336  , 0.932   ,\n",
       "            0.93    , 0.9272  , 0.9263  , 0.924   , 0.923   , 0.919   ,\n",
       "            0.918   , 0.917   , 0.9165  , 0.916   , 0.9146  , 0.914   ,\n",
       "            0.9126  , 0.912   , 0.911   , 0.9106  , 0.9097  , 0.9062  ,\n",
       "            0.906   , 0.901   , 0.8984  , 0.8975  , 0.896   , 0.8955  ,\n",
       "            0.894   , 0.8906  , 0.8896  , 0.889   , 0.8867  , 0.886   ,\n",
       "            0.8857  , 0.885   , 0.8813  , 0.8804  , 0.88    , 0.8794  ,\n",
       "            0.879   , 0.878   , 0.8774  , 0.876   , 0.871   , 0.8687  ,\n",
       "            0.867   , 0.8667  , 0.8657  , 0.865   , 0.8633  , 0.861   ,\n",
       "            0.854   , 0.8525  , 0.8467  , 0.8457  , 0.845   , 0.8447  ,\n",
       "            0.842   , 0.8403  , 0.8374  , 0.837   , 0.835   , 0.8345  ,\n",
       "            0.834   , 0.8335  , 0.833   , 0.832   , 0.8315  , 0.829   ,\n",
       "            0.8286  , 0.828   , 0.8228  , 0.8174  , 0.814   , 0.813   ,\n",
       "            0.8125  , 0.806   , 0.802   , 0.7964  , 0.7837  , 0.782   ,\n",
       "            0.7803  , 0.7783  , 0.769   , 0.767   , 0.7666  , 0.76    ,\n",
       "            0.759   , 0.757   , 0.75    , 0.7446  , 0.742   , 0.7407  ,\n",
       "            0.7393  , 0.7373  , 0.736   , 0.726   , 0.7246  , 0.7075  ,\n",
       "            0.706   , 0.6836  , 0.603   , 0.5884  , 0.5713  , 0.569   ,\n",
       "            0.5215  , 0.4514  , 0.4316  , 0.4229  , 0.4072  , 0.399   ,\n",
       "            0.394   , 0.3616  , 0.3228  , 0.3025  , 0.288   , 0.2578  ,\n",
       "            0.252   , 0.2455  , 0.2449  , 0.2224  , 0.2128  , 0.2106  ,\n",
       "            0.2004  , 0.2     , 0.1958  , 0.1917  , 0.1913  , 0.1708  ,\n",
       "            0.1705  , 0.166   , 0.1617  , 0.1477  , 0.112   , 0.1093  ,\n",
       "            0.1     , 0.0896  , 0.083   , 0.08167 , 0.08124 , 0.0772  ,\n",
       "            0.07043 , 0.06964 , 0.0629  , 0.0601  , 0.05792 , 0.0575  ,\n",
       "            0.05676 , 0.0552  , 0.05203 , 0.05023 , 0.04553 , 0.04477 ,\n",
       "            0.03662 , 0.03607 , 0.0354  , 0.02887 , 0.02182 , 0.02153 ,\n",
       "            0.01778 , 0.01772 , 0.01718 , 0.01359 , 0.011826, 0.01078 ,\n",
       "            0.010735, 0.008545, 0.007122, 0.00664 , 0.003456], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.52238804, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14179105, 0.14179105,\n",
       "            0.14179105, 0.14179105, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1641791 , 0.1641791 , 0.17910448, 0.17910448,\n",
       "            0.18656716, 0.18656716, 0.19402985, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23134328,\n",
       "            0.23134328, 0.23880596, 0.23880596, 0.24626866, 0.24626866,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29850745,\n",
       "            0.29850745, 0.29850745, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.04310345, 0.06034483,\n",
       "            0.06896552, 0.0775862 , 0.09482758, 0.11206897, 0.12931034,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.20689656,\n",
       "            0.22413793, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.30172414, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.35344827, 0.37931034, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.43103448, 0.43103448, 0.43965518, 0.43965518,\n",
       "            0.45689654, 0.45689654, 0.46551725, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.49137932, 0.5       , 0.51724136,\n",
       "            0.5258621 , 0.54310346, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6810345 , 0.6896552 , 0.6896552 , 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.999   , 0.9985  , 0.9976  , 0.997   , 0.9966  ,\n",
       "            0.996   , 0.9956  , 0.995   , 0.994   , 0.9937  , 0.9927  ,\n",
       "            0.9907  , 0.99    , 0.9897  , 0.9893  , 0.988   , 0.9873  ,\n",
       "            0.987   , 0.986   , 0.984   , 0.983   , 0.98    , 0.9795  ,\n",
       "            0.979   , 0.977   , 0.9766  , 0.9756  , 0.9736  , 0.9717  ,\n",
       "            0.9688  , 0.9683  , 0.9624  , 0.9614  , 0.961   , 0.9595  ,\n",
       "            0.959   , 0.958   , 0.9575  , 0.956   , 0.9536  , 0.9526  ,\n",
       "            0.952   , 0.95    , 0.949   , 0.948   , 0.9453  , 0.945   ,\n",
       "            0.9443  , 0.943   , 0.942   , 0.941   , 0.9395  , 0.9355  ,\n",
       "            0.935   , 0.934   , 0.9336  , 0.933   , 0.9326  , 0.9307  ,\n",
       "            0.93    , 0.9297  , 0.929   , 0.9277  , 0.9263  , 0.924   ,\n",
       "            0.923   , 0.92    , 0.9194  , 0.9155  , 0.9116  , 0.911   ,\n",
       "            0.91    , 0.9097  , 0.9077  , 0.9067  , 0.9053  , 0.9043  ,\n",
       "            0.903   , 0.901   , 0.899   , 0.898   , 0.8975  , 0.8965  ,\n",
       "            0.8955  , 0.8945  , 0.893   , 0.8916  , 0.886   , 0.8857  ,\n",
       "            0.8853  , 0.885   , 0.8843  , 0.8833  , 0.876   , 0.871   ,\n",
       "            0.8696  , 0.8667  , 0.866   , 0.8643  , 0.8604  , 0.8594  ,\n",
       "            0.859   , 0.8574  , 0.857   , 0.856   , 0.853   , 0.852   ,\n",
       "            0.85    , 0.8457  , 0.8413  , 0.84    , 0.839   , 0.834   ,\n",
       "            0.8315  , 0.8306  , 0.8247  , 0.8125  , 0.812   , 0.81    ,\n",
       "            0.8086  , 0.803   , 0.7993  , 0.7944  , 0.7896  , 0.781   ,\n",
       "            0.779   , 0.777   , 0.776   , 0.7734  , 0.773   , 0.7725  ,\n",
       "            0.77    , 0.7695  , 0.764   , 0.7583  , 0.756   , 0.738   ,\n",
       "            0.7373  , 0.7075  , 0.632   , 0.62    , 0.613   , 0.608   ,\n",
       "            0.5464  , 0.4746  , 0.4565  , 0.456   , 0.4312  , 0.422   ,\n",
       "            0.4163  , 0.3777  , 0.337   , 0.313   , 0.3083  , 0.283   ,\n",
       "            0.2651  , 0.263   , 0.2573  , 0.2379  , 0.2222  , 0.2211  ,\n",
       "            0.2096  , 0.2089  , 0.2086  , 0.2084  , 0.2037  , 0.1758  ,\n",
       "            0.1755  , 0.1733  , 0.1672  , 0.1586  , 0.11597 , 0.1136  ,\n",
       "            0.10614 , 0.09204 , 0.0863  , 0.0859  , 0.08417 , 0.0799  ,\n",
       "            0.07227 , 0.0707  , 0.0656  , 0.0611  , 0.05997 , 0.05975 ,\n",
       "            0.05707 , 0.05594 , 0.0526  , 0.0511  , 0.04553 , 0.04453 ,\n",
       "            0.03677 , 0.03574 , 0.0354  , 0.02898 , 0.02145 , 0.02129 ,\n",
       "            0.01758 , 0.01738 , 0.01698 , 0.01333 , 0.01142 , 0.01049 ,\n",
       "            0.01041 , 0.00822 , 0.00693 , 0.00651 , 0.003248], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5298507, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.07462686, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14179105, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.1641791 , 0.17910448, 0.17910448,\n",
       "            0.17910448, 0.17910448, 0.17910448, 0.17910448, 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23880596, 0.23880596, 0.23880596,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.29850745, 0.29850745, 0.29850745, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.35074627, 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41044775,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01724138, 0.02586207, 0.04310345, 0.06896552,\n",
       "            0.0775862 , 0.10344828, 0.11206897, 0.12931034, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18965517, 0.21551724,\n",
       "            0.22413793, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3448276 , 0.35344827, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8534483 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.999   , 0.9985  , 0.998   , 0.9976  , 0.997   ,\n",
       "            0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  , 0.994   ,\n",
       "            0.9927  , 0.992   , 0.9917  , 0.991   , 0.99    , 0.9897  ,\n",
       "            0.9893  , 0.989   , 0.987   , 0.9863  , 0.9854  , 0.9844  ,\n",
       "            0.984   , 0.9834  , 0.983   , 0.9814  , 0.981   , 0.98    ,\n",
       "            0.9795  , 0.979   , 0.9785  , 0.977   , 0.9766  , 0.9756  ,\n",
       "            0.974   , 0.9736  , 0.972   , 0.97    , 0.9697  , 0.969   ,\n",
       "            0.9688  , 0.9673  , 0.967   , 0.966   , 0.965   , 0.962   ,\n",
       "            0.9614  , 0.961   , 0.9604  , 0.958   , 0.9575  , 0.956   ,\n",
       "            0.954   , 0.9536  , 0.952   , 0.9507  , 0.949   , 0.9487  ,\n",
       "            0.948   , 0.947   , 0.9453  , 0.945   , 0.944   , 0.943   ,\n",
       "            0.941   , 0.939   , 0.9385  , 0.9355  , 0.9326  , 0.931   ,\n",
       "            0.929   , 0.9287  , 0.928   , 0.9272  , 0.926   , 0.9253  ,\n",
       "            0.9243  , 0.923   , 0.9224  , 0.9204  , 0.92    , 0.918   ,\n",
       "            0.9165  , 0.916   , 0.915   , 0.9146  , 0.914   , 0.913   ,\n",
       "            0.912   , 0.907   , 0.9067  , 0.9062  , 0.9053  , 0.905   ,\n",
       "            0.9043  , 0.904   , 0.899   , 0.8984  , 0.895   , 0.894   ,\n",
       "            0.893   , 0.89    , 0.8887  , 0.8857  , 0.885   , 0.884   ,\n",
       "            0.882   , 0.881   , 0.88    , 0.8784  , 0.878   , 0.8765  ,\n",
       "            0.873   , 0.872   , 0.869   , 0.867   , 0.8667  , 0.866   ,\n",
       "            0.8643  , 0.8594  , 0.8564  , 0.854   , 0.853   , 0.842   ,\n",
       "            0.8413  , 0.841   , 0.837   , 0.835   , 0.831   , 0.823   ,\n",
       "            0.8223  , 0.8135  , 0.81    , 0.8057  , 0.8022  , 0.798   ,\n",
       "            0.7974  , 0.7944  , 0.7905  , 0.7876  , 0.7705  , 0.768   ,\n",
       "            0.7393  , 0.674   , 0.655   , 0.6514  , 0.6455  , 0.5786  ,\n",
       "            0.505   , 0.492   , 0.4863  , 0.4695  , 0.4497  , 0.4448  ,\n",
       "            0.4038  , 0.361   , 0.334   , 0.332   , 0.31    , 0.2832  ,\n",
       "            0.283   , 0.2744  , 0.2556  , 0.236   , 0.2351  , 0.2283  ,\n",
       "            0.2273  , 0.2218  , 0.2217  , 0.2167  , 0.1874  , 0.187   ,\n",
       "            0.1837  , 0.177   , 0.1708  , 0.1236  , 0.1197  , 0.1126  ,\n",
       "            0.0962  , 0.09106 , 0.0899  , 0.0882  , 0.0836  , 0.07544 ,\n",
       "            0.07385 , 0.06854 , 0.06305 , 0.06232 , 0.06223 , 0.0592  ,\n",
       "            0.0576  , 0.0541  , 0.05243 , 0.04672 , 0.04596 , 0.03732 ,\n",
       "            0.0367  , 0.03595 , 0.02937 , 0.02153 , 0.02129 , 0.01758 ,\n",
       "            0.01738 , 0.01692 , 0.01322 , 0.011246, 0.01037 , 0.01021 ,\n",
       "            0.00803 , 0.006798, 0.006413, 0.00311 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5522388, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.12686567, 0.13432837, 0.13432837, 0.14179105, 0.14179105,\n",
       "            0.14179105, 0.14925373, 0.14925373, 0.15671642, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.17910448, 0.17910448,\n",
       "            0.17910448, 0.17910448, 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.19402985, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2835821 , 0.29104477, 0.29850745, 0.29850745,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.05172414, 0.06896552,\n",
       "            0.10344828, 0.11206897, 0.13793103, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.19827586, 0.22413793, 0.23275863, 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.3448276 ,\n",
       "            0.35344827, 0.37068966, 0.39655173, 0.4051724 , 0.4051724 ,\n",
       "            0.41379312, 0.41379312, 0.43103448, 0.44827586, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.47413793, 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.5603448 , 0.57758623,\n",
       "            0.57758623, 0.5948276 , 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.9956  , 0.9946  , 0.994   ,\n",
       "            0.9937  , 0.9927  , 0.992   , 0.9917  , 0.991   , 0.99    ,\n",
       "            0.9897  , 0.9893  , 0.988   , 0.9873  , 0.987   , 0.9863  ,\n",
       "            0.986   , 0.9854  , 0.9844  , 0.984   , 0.9834  , 0.9824  ,\n",
       "            0.982   , 0.981   , 0.979   , 0.9785  , 0.978   , 0.9775  ,\n",
       "            0.976   , 0.9746  , 0.9736  , 0.9717  , 0.971   , 0.9707  ,\n",
       "            0.97    , 0.9697  , 0.969   , 0.968   , 0.967   , 0.9653  ,\n",
       "            0.965   , 0.964   , 0.9634  , 0.963   , 0.9624  , 0.961   ,\n",
       "            0.96    , 0.9595  , 0.958   , 0.9575  , 0.9565  , 0.9546  ,\n",
       "            0.954   , 0.951   , 0.95    , 0.9497  , 0.948   , 0.9478  ,\n",
       "            0.947   , 0.9463  , 0.946   , 0.9434  , 0.943   , 0.9424  ,\n",
       "            0.941   , 0.9404  , 0.9375  , 0.9365  , 0.936   , 0.935   ,\n",
       "            0.9346  , 0.934   , 0.9326  , 0.929   , 0.928   , 0.9277  ,\n",
       "            0.9263  , 0.926   , 0.925   , 0.922   , 0.9214  , 0.9194  ,\n",
       "            0.919   , 0.916   , 0.9146  , 0.9116  , 0.911   , 0.9106  ,\n",
       "            0.909   , 0.9077  , 0.907   , 0.9043  , 0.904   , 0.902   ,\n",
       "            0.9014  , 0.8975  , 0.8955  , 0.8945  , 0.894   , 0.8867  ,\n",
       "            0.8833  , 0.883   , 0.882   , 0.8745  , 0.874   , 0.873   ,\n",
       "            0.8716  , 0.868   , 0.867   , 0.8647  , 0.857   , 0.854   ,\n",
       "            0.851   , 0.845   , 0.8413  , 0.84    , 0.8384  , 0.8335  ,\n",
       "            0.8296  , 0.828   , 0.827   , 0.8267  , 0.8257  , 0.8223  ,\n",
       "            0.805   , 0.8013  , 0.7686  , 0.7173  , 0.6978  , 0.6836  ,\n",
       "            0.676   , 0.608   , 0.5327  , 0.5254  , 0.513   , 0.5054  ,\n",
       "            0.471   , 0.4683  , 0.4258  , 0.38    , 0.3523  , 0.3484  ,\n",
       "            0.3342  , 0.3003  , 0.2969  , 0.2861  , 0.2683  , 0.2455  ,\n",
       "            0.2438  , 0.243   , 0.2422  , 0.2302  , 0.2294  , 0.2249  ,\n",
       "            0.1936  , 0.1935  , 0.1892  , 0.1821  , 0.1783  , 0.127   ,\n",
       "            0.1216  , 0.1152  , 0.09686 , 0.0925  , 0.09076 , 0.089   ,\n",
       "            0.08405 , 0.07544 , 0.074   , 0.06854 , 0.06223 , 0.06198 ,\n",
       "            0.0619  , 0.0589  , 0.05676 , 0.0532  , 0.05154 , 0.04587 ,\n",
       "            0.04535 , 0.03622 , 0.03595 , 0.03482 , 0.02834 , 0.0206  ,\n",
       "            0.02025 , 0.01666 , 0.01653 , 0.01602 , 0.01243 , 0.01045 ,\n",
       "            0.009636, 0.00948 , 0.007404, 0.006264, 0.005936, 0.0028  ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5597015, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.05970149,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14179105, 0.14179105, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.1641791 , 0.1641791 , 0.1716418 , 0.17910448, 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.25373134, 0.26119402, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29850745, 0.29850745, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.31343284, 0.31343284,\n",
       "            0.31343284, 0.31343284, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.02586207, 0.05172414, 0.0775862 , 0.11206897,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.1724138 , 0.18965517,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25862068, 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.3448276 ,\n",
       "            0.35344827, 0.37068966, 0.37068966, 0.38793105, 0.4051724 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5258621 , 0.5344828 , 0.5344828 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.70689654, 0.70689654, 0.7155172 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  ,\n",
       "            0.994   , 0.9937  , 0.993   , 0.992   , 0.9917  , 0.9907  ,\n",
       "            0.99    , 0.9893  , 0.989   , 0.9883  , 0.988   , 0.9873  ,\n",
       "            0.987   , 0.9854  , 0.985   , 0.9844  , 0.984   , 0.983   ,\n",
       "            0.9824  , 0.9805  , 0.9795  , 0.979   , 0.9785  , 0.978   ,\n",
       "            0.9766  , 0.976   , 0.9756  , 0.975   , 0.9746  , 0.974   ,\n",
       "            0.9736  , 0.9727  , 0.9717  , 0.9707  , 0.97    , 0.969   ,\n",
       "            0.968   , 0.9673  , 0.967   , 0.966   , 0.9644  , 0.9634  ,\n",
       "            0.963   , 0.9624  , 0.962   , 0.961   , 0.9595  , 0.958   ,\n",
       "            0.9575  , 0.956   , 0.9556  , 0.9536  , 0.953   , 0.9526  ,\n",
       "            0.951   , 0.9507  , 0.95    , 0.949   , 0.9487  , 0.948   ,\n",
       "            0.947   , 0.946   , 0.945   , 0.9443  , 0.943   , 0.9424  ,\n",
       "            0.941   , 0.9404  , 0.94    , 0.9395  , 0.9385  , 0.937   ,\n",
       "            0.9346  , 0.932   , 0.9316  , 0.931   , 0.9297  , 0.9287  ,\n",
       "            0.928   , 0.9253  , 0.925   , 0.9243  , 0.924   , 0.9233  ,\n",
       "            0.922   , 0.921   , 0.92    , 0.9175  , 0.917   , 0.9155  ,\n",
       "            0.9106  , 0.9077  , 0.9062  , 0.905   , 0.902   , 0.901   ,\n",
       "            0.8994  , 0.8975  , 0.8965  , 0.8936  , 0.893   , 0.8867  ,\n",
       "            0.8833  , 0.8804  , 0.8765  , 0.873   , 0.87    , 0.858   ,\n",
       "            0.857   , 0.856   , 0.8555  , 0.8535  , 0.853   , 0.852   ,\n",
       "            0.836   , 0.8315  , 0.798   , 0.7573  , 0.739   , 0.72    ,\n",
       "            0.7065  , 0.641   , 0.565   , 0.5635  , 0.546   , 0.545   ,\n",
       "            0.501   , 0.4998  , 0.4556  , 0.407   , 0.3784  , 0.3726  ,\n",
       "            0.3643  , 0.3232  , 0.3179  , 0.3062  , 0.2876  , 0.2632  ,\n",
       "            0.2627  , 0.262   , 0.2595  , 0.247   , 0.2437  , 0.2397  ,\n",
       "            0.2075  , 0.207   , 0.2007  , 0.1941  , 0.1919  , 0.1355  ,\n",
       "            0.1292  , 0.12213 , 0.10144 , 0.0977  , 0.09515 , 0.0932  ,\n",
       "            0.0882  , 0.0786  , 0.07794 , 0.0716  , 0.0643  , 0.06152 ,\n",
       "            0.05856 , 0.0548  , 0.053   , 0.04733 , 0.04724 , 0.0372  ,\n",
       "            0.0369  , 0.0355  , 0.02881 , 0.02092 , 0.02042 , 0.01672 ,\n",
       "            0.0161  , 0.01243 , 0.01041 , 0.00956 , 0.009415, 0.007317,\n",
       "            0.00619 , 0.005867, 0.002726], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5671642, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14179105, 0.14179105,\n",
       "            0.14925373, 0.1641791 , 0.1716418 , 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.17910448, 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20149253, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23134328, 0.23880596, 0.23880596,\n",
       "            0.24626866, 0.26119402, 0.26865673, 0.2761194 , 0.29104477,\n",
       "            0.29850745, 0.29850745, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.04310345, 0.0775862 , 0.11206897, 0.14655173,\n",
       "            0.1637931 , 0.1724138 , 0.20689656, 0.23275863, 0.25      ,\n",
       "            0.25862068, 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3448276 , 0.36206895, 0.37068966,\n",
       "            0.4051724 , 0.43103448, 0.43965518, 0.44827586, 0.46551725,\n",
       "            0.47413793, 0.5       , 0.5086207 , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.51724136, 0.55172414, 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5862069 , 0.5862069 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  ,\n",
       "            0.994   , 0.9937  , 0.993   , 0.9927  , 0.992   , 0.9917  ,\n",
       "            0.991   , 0.9907  , 0.99    , 0.9897  , 0.9893  , 0.989   ,\n",
       "            0.9863  , 0.986   , 0.9854  , 0.985   , 0.9844  , 0.984   ,\n",
       "            0.9834  , 0.983   , 0.9824  , 0.982   , 0.981   , 0.9805  ,\n",
       "            0.9795  , 0.979   , 0.9785  , 0.978   , 0.9775  , 0.977   ,\n",
       "            0.976   , 0.9756  , 0.9746  , 0.9736  , 0.9727  , 0.9717  ,\n",
       "            0.97    , 0.9697  , 0.969   , 0.9688  , 0.968   , 0.967   ,\n",
       "            0.9663  , 0.965   , 0.9644  , 0.9634  , 0.963   , 0.9624  ,\n",
       "            0.962   , 0.9614  , 0.961   , 0.9604  , 0.9585  , 0.958   ,\n",
       "            0.9565  , 0.956   , 0.9556  , 0.955   , 0.954   , 0.9536  ,\n",
       "            0.9526  , 0.95    , 0.9487  , 0.9478  , 0.947   , 0.9463  ,\n",
       "            0.9453  , 0.945   , 0.942   , 0.9414  , 0.9404  , 0.9395  ,\n",
       "            0.9385  , 0.936   , 0.9355  , 0.933   , 0.9277  , 0.927   ,\n",
       "            0.9253  , 0.924   , 0.9224  , 0.921   , 0.919   , 0.9185  ,\n",
       "            0.9165  , 0.915   , 0.913   , 0.9106  , 0.9087  , 0.903   ,\n",
       "            0.9014  , 0.8984  , 0.896   , 0.895   , 0.883   , 0.8813  ,\n",
       "            0.881   , 0.8794  , 0.879   , 0.8784  , 0.8755  , 0.8633  ,\n",
       "            0.8584  , 0.83    , 0.798   , 0.7817  , 0.7607  , 0.7407  ,\n",
       "            0.6836  , 0.6104  , 0.6064  , 0.596   , 0.5864  , 0.541   ,\n",
       "            0.5405  , 0.496   , 0.4448  , 0.4153  , 0.4062  , 0.4055  ,\n",
       "            0.3572  , 0.349   , 0.3364  , 0.3174  , 0.2937  , 0.2935  ,\n",
       "            0.2876  , 0.285   , 0.2725  , 0.2664  , 0.2632  , 0.2283  ,\n",
       "            0.2278  , 0.2198  , 0.214   , 0.1505  , 0.1412  , 0.1346  ,\n",
       "            0.1103  , 0.1076  , 0.10394 , 0.1019  , 0.0962  , 0.0857  ,\n",
       "            0.0848  , 0.07825 , 0.06995 , 0.0698  , 0.0693  , 0.06683 ,\n",
       "            0.0629  , 0.0589  , 0.05707 , 0.051   , 0.04    , 0.03934 ,\n",
       "            0.03775 , 0.03073 , 0.02216 , 0.02153 , 0.01772 , 0.01758 ,\n",
       "            0.01698 , 0.01302 , 0.01086 , 0.01001 , 0.00982 , 0.007607,\n",
       "            0.006462, 0.00617 , 0.00279 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.57462686, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.02985075, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.05970149,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.12686567, 0.13432837, 0.13432837, 0.13432837,\n",
       "            0.14179105, 0.14179105, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.17910448, 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20149253, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.35820895, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.06896552, 0.11206897, 0.14655173,\n",
       "            0.1637931 , 0.18103448, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.27586207, 0.28448275, 0.31034482, 0.31034482, 0.3448276 ,\n",
       "            0.36206895, 0.39655173, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.4827586 , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.55172414, 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.75      , 0.75      , 0.7586207 , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 1.      , 0.9995  , 0.999   , 0.9985  , 0.998   ,\n",
       "            0.9976  , 0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   ,\n",
       "            0.9946  , 0.9937  , 0.993   , 0.9927  , 0.992   , 0.9917  ,\n",
       "            0.991   , 0.9907  , 0.99    , 0.9893  , 0.9883  , 0.988   ,\n",
       "            0.9873  , 0.987   , 0.9863  , 0.986   , 0.985   , 0.9844  ,\n",
       "            0.984   , 0.983   , 0.9824  , 0.982   , 0.9814  , 0.981   ,\n",
       "            0.9805  , 0.98    , 0.9795  , 0.979   , 0.9785  , 0.978   ,\n",
       "            0.9775  , 0.977   , 0.9766  , 0.9756  , 0.975   , 0.974   ,\n",
       "            0.9736  , 0.9727  , 0.972   , 0.971   , 0.97    , 0.9697  ,\n",
       "            0.969   , 0.9688  , 0.968   , 0.9673  , 0.966   , 0.965   ,\n",
       "            0.9644  , 0.964   , 0.9634  , 0.963   , 0.9624  , 0.962   ,\n",
       "            0.9614  , 0.9604  , 0.958   , 0.957   , 0.956   , 0.955   ,\n",
       "            0.9546  , 0.9536  , 0.953   , 0.951   , 0.9507  , 0.95    ,\n",
       "            0.949   , 0.9487  , 0.948   , 0.947   , 0.9453  , 0.943   ,\n",
       "            0.938   , 0.9355  , 0.935   , 0.9326  , 0.932   , 0.9307  ,\n",
       "            0.93    , 0.928   , 0.9263  , 0.9233  , 0.922   , 0.915   ,\n",
       "            0.9146  , 0.912   , 0.9097  , 0.9087  , 0.8975  , 0.895   ,\n",
       "            0.894   , 0.8936  , 0.8926  , 0.8896  , 0.8887  , 0.878   ,\n",
       "            0.8735  , 0.8457  , 0.8184  , 0.803   , 0.7812  , 0.755   ,\n",
       "            0.7046  , 0.6343  , 0.627   , 0.6226  , 0.607   , 0.561   ,\n",
       "            0.5576  , 0.5156  , 0.4631  , 0.4346  , 0.4292  , 0.4194  ,\n",
       "            0.3752  , 0.3655  , 0.3518  , 0.3337  , 0.311   , 0.3105  ,\n",
       "            0.3005  , 0.2979  , 0.2847  , 0.2786  , 0.2747  , 0.2372  ,\n",
       "            0.2367  , 0.2294  , 0.2263  , 0.2235  , 0.1587  , 0.1459  ,\n",
       "            0.1415  , 0.11456 , 0.11316 , 0.1082  , 0.1063  , 0.10016 ,\n",
       "            0.0893  , 0.0871  , 0.082   , 0.07306 , 0.0729  , 0.0716  ,\n",
       "            0.0689  , 0.065   , 0.06085 , 0.059   , 0.05234 , 0.05225 ,\n",
       "            0.04092 , 0.04047 , 0.03882 , 0.03168 , 0.02254 , 0.02203 ,\n",
       "            0.01816 , 0.01791 , 0.01738 , 0.01333 , 0.01103 , 0.01021 ,\n",
       "            0.00993 , 0.007694, 0.006588, 0.006363, 0.002811], dtype=float16)}}]],\n",
       " 'roc_results': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.00333333,\n",
       "         0.00333333, 0.00666667, 0.00666667, 0.01      , 0.01      ,\n",
       "         0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,\n",
       "         0.01333333, 0.01666667, 0.02      , 0.02666667, 0.04      ,\n",
       "         0.04666667, 0.05333333, 0.06333333, 0.06666667, 0.07      ,\n",
       "         0.07333333, 0.08666667, 0.09666666, 0.10333333, 0.10333333,\n",
       "         0.10333333, 0.11      , 0.12333333, 0.13333334, 0.13333334,\n",
       "         0.15      , 0.16666667, 0.18666667, 0.19      , 0.19666667,\n",
       "         0.21      , 0.22666667, 0.24      , 0.25666666, 0.26666668,\n",
       "         0.28333333, 0.29333332, 0.30666667, 0.32      , 0.34      ,\n",
       "         0.35      , 0.36      , 0.36666667, 0.37      , 0.38333333,\n",
       "         0.40333334, 0.41333333, 0.41666666, 0.42333335, 0.43333334,\n",
       "         0.44333333, 0.44666666, 0.45666668, 0.46      , 0.46333334,\n",
       "         0.47      , 0.48      , 0.48666668, 0.49      , 0.49      ,\n",
       "         0.49666667, 0.50333333, 0.52      , 0.52666664, 0.53      ,\n",
       "         0.53333336, 0.54      , 0.54333335, 0.55      , 0.55333334,\n",
       "         0.56333333, 0.56333333, 0.57      , 0.5833333 , 0.5933333 ,\n",
       "         0.5966667 , 0.5966667 , 0.61      , 0.61333334, 0.62      ,\n",
       "         0.62666667, 0.6333333 , 0.6333333 , 0.6333333 , 0.63666666,\n",
       "         0.64      , 0.64      , 0.6433333 , 0.65      , 0.6533333 ,\n",
       "         0.6533333 , 0.6566667 , 0.66      , 0.66333336, 0.6666667 ,\n",
       "         0.67333335, 0.6766667 , 0.6766667 , 0.68      , 0.6933333 ,\n",
       "         0.69666666, 0.7       , 0.7033333 , 0.70666665, 0.71      ,\n",
       "         0.7133333 , 0.7133333 , 0.7133333 , 0.72      , 0.72333336,\n",
       "         0.7266667 , 0.7266667 , 0.73      , 0.73      , 0.74      ,\n",
       "         0.74      , 0.74333334, 0.74333334, 0.75      , 0.75333333,\n",
       "         0.75666666, 0.76      , 0.76666665, 0.77      , 0.77      ,\n",
       "         0.77      , 0.7733333 , 0.77666664, 0.78      , 0.78333336,\n",
       "         0.78333336, 0.79      , 0.79333335, 0.7966667 , 0.8       ,\n",
       "         0.81      , 0.82      , 0.82      , 0.82      , 0.82      ,\n",
       "         0.82      , 0.82      , 0.8233333 , 0.82666665, 0.82666665,\n",
       "         0.82666665, 0.83      , 0.83      , 0.83      , 0.8333333 ,\n",
       "         0.83666664, 0.83666664, 0.84      , 0.84      , 0.8433333 ,\n",
       "         0.8433333 , 0.8433333 , 0.8466667 , 0.85      , 0.85      ,\n",
       "         0.85      , 0.85333335, 0.85333335, 0.86      , 0.86333334,\n",
       "         0.86333334, 0.87      , 0.87666667, 0.88      , 0.8833333 ,\n",
       "         0.89      , 0.89      , 0.89      , 0.8933333 , 0.8933333 ,\n",
       "         0.8933333 , 0.8933333 , 0.89666665, 0.89666665, 0.89666665,\n",
       "         0.9       , 0.9033333 , 0.9066667 , 0.9066667 , 0.9066667 ,\n",
       "         0.9066667 , 0.91      , 0.91333336, 0.91333336, 0.9166667 ,\n",
       "         0.9166667 , 0.9166667 , 0.92      , 0.92333335, 0.9266667 ,\n",
       "         0.93      , 0.93333334, 0.93666667, 0.9433333 , 0.94666666,\n",
       "         0.95      , 0.9533333 , 0.9533333 , 0.9533333 , 0.95666665,\n",
       "         0.96      , 0.96      , 0.96      , 0.9633333 , 0.9633333 ,\n",
       "         0.9633333 , 0.96666664, 0.96666664, 0.97      , 0.97333336,\n",
       "         0.97333336, 0.98      , 0.98      , 0.98333335, 0.9866667 ,\n",
       "         0.9866667 , 0.9866667 , 0.9866667 , 0.99      , 0.99333334,\n",
       "         0.99333334, 0.99333334, 0.99333334, 0.99333334, 0.99666667,\n",
       "         0.99666667, 0.99666667, 1.        , 1.        , 1.        ],\n",
       "        dtype=float32),\n",
       "  'tpr': array([0.        , 0.00333333, 0.00666667, 0.01      , 0.02      ,\n",
       "         0.03      , 0.05333333, 0.07333333, 0.07666667, 0.08      ,\n",
       "         0.1       , 0.11333334, 0.12666667, 0.13      , 0.14      ,\n",
       "         0.15      , 0.16      , 0.16666667, 0.17333333, 0.18666667,\n",
       "         0.19      , 0.19333333, 0.20333333, 0.21333334, 0.23333333,\n",
       "         0.23333333, 0.23666666, 0.24666667, 0.25333333, 0.26333332,\n",
       "         0.27333334, 0.28333333, 0.28666666, 0.29333332, 0.3       ,\n",
       "         0.30333334, 0.31333333, 0.31666666, 0.32      , 0.33      ,\n",
       "         0.33333334, 0.34666666, 0.34666666, 0.35333332, 0.36666667,\n",
       "         0.37      , 0.38      , 0.39      , 0.39      , 0.4       ,\n",
       "         0.40666667, 0.41666666, 0.42666668, 0.43333334, 0.43666667,\n",
       "         0.43666667, 0.44333333, 0.45      , 0.45      , 0.46      ,\n",
       "         0.47666666, 0.47666666, 0.48333332, 0.48333332, 0.48666668,\n",
       "         0.48666668, 0.49333334, 0.50666666, 0.51666665, 0.53      ,\n",
       "         0.54333335, 0.55      , 0.55      , 0.5566667 , 0.56666666,\n",
       "         0.56666666, 0.56666666, 0.5733333 , 0.57666665, 0.58666664,\n",
       "         0.5966667 , 0.5966667 , 0.5966667 , 0.60333335, 0.61      ,\n",
       "         0.61333334, 0.62      , 0.62      , 0.62333333, 0.62333333,\n",
       "         0.63      , 0.63      , 0.63666666, 0.63666666, 0.6433333 ,\n",
       "         0.65      , 0.6533333 , 0.6566667 , 0.66      , 0.66333336,\n",
       "         0.6666667 , 0.67333335, 0.6766667 , 0.68      , 0.68666667,\n",
       "         0.68666667, 0.68666667, 0.69      , 0.69666666, 0.69666666,\n",
       "         0.69666666, 0.7       , 0.7       , 0.7       , 0.7033333 ,\n",
       "         0.71      , 0.71666664, 0.71666664, 0.71666664, 0.71666664,\n",
       "         0.72      , 0.72      , 0.73      , 0.73333335, 0.73333335,\n",
       "         0.73333335, 0.73333335, 0.73333335, 0.73333335, 0.7366667 ,\n",
       "         0.74333334, 0.74666667, 0.75      , 0.75      , 0.75      ,\n",
       "         0.75      , 0.75333333, 0.75666666, 0.76      , 0.76      ,\n",
       "         0.7633333 , 0.77      , 0.7733333 , 0.77666664, 0.77666664,\n",
       "         0.78      , 0.78333336, 0.78333336, 0.78333336, 0.7866667 ,\n",
       "         0.79      , 0.79333335, 0.79333335, 0.79333335, 0.79333335,\n",
       "         0.7966667 , 0.7966667 , 0.7966667 , 0.7966667 , 0.7966667 ,\n",
       "         0.7966667 , 0.7966667 , 0.8       , 0.80333334, 0.8066667 ,\n",
       "         0.81      , 0.81333333, 0.81666666, 0.81666666, 0.8233333 ,\n",
       "         0.82666665, 0.83      , 0.8333333 , 0.83666664, 0.83666664,\n",
       "         0.83666664, 0.84      , 0.84      , 0.8433333 , 0.8433333 ,\n",
       "         0.8466667 , 0.85      , 0.85      , 0.85      , 0.85333335,\n",
       "         0.8566667 , 0.86      , 0.86333334, 0.8666667 , 0.8666667 ,\n",
       "         0.87      , 0.87666667, 0.87666667, 0.87666667, 0.87666667,\n",
       "         0.87666667, 0.88      , 0.8833333 , 0.8833333 , 0.88666666,\n",
       "         0.89      , 0.8933333 , 0.8933333 , 0.89666665, 0.9       ,\n",
       "         0.9       , 0.9       , 0.9       , 0.9033333 , 0.9066667 ,\n",
       "         0.91      , 0.91      , 0.91      , 0.91333336, 0.91333336,\n",
       "         0.9166667 , 0.92      , 0.92      , 0.92      , 0.92      ,\n",
       "         0.92      , 0.92      , 0.92      , 0.92      , 0.92333335,\n",
       "         0.92333335, 0.9266667 , 0.93      , 0.93333334, 0.93333334,\n",
       "         0.93666667, 0.94      , 0.9433333 , 0.94666666, 0.95      ,\n",
       "         0.9533333 , 0.9533333 , 0.95666665, 0.95666665, 0.95666665,\n",
       "         0.96      , 0.96      , 0.9633333 , 0.9633333 , 0.9633333 ,\n",
       "         0.96666664, 0.97      , 0.97333336, 0.97333336, 0.97333336,\n",
       "         0.9766667 , 0.98      , 0.98333335, 0.9866667 , 0.9866667 ,\n",
       "         0.99      , 0.99333334, 0.99333334, 0.99666667, 1.        ],\n",
       "        dtype=float32),\n",
       "  'thresholds': array([1.    , 0.5356, 0.535 , 0.5347, 0.534 , 0.5337, 0.533 , 0.5327,\n",
       "         0.532 , 0.5317, 0.5312, 0.531 , 0.5303, 0.53  , 0.5293, 0.529 ,\n",
       "         0.5283, 0.528 , 0.5273, 0.527 , 0.5264, 0.5254, 0.525 , 0.5244,\n",
       "         0.524 , 0.5234, 0.523 , 0.5225, 0.522 , 0.5215, 0.521 , 0.5205,\n",
       "         0.52  , 0.5195, 0.519 , 0.5186, 0.518 , 0.5176, 0.517 , 0.516 ,\n",
       "         0.5156, 0.515 , 0.5146, 0.5137, 0.513 , 0.5127, 0.512 , 0.5117,\n",
       "         0.511 , 0.5107, 0.5103, 0.51  , 0.5093, 0.509 , 0.5083, 0.508 ,\n",
       "         0.5073, 0.507 , 0.5063, 0.506 , 0.5054, 0.505 , 0.5044, 0.504 ,\n",
       "         0.5034, 0.503 , 0.5024, 0.502 , 0.5015, 0.501 , 0.5005, 0.5   ,\n",
       "         0.4998, 0.4995, 0.4993, 0.499 , 0.4988, 0.4985, 0.4983, 0.498 ,\n",
       "         0.4978, 0.4976, 0.4973, 0.497 , 0.4968, 0.4966, 0.4963, 0.4958,\n",
       "         0.4956, 0.4954, 0.495 , 0.4949, 0.4946, 0.4944, 0.4941, 0.4937,\n",
       "         0.4934, 0.4932, 0.493 , 0.4927, 0.4924, 0.4922, 0.492 , 0.4917,\n",
       "         0.4912, 0.491 , 0.4907, 0.4902, 0.49  , 0.4897, 0.4895, 0.489 ,\n",
       "         0.4885, 0.4883, 0.4868, 0.4863, 0.486 , 0.4856, 0.485 , 0.4849,\n",
       "         0.4844, 0.4841, 0.484 , 0.483 , 0.4827, 0.4822, 0.482 , 0.4812,\n",
       "         0.481 , 0.4807, 0.4805, 0.4802, 0.48  , 0.4797, 0.4795, 0.4792,\n",
       "         0.479 , 0.4788, 0.4783, 0.4778, 0.477 , 0.4768, 0.4766, 0.476 ,\n",
       "         0.4749, 0.4744, 0.474 , 0.4739, 0.4736, 0.4727, 0.4724, 0.472 ,\n",
       "         0.471 , 0.4707, 0.4697, 0.469 , 0.4688, 0.4685, 0.4683, 0.4678,\n",
       "         0.4675, 0.4673, 0.467 , 0.4668, 0.4663, 0.466 , 0.4653, 0.464 ,\n",
       "         0.4639, 0.4634, 0.4631, 0.463 , 0.4626, 0.4624, 0.462 , 0.4617,\n",
       "         0.4614, 0.4612, 0.4602, 0.46  , 0.4597, 0.4595, 0.4592, 0.4587,\n",
       "         0.4583, 0.458 , 0.4575, 0.457 , 0.4568, 0.4563, 0.4558, 0.4553,\n",
       "         0.455 , 0.4548, 0.454 , 0.4521, 0.452 , 0.4512, 0.4504, 0.4502,\n",
       "         0.4495, 0.4482, 0.4475, 0.4473, 0.4463, 0.4453, 0.4448, 0.4436,\n",
       "         0.4426, 0.4424, 0.4412, 0.441 , 0.4407, 0.4402, 0.44  , 0.438 ,\n",
       "         0.4373, 0.4355, 0.435 , 0.4348, 0.4346, 0.434 , 0.4324, 0.432 ,\n",
       "         0.431 , 0.43  , 0.4297, 0.4294, 0.429 , 0.4282, 0.4277, 0.4275,\n",
       "         0.4268, 0.426 , 0.4253, 0.425 , 0.424 , 0.4236, 0.4229, 0.4214,\n",
       "         0.4211, 0.421 , 0.4194, 0.418 , 0.4177, 0.4172, 0.4167, 0.415 ,\n",
       "         0.4138, 0.4136, 0.4128, 0.4106, 0.4094, 0.4082, 0.4053, 0.405 ,\n",
       "         0.4043, 0.3977, 0.3958, 0.381 ], dtype=float16),\n",
       "  'name': 'Original NN data1',\n",
       "  'auc': array(0.6139444, dtype=float32),\n",
       "  'model': LitClassifier(\n",
       "    (model): SimpleClassifier(\n",
       "      (layer_stack): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): BCEWithLogitsLoss()\n",
       "    (train_accuracy): BinaryAccuracy()\n",
       "    (test_accuracy): BinaryAccuracy()\n",
       "    (test_auc): BinaryAUROC()\n",
       "  )},\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x71378e8e1880>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Save the data\n",
    "save_to_pickle(list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader, filename='pickle/NN_data2_weighted.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3aba17",
   "metadata": {},
   "source": [
    "# Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "256006b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Load the data\n",
    "list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader = load_from_pickle(filename='pickle/NN_data2_weighted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5d9c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6oAAAOqCAYAAACVfKgeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeXxU5b348c85Z/bMkp2skEBIIIgsogi4Q10QERUUbd2r1bZar/6s0kVt7b1ob7Vqa2t7rWut1bZXrwpuuFRxR0GRJQQCBMKSPTOZzHbOeX5/nMyQkASCgIz6vF8vS3O2ec7Md86c73k2RQghkCRJkiRJkiRJkqQ0oR7qAkiSJEmSJEmSJElSTzJRlSRJkiRJkiRJktKKTFQlSZIkSZIkSZKktCITVUmSJEmSJEmSJCmtyERVkiRJkiRJkiRJSisyUZUkSZIkSZIkSZLSikxUJUmSJEmSJEmSpLQiE1VJkiRJkiRJkiQprchEVZIkSZIkSZIkSUorMlGVpH6UlZWhKEqv/5xOJyUlJZx55pm88MILh7qIX0jyXL4u3n//fb773e8ycuRIvF4vGRkZVFRUcPnll/Puu+8e6uKljRNOOAFFUXjzzTcPdVEGJZFI8PDDDzNnzhyGDh2K2+3G4/EwfPhw5s6dyxNPPEE8Hu+1z1ftHL8uNm3ahKIolJWVHfTXuu2221AUhdtuu+2gvxbA8uXL0TSNa665ptfyN998s8/vg6IoeL1exowZw7XXXsumTZv2enwhBE899RRnn302paWluFwusrKyGD9+PD/+8Y+pr68fVDlbWlpYuHAhJ5xwAgUFBTgcDvx+P4cddhhXXHEFr7/+eq/tOzo6yMnJYfLkyQghBv1+9OeLfFelPXvkkUdQFIVLLrnkUBdFkg45mahK0h5MmzaNiy++mIsvvpiZM2dis9l47rnnOOOMM7j++usPdfG+seLxOJdffjlTpkzhL3/5C0IITjnlFE477TRUVeWhhx5i2rRpXHbZZV/7m6Qv++b9YPvkk0+oqqrisssu47nnniMnJ4fTTz+dWbNmkZuby7PPPst3vvMdKisr6erqOtTFTQtfhyQ9mfydcMIJh7ooKddccw1ut5uf//znA26T/H246KKLmDx5Mps2beJ3v/sdY8eO5b333htwv23btnH00Uczf/58nn32WQoKCpgzZw7HHnssDQ0N/Pd//zeVlZXcf//9eyzj448/TllZGT/5yU94//33qays5JxzzuGkk05C13UefPBBpk+fzrnnnpvaJxAIsGDBAj788EMee+yxfX9jusnvqiRJB52QJKmPYcOGCUA8/PDDvZYnEgnxwx/+UAACEB9++OGhKeAXtGbNGrFmzZpDXYz9dtZZZwlA5OTkiOeff77P+sWLF4u8vDwBiLPPPvsQlPDLc+uttwpA3HrrrQNus3nzZrFmzRoRDoe/vIJ9AR9//LHweDwCELNmzRJ1dXV9tmlsbBQLFiwQDodDtLW1pZYff/zxAhBvvPHGl1fgNHEozz0ej4s1a9aI9evX79dx3njjDQGI448/fsBtmpqaxJo1a0RTU9N+vdZg/OMf/xCAuPHGG/usS5a1v1uo+vp6MXLkSAGI6urqfo/d2toqhg8fLgAxYcIE8fnnn/dan0gkxG9+8xuhaZoAxL333tvvcf74xz8KQCiKIm666SbR0dHRZ5tVq1aJefPmifHjx/daHolERF5enigsLBTRaHTA92Eg+/Ndlfasvb1drFmzRmzbtu1QF0WSDjmZqEpSPwZKVIWwfuD9fr8AxM9//vMvv3DfcH/+858FIOx2u/joo48G3O6TTz4RdrtdAOLBBx/8Ekv45RpMovpVEI/HUzfvc+bMEYZh7HH7Dz/8UHR1daX+lonqV/vcB5OofpmmTp0qALF27do+6/aUqAohxBNPPJFav2HDhj7rL7jgAgGI8vLyPSZwv//971PXutWrV/dat2bNmtT17e67797r+fz73//us+xHP/qRAMSjjz661/172t/vqiRJ0mDJRFWS+rGnRFUIIY444ggBiCuvvLLf9UuWLBFnnXWWKCgoEHa7XeTl5Yk5c+aId999d8DXDIfD4re//a2YNm2ayMzMFA6HQwwdOlTMmjVLPPHEE/3u849//EOccsopIjc3V9jtdlFUVCS+/e1vi1WrVvW7/e43V21tbcLlcglVVcXWrVsHLNs555wjAHHPPffsVxk2btwoADFs2DCh67q46667xPjx40VGRsaAN309maYpysvLBSCuueaavW5/7bXXCkAMHz5cmKaZWt7zpjgcDosFCxaIESNGCKfTKQoLC8Vll122x/ejtbVV3HLLLWLcuHHC6/UKt9stDjvsMHH77bf3W2vZM5ncvHmzuOyyy0RJSYmw2Wzi4osvTm33r3/9S1x++eVizJgxIjMzUzidTlFWViYuvfTSfm+Yk59nf//1PO5AiczFF1+civO6ujrxne98RwwZMkQ4HA4xfPhw8dOf/nTA2pZkrc+YMWOE0+kUeXl5Yu7cuWLVqlXi4Ycf7lOGvXnkkUcEIBwOh9i+ffug9+vvHJcvXy7OOusskZOTIxwOhxg9erT4zW9+0ysGkhobG8W9994rTjvtNFFWViZcLpfw+XziiCOOEHfccYeIRCL9vl7P79JDDz0kjj766NQDrI0bNwohhNi0aZO44447xIknnihKS0uFw+EQgUBATJs2TTzwwAN7vMFvbW0Vv/jFL8QRRxwh/H6/cLlcory8XMybN08sXrxYCNE7Yervv92vXwcjbnt+p3e3bt06cemll4qysjLhcDhERkaGGDp0qJg5c6Z46KGH+nx2/f3X87h7eyhTU1Mjrr76alFZWSncbrfw+Xxi9OjR4uqrrxYrV64c8L3e3SeffCIAcfTRR/e7fm+J6sqVK1Prd7/mb9iwQaiqKgDxr3/9a4/lME1TjBs3TgDikksu6bXukksuEYAYN25cv3E9GMuXLxeAOOqoo/Zpv/39rgph/d4tXLhQTJgwIRWL1dXV4qc//alobW3ts33PODMMQ9x7771i7Nixwu12i4KCAvG9731PtLS0CCGEiEaj4pe//KWoqqoSLpdLFBYWimuvvVZ0dnb2OW7PmNq0aZO48MILRUFBgXA6nWLkyJHi1ltv7TfJjsfj4vHHHxcXXHCBqKqqEj6fT7hcLlFZWSmuueYa0dDQ0O9597xOvfXWW2LWrFkiNzdXKIqS+r7u6fr56quvilmzZon8/Hxhs9lEZmamqKioEN/+9rf7fRiRSCTEH//4RzFlyhTh9/uF0+kUFRUV4pprrhnwN65nbP/zn/8U06ZNEz6fT3g8HjF16lSxaNGifveTpINBJqqS1I+9JarJpl391ajecMMNAhCqqoqjjjpKzJs3T0yePFkoiiI0Tet1g5ZUX18vqqurBSA8Ho/41re+JebPny+OPfZYEQgE+twEJhIJce655wpAOJ1OMXXqVDFv3rzUTY3b7RYvvvhin9fp7+bq/PPPF4BYuHBhv+fa3NwsHA6HcDgcorm5eb/KkLzZGDp0qJg9e7ZwOBxi+vTp4vzzzxeHH354v6/f04oVK1LnsKfa1KRly5altv/ss89Sy5M3mlOmTBFHH3208Hg8YubMmWLevHmisLBQAKKgoECsW7euzzFXrVolSktLBSAKCwvFqaeeKs444wwxZMgQAYjx48eL9vb2Xvskb4YuuOACkZ2dLQoKCsQ555wjzj77bHHDDTekttM0TXg8HjFp0iRx9tlni9mzZ6dqLjIyMsQ777zT67gXX3xx6v0eN26cuPjii1P//c///E9qu70lqj/60Y+E3+8Xw4YNE+eee66YMWOGcLvdqRqT3RmGIWbNmpW6WT355JPFeeedJ4YPHy48Hk+qefy+JKrJ5txnnHHGoPfpKXmON998cyo5nT9/vjj++ONTTSh/9KMf9dnv8ccfF4AoLi4Wxx9/vJg/f76YPn268Hq9qRjpL1lPxtUPf/hDoaqqOOaYY8T5558vJk+eLDZt2iSEEOL2229P1ZxNnz49VR6Hw5Fqlt5fkrFixQpRXFwsABEIBMTMmTPFeeedJ6ZMmSLcbneq1nHNmjXi4osvTsXeKaec0isG3n777dQxD1bcDpSorly5MpW4V1VVibPPPlvMmzdPTJkyRXi9XjFu3LjUtgsXLhSnnHKKAMSQIUN6nUPP78eeEtUnnnhCOJ3O1PXlnHPOEWeddZYYN26cUBRln1oc3HLLLQIQP/vZz/pdv7dE9Z133hmwRvWee+4RgMjMzBSJRGKvZfnNb34jwOrmkIwV0zRFTk6OAMRdd9016PPqT7KLxL40M93f72pLS4sYP368AITf7xezZ88W55xzjsjNzU19X5IPe5J6xtn5558v3G63OPXUU8WcOXNEfn6+AKsZdWdnpzjmmGNSx501a5YIBAICEKeddlqfsiRj6qKLLhI5OTliyJAhYt68eWLWrFmpB6jTpk3r88Bqy5Ytqe/n0UcfLebNmydmzpwpioqKBCDy8vJEbW1tn9dLXqe+//3vC1VVRXV1tZg/f744+eSTxd/+9jchxMCJ6iOPPCIURRGKoojJkyeL8847T8yePVtMnDhRaJrW5/oWjUbFjBkzBCBcLpc47bTTxHnnnZe6DuTm5oqPP/64TxmTsXvLLbcIRVHEtGnTxHnnnZf6rVEURfzv//7vID5pSdp/MlGVpH7sKVFdvXp16sZ392Qp2Sy1oqJCfPrpp73W/fvf/xY+n084HI5eCZBhGGLSpEkCECeffLJobGzstV8kEunzBPMnP/mJAMTkyZP79A36xz/+ITRNE1lZWX2alfV3c/Xqq68KQIwaNarf9+Lee+8VgDjnnHP2uwzJmw1AlJSUiJqamn5fcyB/+ctfUsnRYG7yEolEKino+YCg541mRUWF2Lx5c2pdJBJJ1SDvXqPS1dUlRowYkbqJjcViqXXhcDiV9F966aW99kveDAHiO9/5zoC1lH//+9/7PPU3TVPcf//9AhBjxozpk9gMpunv3hJVQPz0pz8Vuq6n1q1cuTJ1o7Z7rVAyJgoLC3vV9Oq6nmpOuK+JavLm6Ze//OWg9+nvHAHxwAMP9Fr32muvpR4Ubdmypde61atXi/fee6/P8VpbW8XJJ58sAPHrX/+6z/rka/n9/n73F8Jq8thfTV5DQ0Pqpu/pp5/uta6zszP1Xlx00UUiFAr1Wt/e3i5effXVfs99oKa/BzNuB0pUL730UgGIX/3qV/2WZ/fan8E0/R0o1pctWybsdrtQFEXcd999fWqqN23aJJYtWzbgcXd3zDHHCGDAmqO9JarJa+PYsWP7fF8vvPBCAYgTTzxxUGX597//nXqt5HV2w4YNqWVvvfXWoM+rP7NnzxaAePzxxwe9z/5+V88777zUb0fPh5+hUEicdtppAhBTp07ttU/P344RI0akHgYJYT1MTT48Hjt2rDjqqKN6Hbeurk5kZWUJQCxdurTXcXvG+Jlnntmr9nTLli2isrIy9QCsp2AwKP7v//6v13dJCKumdcGCBQIQM2fO7HPuPa9T999/f7/vz0CJarI1Uc8HUEk7d+4Un3zySa9lN910U+r96pn4x+Nxcfnll6ceCux+DsnyZWZmivfff7/XuuT7VVlZ2W/ZJelAk4mqJPWjv0S1vb1dvPzyy2LUqFH9Pm03DCP1NHWgm6Jf//rXAuhVS/Dss8+mbvp3vyntT0tLi3C73cLlcg3YdOf73/++AMTvfve7Xsv7u7kyTTN1vv01TU4++X7hhRf2uww9bzYee+yxvZ7r7u644w4BVm3nYBUUFAhA3HnnnallPW80n3322T777Ny5MzVQSM9azOTgJbNmzer3tUKhUKpJVs/ma8kf9+zs7D61VoM1ZcoUAfRpUn0gEtUjjjii35q9q666qt8b0mQt75/+9Kc++8RisVRt4L4kqi6Xq98kc7CS5zjQ4FmnnnrqPsddTU2NAMSRRx7ZZ10yfr7ozfrLL78sADFv3rxey5M1buPHj+/14GBP9paoHsy4HShRnTlzpgD63DwPZH8S1Tlz5ggYXHeAwUg+oOlvgKCeZe15LTVNU9TX14v//u//Fg6HQ2RlZfU72F4yDufPnz+osqxduzb1Wh988IEQQoj3338/tay/LgH7IplU/cd//Meg99mf7+rmzZuFqqpCUZQ+D3OFEGLr1q2p4/e89vb87ejvAcLdd98twKrt6+/h0DXXXCMA8Ytf/KLX8mRMud3ufpsxP//886kHUgN1A+hPUVGRUFVVBIPBXsuT39WTTjppwH0HSlQ9Ho8IBAKDev1IJJJqFfLcc8/1WR8Oh1OtKXbvWpR8n++7774++0Wj0VQNdX19/aDKIkn7Q05PI0l7cOmll6bmyMvMzOSUU06htraWv/71r9x+++29tl2+fDnbtm1jxIgRHHHEEf0eLzn1Qs85Pl966SUALrjgArxe717L9MYbbxCJRJg2bRrFxcWDfp2BKIrCxRdfDFjzt/W0YsUKVqxYQWFhIaeeeuoBLcM555yz17IdCGIP8wRmZmYye/bsPsvz8/NT59tzyo9FixYBcN555/V7PK/Xy6RJk9B1nY8++qjP+hkzZhAIBPZY3vXr1/P73/+e6667jssvv5xLLrmESy65hJ07dwJQU1Ozx/2/iFmzZvU7v+7o0aMBaGhoSC3bunUrdXV1gBWzu3M4HMydO/eAl3GwzjjjjH6X93cuSYZh8Nprr3H77bfz/e9/n0svvZRLLrmE//zP/wT2/J7v7VxjsRjPP/88t9xyC1dddVXq2H/605/6PXbyenD55Zejadoejz1YX0bc7u6oo44C4Oqrr+bll18mGo3uY6kHxzAMXn31VQCuvPLK/T5eOBwmHA4DkJOTs9ftk78PqqoydOhQbrzxRkpLS/nss8848sgj97s8e7p+HQjJc0xeXw62t956C9M0mTBhAocffnif9cXFxZxyyimA9TuzO5vNxsknn9xn+ciRIwEYOnQohx122IDrt23b1m+5Tj75ZAoKCvosnzVrFjk5OQSDQT755JM+6z/99FPuvvturrnmGi677LLU9VrXdUzTZP369f2+3he5Rh511FF0dHRw0UUX8fHHH2Oa5oDbLlu2jM7OTrKzs/u9Jno8HubPnw/0/z5D/9dSp9PJ8OHDgf6vpZJ0oNkOdQEkKZ1NmzaNiooKAJqamnj77bcJhUJcffXVjBw5MnUzBqRu3jds2NDvTX9PTU1Nqf+/efNmAEaNGjWoMiVf57XXXtun19mTSy+9lNtvv52nnnqKe+65B7fbDcDDDz8MwEUXXdTrpnl/y5Cfn4/H4xlU2XrKzc0FoLW1FV3Xsdn2fAnTdZ3W1lYA8vLy+qwvKysbsPzl5eWAlZglJc/7wgsv5MILL9zja/d33mVlZQNubxgGP/zhD/nTn/60x5vTYDC4x9f9IoYOHdrvcr/fD9AryUi+H7m5uQM+WNnTeQ4kLy+PLVu20NjYuM/79rQv5wJQW1vLWWedxapVqwY85p7e8z2d6/vvv895551HfX39oI+9r9eDwTiYcTuQG2+8kaVLl7JkyRJOPfVU7HY748aN47jjjmP+/PkHJIkDaGlpSSWWVVVV+328jo6O1P/3+Xx73T75kC+RSLBhwwY++OADNmzYwAUXXMCSJUtwOBy9tk9ewwabGPb8PiSvYT2vZY2Njft13snvRVtb26D32Z/vajK5SV5f+zNixIhe2/ZUWFjY73U/eS0a6Puf/CwHemCyp/KUlZXR0tLS67cgHA5z4YUX8swzzwy4Hwx87fgi36k//OEPzJo1i8cff5zHH38cn8/HkUceyUknncSFF17Y69z3932Gfb+WStLBIBNVSdqD7373u1xyySWpvzs6OjjrrLN44403OPfcc1m9enUq4Uo+3SwoKEg9ER5I8mbli0i+TkVFBdOmTdvjtoO92S0rK+PEE0/k9ddf55lnnuGCCy4gkUjwt7/9DbAS2QNZhmQivK+SNdXxeJzly5fv9WZ3xYoVJBKJXvvuq55JY/K8Tz31VIYMGbLH/YYNG9Zn2Z7O+9577+WBBx6goKCAu+++m6lTpzJkyBBcLhdg1V4++eSTB6WGRVX3vXHNnh5Q7O3hRX+OOOIItmzZ0m+N3r7Y13OZO3cuq1atYtasWfz4xz+muroav9+P3W4nHo/jdDr3uP9An2lXVxdz5sxh586dXHrppVx99dVUVFTg9/vRNI1169ZRVVV10GvM4ODG7UA8Hg+vvvoqH330ES+99BLvvvsu7777LsuWLePuu+/m+9//Pvfff/8+H/dgy8zMTP3/UCiUuikfyO6tUN555x1OO+003n77bX72s5/x61//utf6I444gr/+9a988skng3rY9uGHHwJWzWcyuSkrKyM7O5vW1lY++ugjjj322MGdXD+SiXlWVtag9zlQ39UvYm/f7y9yLRusnt/VBQsW8MwzzzBq1CjuuOMOjjzySHJzc1MPJqZOncp777034Pf7i3ynRo8eTU1NDa+88gqvv/467777Lm+//Tavv/46v/zlL/nLX/7Cd77znS92cv04mO+lJA2WTFQlaR8EAgGeeuopRo0axebNm7n77rv52c9+BkBpaSlg3VDsfvOyJ8mnlmvXrh3U9snXqaqq2qfX2ZtLL72U119/nYcffpgLLriA559/nubmZqZOndrnif3BKsPejBs3jrKyMjZt2sRjjz2210T1scceA6wbu7Fjx/ZZv2nTpgH3Ta4rKSlJLSstLWXt2rVcfvnlB7x569NPPw3An/70p36bI9fW1h7Q1/uikk29m5qaCIfDZGRk9NlmT+/rQM4880yeffZZXn75ZXbu3LnXhOpAWLt2LZ999hn5+fk888wzfZKG/XnP33rrLXbu3MnEiRN56KGH+qwf6NhDhw5lzZo1rF27lhkzZnzh1+/pYMbt3hx55JGp76mu6zz77LNcdNFF/OEPf2Du3LmceOKJ+3X8nJwcPB4PXV1d1NTU9Nvsc194PB4yMjIIh8O0tLTsNVHd3bRp0/jtb3/Ld7/7Xe69916uuuqqVFNJsJpT3nDDDXR0dPB///d/e+wCIYTg8ccfB3o3z1dVlTPOOINHH32Uxx57jOuvv/4LnKmlpaUFYJ++b/vzXU1eP5K1/P1JrhuoW8nBsHHjxgHX9fdbkLxeP/XUU/02YT5Y12ubzcbMmTOZOXMmYNXY3n333fziF7/ge9/7HmeddRYZGRmp925P53Uo3mdJ2lfycYkk7aO8vLxUcvqb3/yG9vZ2gNQT1dWrV++xGeHukn0hn3zyyVQTtj2ZPn06DoeDN998c7+bSfZ0zjnnEAgEeP3119myZUuq2e/utakHswx7oygKN998M2AldMuWLRtw2+XLl/PAAw8A1tPv/mr52tvbef755/ssb2pqSvUVTPa1BTjttNOAXTcpB1KyiXJ/NVqrVq1ixYoV/e6XfIKv6/oBL1N/SktLUzU7Tz75ZJ/18Xicf/3rX/t83G9/+9uUlZURj8e5+uqr99j/CuDjjz8mEons8+v0lHzPi4qK+q3Z+utf/7rfxx6o+dxAx05eDx566CEMwxjUa+0tBg5m3O4Lm83G3LlzUy1Oesb0F41jTdP41re+BcD//M//HJByTpw4EYDVq1d/of0vu+wyxo8fTzwe5xe/+EWvdSNGjODcc88FrObRyd+P/vzhD3/gs88+w2azceONN/Zad9NNN2G32/n000+555579lqmt99+u9/ln3/+ObBvLU7257t63HHHoaoqK1as4NNPP+2z7fbt21PX3v19iLEvXnnllX5/yxYvXkxLSws+n6/Xe7Sn6/XLL79Mc3PzwStsD36/n9tuu43MzEy6urpYt24dAJMmTcLr9dLa2spzzz3XZ79IJMLf//534Mt9nyVpX8lEVZK+gO9///sMHTqUjo4O7rrrLgDsdju33norQgjOOussli5d2mc/wzB4/fXXef/991PLZs+ezYQJE9i2bRvz5s1LPeFOikajvPjii6m/hwwZwjXXXEM4HOaMM85g5cqVfV4nFovx3HPPDbqWFqymSPPnz8c0Te68805eeuklPB5PvwOwHKwyDMaVV17J7NmzSSQSnHrqqbzwwgt9tnnppZc45ZRTSCQSzJ49myuuuGLA491www29+h7FYjF+8IMfEA6HOeqoo3o1bb7yyisZNmwY//jHP7jpppsIhUJ9jrdjx44vdMOcHOzn/vvv73Xjt337di666KIBb+CTT/n35eHI/rr22msBuPXWW1M3RmA1MV2wYAFbtmzZ52Pa7XaefvppXC4XzzzzDHPmzOm3NqC1tZWf//znTJs2jVgs9sVPAqisrETTNFauXNlr0CyA559/nt/+9rdf+NjJz/O1117rk/D8+c9/5qmnnup3v+9+97uUlJSwfPlyrrjiij4Pr4LBIEuWLOm1bG8xcDDjdiB/+MMf+h2EaseOHakHTD1v8pPnUFtbm2quP1g//elPsdls/P73v+cPf/hDn+aWmzdv5uOPPx708ZI37u+9994+lSNJURT+67/+C4Annnii13cErO94WVkZGzdu5KSTTurzuem6zt13382PfvQjAO68807GjBnTa5vRo0dz9913A3D99dfzk5/8pN/Pdd26dZx//vmp7+zukud40kknDfr89ue7OnToUObNm4cQgu9973u9fu/C4TBXXnkl0WiUqVOnMnXq1EGXaX9FIhGuvvrqXg+/tm3bxg033ADAVVddleqGAbu+37/73e96HaempoarrrrqgJevq6uLu+++u98+5G+//Tbt7e1ompb6HrlcLn7wgx8A1m9csu87WP2pf/SjH7Fjxw7Ky8sP6eB3krRXh2awYUlKb3uaRzXpoYceEoDw+XyipaUltfzGG29MDe8+ZswYceaZZ4r58+eLE044QWRmZgpA/PGPf+x1rE2bNomqqioBCI/HI04++WRx/vnni+OOO04EAoE+Uz8kEglxwQUXCECoqiomTJggzjnnHHHeeeeJadOmpaZXePHFF3vtlyzXQHpOe0D3PI4D+SJlGGgqi30VjUZ7zQFaUVEhzjnnHDF37tzUfHqAuPDCC/ud+zE5vcSUKVPE5MmThcfjEbNmzRLnnntuaoqh/Pz8fqd++Pzzz0VZWVlqnrnjjjtOXHDBBWLOnDmiurpaKIoihgwZ0mufwUwh8/7776fmfK2oqBDnnnuuOPXUU4Xb7RZjxowRZ511Vr8xuWPHjl4T019yySXi8ssv7zVv7N6mpxkozgeaJkHX9dR8h06nU5x66qli/vz5YsSIEcLtdqemJrriiisGPN+BfPjhh6nvn6IoYuLEiWLu3Lni3HPPFZMnT07NYTx8+PBecx7ubYqWgT6D5LyvqqqK448/Xpx//vli4sSJgu4pqAb6zuztuySEEGeeeaYAa97fk08+WcyfP1+MGjVKKIoifvrTnw74Xfjkk09S0yplZmaK008/XZx33nli6tSpwu1295nC5YUXXki9zqxZs8Rll10mLr/88l7TexysuB3oO52cJ7a8vFycccYZ4tvf/rY4+eSThdvtTk3PsftcyMn5pKuqqsS3v/1tcfnll4ubbrppUOV59NFHhd1uT5Vl7ty54uyzzxbjx48XiqLs8Rx298knnwhAHHXUUf2u39s8qknHHXecAMQFF1zQZ93WrVtT56soijjyyCPF/PnzxezZs0VeXl7q87znnnv2+BoPPfRQ6vvvcrnEcccdJ84//3xx1llnidGjR6fK2d90OHs7z735ot/V5ubmVHwEAgExZ84cMXfu3NR5l5eX95r3U4i9/3bsbXqjga5lyZi66KKLRHZ2tigoKBDz5s0TZ5xxRup9nTJlSq/yCyHEv/71L6EoigBr7tb58+eLk046SdjtdnHSSSeJqVOn9ns92tt1aqCytrW1pa5T48aNE3PnzhXnn3++mDJlSqoct9xyS6/jRKNRMX369NT0OzNnzhTnnXeeGDp0qABETk5Ov1Pp7S22B3MOknSgyERVkvoxmERV13VRXV0toO9k4O+884749re/LYYNGyacTqfw+XyisrJSzJkzRzz44IO95ipMCoVC4s477xRHHnmk8Pl8wul0imHDhonZs2eLv//97/2WYfHixeLss88WxcXFwm63i8zMTDF69Ggxf/588be//U2Ew+Fe2w/m5mrMmDGp7QbzQ7QvZThQiWrSO++8Iy699FIxYsQI4fF4hNvtFsOHDxeXXHJJn4nde+p5U9PZ2SluvPFGUV5eLhwOhxgyZIi45JJL9jhHXDAYFL/+9a/FlClTRGZmprDb7aKwsFAceeSR4sYbb+wzH+1gbviFEOKzzz4Ts2fPFoWFhcLlcomRI0eKH//4xyIYDO4xqXzrrbfEjBkzRFZWllBVtc9NzoFOVIWwJo3/9a9/Laqrq4XT6RS5ubnirLPOEitXrhS//OUvBSAWLFiwx/MdSCwWEw8++KA444wzRHFxsXA6ncLlcony8nIxd+5c8eSTT4p4PN5rny+aqJqmKf7yl7+II444Qni9XhEIBMQxxxyT+s7tT6Iaj8fFf//3f4uxY8cKj8cjsrOzxcknnyxeeeWVvX4XmpqaxM9+9jMxduxYkZGRkYrt8847T7z00kt9tv+f//kfMXHixNT8v/19rgcjbgc6jxdeeEFcffXVYsKECSIvL084HA5RUlIiTjjhBPHoo4/2+fyEsObYvOCCC0RhYaGw2Wx9jru38qxatUpcfvnlory8XDidThEIBER1dbX44Q9/2Gf+4b1JJhqrV6/us26wieq7776bSi76O45hGOLJJ58UZ555pigqKhIOh0P4/X4xduxYccMNN/RJ1gbS1NQkfvWrX4ljjz1W5OXlCZvNJrxerzjssMPElVdeKf7973/3u9+1114rAPHoo48O6nX680W+q0JY83guXLhQjB8/Xng8HuFyucTo0aPFT37yk35/Hw92onrrrbeKuro6cf7554shQ4YIh8MhKioqxC233NLndzTprbfeEtOnTxe5ubnC4/GIww47TPznf/6niMViA16PvmiimkgkxAMPPCDOP/98MWrUKBEIBITb7RYjRowQ55xzjnjttdf6PVYikRB/+MMfxNFHHy18Pp9wOBxixIgR4pprrhlwDnSZqErpRBHiSxhyUJIkKY28+eabnHjiiRx//PF9mnxK+++kk07ijTfe4F//+hdnn332oS6OJO2zf/7zn8ybN4/rr78+1b3j6yQajVJaWordbmfjxo17Hd366+q2227jF7/4Bbfeeiu33XbboS6OJEm7kX1UJUmSpH22YsUK4vF4r2XxeJzbbruNN954g/z8/NTIlJL0VTN37lymTZvGn/70p0HPefpV8rvf/Y7m5mYWLlz4jU1SJUlKf3J6GkmSJGmfXXfddaxYsYJx48ZRWFhIW1sbK1euZPv27bhcLh599NFeg49I0lfN7373OyZNmsTtt9/O73//+0NdnAOmo6ODO+64g6OOOoqLLrroUBdHkiRpQDJRlSRJkvbZFVdcwRNPPMFnn33Ghx9+iBCCoqIiLrvsMm644Qaqq6sPdRElab9MmDBh0FMEfZUEAoE+o8tLkiSlI9lHVZIkSZIkSZIkSUorso+qJEmSJEmSJEmSlFZkoipJkiRJkiRJkiSllW98H1XTNNm2bRs+nw9FUQ51cSRJkiRJkiRJkr5ShBCEQiGKiopQ1QNTF/qNT1S3bdtGaWnpoS6GJEmSJEmSJEnSV9qWLVsoKSk5IMf6xieqPp8PsN5Uv9/f7zaGYbB582aGDRuGpmlfZvEkaVBkjErpTManlO5kjErpTsaolO7a2tooKytL5VYHwjc+UU029/X7/XtMVJPbyIuDlI5kjErpTManlO5kjErpTsaolO6SMXogu1LKwZQkSZIkSZIkSZKktCITVUmSJEmSJEmSJCmtyER1EBRFobS0VI4KLKUtGaNSOpPxKaU7GaNSupMxKqW7gxGb3/g+qoOhqio5OTmHuhiSNCAZo1I6k/EppTsZo1K6kzEqpbsDNSVNr2Me8CN+DRmGwdq1a1OdhCUp3cgYldKZjE8p3ckYldKdjFEp3R2M2JSJ6iBFo9FDXQRJ2iMZo1I6k/EppTsZo1K6kzEqfdPIRFWSJEmSJEmSJElKKzJRlSRJkiRJkiRJktKKTFQHQVVVhg8fflA6CUvSgSBjVEpnMj6ldCdjVEp3MkaldHcwYlOO+jsIiqLg9/sPdTEkaUAyRqV0JuNTSncyRqV0J2NUSncHY3oa+VhmEAzDYOXKlXKkNSltyRiV0pmMTyndyRiV0p2MUSndyVF/DyF5YZDSnYxRKZ3J+JTSnYxRKd3JGJW+aWSiKkmSJEmSJEmSJKUVmahKkiRJkiRJkiRJaUURQohDXYhDKRgMEggE6OjoGLCTuhCCaDSKy+U6KB2FJWl/yRiV0pmMTyndyRiV0p2MUSnddXR0kJmZucecal/JGtVBcjgch7oIkrRHMkaldCbjU0p3MkaldCdjVPqmkYnqIJimycqVKzFN81AXRZL6JWNUSmcyPqV0J2NUSncyRqV0dzBiUyaqkiRJkiRJkiRJUlqRiaokSZIkSZIkSZKUVmSiKkmSJEmSJEmSJKUVOervIEf9NU0TVVXlSGtSWpIxKqUzGZ9SupMxKqU7GaNSupOj/h5C8Xj8UBdBkvZIxqiUzmR8SulOxqiU7mSMSt80MlEdBNM0qampkSOtSWlLxqiUzmR8SulOxqiU7mSMSulOjvorSZIkSZIkSZIkfe3JRFWSJEmSJEmSJElKKzJRHSRN0w51ESRpj2SMSulMxqeU7mSMSulOxqj0TSNH/R3EqL+SJEmSJEmSJElS/w5GTiVrVAdBCEEwGOQbntNLaUzGqJTOZHxK6U7GqJTuZIxK6e5gxKZMVAfBNE3q6urkSGtS2pIxKqUzGZ9SupMxKqU7GaNSupOj/kqSJEmSJEmSJElfe7ZDXQBJkiRJkvZBIgjBdWBEQXOBvxLsA/cHCsaCrGtZR1SP4rK5qMypxO+0tl/TtIanVz1NR6yDgDPAuWPOZXTe6D3us68GOtZAy5uamlj26TK6ol14XB4mjZtEXl7eXs+FYBDWrSPc0sLmjg46SkqwZ2ZSWVKCPxiE118n0tnJdq+X5pNOQi0poRLY21kFgU/inawPbgU9SoUwmZhdYZ0DsA6IAi4Y9PH2dR9JkqR01rzuU1a/9Dg/nJx/QI8rE9VBcrlch7oIkrRHMkaldCbj8wDoaoBti2DHEog2gqmDagNXPhTMgKLTwVOc2rwh2MCi2kUsqVtCY7gR3dSxqTbyM/IZ4hnCO1veYW3LWuJGHIFAQeGOpXdQ4C2gJFCCpmi99pkxfAanjzydYn/xHgq5y0Cv73P4CLgCdEQ7CMVDqeUu04XaqLKzaSdhI4yBgYZG9uJsJhVPInd0Lp+HP+9zLjOyJ3H6OkHW4qW0b9lC0DSJ2e105eTQUFpKYsMGqlevxhmLIYQgT1XJ8PlYfvzx/OO66xgxaRKn0jdGG4AnIm08HWllsx4lLkwQAme0g4K1/0dFzkgSQw4nZPegY91Q5QMzgNOB3d+lBmARsARohEHtI0k9yeuolG7q3niGDYvvJc+xiUJXjOtmHdjjy1F/5ai/kiRJUrprXwWrFkK4DhxZVnKq2EEkrKQ13g4Z5TBmAWSOYVXjKhYuXUhdWx1ZrizyM/Kxq3YSZoIPtn5ATUsNJiY21YZbc6MoCrqpE9EjCASqonJk4ZEcPuRwEmaCxnAj7dF2yrPKWXDMAsbkj9ljcQd6/cauRj5q+IhQPITP6eOooqPI8+SxdcdW3q9/ny6lC7fhpkqvIkAA3dRpMBtocDWgaApjhoxhVMmo1Lk07qyjfeNqSpsN5m4eiiujDA3wxuOUbNhA8caNqKZJ0OejNTsbm6bhEgJPRwf2aJSOnBx+e889NJx5JguA5FmtAm6KtPNBVyN6uImMeBiP5gDVTocnhzZfAUIIsjt3MNU7hDx3NgmsBLQdKIc+x1sI1AFZWMmpHfa4jyRJUjpb/tf/xvz8j2T7w3RF7XRGnURjCSbc/vnXc9Tft956izPOOIOioiIUReHZZ5/d6z5vvvkmEydOxOl0UlFRwSOPPHLAy2WaJi0tLbIDu5S2ZIxK6UzG537qarCS1K56CFSDpwRUByiK9a+nBAKjrfWrFtKwcxkLly6kvqOe6txqSvwlODQHiqKwI7SD2tZaKxlFRUFBURVQIGEmUBUVm2LDFCYf7/iYLaEtODQHJf4SRueOpr6jnoVLF9IQbBiwuA3Bhn5fvyvRxarGVZjCpNBbiClMPm/6nO2t21m+eTmmaZIjcsAG9Y56YkoMQzMIeoLYNBsYsGn7Jro6u1AUBUcsQUnNNiqbYHUm/H5MK1EtTIZp4gmFKNiyBUUIEjYbNsNAFQJdCAxVJZyTQ3thIf7WVv7fddfh/OgjbotG2WKaNAA/j3fxYecOtOYahpg6PrsLTVUxNY2oOwsbYEMh6PCyomk1XfEwDqAEGA3UYyWmDd3/LexeVt29jQNQuv/tbx9J2p28jkrppO6NZzA//yMBbxeN7T5CUTdCWL8pB1JaJarhcJhx48Zx//33D2r7jRs3cvrpp3PiiSeyYsUKrrvuOr773e/y8ssvH9ByCSHYsmWLHBJcSlsyRqV0JuNzP21bZNWk+itB0frfRtGs9eGNLPrkXura6qjMrkRTe2//8faP0YWOpmjYVCshTRgJEkYCU5ioioqqqthVO7qp88m2T1L7aqpGZXYlG9s2snj94gGLu6h2Ub+vX99RTzAeJOAKoKoqAWeAUCzEp1s+pUt04VW9qKhkmBlE1AhNWhNNWhNdahcZIgO/6qdLdFG7pbb7gPUQDBJ2eRiSCNBs6+QDfyMAxRs3Yo/HibpcxJ1O7IkE3nAYU1FIJG/0VZWOggK8LS1cdt99rNN1XsRqnvtpPAgtNWQ6/SjKrhuvTnc2cZsLRyKCU4+A00+LPYP6jvpd7xNWv9ONwOLu49V1Lxvg0+uzjyTtTl5HpXSyYfG9ZPvDtAS9iAOcnPaUVonqaaedxq9+9SvOOuusQW3/wAMPUF5ezl133cXo0aP54Q9/yNy5c/ntb397kEsqSZIkSV+CRNDqk+rIGjhJTVI0gmoGSza9SZbT3ydJbYu00RptRcVKRlFAURQrUTUTKIqSSsoURUFFpSXSQke0I3UMTdXIdGXy6oZXCcVCfYoQjAVZUreELFdWr9ePG3G2hrbi1Jy9XkNTNBoTjWhoqSfxCgo2YaNJbaJZa8Yu7FbNLwo2bDSEGoiGQrC1AdPuIKwq2E3wGXaW+ZtIxENktrRgqCqmat3mmKqKu6sLzTTR6THfn6qScLkY9eablG3dymLgeSNBV7ABV3ctdJKhaHS5MtFMHQWrRlQzdXRvAVs6t5Mw4rveJyATK+l8Eau5714+vdQ+rwJ931lJkqT00LzuU/Icm+iK2lNJqq5DQj/wr/WVHkzpvffeY8aMGb2WnXLKKVx33XUD7hOLxYjFYqm/g8EgAIZhYBgG0P0DraqYpokQAsMwEEJgmiaapqW2S0puv/tyVVVRFKXf5dB3vqGBlmualnr93Zcny7i35buf097KLs/pq3dOyVj9Op3T7mWU5/TVPKdkfPaM0a/6Oe2p7Af0nDrWonRtRziyILQBJdGBkggiEkEQPe8KrDRvdTDOjo5OitoihJWVuDJ0IqrOqkiE2kgUo/s1kklV6hVF8ii7iO7/eX7N02Rou9IsUwhiQnB03XNkaLZeBwgbBvXxBE5F4aMeSV5CCMKGgUr3+yzApgtMQ0W3CRK6QshMWO+fMLGbBmGndX72hIOQEk29SlSN8OGyZ5jWHCfqdGHYcrHpcbJ02OYM0xasQ0skiDkcCEDpbu5r13UyQjHiDg8JdOIuBVNVCPu85Da3UPT2azwyvBShR9GDW7FpTtCju87b6UdXbRDvQkm+YcJE2FxsEfCv9s3YXJk93j+FiN0NgDsR2bVPN5ce5fi6N3ot86g26jOH8eYbt3H4jk+RpJ6ygK0vHepSSN906zc5GFqs09rhQAjrt0TrfnqXOMAt07/SieqOHTsYMmRIr2VDhgwhGAwSiURwu9199lm4cCG/+MUv+ixftWoVXq8XgOzsbIYOHcrWrVtpbW1FCEEoFKKpqYmioiI2bdpEKLTreWdpaSk5OTnU1tYSje76URs+fDh+v5/Vq1f3usGpqqrC4XCwcuXKXmUYO3Ys8Xicmpqa1DJN0xg7diyhUIi6urrUcpfLxahRo2hra2PLli2p5T6fjxEjRtDY2MiOHTtSy3c/p6SCggIKCgrkOX3Fz2n9+vWEQiFWrVqFoihfi3P6On5O39RzEkLgdrsxTZPVq1d/Zc5JNTpxxjdTUphLhi+HtVsSJNj1u3LAP6f6emx6M854PZmRzeTt3ITeugzNW4fpcIJNRVVU3urSube5iw5T4FfhmiwXxzg81ESG85hzOJvtb9HaVUrG1ihmIkyLt4POHA3d5gI9Yn0msMfGWj1TKt3uIeH0osU6wEhYybaiEsoaieEbgpKI4mhdhxYPEdPc6HYHqtOLIky0aAeKEccUAgGoBmTEBe44aAJiqknUBhl6DLtpYDNN7KaJgiDusF4/Nx4hbnMQcrjQhQBFgDUALzGbA0PVUBUD1RAYCsSx4i5Zm6oIBZuuYI9DoF1BqAoCDUMzCXtMujJUVNMko7MTgWLVEJgJhM3d+z1S1O53rce7I0xQVISiIoTZ510VVrV18gC7vcsKiiJ6/W0XCQxVI25zoqbW7faaPbbvu3xftv2qLE+nshyo5elUlgO1PJ3KcqCWp1NZDtTy/T+GKVQ0VWD2veQdcGk76q+iKDzzzDPMmTNnwG0qKyu59NJLWbBgQWrZ4sWLOf300+nq6uo3Ue2vRrW0tJTW1tbUCFVfi6fwX8eaBXlO8pzkOclz+jLOKVSPsv1F2LEEJdYIwkBRbZiOPCiYgSg8DTzF+3dORgw6N0DnerTO9YjgOuishe2t8FEHLA+idOiIfB2mxyHq4F6PndtjYVpF30fWNpsP55QfI8qOJfrmz8BfjmoquFtCODui6FkeokYt0aaVoGgoioranZaZpgkK1uBK3UmVCZgIhGngKRiHr2ACLgTZpo5hJNga3ErRSf+FI28CSkzH2RXF1RFhe+vnbPrsv7B5SlGwYY8myGxsx9G0le0Zm8mM6NiENRmOUBS6NJNmr8GQkIJPtz4jARiKSotHgALZXVZSa2oaLYFMuhSDkUY+o+ub6PD5iLmcKKaJIUya7Z3csLKA77y2hojLhYqGMwqqYaKQIOLOQ9dcqKaJZoBmKuhaAk1p4cFfL+RPF19Ma7ydtvq3UE099X44VSd2XyHB/GpsPWpHBQoJuxv3jhVMcBWR7cjsDibQFZUalweAykgYu7DOR0FJxaOzx2epKApxoN7p5mdb1nN4OPT1+D59Ha8R8pzkOX2Dz6n2pccYqrxMa9BNQrda2aQIk/G3rzxgo/5+pWtUCwoK2LlzZ69lO3fuxO/395ukAjidTpxOZ5/lmqahab17kPT8MBsbG8nPz09t25+DuVxRlH6XJ8u4v8vlOX21z0lRlFSM9tz3q3xOX8fP6Zt6TqZpsnPnTvLz89P/nNpXofWcBsY3nOQ0MGq0ETY9Bk1vp6aBGfA4yeVCQKwFQusgVIsSWocWXAfhzVjpYPe5AmyOwFM7rflKsnKhqhDF6wPH51yh7+TBSGjAp9e6HkJ/++e4d56Ny+Ej1rENM3MooaJcOosEGcEY3o4SosoqqxZQVTFRQFhT0eyq9FMwsJJFYRigqOQ4h6G1xwhpKtvcDsxwE+54AM9ScBhrCGW7WX9EKdHSLJweG45P/KiNDdjt+ehuO80luWS5BL6dG0jYDBy6ZtVbKoKYamI3FVB71yx2ORU8htUvtcshyNAVVMPAHW6jK3cIG0sPp6zpXbxdYXS7DVNVaXfE8YgMlKwKdFstzlgcVbhRTRCqgYkNQ+v+/VfBUMEQAndXCN3u5ZWRh7Oj0RpsysjIQXRuJ9MZwOf0Y9fsGIpKBAPT4cbW3XQ6oTlQjTiZqkJZwQjsmiN1FluBUd3/P57ho6D/j66XNmAocPyYI/ENYnvpm6PnvehA1zRJ+jJ4MnPY+uibeN1xWoLOHhWuKj1/1w6Er3SiOmXKFBYv7j0+3quvvsqUKVMO6OsIIdixYwd5eXkH9LiSdKDIGJXS2VcmPnefBqbn4EVK9zQw7kIIrrO2m3AneIp3bWPq0LkRQrXdiamVnBJv6//17JnWSL2+kdCZDQ//CxLZcHQV9Eh+7wmu4UE1lmqBpXYnlalmqtaLAxBZ9784hs9CxDsAgYrARCHic+LsCmC3BUgkWsE0URTFapKr2NF0HV0xMBVhNXEVAjCxkUWiGaK2COE8L0JPICJtUDYf2jzoNsHO6nxUVZC/s5lIwItZ/S1Y+SiZnmxUOwhNENDDmAknm/0JvKYdRdEQCuhanKJggpDNwMR6OCEQxFWT4UEnIKgLJBC6gq5p6IpOeWuczSNcbB1aStX6DdhQ6FIVutQ4EzuHIjxZNBQVMXzjZoQwMW0KqmmQcPgQiobSs0ZaGECUkPNEipeX4HX8lWxPDttGnIxIRMhyZ6VqVTVh4Im205ExJJWoGqoNe0c9pd7CXkmqgTU36iXWR8YjQCF7HlApuc8ckEmq1MdX5joqfe3lVo5jebyMiqw1dHS50HVAHJyHJ2mVqHZ2drJ+/frU3xs3bmTFihWpfkYLFiygoaGBxx57DICrrrqK3//+9/z4xz/msssu4/XXX+fpp59m0aJFh+oUJEmSpK+q5DQwuyepPSWngWlbCev+YNWqBruT0s663QY4SlIhYyj4upNSf6X1/525u/ov/vnPsKUZqqt7JakAt4utu46U7C6k7N5raNeT7PiWt7GXnYLeXovir8Cmaug2lbDXhqd1JB18hBA6QigoaAjVhilAKMI6uDCx0iYNn6MSTRXE/A4MO2it63D6huI4fBYOxQ9OO6bXS74QKLk+PJpGy+QLUEKfEuyoJ5Bdid0wKF7eRCd+GpUwHfYEflMjqCbw6TYOa4yzMhc6XOCLC0JO8MeguFNDINjpMehwmAgF/DGV0c1h2nWd+hEjKGpuxhMKsjFHIS/h4/BICappUlM1hvJNO1FFBAwVU3Oi2zN2dbcSAtM08MSaiTozWTfyKk5+3c70005kymFT+VEiylJDp721ttcUNd5IKxFngLjdbeXysSA5iTBDcypTn4QBrAPKgZndy97qXjbQFDX97SNJkpSuRsz8Ec0v3UB+oJNtLd6D9jpplaguW7aME088MfX39ddfD8DFF1/MI488wvbt26mv3zVXWXl5OYsWLeI//uM/uPfeeykpKeHBBx/klFNO+dLLLkmSJH2FDTQNjBCgd0KiA+Id1r/J/0LrwFvWe3tbxq6E1FdJjHJatvnRExo23UZOXg5O/27dT4JBWLIEsrJ2JamGAW1tvGFupLUwYdWkwq6mv4JdSW5Kd7Ia7+Ccj1pZ5etgfc5yoplF4M3HFQtTtaOdepeX7e4gKAJriCOB7rCDUMCMWsdAxV8wEU/hWAxTJxxuRITaUfMr8B6zACN/JDWALxjkqHeWU7GuE4STjSMrWXFEAZ3HLEBdupCWbaspalSxt4bxuvwUO+1scDfToIbxxRVGbzPI7TQZY8JHRbDDC94YjGmEQFSQ0DSKOmzU5MYRKuTGHGREdUYt30ZTdjnrM4tQtXZGtAnmNBbgcznJCCtktwSI2Stxxz9HFTq64kEI0OImijCw6+2oZpSoK4sPjvwvWnPHUP55C57NmZSOVbnd4eEmbwEfqCo7w01kxMN4NAcqBq5IGxFfAQJBdryT8XnVeBwZxLFabbdjJZwLgGR9+wJgIbAaa+TWfMAOJPawjyRJUjrZti3EAw8s47bbTmD4iWdx/53rmTf2j5TkhQhH7ATDTnTzwA59lLaDKX1ZgsEggUCAjo6OATv+mqbJ1q1bKSkpkf0CpLQkY1RKZ1+J+GxZBsv/H3jLQe1uwqlHrP6oeueu7RICwgaYJjgVKD4Fhk3vTk4rrabBikKwIUjtolrqltQRbgxj6iaqTSUjP4PhM4Yz8vSR+Iu7f3OWLYPrr4fMTGhvh6YmaLWa5551ajvPjtD7JKpCsRr27iJQTCvtRIHZa+DeV1QWVao8X+2ixa1jj8exGyb5YRgSgqVDYW2+QsymdB9XAdWO4i1ECxRbCbipWzWuGfmoI76FrWImir+YwoYG5v31BeY+9SrD6nfiiOuAnbgjj82lJ/Lu1Jl4mzRaW17hvfwnaXF9jK65UYVChg5ZkU7a3DHCNgMhTDQB3jgEohpBp0Knw0RXbdhMjfywjSO2OTFU+Lg4SrM7QkIbhkopeV35TNs+ieqooLztI3JbmnDEDTRdwxEfQtgzAlNZizf8ETYjZD14UFSE4iXiPJ5N5VeyvawETTSRU+OCO2D8vPEANAB/i7TxVLSVzYkocWGAaeCMtlPQsZWRuSOJDzmckN2DjvXkPx/4Flat6O4JZwPWvKqvYiWng9lHkpK+EtdR6Wtr06Z2pk9/jLq6Nq6+ehL33z+TadMUqH+GiyffxxEVGwlkxFBVk7xraw/YYEoyUR1EoipJkiR9jSWCsPlpqLkPvCPAmWktb3zLWqdooHug2YSmCMS7x+TPjkHtETBxPpx+OhRbaUbjqkaWLlxKW10briwXGfkZqHYVM2ESbgwTbY+SNTTAMWfnkd++Dl54Ad54AxyOVC3pVo/B68PhVxM7qfX1qFGlu+WqCqklQqB2/5SbWEU7drPKc//MIKMrTMRmUpMLYbsCmouKdo1AQsERjVLnT/DXCTZeOekYPp9yAsWHnY8rtxIjFiLeUoOpR4nZXLTlVOFy+lCAUatW8fMf/4pJH2xCM7Lo9OQScWug6Hi6mshs78AdHY7gZjr91TRlvkUj1xOx5eOJuxizM4AvYbJ55FZWF2zDW1+HXbExqslBVkij02FSkxujy5aFy3BS1eLAH9VQgJAjztrcnWzLvZaE50xGtI1iaKMPf0jBVEJsGL6aTWVdZISdjFo7BoSbQEgDcxsx5ysk7CES9gCGNhWXWYgjrhB1R9gydAtau4bzt06qT6vuFR4h4JN4mNrgFtCjjBQmE7NH4nP6CAE1QBRwAVXsvX/pF9lHkiTpUKmtbWH69MfYsiUIQHl5Jh9+eAWzZ3t47z1rmznHf85lJz3GK4sf5T9fkYnqASNrVKWvAxmjUjpL2/jsarD6pe5YAqENEFoPmhtsbjAiYCasprz28bByjdVE1+kEt9uaL8UZhA9GQB1QXg4LFhDMLGXJTUvoqO8guzIbVes+X8OEtjZobsJsbKa1IUrA3sWM4jX4Ey2wdSv4fHw00svdVR28lR0kpOmEVR2z55hOyV9sBYSiAgK1R1OrZKI6s1bjyWcceCORXq2FI25Pd0Kc3MHE1dlJzO3mx08/TXjmTHYNCWRpAt4HvEBhQwM/+eGNTFi6GUOtoiNT7Z6qxSqDK6pQ2AA2cx2mMpSo81d0+h0EOn4IRNDtJbgNA1vCbtVIT+uEt59FJExIuLrLmQBUhFpIsjOuKpIFbgGcbMtfSjCzEJuukd+kYE+ATVeIuQRvTzcIBRSOfl0ht3lXgq/bTFqydOJ2FXc0hE21HgB4wh4SJNgwbAOjXhlFID/whcJJkg6mtL2OSl9rn3/eyIwZj7FzZxiAqqocXnvtIoqL/UydSipRnTULHn+8naysrANa+ScjfRCEELS2tvaZF0mS0oWMUSmdpWV8tq+C5TdB3SOghyEwCpw5oNog1mxNKaN3gbPCSlI7O60+pBkZoKpgj4Le3R919Gior4eFC6l94iPa6trIrshEbW+DtTWwdCm88Dy89RasXoPa3ES2I0Sb4efzvBOom/0jmkvG80i5m7OOqOe5vGYipk5WWCM32HvonWS+lppNZvf+QN2DBf1gmQt3NLpr7KDuVa5YrPcUN6pKxOvFGYnwg9tvp7GftyqAVfMXBY5btIiqT+sQVBIMWEcXPfrKZrapaKZGQqsE6nDEX8YWzyLmPglFdIAiMG0KMWccPWKw/bNOtnpNRCJB98ytKBgIMlJnqaSSVBOIACeSHRyKptrwh1UcCZWEUyWSoeCKqYxebUd32Ug4BfaEQtxmEreb2HQVd8TWPYeqnnq/ujxduCNuHJkOvDkHb1AQSdofaXkdlb7WPv54Gyec8EgqST388CH885+XcNllfnJy4MMPe29/MGIzrQZTkiRJkqSDbqBpaNzF0LbcmmZGsVm1qc2fQ0RAIKfH4EUC7HHYUQaGwxrGtaKC2EefUbf0JVzChlrXZNWi9iAcTqLePCJ2HxHDSag5xtufmARaQXF7+c+jNtPhEuSHHdg0DcWh4NKcNIlgKkGF7mR1t4QVds1elx2BqdsUNCHY/bZBNQ1Uw8DsOc+tqiI0jYpPPyVj3TqMyspeI9M6gBKgIRjk2BdfxdmVScyloaCjCDAUGwpgS4CnS8FUAEXFJBNFLMERnUdLzslkJ97FHl1FVB0GioZDEQRa/Kwuzae4sQWIoKAicILiTZ2dkjq7HUAugmtxxBQcUQVvFwjNek8UQNcgfxt42sETV9HtJnZdIWEXmKrAE1WJanGU7hsqIQSOsIOoJ0qxXmy1y83cS/xIkiR9zb3zTj0zZ/6NYDAGwJFHFvHSS9/hvvvcvPJK3+37jO13gMhEVZIkSfpmGWgaGiMKwqrZw1kIqguC9ZDpAaNHkurpgIgXNvhga401+FFLCy2dfsLRNjIDhjWPjNNBzJdHh+GjK2EjGjagNfliMYQpMHUTb4GXvx0ZoU1AYcSOluHs9asfiCm0u3qnnAJQ6dvkFwE3vufAGY+nalN77qMAWiyG6bRGHjYVK6FVVBUtGuXce+7hvgULqGxtRetO5uIYZNhMqna2krdxO4jhRJ0mqp6wDqyo2HUVX1CgmlayiBAIJQ9FbMKu12Izj6DTexN5zXfgTGwCJROUfJS4iwnbjgdWofA5ontanOQUMgoG0IFVn5uDyT2gTEIRkNkKtjjoNlBMK1lN2MAZgxFrwd2lEgqYuDsFjpiCoSlocXArOoYT1IiKLWEj4UngGu/C0eSwOo9O3teAkiRJ+vp47bU6Zs/+O11d1jX+2GOH8sILF+D3O2nsr9kNMPkgXTdlojoIiqJQUFCQmkdNktKNjFEpnaVVfA40DU1oA3RtAs1j9VM1Y5CIW6P8+uIY7TpxJY5ii2HWC2yLO3Fs793uSXd5MRN21OFD6QwU07otSldTV/daAwDNqeHOcePJ9uDMchLeEWbkDSNZuXID7qgfzTAgHrOmqdFsRI0oXkMhHhd0JTuPdr+NZrKZVY8c+sLPbVz1qQvFjAz4FiimiSmsJruaYeCMx9F0HYTghCVLeHbWLFYXF+Pu6iAS2cEOe4Quu8rhjZ1oCR2EHVPEscdNMiI23FFQhYotYfWhtRlgqgomDhQMFCWGXVfIjIzDod0FLAbzVTDrAR1iNmAEcCoKNcAHKDQhMFFQAR+CUxFcC8okULpfR7fOGRM0BQzV+k8R4AuBaoDhshHMNLHHTDxdApsucCo2Egh0t05saIzMikzcATfx1jhKLA1iVJL6kVbXUelryzQFCxa8lkpSTz55BM88cx4ej73Ptl4vfO97UFUFl10GodCBj02ZqA6CqqoUFBQc6mJI0oBkjErpLK3iM7gOoo2QMQyiTdb/j+6ERLu1PmsceEogXA+tGzAVgaklCIogHY3ZbP18JNuXDUHpUBju3sbI4i78hV7Iy0MNZyKW2GioF3Sa3VWnCviKfPiKfbiz3djd9lRiacQNoq1R3g+9TygWIi8jDzxY/WE7O0lEw2Aa2BQo1jy0KyrNhEk16O2RoGZH4Mb3nVz1mQuhWoli0u41q6aqoigKDiGwCYFms1n9buNxcisrubOlhQedCR4q8tBePAxNdeAQ4N76Plq8A0XvwBV1kRX0YE8omCromoFiKth1FQRopoIqEgjVBqYDv2LgyrJhTcByBZjzIVoDnVGodMHKKnD5QAPF3IZhLMEUnQjTi02fgVCKdjV3Tp6MDUwBpt06SU2AzbQqo2N+SHRBwg2aouJwqjicBkpQIMoEWrGGP8+Pw92d/cfB6XZa778kpaG0uo5KX1uqqvDcc+dz3HEPU12dx1NPzcXp7D9dzMyE3/ym574HfugjmagOgmEYbNq0ibKyMjRN2/sOkvQlkzEqpbMvHJ+JoJVYGlHQXOCvBPsXHElQCOjaAtsWQ7AWOtaSrOVMSc6FqigQGE2kKYPWDWtw5XZR+95EmmtGYm7cicPUCfsLWaEOZXPc4GhPO7YtjXTUrsEeH05HOAvVp5JZlknWiCzsGX2fRAOEG8Nk5GfQkduBudZEUzTQFOJeD810QlxFFSp+dyaaN5OAqqIBbbEwsVADXm8pJy6r57r3BEd1ZOICjEQcYZqpHLa/2wbNZsOuab3XhcPgcsHdd0NBBrVLbqJ4WxPjhx4DNieaoTNEqSeaHUfbvpW8zgpAJ67paELDFk82LHaioHQPitSEYuYj7CNw+m306viKD2KTIBe4DzgNa2JRJ0ARGhehYU1Xq4QAsas1tNL9Uu5sEC1gNwC71dpajYPpgLwq8ATBF7O6GmsakNAgTyNzUibs9pGYjaY1qFKFGw15DZXSj/ydl74sBQVe3nrrUnJy3Njtg481wzD2vtE+konqIIVCoUNdBEnaIxmjUjrbp/jsOW1MtNEa3Ei1gSsfCmZA0engKd77cRKd0PoRNL8Hze9DZJs1wq8eBNVhNfF15YNriPWv5krtGg/H2bEpQSLixRlNEG/PQ7RGUYSJ5nDgz3XgjkVp3K7w8haVwz2d5BotFHrz6MjNpuSYYdgGeAoNYBom0fYoo+eMJuKPoCoqhjDoinXRGrFqYzWnnZyMfJw2J3GgGYgDqs2J3emjasYv+dnT9zNxyzK6vCYxVcWp69gMw6ohVRQrQaf3oEs2++5ZmgmGAUccAZWVLPr4z9S11VGdW40W3LprMyd8dsQQhn3egl1Xidhjqb6koCFUgaGa2EwNIQysDrlnotoDfW+sTaxup6cCxwNjgWXdy3tk0KqKVcuabOabPBFn98flwerCmnyrDVBLIScTawSoGnbVksaBMvokqRigtCm0zmil2DeIuJKkQ0T+zksHwz//uZpTThmBz+dMLSsoSI8R0GWiKkmSJKWP9lXWiLzhOqsfqbccFLs1yFG0EeoehZ1vwZgFkDmm977ChI7VVlLa/B60r2TXWLhYI/nmToH2z8Hm2VV72o+O+g5inQkyC3RibU46GwMQtEaRSLh9xHZ0okd1PAKCRgatjiGMyW0l88LphFbm017X3nse1R5Mw6R1XStZ5VlUzKwg35dPhj2DhlBDqlmvx+YhNyMXVVHRsZLUBFaFYyzWgcPpI1g+g7tuzeXhc88lo7OTLq+XmN2OYppWnaDbDV1dvV/cZut9zqZpNTV2u+HnPycYC7KkbglZriw0tXdyGYwHeSzQzCm2EoRSg92oIGEzMBUTVahgKuhqAs0UqNQiGI6pnIJd2HsnoMkBfHOAa7uX3QqcC3RiTdja821zAWF6z7OT273OizVjTQyrRtYFHNa9biiwHWjv/tvXvawnA1gHolwQOkYmAZIkfbPcdde7/L//9yonnFDG4sUX4Hb33wLoUJGJqiRJkpQeBpo2BkBxWH1H3YVWc+BVC2HCnaDad9WYtnxgNRfuyTPUSk5zp0D2RCtBXf9na/5UTOinmacRNwhuDaE5FRwBQf2nIzC2tBGLq8RwYQZNkgmw0+cgYLPRrvtRxlQT+M4ZHNNuZ+nCpTSvbsaV5SIjPwPVrmImTMKNYaLtUbLKszhmwTH4i/1s2L4BgSCmx7BrdnI8Ofidu5o4d2JVBjoBYZroepT8ilNp8xfxxswi/rFwIectWICnsxNDVYmrCjbTQFHsqKqKavZI1jXNSk6FgGjUqkl1u+HWhZA/k20vriXr8yxyqnIwu+c11dt17BvsdDV3MbppBi2+47CbD+OLrMWVyCahZqMIBQUDVTRhKkFUUQHcjGIrQTVUK5G003MAX7gHmNRdrpnAQmBB9wlrWElncioelV0ttT3d61LDGGMlqSpQhTXxq+h+vUJ2JapF3csEVtbf2L2uHMSPBQkz0TcmJUmSvoaEENx++1vceuubALz55iaeemoVl1wy/pCWa3cyUR0ERVEoLS2VI61JaUvGqJTOBh2fA00b05MA7JnQvBT+fWbvNq0ANi/kHAW5R0PO0eAp6nuMotOtWtngOqvf626vFe2Iokdj5BQ0E44Vsrn9eMKda7GZJqrNRCgCp9+Fw2tHjcdwRttpV7NpOft8ioqLyS+GGXfOYP3i9Wx4dQPtG9sxdRPVppKRn8HoOaOpmFmBt8jLXz75C3/6+E8EnAHao+1oiobXvqvJlYlVmahhJamRzh24PDlok62qyGHAu9dcw45hxcz8+c8ZUbMee0JHESZEuojbVLoK8vE1tmOPJSDR/Z+igMMBY4+AqT+Hj2bCIigMF/K94PcIZ4ZZXrKcUDzEYfWHkduZi8204Uv4KG0vpclVTMT2KjmRT3DHt1mvhw1BHoZ2FpHMk3C5RmBv06wktQkrSfRhNfe9ll1JatI1WIP/3g58CnSxKxl1dK/LB9Z1Hy9ZS+sDTgJGda/biJW42oACYFb3MT7abV0+MAeYCUqhQmmbvIZK6Uv+zksHihCCm29ewq9//W5q2e23n8jFF4/br+MejNhUhEiOb//NFAwGCQQCdHR04Pd/wUE6JEmSpP2TCMIH37X6kHpKeq+LB62ReaM7Id5sNfE144AK3uGQdbiVlOZOgcAYUAcx+MPuTYxd+akmxl3b6glt3ExUL+Ldxcex9RMntkgQv9pJZpaCQ7WmckFVwO1GFBXTHPMz4+6ZDD2md9vSWChGS00LelTH5rKRU5WD0+ekuauZn7/+cz7a9hEAM0fOZEzeGG5ecjPNkWbcNjcBZ4CEorFTGIhYB4YexeXJYeQp97Bl1JkowMlAPNLK8h0rCLZuZ2RtA7PfWUvVp//GKPKxeFKANfY2yj9v4Ja6YVQeOxuCQQgEYNL58GQlok4Q9obZ7t7Oxs6N7GjfwfDW4YxqGgUC1g1Zx478HThcDko6S6j4vAJhCmyKDd3eRtxcidtQ0EQG5FZhU7PQdM1KIEcAm4AzgTHADKyazb1ZBzyJVQMbAM4HKrvXbQOWsKuZcM9jhrD6pUaxal2rsMqxt3WSJEnfAKYpuPbaF7n//o9Sy+6662Suv35Kn22FgI0bIdJjtrPbb4ennrL+f0kJbNmya93ByKlkjeogGIZBbW0tI0eOlCOtSWlJxqiUzgYVn8lpY7zlvZeH1kP7Z72XaW7wlIIwYOJdMOSEfS9U5hir6fC2xbDjVejcmBq0SRguVr0zlk0flxLuUNBiYTLdMbKnjUUtKoD2DjB00GyQGcAUKurGdmyuvj+pTp+Tokm9M7N3t7zLrW/eSlukDbfdzc3Tbub0ytMBGJE9gvs+uI83Nr1BU1cTCWGSUFScTh+lFaeSP/laaousqsgKgHiY5TtW0BnvJCuu0lwwhLuvOY7JL3ZSMDwLDRi98lPWueL88jidO//jCor9xXRt7CL4H0FiGzezOms1kWgEomAKE5fpoihUBBqoqIyIjkBzacRcMcKdYaJaFK/uRUPDVAPEHYeTKfKt0XID3ScpsJLMlcBE4GfsW1JYidVvtT9FwEUDrPPRt6Z2EOvkNVRKdzJGpf1lGCbf/e7zPPLICsBqWPPHP57O977X98JomvCtb8Hrr+/L8eWov4dMNBo91EWQpD2SMSqls73GpxG1EkVlt4Ecwputf5254C6yRui1dTeN7VhtDZD0RXmKoeIKGDYfgjWI7fW0PP4KbX9bwdbtRSAiFNpasBNHdfkgJxvsdsjL7XWY8NYgGfkZ5FTlEIwFWdeyjqgexWVzUZlTmepvmjAS/HHZH3ns08cAqMypZOH0hQzLHJY61qSiSTx21mNsC25jycYlrIp38n8OL+PKZ9DpL+IjrBywDGvMoLUd9QRjQbKcmSjxdgzNhmoaaHo8dUxtZxMjw04+Le3iZ6//DLtmp+wfZZy+8nTqCusQpkBVVPIy8ijIKMC+zk5GIoOYL4aCgifsIaspix2FOzA6DXRVxyZsxJwxNF3DH/NbU+v0pAB+rMGMsvhK1FzKa6iU7mSMSl9UImHwne88w9NPrwKs+VIfeeRMLryw/+a+q1fvPUl1OA50KfuSiaokSZJ06GkuawoakbAGTgLQI5DoABTImQzarqHzMePW9j2mlPnC7D5alnbR9R/3Ym/cikPzkO+PUC+GYo8GUQ0TdB0+/BAmjIesrF3F6J5mJueMHB5d9yhL6pbQGG5EN3Vsqo38jHxmDJ/BxMKJ/O7D37Gq0bpJOHfMuVx39HU4tP5/6Yv8RVw07iKCWN0qN3X/m0xSJwAJI05DcCtOzYmiW82Ro/483MEmAo11JCqyaWnZgq9lBwmhU5eIs6HmWcY4xjBv9TwSgQTDc4dTkFFArifXGuU3DnqHTru9nbgZx6E50G06WS1ZNNmaQMdq8mvTUXUVoQpcCZfV/7Rn9yQBBLES1DasZrdfgWRVkiTp6+juu99LJal2u8qTT57DOedUD7j97gPG92f+/ANVuoHJRFWSJEk69PyVVj/RaOOuPqrR7da/juzeSSpY27nywV+1Xy8baY2w4r8Wkfvwf+ONt9LhLSa3Op+jCwJ0vRaktTNAtqsTdUg+dARh+QqYPBkyPKlpZkJVIR72PsyWFVvIcmVRnlmOXbWTMBM0hhu59/17aY40k+vOJd+bzy3H3cKJ5ScO7m3Baum6GKtbZRlWkqoAHdEOInoEn8MPXV0IRSXmyaR42XN0tG5i6bodFDZFqTLiBDM0bA4XDs3B5d7LOc51HM6RTmuQIrAGJmoAtoCtzYbX4SWmx4glYhjCwBv24m53IxSBoiq0eFvIimThMl2oprprYCMDqw9oHCsxHYM1sm4NAzfJlSRJkg6q6647mtdf38S//72J//3f85g5c+Q+7f/LX8K4HpWvhYUw6Uu4pstEdRBUVWX48OGoat/58CQpHcgYldLZoOLT7oeCGda0Me5CayTeSHei6i7sva0wIN4OJXPA3ruaLhaM0bKux+BFlTk4/bsluYCpm6x6ehUf/+ljyjctwRdrxhg5iuGHF2B32SAR5xjxIUvVsTTbinF12cjwBVA72jDrNhPOKibaHsWsMFl6zFIaE41U51b3mntUUzWauprYGd5JTI8RtUe561t3MbFo4l7fs2QT4rf1KIsdPux5o8nQHIxjV8WlYeqYwmq2q8cidAwpJ2vzJo5+cRO2yBEE3Rq+6FqcNpOs8pGcUTmRmpYajggcgROnVQsaw6qurcOajzQBdIEr5iJfzadT6ySshTFNk7AWRnEoqKh4fB7sATtql2pN82Ji1aJ2Am6sjHoo1lQyzVjJaxqT11Ap3ckYlfaH02njmWfOY+XKnUyeXLL3HXYzdSpMn77nbQ5GbMpEdRAURZEjAktpTcaolM4GHZ89p43xDodok7XcXbBrG2F0ry+HopmpxcGGILWLaqlbUke4MdxrOpjhM4Yz8vSR+IutMjR82MC7v3mXtro27EaEEWwkc8JwXNU9frw3bCBf7GTGEFhfNoQNDRrtnXbMRCZqbTMZx5Yy+pIJLB2+lG2btlGd0ztJDcaDfLj1Q4LxIIqiMHbIWAA+3vHxHhPVhmADi2oXsaRuCTXhRuq6B3jKL5xI7qSr+TQwlCE2J/mAoqjEhaBeGAztKuPSJxPMeDGL4qYfo6lOzE0+wpH1rCl8g88nddEo4thUGzaPzUpQP8TqQ5qcZtWJNWXLVsABdtVOFln4hR/DNBjtH402RCPQEUB1qNacOXasWlQTq6rXjzWgUrKmNo51p3EAWmgfTPIaKqU7GaPSvmhtjRAMxigry0wt83jsXyhJHayDMT2NTFQHwTAMVq9eTXV1tRxpTUpLMkaldDbo+PQUw5gF1rQxLR+BGQV7ADSv1Sc12mjVpHrLoXqBtT3QuKqRpQuX0lbXhivLRWZ5JqpdxUyYhBvDrHh0BZvf2syEyyew/sX1bHx9IwCuTBfHnZpN8fN2lOE9fryFgA0bAPAfNpSJpRHGjIjS0mGzamp3NpDzo7OJHV3BHc/dQZYrK5WkCgSb2zfz6c5PMYSBU3MyvvgoHJ48dgS38vSGV5k5Zj7FTqsmOIg1E0sUaGjdwP8uvYMtTaswXVk0ZJbjVO2UmgmKmmvY+cr/w1Z5BtHRc3jXSLCzq5nOjFzGrIjwX/+VYMRmB10BF23+egynipaZj6/DxZQNFzDyGYNHT32UfG8+pa+Vwnqs5NKBNdjRCKAYK+mMYM01mmG9HVpYQ/Np5E7MtWpNa7sLnNG9rR84Hitp3V0jVvK7fy20Dzp5DZXSnYxRabB27uzkW996nM7OOG+9dSklJV/OAw456u8hdDDefEk6kGSMSuls0PGZnDbmw6shsg1UOwTXWAMnufKt5r5FM1NJarAhyNKFS+mo7yC3OhdV29X0SHNo+Ev8ZORnUL+0nvUvr8dX6MPmslE9r5pJ35uE87OP4FndGs03qbkZYjFrSMNi63WcDkFRXsJKYoNtoOmsbFlHY7iR8kxrSp32aDsrG1fS1GXVBGf7S8gumMAa1W7lfhn5xNs3cnFLDd8qmoQCLMPK5cJ6jHojjjn2fIa0b2F782rUaDtDgSM0B4q/BHekhY/evp3Ot39FVsnRFNgzCGzXWPDgGVRszaAxsBoxJA926KA4MBIh2jM66HB3kr95DHMenUPzsGZ8zT7IxGrmOxnoOYixBpRg9Sn1dC+LYzXlTb5FyfXuftb1+tCx+qfO4SsxkJK8hkrpTsaotDdbtwaZPv0x1q1rAeDCC5/hjTcu3ut+0Si0tu76u6npYJVw38hEVZIkSUov7kIwI+Atg6rrwDvCGt3XX9WnT2rtolra6tr6JKkACAhtC9G4spF4OI4e1XFlujjzoTPJrsi2tnG5wGaDRGLXWPsNDda/hYWwe5+bRMLa3uUiqkfRTZ2EkeDTnZ+yJWjNfK4qKsOGjKctcxh1KDix8jRFtdNm6jTpUX7TfbhqYDiwvq0Os20Dir+UmsBQ1LwqRtS+xITOBhqC29jQtoGWSAtCCGJ6lNz2Tfz8uJ9z1MajaGttpCb7I/yak14trzojoIMZdrHOvY6qliqOsh8FPwSmAHcC9Vg1qj0raIZiNQlu7/7b172s5/ptwA4gb7d1SQZWVXE5MLOf9ZIkSdIBVVfXxvTpj7FpUzsApaV+/vznWXvd7+mn4aKLrOez6UYmqpIkSVJ6af8c4m1Ws9+yb1u1qf2IBWPULanDleXqk6TGg3F2fLaDrkZrjH27x052RTbeAi8ZQzJ2bVhZCfn50NgIJSVWjWkyUS3ppy9PY6O1fVUVRssn7OjcQU1LTWp1qb+U8vzD+MzmphMrB9w1+FECVButNlcqL9wGFBhxtgW3oioawVgHWiyIlpFP89CpLH7tpyQ6NgGgoFASKMHr8FLoLeS4rOPwvevD6WllqwFtTgOnHsFtCtQuHdM0iNgEMWcMvxagoKQAf7kfzsdKPhcAC4HV3QXNx6oZtQOF7EpUi7qXCaxa2Lbu/Q3A2/13cr8EVhVxO1aSugCrSbEkSZJ00Kxd28yMGY/R0BACYMSILF577SKGDcvc676/+c3ek1TbIcoYZaI6CKqqUlVVJUdak9KWjFEpne1zfDa+RSxsoyU6Df3dbQOO3tuyroVwY5jM8szUsmh7lNb1rQS3BEGAoirkVOaQXZmNMAXtG9tpqWmhaFKRtYPfDzNmwCOPWDWobW3WL7bdDnl5vctlGNDejn7mGfxz8yL+uOyPtERaMIVJka+IsfljyXJlsQar72lAGMSMOEIIFEUhEW7CzMgnmlNFTvch24FaPUa7HiHs8COEiaZHMbZ9RFt2Jc6h08hcvZ3hWcMpyyzDbXMTN+JsbN/IlmVbqG6sxi/amdyaQb0tn+3BnSiJOhQzgaLacSpDKSsZxdDCoWSQYU3GmpwqZgxWrepi4FWsdTrWnUEBMAsry/5ot3X5wPexBk9a3s+++VjNfWfylUlS5TVUSncyRqWBfPbZTmbMeIymJuvBbHV1HkuWXEhhYd8+FytXwjvvgGnuWlZfv+fjFxfDxL0PVi9H/T2UHI7+J2WXpHQhY1RKZ4ONz2BDkNq/fEbd+4cTTuRgaksGHL1Xj+qp0X07t3fSWttKV/OuWcq9hV6GHD4Ee4bVgVIIgamb6FG994uefjq89RasWweRiLWsqKh3s1/DQNTUsCPPzc+MZ/n03WYAhmcOJ2bEmFw8GZtqIw5sNnUSeoQd0Q4MYSCEAARmcBu2SVcSsLlTtawOYLNqox0FhI4a70KNtqEAjkQY7+izOclI4DZ3ldmu2tFNHT2sQwewpY2MrnZGh7ZQqb+BYW5AKAaKqqH5StEKTEicDp4MK5nsOVVMMXAFMB8rgY1ijdBbxa5+paE9rJu0l32/QuQ1VEp3Mkal3X34YQOnnvpX2tqsC/uECQW8/PJ3yMvL6LPtxx/DlClWD5aBTJ0KV16562+nE046CXyH6JouE9VBME2TlStXMnbsWDnSmpSWZIxK6Wyw8dm4qpGlt79K22duXN4EmaNLUZ3OPqP3HrPgGPLH5AMQaY2w4eUN6JHuRE4Bf7Gf7JHZuLJ6z4liJqyk1uba7aevuBgWLID/+i9YtMhq/jtkiPVvIgGNjYQbG/gsI8Rvx7uo09xku7O5atJVTCqcxE9e/wm1rbVUZleyJRGmURgQC6IpKnbVjomgq6Me019MbNgJRMKNtHqyUTQHummQAHBkoMWC2GJBvHYvfqcfTXPQ6cml01eMu2NzqrgJPYGtzYbtORvU6hBZD+JpMBNoGV60SAFWp1MD7CasexS2v2WNqGwb0/9UMT6spLM/e1o3mPVfAfIaKqU7GaPS7jZtamfGjMcIheIATJlSwuLF3yYzs//5wN54Y89JKlg1pxfvfeylfpk9q2kPEJmoSpIkSYdcavTeugZyh4ZQ3bnWQEfsGr3XW+ildV0rb9zyBkMOH0Ldq3V0bu9EmAJ7hp3M8kyyR2Rjc/f/0xZuDJORn0FOVU7flWPGwIUXwtKlVq1qZyesXk0UgxqtjedGRXj3sAChPD/fPfw7XDTuIjx2a1jcBccsYOHShazYuYJNsSB67mg8qh1FGOhdzUTiIfAVoR1xJUbmMMxIK7FwE7izrf63qoam2PAbCXL9pbumuhEGpqJiaN3nEwXqoHFbI/mRfEq3loKyFngObK1QdjTE4hDdYW2vOiBzKAgTOtbBRwth4p1Q9RVpjytJkiQNaNiwAN/97kR++9v3OfHEMp577ny8XqvW/a234L77IBjctf3GjXs7Hlx99UEs8BcgE1VJkiTpkEuN3lvUghrHGvl3N7H2GNH2KNs/2c62ZdvIyMsgUBYg0ZWgZEoJNufAP2mmYRJtjzJ6zmicPmf/G332mdUv9eSTCZ3+LV747J+81PAmG/PdRN1+zqg8g6smXUVeRu++q2Pyx3DnjDu5ecnN1G5ZitK5nbgeRVFUEu4s1GHHYCs+Go+vkHYjBqYBRhzNiONy+LC5Agzzl7A92oqq7GpubCoaqjDR2nSrn2gDGMKg3dfOnNgcfN/3wZ+fgI92QsYIUHarZXG7AcVa7q+E7WsgazH4rhjkpyJJkiSlK0VRuOuuk6moyObSS8fjdlvdXBIJOPNMaG/f8/5tbfQaKd7v7/13OpCJqiRJknRIxVqaaFv2KqUjO3EZawmHfOiuAmulsGpbW9e3Em21+uComopqUznpP08irzqP1xa8RntdO9mV2X2nqMFKUlvXtZJVnkXFzIr+C2Ga8NprxBWTv09Qeaj2F3RqnTDUzdTSqVw7+VoqsgfYF/A5fcSMGEfkHU5N9TnEMYkYcdRAKagOlK4mwu2bwFuIYneh6VEcmp1MTw4OVaPKO4Rwh5+OWAcBZwAFhajw4d4aIrB4B0TBwGBdwTrKi8uZef5MsAXhjsWgOcD0W6Py9uR2p95Dghr4MqHtVQjNP3QdjiRJkqQvrKWli5wcT+pvRVH4/vePTP1tGLB1696T1LIyCATSLzHdnUxUB0FVVcaOHStHWpPSloxRKZ0NGJ9dDbBtEcbq5xlTWYvDmUAkuojFvTRHMqnfOJb1b3al+p8qqoK/1E9gWIBISwRPjodAaYBjFhzD0oVLaV7djCvLRUZ+BqpdTfVtjbZHySrP4pgFx6QGYtqdufwTXtLq+MOUVna0vgiKQmVOJdcdfR1HFR814LkFY0HWtaxjxY4VbGjdwOi80UQVhU9KjyWjYQdjPtfwtAeJO7zUlYXpinUQzyzHgUrCTNAlDMrRyHRkMKFgPMu3rqCttQ1H1EUsr5Cy5SsgEWLrsEbac9opLypnwTELKM4uhmXLoH27NUiSV7GmiVFUECpggtMDYSCO1Y/0sHxo2wg1NTDpK96p9ACT11Ap3ckYlR56aDnXX/8yL730HY4+uu/0aU8+aTXd7ejovbyqyhrUPik7G26++cAnqXLU30MoHo/jcvXfOVmS0oGMUSmd9YnP9lWwaiGE60B3E+rIxeHsQjVVnF6V0sBruOIf0BQ4jnazmKzhWWSWZ2Jz2RBCEN4ZTo3emz8mnxl3zmD94vVseHUD7RvbU6MBZ+RnMHrOaCpmVgyYpH7U8BH3vvg91lZtg0CAfO8QfnDkDzht5Gm9muL21BBsYFHtIpbULaEx3EhrpJXNHZtpibTh3eni4o7JTH/vMIZsi+LQFXBotOcavH1ciP89K059qYeE0MkxDYaqQAtkbchm8o7JbHLXU1MGanAjkfD/snFyO/mBfOaMmMPMipkU+7v7mIZCVn9apwlHK9b8pZtUMDxgc0CXBm6gDBgKeOzQpEM02u85fdPJa6iU7mSMfnP9/vcfcs01LwJw2mlPsGLF9/rMkfqLX/RNUgF+8hO46KIvoZAHgUxUB8E0TWpqauRIa1LakjEqpbM+8dnVYCWpXfUQqEYkogixFaFHEYpKNFFIxLDj8axn8ow32NRxFaY9d9fx+hm911/sZ+IVExkzfwwtNS3oUd2af7UqZ8A+qXVtddz3wX0srV8KHRvwGCqXVl/MBWffhtM2QD9WYFXjKhYuXUhdWx1ZrizKM8vJcmWxM9xIzrYyrl9yCmWhOO1FXWwe4UC1gSuuk9tsY+4/8jhimeBXCzQ+Hw15rQnsa9yIVkjYoC07A1E4mumeOGf5DIpn/z9cNhdVOVX4nLs11222psjBbodsJ+QAFXbY4gK70xrdNxOwd28fT1iztssb3T7kNVRKdzJGv7nuvHMpN9/8WurvSy8dz9ChgT7b9dfc1+2GadMOYuF6kKP+SpIkSV992xZZNamBalA0XAEXNqeJ3qXgcGmgudC7EgQb88gtbiLh+4wtO3e1W9rT6L1On5OiSUV7fPmWrhb+9PGfeHX5vyjZ0cXEcIxjVjuZlSgn+65fgs0+4L5rg9v4f5//nW3OAGUVp5Hd1YxDj+JxZeIPl3P9az+gtKOEtZkfohle/PGxxGy5RNxO6ksVNMNk5DqNX9y4nfvmr8BfPoeNWaBngS0T8rNhjg9m4qCYw/b8Puq6lXg6HLvacNmB4QP0P21shPx8qx2YJEmSlNaEENxyyxv86ldvp5b97GfH8stfnoiyl3a7xx4L554L06fDiBEHu6QHj0xUJUmSpC9PIgg7loAjKzVKrebQ8OfGaNmgIjIcKEAikkAIlYThJS97Bduaj8UwPIMbvXcAkUSExz97nBf//SBHfLKTn6wNMjzupTgocLVEYGgnPPwwnH66NbdqDw3AIuDPeoTa0WfhcvhoEiauWIiC5jU0NH7GqevPoKy5hLV5a3DY7Qg9iq21luxIK3G7BzOhoIYE4c4uyrf4ueUPQ5gw0k7NxRA9AVwZUIXVnXRQtmyxhmlUVWsEjT3VshiG9bh9zhw5kJIkSVKaE0Jwww2v8Nvfvp9atnDhdG6++ZhB7T9hAvzwhwerdF8emagOkmxmIaU7GaNSOkvFZ3AdRBvBW279beoQqiUQ2Eqn208s7MXpFOhdVv9TXWSTYW/F626grWPE3kfv7YcpTJ6reY4Hlj2Af/0WrnhxByM7NPJLDiNQMgKWLLFqJf1+ePRRawK6BQusuVWBVcBCoNbUaYi24+tqwRvvxFQ0upw+PimdgstWwYyNNjpcLWgaODQHuqETjofxJ/y4giGIg0DQYe8g0+Nhkm8Snv+BSX1bcA1OTY01bGNODqxbB5WV/SerhmGtLy+HmTO/4It9/clrqJTuZIx+M5im4OqrX+DPf/4ktey++07lmmsmH8JSHRoyUR0ETdMYO3bsoS6GJA1IxqiUVhJBKyE1oqC50PyVu+LTiFrJKTbo3Agda8CM4nBCwWiVHZu9dDVH0OMGqqqgOp0o6ERb2mmubU6N3ksuLNu2jKgexWVzUZlTid/Ze7AkIQTvbnmXez+4l7q2OvLa4nx/SQfjzCIypx2FYrNZ/TxjMYIZNtaNzyeqGLg2r6Lyzl/iX3g3DcXFLATqgcJIG1tCDWQ4/Fatrx6hOdFFDJWxDWUMiQcIFXXiiruI6TFUVBKxBLFoDKfpJGKLEHPH8Pv8DCsYhme7B2qBLzIAr2lCba2VYN90E/z1r7B6NWRlWc177XZrMr3GRqsmtbzcSr53qymWLPIaKqU7GaPfHJdf/hyPPLICsHp1PPjgbC67bMIe91m5sv+BlL5MB+NBikxUB0EIQSgUwufz7bVNuCQdCjJGpbTQPd0MO5ZYtaamDqoN4cwnmnkMruFno6hO0MOwcwnondZ+WgZkHobbXURxYYJty7YTD8VAU0iEuoirAtXhYcIlE/Ac7+HZ0LMsec4abVc3dWyqjfyMfGYMn8HpI0+n2F9MTXMN935wLx82fAiA3+nntq7hHGmsQh03JlXz2NC8kUXVEZZU2WnM+ggdE1tAIb99CzP+cTPt37uPOncW1UCTqWMKk4geIRgPEXJ4EaodVehk7qzHqUymPbuY/JCgs6uTznAnCSVB0B7E6XLi9ropyyxjqH8oGfYM2BiEFeusUXhdLqtG1N//yMS9BINWrW9jo5WoTp4MY8fC4sXw6quwceOu/qv5+VZz35kzZZK6B/IaKqU7GaPfHCecMIxHHlmBpin89a9nM3/+nscrWLYMTjml94DuRXsequGgEGL3ybz3n0xUB8E0Terq6uRIa1LakjEqHXI9p5txZFlNexU7iASiqxFj/V8Qza+iaA4IbwJMsHnBPwoyykG14taR4UDVFBw+B5llWWQOCYNtJMde/l3WJ3byq6W/6jXarl21kzATNIYbeXTFo7y8/mXyMvL4ePvHCCGwa3bmj5nPpSPOwf+D660J5Lq/I6u0FhaWrqXOmyDLnUG57sWOSgKTRmc7f2l5mx1Naygbchi65mRrsIH2aDsoKglPLkK1oykKBagEMgOYmknMlo0/3kRmiw2v8NLmaqO6tJrczFwCrgAOzQHhBqh5AuqWwB8bwd0jqZwxo98+sgA0NMCiRVZT5Zoaa1b3jAz43vd27Td/vrUumfxWVck+qYMgr6FSupMx+s1x8cXjiUR0Cgu9nHnmqD1uu3y5NWBSMLhr2VFHwfe/f5AL2Q856q8kSZKUfnabbiY5SBIAigOcWajmBpSmN0F1gM1nJab5x4Lm7nUoUzfpau5CURRyKgI4RQsMn0+DFmPhGwup76inOrcaTd31Gg7NwRDvENqibbxa9yp21U6xv5gzKs/gB0f9gCJfkfXIubHRagILNKhhFjo+oN6ToLrNhubLAqxaCgcaJbYsbK5yVis2QnWvsRoTU4ChOTBtblSbC7uiUaQo2IFN5RHasqNkNruId3pwmSFinhj+bD8jCkZYCSpA6ypYsRCa68CVBdXl4O7RTLefPrIArFoFCxdCXZ3VvNftthLR4mIIh3vvN+mLtCWWJEmSDgXDMNG03nN2X3XV4K7jCxf2TlKPOw6ef/7r83yy/5nMJUmSJGmwktPN+Ct7J6lmAtpXoex4Fbu+ExQnaB4ovxhyp0HnJhBGr0OFm7sQpsDm1nCwyaqZLZrJotpF1LXVUZld2StJNTHZ0LaBlze8TG1rLQ7NgU2zMbd6Lv85/T8pEl4rSf3wQ2hrg+6mSYtYR128kcp2DS3Du2t6F0AAYT1Cp0igmwbBaDshWwbRYcdhyx+Lqig4eiSpAGGvwXvjWsls1RCoCJ8g5o9RklmyK0kNN1hJaqgeHNUwsgQ83VPLOBxQUgKjR0N9vXX30dBg7dfQYP1dXw/V1dZ24bC1X07OwPtJkiRJaa29Pcpxxz3CY499+oX279kvtbISXnxxcD1IvipkjeogueQE6VKakzEqHRL9TDeDMK2BkoJrwIyDANOejcidiGJ2QWcNjPp/UHMfdKy29nXlg2Kna2c7Hm8bmUUCJWM8VC8gqPlYUreELFdWKkkVCLaFtrGqaRWdcauvq8/h47D8wzBMg883f0Togfvwvb7Uqqlsa4PNmyEYJFiUw5IRq8hSBZrdCVnZABimSSgeIhgLYho6RmAopurAzCjAVFW8zgCa3YPR1YQa68DmDFjJogk0wptHdDD+syGMqs2kLr8ev9PPUP/QXe9V/SII1oFSDX4NeqxK0TTrbmPNGqvP6RVXWM196+qsJDXZ5C85s3sgMPB+0j6R11Ap3ckY/Xppbu7i5JMfZ/nyHbz//lYyMuycc071Fz5eYSF4PAewgGlAJqqDoGkao0btuY24JB1KMkalQ6bndDNCQGQbdKzaNVCSzYeSeRhOV0F3Uue1klhFhQl3wrbFsONVa5mpo4Rb0RMeEkPmwvgLwVPMum3LaAw3Up5pNdttjbSysnElLZEWAJyak+q8asoyy1BQiLc0snHNu9R8uplJWqnV3LeszHr0HAqxbutWGqsMyqNu65ddU+lKdNEUbsJQFEy7B5eiYkTaUTCw+YqwBTczMtbBmIw8ggXjWb5jBW3RNpw4cbe4URMqGysc3Hd1LQt+1U7VzioKhhaQQUZ3FW0QapdAPAtyNZgAeATsbLSa/e5O1+Hxx60+qH/9qzXFzPbt1jrD2DVqRqDH3DaaBpmZ1oBK8+d/fdp+fQnkNVRKdzJGv162bw8xY8bjrF7dBEBOjpuKiuxDXKr9I0f9PURM06StrY2srCxUVbaWltKPjFHpoNltqhn8lWDv0a4oOd1MPAQdKyHeai1XnVZ/1YwyBBCLxXA6nSiK3dreiIKnGCquIFgwk3X1r9Ha2MiKd1fh31nNZT/+kdUsFojqUXRTJ27EWb5jOQ0hq2mrpmiMzB5JZU4lNrX756wrjP2zlehmlOjwoWD0GJRoyBDYvp1oAHQV7KgIYRKMddIc78RwZYLdjaZouNs7aMnLprC1hlDpFDQB+aaOBmS5s5lcPJn67fU0bNlKiCCGC6J52YRj79Fyi4/JtUfgf9sPGwEdiKwDvRFGl8NwINIMr3868HwCpgnxOPzkJ9DSYjUNrqvrvY3Xaw3C1FN+vjXqb02N7Ku6D+Q1VEp3Mka/PjZvbmf69MfYsKENgKIiH0uWXMjo0XmHuGT7Rw6mdIgIIdiyZQuZmZmHuiiS1C8Zo9IBN8BUM7jyoWAGFJ1uJZqJDmsQpeAaq5ZU0cA3EnyV1vaAMAWdnWEcDicKCWu55qIh2MCi2kUsqbOmmgk2Bukc0kl+eS3q2kBqqhnd0NneuZ2a5prkeEcMCwyjOq8at633YEzU15MIdWDL9eDSHZDsAtvZCVu2AOAyVWx2G3EzQVd7C40BH8Kdi6aq2NDICnZg8/s5bOhQKho/593sEbRmDkNRd/1kZjRlMHr5aCrECFqzO9g43k6RqnNP9neocnrhVOASoAaIAmuj8BcdRujw+QprxF6w5jvt73srhNW8t7QUYjFrm55TUigKDB/edz+73aqN7TlPgbRX8hoqpTsZo18PtbUtTJ/+GFu2WCMglZVl8tprFzF8eNY+H6u9ve/zy0NJTk8jSZIkHXx7mGqGaCPUPQrbl0DGMNj5BiRCgAnekeCvht2Tx56ijeDKZ1XMZOG/b+o11cyOdTtwdblQShQeXfEob2x6g8PzD2dR7SJaI62YwqTUX8ph+YcRcAb6HjsRh60NNGYo5JseqvTubTo74e23IZFA5OdT6tDI6txBg8skLxJD8QdwKArZkRgZsTg2vw/GTwBPBhnRdko+fRxj7Plszx9DQkB+Ldg/h4QNGkc4aB+Vx1gNFgBVPcvjA5KVmpoGbc3wSq1VWwpWk+TqanA6+55LPG7VjF52GTz0kLWtw7H3zy6RsGpZZV82SZKktLJqVSMzZjzOjh1W15jKyhyWLLmQ0tJ+fs/2ornZmjt1/fpdy3JzD1RJ04dMVCVJkqRd9jbVjKsQEp2w4xVrnacYsiZAvA2yxvfefnfC+P/svXl8VXed//8859x9y71ZbvZAWBIghUKhG6V2kbrQVlE7italo+LYr6N2qmPFsTqOVaQzat3nV0fHqnWpy1grVAtV29KNblDWBEhISEJys93cm7uf5ffHJyEEAg1tIDfweT4eeZB87rnnfM7Jm3PzOu/35/WGbJSOwqtY/8y3x7SasUyLVCSFzbIxs3ImESL85cBfeOTAI1QGKplTOIe0nubSikvHuP6OYXAQI5UkWgSr05X4cyo0N0FTExnLorW+nkPz5pFNJahLP82Wkk7K4xmq+gdwuzwobrdYy1pTAx4vAIZpYPTu4mMzVhAybWxuhJY06LVgK4ZwFaxWYBUwTudTwRNPwNe+Bt3dQqSWlcHixeNnUkeIREQZ7+tfD3/6k/i5qurk2x//vvr6V95WIpFIJGeFF188whve8DP6+lIAXHBBmC1b3kdpqW9C7zcM+Jd/gT/8QTyPHBoSXyMUF8N//McZmPgUI4XqBPFLUwpJniNjVDIpjLSaOV6kWhYk24VRkpEEZfjjo+IGqPsYvHSHWMt6fIuaYex2FeJN4KtlYwKaB5rH9ENN9iYxTZOUL8UzA88wkB5AVVR0U+d1M17HHVfcwaf//GleaH+JKu8M7JqNAq8Xh300y2jkcjR5EtTqJazao2Pt+jO9Hg8tc+fSWVaG6fejY5LUdCqVYgL00VxuMK9qAUppGRQERensyP5Mg6b+JmpDtdxcdDWVH4c1u6GxFtIfANcSkUE96f+8tjb4+tfhySfFz+Xl4jouX37i2tJjMQxR07V6teiTunIl/OQnw8ZPp3gQcOz75P3gtJH3UEm+I2N0+pLJ6KTTOgDLllXw5z/fTFHRxC16H3sMvvOd8V8rL4ctW0SBzrmGFKoTQNM0Zs+ePdXTkEhOioxRyaQwXqsZ04BMj2gjk4uKMc0tSnwVDYYOCHOlhnUiE3tcuxmsHGo6QoEVBV8tsdkfZ8vjXx/Tagagq6uLg8GDJAoS2NN2bKqN+qJ63DY3rX1t/N/zu4iGbqQz/gsOxg5itwcIpAJUWSoVfi9DVpxoopWqQYs3NQ/yuF2j74pagrZSPM4A2O049RS5yE788S6qnD6W+6/kHscL7HEPEXJkCKsWdssiZ+aIJCJE01FqQ7Wsm7uOyo9XQiv4PbDsI8AVp7iOyST86Edw//1ivajNBu95D6xaBf/+77B/v2glM57oNAxoahKlvqtWibHrr4fHHxfjp/M+yYSR91BJviNjdHpz+eXV/OlP7+GrX32C3/zmHygoOL3lGd3d44/X1MCjj8KcOZMwydeIdP2dIkzTJBKJEA6HpdOaJC+RMSqZFEZazTiLIX4A0t1CpFrDayoVGwTqwTcHVE30SB1qgVgjFC0bt90Mqg3LGSZWdC3++nfSFOs+2momrac5HDtM22AbkVQEy2XhsDmYFZzF/JL5ODUnkWgvT/U30zpjkGp/HVepH6ar92kO979ALHOEHVg09cD8lEWoL0WXS+Pri3OkXQOoSoyQ1cnVmUqu7FFJHN6DHSj1lXJJ5aXYO7vYUHAJmy5+A5s7nqAl2oJu6thUG2FvmNXzV7Mqu4rKf6mEvhh4muCjaXC6IFZ3Yld1y4I//xm+/W3oES0HWL4cPvUpmDFD/LxuHaxfD3v2QCgkynTtdlHLFYmIjGhtrdiucriYuLLy1b1PMmHkPVSS78gYnf5cffVMrrpqBsqxxnivkg98QHys3HqrWE2SD0jX3ynCsiy6urooKZnettGScxcZo+cpr9Q6ZqJkB6FvG7T+CgZ2iEzpsR+kmgvclRCYB5ow/onlsjQloqRj/biObKfOV0dguN0MM9YI8To8L9M7h5Z9h1joriDWs5+eZA89iR56kj1YWFimBQaEMiEuX3Q5QW8QgEQyyc5UjrQKNdFeKoMV4CgmVHEjs8OvZzDRSjoRZX9JmL1uG6ldP6b8iI15bX0Y9kLcqsWQmuYh20s87s/xdq+Hqx11LCq9ENU0IRqlcvUtrF2+ljWZW2jsayStp3HZXNQX1eP/ux8+1wG99wJbwBOB7w9nSMNhUZJ7/fVCGDY2wt13w44d4ppVVgqBeuWVY69lQwNs2ACbNol+py0to1nXcFiU7a5adaLYfLXvk0wIeQ+V5DsyRqcXv//9Xp59tp2vfW3lGGE6GSIVRHHOzJmTsqtJQ7r+SiQSiWTirWNOhmmInqe9z0Dv06JcFwv0BFjD+3KGwVUqvuz+o2KrI51gY6SNLX3tRDJJdD2FbeAHhPc+wspZK4+2lKFotIenpevsi+7jj0/8kT80/oG2wTYcmgNVUSl0F1KULoIIBAoDR0UqQNvgIIN2FU/KwqGOrkW1TBMjbQIVJIpriHuiJEpnUjxwHcWB3RQObsMRi2EE/GSG4pToOp0ek7/VO/mHzFzUnHlCmazf6WdZxfCcLeBHwDd3Q9d6cDbDohCU147NYt53n1gYVFEBTz0ljJJcLuHU+973ntylt7IS1q6FNWuEwE2nxfvq60+9tvTVvk8ikUgkZ42f//xlbrnlDxiGhctl40tfumaqpzRtkUJVIpFIphMTaR3T/bhYMxpsGH1fslOI0r5nRPZUT4zdr2+WcO/t2iLcfX01Jxx6d7yf9Qe305yKEbI7qXXYsLuKyBUtIJLq577t9/F46+OsW7GOhnAD7bF2NjZt5E9Nf+Jg5CAejwfLsvA7/BR5ilgUXoTP4ePwM4cZsobwlnqPHiuby9KhqiipHjz2EAWeGiwgnkwSA3J2O9jt9DjiZNQsgUQCtfxC6ox2HIuXoL/4HENdbaCZ2B0aiymn1Z1m08AO1h4InLxMNgvcBfyhQ4jUYBtcvQBsx6y9cTjE+9JpeOQRsWa0shJuuAE++UkoLZ3Y79Lvh2XLXnm7yXqfRCKRSM4o9977Ah/96J8YSS62tcUwTQtVfW2Z1KamSZjcNEQK1QmgKAqFhYWTlq6XSCYbGaPnCa/UOsZTBe5yUQ6868tQ8w8wdFBkTpNtY/dlD0DRZVA8/OUKi3FnETT/RLSSOWb/HekE6w9upy09xAJfCA0gGwXvLBx2D1V2D+W+cvb07uHWjbdS4avgwMBogze/y8+qulXcWH8jz3U+x33b78Ntc2OZFsmeJAC+Y2z6BxMJkpoCmUEqy9+Mw+ZhMB6nfzhLqQBOxSLpTOPHhisZZShYwSBeVFeEl0rTFKp2ygcNKiwftkSWoGGwuSjKmuUfwX/D208UqYPAvwIvArGNUNwMVy440byot1eU+A4Ojrr3vvWt8OUvn8YvU5JPyHuoJN+RMZr/fPObT3P77Y8c/fn//b9lfOc7q16zSL3nHlHqeywFp9969YxzJmJTCtUJoKoqNTUnZhckknxBxuh5wslax4Aw8skNCgOkdAT6XxIZVNfIeiYVQoug+HLxFZgHyjiGHBXXi4zsca1mNkbaaE7FRkVqblCUBHtqMDGJDEVoHWylM95JMpek1d1Kqa+USysv5fq667l65tW4bMLlsNRbyhOtT9DU30SlVYmpm9icNpxB59Fp5AydRKKNUncFNUWXkY5G6Xe70RUTVcnidtqJqznSik6B6UDBwFQ1ejMxGtuewLSZqLVlLCi9GFsiDbpBTcaJ2R2go/Q65h2pFH1lRpb0tgGfBA4DzhjM3gKu0FiRmkrBzp3Q3i5+tttFPwCnU5TixuOyBHeaIu+hknxHxmj+YlkWX/nKE9x559+Ojv3rvy5nw4aVr0q8Pfyw6Ik6OChWlDQ2jn39858Xnnr5xpkw+ZJCdQKYpkl7eztVVVXSaU2Sl8gYPQ8Yr3WMZUGqU3ylI2BmRrdXVVEOXHEDlF4NRReDzTvursfgqTyh1UzMFmRLbzshmx3NSIKRBbuflH8e+/sPcnjwMBlj9Nh+p58yXxm/uulX1IZqT4jPykAl61asY/3W9ezYswNcUBWuAguyZpZIIsLhoU7c7nIaKt6Fa0il2avS5YwzaE9iaRYmFjoWQ0oORQWP5cIycrT0NWFaJuW+ci6uuBibaiOYrOaCHRcwb/s8bD02yv9cDl4gDKwEaoC7gRhQDnyoCe6JQLh29LoMDMATTwgDIxClwyMiNZsV5kaNjbIkd5oi76GSfEfGaH5iWRaf+9yjfO1rTx4d+9KXrubOO1/3qkTq/fcLR1/DGP/1L35RfOUj0vV3irAsi/7+fiqlm6IkT5Exeh4w0jrGd4x4iu2F2L7RnxUbOEtEGa+jEDIRqLxhjLHRhAg2jGk109Szj0iqj1qnGxQvBGaSdBTz9/bnSOtpAJyak+qCamoCNbjtbg5FD9GX6qM2VDtufDaEG9iwcgNf/suXed56nv6CfuK98aOtYdYu+SCPZGrIKQGaibLXN0ha0/Fjw23aUFFIKjpDSo6okiXqK8IXP0I20cKcwjksDC9EQaG8rZw3/eZNlHSXMOQdor2knaoZVeAAIsA3gR6gFLgY+AawJy0Eqd0+ek327RNjoRAsWQLB4Ohrdrt4LZ0+vessyRvkPVSS78gYzQ8sC1pbxfNJ07T46lf/zM9+tu3o63fccR1r1ixn//7T3/fmzfDxj8PJzHM3bIDPfOZVTvwsIF1/JRKJ5HxjpAVN3zbIDoA1U4zHD46KVN9s0T7GWThazjuSbTVepXg6ptVMet+v0SPfxl44GxwhMpbJ1tbHSOtp/A4/F4QvoNRXioo6fGgL3dSPitiTEUwHueiFi2iwN3DRpy/CclmjrWHsXpz//d9877IKul1dZFSDYss15kPLZWk4UMlaJronSLLxQZYW1jC/eL7Yf1+QN/3mTRT1FNFZ3cmQPoRDc1DgLgAVkUHtAUaSwV8AChFOujabcPd1OCCTga4usc3SpSf2T83lxPau02vgLpFIJJLpQzoN11wDzzwzMpICjnU5WsWGDRezYcPkHO/1r4fycvHx8pa3wNveNjn7nU5IoSqRSCT5yPEtaDIDkGwVwtXmEyJUUSEwHwrmn/h+KyfazGivUTzZ/biKFmNzFpKzB1FReOrwUwxlh/DYPKyoWYHb5h7zlpyZw6bajq5JPRmHnzoMQM28Gq6ou2L0BdOEu+9m3t69ZBbXEA/XUNrXgY3jntZaoOlglNXh6GvB0b4VfMVHX77g+Qso6S6hs7oTUzHJGBlmhmbiwAHPAe0IV6aFw294FJgF1NWJ3qSRCFRVweHDQviHQieKVBDbhcOiTYxEIpFIzkmefvpYkQrgAd4P3AdcDSyetGPdfjv813+NbcN9PiKL3CeAoiiUlZVJpzVJ3iJj9BwjuhteukO47+oJUe5buAQcQeG0G9snxl1lwhRpPNIRUQIceO3iqa6ojrA3THeim2c7nmUgPYBDdXBFzRUniFSASCJC2Bumvkgc+2TxOSJUqy6vGh20LLj7bmIPP8xXb3k30cO/xzvYRaKoloS3GEPRsIAcClF3AIrnYR84jOvF7+PLxemIdZAzc7iSLuZvn0/Cl8BUTAYzgwScAWpcNfAEoyJ1KUKohoDNQBwhRleuFOtSdR0OHRJzmzHjxItjGBCNwnXXSSOlaYy8h0ryHRmjU08iMd5oCPgYkylSv/CF6SlSpevvFKGqKmVlZVM9DYnkpMgYPYc4VQsaR7Hoh4oqxo00GMkTTZIsQwjaqtXCmfc1EnAGeP2s13PX43eRyqWwqTaW1yzH7zhx34ZpEE1HWT1/NX6neH28+DT7o6S3bKU0maK2YCbEYkLobdiA9dvf8h+33UZrhRO9tZmr2jbT466lI3wBQ8EKDEXBNLLY4hFKDmxmpt5FS6qHQSNDMpekJ9HD7COz8UV9tBW2kUwnCTgDLPYvxvukFxKAHbgMGDFFDgMtQCOwDLj+enj88dE2NJomsqtjTtYQze1qa2HVqtd8nSVTh7yHSvIdGaNTTzqdA7YCVwI2vv71keeX9lO+73SYMwcuvHDSdndWka6/U4RhGBw6dIiZM2eiHd9PTyLJA2SMnkOcrAWNnoBUx/AjVk2sSdVjkGgbW/prGWJNq68WKiZPPB2JHyGZTZI1siyvXU6hq/CEbQzToKm/idpQLavmjB57THx2dcHGjWR+8xBL9zeiaRD6/jb4XVhkLw8c4Fc33sjfb7gBNbaLGlOnSDMpzjUzu72VPtPFrt4mcnqCQiXJxeUL0ZwBwpWX0jbYxp7ePbTH2+no7SCXyaE4FOoL6qnJ1eB92gs5hOPvckR7mhHsgA6MLKutrIR16+C97xULk0b+QLQssSY1EhGZ1NpasZ00OJnWyHuoJN+RMTq1xGIZ/v3ff4HoZRYBbuK66zQWLnyFN55HGCezKn4NSKE6QeLx+FRPQSI5JTJGzwHGa0EzMt77NFg6OEtBtYs+pliQPCzMlBREuW82KkTqgnXCEGkS+NmOn/Gnpj9R5isj7A3Tm+zFMA3C3jB21U7OzBFJRIimo9SGalm3Yh2VgbHHjsfjsHs33H03NDeTjinEHcX4akIotSVi4U97O9GiIv54/fUQDPLepIu/qDZyZg6H5sChGPT0PU184AB+h59Lal+POmwe5XV4mV04GxOTjyz9CIsqFzHj7zOor6jH0e2Al8TlohC4HHAed5I5xCfisctq584FjweKisRj85YWIaZtNrEmdfVqkUmVIvWcQN5DJfmOjNGp4YEHUnzkI/czONgxPNIC9DNakiM5U0ihKpFIJPnCsS1ojAwk20XGNDcgXtc8EL4aMMR48rBwAh54SaxfdYVFuW/FqkkTqZv2b+Jbz34LgDtW3MHra1/PpgOb2HxwMy3RFnRTP9pSZvX81ayas+oEkQpgj0RQ7rtPGBMtWED0sTZMNY2vzA9790JfH1mfj/byct73/e/z4owZ/L/iOl7yhokkIlQFqohn4xzsPwjAotJFR0XqCJFEhAp/BW+b9zb8tX7hb/EC4uE3QBViTep4yYgIovz32CW9jz8uHH8bGuCXv4T9+0V21eUSxklyTapEIpGc0xw+nGDNmp9hWd3DI27gvUiRenaQQlUikUjOBCNtZYy0cN4N1IF9HMfYMe+JQ6YXMn2Q7oajLreKME4KLYIRJ92C+eCbBf0vwZyPQNElwjhpEtakjvDU4af40mNfAuDmhTfzvkXvQ1EU1l60ljUNa2jsayStp0dbyjhPfmz/E0+gNDdDQwO5nEU6KmpsvZEWaGvGAl68+mqO+HzM27uXazdtwrV2LStnreQn239Cma+MHd07sLAo95VT6i0ds//x1sYSB1oRWdIFwDxxKU/AAKLAasaWA//xj+LfG26AggJYdpr9aCUSiUQyrdB14aMHcORIjLe+9adYVt/wq16Ey28YhwNmzpyaOZ5PSKE6ARRFobq6WjqtSfIWGaN5xPFtZUxdtIlxhaFsJVRcPzbbaVkwuBs6/gSHfwuJVlAdovWMPQjeGeCpAu34WlXEelVnSIjUoskVUbsiu/jM5s9gmAZvnvNmPnnZJ8fEl9/pZ1nFxI6pxOOUvvwyFBaCppFoHwTAZaWwtR0CoPnKK+ksKEABqoJBXJs3w5o1XD/3eh5vfZznO5+ne6gbTdVYVLpozP5PWBvbD/wL0IkQqWVAHScXqU1ALXDskt5IZLQPwQ03TOg8JdMXeQ+V5DsyRs88jz8uVnQIoToA/BTxFBMgALyfCy8soq4O1q6VRTXHI11/pwhVVSkqKprqaUgkJ0XGaJ4Q3S0cexPNYp2prxYUu+hpmo5A833Q/Tg0rANnIXQ+LARqsk283zKEg6+jSGRPXykDO4ktaADhvNvUxJGeFr637W60oM7lc1fwhau+cEKZ7emgHjiAc2BAZCX37CGxZxBi4HXFwQUDl17KyyWijGoh4A+HxXrQxkYqly3j08s/zQ2/uIG0nmZmcCZ21Y5lWeOvje2phNuAI0AxcCfwILAH0UUgjDBOyiHKfaMIkboOOLZi+eGHRT/XCy+EmppXfe6S6YG8h0ryHRmjZ55vfnNEpPYiROrImuAQIpMa5I474N3vnqIJ5jnS9XeKMAyD/fv3M3fuXOm0JslLZIzmAadqK6M4RFbUWQJ9z8Hjq8HmFplTEKXBpdeKbOvAdmi578SWM8czmS1oOjpg40bYsoXskXb6I/v4sJVDLylk8XvrsXdFTt8wKJOBnTvhhRcw//QnrBdeQHW7QVEYipcCCj4vZC+6mGcrK7GACmA2EHNYNHkGSHdtw9UJz7Y/S6G7kJArRF1R3cnXxu6phDsQ7WdqgHuG/10ObEL0SW1BuPvaEKJ1NSKTeuzpWdZo2e9b3vKqLqlkeiHvoZJ8R8bomScWG/nub4yK1GKESPUTCMCKFVMxs+mBdP2dQtLp9CtvJJFMITJGp5iTtZWxLMhEhPlRqlOUAhtpcBZBxZuh8gYhUm0esb2nCiJPiPWtgbqx+zq6z0lsQbN7N6xfD83N5Ar8PGk7wkBYpUAr5EpXPY6f/xKefEa0YGloOPl+stmjwpTnnxff53IAKImEWG3rdJIKlGJm7aguJ64bL2ebqpAEPECpmuCHrja22NuIuKPozf8fZvfPaeprwmv38pXXf4W31r91/LWxvwe+BpjARcB/AgXDc6sE1gJrEH1S04iS4HrGrkkdziizaxfs2SMywNdd99qur2TaIO+hknxHxujZ4i24XIOUlBj8y7+8F7/fi80GV18N1dVTPbfzCylUJRKJ5LUyXlsZU4fYPpFhNY7548LuF2tUvTNgyX+emA31VIrS4N3rYXCP2KcrPLaEeLJa0HR0CJHa1oYxr56nOp9mwBjCZXdz2cwrcdi9YBhCvK1fDxs2jGZWjxemu3aJsWMpKYGlSzHnzWPo3nvx+3wk4i7o7cVbEaBFVehELB0N2Pq507edZi1GKGlRa4WwV17EM5EXyJk50nqahw88zJKyJWPXxprAN4H7h3++Hvg3wDHO+fqB8ZbVHpNRJhIRZcf9/WIN8M9/DtdfL1vQSCQSyXmDk0suuZk//AFCIfdUT+a8RgpViUQiea0c21ZmhKGDEG8S36vDpb+eGaKNjJWDoRaINY5vghRsgCUboHMTdG0W2x5ryjRZLWg2boTmZsz589l25Dn6kn3YVBtXVF+B1z5ceqxpUFcnMq///d/icfILLwiRerwwLS4WzrhLl4qv6moh9gyDwcZGAlu2MNQr9mtWBtg58jY1wfd922nThliQC6INDUJ9Nb16jCNDR3BoDq6ccSWHBw+zfut6NqzcIFrgpIDPA48N7+hW4IOMb5p0Mo7JKBMKifWo+/aBwyHMn+67TzhsvFJGWSKRSCTTkr///RDz5xcDvqNjdrubUGjq5iQRSKE6AVRVZdasWWdkkbBEMhnIGJ1ijLQQkop9dCzTK/7110FgPqjHlvDaR0uAT4anEuashRlrhKA92ubm1begiWViNPU1ibLZtE7dXx/GHwqxvedljgwdQVVULq9eToGrQGRSBwagpwd6e+HIESHgZs4U4hWEMB0RpcuWjQrT41BVldDNN2Ps249r1wskvOXsKfNiAuXATlcbzVpMiNTBGAT8WNXV7Oh+FoDaYC1F7iKCziB7e/ey6cAm1lavhduBvYjs6ReBN57mBTkmo8yCBeK8Dh8W5+7ziTHTHD+jLDmnkPdQSb4jY/TM8NBDjdx002+ory8iGPwAYiGK5NUgzZSmCEVRCARewX1TIplCZIxOMZpLZDutnDBOsizI9IvXPJXHiVTEdqpNvO+VsPtfc+uZjlgHG/dvZEvzFiKJiDAiSqQIFx3mAreP8vYoRdi4uPJiSpLAC09AX58QaSOoqjivxYvhxhtPKUyPR1EU/PPm0fr695P9awu2YBzvkU60cJi5Dotv2tsIJS2RSQ34MS+8kKZUO4OZQeyqnQUlCwDQVI2gK8jm7ZtZ84U1+Lv8EAS+ASw61QxOwnBG+ahIBWhtFf/OmCHObSSjvHcvbNokehJIzjnkPVSS78gYnRxMc/Sj7YEHdvGBD/wfum6yc2eEmpqngddP6fymM7I9zRRhGAZ79uxhwYIF0mlNkpfIGJ1iAnWiJDcdESW+enxYtGpgLzhx+8luK3MKdkd2s37repoHmgm5QtQGa7GrdnK5DtrNRn4R7Cfs1Pi3xFIq7WF47C+jJb1Op1hnWlICRUUi2/ihD03Y9nBvJsYDyV4GDJ1sbx/LojYa33Ub9jn9XP3MY1ze0sI+zwARd5RaK0RubjltAYum/m2k9BQAC0oW4Dymh2w4EaZlTwuNqUaWzVwmnH2rXsWFicXEmtRQaFSkJpNijSqMbUmjaRAMwnBvV9k879xD3kMl+Y6M0dfO7bfD978vTOnhJeAhEFZ/wELa2q6eqqmdE0jX3ynkTFx8iWQykTE6hdgDULYSmn8C7vLRbKojBMf3H53MtjKvQEesg/Vb19M22MaC4gVox2R2o9lB/PEMNTmN/pCLnxX0cMFLFpXZrCh7vfxy8e/IE9JsFmw2cL1yFnjTUDdfSkfZ6Ski6ykBSwVPOT9am0IZjFAeCHHB2vfja2wk3bWNoaZvs8vpoi11EHNIPOp2ak7mFM5hVmjW6I6bwb7Dju7TSTek4S5ED/ZXQ1OTEKW1w+uKLUusVwUhzL3HtQc6prcry15bhluSn8h7qCTfkTH66jl8WPRJFWwDHj7m1SXADcDo57WssM4PpFCVSCSSyaDieuh+XBgr6UNizHFcc/bJbCszATbu30jzQPMJIrUn2cO2RCOLHSqFuKlWytinDrBJ72Etdpg//8SsYSQixFr9qbPA34m2sc7mIuWvwp7R8femUXImpqKQCbjIhWfTlU7QGungkVA/393/ZxozHTh0B6qiEnKFmF04m0p/JdqxrXleBg5CTslhK7Lh+kfXqxepAOk06DrYh9cVNzaKv2QUBebNO3F7u11sL9tDSCQSybRjYGDkuyeBLce8cinC4GBs2eq1156VaUleASlUJRKJZDI4tq3MkYfB0kXZr2VNfluZCRDLxNjSvIWQKzRGpA5mBnm6/Wl0DbJlYQKRLIoFwSGdzRUp1hwuwF91XC2tYUA0CqtXn7LsddNQN+tsLjI2L4GuITRdwVItsIFlmdiHUthjKdLFfr7sKmTWgxvQ1MPYVTshV4glZUsIuUMox/7BoAPPAV3ix0hdhPCsMPWlr7Fs2uUSGeJcTojwPXvE+OLFIqN6PLnchDPKEolEIskvLMsC/g48fnTs2mtX8MY3XnvC2srZs8XHnWTqkUJ1AqiqSn19vXRak+QtMkbzhGADXPA56HlC9FbNDcLg4OS3lZkATX1NRBIRaoO1Y8Z3RXahmzrFnmJmVC1Bee45GIgSTqRo8Zs0Lq5i2bEf2iN9VGtrYdWps8BfSkdJ+atGRarNAkW0OjWHxaei6Dj7+kkXF5Go+RCf1naSCqb47Z7fUuAsGCtS08BTwCCggrHMIGqPsnr2avzO11g2XVcnMsQHDojzA5gzZ7QU+HgmmFGWTE/kPVSS78gYfW08+ug+jhWp73//tdx335VTN6FzEOn6O4U4HON1j5dI8gcZo3lCpg9cJRBaDBfcOSltZV4NaT2NburY1dGWObqp05PsAWBJ2RI0hx8WL4HHH8OeyaIXqKQLAyILPJJpjEaFeFu37pStWfZmYuz0FGHP6EdFqoWFZVnoIyLVsECxUFHQcjkiFzVQsdnBsisqefHIizT1N1FXWCcywFHgaYRYdYJxmUGT2URtQS2r5kxC2XQgABdfDHfdJcp6Kypg4cLxt51gRlkyvZH3UEm+I2P09Dl4EL7zHdi/fx7CHv5l4I28852XTfHMJBNBPpaZAKZpsnPnTsxjWzVIJHmEjNE8Ivqy+LdwqWgrE14h/j2LIhXAZXNhU23kzNzRse5EN6Zl4nP48DmGG5v7/aAo5NwubE43rs7hMtiWFmEodMston9oQ8Mpj/eT6GEyqhPnQBoDg5yZQzd19OHXFdNCtSxsqg2bZsOdTJP1OflD3xDFSjHrVqyjpqCGPb17aD/UTvaJLFbaIuvP0n5xO3v1vdQU1LBuxToqA5OQkR4agscfF+W8qgoXXTR+q53TyChLpi/yHirJd2SMvjre8Q741rdg0yYFeCvwXkCK1DPBmYhNmVGVSCSSyWRgh/g3dOGUTqOuqI6wN0wkEaEqINacHokfAaDSWYLS2wu6AR3tkNOJlPkIL72c+nffBrom1mLW1x/NIGZiGfqa+tDTOobNoLeol8ZUI7sju9nVs4tt5cuwLr0dsgaGbeTDSmHEoEI1LFRNOboWSDEtLFVhSIe+xj4aljWw4fUb2PSLTWzeuZkWZwt6iY5tlo2wP8zq2atZNWfV5IhUXYc77oAjR4RxVFmZEKOhkCjvtdtPO6MskUgkkvwhmzU4dCjKyy8fa2qoArMBeTufLkihKpFIJJOFqcPgcIuT4KIpnUrAGWDlrJX8ZPtPKPeVo6oq0f4OZvakmdPaCdl2MEVJq6FYRKuKWF26HP9lV43ZT7Q9yjO/fYbGvzQy2DVIIpUgZaVI+9P0zuslsjBCOpRGK06iWBaKZkNVDLDE2lQLBcW0UBRQjlm/YqkKWCbORA49rYMBlT+oZO1v17JGW0PjjY2kb07jcrqoL6p/7WtSjx7YgrvvhmefFWL8f/5HiPFNm0Sf1JYWIWRtNiFaV68WmVT5V41EIpFMC9JpnZtueoBnnmnHsm4BwgAUF4tb+bvfDRdO7bNkyQSRQlUikUgmi3gTmBnRV9U7Y6pnw/Vzr+fx1sdp6m8inHVQdyCKL23iCKoQ8EIsjqFAUyHU9uis+unTDBRsZUexzu7IbvY9t4/cz3M4I05ynhwZfwbLZ6EYCv6kn4aXGri8/3KWfnopwYsbWJHNkgm4cEUTAFjacDZVAUVTx7j/p70uHMksS3b0YVtpg9sQa1IV8H/Cz7L3LDu+W8Dk8Mtfwu9/L8p877prtBXN2rWwZo1oU5NOn5BRlkgkEkn+MzSU5a1v/RV//WvL8MivgI8BGrfdBv/2b1M3N8npI4XqBFBVlYULF0qnNUneImM0TxgYXp9asBCUqf9dVAYqWbdiHesfuZPdux7Bp+awBQvA6yFrmnTr/fQWG5Th5/ruIAN7/s6OfY/xnbdXEifA/N/Px9XvIlmZJOQJUe2uptBdSMgVwm1zY5om/Y39tH+1nf5wP6UfKqP90qVYloKiWaAqKAqoyhgvX0xAd9iZ98whakw7Rd8sgjbABdwFXH2GLsjjj492fP/kJ+Hq4w7k98OyZWfo4JJ8Rt5DJfmOjNFXZnAwzapVv+Cppw4D4PM5GBp6C6Cd+o2SSUG6/k4h2WwWl+yfJ8ljZIzmASNGSlO8PvVYGsINbIhfyo/3/IWHZ2p0unIcNjuwshl8qs7STpWLkgrOTJT9xSqzjqRZ3eKk2/8G3Fk35ZeWE/AETugzZ+om0UNRom1RUn0p3EVubvQk+XFDHcnSAJ6B+NGMqAJgcbRVTaLQjyeW4I33NTL7wGycHicUA98E5p+hC9HYKB6lWxa8/e1w881n6ECS6Yq8h0ryHRmjJ6e3N8kb3/hzXnxReDEEgy4efvhmli+vwrKmeHKSV40UqhPANE0aGxtZuHAhmiafykjyDxmjeUJ02EhpAutTY5kYTX1NpPU0LpuLuqI6As7ApE0lkoiwK7KLppbnWfyz73NxX5rCqMJQSENXLexxk8qYSsgVorCwgsKCQkLuQkKBBPO6g/yxey7ZCpOAd+yccokcAwcHiB6KYurCNElzaXiKPHzpczdSk+zly6ZGoqgANZvFkUxjGRaGopD1u9AddjyxBGvuepZLHtWYUz4H5gL3AKWTdvrHXYwI/Mu/QCoFl1wCn/nM+A6/kvMWeQ+V5DsyRk9OV9cQK1f+lN27Rfu14mIPmze/j8WLy6Z4ZucX0vVXIpFI8pVUN6S7ARUKFpx0s45YBxv3b2RL8xYiiQi6qWNTbYS9YVbOWsn1c68/bWfbZC7Jnp49woE3sotdPbvoSYgP7PmHEiyORIgUKAQsBwsHPBT2JgilfRTa/bgvfvNY0WYLEHm5lwS9BBdVjznOwMEBul/uFtlRwOFzUDi3EF+Zj8G2QVL9KT69bC7VOw/whT2ddCyoIhPwkRk2TnIks8x7+hBv/P8auWSrxoqyFQSuCcB6wHNapzxxUim4/XYhVmfOFK12bPKjTyKRSM4FDh8e5PWv/yn79/cDUF7u409/ej9btpTw4x8js6nTHPlpLZFIJJPBSNlvoA5s46uu3ZHdrN+6nuaBZkKuELXBWuyqnZyZI5KIcN/2+3i89XHWrVhHQ3j8vqWGaXBw4KAQpJFd7O7ZTfNAM9Zxn8aqojKncA7X5Xz4lSO4VYXFPU7mxnKAA3w+WLrsxMyi3Y6eszAxUO3HuPQaFj27e8ACT4lHCNRSHyhgWRambgr3XuCdC+dwX2GMmZv3Udg3RE4HdSDJJbsHmdHsYHZ8NnMq5xB4bwA+xZlbPmSacOedsG8fBIOimZ40R5JIJJJzgqGhLK973U84dCgKwIwZBTz66Pu5++5C7r13aucmmRykUJ0gssxCku/IGJ1iRoTqScp+O2IdrN+6nrbBNhYUL0BTR39fDs1BVaCKcl85Tf1NrN+6ng0rN1Dhr6A70S0E6XC2dG/vXtJ6+oT9l/nKuCB8AQ0lDVwQvoB5xfNw5ywSX/sy+9JDOBNQnnALgTpvHlRXj1/+msthsyuoaJg5E80h5hnviGPqJnaPnZoVNWMcec2ciWpTsbnER0oLEKkM4PzAJfwunmFgT4Tm7c3MblpMib0EZ6lTCNR3vaorPXG++134+99FX9Svf122mJGcEnkPleQ7MkbH4vM5+PjHL+FTn3qEuXML2bLl/dTUFPDcc+NvX3qmlpdIzhhSqE4ATdNYuHDhVE9DIjkpMkbzgIGR9anjGylt3L+R5oHmE0TqsZiYhNwhnml/hlv+cAuqqtKX7DthO6/De1SQjojTIs8xTc2TSfjlb+CnP+UZpQXTDZUpG74ll5xcoI4QiVBU48dLMYlIgkCVWKMabY0CUDCj4IS2MYlIAm/YS1G9mMPzw+MXAj6/E191NdX/VQ2tgA9R6rvi5FOYFP7v/+CnPxXff/GLsmme5JTIe6gk35ExOj633345Xq+dt751HmVlvhNedzqhqAiuukr0T5WcOc7EgxQpVCeAZVnE43H8fv8JzpcSST4gY3SKMdIQbxTfh07MqMYyMbY0byHkCo0RqbFsjL5kH/2pfvpT/cSzcQCyRpa+VB8zC2bisDmYWzh3jDCdEZyBOl77m1QKfiMEKtEoAH+92IY7UMiHmrwio3iq+DAMiEZx3rKaWVYd23+yHV+5DyNjkOxJAsNC9RhMwyQdTTN/9XycficALwy/tgzgZbA+ZWH2mqjlKso9CtS94hV9bWzbBl/7mvj+Ix+BN73pDB9QMt2R91BJviNjVDA4mKagYKzz8T/908nbit14o/hYlJx5jl+CNBlIoToBTNOkublZOq1J8hYZo1NELgaxJuH2m4uBuwpcoy6DI86+27u2c7D/IPNLRO8VC4s9PXto7Gs8YZceu4dyXzk5M8e/XvGvvGP+O3DanKeeRyoFv/2tEKgDA8RsBk1zAwy95U38OfZbCgdsfIyZ0NQEdXUwXowYhni9thZWrWIuflofb6W/qR/LFB8+nhIPdo/96FtMwyS+J05tQS31xfXwPFh18MKwUfBVjwD/DmRhsHyQgh8VoJWf4fhsaRGuvoYhBOratWf2eJJzAnkPleQ751OM9vRAe/uJ488/f4hPf/rX/Md/vI3Xve7kTzyTyTM4OclJka6/EolEkg8kO6BzI3RtgXRE/JzuEvaCB3/IEf9FPNT+4lFn3/5UP62DrQykBqgIVDCQGiCSjAAQ9oQpdBcScocodBfi1JxYlsWe3j3UFNScWqQeJ1A7XFk2XqiyZZGPSACig7/m4MBBPDYPD3zgJm743U4q9+yBUAjCYbF2M5cTjrjRqBCp69ZBZSUBYMW6FWz96lb2P7wfy7AIVAaEcVLOxGwzKTlUwlJ9KeFcGMfXHWCDRBiuXgmBONT+UkzTWmFx+F2HKQgXnPxcJoOBAbjtNhgagkWL4AtfkG1oJBKJZBrxv/8LH/0oZLPHv3IA+DWgc9ttDwC3AFVneXaSs40UqhKJRHI6RHfD7vWQaAZHCHy1kO4D1QGam0Tj9zkYH+SxZAEJZyW1wVpCrhCRRIS0keaFIy9gWRZeu5dLKi+hpqBG7DeXhYFB0A1yqokNcNlO0tg9nR4VqP3Ckn/3bD/rr7Bo9mYIuQqo9YbZ27sXh+Yg4Arw054tPHFdKesufSMNf98tMo+6Llq1hMOwejWsWjXGcCjcEGbhexfSurUVPamjZ3R69/RSmClkaWQpRbYinHOc2GvsYAdyEO+GD38ZfElQy4APg/XPFtbuSSwJam+Hv/5VCFKfD669VpzDpz8NHR1QUSHMkxyOyTumRCKRSM4o3/kOfOIT472yF/gtMJKxmwVMrEeq8xUKkiT5jRSqE8TlOskfjBJJniBj9CyQ7BAiNdkmeqUqmsii5vpBUUm4KtkW2Ueh3s8/ezX+4AoRVR0EXUEcmoOeZA+WZQmh6vAKA6RkAtraoL1DZEgtk4grR9juoT73FNxYPioe02n43e/gvvuOClQqK+l432rWs5m2eDsLChvQVA0Li+5EN6qiUl9UT5m3TDgKl+1nwz1fprIzLvbnckF9/UnbtnQ824G3xMucVXOY95Z5WIctQveGcNldqAvUE1rLqC3gSIEjCxQB7wTUSYrP55+He+6Bxx6DeFy0n1FVMfdgUAjv0lLRhiYUeu3Hk5xXyHuoJN85l2P0a18TBT0n8jLwB4428GYB8HYm0tdMUWDNmkmaoGRKkEJ1Amiaxrx586Z6GhLJSZExepbo3CgyqSMiFUBPgJkFRaUtNchgNo7mLKPCGqRBb+NJx3yi6SjRdBTd0HHanJR6S0nkErQd2cf8g4MQi4nHvgE/hqoQ1fpZ3RnE/7Nfw9ZtcPvtsHfvWIFaUQEf/jCsWsXGHT+mefuhMY7CQ9khhrJDqIpKqbcUTdWoK6xjb+9eNnU9ztplr7x2M5fM0bylGYCGmxooXVQKLwKDiL8Vjv07YQisp8A5BDk7JJeDow/YBNraSYjPBx8UZb29veB2Q0mJWGtrGNDVBZ2dIjv8wQ+KEmaJ5DSQ91BJvnOuxqhliXbXX/nK2PFPfQpyuRf4znf+xIhHz8qVF3LbbW9B08YxExyHefNg5szJna/k5EjX3ynCNE0GBgYIhUKo6sT+c0gkZxMZo2eBXEysSXWERkUqQEa0j8naCmiPd+LUnKCqJE0HC4wOfhe18XTXLmyqDY/dg9vmxq7ZceQ0OjobmZPwYA+FQFEwsGiyDVJrFLDKcyHU2eHpp+H664UwczjGCFRstpM6Ch8ZOgJAiacEmypu9ZqqEXQF2XxwM2sa1uB3jp9FHaF5SzN6Wic4I0h4YRhiwBYgxFiR2gc8LfR6ygO7LodrCwAD2AzmO00G9NcQn88/L0Rqf784/2P3kcmMljBrGnz/+3DNNbDs5C6QEsnxyHuoJN85F2PUssRz2HvuGTv+1a+Cx/MMt932l6Njt966jO9+dxWqKn0H8pUzYaZ0bkT6GcayLA4fPnxGbJclkslAxuhZINYkjJNc4bHjWSFUBxU3qVwKt90NQFxx4chFSfS9iIVFbbCWlbNW4nf6GUgPYKaSJMw0A0EXWcWkXU2w1xalxvCxbnARlU1HYMsWkUGMx0UN0513wu9/D295ixBmQFNfE5FEhLB37LyOxIVQLfONXccT9oaJJCLjOg4fT+MfxTZ1N9aJdghNQAQYOZSFGHsCyEIyBC9cDa6CYR0bFttb+15jfN5zj7gOZWUnitSeHvF9MCh6xPb1wbe//eqOIzlvkfdQSb5zrsWoZcHHPnaiSP3Wt8Bme3KMSP3Upy7ne9+TIjXfke1pJBKJZKow0mDqoIy2Z8E0ICUEoW7zY1ndqMPP/wxUsnoSl+JkTuEcFoYXoqBwaeWltPW30N6/nbgNDlpDFJo5woab1YkZrGqyqNy1TawfBfB6Re1Sba0wDbKNvW2n9TS6qWNXR+fVk+yhLyUEdLm/fMz2dtWObuqk9fQpT3fw8CBd27tQVIW5q+YOHwzQEcZJQ4iGqX3Db6iEfcsgq0Hx0YMNb58GXq2hRXu7WJPqdo8VqboO3d3ie48HCgvF9y4X/O1vohS4ouJVHlQikUgkZ5Jt2+AHPxj9WVHghz+ED30I/vznUux2lVzO5ItfvIovfvGq87p37PmMFKoSiUQyETQXqDawcqAMu8kmD4OZAc2NzVmMojRjYqKiYhgZMqZOFjfziuahID5kvQ4v822l1PR72RtycWuqgcV6MfV6Af5tO+DwYbFvj0cssKmpEaKspQUaG08oaXXZXNhUGzkzh0NzYFgGL3W9BMCs4Cw8Ns+Y7XNmDptqG9dROBPL0NfUh57WaXyoEdMwmbF8Bt6wd/hgiE+N/QgTRgOyLhhcAnoZtCvCk7Hk6MGGt38t/h9//avIKJeUjI6ZpigD1nXRYqeoaPS1ggKRZd2yBd7//tdwYIlEIpGcCSIR2LFj7Ni99wqRCvCmN83h17++iYMHB/j0p5ef/QlK8gYpVCeI/ySOmBJJviBj9AwTqBNlv+kIeKpE3VJ8v3jNN4cCdwi3XZT/eh1e7LkBegyVhKsKh3ZcmxTdYMCWY7YZ4l3p2fgth2gaN9LhfPFikUUdySDa7UKUpU/MgtYV1R0t560KVLGvdx9D2SFcNhcN4YYTth8pE64vqj86FuuIsX/jfpq3NJOIJDB1k569PWCCcpVCrCNGoDIg1qa2Az2QCEDbAmivhZRNJE6jiJLfbsANeEfKhOvB3/cq43NoSAhTTRPXYGgIEgnhkGwYYpuuLpF59vnEdqYptpNITgN5D5XkO9M5Rk0THnpIrD/dtu34Vy2uuGJsxvRtb5t/1uYmyV/kGtUJoGkas2fPPiNuVhLJZCBj9CxgD0DZSsgOgGVAuhv0OCg28M3EoTmo8leSMTJYpoHTTPL3jJ1wcPYJuzI0hajD5LpkuRCpAEeOCPFbUACzZo0tc83lRMnvOK0JAs4AK2etZCA9QH+qn6a+JgAWly0eUw4MYJgG0XSU62Zfd9RIKbI7wpY7trD9J9vJJrIEa4O4i9wiA6yJ9jRbPrOFyA8i8CEgBwkHbFsOjXNAt0EAcCA+UEYSrtsMSESB60ALvob49PnEtUilxGP4aFT8xWOziVqxEWE6OCheT6XE9j7f6R9Lct4i76GSfGe6xqiuw/33w6JFol33iSLVAP6PH/9469mfnGRSOROxKYXqBDBNk66urjPiZiWRTAYyRs8SFdeDd5YwVooNmxH5amFYENYU1FDg8ONNt3Mop/CUUUCJp2TMLgzToMmMUGsFWXX4GOE5kk0d6Zl6LJEIhMOi3+k4XD/3empDtTze+jimZVLhq6DCN3Z9pmEaNPU3URuqZdWcVYDIpG5dv5XBtkGKFxQTqAqgOTRibTEUVaFwdiHFc4oZfGyQrZ/fSqw/xpHr4KVrofAIFJrgRXyQpAEF8AOFBhQ2wUu1cGTVa4zPa68VZdDd3UKwO50iwwxCqIL42eEQr3d3i+1Xrjz9Y0nOW+Q9VJLvTLcYtSz48Y/Fx9Z73wu7d4+3lQ78FtjJf/3Xo3znO8+e3UlKJhXp+jtFWJZFV1fXOeO0Jjn3kDF6lvBUQsM6sBdAsh3MHHhmiE9kM4tXH+ASv492Q+PuqEbaXkTOyGFZFlkjS3usnb29e6kpnMW6Of9IZWS4fDWbFWIUThSqhiGyiNddBycp+6oMVHJR2UXopk7OyBH2hska2ROPW1DDuhXrqAyIY+zfuJ+B5gEK6wpRh/vSmTmTeGccgEJPIerfVArThQxkBziw5AAP3Qs/+AIka6ByDwTbQctC2gJbFiraoWKveP2/18GfKl9jfFZVCTffXE4I0pMZaiiKeD2XgxkzpJGS5LSQ91BJvjPdYvTuu8Wa0+bmseNOJ9x6K/zv/+ZYtOhXwD4AHA6NmTODZ32ekslDuv5KJBLJVBNsEFnU6Mtg80L6iDBVUm3gCpOueTffPfwTeuwpLgzW0hJtQTd1bKqNsDfM6vmrWTVnFZVx4OkD0NQkSnotCwKBsWLUMMTrtbWib+pJ6B7q5sHGB6kMVLK8ejn9qf6TH3dYpGZiGZq3NOMKuY6KVIBYewwMKDPKcOwSZclqgYqr2sVOWnnEuJBUg8YfNkDDJliwGUItoOlg2MAKw1OrYfcqGKiEzcA/vJbrHYuJa+JwiLLe491/RzBN8brTKdarxuMnFfYSiUQiObP85S9jf/Z6hUC9/Xbw+TLccMMvefnlVgA8HjsPPriGlStnTcFMJfmMFKoSiUTySuRiotzXSIM+BD1PgqsELrkXLFOMay4I1HP/i/9LVPWyet4b+fI1X6axr5G0nsZlc1FfVH90bSgBYN06WL8eHn1UZFXLyoRgzeVG12PW1ortxisJRjzB3PDkBpK5JMsqlvH9679PIps4+XGH6WvqIxFJEKwNigET+pv7GdoxRGWsEpfLJdrLzAXmg9fw8pJDoyOlM8+uEa2EJ9fC82tAb4S2NLhdUF4PmeFDhYEWoJGTdKdpbxeuvkNDYk3ptdeKDOqxNDWJRU6XXw7PPQfJ5PB8TXGtLEuYTOm6EPwXXyy+H8chWSKRSCRnhxGvO4ALLxS3+sJCGBhIsXLl/Wzb1gGA3+9g06abWbGiZopmKslnpFCdAIqiUFhYKHs4SfIWGaNniGQHdG6Eri3C7dfURQY10w/BC8FVKsqBh9FNnT81/QmA1fNW43f6WVZxCrHU0ACf/zw89ZQQW4YBe/YIo6BwWDhPrFp1UpEK8LdDf+Px1sexqTY+/7rPoyrqKx8X0NM6pm6i2lWSkSTd27vxRryEs2FUTcUWssHFwHDnF1VVyWoqumUxYtFkAfv8sGOZaEvTABQec4yRNqoZRaH82Ph8/nnR5f2xx0Tm0zRFltTvh6uugttuGxWZIyK0rAzKy6G1VQh5yxLlvoYhsq1VVbBwIRQXi2s4jkOyRHIy5D1Uku9Mpxjdvx/27h39uaxMiNRIJMEb3vAzduwQPbBDIRd/+ct7ufjik3/GSaYPZyI2pVCdAKqqUlMjn/RI8hcZo2eA6G7YvR4SzeAIiXJfi+GWNCZk++ClO8Sa1aBoA7O1bSv9qX4K3YWsqFkxsePs3y8+wRcvhs99Tggsl0s4ULxC6Wo8E+fuJ+8G4JbFtzArNPGyKZvLhmVYHH7qMEaHQXGyGIflwOaxoc3T4ALGfEKYOROHomBTFHIIg4MXEd1qAMqA4/2NR9qoeo6NzwcfFEK0t1eU8ZaUCOdewxDOvX/8Izz5pBCyN9wgmu0dPCj+6lFVUR4dDIoMrMcjRGplpagrA5GZPolDskRyMuQ9VJLvTJcY3b1beNn19IyO1dZCR0eMlSt/xr59vQCEw142b34fixaVTtFMJZONOt6ynNeIFKoTwDRN2tvbqaqqOiO/BInktSJjdJJJdgiRmmyDggWgDFuux5oAE5zFUHSJEK2718OSDeCp5A/7/gDAjXU3YlMneHvdskX8++Y3n3ap6ne3fZfeZC81BTV8cMkHJ/w+Pa3TurWVvqY+PEkP5Xo5NqcNLaihLFNgnL8bEpEEs4o9VLpttACtwBDC6bcBUSF8/LPUkTaqc02TtvZ2qrq7UW+7Dfr7hdnRsbFqs0FRkciuHjkCH/6wEOuJxGh2dOZMmDtXtPA5Ga/gkCyRjIe8h0rynekQowcPiqKYvr7RsQsugP/4D+jvz9LfnwKgstLPo4++n/r64imaqeRMIF1/pwjLsujv7582TmuS8w8Zo5NM50aRSQ3UjYpUy4ShA+J731xQbWS9M4kPvMz+Xd/mkYOP8ETrEwC8dd5bJ3aceByeHbbjP812Ktu7tvO7vb8D4POv+zwOzfGK77Esi5a/tvDATQ/Q9j9tLEwtxK7bsfvs2OptKG8YX6Sahkk6muaCFTMI2zVeAOKAG3gdUMeJItUAosB1gG84PvnWt0QmtaxsfEMkXRfrcnM5IWb37BHiddUqIVCXLDm1SJ2AQ7JEMh7yHirJd6ZDjP7oR2NF6tKl8Pe/i8KZ+vpiNm9+H8uWVfDEE/8oReo5iHT9lUgkkjNNLibWpDpCoyIVRDuaYdOkhL2Qtp69tMc78OaipAZ+xGejv6cl2csFJRegKRNsev3YY0KczZ4taqMmSNbI8pUnvgKItbAXlV/0iu8ZaB7gqf96is5nO6nrq6NhsAHKIJVKMVAyQOGSwjHuvyOYhkl/Uz+B2hAPrprDVsAx/HUV4BnnWAbQBNQCI17Ftu5ulMceG9+1N50W7r4jRkkgMqyqCv/zP6LtzB13CGOlujpRKnzCQSfmkCyRSCSSM0MiMfp9ICB8Ao99trhoUSnbtn14WqyzleQHMqMqkUgkxxJrEsZJrvDomGUNr02FfkcZz3Y+R2NfI7qRw3AUUmW3U04M0zLpS/Vxx5Y72B0Zt7v5WEbKfk8zm3rf9vs43HmYmiM1vEN/B53Pd5KJZcbdNhPP8PQ3nua3a35LdGuUqw5fxTJrGUWziih+ezErfreCgkUF9O7pJdnShb+zkdCR3fg7G0m2dNG7txe1poA/rFvBpsoALuB24BrgIGKNahaxfDc7/PNeoAZYB4xYZPi2bRttGZNOi8xndze0tUFX16hIdbtFxrWmRoj4xx8Xa1DXrRNje/YIt+BsVvxeslnx89694vVTOCRLJBKJ5Oxgs3Wybt1GDGNsOagUqZLTQWZUJ4CiKJSVlcn/XJK8RcboJGKkhbuvYh8d0xOQGyRhwvZYP0O5JCFXCEVRsCwLw8iimAZeu5dLKy/l4MBB1m9dz4aVG472LT2BeByeeUZ8fxpCdffu3TzyrUdYtGcR87X5PL35aVSbijfsZdbKWcy9fi6BygCWadH4UCPPffc5Uv0pZg3MYmlmKYHyAFpQg88AqyCshLnOsYD+b/0c9e9/xRbvRzUNTFVjtr+Q1quv5dufvILmhjAlwFeBJUAHsAnRJ7UF4e5rQ6xJXS12TaVpQmsryo4dlD3xhHjcnkqdmFFVFGGOFAiI7CkIEWqaonUNCIfkDRtg0ybYvBlaWoSQPQ2HZInkZMh7qCTfmV4x2sbAwC/4wQ8yZDI6P/zhW1DV6TBvyWtBuv5OEaqqUlZWNtXTkEhOiozRSURzgWoDKwfK8LrPrFh002ZoxLJDR0UqgIZJUs+QtmxUB6pxaA7qCuvY27uXTQc2sfaitWP3H4uJEtVHHxUut/PmTbjst2tXF/f9831UHK7AV+Sjdn4tqkPFzJkkIgm237ed1sdbWXDTAvb+fi89e3pw59xcG7+WGmcNjkIHXAJ8kdG1qLt3479nPf7mZoyGAtL2akxFw7IMjuRi+Jv/xi33HOKldev4fw0NhIbfVgmsBdYg+qSmAdfQEPW7d+PfsQN27oRduyAeRwVcvb2jbWhsNnA6xZfLJZx7j8cwxLY+3+hYZSWsXQtr1og+qafhkCyRnAp5D5XkO/kWo1u2wP/+r3j2OMKOHQDNwK+wrBwABw4MkE7reDz28XYjOYeQrr9ThGEYHDp0iJkzZ6KNtzZKIpliZIxOIoE6UfabjoCnSoxl+smaFu1ZHafmGfPU0GcmOZTVOaA7uTQ4EwBN1Qi6gmw+uJk1DWvwO/3Q0QEbN4pP90hEiNV4XLRVufdeuP76U2YDYx0xfr3u16Q6UqQr0yyfsxzNLn7XmkMjUBXAXeim7fE29j+8n0BFgLnmXC4zL8Mb8qK4FPgkcBOjiz46OmD9elF+u2ABmqbhBWLAs0CcIIphcHlTE29evx5lw4bROZomNDfj37mTZTt3CmHa0nLixJ1OzAULiHq9hO6/H8WyhLPGKzE4KMTneNlmv/+0HZIlklMh76GSfCefYjQaFQUsudzxrzQBDyCcCuANb5jN//3fu6RIPU8wDGPS9ymF6gSJx+NTPQWJ5JTIGJ0k7AEoWwnNPwF3uTBUyvYxaBikLJWA3X10U8Wy0PQ4f8vYsDsLCbqCR18Le8O0RFto7Gtk2YBbCMLmZgiFoLparLV0OITouu8+sRZz3TpR4joOL/3fS7TubcUoNrjGfg1VfVUYmkGiIIFu0+lv7qd3Ty9GzsBKW8xNzOWawDVoNg0WAf+OWDh6LBs3ijktWHDUoKgVeAkwARdwsaZRUlcnhOi3vy1axIxkS481PxqhuhoWLhz9mjMHS1Fo27mTYG8vyoMPjmZWT4Zpimzpm94k2thIJGcBeQ+V5Dv5EqPNzeOJ1N3A7xGfHhAM1vPHP96E0ymlhuTVI6NHIpFIjqfieuh+XBgr+WohF0PHwkJDHU5HKpZF2IyyK5Pj0bSL2vDY8l27akc3ddJHDsM3f3c0a4mmie8tC4JB4WI74li7fr1Yh3lcZjUTy/Dsz59laWopDYcaqFKqUCwFS7VIKkmaMk0kzSSmZhJyhXAbbgYGBtCLdLSPafB+TrTOi8VEdjcUAk1DB3YghCqWxYzBQRb29+Po7xetYvr7xRxnzhx13fV4hLAeEaUXXCD2dzzDT1mtT3wCnnxSmCedrEWNaYrXi4rgE584vd+bRCKRSM46paU76O5+EGGrBxUVF/DHP67G6ZTVCZLXhhSqEolEcjyeSmhYB7vXQ/+LYGaxqy4UVUWxdAqsDB4ry4GswTdjToZsBcwomDFmFzkzh0214Xr6uROylrS3i39HBKmmCcG6d68wC1or1rVmYhn6mvrY/ovtXLvzWoJqEFeBi6QniamYpHvT2ON25lnzqLRV0lbcRjadxVANorYofev6qHj7STKSTU2iBLm29mipbzKXo37XLmoPH8at62N7o460i7n4YpHpXLhQtNU5nTUpS5fCPffAbbdBZ6dw+C0oEOdvGKLcN50WIvWee2R5r0QikeQ9z9HdvenoTx/84GLuvfdGtHHanUkkp4sUqhNAURSqq6unidOa5HxExugZINgASzbAS3dAsp2g3clcPUlO7ydrD/IMZXy35yBHTBvLqxahKmM/lCOJCGFniPo/7z2atQREvVQkIr4/NnOqaSLDunkzsdddz/7HjtC8pRm9Tad+Zz2hVIgB1wCGYWAzbKT6UhgZg4yWQXfplCRL8Ef87PXtJTUvhYmJHtZPfn7pNOg6bXY7LwEF3d1c/uKLhFIp7CDcd0MhIRoLC8XcDhyA978fVqw4rUs5Jj7f+lZx3t/+Nvztb9DTM1oK7PcLEfyJT0iRKjmryHuoJN/JhxjVdWFW/9xzIyMGYrGI4OMfv4R77nmTdPg9T5Guv1OEqqoUFRVN9TQkkpMiY/QM4akERwB8M7HVrKGpv48H9/8Zt3cxW9ueJzVoMtdZQFlaA2cW7MK91jANoukoq0PX4O/aKlx9h1u10Ngovg8ExNexhMNEdnWz9baNDAyquEIuChIFFFBAr60Xh+IgHU1j9pooqoKqqfidftS0SkJJ4MdPycwSDtUdItPtZHehmzbEWtM64NijZVwujths7E4mmbtvH9WtrXgB1euFJUuE4dGxHzrZrMiqulynfRlPiM9ly+CnPxVZ1S1bRAsan08YJ8k1qZIpQN5DJflOPsToLbfA/fcfO6IBN1NTcx/veU8dX/3q6+XDnvMY6fo7RRiGwf79+5k7d+6UO61JJOMhY/QMYZkQ3SUMlarfzrJqD79pPcDLL/+VikMR3FkodNqg9RlRxlpViVFdSVOqg9pQLasCSyH3N+Gu29g4aj7kcsGFF55wuFjWydZD1QxmExRfXEtyKEm4K8yQYwi7agcDTN3ENExUS8Wn+VDTwx8MBZBz5ChIlLF5fpaX1pZjqyvEZLS/6UrgeiAH/HtdHR9TFJb/5S+4EGJWmTNHrDkdL4YiEdGvtL7+tC/jSeOzokJkaCWSKUbeQyX5zlTHqGnCr3893itefvjDD/GGNzjP9pQkeYZ0/Z1C0un0VE9BIjklMkbPAPEDYCRB84B/NpV79vKZR9P8mxWhxW9QFAhQ4AihmpBLJ4kc2km0by+19Zex7vJ/pfL+zbBvn9iXqgqBWlcnMqzj/KGxv8XOQNZOcW0ARVXobOlkSXYJyUASV9JFKppCQcGm2MCEXC6H5tKgGHBBv9MgrRTSUWNHq9SYbdOwI4RpBLgP+CWQHRrilv/6L6qbmwmkUmjFxSLLebKn9YYh+hGsXv2q+5XK+JTkOzJGJfnOVMTo4CB84xtw+DDougU8BSxFPN6ESy6Bq66SIlVyZpBCVSKRSE5G9GViukGTVkr6xQdxff9eCnbv561+Ly+XQmd1kBZtCB0Tm0MlbIRY3aKx6oUeKn/xaejtFY+hNQ0WLTqpQAXIZBWaWxRcHgW1MEhT/36y6Sw2bHhMD+lEGgUF1VLRFA1TMcmqWZxlThSbQtqpsX9GgIo2hZmRDKHiYhzD+3YA5UAX0ByNsuiFF1j03HMUh0JoJSVCQAeD41+DEUfi2lrROE8ikUgk5w0f/zj87Gcg2s78EeEP38jHPvZebrvNwezZY1eJSCSTiRSqEolEMg4dsQ42vvQTtrQdImJLoA+8hOrtxlyWY2G/jX9UL2b+4EwabYOkFQOXoVB/aAj/ribo3yWyk/X1wul2165TilSAvn6FRFIh2FBKwsqyt2cv1VRjt+yk+lLYLBtOxUmaNAYGikPBVEx0XUdTNY54XWQUFbtpUtBQSMrrOLrvOPBCJkP5jh1c0dFB26xZvPyWt3DplVeKvzDWrxd9XUMhUd5rt4+aPkWjYu7r1p3QNkcikUgk5zbbt4MwTfo9sGd4tB2P5zBz5syeqmlJzhOkUJ0Aqqoya9asM7JIWCKZDGSMTi67I7tZv3U9za1PEVJNav2zsO9rojep0Oo2eaLSIGZr53NDxSzLFImaqH37IJEQO3C5RJ/Q+++HbJbM7evoe+EIeuUMbA6VogIdp8MaPaBhoB/qxHQ0oNZW83zr86SH0vQn+kllUgT0AKZqotpVNJtGzpMjm8pipA0ysQx4HURLvFTGbGTmaAxcMiqIDwOHOzpY8NJLOLNZPEBJIMDmj3yENZqGH0Tv1k2bYPNmaGkR1o42mxCtq1eLTOprEKkyPiX5joxRSb5zpmM0mYQPfUj425nm6PjAgA78BmgamQnXXXcTX/6yFKmSsUgzpSlCURQCx7tzSiR5hIzRyaMj1sH6retpGzjIAqcosyXjIJeIkyRLUUaj1F5OqzbEeuVJNjypUtmTEW92OsUa1KoqaGsj9lwj+9vdNA9eRaKzCfNgBtWu4fV7mFWdZW75EIHEEYhG0crnkcuU8sKL++iwdaCiUhovZVAdJKyEiWtx8INWqKEpGnbdTjqapmRBCalSH5rPSUmPytNvgoxfPP/enU7j3LGD+R0d2ABPIIC2dCnhUIgWoBFYBkKErl0La9YI06d0Wojt+vpXvSb1WGR8SvIdGaOSfOdMx+jvfge/+tXxo1ng10AzAJpm46GH3smb3zz3jM1DMn2R7WmmCMMw2LNnDwsWLJBugJK8RMboayQWE+sw02k2Rh6muXc/CwqK0bIK2AJYJiQyQ5gu8Dt8eNI56rri7A1k2FTsZG0sOGqSZLOBZRGJOdl6zy4Ghuy4Qi6CV1+I2tmO2d5BIpZl+w4brU12li8KYlxwCdsOFtPbE+WI/wiKX2GuNZcGpYGYO0aSJF63l0RhAoY/B4yMgTPgpHB2IRFVo7oJ+mph9ypIWRb729sp27EDezYrXH3r61HmzQNNGCzpwAm2HH7/GelfKuNTku/IGJXkO2c6Rkfae4+SBn6BqMsBsHPrre/hzW+eOenHlpwbSNffKeRMXHyJZDKRMfoq6OiAjRtFrVMkQsxKs+WCZkIuDS3QCwETioroHOjGYelohkqoPwW5ITQgmNXYvNDDmrpr8Wvuo7uNRU22dsxi0MpSvLQcVRsuhwnOR5s7h0B0EFc8RefeQe7foeLpDqA5NA7UH8Db7iXsDHNR20UolkI6lGb/5fuZ2zQX/4CfnDNH2pXGyBiEqkJo3Rq+KOyshcfWQUtRmoFnt1Pd2YkCOAsKcC9dOsYsKYe4+Z9+R9RXj4xPSb4jY1SS75y9GE1SWno/3d2dADidTj796Zv5j/+oPkvHl0gEUqhKJJLzk927hYlQczOxIh9N9X62u00Oegzmx23Q3Akui955MV6MdbJEMSgastAsFTQVCgoI+320OIZojA2xLDcqVPfv1RnQCyleVDEqUodJxXX6WzLEOxJYpoae1vFqCt6Pe2lqb2LBrxYw/8B8LJuFMkOBxTBkG2JvaC8lbSWUtJfg6HbgdXoJWkHwgm01/O7NFjvtEco2byOUy6EqCq5583DW1Z1g4hRB9FU9/Y6oEolEIjn3eeqoSC0u9vDII+9lyZLyKZ6T5HxEClWJRHL+0dEB69fT0b2fjRfb2eI6QERL06+kadWGGCjIUmXXqeo3yL7UhFaqojtseJJAURACBaAq2LHQMUkro0+5MymT5iNuXBWFqK7R3nKJ7gS9e3tJ9aeOjnnDXpwFTnyVPn4V/RWZwQx1FXWUd5XTW9SLq8yF1/SiWioJe4KIP4IRNqiqr2LJe5Zgm2+DerCleyj6299I1tej6jpGQQH+pUuxjdNyxgCiwGrgta8+lUgkEsm5xzW8+c0Rtm8/wpYt72fBgpKpnpDkPEUK1Qmgqir19fXSDVCSt8gYPU02bmR39y7WLxmi2RYnZDqp1X2EVAcRLUXWyNDo0jkchrldsKTfQdmcxSjd3cIacXidaA4TGyouazhjaRj07TxCQruA4IIaMWZBX1MfPbt7AFBUhUB1gMI5hTgLnBgZg11P7iLuiFMWLONjvo+h/17nwL4DtG7aifbyS6i5LIrdgadmFjM+tJA5q+YQqAyAZRHbuJHOr3+d61wuXv7kJ9l/+eUsC4exjRMLBsK3sRY4mx1RZXxK8h0Zo5J850zGqGWJDmWjaPzqV++kv3+ImTODk348ybmJdP2dQhwOxytvJJFMITJGJ0gsRsffH2L9vB7abCYL9BDasPIMxnO4XTnSNoOABVENDoRtLNeLUernQWUVbH8JBgbA6STiMwkbLuqTHuhuh2gUvWQ+plKNWuADC7p2dBFtjor9zwpSPK8Ym2v41puD2EsxehI9aLrGZ4OfxfOfHoh2cNHe57mQR9DpwEJHwYaNSjQrA5RCJE3fXXfR99RTmEC2upr3L1jAH8vK2AuEEOW9dnEYIohMai2wDjjbHVFlfEryHRmjknznTMSoZcEtt/Tw05+qQBEAPh/4fDYCgeCkH08iOR2kUJ0Apmmyc+dOFi5cKN0AJXmJjNHToKmJjVYjzb4cC/RCIVKHhiAaBSOLt9ggXgCKDiHLScyt0BYfZP5gFIpL4NJLoa0No72daK6P1e0l+CPtR3uO2iovRr17O0baoGt7F0NHhgAILwpTOKdwdB5RsJ612O7YjqmZXDzzYlZ8ZQXsGV07q4VCaIvmgd0OuZywZfzJT+D++xlIJIgAObudJ/7pn7jxfe+jRtO4AtgEbAZaEO6+NoRoXY3IpJ5tkSrjU5LvyBiV5DtnKkbXrOnigQd+hvik+EcgyH/9F8jiAsnpYh7bgHeSkEJVIpGcWxzTagaXS7SNOab3XGyojy3BfkKWB20oCdEByOkkNZOEN8flTpVBl0lMgZ6sjTTQ4cwwJ5fBDuDxYtTV0RTSqbXqWbXqIxCsPtpztCiWwXXvPlr+2oKRMVBUhYqLK/BXDq8ItYBDwA446D5IWk+jlCj886f+GTrF2lna2mDBgrEmSA4HFBZitbSQPXwYxeGg/dpree7uu7mtthbP8GaVwFpgDaJPahrh7luPXJMqkUgkklHuv7+dBx64n9FmZZu5995/YO3aqZyVRDKKFKoSieTc4LhWM+i66GkaDsPKlcSuex1NziG29z7GQWeC+e0pyIinf5rf4KIKg4uKFYocCpoKMRW6zBRbhzQ2xywGjARBI0skESGajlJbOIt1K9ZRGW4YM430YJpoa5R0NI0j4KBmeQ3uomFHYB14CTgMSS3JnuAePDEPi962iPLScrj3XmhuPlGkWhYcOoSxcydJXSfrdpMoKMB53XV8traW8R58+4HJ74gqkUgkknOBxx47xNq1vwSywyNV/Od/3ihFqiSvkEJVIpFMf45pNUMoBLW1R8tlOwba2LhlA1uavkKk0En/YBetnjQDJVCVtNPgsfGOaoMyt0XKsDGo2zFyaSxNpcSlsqYgxzIv/Ip2WqIQ9oZZPX81q+asojIwtog2sivCn2/7M5Zh4Qq68Ff4cQaHnX9jwLNAHFBg+4ztuPpduGpc3PSPN4lM8JYtYv7HitREAl56CT0SIQEMFBWxf+lSLopGed2WLfDud4Nf5kolEolEMjH+8pcDvO1tvyaV0odHZgLv5nWvk+u0JfmFFKoTQFVVFi5cKN0AJXnLeR2jHScvl93tGWJ9uI1mvY9Qb5LaNoVQgZNIoUbWZtFXZrCyJEeRqtCVdmHXnGCkAQXFsqFnnWSyMDcEd5cWE5txO4H4fJxJJ0qTQqYugzMghGjr4608uu5R9IxO2YVlLP3oUp7/wfP07unFlXPhbfWimiqm06S1spVkb5JsOMuH1n+IgqoCeP55kQmurR09t74+ePppMtksQ5rGwYYGorNnc7mi4Hc4oKUFGhthWX7nTs/r+JRMC2SMSvKdyYrRP/xhH+9612/JZkfaqs0F/gFhvSeRvHqk6+8Uks1mcblcUz0NieSknLcxunHjuOWyHcoQ69WnaIv1saAPNEsF0yQYKMFVnCbV18WNTpMqJ+zLqIRtdrF+1Br+8FY0yGZJO2xYlDCnP0H0sY08+Vw/pm6i2lS8YS+zVs4CC1780YtYpkX18mpWfm0ldo+dYHmQA7cf4OBjB4nqUUyfiTXDYr+xn47lHbzp5jex+PLF4njptChXtg//sdDRgfXcc6RMk55QiD0XX0zQ5+Mahv+csNvF9uk004HzNj4l0wYZo5J857XG6C9/uZP3ve//MAwLgCuvnM8TT7wDkAZikvxEPjqcAKZp0tjYeEbcrCSSyeC8jdGTlctGImxseYTmXIS6PtAUTWxTWgqZLPFcAtMDVxRAMqeQxWKIHGAJoWpYkDOw7HZMNUBheynRwwrhwu0Uz3FSvKCYYG2QbCLL1q9tZcvntpBNZJm3eh5v/OYbsXvscBgCnw9wUftFvKX2Lbzh429g5a9X0v6Bdp67+Tnsb7Hzwes+ODpnl0usqc3l4MABzGefZcg06Sgv56XXvY6ZPh+Xccwz71xObD8N/rA+b+NTMm2QMSrJd15rjG7f3sXNN//+qEh973sX8fnP34QUqZLJ4kzcP6VQlUgk05emJlEuGw6PjmUyxJ5/ki0lMUJZDS0YguoqCAZJ2hVi0W4CaYt5HgeFbhv9qhMNhQRZzEwKdAtUFauggLjLQ2FXCY6MA8tZgjeQJFBwBEVRUG0qQ0eGyMQyGFkDp9/JhbdciKqp8FfgZqAJCIHzB04qvlpBZE6Eh5SHMFwGn3/d57Frx5Ra1dVBSQk8+yz6yy8TB1pnzWLvZZdxiaYxH4a7vQ4zct719WfhQkskEolkOnPhhaXccccVAPzTPy3lvvtWo2lSBkjyG1n6K5FIpi/HlcvGlCxNXS+yvTbJwUKY76gE1YEFxDIx+pN9+C2LMkchV1ZW48w+R0KzUDUnOdMg47ThtCDlcJHRoKinEL/ux1Mkmr8oqoGm5jBzJu3PtJPsSaKoCtWXV5NNZDn4p4NclLgIfjk8v8XAV4EwZPQMX33iqwDctOAmFpUuGnsuLhfE4+htbcRdLg4uXEj/3LlcrSgEOA7DEH1fV6+WRkoSiUQieUUUReGrX309l15ahWnWc801Cl1dUz0rieTUSKE6QWQDcEm+c17G6HC5bIcZZaO/iy22NiI1nfQ7TVoLFAasCFWmD/9Qjlw6gWqB0+7igooL8blVvAQoUmEwmyJnZomh49QU3M4CZnhnYmvVUNwKiqKgKDqWqZFNqbQ+1komlkG1qVReWom31EvsYIyDXztIQ6gBp+aE9wP/j6N32R+99CPaBtso8Zbwz5f889jziMUwb7+d3s5O7C4XfWVl5GbP5hpFOdHewjBEJrm2FlatOvPXeJI4L+NTMq2QMSrJd04nRi3L4uDBAebMKTw6pigK3d3zuPVW0fVMIsl3ZM5/AmiaxsKFC+WHmCRvOW9jtK6O3dVO7nA/yU/cjSSSg9QOqsxOOnErNrKKwS6lhxddAwzZTIoVL76CMGqwkG61gITmpdrhpMxbSsDm4AK3m0sDNVziW05JtAR9yMDmFErTaR8klfSz+886mVgGm8tGzetq8JZ6oQu8u70k+hL0qX3wDeATHBWpB/sPct+O+wD4zPLP4HP4Rs+hs5PsBz/I4e3bOVxYyIbvfQ9z8WIu27MHe3s7ZLPiL4psFtrbYe9eqKmBdeugcmx7nHzlvI1PybRBxqgk3zmdGLUsi9tv/wuLFv2AJ55oPTr+zW/CRz86vki12WD27MmcseR840zcP2VGdQJYlkU8Hsfv96Moyiu/QSI5y5yvMdpBnPUXRGnrjLMgHUbr6QRLIegpwm32k9TTuE2LpA2OBG3M6lNRqirBbicN7NWqWJ5rpNMwCeZUQrEihoYqiGa70NMG2aEsRlbH4bXhLo6y58nFpAZtOPwOqq+oxu62w26gEVRLxXSb6Hfq8LrROZqWyV1P3IVhGlw982quqb1m9MV9+0h88pN09vURCYf5zne+w0dmz6ZuxQrYtAk2bxYtaHRd/BURDoty31Wrpo1IhfM3PiXTBxmjknxnojFqGCa33rqRH/7wRQBuuOGXHDz4CR54wMPtt4/d9pprIBgEtxs+8AEoKjqDJyA557HOQJpeCtUJYJomzc3N8mmrJG85X2N04/6NNAcMFnSH0bojYJngdGLZ7XgTOQbcJnZTpRg3cTK0BVXm19Qcff8uWw1z9E4qkt1Yh0uJZn1oPjsOvx3NYaCnc2AaeOxH6DoY4MD2uXiKPVRdVoVqqPAE0Cv2Zc40UT0qtqqxt9Xf7vktO7t34rF7+MwVnxl94amn6L/jDiKpFK1z5/LLb32Lr4bDzAIhQteuhTVrRJ/UdFqUOdfXT8s1qedrfEqmDzJGJfnORGJU101uueUP3H//TgBUVeGee95IcbGHe+4Zu+2//zt84Qsgn8tIJosz4forhapEIpmWxDIxtjRvIRQoRVtQBYf/AoZB2qHSHe+kUIWoQ0O3K2hZHYfTTkehgzkux9F1n324+FF3Mbf2GFQGEuBwkTVVLAsUl4W/MIbDnqC/O8hTD72OocEC5iwvQ42q8ByQQdxFL4IECbxeL0X1o4+kI4kI3932XQA+fsnHCXuFO7Hx4IP0fOUr9Jsmuy+5hGfvvpvv+HycIEH9fli27AxfSYlEIpFMd7JZg3e/+3f8/vd7AdA0hZ///O2sWXMBAMnk6Lbvehd88YtTMUuJ5PSQQlUikUxLmlpfJNJ1kFpHGbS1gNtFwqkyYAzhSZmEVAdhzc2OYJoBv4rd7SVBjoHUAEFXkEgiQjQd5cLts9jx8nzU5S2EZ+l4XN0oqoFlavT1Odj15Bxads0ja5WgORRiz8coHigWkygALgXTbZLem2b+6vk4/U5iQKNl8fVdD9BTMIOlTj/vWPAOsCySP/whPffeSwJ4ctUqjDvv5G67XRoGSCQSieRVkUrleMc7HuDhhw8A4HBoPPDATbz1rfPG3V6W+EqmC1KoThCXyzXVU5BITsl5E6MdHbBxI+mnfoUeOoA9dli0alEUesMhGv0eypxFLCxagGKzcanHTlvyCO2xduLJProGmgh7XFzkKmBxzVVkf9mPqaq099zIEb0Kn7sDxcrQvWuQwzs9JPpVbG4bvrCb3JEcsWiMQn8haq0KF4KJSX9TP6HaEJ4b5nIvsAVoTEc5WLMCtfpyaovq+R/T4vJvfwvX/feTAx7+4AdZfOutvP48qbs6b+JTMm2RMSrJd8aL0Xg8w1ve8iv+/vdDALjdNv7whzW84Q3SGUky/ZFCdQJomsa8eeM/lZJI8oHzJkZ374b166G5GVeVgq3MTU41cCgqpk3Df6SfeQMqgUtnoZSVA+AF5nuCXOgvJhx7nptL3BSrFh5bCiP6JzovTxIdqKDXWkJa99DdXk3Xi12kozYUVaHysiLiLXHSrWlUSyVn5UjNSeGa7yJxJEE6miZUG6L436/irnI/zUDA0Ont2IYrl2Bu8XwUzcW9ra08VF/Ph+fMYc8738k73/52zpc/I86b+JRMW2SMSvKd8WLUNC2uv/4XPPFEGwB+v4ONG9/DlVfOmIopSs5zpOvvFGGaJgMDA4RCIVRVFuhJ8o/zIkY7OoRIbWuDBQuosxmEjQ4ixhGqFJVEyMOgHieYhoK9LVAQBo8XgHKjn6syz1LhSlPtLcbuKQfFTqprK5pNZ0b9IYozP+fZLddy6AUPAKpDpfryatz9bgKJADF7jJgVI6NmGEgO4G5x4w17mb96Pp4b5nJXuZ82YAHwcmQn2VwCv8NHg7eG+GOP4Y7FaK6t5T++9S3uLy09b0QqnCfxKZnWyBiV5DvjxaiqKtx66zK2bm0jGHTx5z+/l0sumT6O8JJzC2mmNEVYlsXhw4cJBoNTPRWJZFzOixjduBGam2HBAtA0ApbGylaNnxSalDudxMmCoqCGgijxuBC08+YTNBO8MfMSbjOOWbgIu2/4SXN2EFUfJDUUIq0X4HEcZv78B+k5sArVX014XhjbbhscAYfqoHhuMYF5AXqbern41ospW1xGUX0RTr+Te4FmhEiNJntpibYAsDBQx+DjT6AkkxgOB4GaGrKFhTwBnE+5m/MiPiXTGhmjknznZDH67ncvxDAsFi0qZdGi0qmZnETCmWlPk3ePDb/3ve8xc+ZMXC4Xl156Kdu2bTvl9vfccw/19fW43W6qq6v5l3/5F9Lp9FmarUQiOSvEYrBlC4RCMFJakslw/YtxZg2q7ClVSRkZAHyOADgd0N4BuRwLcofw5yIM2MPUFMwc3Wd8P3ZXFstSSPTq9HcXEyodYOlbI1TMrcD2lBCpqMBi4GJIx9IUzi6k4V0NVCyrOGqctAUIAZgGLx55CYByewmOZ3aiJJOkfT6Mq6+mvrCQELAZiJ+VCyeRSCSSc4lEInvC2Hvfu0iKVMk5SV4J1V//+tfcfvvtfPGLX+TFF1/kwgsv5I1vfCORSGTc7X/xi1/w2c9+li9+8Yvs3buXH/3oR/z617/mc5/73FmeuUQiOSPEYvD88/DAA3DwoBCqAKYJL75I5aDFuv2lhHQbh70GQx47hmphuV1k0wn6uvdQldxHzubnwvKL8DpEKXBuKEYm0oyRSmPiACxchV40TzGVoT1ozyQhCXiAq4BZoqQlHU0z+7rZOP3Oo1NsAiJAGGjqayKejWPXLWbv7kHN5UgWFuK96irKfT4Y3i4CNJ6tayiRSCSSc4LW1iEWLvxv/ud/XpzqqUgkZ4W8Kv39xje+wdq1a/nHf/xHAP77v/+bjRs38uMf/5jPfvazJ2z/1FNPccUVV/Ce97wHgJkzZ/Lud7+bZ599dtLn5vef0OFQIskrzqkYHXb2ZcsWiESgvx9aW2FgACorobdXfKkq82Ys4x/2PcWzQScdVX5abEPomNhcKS7TdOb7iygoWozXFcQ0TOIHGiHeiMOhk075CMwoJxPLoCdzpDsDeN0RfMUdDOpzYSngANMYdfads2rOmKmmAR1IZ+I09jVCOk39ERW74SBeXk7ZxRfjsI3eau0j25/Fy5kPnFPxKTknkTEqyWd27Yrw4Q8/SW9vmo985CGKity87W3zp3paEskZJW+Eajab5YUXXmDdunVHx1RVZeXKlTz99NPjvmf58uX8/Oc/Z9u2bVxyySU0NzezadMm3ve+9530OJlMhkwmc/TnWCwGgGEYGIYBgKIoqKqKaZpH661nzpyJMtxGYmS7EUa2P35cVVUURRl3HE5cdHyycU3TsCxr3PFj53iq8fHO6VRzl+c0vc4JRIyCiM9pfU579qBu2IB18CBWYSHMnAnBIEokgpLNYr34IhgGeL1Yy5fTaU8TSBncmAuxvOBamtIx0noad2eEBas/gCf3KyzNTbJtJ2b/fhxqGhygaBruWUspKKogfThF99ZuUpk0bk8W5qQxAyambpJsT5IeSBOsDbL8M8vxlnkxTfPoOdktC01ReKFrO2ZiiOKYSUnay5FZs6hZuBC7omBZFoqiYJkmWUBTFOymiTWdf0+n+f9p1qxZwIn3z+l8Tufi7+l8PqeReyhwzpzTsXOU5zR9z2nHjghveMPP6OsTjzgXLgxz6aUVR/cxkXMSRZTi71jLMjEMa0rP6Vz8Pclzmvx2e3kjVHt7ezEMg9LSsTX2paWl7Nu3b9z3vOc976G3t5cVK1ZgWRa6rvPRj370lKW/69ev50tf+tIJ47t378Y3XJpXWFhITU0N7e3t9Pf3Y1kW6XSaGTNmUFFRwaFDh4jHR1eYVVdXU1RUxP79+8esj501axaBQIA9e/aMCaD6+nocDgc7d+4cM4eFCxeSzWZpbBwtCtQ0jYULFxKPx2lubj467nK5mDdvHgMDAxw+fPjouN/vZ/bs2UQiEbq6uo6OH39OI5SVlVFWVibPaZqfU1NTE9FoFJfLhaIo0/ac7JEIs3/4Q1zd3UQrKzEAhoZQLIugy4XW34+p6yimSc5mYyBlsqM7SiJVjt9dTLI7xSy7hr17CH/ZLLLhYtIvt2K17wLDQFXAwo7lnUnaX4mluHDsjuNu8lDpqGTQ2YPu6qYrEaV7fxs2h43iGcVUXFuBa6GLLrOLrp1dY84pF40yWOSgK5XCnc4wd7CA/Qsa8JeXkxkYIAN4fT5cLheDg4N0qipu00Q/fJj4zJnT8vd0bOxN5P+TZVkUFRVRXl7O7t27z4lzgnPv93Q+n9PI57zX62XRokXnxDmdi7+n8/Gc9u4d4qMf3UosJpIsDQ1Bvv3tpaRSvUDBhM/JNBcCwuOhr6+PnTs7puyczsXfkzwnsNkmX1Yq1pmwaHoVdHZ2UllZyVNPPcXll19+dPwzn/kMjz322LjlvH//+99Zs2YNd911F5deeikHDhzgk5/8JGvXruXOO+8c9zjjZVSrq6vp7+8nEAgAJz7lMAyD3bt3c8EFF2C326ftU45z8cmNPCcxns1m2b17Nw0NDWiaNm3PSfmf/0G57z6UBQswj20RYZooDz+MEolgaRqxoloOxErZ76zncM4CFArdQfwemFWRYu7Qs/hXBUnWH8JmtKNgksn4MN2z8M9pQLXbsHRQdgBtw8cuVbAa2jFsLrrcd5HLurC5bIQXhLF77Sc9p54jB7ny2f+PziU3Mf9AG8l5l+OrquLCY6+NoqAoCrppsldRuMWy+JBlTdvf06nGxzunkXvowoULT3jiOl3P6VRzl+c0/c5pJEYbGhpwOBznxDkdP0d5TlN/Tr298LWvKXR2jmQ2x85RUVTAOjoeibSwdeuvMYwcAMFgBVdddTMOh+vo9mLbY/cjPm+OH3/oIYV0Whz31ltNvvMdmVGV5zS55xSNRikuLmZwcPCopnqt5E1Gtbi4GE3T6O7uHjPe3d1NWVnZuO+58847ed/73seHP/xhQDwlSCQSfOQjH+Hf/u3fjv4yjsXpdOJ0Ok8Y1zTthEa1x77/2BLLkzW0PZPjiqKMOz7eOb6acXlO0/+cRo597DbT6pxiMXj00aPOvke3Nk147jlIpUDT6HFWszV+KQNZD7ZcElcghdPhpMhTQGIoy46XsrR6a7kwtoeCvjTZbCX+oizOuVfiDIgeqcRBeRaIISqh5gN1Bkosiq3mFqrmTGzdj9rVxT1fvQFXiUGw8jJaL3sTAX+AyzmxBMYA9qsqs4DrFYVjr+i0+j29ynFlWKyfS+f0asblOeXvOR17HufKOR2LPKepP6d//mf47W+PfWW8Ukll+KsJeADx6QEwi2j0XTz4oOMk259sP+O8oqgcP1X5e5Ln9FrP6WTbvRbyxvXX4XCwdOlSHn300aNjpmny6KOPjsmwHksymTzhooxc4DxJFEskkonS1CSMk8Lh0bFkEp55Bjo7wW4ntvRq/sZy2nU7hr+XlGsAzcpRqClog4cIJFsp9PTQ5wjyt81Xs3XrbXDZzwksWIHTagXLgHbgbwiR6gSuAOoNiDeBrxYqVk1svnv38sQn3spmRztKopfKQCWKP0AQ0dUmi3iWnUUcci9QA6wDZDt2iUQiOf84buXDKdgL/JpRkVoPvBs4XqS+OqqrJ2U3EskZJ28yqgC33347H/jAB1i2bBmXXHIJ99xzD4lE4qgL8Pvf/34qKytZv349ADfeeCPf+MY3WLJkydHS3zvvvJMbb7zxpE8QXg2KolBYWHhGFglLJJPBtIjRWEyI0XQaXC6oq4NjS0PSadB1sNuFQG1shEOHwLJAVel43WIeGAhyxOslGopgWjlUw8RlmSQyg1SpCvaQg0G1lKFUOTbDS/UbllN59TKIroOd62HPHugIgRmGYjssywERGIwKkbpgHXgmICOfeorkuk/ztYYmdKeT9MpPYZ9/Od9G6N/NQAvC3deGaEmzGljF+SlSp0V8Ss5rZIxKXivpNPzTP8Hvfw+53PjbHLPyjGAQZswYf7tksoCDB+2YZoZgsIGamrehKCq5XBa73c7JMqUTYdkykdmVSCabc9pMCeBd73oXPT09fOELX6Crq4vFixfz5z//+ajBUltb25gM6uc//3kUReHzn/88HR0dlJSUcOONN/KVr3xlUuelqio1NTWTuk+JZDLJ6xg9vtWMroPNJjKnK1fC9deLljMul3DzfeEFaG8XJb8A4TC7L6piQ9FhvLvCOF0pAgpgWpgmpDwqe70KB3UP5f2zKSutpPaKMMm+JC1/bWHhzQtxJhvgpxsgtwlmbIb6FijXQbeBKwxVq0UmdSIi9cEH4Stf4Qczj3Ck0MmReRdTefWneCfwruFN1iD6pKYBF+JZ+Pnc+CKv41MiQcao5LUxNARvfSv89a8Tf89b3gL33XeyVyt48sn38Itf7OTb334zmjbyt+/kZFQlkjPBmSj9zRszpakiFotRUFBwyoW/pmnS3t5OVVXVGfklSCSvlbyN0d27Yf16aG4Wa0/DYZExNROQOQSpGJRWwU0fh789A9/7nhCyDofYdv58Wgo83JXbx1DEyewXLkAP9YI9h6kbmJZKylaAbjhJu9OECkJcMesKPA4PRtYg2hLlDe95AxW/rIA4EAC+FIcFjWCkQXNBoB7sx8jIcTK/MSc09TaS/v0DuP7wJwws/vnKOIfKyyi6/nssrbqM/0X+CXEy8jY+JZJhZIxKXi2Dg7BqFTz11Om974c/hGGLFYCjbcxOhoxRSb4TjUYJhULnpplSPmNZFv39/VRWno9Fe5LpQF7GaEeHEKltbbBgAWgaOBJQeBBC7WBPg5mDwf2w8a/QVQwVLugx4PLLiXnL2H9IY8tLSbzZCyhLutCGClAzTnTfELptkJTNhqG48BS6KQgUEE1HaYu1Ma94HqqmYraZ6N/QwQdcAHwNKPMDy8af73GZ3w6PwcaZObbMsogkIuiDA2gLFFrCdoZ8fuwzriRcdRlfQ4rUU5GX8SmRHIOMUcmrZfXqsSK1oECU1p5qBdqFF8Lb3ia+tyyLL3/5cSKRBN/5zptPKlZljErynTOR+5RCVSKRnBk2bhSZ1BGR6umHmu3gikHaBp1ZGBwC1QKPDhcNweqlsMVD5NlBtvYV0Ru3iBTkMP1DGDYPWtqHYtqx9YdQbT7SxUm8pV7sHjsATs1Je6yd2e7ZqNtU1B4VW5UN3gN8HLCfZK7HZ35ra9ntjrPe+yLNZj+hphS1Q2B3e9h7QRn9RiepTJRAvIP3RXZTHW44SxdVIpFIJPlCXx/8/e+jPxcXwyOPwJIlE3u/ZVl89rNbuPtuoXS9XjsbNlw3+ROVSKYpUqhKJJLJJxYTmcnhVjM4EkKk2gfhsAWx/uH2bgo43KIEN+UGZw/JS+NsfnwhPYMWRqibWMCiwHJhejRMTceRdVGohrDlfFTGTLrNbtKI5tduu5vYUIzBrYM4Bhx4XV6K/rMIbjjFXMfJ/HaoCdb7d9CmJFjQaaJlFTBMcm4Xrdlesg4H3rKLCA5189jW9axauYHKgHzKLZFIJOcTx5sm3XXXxEWqaVp84hMP873vPXd0rLTUN4mzk0imP1KoTgBFUSgrK5NugJK8Je9idKTVTG2t+LmwDdQ+aEyCOTxHt0vYHrqckImTSHTQdkTFnrVjmz/IbqeLnKWQUEzQs1SkC1hoLKY+dyFuxYumaBCD+M44TVVN7CvZRywVw0pY5HI5TLvJ/H+dj/OGE/smj+H4zC+w0dVGMwMsaE2j6QZoGlZ5BamBLgr6NHpm1xAOzuBK06Spdy+bDmxi7UVrz9z1nObkXXxKJMchY1QyGTgmuAbEMEzWrn2I//3f7UfHfvCD6/noR8dZljKMjFFJvnMmYlOuxp4AqqpSVlYmF69L8pa8idFYDJ5/HrZtg4EB0VpGy4L7AESGhEh1OaG8DEpLQE1D4jD9Vi/PBnM0ZU3SAwXMa+imrLISX6gMy27Da1bz+r73cKFxOZpiZ0AZoNfeS7+tH2faybL2ZazasYqSSAmKqZC2pwm9IcScm+e88nyPzfwCMSXLFpoJ9QwJkWq3QUUFQ2qOuKpTHs0RKmrgUhQcqkbQFWTzwc3EM/GzcIGnJ3kTnxLJSZAxKjlb5HIGN9/8+6MiVVUV7rtv9SlFqthOxqgkvzkTsSkzqhPAMAwOHTrEzJkzJ7U/q0QyWUx5jB5vRDQwAK2tQgjW2aC0B+IaeD3CzdfMQrIdsEioJttdkMn6KE6Uk446CZUPUFLQTyoXpqQ/zNs6305RrphDnkM4NSfupBt0MBWTmBXDMiyKs8VcE7mGTGGG0itLWfFvKwhUvoLr3PGZX8uiqfNlIuURahMqOJ1QWkpOMelN9JOzqxSYLi5J6fi84i1hb5iWaAuNfY0sqzj1HxrnK1MenxLJKyBjVDIeXV2wdq3omjaeT4xhnN7+0mmdd77zNzz0UBMANpvKL3/5Dm66acErvlfGqCTfMU73P8QEkEJ1gsTjMlsiyW+mLEbHMSJi5kzh2Z8eAD0OLhMKnBAsBkOHVBfw/7N35/FRVXfjxz/33tkyW2ayTEISAoGQQNgRccNaBauCC63VUmt9ujx2ta1ttUoX69MNrV2s/bV9ap8+j0trN61tFVyI1gU3VESRLZAEQhKSIcksyUxmu/f+/jghIYQlICETOO/XixeZmTt3TobDmfnec873a5IycqjPeLCGbbjSVhTFjplQ0BJg7zBJtiWZG5xLUaqI3Y7dmJoJFjByDZReBaVXAR2UtEKH1kG+ks8Zs8/gjLvOOHKQCqIETSYjSubE4/DGGySse8iUmFhzXFBYSMY02NPTRso0wGrHlXHgzgwMxlbVSsbIkMgkRuwtPhnIMVTKdrKPSvvbvRsWLYLt24f/nMOtfIzFUnzwg39hzZoGAOx2jUceuZqlS6uGfX7ZR6VTjQxUJUk6dgcrQQMiedK5GciLQpEJ+UBuL2jN0JOBFPQmvbTGxhHP6GhKGtNpgmKiGSamrpLZbcHb5GWOMYceSw9ooCoqaT2N1WpF0RSwgYpKuihNND+K1bByjvUcnF7n8NrvcIDFAjt3wrvvQjqNY5wFi8tDOjcfzTRpj7WTMDKgWnDnBHD1xMAycDU7baSxqBYcFsdxf3slSZKkE6++XgSpu3YN/zmKAvPmHfrx7u4UjY1hQGT3/de/PsoFF1S8t4ZK0klOBqqSJB27gyQiwtkFha9AURt0A3tU8Kqg6GAmwGuiOyx07s4jnlZI2XuxKhrYrJiYuHNjdEectOx1My5dTJ6Rx173XjRVQzd1DNNAj+tYDAuKoZB2pekc34nb6WZC/gSce5ywjYOWSh1i3Dhob4fWVpEFIy+PqjlzCFhfJ6j0okV7iOspTEXD5i6mqDeJkpMDub7+UwRjQQKuANX51SPwBkuSJEkn0ubNsHgx7NkzcN/kybBkyaGfY7GIx2fNOvQxxcVunnnmOi677E/85jdLOfvs8cev0ZJ0kpKB6jAoisL48eNlpjUpa41KHz1IIiJsMRGk6kFot4DdARYTuuJQaEKvCaaGbrXgCQTpTfkxVVDsDlAVMAxsOXHefW02iaQVcsDaY0VLaeS4c0jraZLpJGklja7q2FQbekBnStEUyr3luKwu2A0MZxXu+vVw221iya+uQ3U11NTgVRQWJ0v5pWU9hRkdAxWLu4hCRcOSTIllzVZRkFU3dMKJMMumLcNj94zUOz3myTFUynayj0oAGzbAhRdCR8fAfTU14qNu3Lj3fv7y8lzeeuuzqOrR9zPZR6VsNxJ9Uwaqw6CqKvn5+aPdDEk6pBPeR6NR+Mc/xOadsjJIpcSMpOVdMNuhXQOnCwoDYg9oTzOkMuAAI63Sm7Rjy0nhLtJRIjmYqoqi6+Q7OwmG3GzaVo7FtKBaVQzFQEtqGC4Da8aKaZj4dB+qTcWSa6F8Tjkub19moxRiVDvcKtx0Gn77W7j/fpEdY+pUUlYryWiUHsNAU1VKW2L48zM0O03K1GJyVSvuSAS8HigvB0SQWtdVR4W/giWVh7nULskxVMp6so+emhob4W9/g3AYDEN8NITDA4/PnQtPPw0FBUd/7ubmKP/1X89xzz2XkJNj7b//WIJU8TzZR6XsJrP+jhJd19m+fTtTpkyRmdakrHTC+uj+2X23bxcbedrawOmEfCecVwcxZSBIVQAjAjagxwq5JqbPjtYLhsWBx5/AEXfgsIZxagk6Ql6eWDebBm+cwriLcCpMj9qDO+MmnAiT0TPYMjZsNhsOn4PiucXkeHMG2hcEAsChVuHu3Anf/jZs3Sp+nWuvZdXnP8/WHTu4ZOVKijdvpsObQ8hdyIWdlTxdFqZDjZATj5By52GdPYe03Uow2kw4EabCX8GKhSso9ZaO3Ht+EpBjqJTtZB89tWzeLNIr/OlPh87ce9ZZsHq1KPd9tBobQyxa9ACNjWFaW3t49NGPYLO9t34l+6iU7WTW31GUSMiMnlJ2G/E+emB237IyEaS63WKGVd0FOQb0ekQJGjMFyS7Q+9qlFEFnirQ3gGG2Y9XSWNQeynwqTR023tpexdbmCoKqlYQ7Svfkbhw9Dup31zOvZx7RniiKRSHHkUPB9AJyy3Oxufarrq4DYWAZcOAqXNOERx6Bn/8ckknwetm0ciUrzziDBsA/fTrmnXcy/uEHqHhyFeXNXVSobmZGvNRPTPPaZGj0Wcnoe7CELQRcAZZNW8aSyiUySB0mOYZK2U720ZPfG2/Aj34Ejz56+OPOPx/+9S/x8Xa0tm3rYNGiB2hp6e6/3dERp6TkvW8PkX1UOtXIQFWSpCNraYG7vge9dXBWKWCDSA7k5IggNRqFgAqaCRkd4u1A78DzbQWQUsDiRvdOp60+F1dumhxLC+ufnc8TO730WBQK8wvp7WkFwO62k/FneNfzLhM2TMDtcBMsDDJpwSS87gNKz+hAHVABHLgKt6sLvv99ePFFcfuMM2j53vdYmZ9PE1ADaMB2D/zhA9U4zimnImTDkzMOt8OBp7qa79ugu3MbiUwCh8VBdX613JMqSZI0RkQicN11Ivg8GJcLVFUkRbr8cvjNb8TH29F65512LrzwQYLBGADTphVQW3vdcQlSJelUJANVSZIOL94CT90CFc9AgRXUPWCokHaIvalPdoJpAc0BlgRkYtCTBLcFLC6w+QENesIwcSKOAjeazUGkNYPusdO1u5wqz2R2OnfSmegkqSdRFRWHxYFhGnSEOngs8BiLbIuY756PK+wSS4mtQBqx3DeMCFJXAPtPcL74oghSu7rEHtovfQk+8hFWqSoNDASpe2N7eb31dQwgWlrDltPmMEFRGAdsAV4Ari8ZThphSZIkKdvcc8/Bg9RFi+Cb3xQzqO81D8zrr7dw0UV/IBQSs55z5hTz9NPXUljoem8nlqRTmAxUh0FVVSZNmjQim4Ql6XgYsT4a3gRvfw9itZCjQcKDSNNrgBmBqk7wmvC0DrE0dOvgVaBbgfxisDjEsttIBDx9iYgUyCQy2CwhYt0urMUzmDR+HMWpYt5ofYPuZDeaohFJRlB6FXxhH94SL5NunYQr6oI1QCOQQYxgAcRy3yUMBKmJBNx9Nzz8sLhdWQk/+AFUVhIFaoG+8JlIIswrza9gmAaKpwRb8Ry8isKcvsd9iJdcztAVxdLwyDFUynayj57cdu8efPuyy0SAeuaZx+f8L764i6VLH6K7OwXAmWeW8cQTH8PnO371tWUflbKdTKY0ShRFwev1HvlASRolI9JH4y2waSV01kHQBh6vCFIBEhnYEwWrCuN1uMyAR9KwRYWzFOjWIGVAMiZmXT0emDOXtGpj9wtN6Mk0Lm+S5m2n4ywpAsBpc6IqKm6bm0n+SRRrxSTeSVCkFnHJBy/B+5G+3285ok5qApHdt5rBEeSWLSJh0r5K7ddcAzfcIGZUESuEg4gJ2Fgqxku7XyJjZNCcBWRKTkdTFM5ABKkg4uBGhl+aVRpKjqFStpN99NQxceKhlwAfizVr6rniij/T25sB4P3vn8i//rUcj8d+/F4E2Uel7DcS5WnkZZlh0HWdjRs3jkg2K0k6Hkakj7auglgDaGVgmGIDzz7hveBKgcuAhBXKNLigkGTjeOLtThJ+hVg0ha5aoaoKzjiDpMXJzud2kYzGyS/uwFM1i7jtPDo2dxBtjpLsTdIR70DTNUp7S9HWapQpZZx/7vl4v7nfh7MHETEu7Pt7X5BqGHDfffCJT4ggtbAQfv1r+NrX+oNUEPFtBjAyCV7avZZEJoli95IpOxNF1ZjD4LjX2ne8TGFx7OQYKmU72UdPXqYJb789cNtqPfSxx+Kee9b1B6mXXFLJ6tXXHPcgFWQflbKfzPo7iuTAIGW749pH01FoqxX7S9NWEaQahljyGwuCVSSKwGIDq480VronOnh+7RKUp0PMWPQq3tIEEc2LjVysnWnaN+7Cbg3jG5cit2YOtvm3sfCc8exYvYP6NfXs3rYbV6cLm82GN+5lsnMylWWVeH/jPfJItWcPfPe7sH69uH3BBfCtb0Fu7pBDHYBi6LzU/Bo9qRiG1Qnjz0HVbEwHJhz4VnDk0qzSkckxVMp2so+enB5/HNatG7h9/vnHBcBztAABAABJREFU9/x//vOVXHzxHwkEXDz00Iew20fuq7Xso9KpRgaqkiQNFa2DRBDcFX1RWg70xoEuSPfNLapOcJXQm7LS3qJi90Zx5IdI7vbQ8PxCCpdYyPNuwGzdSm8mg8thAXsRvvM/hnXy5eAsxeuDedfPY/ry6dzx0B1srd/KNco1XP705dgL7bASKD5CW598Eu64A3p6RD3Xm2+GSy89ZGaMCj3NnvaN7FVUVM2GOv4cVGsO0zl4+dUjlWaVJEmSspNhiGuW+1itYm/q8eRy2Vi9+hpycqxYLHKhoiQdTzJQlSRpKD0BRgYUK9gUKCuFzW+DPSNKwfTaoKSElG6hrdNKKg0em47XnaIrkyCZO5XmzqlsXj8XPbgZzASOfB+L//uLWKccOGcJVreVl5wvoRQqfOgfH8Ku2eEa4H2HaWN3twhQn3pK3J41C773PVHfFYgmo9R11vWXlKnKr8Jtc/Oz524nbckhNfUK7IHpqHbPIYPUw5VmlSRJkrLbX/4CGzcO3P7c52DC0I+go3LffRu48MJJlJYObEkZiaW+kiTJQHVYVFWlurpaZlqTstZx76OaA1QLmGlQbDC+DOrfhO60KEXjygVNIxLWSKYUcnLSmIaCHk6AZxyMH0/7O+2E6ruB8fgqfKR7VXY+10neQQLVrR1bifREuO1ft+FOukXdmC8dpn3r18Ntt0Fbm1iWfP318KlPgabREm1h1fZV1DbUEowFyRgZLKqFgCuAaZps69yGmVuOdf5n0XPymMWhg9RDlWaVjo4cQ6VsJ/voySedFh8T+zid73029c4713Lrrc8wdWoBL7zwiRNaekb2USnbyay/o8i2XzIWScpGx7WPeqvAERDLf51lQBdM0ETq26gJuVb0tEE0pqGpJg5HN8mwlZ54Keas2bS+G6a7tRuAwMwAeZV5RFui1K+pZ/ry6dgPuPq8tmktH37+w8xqn4VaosIdiCxGB0qn4be/hfvvFxkyyspEndSZMwHYFNzEyrUraQg14Hf4qfBVYFWtpI0069vWU99VD5qdvPlfYLyrEC8iUVIzYnnvcEqzSsdGjqFStpN99OTy1FOwY8fA7a98BYqPtJXkEEzT5LvffY7vf/8FALZu7eBvf9vMF75w+nFo6fDJPiqdauRlmWEwDIONGzdiGMZoN0WSDuq491GrF3IXQtduaG2B3RvBTILXCePHg81OIpwgk9CxkMDqSrE3PI/U9LNoereb7tZuFFWhZEEJeVPyQAFXwEUsGKNzW+eQl2t7uo2lryzFY/PAbUDJQdq0cyd88pMis69pwhVXwEMP9QepLdEWVq5dSVOkiZqCGsq8Zdg0G4qisKdnD63drWBxkHEVEtu9lk9FW3gY+CTgQpSg2dz3twv4BHAnMP34vKOnNDmGStlO9tGxKZWCvXsP/mfTpsHH3nDDsb2GaZrcdNPT/UEqwMqVi054kCr7qJTtRqJvyhlVSZIGa2mBVatg7RqY3A459bA3AZig29DPn0tCtxLb3Ym+M4pnfBcxvYpW/SJ2vd5BqieFalUpO6sMZ4Gz/7SqVcXIGGQSmUEvF9oV4qIHLgLAutwKFxzQHtOEhx+Gu++GZBK8XlEn9YLBB67avoqGUAM1BTVoqtZ/f1tPG+v3rBflZfKrcRdMw9exBe+O1ZTOu57rOXJpVkmSJCm7/O1vohpZPD68413HsErXMEy+8IVV/Pa3b/bf94tfXMyXv3zG0Z9MkqSjJgNVSZIGbNoEK1dCQwP4/eA9C0r+DcUG6ZCVSMRDpHY7usuJ3RHD64uyt6WQd985n6Z3ohgZA4vTQvnZ5di8g5coGWkD1aJicew37OgQvTmKJ+4hNCFEzTdqBrenq0skSFq7Vtw+4wy4/XZRI3U/0WSU2oZa/A7/oCC1s7eT11peoxcTw1uOMzCdGhTcDh9r6tewfPpyPHZPf2lWSZIkaWy4447hB6kAmnbkY/aXyRh86lP/5MEH3wFEIvnf/e4yPv3peUd3IkmSjpkMVCVJElpaRJDa1AQ1NeJTPRaGdRD1eInm56IVgEftQFE1ktYStqyrYdsbkwi1aihqL66Ai4nnTcSSM3RoiQVjuAIu8qvzB+68F7QNGglbgoZvNHCO7ZyBx158UQSpoRDYbPClL8FHPiKSJx2grrOOYCxIha8CgJSRYmvHVhq6GohjkHEV4S6ZRw0KU4GUK0BjuJFtnduYXyJDVEmSpLEmGh3+seedB2738I9PpXSuueYRHnlkCwCapvDggx/kox+deZStlCTpvZCB6jCoqsrMmTNlpjUpax2XPrpqlZhJnVkJ7i5QdQhtJdphofa5RcQs+ZTPjGGxpNFDcXpy59O4J4+ulk4UFRRNQbNqmIY55NSGbpAIJ5i2bBp2j12Ujnmhjt5He2n3tvPUwqf4yoKviIMTCfj5z+GRR8Ttykqi372FulydRPPL/aVmvPaB0gCJTIKMkUFVVLZ3bWdrx1bSRpoEkHEX4ypZwDRUpvYdb1WtZIwMiUzi2N8vadjkGCplO9lHx5Z4XFQo2+fss0UKg4PJzYWLLz66899//4b+INVm0/jrXz/MFVdMPcKzRpbso1K2k1l/R1EqlcLhcIx2MyTpkN5TH41GYe1jML8bJq0FawKUDBR3kSn0UpjThqvTR7StL2ViLEZyVwvxjIaqqqg2Fc84D8lokkhThIJpBf2nNnSDrrou/BV+3Oe6uffNe6ndUktwfZBkdZIOewfR4ijzd8/Hv7uD0h/9EnbtAqDlo0tZdW4xte+uHFJqZvGkxSydspRSbyk2zUY0GeXphqf7g0/V7kULzMThKmIaMG2/XzdtpLGoFhwW+X/6RJFjqJTtZB8dG7q74bLLoL194L558+A///P4vcZ//uc81q1r4Y9/3Mijj36Eiy6qPH4nfw9kH5VONYppmkOnP04h0WiU3NxcIpEIXq/3oMfous7GjRuZOXMm2tFucpCkE+A999GX/gK1X4ZCEzIOSDsgEUbvDdGuF2B1miRjeWx/+Ux69hYQD/ZANErQPQnbpFKS0SSpaArTNLG6rEx8/0RALPdNhBP4K/wUf6aYX3f8WpSO2eEnEAwQs8X494R/43P6CMRMKhrDrKgrYnpOOZtu+g9WRh7vLzUTcAX6S80EY0HCiTAV/gquqL6CR7Y8wlP1T2GYBl67F1/hdNpyywFlSJAK0BxtxmVz8fvLf4/HLtMmjTQ5hkrZTvbRsSESgYsugtdeG7jP44GXXupPAH/c6LrBli0dzJgROL4nPkayj0rZLhQKkZeXd9iY6mjJGVVJOpVFo7BpLWz/KTh6oLsUNA1dN0hEk8RTPsKxPHISCp5AmMqzX+XNP88nFbNjAwqm+HHPLSEVSxFtihLZHSERStD2VhsOnwNXwMW0ZdNwn+vme5u/J0rHdNagtWugwbqJ63BkDM5oSOKIxqlzJVm50OTG627h7nf/p7/UzP4JkmyajTJvGW6bm+d2PscT25+g1FtKQU4BBgal489li0XUaT1YkKobOuFEmGXTlskgVZIkaQxZuXJwkOr3w5NPvvcgtaMjzu7dEebOHdd/n6apWROkStKpSgaqknQq2leCprYW/BtgcgvsSpOy7iWi5RFNaGSMYjKGhZRpR++FZGs+eYXtFFXtpKe9GnuuHa3MB4DNZaNgWgG+ST7a32rntM+cRumCUvKr87F77Nz75r2idIxSg7ZVBJ2JmQmUPc0s2N2L06qgWK1UVc9jS04Pv9j0+4OWmgFI6km27N1CY7gRwzRI6kkm+yfz/Qu+z2fX3sFb4QbseVXUqNpBg9S6rjoq/BUsqVwy8u+zJEmSdESmCbp+5OO2bx/42euF556DWbPe22vv2dPN4sUP0trazXPP/QezZxe/txNKknTcyEB1mOQyCynbDbuP7l+CptAN1SlQ/fRqvbT1+kkaVjQlg82aQrOoZFIKpmmS6FXp7nZSVNNKV10lhuYBX+6gUyuKgsPvoHRBKSXzS4D9SsdofrR1fW0sS9Pb/AI1u+NYNAtKfj7MPx3N5cIVbuS5nc8xvXD6oCDVMA3qOuuo66ojY4harCWeEgqcBVg1K6/mTiC8cAW2tSvJ7diMx+EndYjlwisWrqDUW/re33Rp2OQYKmU72UdHx5//DF/8oqhGdjQmT37vQWpTU4RFix5gxw7x4p/4xD9Zv/4zKIry3k48QmQflU41MlAdBk3TmHm8Nz9I0nE07D56YAma3C6wJ0lFcmjTnaQMBYcaRzEBXQG7BTVtYOgmKiaxqJu84gg5eWFi7mlgtQ46/cFK0NR11hHsCVKxrQISgK0DY+9rqNG9GArEJ5fjOe08UaQOsGt2upPdWNXB5960dxPbu8TldL/Dz8zATAqcBaT0FK+GG9nYuQ1XyXxuXnwn+TtWs6Z+DY3hxkEJmJZNW8aSyiUySD3B5BgqZTvZR0fPd75z9EEqHLRS2VHZsaOLRYseoKkpAsDEiT4eeeTqrA5SZR+VstlIXEiRgeowmKZJd3c3Ho8nawcw6RSQjkK0DvQEaA7wVoFVbFYfdh/dV4KmugISzaDVQ7qLSMhP0vDjUHtFkKoqYKqQTKEakMGCpoCqKqAY9NpyoLx80KkPLEGzTyKTINOWwdquQfJdTL2Onkw3MSs0TC7g9Jln9QepAAoKhmmgMHBfykjRGG4EYE7RHCr8Ff2P71Kt7DYylGUS/CfwWW8pyrzrWT59Ods6t5HIJHBYHFTnV8s9qaNEjqFStpN9dPSEQsf2vEWLjv01N20Ksnjxg7S19QBQVZVPbe3HGT8+9wjPHD2yj0rZbiTy88pAdRgMw6ChoUFmWpNGR7wFWldBWy0kgmBkQLWAIwDFi6FkKYa9+PB9VE9C01r4+6+Bdmjft9Enja5Dd9KJRgZFVcDUwBQDjplKY1FVdDRMRUEljWmqRCnAaXOw74L2/iVoKpcMTuPvqHdgaUmTjv0bqzVKj95Ds19j14RcFk56P3bNPuh4ExNVUTEZGPAaQ2JmNNeeOyhI3QG8baRRVAvLLA4+C/3hrcfuYX7J/Pf67kvHgRxDpWwn+2h2OPdcUXrmSMaPhw9/+NheY/36PXzgAw/S2dkLwIwZAWprP05RkfvYTniCyD4qZTvDMI77OWWgKknZLLwJNq2EWAPY/OCuAMUKZloErQ33Q/sLMO0bg59nmtDTAB2vQscrEFoPW0PQ2gzFNkAV5yOfZKQeqyODklAgx4mpqBi9SRQjg2oa2JQMFqtKXLdhz00R7/UR3FNI0bheHD7HoBI0C1csxFu6X0rysEnVNzYRqKwn6E7jMXTeLrUTzsvhfeXn4rENneFM6kk8dg9pIw2AburUh+oBmJI/ZVCQ+g6QiQWZ4grwzfxq5DVmSZKksev00+Hmm0fu/K+8sptLLvkjkUgSgNNOG8dTT11Lfr5z5F5UkqRjJgNVScpW8RYRpMabILcGlP2uoCo2cJZBzjiI1qFsuRObdiW07YGudSJATe494IS5oMUgMAMcRaDZIJmkd/1ubKcn0RMuMrqCnsoAGoqqYlF11Pw81JwcXKqKy97NxlenEg9rhOpD5OTl9JegqVxSOThI7eiCC/8Lb91LLLa7+OWZnXT6bOgOKwvLzsbn8A35lXVDJ5aK8f6J76e+q55eQ2d7PEi31YXD7iPgKQMGglTT0MlPhPn8tGV45bJeSZIk6RCCwRgXXfQHurtTAJxzznhWrbqG3FzHKLdMkqRDkYHqMDkcciCTTrDWVWIm9cAgdR/TgGQIjAzKnqepNJ9DDY0bWPuq2iDvNCg4CwrOhPxO+PvNYO0LUgHq6ki1OOmZCJ78MNG2XEBBtahY7BpKJg05OeCw4XW20JssI+ldRF6lyemfP53iOcX9JWgGeeEF+ML3oTGEqdrwnHYWrYVPkzLSnF+6kAJnwZBfZ//SMR8946v816s/44mubXS7itALZ4A1h7WKig0IAoqh4+uq40xZamZMkGOolO1kHz3xdB1SqRPzWoGAix/9aBFf+tITLF48iX/84yO4XLYT8+LHieyj0qlGBqrDoGkaU6dOHe1mSKeSdFTsSbX5BwepRhrizZBog8ReMEWZFsVMYSMDrgkQOFcEp/65AwEpQHUBBAIQDEJZmZhNrWuiu9vHxsdrmHXp2/jLwmTSOaR7XZipDIpNwe7pxmqLE0sUsaPpKsJtLvIm25j+kelDA9TeXvj5z+GPf4edgH0Kz396MT+d8hvGZUoochXREe9AN3QChygdc9V5t/NQfiXJhSvg+dvJtG9Es3nIL6whbJpEjDRqLEhRIsyZstTMmCDHUCnbyT46Ov78Z+juHrg9btzIvt4NNyxg3Dg3S5dW4XCMra/Aso9K2U5m/R0lhmEQCoXw+/2o7zUfuiQNR7RO7EF1V4jbpgE9jRDdCkZy4DjVBo4ApjWPTKobreYW1IIFBz+n1wuLF8N995HJKyT4/BYiET9oFhxdGq/+6wJmnN1IYPJOnP4IipHCtLtJmnnsaTuLvV3ziff6SYQ7hmT2BWDLFvj2t6FhF7QAeR9j46L3cVPlZwH4wQU/4PSS01l9mNIxc6dcyt2ecTQB8wPTiU//KL3OAuxdDXRFdtFjZFBUCzZXgJJpy7ixcgnTZZCa9eQYKmU72UdPvHQabrtt4LbLBR//+PF9jV27wkyY4Bt035VX1hzfFzlBZB+Vsp1MpjRKTNNk9+7d+Hy+0W6KdDI5TLkZ9ITI7osF4q0QeRcyIo0+FreYOXUEwOoDRcHUDZLdb5CT6T3sSxoXX0LkgX+R/OdLROJ2UBS8E3ycNdPNc2972fD8PAKbqvE4mtC8NvSps+kxJ6PrzkNn9jUMuP9++O//Fuu4IgEYdzutJWV8/rSrQYGvnPEVlk1dBsD1hykdcy/QANQA3b1hQgo4J11I5XnnsDm6G1cmwQSLg9n51dTbPbwFyLy+2U+OoVK2k330xPvf/xXV0va58UYoKjp+57/33je54YbV/OlPV47Z4HR/so9K2U6Wp5Gkk8Ewys2gOcTM6d7nIdVXZE61Q+40cE0EZeBqqp7S6Q1FSfcY9Gzrxu9MYvfah7xs6xutvPTjVyE0nzn6bgK04cqz4TjrNLApLJweYu3rdtp2WQh7KnGVTUdN52GkDWLB6MEz++7ZIy6Jv/WWuF2yCPRvEcbgy+f9Jwl7gk/N/RQfnz34MvnBSsdEgVrAD2jA9i5RQsflHc92dxFWdxFVwHTENlwfsAZYDsg0SpIkSWNHby9873sDt30+uOmm43f+n//8Fb72tacB+OhHH+HNN/OZOfM4RsGSJJ0QMlCVpBNpOOVmWp8Eiwe6dwAGaDngrhQzrqq1/1SpWIpIU4Roczc2NUiiV+PV+5tw5P2LSYsnMWXpFLylXnraenj17ldpqBWXrh0F4yFZQl46jDJ5MuzcCZkMAYuFxfNK2OFfQH0oj3DIwNjbgWpRD57Z94kn4I47IBYDpxM+cjM8cCndeg8/PuvH7CzeydXTr+bz8z8/rLemDpEkqQLoTcdpju7GACJ5lWgwKEgFCACNwDbkrKokSdJYYZrw3e9Ca+vAfbfcIoLV935ukx/+8EW+851/99/3la+cwYwZgfd+ckmSTjgZqA6TxyPnbKT36EjlZhwBSHRA2xqx99TiEjOnheeCdXAh8t6uXto2tJGMJtHsCs6CJM2hc3CXjSO+N86G+zfQ+O9GCqcWUv90PZlkBkVVqPlwDfN5A/tf90LNefD//h/U1UEiAQ4H3upq5nk8TO9O0rmtk0wig8VhGZzZt7tbBKhPPSVuz5oFt34fbi4llojxz5J/8vS8p1kyZQk3nX0TijK86qYJIANYgW1d9ZiAw1lIKsdPAYODVPqOy/Q9T8p+cgyVsp3soyPPNOHWW+GuuwbuKyqCL33peJzb5JvffIY77nip/77bbz+P2247b9ifQ9lO9lHpVCMD1WHQNI3JkyePdjOkse5Q5WYMHXoaRKIkMy2W+KpWmHAN9LaKwNZb1f+cVCxF24Y2Uj0pHH4bblcr8WQxPb3nYrFb8JZ6UVCof7qe+qfr8ZZ6KTuzjLNvOpv8QhUuu0W87vXXiwRL84fOR9o9dkrmlwz9Hd58Uyz1bW8HVYXPfAY+8Un4lkbvrl42qBu4d8m9vG/i+7jtvNtQleEnfHAgBqRePU1juBEANX8KAOMZHKQCpPuOl8n6s58cQ6VsJ/vogB074Pe/F4tljredO+Gxxwbf95OfiERK74VhmHz1q09yzz3r+u+7664Luemms9/bibOI7KNStpNZf0eJYRgEg0ECgYDMtCYdm0OVm4m3Qvgd0OPittULuTNFwBrfCVNvgm33QGSzeK4jQKQpTLonRm4gic0aE2Vjdl1FKOxEzSQJvhMkFoyhKAqGblCxqIKLfnaRuKL8y1+K2dNp02DhwqNofxp+8xt48EFxSbysDH7wA5gxAx6G5NNJdnbv5Bcf/wU1k2q4Y/EdWNSjG16qEMt5N8bayRgZnDYPcVcRCnCQkJlg3/HVR/Uq0miQY6iU7WQfFdatg4sugnB45F9LUcTHyrXXvrfz6LrBZz/7OL///Vv99/3610v4/OdPf48tzC6yj0rZTmb9HSWmadLW1kZhYeFoN0Uaqw4sNwMieO18DTD7sv5OB1e5+PQ2UqIcjaLC3DuhdTW0rUEP10M0SG6+QsbIp6ntTPZ2zSfW46PtnSaSe5JggqIq5E/Jx+a20d3STaonhT0Th7/+Vbz29deL1xmOxkZRdmbbNnH7iivg618X+1LrIHVXil2RXfzx/D+SMyeHn130M2za0RdR9wLnGxnWJKNoKHjzpxBXFAqBA1ND6UAYWIZMpDQWyDFUynayj8ILL8Cllw6uazpSVBXuu+/4lKP53OcGglRVVfjf/72c//iPOe/9xFlG9lEp28msv5I0Vu0rN6MMJEMi1gSYYA9AwVmg7r9n1SqO1xPgLIXK62HCcrpeW8vra1/EWZxHPD0eXXeSCCXY/XIDyVgSi8WCe5ybwMwANrcNPaUTbgzTua2TklceEakWp06Fc8+FaHTQ/lSqqsRS4H1ME/72N7j7bkilIDdXBKznny8ej0Py5iS79+7m9Umvs/3i7fzukt/htDr7TxFNRqnrrOsvQ1OVX4XXvt9rHMC183lUPYmeN5le73gADqySqiMSL1UAS47hn0KSJEka7Pnn4ZJLxEfEPrm5kJNz/F8rLw9WroTLLz8+51u+fAYPPvgOum7y0EMf4qqrph+fE0uSNOpkoCpJJ4LmECVozLRInGSaEN8tHnNXDA5SoW+vqkU8bx+rh16m09ayh4LcArGU14Q96/egJ3UsTgtlp5XhHjeQeEm1qhgZg8ze0MBs6gc/CL/7HdTWQjAImQxYLBAIwOLFsHSp+HbyX/8FL/UlpTjzTJGmcd+VXBMS30vQ8m4Lba42HrvmMX619Ff9QWhLtIVV21dR21BLMBYkY2SwqBYCrgCLJy1m6ZSllHoHh6CmafLkW7+n2MjgWPQjtqkaFqBQvBxpxHLfMCJIXcHQIFaSJEk6ejffPDhIvfhi+PvfRyZQPd4WLZrEI49cjWGYXHaZ3AwiSScTGagOg6Io5OXlnTRZ46RR4K3qy+obBGcZJDtA7xUzp47ioccnguJ47+APXYvDgmpRMdIGmk0jvCtMMpJEtaoUn12M2z84O7CRNlAtKpZ/rxHfQoqLxbePxkbw+6GiAqxWsQc1GIT77xezqD094j6bDb78Zbj6arFWq0/ykSR7Ht5Dwkjwx2v+yM+u+hkFzgIANgU3sXLtShpCDfgdfip8FVhVK2kjTTAW5P4N9/PCrhdYsXAF0wMDV75fb32dus46/BYHl7qK+A1igGpBZPe1IPakLkPMpMogdeyQY6iU7U71Prp378DP55wD//gH2IeW484KiUQGu10b9G+1dGnVKLboxDjV+6iU/Uaib8pAdRhUVaW8vHy0myGNZVYvFC+GhvsgZ5zI5AsiaB0ym6pDKgxly8A6eAdmflU+roCLWDCGu9jN3k3i20XB1AK8eUOX1MaCMVx+G/kv/kMs300mYfduqKmB/bOz2WwiiG1vh3feEbcXLoSf/QwOyDKYqkvR/J1mkukkj1/0ODd/7mZKPCLdUUu0hZVrV9IUaaKmoAZtv9/Nptko85Yxzj2Ouq46Vq5dyZ2L7+yfWX3w7QcBuKL6CjbaPRQCNwJTESVoHIjESXJP6tgjx1Ap28k+OqCmJnuD1K6uXi655I8sWVLJd7/7/tFuzgkl+6iU7UYiyZdMGzYMhmHQ1NQ0ItmspFNIyVJwTYLIVog1i/tcB3zomLpIvOSugJKhOzDtXjuTFk8iEUrQsaUDPaljc9vwTfLR09Mj1sj2MXSDRDjB5JxW7OkesYYrFhN7UQ9MIR4KwbPPwq5d4huK1ys2LB0QpGZiGbZ8egvJeJLNUzZz2fcvY5J/Uv/jq7avoiHUQFVe1aAgdX+aqlGVV0VjqJHVO1YDUN9VzyvNr6AqKhfMvIbNiMFpCTAfWNj3twxSxyY5hkrZTvbR7BcMxrjggvtZt66F229/nl/+8rXRbtIJJfuolO1Gom/KQHUYTNOkq6trRLJZSacQZylMXwGqDTI9gAoWt9ivaqQg3gyRLSJ4rVkhjj+IKUun4C52E3w3iGmaBGYEUFSFZDKJ2RepGrpBV10X/lIXlfVPga6LLL1+/+Ag1TRFNt/nnhPLfXNyRKKlmhoRuO6X/tEwDV78wotYm6xEvBEq76mkpqim//FoMkptQy1+h78/SDVMg+ZoMyk9Neh30FQNn8PHmvo1dCe7+cM7fwDggooL2NQ3wzoPyHuPb7mUHeQYKmU72UezW0tLlPPOu4+3324HoKjIxfvfP3F0G3WCyT4qZTuZ9VeSxjrfdHBVQE892AsgtlNk91UtYk9q2TIxk3qIIBXAW+olJz8H1aqiaiqGYaCndEzTRE/pxPfGSYQT+Cv8LJy4G29DSCRKSibF3/skEqJoXkeHuF1aCnPnimW/qZTYx7ptG8yfj2maPHrXo0x7bhqmamK/w86cmjmD2lXXWUcwFqTCN1CC5532d2gINzAlbwozAzMHHR9wBWgMN/Jq86s8seMJAK6ddS0/7nt88TG+xZIkSdLJo7ExxKJFD9DYGAagrMzLM89cR1VV/ug2TJKkEScDVUk6kZJdENkIjkI48wHQ46IEjeYQiZOsQxe3JqNJOus6ySQyWBwW9JRO21tt5JblUnNVDe3vtBNuDNMT7QEvuIvcTFs2jcqFRXg/e7c4yaWXwl/+IhIngUis9OKLYhbVYoHZs6G8fKC2qtUqsgEnEgD88Z9/ZMa9M0AB8zMm85bOG9LORCZBxshgVcVrhBIhGsIN4nfQk0OOt6pWMkaG1dtXkzEyzC2eS15gRv+y3wve0xstSZIkjXXbtnWwePGDNDdHAZg0yc8zz1zHxIm+0W2YJEknhAxUh0FRFIqLi2WmNem92/M0YEDudPDVHPbQaEuU7au201DbQCwYw8gYqJpKeFcY0zSZfvV03vft95HsTrJ3y1466ndRkIpTOM6KPc+A1X+GeFzsST3zTHjkEZHJV9cHglSnUyRNcg/OFkw6LQJYh4M/rvsjgR8EsKVt2M+yM/mWyQdtr8PiwKJaSBtprJqVDW0bDvv7pY00iqLwQtMLKCh8fPbHeabvsbnIZb8nEzmGStnuVOujpil2d/zqV9DQAC0to92iod55p50LL3yQYDAGwLRpBdTWXkdJyamZreBU66PS2COz/o4SVVUpLj5ICRFJOlqtInkQJUsPe1hwU5C1K9cSagjh8DvwVfhQrSqRnRESoQSmaRLeGSa4KUjAl6Zsw2rK9q+LCmLZrtMJt9wC1dVi2W9zM+zYMRCknnsuuFyk9BSRRISMqWNRNHydMayBAI8r24n8KMLcvXPJLcml9Nelh9zZXpVfRcAVIBgLkjbShBKhw/+OsSBpPY1hGFT4K1hYvpDf9z124VG8pVL2k2OolO1OlT5qGPDYY/CjH4mdH9nqzTdbufDCBwmFxKqeOXOKefrpayksdI1yy0bPqdJHpbFrJLL+ykB1GHRdZ+fOnUycOBHtwGypkjRcPTshuhkUDcYdOhSLtkRZu3ItkaYIBTUFqJr4j2/qJh1bO9BsGgXTCoi1x1h7y+Mstj2PZ08dMYcD58SJqDabKDGTSonL5v/4h0iOtGCB+HaiquBywbnnErNC094tNHe30JvuxcRANRSmtKfZcPEcnvrD09z81s3ku/Ip+kXRYac5vXYviyct5n/W/w/NEZHV2GV1EUvHhhyrGzqhRIh4Oo5Ns3HtrGtpV1Q2IZf9nozkGCplu7HeRxMJaGs7/DEvvwwrV8K77x7+uBkzjl+7jpXP58DhEF9RzzijlCee+Bh+f84ot2p0jfU+Kp38dF0/7ueUgeowde+X/VSSjsm+2dSCs8HmP+Rh21dtJ9QQGhSkAnRu7yTTm8HitJBflY8Zi9NRu4EdvgRz3ldDIhLBabOJZbu7domkSAsWiLqpt90mKrorighezzmHLjXFhpa3iCaj2DU7XrsHzVQINIdpzFP4vvUNJuy1ESwKMu1T02DBkX/FpVOW8qt1v6I71U3AFWB87ng27d006Bjd0KnrqiPHkkNPqgd/jp+lU5byt77H5bLfk5McQ6VsN1b76BNPwJVXitQDR0vT4AMfAE/fatp58+ALXzi+7TsWkyfnUVt7Hbfd9m/+7/+uwOPJ0sKuJ9hY7aOSdKxkoCpJJ4JpQKvIbHuw+qj7JKNJGmobcPgdg4LUTG+Gzm2dAKIcjaagtOzGkemmXp/IND08cJIdO8Ty39xckcm3pweefFJ8E5k1C/LySNbXsSuzh96cDH6nD4th4unqxdmToqXAxsoFccZ3nUmnu5Pfnf87piyfQimHzkS8T1dvFxkjg02z4ba7CSVCGKaBaZqk9BTBWJBwIkyFv4JIMoItaePqmquxW+ys6TuHzPYrSZI0PIkEXH/90Qepdjt86lNw881QUXHk40dDTU0hDz989Wg3Q5KkUSTrqErSiRDaAIk9YHFB4H2HPKyzrpNYMIYr0LcPx4TwzjCNzzRi6iY5eTl4S72QSkNLMy6XQiyh0Rnpu+aUSolAFWDaNJFM6aWXRAKlTAb+53/gnnt49cJpdKlJKsMqJc0RCtp7SNmtPPO+8dx4foJMupr8VD4z9BnsrNjJ6obVR/wVDdPgzpfuJMeaw3/M+Q9uWHADDs1BSk/REe+gMdyIy+biE3M/wbWzrmVP9x5smo2rpl/FHmAToCCX/UqSJA3Xb35zdImQ3G4RnDY2wq9/nT1B6l//uonlyx8mkzFGuymSJGUROaM6DIqiMH78eJlpTTp2+5b9Fi0C7dBLmDKJjMjua1Xp7eyl/e12EmGRTMLmsTHutHEimotEoLcX1e3FiIKuK7i9LpT9Z1Nzc0V233gcfD4xuxoKEZ1Zxa9mJzEmnsa8qAtLWidj1dgR0Hgq+DK5HQVM65qAy+pCOV3B5/Cxpn4Ny6cvx2M/dLbFhzc/zNaOrbhtbr79vm+Tl5OHYRjc/erdnDX+LL5w+heozq/GY/fw1Se/CsDl1Zfjc/h4vO8ccwFZGe/kI8dQKduNxT7a3S3SDuwTCMDPfz5QZexAOTlw3nngP/TOk1Fx330b+PSn/4VhmFgsKvffvwxNk/MoBxqLfVQ6tcisv6NEVVXy8+XXZ+kY6SloqxU/lx4+26/FYcE0TVrWtdDT0gOAalEpqCkgb1KeWAORSkNnBySTGNYUKhasFnB0dEBdnTjRxIkDQarbLUrQNDZCIkFdZx3BWJCKggp2FdkA6En18GLTi6hxlZnNM3Fb3ShTFQhAQA/QGG5kW+c25pfMP2i7u3q7+PXrvwbgC6d/gbwcscs0x5qDy+aiPLe8/7mNoUZebHoRRVG4ZuY1APS9O3LZ70lKjqFSthuLffTuu6GjY+D2t74F11wzas05Jr/+9et88YsDK3b2JVCShhqLfVQ6tYxE1l95yWoYdF1n69atI5LNSjoF7H0RMj3gKAb/3EMepqd1Wte30lnXSaQxAkDuhFwmXzSZvMo86I3Dlq3wwvOweTN09xBr68bV007elrVkXn4Z0zShpEQErPuC1HPPFTVR++qiJjIJMkYGq2oFoCPewXM7nyOZSjK3aS5ezYuSr8A00S6raiVjZEhkEods+z2v3UNPqofqgmo+XPPhw74df9z4RwDeP+H9lOeW0wa8i5goXjTsN1UaS+QYKmW7sdZHOzvhJz8ZuD1+PHz2s6PXnmNx110vDQpSv/zlBdx772VyNvUQxloflU49MuvvKEokDv0lXZIOq2WV+LvkElAO/gG8+5XdvPKTVwjvCmN1WsmQYcJ5E8jJ70vHHwrBWxsgGhVZMHw+jESSRNLBNGUz9h2bMBVFzKR2dYkMG/uC1JwcUT81EIDqahzd27CoFtJGmraeNtbvWY+Bwey9sylKF6HaVJHht28FR9pIY1EtOCyOg7Z9Q9sGHq8Ti3dvPedW1EP8jgCd8U5WbRfvx8dnfxyAZ/oek8t+T25yDJWy3Vjqow88ID4O9rn9dvHRMBaYpsnttz/H9773Qv99K1Ys5Ic/vEAuaz2CsdRHJel4kIGqJI2kVBg6XhI/l1wy5OFoS5RXfvYKu57fBUBOXg6nf/F0GmsbieyOYPfZURMJEaT29IjNRYqCYUKXGsBPG5WpTaBpmIqC0tICDofYn3ruueJnXYdwGJYtA4+HKlsVAVeAN1rfoC0mCu9NS01jUuck8SVhPrBfubpgLEjAFaA6v3pI+3VD586X7gRg2dRlzCyaedi346+b/kpaTzOzaCazimYBctmvJEnS0dq5c+Dn3Fy47rpRa8pRMU2Tm29ew09/+kr/fT/84QV885vnjmKrJEnKVjJQlaTjKBlN0lnXSSaRweKwkO94Hrupg3cquCf1H5dJZHjr/97inQffQU/pqJrK9I9M57TPnIbNbaN0QSlrV66lY3MHju69uMLdqHk+DEMhllBJpFT8OT0s7F2L14hgut1iFjWVAqdzcJBaVydSOy4RZXEcFgc9yR4aw404LA5muGdQtaNKBKlTgOKB30c3dMKJMMumLTtoIqW/bPoL2zu347V7uWHBDYd9b3rTvfxts6iW+vFZYja1HdiIzPYrSZJ0rBwOsbMj2xmGyQ03rOY3v3mj/76f//wibrzxzFFslSRJ2WwMDG2jT1VVJk2aNCKbhKWTQ7QlyvZV22mobSAWjInMvRYVl7aZSTPKmfLRD+BFXE1uqG3gtbtfo6ddJEsqXVDK2TedjX/SQCrGwPQAi+9czI6/b6T+x5sIG16MiBVVBVeOzrTcFipbX8DrioHpgngc1TTFtxWnEwxDLPcNh0WQumIFlJYS6g3x9ae/TnN3Mw6LgyJXEZUNlShpBfzA9IHfSTd06rrqqPBXsKRyaO3XjngH//3GfwNww4Ib8Dl8Q47pTfcSS8VoijRx96t3E+oNUe4r5/0T3w8MXvZb8J7/FaRsJcdQKdvJPjryenvTvPFGKyAyE//2t5dy/fWnjXKrxg7ZR6VsNxJ9Uwaqw6AoCl6vd7SbIWWp4KYga1euJdQQwuF34KvwoVpVjN5uYtt62LBmPLuCVmaGtrP1H1vZ8+YeADzjPJz51TOZeP7Eg+7L8ZZ6mXeWnekT3qbTX0lGTWHRTPLTbdhfewFUE0rKoLMTJZMRT3K5RHC6eTNMniyW+y5ZAqWlNIYa+cqTX6G1u5V8Zz7fPPebPP6vx9mc3ozf5SdwWgArVtJ6mmAsSDgRpsJfwYqFKyj1lg5p392v3k08HWd6YDrLpi4b9FhLtIVV21fx+7d+T3N3M2sa1vCvbf9CN3VOLz2dPd17KPWWymW/pwg5hkrZTvbRkedy2XjyyWu58MIH+drXzuRjH5s12k0aU2QflbKdLE8zSnRdZ/PmzdTU1KBp2mg3R8oi0ZYoa1euJdIUoaCmAHW/bIVaugVvQQJXsZddrwbZ/vTf8ZZ6sbltzPnkHGZfNxuL/Qj/BRMJ7CQpGWeCkgLThH+/Lf4OBESSpXQas6iIXTWTCbqTpNqacVx1CVVXfx5vgQgw17Ws486/3MmcjXO4RLmEDy/4MIV1hZy7+lxWF65mzYVraEw1kunIYFEtBFwBlk1bxpLKJQcNUt9sfZMndzyJoijccs4tgxIobQpuYuXalTSEGkjqSWyaDcMwMDHR0NjYvpFbam/h+oUreCcwXS77PQXIMVTKdmOtj3Z2jnYLjk1eXg6vvfafWCxyVvBojbU+Kp16ZNbfUSTTgUsHs33VdkINoSFBKiYQb0JPZmjboZHsTqInddwlbpb93zI844bu9zyofZuP0mmw2aCtTcyYQn+Q2lLs4vHzAqy2biZsz6AX92LRnyDw7zoWT1pM0ZYiLP/Pwq+2/QpPykOOmoP6iApJKHWWcv3Hr2f5p5ezrXMbiUwCh8VBdX71QfekAmSMTH8CpSunXUlNYU3/Yy3RFlauXUlTpImaghrqw/W0dreSMlKoisrUgqlU51dT11XHt9auJLX4Ts7wlsplv6cAOYZK2W4s9FHThB/8AP74x4H7nM7Ra8/h9PSkuPXWWr73vfPJyxvI0CeD1GM3FvqoJB1PMlCVpGOUjCZpqG3A4XcMDlKB5N5WlFCITEqhJ+zFnmunoLoAh9eBzW0b/otUVYmZ02AQSkthyxaRIMkwANhUnsPKC1QarA24kioVPRZsWj7p4hqCqS5e//XrfPvv3ya/Nx8zxySnJEe0tRXIAN3AP8FzgYf5V8wfVpMe2vgQDaEGfA4fXzj9C4MeW7V9FQ2hBmoKatDUwVd8VUVlct5kNFWjKq+Kf3VsIWfHahbPu37474ckSdJJau9e+P73RXqBQ4lE4NlnB993440j2qxjEokkWLLkIV5+eTfr1rVQW3sdXu8YqZ8jSVLWkIGqdMoakqG3Kh/7UXyQdtZ1EgvG8FX4wBTn62nroWdPD05tG55cg97eAgpnFpM3KQ89oxNuDNO5rZOS+SXDexGvFxYvhvvuA1UV671iMfB4aCl2sfIClSZrL9MyfjLpJLZEHKV6Eprdjme9h2///dv44j72+vZS5isTG91DQBqwAeOADuBGoBRRmuYwgrEgv1v/OwC+fMaX8doH9stEk1FqG2rxO/xDglSA8txy7Jp4f1OqRtLhI1O/hgXTl8MhZm8lSZJOFTfcAH/969E956674MtfHpn2HKuOjjgXXfQH1q8X+Rjq6jppaAgxZ07xEZ4pSZI0mAxUh0FVVaqrq2WmtZPEITP0BlxMWjyJKUun4C09csKCZCRJb2cvqViKWHuMTG9fQiPFoLAijGbX8E2chebNAxAJljIGmUTm6Bq8dCk8/zw8+SR0d4uq7n4/q95fSIO1npqMH9UALd4LXi/JkiJe3vUC33/q++TF8wjlhQDoSfXgN/0Q6TtvISJYLQb2APcADxy+KT975Wf0pnuZVTSLS6suHfRYXWcdwViQCl/FQZ87JW9K/88tgMUVwBZupLNzGxUlw5vNlcYmOYZK2S4b+uiWLUd3/K9/DZ///Mi05Vi1tfWwePEDbNq0F4CCAidPP32tDFKPg2zoo5J0ODLr7yiy2Y5iuaaUtQ6ZoTdtEAvG2HD/Bna9sIuFKxYSmB4Y8vzu1m6a1jbRtLaJnc/tJLwzjGbTsOckKZ7QgbvQgjNXR48Z6OSCZ+DD2UiLgNjiOMr/dqWlMHu2uNRuGODxED1rHrXO1/HrVrRYHDOZBI+XeM0UXgyuw9vhZWHDQnS7jtViBQNiqRjeiBcNDTzAvn1NKuAA/o1YEnyIyd7Xml+jtqEWVVG5deGtgxIoASQyCTJGBqtq7b/Ppor/N+Pc4/DYBmZNmwFFteI1MiQyiaN7P6QxSY6hUrY7UX00GoWPfATWrOnfxQGI/af7+P0icfvBOJ1iFvXKK0e2nUerqSnCokUPsGNHFwDjxrmprb2OmprCUW7ZyUOOo9KpRgaqw2AYBhs3bmTmzJky09oYdtgMvTYNb5kX9zg3XXVdrF25lsV3LsZd7Kb97fb+4DTUEOp/jqIp5JX2MmXudirnNOJ096CoBmYqRjKu0tE1h2Cik0QqH4BYMIYr4CK/Ov/oGr5tG/z85yKpUlERzJ1LXWgHQX8nFYkccLhg4kRCbjdvxeuIZ+JcufNKfGkfPV5Rq9WiWkglUqTMFDm2HMg74DVygb1ALXDd0Cak9FR/AqWrp19NVX7VkGMcFgcW1ULaSGPTxIfp+NzxKIpCiaeEFGIyNw4EAdVIk69acFgcR/d+SGOOHEOlbHci++jf/y4WyBzOJZcMTpiU7Xbs6GLRogdoahJLdiZMyOWZZ65j8uQDP2ykYyXHUSnbGftfeTtOZKAqnTIOmaF3P6qmkjshlz1v7uGx6x8j05sh2Z3sf1xRFYrnFFO+sJyJ82Jk3vwXmY5tmFY/8UQxpqGg9O7C7ogzvmIT+ckQ25uuItpdRiKcYNqyadg9R5FQYts2uOYacQne4xFLgPPySLzyFzKb78HqnQw+P1gsNDdvJJKMYFWtzHbNRjVVDE0MGoqugA6GYkABcGCpKw0wgJ6DN+MP7/yBpkgTeTl5fG7+5w56TFV+FQFXgGAsSJm3TJxW0SjIncAOxHLfXkSgGgOssSApVwBPfvXw3w9JkqQxrqvryMe8//0j3ozjZvPmvSxe/AB79ogPkClT8qitvY7y8txRbpkkSWOdDFSlU8LhMvQemAipN9SLntTp2dND7sRcnHlOxp8znvKF5ZSdWSYSLsVb4K27yBSE2b2nglQogz1XQ8n0YJoKiaSfhDoOl7OFyvF/5eU1V+CvmEjlksrhN3rrVvjCF2DnTsjJgZtvhgkTAHDMmIOlNY+0z4dNs5LKJKnvrgcVagpr0Jt1DMVA1VUMi4GZEGvKVKcq9qUeSEcsAXYPfWhP9x5+/9bvAbjxzBtx2w5yEOC1e1k8aTH3bbiPce5xaKpGCHgLiAJ2xIrjOKAaOmoiTGjaMr5v97ACmD78d0aSJOmkcfvtYsHMPjNmwOWXj1pzjtpvfvN6f5A6fXohtbXXUVx88M8JSZKkoyEDVemUMChD73562npoe6ttIBFSn5x8UcblnG+cw4yPzEBRD5iCbF0FsQYsBTUUz0nRtqGNRCiBRgyLVUGxuTENhdDeQrzuZipnb2f8x68dVpImQGTV+MIXYM8eUBSYMgU+/en+hw+cvdzSsYW0kcbv8FPhr2DrrK0kc5LkxHOIOWJkzAwWLNh8h9jfEkFEkYuHPvTTV35KMpNk3rh5XFJ5yWGbvXTKUl7Y9QJ1XXWU5lXxlqrRA/gRk7g6kDB0jK46Av4KFlQuoQlYCdyJSDwsSZJ0Krn1VpEjb6z6+c8vprW1h507wzz11LUUFGRpYVdJksYcmTpsGFRVZebMmTLT2hiWSWREdl/rfv+GJrStF0Gqoim4x7kpnltM5SWVVCyuwFXkInd87tAgNR2Ftlqw+UHRyMnLofSMUvKneFDVJKm4hUS3lVR3EtVixV44jlmL2ghU5TAsmzeLILW7GzIZGD8eli+HvIG9PvtmL0OJEF29XTSGG7FYLMwumo2KSqQgwraZ27CmrJAAXdFxOVwH39diAAngfIYkUnqp6SWe2/kcqqJyyzm3oCgHrhkerNRbyoqFKyjPLWddx2Y6os149BSYJrqeoivajN6xBWduOactXIHXW0oV0AisHt67I41BcgyVsp3so8fOYlH505+u5Nlnr5NB6giSfVTKdjLr7yhKpVI4HDLpy1hlcVhQLSK7r2YTwVpPew+ZRAbNpjH54smoloH/YHpKP3SG3mgdJILgHijDYnPZKCyLkufsJJEqwsgdj6opOHIdaBYdehohug3yj1CGZV+Q2tMDxcWg6yLF48c/PuTQpVOW8vyu53m24VkM06DEXUKhayC74rOXP0vlW5V44h4Ml4Hbe5ClWAbQBuQDB9TiS+kp7nr5LgCumXkNk/MOkYLyANMD0/n24ju5dsdq4vVr6Ak3YhgZVNVC0hXAPm0ZMyuXkOcV86ca4APWAMsRE7vSyUeOoVK2k310eJ5+up6yMu+gbL42m4bNJhP8jDTZR6VTjQxUh8EwDLZt2yYzrY1h+VX5uAIuYsEY3jKx/DayS2Qn9JZ7BwWpcIQMvXoCjAwoA2VYSHRA9zY0i4krUAau/YJCUxXH60cow/Luu/DFL0IsBrNmQSoFbW1w1VX9s6nRZJS6zjoSmQQOi4OzSs/iye1PkjJS5Jg5pDIpbJqNtJHmZdfLRBdG+frzX6c4WYwW0kR2Xw2xBjeCmEnNB+4GDoih79twH83RZgpdhXzmtM8cvu0H6PGW4p53PYumLyfeuQ09kyBjcfBqfjWq3cOkA44PIGZVtw1thnQSkGOolO1kHx2eRx/dwkc+8jAFBU5efPGTMqvvCST7qJTtZNZfSTpGdq+dSYsnseG+DbjHuTF1k56+5A++Cb5Bxxq6cfgMvZoDVAuYaVBskIpAxytgGuAYB87xg4830+J47TBXQTduhBtuEEHq3Lnw0Y/CN74hNi5ddx0t0RZWbV9FbUMtwViQjJFBVVS2d23HYXFwXul59HT30BhuRDd1LKqFQH2ASmsl5odNNF0TdVL3ImZRVcTU5cWImdQDosOWaAv3bbgPgK+e+VWc1qNbzpUAMoDT7sFVMh8DWNv3sgXAgYugrX3Hy4qqkiSNRRs2wGc+A/X1Rz62t3fEmzMiHnpoI9dd9yi6brJnTw/33PMav/jF4fMWSJIkvRcyUJVOGVOWTmHXC7voqutCtaiYhonD58CeOxCMGrpBV10X/gr/oTP0eqvAERDLf21+6HhJBKP2fMhfIJIf7S8RFMd7D1GG5Z13RJAaj8O8eaJm6he/KB676io2Zfaw8rmVNIQaRLIkXwVW1cq7e98lno6jKio2zcZ1k69jypQppM00jtcdVD9Xjcfqgf8GioBWRJ3UHkR238UM2ZMKYJomd718Fyk9xeklp3PhpAuP5m0GwIEYXNKIIHQD0NF339yDHJ/ue0wuaJIkaax55RVR9zQSGe2WjJz/+Z/1fOYzj2GKBPJcd91sfvrTi0a3UZIknfRkoDpMcpnF2Oct9bJwxULWrlxL/VP16CkdT6kH0zQx0gaxYIxEOIG/ws/CFQsPnaHX6oXixbDjfyC8SSzptXqh4CxQD+gnpg6pMJQtA+tBdl++/TZ86UsiSD3tNLj7bnFp/t13wW6n5UOLWbl2JU2RJmoKatD6zh9Px6kP1WPTbJxecjot3S38ufvP/Hrurym3l8PvEct7P4sIUkEEpdcd+X16selF1jatxaJauGXhkRMoHUwVYjlvEDFLuhOR9fcMDr4HNdh3vKyoevKSY6iU7Y6lj/7733DZZWIxzLGYOzf7M/7+4hevcuONT/Xf/tznTuNXv1qKemCiQWnEyXFUOtXIQHUYNE1j5syZo90M6TgITA9w2mdPY9eLuzANEyNj0LG5A9Wi4gq4mLZsGpVLKo9cRiZwAWy6A1KdYPVDwTmgHlD6xdRF4iV3BZQsGXqODRvgy18WQer8+WIm1eGAe+8Vj3/4w6za+zINoYZBQSrAxuBGDNOgwFlAmbcMwzDY0rGFpxqf4vpXrxeRXwlw7dG9P4lMoj+B0rWzrmWib+LRnaCPFzFh+0tEriaAmQzEzPvTgTCwDJlI6WQlx1Ap2x1LH33iCfjQhyCx356Fs86Cs88e3vP9fvjEJ47qJU+4H/3oRb71rWf7b3/962dx110XHtMFTOm9keOolO1G4kKKDFSHwTRNuru78Xg8cnA+CbS+3oqr0EX5B8uZde0sMokMFoeF/Or8g+9JPZCRgbp7QMsBixMchSJgVQMiwZKZFst9U2ERpNasAOcBFULfeksEqb29cPrpA0HqK6+I/ap2O9HlH6R27TfwO/yDgtS98b20dLegoDC7aDYKCqqq4ra6WbNxDcsfWo4HD3wNOETZ1EP537f+lz3deyhyF/HpuZ8+8hMOYwYDM6pVwMFyButAHVABHCSUl04ScgyVst3R9tG//11UDUunB+5buhQeflgM5WOdaZp861vPsnLl2v77vvvd8/jud8+T/4dHiRxHpWxn7tsbcBzJYkzDYBgGDQ0NI5LNSjqx9LTO9tXbAaj5cA0l80soX1hOyfyS4QWppgHvfg86XgabD87+I0z5HFhcogRNZLP42+KCSZ+AOXeCb/rgc6xfPxCkLlgwEKSaJvzud0QtOm8sW8Bf99RS31WPP8ff/9RQIsS6lnUAVPgryLXn9rULHBkH7dvb2WbfJtbYnnd0701TpIkH33kQgK+f9XVyrMOs+3oQEeDHiMRJxYh4uQVIiaaSApqBLUA5sAIoPeiZpJOBHEOlbHc0ffQPf4Crrx4cpF51lQheT4YgFeC553YOClLvvHMxt9/+fhkgjSI5jkrZTmb9laT3qGltE4lwAme+k7Kzyg59YDoqlu3qCZGt11sl9qFu+yW0rgZUmPtjKDxHHD9huaiT2n989cH3pL75JnzlK2Kt2BlnwM9+1r9BqeX5x1gVfobauTGCvnV0vfYMuyK7CPWGKMstw6bZeDf4Lrqpk2vPpaawZtCpHV0O9KhOwpqAmxCbQg/hwDI3U/Km8OOXfkxaT3NW2VmcP/H8o3tj93/rgG8gAtHJwB3AS4g6qY2I7L4WxJ7UZYiZVBmkSpI0Ftx7L3zuc7D/xMF118Hvfw+Wk+gb1fnnV3D77edx++3P8//+3yV88YsLRrtJkiSdgk6iYVWSjqzusTpAZABWtYMsKIi3QOsqaKsVy3eNjCgt4wiAxQ1db4i9qDO/OxCkgghK849QAfT11+HGGyGZFBuZbrtNLPNNJNiUamblqhU0jO/EX1hORWEV/kSYYCxIykjxdtvbJPUkOdYcSj2lnFF6BhZ1v/++BljqLVgsFhyLHGIt7UEcrMzNvvM0hhopcBVw8zk3H/NVcxO4C3gTcCLKs04CaoDliDqpCUR232rknlRJksaOn/8cvva1wfd97nPwq1+BehKuT7vttvNYsmQKp58uLyVKkjQ6ZKA6TI6TZT3PKay3q5emtU0AVF1WNfSA8CbYtBJiDaLsjLtiYM9p+F2IbAHNDlO/DqVLj+7F162Dr35VBKmzZkFNjShBEwzSosVYWVFPkxKlJp6Ddtp00Gz4HD6cViedvZ0k9SS6qaMpGrOLZg8OUgEaoNPoJGAGqP70wXPnbgpuYuXaoWVuEpkET9Y/STwdp8hdRHey++h+t/38Bfg7YjL3R4ggdR8PQ8q1SqcQOYZK2e7APmoYsHkzvPgi1NaKpb37+/rX4a67hlYkG4uSyQxvv93OggUDQamiKDJIzTJyHJVONTJQHQZN05g6depoN0M6Bsloks66TjKJDI3PNqKndYpnF+Ov8A8+MN4igtR4E+TWgLJf5rJECGK7xJJeay5ENonjD0yQdCjr1omZ1FQKpk4Ve1MffFCkfKyoYJV3Bw2ZODXtCpoNkQ14zlyUXDe96V7iqTiaqhFwBtBNnd3R3UwrmLbfLwnGVoPunG6unHUlnryh85Qt0ZaDlrkBqA/VY2KSl5OHTbOxcu1K7lx8J6Xeo/uC8irws76fvwIsPKpnSyczOYZK2U7TNCZPnsobb8ALL4jg9KWXoKvr4Md/97viz8kQpMbjaa688q/8+9+NrF79MS644BBLcqRRJcdRKdvJrL+jxDAMQqEQfr8f9WRc33MSirZE2b5qOw21DcSCMYyMQee2ToyMQdkZZURbooNL0LSuEjOpBwapyS7ofBUwwVUO/rkQ3Sr2qVZef+SGvPqqWCuWSsGcOaLYXkuLmFHVNKJKilqlAX/MQFMtUFwMPT1k1r/OKyUGSTOJRbPgtDjx2D3E03Faoi1U5lViVa0A6Jt0ttm3MUGdwMUfvPigzVi1fdVBy9x0p7rZ3iWSS80pnkPAGWBLxxZW71jN9fOG8fv12QncChjA5cDHhv1M6VQgx1ApG6VSsHbtvsDU5NVXIR4/cuT54x/DzTefgAaeAN3dSS677E88//wuAJYvf5jGxq/gch1lynhpxMlxVMp2I5FMSfb0YTBNk927d49I2mXp+AtuClJ7Sy0b7ttAKpbCV+HDPc6NaYh/v7YNbdTeUktwU1A8IR0Ve1Jt/sFBarpbZPc1dXAUQd5pYr+qzQdta8Tjh/PKKwNB6vveB6edBrt2QVUV9F11qtPCBFMhAr0qeL1gsWB4vXR3tOJu68Jtc3Ne+Xnk5eQRSoQwTINYOkaoN0RKT9Hc2syWri1M6J3AR+d9lJLckiHNiCaj1DbUDilzY2KyoW0DJibF7mLGucehqRo+h4819WuGvQQ4CnwV6AHmIALWk2CSQTqO5BgqZZtIRAzJixbBf/0XPPusctggNT8frrgCVq06eYLUUKiXCy98sD9I9XhsPPLI1TJIzVJyHJWy3Uj0TTmjKp1Uoi1R1q5cS6QpQkFNQX/CpEhTBEVVyC3PpXBGIV11XaxduZbFdy7G66gTiZPc+y130pOw9yUwUmD1Q/4ZoPRd13EERAma6LZDJ1B6+WW46aaBIPVb34LPf14s991vaUQi0knGlcZqapArSs1EUlESmsm4iMG0M88hJ8dLgbOApmgTzdFmupPd1IfqyXPkEdgRYFnTMi6ecTGdMzsP2pS6zjqCsSAVvoHfL56JU99Vz974XlRFZXbR7P7HAq4AjeFGtnVuY37J4XeVZoBbgN3AOERJGvkVR5KkbPfkk/Duu4d+vLwczj134M/UqSdXwqRgMMYHPvAgb7/dDoDf7+Cpp66Ve1IlScoqMlCVTirbV20n1BAaFKSaukl0dxSA3Im5qJpKXlUeHVs62LF6B/OuSIjsvop14ETd20GPi0y/hWeLmdR9FKs4Xk8cvBEvvSSC1HQazjsPvvlNcRl++3YoKxPBq80G3d04tmzDcjqkvR5smkbayBBJhFGsKsWmA3ssCTngsrmYVjCNcm85Wzq28PnTP8+c7XOofqEaj92DfoNO556DB6qJTIKMkUFBYVdkF02RJvbG9/Y/PjV/Ki6rq/+2VbWSMTIkMof4/fbzU+B1RIbfnwN5R3yGJEnS6ItGB9+eOtVk+vROLr88j/POU5kwYXTadSK0tERZvPhBtm7tACAQcLFmzceZNatolFsmSZI0mAxUh8njkYU0sl0ymqShtgGH3zGo9Ez3nm6MtIElx4KrUARkqqbi8DmoX1PPjItLsakWkd1XsYGRhp4G8WTfTJHpd39mWgSu2kGy761dK9aFpdMwfz5UVoqZ1O3bob4e2trA6YSCAmhqokrJEEjbCQbslJnQ1duFCdhtOdjSVsjog04fSoSYnDeZj1R8BM+tHtCB/wQKwNMztI8apsGOzh3sjuymrrMOk4FlGYXOQib4JjDeO37Qc9JGGotqwWE5fHbBv/X9UYAfAJWHPVo61ckxVMpmzz1n0NMTYeJEPyOQDyRr7NwZZtGiB2hoCAFQWurhmWeuo7q6YJRbJg2HHEelU40MVIdBZAOcPNrNkI6gs66TWDCGr8I3cKcJ4YYwALnluYM2T7oCLsKNYTpb8xnnCIjlv84ykeHXzIDFA47ioS+UCIrlv94DysC88AJ84xuQyYgSNNHoQHbfsjIRpLrdEI+LzL6KgrewkMWuau7T6vEleomn4wDk2/0omQRYBr4x6YZOOBFm2bRleB70QBdQDnx0aB9tCDXweN3jPLHjCdq624imohimQV5OHhNyRXDqtDoP+j4GY0ECrgDV+QcvcwOwDlEvFeAG4H2HPFKS5BgqZb9ToY+mUvqgILWiwsczz1xHxYFZ8KWsdCr0UWlsk1l/R4lhGASDQQKBgMy0lsUyiQxGxkC1Dvwb9bT1EO+Io6jK4AAWUK0qRsYgnc6B4sXQcJ9ImtS9QxzgqRxae8DUIRWGsmVg3e/K5v5B6oIFEA5Dc3N/dl9SKcjJEUFqJCLOqyhgtbK0u5jnXUHeMZspAnz2XGypjDg+V7RZN3Tquuqo8FewxLEEHup73a8DVtFH63bXsT6ynifqn2DL3i39TfPn+KnwV9AQauC0cacNrcG6n0HBsP3gV26bEPtSDWApcN0hzyZJghxDpWxnGAZtbSd3H7XZNO6660KuvvpvTJmST23txyndP/u9lNXkOCplu5HI+isD1WEwTZO2tjYKCwtHuynSYVgcFlSLipE20GwaGBDcKDL7+iv9WJ3WQccbaQPVomJxWKBkKbS/AJ3rIBMTy3qd5YNfwNQhWieSLpUsGbj/uefg1ltFkHrhhTBhAjzwwECQCmJPamFh/0xq1G2lbrKPRDKMo6ORD5o+djt30+I2sVqteLoSWCdMIK2aBKPNhBNhKvwVrDhnBaU/LBVZjBZC6swULza8yGN1j/HMtmew54hlypqqsXD8Qi6tupRzys9hb2wvt9Tewvau7VTlVQ3K/rvPoGC4csmQx0Fk+L0R6AZmAd9CZviVjkyOoVI2SSbhH/8YfN+p0kc/9KFpPPLI1Zx11ngCAdeRnyBljVOlj0pjl8z6K0mHkV+VjyvgIhaM4S3zEmoMkepJodk1Cg6y/yYWjOEKuMivzgenHabfCs9fJpIk5ZQAOpiq2JOaCIqZVHcF1KwAZ19mxH//WwSpug4f+IDYn/rZzw7J7ktPD+wWgeiqSoPa6VaCjk4ypo5mbsFQYGK3xjlmKfVamMY8lYw3iSXcSMAVYNm0ZSypXELp26WYL5ts9G9k1eJVPP2Hp/vLyOimzrSCaVxWfRkfmPwBfA5f/8uXektZsXAFK9euZHPHZvwOPwFXAKtqJW2kCcaCA8HwwhWUeodmftSBbyJmVIuAnyAz/EqSNLbE4/ChD8FTTw3cV1Aghuw9e0avXSNlz55uxo0bvDrmiiumjlJrJEmSjo4MVKWTht1rZ9LiSWy4bwPOfCd7t4jMtoU1hYOWAwMYukEinGDasmnYPX3JkvRE33JeFTyTRQkaIyMSJzkCYrlvyZKBIPXZZ2HFChGkXnQRfO978NZbEAxCxX6lbpJJePFFNnl6WXmBhYZcA388SUXEilWx05uKsyNP4Z18AyMR5qbkaagf/SSJCaU4LA6q80Vm39bOVv7nvv9h1fxV7C7bDa3i9AFXgIsnX8xkfTIXn3nxIfcITA9M587Fd7J6x2rW1K+hMdxIxshgUS2Dg+GDBKkAPwNeBRzIDL+SJI0dhgGvvgp//zs8/LAoZ72P0wl//jMnZQKlZ55p4Ior/syddy7mi19cMNrNkSRJOmoyUB0GRVHIy8tDOXC/opR1piydwq4XdtG0tgk9qePIdeCb6Bt0jKEbdNV1UTjFTtW5UQiuFUt9d/wPqDaY8jGY8gVRJ1VPiMe81YP3pNbWirIzhgGXXAK33y6+6SQSYgmwdb9lxg0NtKg9rDwjTVOJh5qUBy0dg1QMI5XGmtIpD2vYCorYNSGHe8qd3Dl7IaXeUmKpGM80PsPjdY+z/t314AUskFOcwwWTL2Bp1VJR69SE5ubmI/bRUm8p18+7nuXTl7OtcxuJTGJQMHwofwf+0vfz94Gqo/g3kSQ5hkonWjotFrw8+qhY5tvWNvQYjwdWr4aFC8EwTq4++vjjdXz4w38lmdS54YYnmDTJzyWXTBntZknvgRxHpWw3En1TBqrDoKoq5eXlRz5QGhXJaJLOuk4yiQwWh4VpH57Gjid3kElkcFW70NO6SJyUNogFY6jpPcw+u56ac1txNEegKSOW90brwJoLgQug14RGIIGYQqwyYV/suWYNfOtbIkhdskQEqfsSGzgcYLGIb0k2mzimsZFVk1I0BKzUGH40iwI+H6bHS1eoBUtcIzSljIq5F1ClqWzu2Mwv1/0STdH4985/k9JTkAFlr8Lp4dNZeuFSzr/q/MFZexWOqo967B4R4A7DG8CdfT9/ATh/2K8iSYIcQ6UTob1d5LV77DHxJxw+9LH5+fDkk6KKGJxcffRvf9vENdf8nUxGJDa54opqLrig4gjPkrLdydRHpZPTSCT5koHqMBiGQXNzM2VlZTLTWhaJtkTZvmo7DbUNxIIxkfHXotLd2i32pU4rwDPOQ7gx3P/YuMldzH/fs+Tmd2JxFYCjAhQrdL0OGNCRgLtugDo/hPpmRy0WCARg8WJRXubuu0UAunQpfPe7A0EqQFWVODYYFCVpWlqI6nFqJxr4LR40Y+BqU0yPk9ZTJJ1Wxs08m4gRpynUxPau7Wzp2MLE3IloqsZE30Qu3XQpl7x6CUVTi2A5cEA3HKk+uhv4BmJ/6sXAJ4/bmaVTiRxDpePNNKGxEV58ceBPXd2Rn3fGGfDBD8InPymG6n1Olj56//0b+NSn/oVhiKQmy5fP4IEHlmG1noRrm08xJ0sflU5eMuvvKDFNk66uLkpLD753TzrxgpuCrF25llBDCIffga/Ch2pV6WntIdYewzAMnPlOzrrpLFRVJZPIYNP2Upj6CVqqB7wzQen74M4kIN4KLSqsskLrFsj1QOVCcOSK2dFgUASo7e1QXAxXXw3f+c7gIBXA6xUB7X33wbhxUF9PnV8n6LdSYTj6DzNMk1C8C2fGpGucj61t64gkI32Pif/o5044l8/N/xzTWqah/FgR6XVvYkiQCiPTR3uAryEy/U4HvoPM8CsdGzmGSu+VYcCmTYMD05aWIz9P0+C880QCpSuuENcPD+Zk6KO//vXrfPGLq/tvf+pTc7j33svQNBnUnAxOhj4qndxk1l9JQsykrl25lkhThIKaAtR9H8ImdGztQLNp5Ffk09vVy7p71rH4zsV4S72w40lo2AW5NQNBKkBPPXSm4R86hDNQOQ4yEUjtgRyfWMJrmrB3r6iHqmnwqU8NDVL3WbpUrD976y3o7CRRqpBx2LAaal8zTYI97dh6EoRtsN2dJJHMoKJS7C6mPLecrt4urp5+NTX5NfDVvvNeAdSM1Ls62L4Mv41AAPgpYD8xLy1JkgSIYfepp+C3v4Xnn4dQaHjPs9tFfrsPfhAuu0ws8z3Z/eQnL3PzzWv6b3/pSwu4++6LUVV5eVGSpLFLBqrSmLN91XZCDaHBQSoQ3hkmGUmi2lQKpxeiaAodWzrYsXoH8z5RCW21YPMPDlKNDMQaYX0KOqwwORdURSRV6m0BTyU074E33xTHV1WJb0FPPgnXX3/wBpaWimzAy5dDIoHD4cdCmp5ML6lEjHSsGyWVotuusKPchTO3kKm55ZR5y7BpNlJ6iu5UNw6LA/4JbAXciA2iJ8gvgJcRwenPgKHFfSRJkkaGYYgkSD/6Eaxff+Tj3W44+2w491zxZ8ECyMkZ+XZmiwOD1FtvPYcf/WiRTLojSdKYJwPVYVAUheLiYjnoZ4FkNElDbQMOv2NQkGqkDfZuFuVoCqYWoNlEMOrwOahfU8+MixPYEkFRB3V/PQ3Qk4CNpljuu+/qs5YDmW5o2gLrd4j7Jk6EuXPFerM1a0Qg6jlEptxx48BqJVSci8Xhwr63kd1qhsJelYTFoKVQJV5cwDnVi/DYBp8jGAsScAWotlfDr/ru/AyHrQdzPPvoP4GH+n7+PiAr7knvlRxDpeFIp+Ghh+COO2Dr1kMfV1AwEJSeey7MmSNSCbwXY7mPXnjhJPx+B6FQgh/84Hy+9a33jXaTpBEwlvuodGqQWX9HiaqqFBcXj3YzTmn7Mvu2bWijq76LwmmFAw+asHfzXvSkjs1twz/J3/+QK+Ai1ryH2LZd2JJdYPWD3dc3Y9oGkU3QqkOPDcYP7CGNqgZ1apREaCOOgIWq3Ml4Z8wFRREZOBobYdu2gZSR++lJ9VD7x++was5u3io2cRYHSAX97NS6iVnz2a1EUGx2Lpy0GLfNPei5uqETToRZNm0Znvs8EAYqgKsP//4crz66HljZ9/PngAve8xklSY6h0pHt2QMXXij2oR7IYoErr4RFi0RgWl0thuLjaSz30dmzi3nyyWtZt66FG26Q9VJPVmO5j0qnBpn1d5Tous7OnTuZOHEi2slYFTyLHZjZt7erl8iuCL2hXnLLcvGO99K1o4twQxiAwMwASt+sqMPWSWHx63gr1uEM9YK5GxJBsLrA6oN4k3gRrQiIgEWlxZpmlb2LWmeUoF0nU6phsToJ5IRYnNrK0kQ5pVanyAacSPS3Uzd0Xm1+lVXbV/Fc479JNW2G3AxKXikzJ5/NGeedweN1j/Ns47OAlaq8KQcNUuu66qjwV7DEtmSgcOlNHPF/6vHooy3AzUAG+ADw6WM6iyQNJcdQ6UgefHBokJqTI3ZYfP3rMNJVOcZSH9V1kXBv/yRJCxaUsmCBTLJzMhtLfVQ6Nem6ftzPKQPVYeru7h7tJpxyDpbZ1+F3iFI0KYPObZ20b2xHQUG1qARmBXCPE8Gf29nElPK/kWNvIx6xk3FUYTfiYKRElt/YRlBUcI6HgmmgrWOTGWGlr4MGh44/AxUxFastQNrhJqgkuD+njhdse1gRms50iwUcDuo661hVt4ondjxBV2+XaHg0SkVUZVFvOZM+91OcOV4cFgf1XfU80/AMuqnjsXtI6SmsqpW0kSYYCxJOhKnwV7DinBWU/lcpGIiipWcM7/16L300hsjZFEHka/ouMsOvdHzJMVQ6nK6ugZ9VFW65BW68cXAJmZE2FvpoKqVz7bV/x+u1c++9l8lkSaeYsdBHJel4koGqlJUOldnX4XNgdVrRUzrpRJpMPINiUSg/pxz/ZLHk12HrZEr533DY99K1txjVYsXhz4PeMohsAT0uglQUwIDcNC22blb6YjTZoaZbEXtc3Xlgz8UGlBkuxhlO6iwRfmB7ja94ivnt1jvYuH5nf5t9Dh8XV17M/AeeoW5vgtozXPz5lR+TMTKYpkldZx0Oi4MPTP4AsXSMxnAjGSODRbUQcAVYNm0ZSyqXUPpGKawDbAxk/B1BBvAtoAEoRGb4lSTpxIpEBidNcrtFIiVpsEQiw1VX/Y3HHxcFY30+Bz/5yQdGuVWSJEkjRwaqUlY6VGZfzabhLHTSvqEdFFBtKlaHCFz3CeS9gdPRTrSnDD2VwjfR25dcqRhC68WsqmoHexGEg9AWZFVViganSU3ChpajgmYD60CSI9M06U3H8fX0skXpZuX4JC1xDatm5dzyc7m06lLOHn8229atZqW+kobyFP5ANRW+MqyqlXUt60gZKRRFIWWkuOmsm1BVlUQmgcPioDq/Go/dA0ng530v+nGgZOTf618CaxFx8U8RwaokSdKJ8OijcMMN0No6cJ/bfejjT1WxWIorrvgzzzzTCIDDYeGCCyqO8CxJkqSxTQaqw6AoCuPHj5eZ1k6QQ2X2BUh0JYjsiogbJriL3Rhpg2hLlLzKPGyOBAX+DaTSLpKRNHaPndxyLxg6hN8BxQqKAWkFws1gGkSdUDvZjr/DRIubYLeBrQBTtZDMJOhO9RBPxTBMA0+vjtWrsWWii9vOuJHLp16O1+4FoCXawsonv02TI0WNdzJawSQAOns7aelpwabZeN+E97E7spt71t3DnYvvpNR7wJ6iB4E9iOKlnxj+e3asffSxvpcEuJ0TVqZVOsXIMVQ6UGurCFAffXToY1//+olvTzb30UgkwdKlD/HSS7sBcLmsPPbYRzn/fBmonkqyuY9KEsisv6NGVVXyT4WK4Vmis66TWDCGr8IHgGmYJCNJ4nvj7N2yF1M3cRW5UC0q6Z40qlUlHUuLBEvlzVjMTiJ787C5bRTPKcZmS0LHBkh0QocCe91gj4MHcFioc0AwpVDhLoTGNPSaJNI9dJoxUmYG1QRb2sChK6heP5PnzqPNmmBq4dT+IBVg1Ya/0hBupCZmR5s/RbQdk7fb3wZgQu4E8nPy8dl9bOnYwuodq7l+3n61WNuA/+v7+UbgKOoAHqmPRoE6IAE4gCqgEfhh3+PXIxIoSdJIkGOotI9hwL33ij2o0ejgxyZPht/+VmT3PdGytY92dsa56KI/8OabewDIzbXzxBMf46yzxo9yy6QTLVv7qCTtI7P+jhJd19m+fTtTpkyRmdb67CsXk0lksDgs5FflY/cen52N3Xu6iXfEySQzJEIJEqEEpmH2P+4br1L1PgNTjxFtTdGy2UW41SBUH8Jr60KtNPFXFpFbmoMtsw32NEA4DTsTkMoB1QTyoXIqFOSQ2LORjF3FWrqQZHEPrZtexdoWxJ4ycKBgs9ixeXKxTZiEUl6OmeOkuWMzicxA1t9oMkrtqw/hT6lovjzIE/tld4V3EU6EsagWZgRmAKCpGj6HjzX1a1g+fblY8gvwC8TS33nAhUf3nh2qj7YAq4BaIIjI6GtBxOg7ACtwCSJQlaSRIsdQCURt1Ouvh7VrB9+vaXDTTfDd74pMv6MhG/toW1sPF174IO++GwSgoMDJ009fy9y540a5ZdJoyMY+Kkn7k1l/R1Fiv1Ikp7IDy8UYGQPVouIKuJi0eBJTlk7BW+o98on66Cmdjq0dBN8N0v5OO8GNQboauuhu7kazaf2lZlSbSkF5kilztjOhejt2awRF1TGnavSe5aHh3UnknXstxdUTyet5AU1th2gDdCdhZy90K6C5wO6AqdUwaZL4dmSkcNh9WGzQEN3Nlr1bSPlTWL1eaqwlTPSMR7PaINcHVisAaT2FRbXgsAzUXa1r30ywrYGKpAVmTAYUejO9bNor6i3UFNRg1wYC+XKlHONdgxZrC1PLpoq0u2sAFVGO5hhWTxzYRzchaqI2AH5EOVYrYlZ1DdCN2I/6kb6XlaSRJMfQU9tDD8EnPwmp1OD758+H3/0O5swZlWYNkk19tLk5yqJFD1BX1wnAuHFuamuvo6ZGZhE4lWVTH5WkE+GoA9WdO3fyz3/+k5deeonNmzfT0dGBoigUFBQwbdo0zjnnHC6//HIqKuTeiZPNwcrFqFYVI20QC8bYcP8Gdr2wi4UrFhKYPrSmgGmaxNpjIiDtC0w7t3WipwdfgbE6rTj8Dqw5VnwVPnLyc8grbGPKhMdwOtpJp93EE0WYpoai6KhGB9NPex1/ZQYt7zQI7oBEHHbp0KGDlgM2m1hXVl0tft4nEaTMXUhrUx3tnTuwaTZy7bmcNu40fA7fwd+HWJCAK0B1fvXAaV5/hUwmidWWC6WlhBNhXm5+maSexGPzMClP7Ff1dfqY8cYMpm6YimWvhXGrx4ETEU2qwDWIdbnvUQsiSG1C7Dvdd+3VBDYgZlZ9QBHwM+BOQFbgkyRpJLS2wn/+5+Ag1emEH/wAvvQlsMhL5kPY7RqaJq5Ylpfn8swz11FZmTfKrZIkSTqxhv3x8Pjjj/OTn/yEtWvXYpomkydPZtKkScycORPTNAmFQmzYsIFHHnmEr33tayxcuJCbb76ZSy+9dCTbL50ghyoXAyITr7fMi3ucm666LtauXMviOxfjLHDSsaVjUGAa74gPObfD56BoVhGBmQGKZhZRWFPIO394hw33bcBT5sGZE2LKBFFupjs2nv3n/wxDIx7JxZ6Xj7b3GdjzFNQbYIlD2AlWJ5SVwfTp4HINel3TyNAR3s59EYOkoWOYBjUFNVQVVKEeYo5RN3TCiTDLpi0bWLILOGqfw2JRSE8spzMeZF3LOnRTx2vzctb4s1BRGdc0jov/djGF7YX0uHpoLmymbEIZtCI2kQLUI6ZCpx/jP1SfVYjYd/8gFWAzIleTCpwF5AJbgNXI5b+SJI2MH/4QensHbl90Efz3f8PEiaPWpKxXWOiitvY6Pv3pf/Hb315KeXnuaDdJkiTphBtWoHrmmWfy9ttvc8UVV/DXv/6VxYsX4/UefHlnNBplzZo1PPzww1x99dXMnj2bV1555bg2+kRTVZVJkyaNyCbhseJQ5WL6maAndKxOK00vNvHXD/8VDDB0Y9BhiqpQUF1AYGagPzD1lHqGZAqbsnQKu17YRVddF+XnvY7T0T4kSDVNk2Qoht3WQ669DdoS4ttQvQdKvDDBDpPOgbyhyQcivV3s2fMCDckMz6dKWVg+k3g6Tmdvp9gPe5BfUTd06rrqqPBXsKRyycAD27ZR9VYTgdlWNrh6aG7eAUDAGeCMsjOwqlZ8nT4u/tvF5O/Np3V8Kz2ZHjF7q+WKLEc2YBYiodJKjnqKc/8+GkXsSfUzOEhtArb1/XwasO/avA+xFHg5Yu+qJB1vcgw9dTU0iORJ+8yeDatXQ7Z1hWzsoyUlHp544mOj3QwpS2RjH5Wk/Y1aMqXzzz+ff/7znxQVFR3xWK/Xy5VXXsmVV15JW1sbv/jFL95zI0eboiiHDMxPBYcqF5PqSdHd0k1vVy+9Xb3oSbGEV0/pJKNJcifm4g64CcwSAWlgZoDCaYVYHEfudt5SLwtXLOTVu54m1/I68W47BgqKKrIAZ+JJ9HgPdnsPxb5ObFujkLKC1wlTXTD3O+B8AWKNEO8FRwAUK7qeoHnvW0SiO2k2bPyFCq5f+E2WTV3Glr1bWLl2JZs7NuN3+Am4AlhVK2kjTTAWJJwIU+GvYMXCFYPLyvzlL7gyKumiQrZHG3FYHEzyT2J28ez+mdkZb8ygsL2Q1vGtGIpBUk8y0T8R2zYbpBBTm5MBg2Oa4ty/j9YhEiftv/i+BVjf93M1sH++yAAiA/A2YP7wX1KShu1UH0NPZf/1X5DJDNz+4Q+zL0iF0e+jr73WzA9/+CJ/+tOVuFy2Iz9BOuWMdh+VpCMZtfI0K1euPKaTFxcXH/Nzs4mu62zevJmamppTMtPageViAFLdKXb+eydGZr8ZUxUcuQ7sPjt6QmfRykVUXlR5zB03MD3ABbeWYb5usHe3n3RvEtMwUIwEFq0Hn7+H3FgIW7MOmhucOVBZBQU6zDsNci6F1tXQtgZ6GoklI+yMNtOayvCqnodRfBF3nfcDAi6xn3Z6YDp3Lr6T1TtWs6Z+DY3hRjJGBotqIeAKsGzaMpZULhkcpIbDxNas4tYZu6n3+7Cn7OQ785kZmNkfpDriDqZtmEbMHcNQDCLJCF67l3KlXESIALMRCZQ0jmmKc/8+mtA0MojESSYiAN3cd1wpQ2ulWhF7VmWKBmmknOpj6Kng8cfhySdh/6SPug4PPjhw++yzYcmSoc/NBqPZR59/fieXXvonenpSLFv2Fx577KM4hnFBVzq1yHFUynZjKutvY2PjSZVQaSTe/LEik8iI7L5WEXiZuknLay0YGQN7rp3c8lxy8nJw+BwomoJpmnRs7sDuth85SE1HIVoHegI0B3irwDpwxdCdZ4GiHJwTJ5Jo24kR3Y2aSuDo6Ebr0MHiALsLpkyBqiqRyTeyWZzPWQqV1xMvuZyHX/0hL7Q9TdIsIGofx5fO/SaLKhYNaV+pt5Tr513P8unL2da5jUQmgcPioDq/etCe1H32PPx/3DhtO/X5Ct7cAF+du4JnGp9hS8eW/lnZ8uZy3GE3TXlNxBNxvHYvc7xzcG10iUiyDCjY76THOMW5r486EP+xE8BGoLnv8UpgJkMTCqf7jncgSSPnVB5DT3ZPPAGXXXbk4370IxiBC+7HzWj00Sef3MEHP/gXEolMXxsMMhnjCM+STlVyHJVONcc9UH3nnXe44447ePjhh0kdmIdeGpMsDguqRWT31WwabRvaSEaTaHaN8eeMH7KU10iLkjWHXeIbb4HWVdBWC4kgGBlQLWKJbvFiKFkqAk3VDpketM5ncek90JWA9gyoOWDNgQkToKZmoPiekRLn0UTY9VLTS/xo7Y9o72kH3FxWdRlfPeureO2HXz7jsXuYXzKfaDJKXWcdb7e/jcPioCq/qv+5m9s28s23foGnp4bz7NXcMP7bVEyu4AOTPzBoVjanI4d0Mo1iVahWqinfU47rrb7EThow44AXf49TnFWIlcTPIsqyKsAcBi8F3l8QERtXH+JxSZKkQzEMuOWWIx/3gQ/AeeeNfHvGkn/8YytXX/030mkRmC5ZMoWHH76KnBzrKLdMkiQpOxxVoLpp0yZ+85vfUF9fj9/v56qrruKDH/wgAOvXr+fb3/42Tz31FFarlWuvvXZEGiydePlV+bgCLmLBGKZuEtkVAQVKF5QeNBiNBWO4Ai7yq4cmMQIgvAk2rYRYA9j84K4AxQpmWgStDfdD+wtQfhU0/x16dkFHAnYaYNrB4oSiIpgxA3IPyISYCIIjQMga4KfPfpsndzwJQImnhG+/79ssKF0wrN+5JdrCqu2rqG2oJRgLDloCvHjSYoojxWz+zZt88e2fUhobR+X407BttEMASheXcv3SgVlZi9vChEcnUF1fjS22396jYmAqojzN/t7jFOceRPLgMOAFzkTUSz0Yve+4ZchESpIkHb2//AU2bhy4nZ8/JME606bB739/YtuV7f70p418/OOPousmAFdeOY2HHroSm00u6ZQkSdpHMU3THM6Br776KhdccMGgYsOKovCzn/2MTCbDLbfcgsfj4bOf/Sxf+cpXGDdu3Ig1+niKRqPk5uYSiUQOuUndNE0SiQQOh2NENgqPBW/e+yZv/PcbRFuiYEBBTQEFUwuGHGfoBh1bOpj7ibnMu37e0BPFW+CtWyDeJJb5Kgf5UE5HIbgWMjGoy4X6dqjWIeSGXD/MnAmBoXVaMXXM8GbedZ/OjfXvEklEUBWVj874KJ+b/zlyrDnD+l03BTexcu1KGkINB02qZLxr8KknP0Xl3nKsRKkuK8E6a7oIMIOIyK8C+A/gLeAfiARJBiIonQhMAtyHaEAz4AJ+z7Cjx3199FWHg+8oCtG+ZoxDLPc92FcfHZF4qRxZR1UaWXIMPTml02JByw6R6BynE+rrobh4dNt1LE5kH/3979dz/fWPse/b17XXzuL//u8KLJYszDIlZQ05jkrZLhKJ4PP5DhtTHa1hz6h+73vfw+Fw8Oijj3LuuefS2NjIJz/5SW677TZ6e3v52te+xre+9S1yD5zhOknYbKd2Fr6KCyp44QcvkI6n8Y73UlB98CC1q64Lf4WfyiWVBz9R6yoxk5pbMzRINVIQ3Qbd9RBOQqQHNunQPBEmhWFuHkw4QyztPZCpkwy9yzvdYW5r+jcR00ZlXiXfed93mB4YflHSlmgLK9eupCnSRE1BDZo60EaLZsFsMfnUk5+iJDTu/7N35vFR1Pf/f87MntnsJptjyQUkBMIlcogXAraKoqgVrQdar/Zb22r9etWj6K/92lZFvGrtYau29arVelRtwQMsFalXUVHkCpBAkoVkc+1usvfOzO+PyUkCBEjIJnyej4eG+ezM7Ocz+85k3/N+v19vKjI2cnqTE3PZbCO/1oLh7ckYebdvtm1bMBzXEEbzUus+JnCQIU4deN5q5bG27bnAFcCjGEJKboz0XjM9/enFCCdVMPAc6ffQoU5NDXi93cdWrux0UgFuuGFoOqntHA4bffTRj7nhhrc6tr///WP43e/OQpaF4yHYP+I+KjjS6LOj+vHHH/PDH/6Q+fPnAzB58mQefvhh5s6dy80338z9998/YJMcbDRNY/369UyZMuWIVFrTdZ0vnvkCi9NiCCilWwl6gzg8DmSzUbsa8oWI+qO4S9zMXjwbV2EvT1ISQaMm1eLu7qRqKrRWQMsWaI3AjojhRWXaYYIFTrsOzj4Ryh+C4Cbj+LZ2M+gJ9IiPxsA2Pm1p5o+xXPyyg2umf5crpl6BWTmwWp9lW5dR0VzRw0lNaAk+rvmY0z8+ndFNo/FlV6AkdGry05hotxve306gAmjF8BxjwAjgbgxP8Mdtr5ex7xBnCXAAyphx4Oe6zqvRKGl2OxcBP2p7i6UYnW5WYOgzJTF+6T0YvvAChJMqGHiO9HvoUOeRR+Cmm/a9T0YG3HrrYZnOgHA4bFTTdN55Z3vH9s03n8CDD54uomOCPiHuo4JUR9P6Xwiuz46q3++nrKys21j79imnnNK/sxKkFFte38LW5VuxOCzMf3g+waog21dsx1/pN9SATTIOj4OJCycydsHY3p1UMNR9oz6jJhVA1yHiBf9XEGmFqijUqyDbwGKBEaNglA2OPQ6yp4Njabd2M2hJIlqC9QEfb4c0PlDzKPAcy/Nz/x8l7gNXnA7GgqysWInb5u7mpIYSIT6o/gA9qPP1bV9Hcuu4wnFCikSNQ6d0XRxLlcXwAsEIWxYDdoxQ5iSM6OhiYAn9GuJsAm4BvpQkZF3nNk3joi5/wAox2rEuwhARjmKUvo5H1KQKBIL94/XC4sX73++228DtHvj5DGVkWeKlly7k7LP/yuzZI7nrrq8JJ1UgEAj2QZ8dVV3XezzBad+22URji+FKY3kj/7n/PwAc+8NjGTvfSOmdvGgyjVsaSUaTmGwmssdnY7XFDGfU13urGdSooe4rmSHaAIH1EGkCbwx2xQGbIZRUUGAIJTkcna1moKPdDKMXkfRvYPnmV/n71jfZnswEs5P/nfW/fHPSN5GlA6vzaVf2XVe7ju1N25mYO7Fz/ZFGPqr5iJga4/jm4ylNluJ37ISIjl22EQypBOoC5CZzDeWiUmAkxm9WnO5tZibTryHOrcBNQC1GueuNXi/fLC3tdV8nB9TpRiAQCAC4+26I7keBfMoUuP76wzOfoY7dbuatt76F2SwiYgKBQLA/Dkj1d/ny5dTW1nZsh8NhJEnipZdeYt26dd32lSSJm/aXKyRIaeKhOCt/vBI1rjLypJFMvXxqx2tWp5WCmQXGRtgLu57ef6sZxQZ6Eho+gEgd1MWgOgaqBWSnIRc5ZYrxE3q0mmnnq+ad/GL1L9netB2wMnvUbBbPXsyI9BEHtL49lX2bIk3sDOykOdJMUUYRZtnMV/VfoekambZMTsg5AatmQW1tBkA2ZaPHIySVJMzCSPPt+nC8tzYz/RTiXA3cCUQwxJAe0jQC4fABrV8gEAj2xfbt8OSTndvTpsFDD3Xfx2aDY44B675q749QVFXjpz9dxfe+dwyjR2d2jAsnVSAQCPpGn1V/ZfnAolSSJA2JxsR9Vf3VNA1Zlo+YNB1d13n3jnepWFFB+oh0zn/+fGwZvUTO92w106V2lKgP4n5wlEDZtUbK7uZfQTAOlQmItjmh6U4jglpQ0L0bfLgGTA44/o9gdhJJRHhs7WP89au/ous6mbZMbp11K6eXHniNT2/Kvv6onw9rPsQkm2iJtRBTY9jNdka6RnJswbGUbi/lm78/hwb9S1TZjCblEjS1cGLeieSW9tIApj2i+iD9Fs7UgWeBX7f9+zjgPsB5BNqoYOhwJN5DhwOXXw7PPde5/eabcMYZgzefgaS/bTSZ1Ljqqtf4y1/WM3ZsFqtXX0V+vii4EBw84j4qSHUGVfW3srKyX95wqBKPx4+oFOeNL2+kYkUFsiJz6n2n9u6khr2Gkxqu6qniK1kgrQisHqj/D6x+B5rd8GUcCmOQTAd7GkycAGPGwJ4PQnTVcHKLFoLZyUc1H3Hv+/eyq2UXAAvGLeDmE28m05Z5wGvbm7Jvpi2TNHMajZFGYmoMVVcxySameKZgkk3UFdbRItXgDI/Ab5eJWKLYbXYyiveidO3DSOkdf8BT7JU4RonrP9q2L8CoTzVhOK1Hmo0KhhbCPlOfzz+Hhx+Gzz4zJAQ2b+58bc4caNNSHLb0l43GYkkuueQV/v534wJWVjazdu0uzjmnn/4YCI5YxH1UcKTRZ0d19OjRAzmPlEbTNLZs2TIsldZiwRiN5V1qTcuyCXqDfPTwRwAcf8PxjJjSS0ptMAjv/hYq10FWKSgqpHe5NroOoSoIboRwKzS1wpoQ1BRAph8muKB0Nlh7ueHqqlHrml5CMHs2D//7Lv5Z/k8A8tLzuGPOHcwaOeug17w3ZV8kCCfChONhFFnB4/CgairVwWom5kwkmqxjU/YKZjV8F39aPTFzjOKRxViUXuTiD7LNzN5oBm4F1mF0v7kFuKjL68PZRgVDH2Gfqc2aNXDvvUbEdG/cc0/3hJfhRn/ZaCSS4Pzz/8Zbbxl9eywWhb/97QLhpAoOGXEfFaQ6g6r6C1BbW8vTTz9NZWUl2dnZfPOb32TGjBn9PinBwBP0Btm6bCsVKysI+UId6r12t52miibQofT0Uo665KjuB3q9sGwZvPMmbF8DySSYmyDLBscVwaxR4AqBfz1E/FAThdoEOM0w3gITzofLzoS6JyG0FdTe04V1RwkfOOfys3/eQFOkCUmSuHjyxVx77LWkmdMOft17UfYNxAJ87P2YuBrHpJhIM6fhtDgJJ8J4g17GZo3FvH07X+VEGettIiOUiVqgMSpzVM83Ocg2M3tjO4Zo0i4M0aT7gBMO/bQCgWAYoOtQVQWx2IEfu20b3HcfvP/+vvc7+2wjoirYNy0tMb7xjRf49793AGC3m3jttUWcfnrvIncCgUAg2DcHlPp73HHH0dTURHtZ69KlS3nmmWe49NJLB2yCgv7Ht8HHmiVraK5oxua2kVmSafRDjWvsXL2TkC+ELdPGpAsnda+D2LABliyBigpwyDBCAavbcMyawvDGl/DBOviGAmYVamKgWUBxQXoWjHXBSRdC9kwoGNej1Uy7AFMw91R+uXMz/9jwOABj3GP4f3P/H0ePOHqf62pX740mo9hMNsqyy3BZu+fIlzeW4wv5KMksQUdnV8sutjdvpyHcAIDT4uT4wuPZ1rSN5mgzZtlMKBGiOegjc1uUrzKa8Z70W36w/YccFzoOh8/RL21m9sYa4A4gDBQBj2B0vhEIBIJgEM4/H959t3/Pe8ophmQAwKhRRusZwb5pbo6wYMHzfPRRDQBOp4Vlyy5lzpwjNxtNIBAIDpU+O6p33XUXLS0t/OpXv+KUU05h27Zt3HDDDdx8880sWrTogMWWhhrDJc0i6A2yZskaAlUBciblYLFEcdgrUOQEzVURiCuY02ykj0jnk19/gqvIZfRF9XoNJ7WqCiZNgng9NG4DLQZqK6SHwa5DVQL+BMy2QoYTMjNgylHg8UBwU6+tZghuATWKJlv4x+5yHvrkccKJMCbZxHemf4erpl3Ve3ptG3uq9ya1JCbZhMfhYd6YeZw17iwKXYbHGE1GiSajVDZXUumvJJw0lHIlJAqdhRw94mhsJhvZ9myqglXUBGtoibWwvWI9WeZcPNF0Tj7uFEp/WorjfUe/tJnpDR14HsMx1YFjgPuBvVTDAsPHRgXDE2Gf/UtTk1EzunZt/5xPkuCCC+COOwx13yORg7XR+voQp5/+HOvWGV0R3G4bb711Gccdd4hPKgWCPRD3UcGRRp9Vf0tLSzn77LP51a9+1TG2fPlyzjnnHL788ksmT548YJMcSPqi+juc+PTxT1n31DqKpknk5X5GjnsdVnMAXU0QaU4Qbk2nKTSDFuZQ84XO9KumM+PqGfD44/DUUzBxImgtRn/Tlq2AZHzDiWvQqkNMhyYdZjjhsmNhdDHIktFqprUSpj9oRFT3YKd/J/e8fw+f7f4MgCkjpvCTuT9hjHvMPtfTm3qvWTaT0BL4Qj78UT8l7hIWz16MWTHz0AcP8cJXL2BSTMiSjEWxUJJZwhj3GOwme4/zh+IhNtVt5Jq/ncG06mmMnzIe56tTjUJRgBYOqc1MbyQw0ntfb9s+D7gNI2grEAgEdXVw2mmwfv2hn8tkMtR9b78dxosyyoPi4Yc/5Ec/egcAj8fBihWXc/TRB9YuTSAQCIY6A+FT9TmiWl1d3aMedcaMGei6TkNDQ79MJlXRdZ2WlhacTueQlgSPBWNUrKxgRHEDk8e9SZqtjkQindawh2BNCElXceVEmTDmI8LRShL+M9m+YjuTF4zE+vY/wRqC+lWQbMGI8wGaDiEFohqggEmCHBuEM8BTaDipYNSe2jzg6v5NKKkleeaLZ3jysyeJq3HsZjs/PPaHXDT5ImRp31H6van3AlgUC0WuIvLS8/jE+wnnvnAuaeY0FElBlmVsJhtTPFMochWhSHt/QtkcbaZ0ayEXf3EeTlMMnpzQ6aSC4ZT2U+sZMLKGbwM+w3ibmzBaru7P6oaLjQqGJ8I++4+aGjj1VCgv7xzLy4MHHzR6mh4IJhMce2xnmu+RzKHY6E03nUBlZTN///tmVq68ggkTcgZoloIjGXEfFaQ6fYx9HhB9dlSTySRmc/eYTvv2UOiXeihomkZFRcWQV1prLG9Eb61h6inLsVkbaAmNRI3rRBoj6EmQzGZ0WxYtIR1HmpepM5bx4VtfI/jES+RuXQV5FkjKRhsaxQPNDaDXQ0wFSQanEzIzQQN2tUJVACbm9mg1087G+o3cvfpuyhuNb1wnFp3I4jmLKXD27VvTXtV7gZgaY4d/BxXNFYQTYaLJKLlpuVwy5RJMsomVFSspcu7bSVU1Ff9OPws/OwdnwgLXbYac2Qd41ftOBYZj6gUcGK1o+qptPFxsVDA8EfbZP1RUGE7qjh2dYyNHGjWq48YN2rSGBYdio5Ik8atfncmdd84lLy99gGYoONIR91FBqjPoqr9r167t1r+ppaUFSZJYs2YNfr+/x/7nn3/+IU9Q0Dd6azNjdVm77ZOMJikoXIfDUUdTQz6xQJhkJGm8KIHD40CSJVBjhJotOB1byPeY0eqDoOqQlgvWIqgJwfZKkBOQpxhtaVx5YGmrI5V1UDXDge3SaoYCQwI3mozyh7V/4C/r/4Kma7isLm6ZdQtnjj2zz08J96be2xJvobyxnOpgNZpu/MLYTDby0/MZ4x7D4tmLCcaCVDRXUN5UTllWWQ8nl0Qc1d9M+e5KSsrzWLDpKCj4M/zwxwfxyfSNDzC0l0IYpa2/BPad9CwQCI4UdB3eeQf+538MuYB2SksNJ/UI7h43KHz1lY9AIMpJJ3WqvsuyJJxUgUAg6GcOyFF95JFHeOSRR3qM33XXXT3GJEka9pHWVGBvbWYcHgdj5o1h3FnjDDEkQNJayBuxHv8umVBTxDiBBOY0M7YMBYWg0fNUN5zXWMxCUWkNiussyJSh0QIVmyAeN47NyIGR04GdkAxC0gqKHZI6KIDeAIEGw0mdtBjSCvmv97/c8/491AQNZcT5pfP50awfkWXPOqB1d1XvbSemxvj3jn+T0BIAuG1uSrNKKXQWomoqlf5KtjRuYWbBTBbPXsySNUvY2LCRAq2AKYEp2Fsh0rST9doadpt8lOy2sHgNFLb8BKZ7YADsWQdewHBMNWA68ACQ2e/vJBAIhhqaBq+9ZvQ4/fTT7q9NnAgrV4q03cPNp5/uYv7854jHVf71ryuZOVN8AAKBQDBQ9NlRXbVq1UDOI+WxHWjxz2Fgr21mEhohX4h1T69j5+qdHPO9Y6j7so7aVf9k2hQ/zQ1ZIEtYnRasLiuy5odEoMuZZTClE4pk4coJ4EpzwfadEIkYUVOXy1D+zc83hJSSeRCqgojXqF+tjxh9U0s8MGYBFCwgqDj51Xu/4PUthkSQx+Fh8ezFzBl9cM35oskoSS2JWe5MR69oriChJXBanByTfwxuuxuprbpTlmWSWpJo0lAdnuyZzAOTHmDrc1sx/cuEvd6KEkmi6nFOsy8kadnIOH81+U3lYP0v1GqG2sjixdBPwmFJDCXfV9u2v4ERVT1Y0aRUtFGBoB1hn30nkYAXXjCE1jdt6vn6tGlGhDU397BPbVizPxv9z3+qWLDgeYJBo2ntT36yijff/NbhmJpAAIj7qODIo8+OaklJCbm5udjtPZVRhzuKojBhwoTBnkY39mwzIyudCj+KRcFV5MJsN7PzvZ1se2sbWcUmxh1ViSMzRkKNY3K5QLIYDmq7k6qkgckJJju6DsnmAPa0RizvvgBWq9FRfsYMI8+sa4quyQEZE8E5FiJNULcNzlsIX78dzE7+Vfkvlv5nKY3hRgAunHQh1x13HQ6L46DXbzPZMMkmEloCi2IhqSXZ3rQdgEm5k3pEaBNaApNswmZqu8lvgPwl+eRX5JOwtRKQ/kNCbsFszyCjbjTm0CSQ6sD+E8jJhpkzYetW45vj0qVQeGhtBwLA7cBaDKGkG4FL2b9o0t5IRRsVCNoR9tl3mpuNOtTPP+/5mskEV15pCCdlZh72qQ1r9mej//pXJeec81fCYSNjZ86cUbz44gWHa3oCgbiPClKegaidPiBH9dlnn+XSSy/t90mkOpqm0dzcjNvtTpl+sVuXbaW5ormHk4oOLbtaaNrWRKQxgsPlp2zyBibN8pI/IYJFbyHNFSIR2008mUE0qqNiAksWmI0unXo4TMwXxCaFsatRSMuAH98Aq1cbBVKaBr0Zoy5DVROMnwYXXkNDIsbSVT9n1Q4jGj86czQ/mfsTpuVNO+T1l2WX4XF48IV8FLmK2OHfQVyLk25J71WMyRfy4XF4GJ893lArWgJUAZPAXF5NTiAC7lxolSAWACUIWhpEr4HCV41viGVlRnhj+XK4+uqDnvsODNGkaiANuAc4uLhyJ6loowJBO8I++84bb/R0Um02+O534dZbYdSo3o8THBr7stFly8r55jf/RixmlH+cfnopf//7xaSliaZhgsOHuI8KUp1BFVMaCMnhoYKu61RXV5OZIo+w29vM2Ny2bk5qYGeAhk0NJNqe+Gbn1zLnG2twZTWi6i7MnqOQA2EsUhRNjZKm7MLiNtPSOoqEkoEeiZJs8KPGVKxygvwCP6bCMrj2DcgYAXPnGhHFjRvB7QaPB8xmI0/N5wO/H0pK0H/8Y15v+S+PrHiE1ngriqxw5dQr+e6M72JRLP1yDVxWF/PGzOOpdU8xwjGCrU1bARiXNa4j3bcdVVPxR/0snLgQp9UJyzAkdicBahy8NUbEOC5BY9tB6TFo3QHaBNDPAD4wnPPMTFixAhYtMlSOD5CPMSKprUABRm1q6UFdge6kmo0KBF0R9tl3AoHu27fcYvw3QrTlHFD2ZqMvv7yRSy99hUTC+AL2jW+M529/uwCr9YAkPgSCQ0bcRwWpzqC2pxGkDo3ljYR8ITJLMjvGQr4Quz/dDYBskSk8Cmadtpa0tFZaWkuItyTICJlwpBWhJDZgc0SJhxXMVo106qivADWkY5JVMu0xMsblYinOgLLvGk4qGLWZS5caEcUVK6CyEpJJI9ro8cDCheyaPY2fb/8Na3etBYw03J/M/Qnjsvu/d8JZ485i9c7VfOz9mHAijN1sZ1RG93CDqqmUN5VT4i5hwdgFEARWAm4MwaemgFF763DB7raD0gC1CSQNHHHYNRnGfgqWmLHOykrYssVIBz4A/gY8iCGaNBVDNOnAJKQEAsGRxl13gePgqyQEh8Azz3zBt7/9OppmfPm6+OLJPPvseZjNojWIQCAQHA4OyFEVDYZTg2Q0aaj7mtuiqTr4vvQBkDE6g7xpeYwufId0h4+W0EgkWUbXEmiqDhY3JMMoUhK7w4wWNmEx+7FmJ1AlB7aSfJRJMyBZDY5RHS1lOigsNNJeFy0ynLVoFGw21HFj+cuON/j9BzcQV+NYTVaunXkti45a1LP9Sz9R6Crk9pNu56znzyKajFLoMtR9ZVkmoSXwhXz4o35K3CUsnr2YQlehURTqA4riUB8wIsGxOMR0UDF+I0zNEIwAEmQlIZIDgTzI3WlEkJNJY91dCALlQBSwAWWAq/3zAh4CXmrbPhu4A+if2LJAIBAI+pvt25v4znc6ndRvf3saTzxxDooiUi4FAoHgcHFAjuqNN97InXfe2ad9JUli+/btBzWpVMR5EGmeA4XJZkI2Geq+ikXBv8NPLBhDtsiMmDICsyVCjnsdiUQ6IKNrOpIMMnFo/hw0C0Q00MLIqgToKPk6zDwWLHGI7+jWUqZXnM6OiGJ5Yzk/f/c6NjdsBuC4wuO4c86dhmM4wDRGGsm0ZWIz2RjrHkulv5KklsQkm/A4PCycuJAFYxd0zqW6HmqSUPUVRCOGk9rSYqQAy+lg1yDYlnuXnQVmCUIyqG2/KomEEUFuU97zYmQSr8Twf5MYv1QeYB4wF3gU+ARDKOl/gcs5eNGkfZFKNioQ7ImwT0Gq09VGS0uz+P3vz+bqq//Bddcdy69+dSayLB7WCwYXcR8VHGkckKNaWFhI4SGqne6P3/72tzzwwAPU1tYydepUfv3rX3PcccftdX+/38+dd97Jq6++SlNTE6NHj+aRRx5hwYIFez3mQFEUhdLS/qgk7B+yy7JxeByEfCHSR6RTv7EegNyJucgWGYfdi9UcIBw1UnaTkQQmm4ItuhZqmmB3Eixp4EpAjmK0kiEBahWYSqFooRFJ3ZuT2kYsGeOJz57gmS+eQdM1nFYnN51wE+eUnXNYou+6rvPUuqewKBZ+MPMHXH705Wxp3EI0GcVmsjE+e7xRk9rOhg3w+AtQfx44dXC6jJ/huBElVZsh0OaI5uQYr6sKyBooRm9ZfD4j/Xf8eDZgaDJVYGQSl2C0lklgOK2PA7/AiKxmYYgmzR2ga5FqNioQdEXYZ98JhQZ7Bkcmvdnod787g4kTc5g1a6TIKBMMOuI+Kkh1BlX1F+CWW24ZUNXfF198kZtvvpnf//73HH/88TzyyCPMnz+fLVu24PF4euwfj8c57bTT8Hg8vPzyyxQWFrJz585+LzTXNA2fz4fH40kJpTWry8qYeWNY99Q6Ik0R1JiKxWnBXeLGpIRxOSowm1swJx3EEw7UaJJMmxdlrbctvdUJrhw4ajJkZ0DMD63bYdw1MPpiMO//id1nuz/j7tV3UxWoAmDemHncOutWstOyB3bxXfi89nO+8n2FRbGw6KhFOK1OZhbspW7U6zWEoAINkP0No/er7Dde0x2g+0HSQdcN0aS0NOO1qBPsLZBRC6pqCEYtXIjX6ewqHEzXX01L239eDNEkDfg9h67suy9SzUYFgq4I++wbsRj84Q+d29nZcAR2hBsUVFXlnXc2MH/+Ud1s9KSThMyyIDUQ91FBqjOoqr+Hg4cffpirr76ab3/72wD8/ve/Z9myZfzpT3/ixz/+cY/9//SnP9HU1MQHH3yA2WzIxBcXF/f7vHRdp7a2ltwU6q4+7qxxbHtrGxUrK1AsCqOPMzGq4G1y3Otw2GpJs9ZjMQVIhGXS7CYyWgOQ1CErH46aCvn5nb1QrZmQyAL3tP06qa3xVh79+FFe3fQqALmOXH580o85ufjkgV1wLzy17ikAvjH+Gz36pvZg2TKoqIBJk8C0GbbMgrQAxHVI2jFcyjDYbYaz2toKGW6Ip0HxOlDCUF4OJSWwYEE34eA9nx9VAusAHcgHMoHNDKyjmoo2KhC0I+yzbzzxBOzc2bl93XUgvo8OPJqmc/31b/HYY2t59lmdb31r6mBPSSDogbiPClKdYa36G4/H+fTTT1m8eHHHmCzLzJs3jw8//LDXY9544w1OPPFEfvjDH/L666+Tm5vLpZdeyu23377X8HMsFiMWi3VsB4NBwHiaqqpGjzRJkpBlGU3T0HUdVVXRdR1N01AUpWO/dtr333NclmUkSep1HHo+edjbuKIo6LpOpKqO4Kq1aC1hZGcaNnMc2SyTW+jj6KM+JCOrkUQynUBLIYrWjKTHUXSNrBFR5GzAfTT6mJnoSIYXpetIEkhRH5olF90x1oga7mVNq3eu5v4P7qc+bKQaLxy/kOuOvQ6n1dlhnAe6pt7G26/7vsbLG8v5oPoDZEnmW0d9q9s8e8w9GERasQLJ7UZSFLSR65F2jwP/CGjZAZqEpNjQLSq0CWfQEgZtPDh86OaVSBu3oZeUoN92G60FBazUddy6joxxKdsWyxe6TkXb5khguq5TK8us0HUu1DS6Pgboba172t5e19TLeLuttl/3/rS9g/2cDnVNe85RrGlorqndPrva6FBf077mfjBramnRuPtuifYK9qwsnZtvlob0mobC56SqGt/97hs8/fSXAHz7228wZ04xI0e6huyaehsf6p+TWFPn3Lu+x3BZ0/7GxZqGxpqGdUS1oaEBVVUZsUezuBEjRrB58+Zej6moqOBf//oX3/rWt1i+fDnbtm3j2muvJZFI8H//93+9HrNkyRJ+9rOf9RjfsGED6enpAGRlZTFq1ChqampoampC13Wampqor6+noKCAHTt20NLS0nHsyJEjyc7OZuvWrUS7qMGOGTMGl8vFxo0buxnQ+PHjsVgsrF+/vtscpkyZQjweZ8uWLR1jiqJQHDNT9+Cfkf79LrZQAElTSSJTFk8jI3skY75RhzktQG1VLiRUTDE/kRwzmXktKEkVySSjZTpQ7K2EWxqIJDqd+DS7hbSEnwbnSezavKPXNdUF63h629N85PsIq9VKcVYxi/IXMd41nh3lOw5qTVOmTKGlpYWKioqOcZvNxoQJE2hubqa6urpj3Ol0Ulpais/no7a2FoBfb/w18Xiccyaegx7UWb+j833z8vLIy8vr+JzsGzZQUFmJuawMGxBI7oTiF0hfezqm8BggBJka8bQ0pFAcJeRAjqSjm7cijXyJgFJLy7x5tMyeTULTiGkatYDb76ep7Rc0oShsc7upa/sjUhqNMjoWo1VR8LjdlCeTLKuoYHIkstc19WZ7e1vTnp/Ttm3baGpqYsOGDUiS1G+2d6if06GsaaB+n8SaDv+a2r9caZrGxo0bh8WaoPfPqblZIRCYRCSSxOvd1TEuyzKjR48mHI5QV1fXMW6xWCgsLGTZsjh1dbaO8e99rxGXK4fa2sFfEwy/zwlgwoRJXH7533n5ZeM7hizDXXdNZ9SoDILB4JBc03D8nMSajDX5/f5uf+eHw5qG4+d0JK/JZOp/t1LS+xin3blzJ7m5uaS11+71M7t27aKwsJAPPviAE088sWP8tttu47333uPjjz/ucUxZWRnRaJTKysqOCOrDDz/MAw88wO7du3vsD71HVEeOHElTUxMul9FQZM+nHJqm4fV6KSoqwmQyHdanHM2vryH8o59gbfCSsDtJZmSBbCK0K4A1EiAnowHbmDjqN6eiJ5rQ/QFkdKy2EMqYENgBmwfMTqSEH91Zhu6cYJxcV5FaypHSR6NOubebeJIkSUiSxOubX+dXH/+KlngLkiRx+dGX8/1jvo9J6m6Mh/PJTU2whgtevgBd13n+m88z1j1270+jgkH429+Qf/MbKC1FcrvRTCakTZtgnR3C3wTLVCR3FrouG71TrX5IvgnXFMPpk9HGjTNUjtv4QJZZDEzUdSSgHvivJBGTJBRd5xhdp5sMlSyzUde5R9OYvZ+1HuwTtkQigdfrpbCwEFmWU+oJ23B8aijWdGBr0jSNXbt2UVRUxJ4M1TX1NveqKpg1S6a29tCEdwoKdLZs0UhPH/w17W98KH5OANFokksueZV//KMcALNZ5le/mst3vzsLs9k8JNe0r/Gh+jmJNXWOJ5NJampqOv7OD4c1DcfP6UheUyAQIDs7m0Ag0OFTHSp9cn3/+te/smjRogNWvdN1nRdeeIFLLrlkv/vm5OSgKEq3J80AdXV15OXl9XpMfn4+ZrO5W5rvxIkTqa2tJR6PY7H07FRptVqxWq09xhVF6ZEu3PVG0LX2dW9pxf093rJ2M+Ef/QRLUy2RgjFIsoIExFvjJJMSut2JaUwj1CXQ//QlllMsWLJkGJkN7hgo6SBbQE+CGgbJhBSuQXKMhngTxP0dbWgUZ3fBiF0tu7hn9T187DUeEIzPGc9P5/6U8Tnje53zwaxVkqRex9uv+97Gn//qeXRdZ9bIWZRll/U+Ea8XZdkyWLkStm83vkHW14PDYZynqQmSx0H6hzBtI+TkIakmQ903rRpqNsH8B2HmzB41qHaMX5yEJFEJbMJI/3UBx0kSrj1+T+KASZJwKEqPc+1vrXuyt+trNpt7rc/uD5s82M+pr+OH6/epK2JNh3dNiqIwevToXvfb13lSeU17jmsafOc70OXh8kHz059KpKcb7yVsr//nHgrFOe+8v7FihRE5sFoVXn31YhYsGNex71BbU1/GxZqG9ppMJlOvf+eH8pqG4+d0JK9pICKqfZJpuPHGGykrK+P++++nsrJyv/tv27aNe++9l7Fjx3LTTTf1aSIWi4VjjjmGd999t2NM0zTefffdbhHWrpx00kls27atm/dfXl5Ofn5+r07qwaJpGlVVVQOSe70vGh95FmuDl2jeaCTZMBxd14k0R5B0lUxHAEUPkUg3IwcTxHanwSkngafR6P/pGg9584yfktlwWGONENgIJgeMuQqmLYXMyZ1r1TWeX/88F710ER97P8aiWLj++Ot5ZuEz+3VSDweN4Ub+Uf4PAK6adlXvO23YALffDk89ZfR6mDDBkM80maC5GXbsgNYYKBZDPGlMDHJ3Qt5242dzVUcLmt4owxBIWgVsxHBSRwNfw3BW98SH0Vd1IK/eYNmoQNAXjgT7fPhh+Pe/D/08p59uOLyCgSEYjHHGGX/pcFIdDjPLl3+LM84oHfY2KhjaHAn3UcHQZtBqVCsqKnjkkUd46KGHWLx4McXFxcyYMYOSkhLcbje6rtPc3ExlZSVr166lurqa7Oxsrr/++j47qgA333wzV155JTNnzuS4447jkUceIRQKdagAX3HFFRQWFrJkyRIArrnmGn7zm99www038L//+79s3bqVe++9l+uvv/4gLsXeaa9RHegesl2J1dSjvLeKhN3Z4aQCxJrDWGItmLUYJi2GJOlgtqClm5AqoqiNlSgmDaweyDzaUPbNmEjQPpLyZi/ReDW2rDMpm3wNrvTu69nWtI1frP4FG3wbADgm/xjunHsnozK6R1sHkxe+eoG4GmfKiClMz5vec4f2NjRVVYbCb/uTocJC+OILiMeNMckG6kbIcYLV0Xl8lxY07KWx9ra2/xoBBzAdw1HtDRXwAwuB3s/WPwyGjQoEfWW42+eXX8Kdd3ZuOxzw9ttwoOKcdjsUFXUKsgv6F13XOf/8F1mzxmirlpFhZfnybzFr1khUVR3WNioY+gz3+6hg6NPHatIDok+OqsPh4M477+T222/nH//4B6+//joffPABr776asekJEmitLSUk08+mXPPPZdzzjmno2VMX7n44oupr6/npz/9KbW1tUybNo233nqrQ2CpqqqqW5h55MiRvP3229x0000cffTRFBYWcsMNN3D77bcf0PsebmLBGI3ljSSjSUw2E9ll2Vhd3dORg/9ai6mliVhuIRKgJjTi/hDmZh/oOopZRjfb0M02MFnRzKDUtxLfsAv7VCBjIkgS3miIZb4qVjbW4IuFSSYjmFrexFNVzrwx8zhr3FnkOnL542d/5KkvnkLVVNIt6dxw/A2cO+FcZCl1eiO0xlv528a/AXDV1Kt6T0Xv2oama/pCPG40KdQ0yMmFgAuSfrBUARONfVS1WwuaPdGAp4HHMFIRsoA8oGfVXdvpgHKgBOh5NoFAMByIRuGyy4xbTDu/+hWcdNLgzUnQO5Ik8X//dzIffFBNWpqZd965nBkz8gd7WgKBQCDYCweUTGwymTjvvPM477zzADqeQIKhXrW3POgD4brrruO6667r9bV/95JXdeKJJ/LRRx8d8vseDoLeIFuXbaViZQUhXwgtqSGbZBweB2PmjWHcWeNwFRrJo1prGFlTScZ1Yg2tJKNJbIkWo8en2YxUMIJEmgmNIIocR1WsSKqGHtXAkgXWbDa0NLFk+zoqIkHcZislFhNmWzaJ7En4Ik08ve5pXt/8OgktQVPE+By/Vvw1bj/pdnIdqden69VNrxKKhyhxlzBndC9dSYNBoybV7e7upG7aZDivaWlgsUBUhWQYFBMEaiA82qhZ9fsNJ3XxYiMC24Vm4KdAe6Ok84BvAL/ESP91Y6T3moEERrqvH8NJXQyI558CwfDk//0/6Cqq+I1viNTdVGbOnNH84x+XkJeXzuTJnsGejkAgEAj2wSFVvSqKckQ0HpYkiby8vAMWk+qKb4OPNUvW0FzRjM1tI7MkE9ksoyU0Qr4Q655ex87VO5m9eDZZY7Oo3ezHHdEIx4LosglZS2IhjmRWkIrywGJF1yAay8aRtoukakKXNGQr4ByHNxpiyfZ1VEVbmZTuNkR84n5wjMFiTiNPseAL+1i9czUWxcJkz2Tu+tpdfL3464e0zoEirsb5y/q/AHDl1Cu7R3qDQSMSum6dIZw0cWLna5s2Gf8BTJ8OBQXwbhWEvWANQWMLbNwIpaVGuu+CBT2c1HXAHRjOpxW4HTgHo9vhUmA5sAKoBJIYv1QejHTfBRweJ7U/bFQgGCiGq32uWmXUprbj8cATT4jU3VSivj5ETk5aN9s79dQxPfYbrjYqGD4IGxWkOgNhmynTRzWVkWV5r8rDfSHoDbJmyRoCVQFyJuUgK51OlmJRcBW5SM9Pp/6rel7/9usoFgU9GGQWDtK0VpKZI7BFwkgJGdLTwdKZJhyJ5WK1NGMNN5NwmrCMTwN7AcuqN1MRCXY6qYkAmJ2QNora1lo+r/2cSDKC1WQlzZzGhZMu5JSSUw7hKg0s/yz/J43hRkakj2B+6Xxj0Os1Un1XrgSfz4iK7txpCCYVFRmpvu39oKZMgXHjoBVIToT0UjjOD97tcM01cPHFPWpSNeAZ4Hdt/y7GcExLu+xTCFwNLAK2AFHAhiGcNJA1qXtyqDYqEAwkw9E+/X648kojyaWdP/7RcFYFqcHmzQ2ceuozXHHF0dx776n7/BI1HG1UMLwQNipIdfamDnxI5+z3Mw5DVFVl+/btPXoU9ZWty7bSXNFMVllWNye1nag/Su3ntTRVNFG/sZ5AdYC04jxix8/BaUtgMyeQEjGQZHBn7TE3G4HAaLSghGmGipKdTTARYmVDDW6TGUUNG5FUUzpx12T+69vIBzUfEElGcJgdzBk9hymeKbxf9T4tsZYec0sFNF3jmS+eAeCyKZdhVsw9lX1LSoyoqN1uFIutW2eIJyWTnU4qwM62k+ZbIC8TsrJg2rQeTqofuAn4DYaTugDDaS2ld5zATGB228/D6aTCoduoQDCQDEf7/NGPoEv/c773PTj77MGbj6A7X3xRy9y5f2bXrhbuu+8//P73a/e5/3C0UcHwQtioINUZCNsUEdU+0tJycE5cLBijYmUFNretu5OqQ+vuVpq2NRFuCAMgIWFz23CXuDnv2fNIbJ1O8wXrsXkriMppSFkZ3WsvAV1TUXb5aHJ5yDrRCo4xlNdvxhdppMRqB8kBrmJUeyH/rv6I1ngrEhJjs8YyKXcSiqQQV+NU+ivZ0riFmQUzD/oaDRTvVrxLTbAGl9XFwgkL967sm5lp1KH6/YazqqpGTWpBgfG6TqejWowRhe2lDc0XGHWlPsCCker7DYxU31TmYG1UIDgcDCf7bGyEZ57p3B47Fh56aPDmI+jOJ594mT//Ofz+KADTp+dxwQWT9nvccLJRwfBE2KjgSEM4qgNEu7Jv7bpamrY3kTuxs5Y3HoxT83EN8ZY2mUgJXEUussZmYTcn0DdvofWlt8iZVkRi/om0PrULu9pKIplGMpkwRIDUJKZAI+ZIKzGnFcd3HdhP/x8o/hbRzS+S9D2KOasULG6QzZQ3bKI13orNZOPEohNx29wd8zHLZpJakmgyergv037RdZ2nv3gagEVHLcJutu9d2ddiMXqltrQY4zk5Rl5eVZVRt1qLkZtrBTwqbPF3a0OjAc/RGUUdhZHq29kCXiAQCOCVV4xkjXYeecSoyhAMPqtX7+Tss5+npe3v6wknFPHmm98iM9M2yDMTCAQCwYEiHNV+Zk9l30hThMDOAJHmCBlFGVjSLdSuq0VLaMgWGXeJG/cYN+laAE/Ve+TUrENurCf90eXgtJBVXo7d7aCxdDZ6VQ3Wei+SpqLLCklnFtGvn0TWSZ/gnGCGUReB2YktexomaxYJcyYW2UxrvJUtjVsAmDpiajcnFSChJTDJJmym1PhDHowFKW8sJ5qMsq1xGxt8G3BYHFw0+aK9K/sCbN4MDQ0gy2CzQUYGhMNGBHbsWNjR1i6pSIVt3dvQBID/A9a0nWo+cCeQdniWLBAIhhB//Wvnv3Nz4fTTB28ugk7eeWc7Cxe+QCRiPEX42teKeeONRTid1v0cKRAIBIJU5JAc1VgsxmeffYbP5+Okk04iJyenv+aVUkiSxMiRI/erZtWbsq/NbTNa0cQ1fOt9JCIJzHYzDo+DollFKBaF9KYqxq17ibRgHTGzgxZ7Lq7S0bBzE8Tj2C1QVGwmfvf9BKpb0FrDKOlpZM07FmvtfeDToeAssBr1q2XZZXgcHnwhH4WuQr6o+wJN1/A4PBQ4C3rOO+TD4/AwPnt8j9cOJ96gl2Vbl7GyYiW+kI+klqSiuYJIMsKpJacSiofILN9tpOyWlHQeGIsZTur27YbzOnWqIajU3Axms1HDWtsMuzIh4YOEH8Z2tqH5EiPVtw4j1fcWjPYzqZ7q25W+2qhAMBgMJ/v0euG99zq3L7zQuM0IBpfXX9/MRRe9TDxu1EideeZYXnnlIuz2vn04w8lGBcMTYaOCVCelVH8fffRR7rrrLgKBAAArVqzglFNOoaGhgQkTJnD//ffznWHSTE6WZbKzs/e5z96UfW2ZNsxpZqLBKIlIAl01JCLzZuShWBRsoUbGrXsJW2s9Le6RxMNJFIeCTU4YSh0WC8yZA9XVWP74e3KXLu1snxKqgi/bvjEVf6tjLi6ri3lj5vHUuqcAqAvVIUsy00ZMQ9rD/VI1FX/Uz8KJC3FaD7cEUCcbfBtYsmYJFQ1bcatmSuQMImqUrbEYuqyzM7CT21fezuK0+UxOJo1vhrEYbN1qpAG35+FNnmzUnIZCUFVF0O+nPCuLqM2FbZKFMn8Orh8shAUL0AsL+Qvwa0DFSPW9DygbrItwCPTFRgWCwWI42eeLL3ZX+r3kksGbi8Dgtdc2c8EFf0Nt+/t6/vkTef7587Fa+/4VZzjZqGB4ImxUkOoMhOrvQTmqf/7zn7nxxhtZtGgRp59+ejeHNCcnh1NOOYUXXnhh2DiqqqqydetWxo0bh7Jnumkb7cq+PdrPmBV0XScWiCErMja3DUmSaPG2YHVZ8VStJS1YR4t7JDoSalwlszgTZdNXxgmKiozcsqwsox/o8uVw9dXGazv+AuiQOxfSi7vN56xxZ/Gvyn/xzvZ3kCWZcdnjSLd0L6JSNZXypnJK3CUsGLugvy7XAeMNelnyzk+oqlrPpDoVJRIFXSOaaGWmnEDNz6OoeCzlgSqWND7PUmuMwi+/NFrRtDuobrdRszpihHHOwkKWzZ/PynHj8JlMJJUiTIk0PHl25o0yMxd4HFjdNofTgf/H0E317YuNCgSDxXCyz65pvyNHwqxZgzcXgcH06XkUFDiprg5y2WVH8+c/n4vJdGBfmIaTjQqGJ8JGBalOyqj+PvTQQ5x77rk8//zzNDY29nj9mGOO4dFHHz3kyaUS0ejehYb2puyrqzre/3oNJ1WWMdlM2LPsJMIJgt4gnlE2cmrWkbCmoyMRC8SwOq1k2GJQX2/UWk6ebJxMUQxV2xUrYNEisCbB+w/jtZLLesyp0FXIWPdYVrACVVdxWpzE1Thm2UxCS+AL+fBH/ZS4S1g8ezGFrsL+vFwHxLL3nqDiq/eZ1CChWG3gcpLQVZoDfiwJnbzaMEpkLWWTJrJp95csTzRw9SbFiDZnZhpCSXl50JZysCE/nyVnnEFFbi7uxkZK6oOYQ1kk7BZ8xxh9UX8GZAIZwI+A8xlaqb69sS8bFQgGm+Fgn1u3wtouXU4uucS4TQsGl9GjM/nXv67kySc/4957T0WWD+5uPhxsVDC8ETYqONI4KEd127ZtXH/99Xt9PSsrq1cHdrjSWN5IyBcisySzY0xLalSvqSbSFEExK+Qen0vr7laizVFks0wilMBUU4El7CdgyiLpj2J1WskrTcOyeZ1xknHjwOHofCOPByorYcsWyPwMtDi4JoF7eo857fTvZGXlSgpdhcwvnc/OwE4q/ZUktSQm2YTH4WHhxIUsGLtgUJ3UYOVmVr73Z9wxFcXt6XA2/eEmNFlCdjgx2TKhzodSU0NmlpkVJRqLtllxzjjeaD3TJSfem5nJkjPOoCo7m0leL0pTE1jHg2zBXABRBbwY4r8y8BgwdxDWLRAIhh6PPdZ9W6T9Dh7JpNYtajp2bBb33TdvEGckEAgEgv7moBzVzMxMGhoa9vr6xo0bycvLO+hJDTWS0SRaUkM2d/7RbNnoxVVXTo5JI2tyAepoB+FRGQSrggRrgsRaYoSrm9AiMaQsM9lZOhmhaiyftl1Xmw3K9qiWNJuNVNdQEAJ/M8ZKLu/mqIHR0mXpf5aS1JKcUnIK9592f4fybzQZxWayMT57/IDWpHZV7rWZbJRll+GyunrsV77sGXxxPyW2ESBJ6EAoHqI13gq6TkZcgkYvaBqoKp5kOpVHjWSLMpKZ24JGJLVLCsyyo46iIjfXcFL9fkh3QWAUugRfFENF234lGGm+WxCOqkAg2De6DvfcA7/8ZefYhAmGbpvg8KLrOj/96So+/7yWV1+9GItFpEAKBALBcOWgHNUFCxbw+OOPc+211/Z4bcOGDTzxxBPDpj4VjOLgMWPG7LVI2GQzIZtktISGI+Ene9vHjFv3AWlqKzanCXmzhdiODBqKpuEbNZPgqCIaNjUw8VQPmS/9k5zEVpTdkfY3M+pSJ0zoKSWZSLT1CV0LJj/YC2DEKT3ms7JiJZ94P8GiWLhl1i1IkoTT6mRmwcx+vjI96U25tz2CO2/MPM4ad1ZnBDcYJLr2I5I5MrIOzTE/LbEWVC0JqootAbZoyNjXagWbDbPDQTLTRfTKb8ETb8PGjUZ9qsdD0Olk5fjxuBsbjUiqywXZ00gGHdRnQEWmEUU9GsNR9QIrgEXA4MlI9Q/7s1GBYDAZyvapaXDnnXDffd3Hf/zjHs8IBQOMruv86Efv8MtffgTAZZe9yosvXtAvSpND2UYFRwbCRgWpTsqIKd19990cf/zxHHXUUZxzzjlIksTTTz/Nn/70J1555RXy8/P56U9/2t9zHTQkScLl6hkNbCe7LBuHx4Fp+xYm7n4T065qQpqFkCMX3ZOBpKlYowFGlr9L9u6vWJd1KlmqRMm/38bq9xnfhNLTYcwY4z/bXvqZ+nxG+q/pfWN79KUgd3+aHE6EefijhwG4atpVFLmK+uUa9IUO5d7mCtw2NyWOIswtIRKxOL7ILp5u/iOrd65m8ezFTPZMhvJy9LpaIlkJdoSqUDRAVVGSGs6kTEayrQ7VnQlpaaBpJFoCmKJxbOMmwtJTDHGpFSugspLy0lJ8ZjMlzc2G8u/IUUQ+chAFqorBIcHxGLWpAB6gEiOqOvAu/MCyPxsVCAaToWqfmzfD974H77/fffyBB+DKKwdnTkcqmqZz7bXL+MMfPu0YmzNnVL+1QxiqNio4chA2Kkh1UqY9TUFBAZ9++il33HEHL774Irqu8+yzz+J0Ornkkku47777hlVPVVVV2bhxI5MmTepVac3qsjL+mHTSHvw7Vj3AbjUbXZFJz3Ya6ayKiagjm6hsx7GrggmVtURGFGPNj0BpKbS2woknGk7Z3icBfj+cMglYBSYnFH2jx25PfPoE9aF6Cl2FXDn18H2T8ga9LFmzhKpAFZMco1GqvVCzGSIRLLpGkSSTb7dRPqKJe0J3smDqBex85y+cvGMn1uIEfkWlICzhSsg4VAuSxQKeTMNBbUeW8ZljeEwZRs9Xq9NQQF60CLZsIWqxkCwpwWy1gsVCfTOYgqDJII2EU4CuMWozkMSoVx3q7M9GBYLBZKjZZzwOS5fC3Xcb/+7K734H11wzOPM6UkkmNb7zndd59tkvASOS/eST3+A73+mpz3CwDDUbFRx5CBsVpDopo/oL4PF4ePLJJ3nyySepr69H0zRyc3OHbUrC/i7+OGkrYZrxhjLQkLCmWzBZFEA3enoGguixGI3JdHJopLC4EB78tdHf4Mc/hu3bjZrU3m4+qgrl5VBSAmVeY2zUBWDq3kylormC5796HoBbZ92K1WTtj6X3iWVbl1HRXMEkUwHKJ2shGDTSdV1OI51Z0yAcoqg8wBe+nZRv/4SJUSdnRFW+vgNWFEuMiJlQzFbIyezuoLahaip+i8bCEbO619c6nTBzJjYMg04AjUDzDsgHooVwrKWnqm+ibf+9xK+HHANxgxAI+ouhYp8ffmg8/9qwoft4Whr84Q9wWU+RdcEAEo+rXHrpK7zyyiYAFEXi2WfP45JLpvT7ew0VGxUcuQgbFRxpHJRX+Z3vfIePP/64Yzs3N5cRI0Z0OKmffPLJsKpR3S/BIPa1a1DyctF0CV3TUawKmj+AXlWD5msgHlGJqhYsGWmkzyjDXpgNRx1l1KMuXgyjRhn1ljU1xiN8XTd+1tQY/VNHjYIfXgDmcpBMMOriblPQdZ371tyHqqmcPPpkZo+affiWHwuysmIlbsmO8sUXRoTY7QaHA12WiSZj1EcaqUo20mBOkBVSSffWM299hKOCNq790kpZ2E75qDTUwvzenVR0yvUGSvRMFpxwea/zKMNI590M/DcJnmqwAAXFvbee8bXtP76/LoRAIBiyBINw3XVw0kk9ndTTT4evvhJO6uEmEklw3nkvdjipFovCK69cNCBOqkAgEAhSj4OKqD711FPMmzeP448/vtfXKysrO2pWhzOxYIzG8kbkdZ+RubWahiYzZoeFtGw7WjhKvKEFHQlJtmDKsJNZlkdGSRYWM51tZmbONHqlLl3ard6SZNIQTvJ4YOFCWLAA6n8NAaBgAdi6p1a/vf1tPtv9GVaTlVtm3XJY1t+u7Luudh3bm7Yz0W8yvu253SBJRJMxGiONxNW23Dldx6rJZEYV6mwqk3fHsY4ZR2E4zGL7eJYo69moNOPWrHg0G2ZkEmj45Ch+OUZJQGHx1O9QWNC7a+kKwuxy+GcU5jRDRhCkXJB6yUJXAT+wkKEvpCQQCLqj67Brl6E/1xc++wyuvx683u7jOTnwyCNw6aVCOOlw09oa5xvf+CurVu0AwG438fe/X8z8+WMHd2ICgUAgOGwcdOrvvti1axd2u30gTj0oyLLM+PHjOyLGQW+Qrcu2UrGygpAvRG7TFqZv9dGqZmNOt5B/TAHm+l1EQ81ozkzkGUdhy0pDMbel9eq64Yh2bdxcWNit3pJoFExJyJMgTYHEF7B7hfFtqeSybu1fNF3jgQ8eAOB/pv8P+c78Ab0eeyr7NkWa2OnfQXOLSlGGlVGyih6LUh82Wu1IgEM14Qolsao6OjK7nBAdmQ/3PQP33MPkjVUsnTiT5WleVli8VJpaSaJhQsaj2li43coC2xQKz/1uLxMClkHDSpjlg+OSYIqDbobNZ8BXR4G/S6tYFSjHUP5dMKBX6vCxp40KBKnE4bTPhgY491z44INDO88VV8BDDxnOquDwI0lG2i9AerqFZcsuZe7c0QP2fuIeKkh1hI0KUp1BVf19/fXXef311zu2H3/8cVauXNljP7/fz8qVKzn22GP7Z4YpgqVN6Mi3wceaJWtormjG5raRWZKJ3eFG3QySroEOu9fuIs8ZwmGKQ54DRuwRs2tvM9Obuq/TCZPyYdcyqF0J23ygJSGyG+JNeNMmsWz9y6ysWdvR/mV3y26aok0UZxTz9eKvD+h16KHsm1mC2+bG5/cS12JsSdPYqdZQGNdI1yXSNBM5IQ1FTbZdSDMJdwam9AQ2r2zU7y5eDEuWULi+gqvdbhaNOJEt9hBRNYatKcD4WhXnqLFw22LDoe82IWAJBCtgixsaSyAnDq0+MEfhmOVQugXeXgxVk410Xz+Gk7oY2ONsQxrLvsS4BIJB5nDY5+7dcNppPVN3D4SSEqMW9bTT+m9eggPH4TCc0wsvfIm77z6F444b+Lu1uIcKUh1ho4IjjT47qhs3buSll14CDPnhjz/+mE8//bTbPpIk4XA4mDt3Lg8//HD/znQQ0TSN9evXMzprNGuWrCFQFSBnUg6yYjw5qNpto0BKx2WOII3IJhaIUdsYpVBSsDgcPU/Y3mZmfC8prP4NsGEJhCrA4ob0EiMC21LOhmiCJbUbqCgvx501iZLMMYQTYTY3bEbTNZJ6kp+s+kln+5f+JBjE++Ualnz1CFXxeiYVTEGxGlHzTFsmabKNJC3YExoBOUHcAcf4FDxhyagPtZgh0w2ONHxyCI+exvig2Ygcz5zZLfXZWVHDzI7U50K4/DRYsIBgYSHlGCq9NmC8F5xLIFAF/54EqgIFwHFbIFINVePBOx5yy2HWEtiwFByFRrrvAoaXk9puo1OmTBFqgIKU43DYZ1UVnHoqbNt2cMcrCtx8M9x1V69l8oJBICPDxjvv9K5J0N+Ie6gg1RE2Kkh1NE3r93P22VFdvHgxixcvBozQ7h//+EcuvfTSfp9QKrPtzW00VzR3c1JjgRj11TF2mMcy0/oVIXSsGVaiOwMETHZy9/zG095mZuFCI3ralbDXcFLDVZAxCaS2G1FwC95EkiXNElW6jUk2UBK70PUivqj7AkmSKMksYWb+TMqbylmyZglL5y2l0NUPrpjXC8uWwcqVLFPWUZFXy6SQA2V7EIoKYdQoLGkO8qzZlLMbW1InTYe4CYJWKEyaITMT2hx2FR2/HGdhy0ickrkzqtxb6rPNBuPH43U6WQasxIiIJjEM95JlML8CPpsEtDupGshV4IjBxDQoVSBQBsWbYPxyyL5a1KQKBMONbdsMJ7WqqnNs9Gj4xS+M5137Q5aNDmGjRg3cHAX7ZudOP9df/xZPPnkOubm9POAVCAQCwRHHQdWoDoTHnOokWhNUrqzE5rZ1OKnoUPdlHQD1o48lGm/EEfASyihEIUkwbiPLYqfjuVfXNjMLeqmO3LXMiKR2dVI1FVq2sawlToVqZpIr0zhf3E9T4xc0RhoxySaOHnE0iqxQllXGpoZNLN+2nKtnXH1oi96wAZYsgYoKgtnprJwYxy1noih2iERgSzns3k1o/Bi8gSqsCZ2ICbJiEoos4822MDYzH3ObuLSKTrkpQInqZEG1DTzZPaPKba1mOqYALAEqADdGyq4ZUIIwdiVsdkNQgWLgOEDeDcQwQq55hupvrgJkQsYKYBHCUxUIhhEbN8K8eUbabzvjxsHKlcLxHCps29bEKac8TXV1kNNPD7Bq1ZVkZg6XxmECgUAgOFhERXYfad3ZSsgXwuHpfNIbaYoQrg8jyRKOGWVsnXYh0fRcnM1VpKt+VBWicalnm5nFvdRaJoJGTarF3emkAoRrCCYirAxpuC1OFEkCSUKTzcRatmNCZ0LOBOwmIw1XkRUybZms2L6ClljLwS/Y6zWc1KoqmDSJ8tHp+ExxPJrNCD84HOguF7G6XTSvWYnW2sqIiIw7JhN0mNFsVkJmnWY5RhyVGjnEJpOfUWo6iwNHU1gfNYrA9owqd50ChpNaBUwCijAcTwlIKwebDxo9xtMWFYgkge1tB4+me08aD0Y4dsvBXxKBQJBafP45nHxydyf1qKNg9WrhpA4VNmzwMWfOn6muDgIQDicIheKDPCuBQCAQpAIHrfr75ptv8vDDD/PZZ58RCATQdb3HPsOlMbEsyxQXFVOpViKbO337SFMEgPS8dMxpZlrTRrHp+KvI3foBuf4VOGlBqd4BIUf3NjN7OqkAwXKI+oya1HZ0HVq3Uh5X8elWSqydT5hb1CRmPckIi5Wx7u5y/R6Hh0p/JVsatzCzYCb7o6uCsM1koyy7DNeyZVBRAZMmgaIQlVSSaJiRUdUkrYF6gvEWkoqOK6ZT2mKluOw4kjXVVIWaqEnXaJFibDe1kKVZ8ah2FkaKWRAupHCTd+9RZYAgUA5ro2CxwdFlkHB1vlwH7GoTRbaaIScB/jhUbYWJDW07Fe9xTjNGznCUYYksy0yZMkWoAQpSkoGwzw8/hDPPhECgc+yYY+DttyE7u9/eRjCAfPbZbk4//VkaG42/pVOmeFix4nJGjEg/7HMR91BBqiNsVJDqDKrqb1deeeUVLrroIiZPnsyiRYt47LHHuPTSS9F1nddff51x48axcOHCfp7q4KIrOrJJRktoKBYj4hn1G16Pzd3pQEYd2VQXnEDN1ii6Bidefz62aUVGius+ooeoUUPdVzJ3jkXrIBEkqiskZRNmqdMAVF1DAnJsmchSd8Mwy2aSWpJoct9e2Z5tZpJaEpNswmNxM29tNWd5MihsK9i36QqoKruba4jHI+joIIEsyVjsdsosuUjFY7Hm5DFx3eeM8jWxKUPmmugEpmkexkccOOuawV9lOKm9RZXb2sywEpI+GJ+EG00Q98CmefDVWbClED4EpljBrEG+F9QEWG1QkwOljWCZAOxZ4pTAsPZhnE0Wj8ex9aYkLRCkAP1pn//+N5x9tiEa3s6sWYYeW0ZGv7yFYID58MNqzjzzLwQCMQBmzizgrbe+RXb24ClZiXuoINURNio40jgoR3XJkiUcd9xxrFmzhubmZh577DG+853vcMopp7Bjxw5OOOEESkpK9n+iIYKmaTTSSFpuGiFfCFeREd6LBgxH0Jph7X5AKERATcfiycR58ZngtO55yp4oNpBNoCdAapMfb9kKgM1RiMnfQELXsLSlBUuADmhSz6cXCS2BSTZhM+39ZtZbmxmzbCahJfDt3srT6VtZnZHN7SE3WQ2t1O/6HG1iI7sUnWwkLCi47JmkO7ORdB2CLRDwQ04uHH88zZVfUOrzc/FGCWesHkzN+44q71GM6i+BcjO4E5DhgxOehhGr4ZNboMAJ+TVGuq+zFvzZYJchmA2BQsiV9lwtRtqvB+hFaHk4oGkaW7ZsEWqAgpSkP+3zzTfh/PO7t6E+5RR4/XVIP/yBOMFBsGpVJeec81dCoQQAs2eP4p//vISMjMH7Ai7uoYJUR9ioINUZVNXfrmzcuJElS5agKAqmNknFRML4g1NcXMy1117L0qVLueKKK/pvpoOMOd1MybwSvnz6S9Lz05GQiLcYdTS2Pf64aq0hoqqZiUc7sPbFSQVwlYHNY6T/phVBvBli9YBEWc4kPPWf4ItHKbIZoUKTFieky8Rke49T+UI+PA4P47N78cr20WYGwKJYKDJlMyJo5cvMBq5P/oNLd2pkh2FqLawpVvBIOaQ53Z0loJIEugZJI9Vbtdnw57pYOPd7OC89sZuCb69R5T2LURUjAKoDqgV2FEEkB8avh7tuhJe+BfFs2DwdZq2BQD7INmP/ZG/XVsVonroQIaQkEAxhXn3VEAZv+3MDwFlnwUsvgb3nrVCQgixfvpVvfvNvRKPG3XrevDG89trFOByiP6RAIBAIunNQjmpaWlpH0+HMzEysViu7u6hZjBgxgsrKyv6ZYQox9syxVL9fTVN5kyGqpINiVTDZOi+jpmo01URwW0OMnVvQ95ObXZA3DyqeAnt+RzSVtJG4bBnMyy7iKe8W8q1pKICsJ/HpFkxS96dqqqbij/pZOHEhTmsXr6wPbWZIc+CP+tndtJnccBNZcZWqDPgyV+YH290cLU2gJa2OKqWVsqSO0u6qahpIMpgUVE2lvKmcEncJC446H/rSImcZRiS1zUltJ6JDNAKOIGRFoDELRtXAcRvhP9fBVzNgXADyKmFXmaFB1cOgVaAcQy54LyWxAoEg9fnLX+DKKw3x9HYuuMAYtwgfZ8jwj39s6XBSzzmnjL/97UJstoOWyxAIBALBMOag/jqMHz+ejRs3dmxPmzaNZ599lssuu4xkMsnzzz/PqGEmuagoCq5CF7MXz2bNkjXsWrsLNa5iz7ajo6PFNUK+EFF/FLc5zOy8bbiOuuTA3qTgLKhbDf71EKox8nud4wA4yzOK1U27KQ/5KTNDQrZRq2sUdTm8m5M4totX1oc2M5GqCjYUmKhKNmIKRXHKGs6ETEFUobYki1GFZ+DEyuLWfJakr2OjqRm3ZsWj2TBHIiTsVnxKGH9DHSXuEhbPXty3Pq5BjAapbjoiqRUJCFZBmgPQwRY1DFVOh8hImOSFtR7wO+GtxXDGEsjdCOluyPBgCCclMNJ9/RhO6mKgH9rKpjIiFUiQyhyKfT7xBHz/+4a+XDtXXAF//GPf+qQKUoff/GYBfn8MXdd59tnzMJtT574l7qGCVEfYqOBIQ9J7k+vdDw8++CCPPvooW7duxWq18s9//pNzzz0Xu92OJEmEQiH+9Kc/cdVVVw3AlPuXYDBIRkYGgUAAl8u1/wOAoDfIm//7JjtW7cCebSc9Lx3ZJOPwOCg9rZSxf7kLV+sueOYZQzX3QPBvgA+vgOAWsGZD3imGwJKeYEPjdpbs2ERFAsKmDKrDzYzLGsfEnIn4Qj78UX+HkzjZM9k4n9cLt99utJkpK2OtrYlbXB9RkkzHgoIO+MONqE2NhBWdjXkyWaqFyQEraQlIeHKptLTyYPAEZiZyjVPKIZbbqlhh8eKTwyQjIUwj8vGMncpppaexYOyCvjmpAGuBWyBRAlUxiG+H3CpQklBZDDuKIQuQnYAZlDjkVMIrD8LONkFjpxeyl8NFK6DUh5H/a8KoST0NI5I6zJ1UgWC48sgjcNNN3cd+8AP47W+NTlmCoUcioSLLEooiPkCBQCAYLhyMT7U/DupZ9C233MItt9zSsX322Wfz73//m1dffRVFUTjrrLP4+te/3i8TTAV0XaelpQWn04kkSbgKXdgybWQUZzDjf2aQNy0Pk81E9vhsrFYJ/rDLOLDgAFJ/23GMAslkOKnOsdBaaagByyYmZ+SxdM7ZLA9LPLbur8TVOupCddhMNjwODwsnLuzpJO6jzYymadT7vYSTETDpeCISpza4MB97AmS54ZNPMAeDJHN0olJnvl2h5uDq8EQWtRazZdd6ovm52K66kfET53RPN+4DkTBEGiHog6x6Y0zGyIQuywF/JgRlyMAIMKtmkJNgahNSUYFPCmHU1WBfhNEnNYqh7jueI6YmdU8bFQhSiQOxz+XL4cUXoaXFUPV9553ur998Mzz4oFEaL0h9fvvbT5gzZzRHHz2iYyyVoqjtiHuoINURNipIdQ4i9rlf+i1pas6cOcyZM6dju/2XaTigaRoVFRUdSmu6ptNY3oisyJSdXUZmcWbnzlVVxs+0tL73SUgEjT6qahRq3wU9DjknwHFPQEvbuGID13gKzU6uBmpjUf74+R+ZnjedhRMWcmrJqT2jmMEgrFwJbjd0aTNj0iWigSaaI03EJEOhK1ez4nCmg9MFeXlgNsO06STWfYqptQFbXQM4sozxRAJ8Ppx+PzNLJsNNi2Hy5AO6pqEW+O8b4P4DjN0BGRYjOiLnQ/pYkHIACaYB64BmwAqkJ0AzQcQGNXTP7C1wAvtvGzss2dNGBYJUoi/2uXs3/O//wiuv7P08P/0p3HWXcFKHArquc8897/OTn6zC43Hw3ntXMWFCzmBPa6+Ie6gg1RE2Kkh1Ukb1d1/4fD4eeeQRHnvsMZqbm/v79ClBoDpAMprEZDORMWoPZ3RXWzQ1P3//36bCXti1DGpXGmq/WgKCm4xCrJyTINkC2d09r/bep69uepXGSCOf135OU6SJf5b/k3lj5nHWuLMMhzUYhNdeg61boagI4nGwWCiLOnBHW9ishMls64PqseVgd7kNUaSubWbcbnxHFeOpdzPe54HKSkgmjaKwfbWa2deSK2DjC2BdDp4oyCok7WDKgfQZIO3R/zQLOB5DELgGUHxQ44GPxhvB0oWIzF6BYCijafDkk3DbbRAI7H2/pUuNfQSpj67r3HHHu9x3338A8PlCvPXWtpR2VAUCgUCQehyQo+rz+XjmmWfYvn07brebb37zmxxzzDEAeL1e7rnnHp566imi0Shf+9rXBmK+KUHjlkYAssdlI8l7OKO7+pj2698AG5ZAqAIsbkgvgfBuQAJZgaZP4fPbYfJiyDSilV17n8bVOBbFwgjHCEoyS/CFfDy97mlWb3qLxYGjmfzeRsNJ3b4damuNCG9+PrH6nRSUhdlYopOtWsnPKMKsmI05yXL3NjOail+PsvC07+O8dhFs2bL/VjO9oUF0NVS+CPJ/ob2de3MppC0C526Qn8NI1+0FBzARKFUh5ofahfAL5xGV2SsQDEs2b4bvfQ/ef7/7uKLAtGnGsz6bzRBSuuyyQZmi4ADRNJ0bb3yLX//6k46xBx88jRtvPGEQZyUQCASCoUifHdXNmzczd+5cGhsbO3KQ77//fp577jkkSeK73/0u0WiUb37zm9x6660dDuxwwWbr9KIatjQAkFWW1XPHrhHVvRH2Gk5quAoyJhl9VXQdWrcabV4yJhv1qcFyY7/pS/EmYcmaJVQFqpiUM4lNDZvwhX1IkmT0PnUVkZ+0U75+NUv877M0fjSFRUWGk5qeDtEo0c//S8ScYLZNonxkGi256RSqXUxgb21mxi4wnNKZB5hXG4TYa1D3MkR2tfU5lWHr18BzMZw4A2QJo4/qBxhtZMro1qKmAxUs5WApAadoM9MrXW1UIEg1utpnPG5ESO++2/h3V2bMMCKs06cf5gkKDhlV1fje9/7Bn/60rmPsd79bwDXXHDt4kzoAxD1UkOoIGxUcafTZUf3JT35Ca2srv/vd75gzZw6VlZXcdNNN3HjjjQQCAc455xzuu+8+xowZM5DzHRQURWHChAkd243lRkQ1Z3wvaUztjuq+0mF3LTMiqe1OKkDMZ9SqSiYjuiop4CqDwCbYtZxlAZ2K5gom5UxCkXvx5MIh1C8+Jyumsi5H4zFnE7c15eGy29GjUZrCDQQtCdLjOqfXOZkcmc39zvL9tpm5c+qdFJYXdgoUlQH7E/LaBvEXoXk5+GOG4FHIBV+cB2MugG/kG4JJHRRiFJkuATZitKo5gtvMHAx72qhAkEp0tc8PP4Srrza6ZnXFbodf/AJuuEG0nBmKJBIqV1zxGi+88BUAsizxpz99gyuvnDa4E+sj4h4qSHWEjQpSnYGone7z14HVq1dzzTXX8P3vfx+ASZMmYTKZOPPMM7nyyiv585//3O+TSxU0TaO5uRm3240sy52pv+Oze+68e7fxc28R1UTQqEm1uDudVIDgVuOnoxjktu71kgKWTII1y1lZB26bu1cnNZQIUbX9Y7xmLxGHTERSeTxtMxuUZs6YqXDye7uwahrIEiZ3NpkJheztLSy1Hd/RZqZSaSFpbmszY3dxqedyFpQvwP2C23AUu7Z8mQecRXeHUQXeg+QL4P8MGtuGqsrg84thxhnwHeseDmpXJgNLgeXACqByj/dciChG3Qd72qhAkEpomkZVVTMPPpjF734nsacw4Omnw+9/DyUlgzM/waERjSa5+OKXeeONLQCYTDLPP38+F154YCJ7g4m4hwpSHWGjglRnUMWUGhsbOfroo7uNTZ06FYDzzjuvf2eVYui6TnV1NZmZmYQbwkSaIkiyRFZpL6m/Xq/xc281qsFyQzgpvcs3smTYiKgigbO0+/42D+W7v8QXhJLczuuf0BIARBIRPq7+kGDYi1WRcOpm0nUzQTlOrRTi1yOaeOvrGj/6AKbpHtLT3UbPB6+XwrFjuVrr2WZmon4yjoccUIER3Syhe3TzaWA1ndHN10B9CZrrDAc1KcPar8OXi+DUaXCb1Hs2bw8KgauBI7jNzMHS1UYFglTjjTd0fvADJ3V13Wv6s7ONPqnf+pZQ8h3KvPnm1g4n1WpVePnlizj77LJBntWBIe6hglRH2Kgg1RnU9jSapmE2m7uNtW+np6f376xSmPa038ziTEy2PS5fLAZNTca/9+aoqlGjL6rU5VrGjHNicYNpD9lbyUxUTZDUwCwbx+jo7GrZhaZpNIQbUGNR3HEZyWwBJHR0dE1Db24mL6qxPQt+O9fGgx8kSQ+FwGqF1laorwdN695mJnMy3I4hszuJ7h6mBSgC8jF6xlxi9DVtlgwHNZABq86HzRfAhSPgfvrooO7JEdxmRiAYTtTWwvXXw0svKex5N7j8cnj4YcgRQrBDnvPOm8iSJafyi1+s5o03FnHqqcOvBEggEAgEh58DqgRau3Ztt0LulpYWJElizZo1+P3+Hvuff/75hzzBVKNhsyGklF22j7Rfh2PviriKDWQT6AmQ2lJ84+2Oai8RWj2BDQlTNEZitxeLxUq9KUZMjaHpGgktgdvkQNLDRkhC00jEwyRMSXQNrLrMdKWAbUVRlh+bydVrNcNJDYWgpgbGjeveZuZxjEjqnk4qGGpIu4DtoNdDMgqN2fD5bHhnEdTMh29b4JZeDhUIBEcOug5//CPceivs+aehuBj+8Acj3VcwfPjxj2dz6aVTGLVnyzaBQCAQCA6SA3JUH3nkER555JEe43fddVePMUmSUFX1YOeVcjjbHM/2iGqvjmrX1jR7y2NzlYHNY6T/phUZY+0RVese5wyFoPoLynY34amO4aOOorgdExFGpieoyjVjVaxImmx8M4xESKgJAhYNiwrZSQv5WYUoFiuZSKwo1ljkOBFnfcBwUm+6Cc47r9OpDgIrMdJ9u3qacYya0QrQI0ZGblSGljzwjoFnHoPLXHAGwkEdTJx9bRckEAwg5eVGy5n33us+Lss6N9yg84tfyDgcvR8rGBr4fCE+/3w38+eP7TY+1J1UcQ8VpDrCRgVHGn12VFetWjWQ80hpFEWhtNSoHe1Q/O2tcXlfWtOYXZA3DyqeAnu+4WAmgsZrXSOqTc2w7jMw1+HyFjNPcvKUczsjYg7ijY24/Sq70pLY5XQIBSEeR5V0IiadpAIjY3aKckfT7i57NBuVpla2pIWZqWlGJLWrkwpGexgfRk1qxzyAD0GPQQxosUJNCXhLwKbAtEp4rhwUkao7qHS1UYFgMIjH4YEHDOXeWKz7a9OnwxNPSBxzjChEHep4vUFOPfUZKiqaeeONSzjjjLH7P2gIIO6hglRH2Kgg1RlU1d+TTz653998qKBpGj6fD3e6m0BVAICscfvoobq3+tR2Cs6CutWGsJLFDeigpIHJbrweChlOqqkepBGgT+WsJKxW6/lKacRlkQhbzJCII3t3gdmMrsgk9SRhi0QGViaZC5C61DSbkUmiEdXiRi7ewoU905OjGEq77eWzXtD+C3ENmp1QMR58hZCmwBRgpA5ysu04waDSbqMej0eoAQoOOx9/bLScWb+++7jdDj/7Gdxwg0ZTkw9NE/Y5lKmsbObUU5+hstIPwA03vMWGDddiMg39z1TcQwWpjrBRQaozEKq/wtL7gK7r1NbWdkRTHR4Hdre9547tNar7c1TTCmHyYkgbBYGvQIuDJcOIrmpxqP4CzHUg50L1dIg7KNQcLG6dRmZrgmp7nJgWB01DRUNVZHxZVprsEq64xLHqCNL17sJXCTRMuoRtp9foAbFgQc952TAeXcRB3QLRjyGoQXUefPx1aBkFMxQ4DRgNyIm2/UX/6UGn3UYHQnFNINgbLS1G39MTT+zppM6bZ4zdeisoirDPoc6WLQ3MnftUh5M6Zoybt9++bFg4qSDuoYLUR9ioINUZVNVfQZf61N76p0LfI6pgqOtOXwofXAGxJkMJOLARNKDWDzXFoE+FeFsxV2srYzZv4UI5wmd54M1SqM6QaLCCVVeJoJJutXFsOJPsQASsmhHOkGXQNHxJP56YxvisMvjxYkM4aU/KQM2B0AegNRvaSTWlsOtomCbBKPZ4suHD6HE6fv/LFQgEw4tly+Caa6C6uvt4Vhb88peGqq9oOTM8+PLLOk477Vl8vhAAEyfmsHLlFRQUiHo5gUAgEAwcwlE9ABq37ENICQ7MUQWjRhUV0oth0p1gz4PyCljxOBSNA0ubKnB1NaxdS3VahGynxMU1mRzjOJkliR28Ie1gRH2EHfk2HPmjyJ54NFRVQY0Xgi2ga6iShD9TY2HxApwXLunVSY0CbwDj62HcLojaoWoqZJYaEdQez8xVwA8sRPQ4FQiOIOrqjCjqiy/2fO3SSw0n1eM5/PMSDAz//a+X+fOfo7nZqPGYNi2Pd965jNxcoYglEAgEgoFFOKp9QJIksrKyqNhaAUDO+F6ElCIRaG42/r0vMaWuhHZAstXonZpxKmzbDl+2gq8FCtvC521OKrpOlVuGNCejC2fizPDww5CDzVo9O8xBzLqNKZ4pYHHAhIlQOhYCftREgvJoDSUjxrPgzCXg6u6kxoBXgH944bs3gL0Z4mkg58PRxXvJDVcxhJdKgF4yiAWHn3YblUQISzCAPP20IRbefqtrZ/RoeOwxOPPM3o8T9jk0WbOmigUL/kJLSxyA448v5M03v4W7t9KXIY6wUUGqI2xUkOoMhG0KR7UPyLJMUUERK7avAPaS+tten5qevvceqnvS/AU0xGGjA574Pvh8xjfAnTshGDTOtWsXyDKB4jxq03dR69Bx55holOspTaRz5maVv3tkto904I/6sSgWzLKZhKzjs8Twa35KiiazePZiCrs4qe0O6tOA+0u46WbI8oOrCNKXgOmvwEaMVjUeDIGlBEa6rx/DSV0M9JJBLDj8yLLMqFGjBnsagmGKrsOdd8KSJd3HZdmIrv7858btam8I+xx6tLTEOPfcFzqc1JNPHs0//nEJTqd1kGc2MAgbFaQ6wkYFqc5AiHwJR7UPaJrGxg82oiZULA4LzvxeHNG+Cil1Ze1K+JMXmluhIN0QOSouhkDAcFhrakBR8B41msePDrPC2krUbuY162eYkLFHkhylBFnodZL4n5t5r/ZjKv2VJLUkJtmEx+Fh4cSFLBi7oMNJjQGvAk8BjcAJb8MPfwZ5cciYAPIvgVxgGrAcWIHRQzWJYS0ejHTfBQgnNYXQNI2amhqKioqEGqCgX9F1uPFGePTR7uNTp8ITT8Cxx+7/HMI+hx5Op5Wnn17Ieee9yKmnlvDqqxeTlmbe/4FDFGGjglRH2Kgg1RkI1d+DdlSrqqq49957WbVqFfX19bz22mvMnTuXhoYGfv7zn/Ptb3+b6dOn9+dcBw1d16n5ogYwoqmS3Eto2+s1fvbVUfV64XdvgC8OUydDepfj0tON12WZDXky907exTpXDFsSxmluMpIOolqSTckqVoxS2TTCw9LxZ3DFcd9jS+MWoskoNpON8dnjcVoNpzoG/B3DQW0A0OHKP8Jlv4cMQD4ZuBtoz+gqBK4GFgFbMIpYbRjCSaImNeXQdZ2mpiYKexPJEggOElWFH/wAnnyy+/jPfw4//jGY++i3CPscmpx9dhn/+tcVHHdcIVbr8H6uLWxUkOoIGxWkOimj+rtx40bmzJmDpmkcf/zxbNu2jWQyCUBOTg5r1qwhFArxxz/+sV8nO5i07mgF9iGkdKAR1TdeBm8zjLJBWpea1+pq41yyjDfLxJKvKey0RBhXrxN1WMmwO5CQaA03Myqok0hLo9mTwZI1S1g6bykzC2Z2e5seDiowMg5L7oay5W01qJcB19N7QaoTmNnLuEAgGNYkEnDVVfD8851jsmw4rd/+9qBNSzCAfPFFLVOn5nUbmzNn9CDNRiAQCARHOgeVO3DbbbeRmZlJeXk5zz33XA8P+qyzzuL999/vlwmmCqGdhiz/fhV/+yKkFAzCW69BugIWF8ht6r41NYZwkizDuHEsm+agwhahtFknPaqTrtiRNJ140I8cCBK2KjiOPYnx+VOobK5k+bblHW8RB14EzgUexHBS84CfBuCV62DCcuNtuAO4EdFRVyAQdBCLwUUXdXdSFQX+8hfhpA5XfvvbT5g27Q889NAHgz0VgUAgEAiAg3RPVq9ezTXXXENubm6vCk+jRo3C254KO0yI7zYEJXIm9KL4C50R1f2lZASD8NprUL4NZAnkDGO8pgb++1+jIGz0aIInzWTlZDtuUzpRezrB0dOJFMzE5y7BZ4KdI2wEp03AlTcaRVbItGWyYvsKGmMt/A3DQX2ATgf1DuDvVfCNb4P8GeAAHgXOP6TLIkgRJEkiLy9PqAEKDplwGM4917hNtWOxwCuvwKJFB3dOYZ+pzQMP/IfrrnsTgFtuWcF//lM1yDM6/AgbFaQ6wkYFqU7KqP5qmkZaWtpeX6+vr8dqHR7KgLFgjKoPqog1xpBNMvbsvcjytzvme4uoer2wbBmsXEmwcjPl8d1EW3VsVVWU7YzhqqozQpyjR8OMGZSbG6jOySZRfBGflh6P5shFT3cR0+PEw7uxVq/hdC0JiQgA2Q4Pm3bXceu/qpGck8ixgaMMLnXBOYD5M+AWIAjkA48Apf15pQSDiSzL5OXl7X9HgWAftLTA2WfD6tWdY3a74bSefvrBn1fYZ2qi6zp33fVvfv7zzg/8jjtmM2vWyEGc1eAgbFSQ6ggbFaQ6KaP6O2PGDJYtW8a1117b47VkMskLL7zACSeccMiTG0yC3iBbl22lYmUFDVsaCFQHsDgsLLtmGWPmjWHcWeNwFbqMncNhQ6kXendUN2yAJUvwejexbHSclSc24ItoJBUwaUE8gWbmWWTOUsdQOGMGSBKb8gvYNv9SVNdI5NYGHPWVNIcgbjOjpeUiTfs26+ItHL31LUw7I4z+72TO/aSQkUoBDhN4TJDlAWUeYAUew1DunQz8Esg6HFdRcLhQVZUdO3ZQXFyMoiiDPR3BEKS5Gc44Az75pHPM6TSer82Zc2jnFvaZeui6zq23ruChhz7sGLvnnlO4445D/LCHKMJGBamOsFFBqqOqar+f86Ac1cWLF3P22WdzzTXXsKgtF6yuro6VK1dy7733smnTJn7zm9/060QPJ74NPtYsWUNzRTM2tw1zmhnJLJFekE48FGfd0+vYuXonsxfPxjPZ05n263L1bCbo9cKSJWxo3MSSYwNUmFpwJyRK6sGchISq4XPA01N1Vsd2szi5i8zcyTw77wyiLgtpNeuxqiq6LKOarThNdlySjCnShM+Rx07tPG57VqXY66TZWo9tQpIJGaC09zxditH3NA84G/gZhnqvYNjR0tIy2FMQDFF8PiNi+sUXnWNuN7z1Fhx3XP+8h7DP1EHTdH74w2X8/vefdow98sh8brhhaD9gPlSEjQpSHWGjgiONg3JUzzzzTJ566iluuOEGHn/8cQAuu+wydF3H5XLxzDPPMHfu3H6d6OEi6A2yZskaAlUBciblICsywaogkiSRlpWGq8hFen46TeVNrFmyhnlL5+FqF1LqTfF32TK8XsNJrTKFmJR0oyRbwCRBVMOiSxRFreRjYUtahJ/rH5AzagaVDge23etJyippSQk93UlRRh6SLNMK1KHj2d7ETb+fSFFzmJq8daSbFSY4XSgSoAC7gACGslIacB3CSRUIBN3wemHePNi8uXPM44EVK+DoowdvXoKBIZnU+M53XufZZ78EQJLg8cfP4bvfnTHIMxMIBAKBoDsH3Rjt8ssv5/zzz2fFihVs3boVTdMoLS1l/vz5OJ1Dt9Hm1mVbaa5o7nBSAaKBKADWTKPuVlZkssqyaNjUwLbl25jh2oujGgzCypUsGx2nwtRiOKlIEG0Fk258Q5BkdKsVVUsyqlljY0GST6dPJSPoxxTR8dklZKsNs9tDqyzjB9oD6wtWuRm3Q6FivIy1NslI12gsisXoSfMh0IQhl3UiEALewuiNKhAIBBhO6ty5UFHROVZYCCtXwoQJgzcvwcBxww1vdjipiiLxzDPncemlUwZ5VgKBQCAQ9OSgHFVd15EkCYfDwcKFC/t5SoNHLBijYmUFNretw0nV4hrJSBJZlrFldIYjZUXGlmlj+4rtTJ7uxQo961PLywk27mJlcQtuzYojHmGEHsBkayFp09klpdEa1iDSgiqBLoElo4zmHA/TtzcTbpEIWGVastIIK0qHg6oARS0KZ72fScgZJWKScTlGMMo1ClqADzAcUzNwApAL1AArgEUYvVEFwwpJkhg5cqRQAxQcELfd1t1JLSmBd981fvYnwj5Thx/+8DhefHEDwWCMF1+8gPPOmzjYU0oJhI0KUh1ho4JUJ2VUfwsLC7nwwgu56KKLOOmkk/p7ToNGY3kjIV+IzJLMjrGmUBTfUU50pwVzjkxhq06aZnwQDo8Df6Wfxk0+CqBnRDUUojxZh6bWc4EUZ0qBhtOmo5h0kjrUJaKsa5RYv0tCbQG7rpClOkgqJvxyBH+ODbcnl2ariVi0GUWxktVWozp5u43MBoXKwhYUOZOxOeNxhBywBkhgtJ+ZRadT6gEqgS3AzAG9jIJBQJZlsrP30uNXIOiFYBBefbVzu6zMcFKLivr/vYR9pg6TJuWyYsXl1NWFOOOMsYM9nZRB2Kgg1RE2Kkh1Ukb19+STT+ZPf/oTv/nNbygsLOSiiy7ioosu4rj+Ut0YJJLRJFpSQzbLNFp01o608NmEsfgz0tDMMmYgoznMtA11zKyOk6XLaEmNZG2DcYKCAlBV+PRTI3futdeQrdVcXRSn1AThhERD3ISaSKKhYzPD6QUwM9fKO3W51AZ0bCYTmGTWj7KjkuT4gslk2DJpCVRhCtZAPIhf11FDMuakTFp6JlicuGOKEUlNYCj6noih9tuOGUP1N3pYL6ngMKGqKlu3bmXcuHFCDVDQJ15/HaJd7gf33TcwTioI+xxMgsEYaWlmTKbOLxDTp++ljdoRjLBRQaojbFSQ6qSM6u9f//pXIpEI//znP3nxxRd57LHH+OUvf0lxcTEXX3wxF110EdOmTevnqQ48JpsJ2SSzw6bx6qkjqSvIID0YoaA+CLEEWM0E3Gm8+7WxfLU7wPnvVuMyyZgafRAOGc0Gf/Yz8PuNE9ojjJ6toVjBG0tDMplBjaJrKgkdwnGZBA7yrHHOzG/m72EHrWEfciJAq82FKx4kLz2PJlnBljuRMVmlFEYDqFqScfU20tMzSFNkJB0yPsCoTc0EZtPzk020jQkxpWFLNCqeQgj6zl//2vlvlwvOPHNg30/Y5+GnoSHM/PnPMXlyLk89tRBZFimD+0LYqCDVETYqONI46Bit3W7nwgsv5OWXX8bn8/Hcc88xZcoUfvnLX3LMMccwYQgqcWSXZRMb7eDFk0dSP8LJyB2NZDeEMKlGTa5J1cluCDFyZyP1I5y8OKeImFpHdvl/oKoKVq0ynNSMDDjvPPjpuWRMLKA+Yibc4Tiqbf+XUCQZHYnamIUcS5zJ6a34s8Be/R90u5t810gUWSHedqRdsZDryCXPmU98qpuWETIOHxRtA0sAQ9l3Fr0/fvBhpP+OH9BLKBAIhgD19fDOO53b558PNvEQa1hRW9vK1772FJ99tptnn/2SH/945WBPSSAQCASCA6JfkokdDgeXXHIJzz33HA888ADp6els3bq1P059WLG6rFTNyaS2MIuCqmZkTe+5k6oiRyIUbKqmriCTmmkyVi0KVit885vw29/C22/Dbf8L9m2YPKUUkkFMjaPrGmgaOjoaoMiGR6kD4ajGxBEaUZeCrfJf2Fq86FljUTECpdA9kzfkglXzILcaRm3DSO2dRe8RUxWjl+ppCCElgUDAyy8bVQrtXHrp4M1F0P9UVQWYM+fPbNhQD0B+fjpXXTVtcCclEAgEAsEBctDtadoJh8O88cYb/O1vf+Ott94iFotRWlrK9ddf3x/zO6wEg0E2jneS2dpKIiYhW3QkIKmpKIkERCKg6+hAQreSEQjy1elTaFlThnPyZLjzzs6TNZZD1AeZJYyaYGf3tvcIaGFcqoYm6+i6EVElmQBVI2i14nDqlElm6kMBRpUvo3DsmWwEmgENsGC0RPVh+J32ceAJgCMInAq4elmUCpQDJcCCgbt2gsFFlmXGjBkzIIXsguFH17Rfjwe+/vWBfT9hn4ePbduaOPXUZ6iqCgAwenQG7757BaWlWYM8s9RG2Kgg1RE2Kkh1UkZMKRqNsmzZMl588UWWL19OOBymuLiY66+/nosvvpjp06f39zwPC+U1NTSnWymLBWk0m4jGZCBJ0gSYzaQnkiQwo8pmrBaYGq/HHKjDm5HBBFk2ZDTtQLAcGj+BeDPoxThyC5kmzWZd5Sr8UhJTEkyqjiypaIpCY7qVSkmnQJXAbEKRklzkmcy5ksRy4C4MB7UGo/uMB1j4MSy4HzLTgVKgrm0nD0Z0NUGnR1sCLAYKD+fVFBxOJEnC5ertSYVA0J2qKnj//c7tiy4C0yE/stw3wj4PDxs31jNv3jPs3t0KwLhxWaxceQWjRmUM8sxSH2GjglRH2Kgg1UmZ9jS5ubmEw2EKCgr43ve+x8UXX8zxxx/f33M77ESTSZKKgtOiYvNoBFsV6ltl1CSgS8TMDsxmmdJYLbM+W8NRn6/FFAySX1UF3h2w6BQ4CphhBmcYwjshEQR7EVlqHcfnOtgeVtgYiqPJClHFyqdxla/CCSIoKCGVyviXxGQLgWgAgl6udhXyNNAI3AkUA+PfA+ctGDnDtwHzgOUYfVIrMdR9TbR5tBiRVOGkDmtUVWXjxo1MmjRJqAEK9smf/9x9+3Ck/Qr7HHg+/3w3p5/+HA0NYQCOOsrDihWXk5eXPsgzGxoIGxWkOsJGBalOyqj+XnXVVVx88cXMnj27v+czqNhMJkyxGAlJwmLSyclMorogGJPRNJ0iWWLMrnIWPP8cubt30+p0UpOXR1GoAUZEoHG74TB+4YYrpkB6AJIhaP4MdBWHyYniKsFELXFLNv/0h6hOhMmxpTFGgVgyToWq4jDZ+Wf5P9lQv4FbZy8m6pmMAzgdcH2JER3VgQuAKwAJuBpYhNEnNYpRqzoeUZN6BDEQNwjB8KKpCR5+uHN7zBg44YTD897CPgeOzz7bzamnPoPfbyiCHnNMPm+/fRnZ2WmDPLOhhbBRQaojbFRwpHFQycS//vWvh52TClBWVIQnEsFn7ZQtkmQw2TVMdpWC1joWPP8c2T4fu4qL2ZWXh0VXyUhvBEsSCkZA6Qioi8CzGyHkgWQEtCToKphsNMSCNKsaL/tDNCRVpro8jLKlY9GTeFUJTZKZkDOBiTkTqQpUcfeaJcSDXmQgvQq4CSPFdy5wK4aT2o4TmInRnmYmwkkVCATduP9+o0KhnTvugAHI1BEcZoqLMxk50kgJnDVrJO++e4VwUgUCgUAw5OlTRHX16tUAzJ07t9v2/mjff6jgcrmYl0jwlNNJfjTKnokVR330Ebm7d7OruBhNlomZTBQ3erGYYmAZAUiG6z86Ayr98IkKJ8QBDWwjUNUY6YkIn4V1dqsmJjuzjPdIBEgodiriQSQUilxFKLJCWVYZnzVsIrBtOWOLr0b+XyAATALugR4TFAgEgr2wezc8+mjn9rhxcOWVgzcfQf+RlWVnxYrL+clPVvHww/NJT7cM9pQEAoFAIDhk+uSofu1rX0OSJCKRCBaLpWN7b+i60Xd0KKYonFVWxurt2ynPyKAsEOgYT49EmLh2LSGnE02WCVgsuOIxRsWqQZPAbO48iSxBmgqfeGGGHdJtoCVIqgkcepRNcQtZNguKGgY1DmYnVbqTKK3kOUZgVYyIriIrpNkyqSpfwdWPLgKvEwqARzBEmwSCNmRZZvz48UINULBX7rnHEC5v5xe/GHgRpXaEffY/mqYjy51/h0eMSOfxx88ZxBkNbYSNClIdYaOCVGfQVH9XrVoFgMVi6bY9HCnMz2dxKMSS2lo2ut1YIhFM0SiFVVWkNzdTXVRE2GrFFY8zTW3BQQg0S/f8OTUCaS1Qp0FwNIydAqEqok0bqEuoxLUEJVISJAe4itHTRrJ15xoARmWM6jafdIeH3LWVJKq3gGsm/BoQXQYEvdD++ykQ7EllJTz+eOf21Klw4YWHdw7CPvuP559fz+9+91/efPNbOJ3W/R8g6BPCRgWpjrBRwZFGnxzVk08+eZ/bw43JY8ey1OFg+datvGwy0eB0ErJaSQKSojA+FmNURgaO5kajRlTZ4zLGGtvScq1gHg0mB2RM5IvGXdRorUTMWZhzTwCLG2QzFc3bCSfCmGQT+c78bqdyrDdjDyaJWaOwBBh9eK6BYGihaRrr169nypQpQg1Q0IOf/QwSic7te+6Bw/lQXthn//Hkk5/xve/9A12Hs8/+K2+99S3sdvP+DxTsE2GjglRH2Kgg1dE0rd/PeVBfVU455RTefffdvb6+atUqTjnllIOeVCpQmJ/P1XPncsyUKYywWHBIEqPMZk52uZiYn48jLQ102VDf7XoVk2HQk6DKYHWCzXBik5pKIOZHkxTS7DkkzJkgm2mNt/KV7ysAJudORpG63Hy2gmVHAkU3sfn7Nph62JYvEAiGCRs3wrPPdm7PmgULFgzefAQHz69+9RFXX204qQCTJuVgtR6m/G2BQCAQCA4zB+Wo/vvf/6aurm6vr/t8Pt57772DnlQqITmd+CZN4pP583EWF2NpauryahokZVC61OIm/MbPkA2y0qCt0XpzpIlMKUGOzUlh5lh8IR86Omt3r0XVVTxpHsa4x3Sepwb4CuqtPlqLPTjOGD/QSxUIBMOQn/4Uuj7kvPdeofQ7FLn33ve58ca3O7Z/9KMT+d3vzupWpyoQCAQCwXDioJO/9iWmtG3bNpzO4dUbJeRywbx50NwM7SJRugytFpA1QAc1ClocNB3CJjiuEBxGPUFjuB6XpBLJPIZ5Y8+kOdrMlsYtNEWaMMkmZhTMQGrvNdMAfAoqKrvy/YS/fhp51uF1PQUCwcCzdi288krn9umnwzCv3Bh26LrOHXe8y513/qtj7P/+72QeeOC0ff4dFggEAoFgqNPnnKGnn36ap59+umP77rvv5oknnuixn9/v58svv2TBMMstS7Pbkc46C95/H8rLoawMdB1aLJCtQjwAasxwUmvN/5+9+w6PotweOP6d3U0vbEgIgQBCKKFIUwRBUJDeBOyICKhcu3L53avgVWxXwY69gggCYkdpSi9XbChKDUgnEAIkm952Z35/zGaTkARSdrOT7Pk8T55hZ3dnzySHTc6+73sGmtaDXs7GSJoDS9YBDqoB+DW9huFxw1m+bznrD6/H3+xP54adCbY4r3mXAfwEDtXBvib7sLdvQb1Ww7B668RFrWAymejYsaN0AxQuqanwz3+W3Pfss96JRfKzajRNY8qUVbz++i+ufS+8MIB///sKL0ZVN0mOCqOTHBVG57WuvwDZ2dmcPn3adTsjI6NUQIqiEBISwt13382MGTPcF6UBqJoGsbEwfTrMnKkv/CoogDwgOwqs+ZCcDFnARQ3hts4Q5QfZx9HyUjmY52BeQQz/bXo1DUMbYtfs+Jn88Df7Y1bM5Dvy8cv3o2BrAcnmZGz1bbTo2IKwPtM5FR4rhaq4oPz8fAIDA70dhvAyTYPPP4cHH4TiKzSuvRa6dfNeXJKfleNwqNx99zI+/PAP17633hrGvfde5sWo6jbJUWF0kqPC11S4UL3nnnu45557AGjRogWvvfYa11xzjccCM5rc3FzUgADMHTrA88/DihUwbx7k58PpHLCYISgAeoVB78ZQPwkyz0BgNKesPXn16GdkWay0qt+Kjzd9TP2d9RmljKJLpy5sUbdw6Owh7PvtWLAQ7R/N6OGjGdZpGJPDYwGI8O7pC4NTVZWEhATpBujjjh2D++6D774ruT8oCP77X+/EBJKfVaFpcPasfuFbk0lhzpxrmDixi3eDqsMkR4XRSY4Ko/NE198qtQs8dOiQu+OoXWJjYeJN4JcIcxMhLg4uOQVNIqH3G2AO1NermgMhPJ5N+1ZyWvNniPlKTr16iqaLmjIlfQpxYXFE/C+CSQ0nkZCTQG5GLoHWQOJfjicsLgwNsDlf0uq9sxVCGJzDAe+8o0/4yMwseV+bNvDRR9CunXdiE1VjsZhYvPg6brjhc8aN68hNN13s7ZCEEEKIGlWhQvXo0aMANGvWrMTtCyl8fJ2SnQgnlkPSGvDfASPPQEg6NNAgpC2ENIeQJiWesj1pO3En4pjw8wTSD6YT4B+AGqcS0SwC8iFsaxjdErtBEPAh4Gz+mwPkO49hrbETFELUJjt3wuTJ8NNPJfdbLDBtGvznPyAzxWqngAALS5feLE2ThBBC+KQKFarNmzdHURRycnLw9/d33b4Qh8NxwcfUFgpA2i7Y8wJkHQT/CNAawNnToOZCAzMUpMP2adBhOlg7AHozjGO7jzFx5UTM2WZ2NtiJv78/3Zt01w96GEhBL1IbA58D3YDYotFUf0D+zhQXIlOBaj9Ng8RE2LsX9uyBv//WVxeUJzMTlizRl8sXd/nl8MEHcLGBBuEkP88vIyOPf/xjGc8+ezVxcUWLPaRIrTmSo8LoJEeFr6lQoTp37lwURcHPz6/EbZ+hKDQjFfOeFyD7KNRrD4oZ1ARw5Ot/XfpZIepyyNgPu2ZC1+chOJakzCTif46n8enGbG+8HUxwScwlBJgD4Ciwy/kanYHmwB5gBTC5qFCNAHzouy2qwGw207FjR2+HISrIbocDB/RidM+eosJ0717IyKj6cUND9V5v99wDRvp7RvLz/FJTcxg6dCE//5zITz8dZ9OmiTRtWs/bYfkUyVFhdJKjwug88UFKhQrViRMnnvd2nadp9Dy+DC3zIIrVWaQCqCqoeaBYIKw1mCwQ3gbS9sCJFdBqMjv/3kn3Pd05G3gWTNCsXjMahTWCZGCb8/htgJbOf1uB1cDNYAsr2iXE+WiaRkZGBmFhYb71IZLBZWVBQkJRQVpYjO7fX3oUtLpGjoS33oKmTd17XHeQ/CxfcnIWgwYt4M8/9RbN6el5nD6dLYVqDZMcFUYnOSqMTtM0tx+zSs2UypOfn09BQQEhISHuPKzXhRSk0/3E92h+EShKsU8L8m2gqWAyQ8hF+j7FDP5WChJXsMO/Db+u/5WrbFdxLPIY4ZZwOjXsBMeB3wANaAJ0KPZi0cAhIAFszktJWD1+hqK2U1WVgwcPSjdADzl0CF56CVauhJycij3H4YBiV/Sqknr19K/ziY2FKVPghhvAqH+7SH6WLTExnQEDFrB37xkAoqNDWLNmPB07NvRyZL5HclQYneSoMDrDdP399NNP+fnnn3n11Vdd+5566imeffZZNE1jxIgRLFiwgNDQULcF6k3N0vdRP+80hLUs2qlpkOO8SGFgpD6aCmTlZ3E8MxV7xn7eO3yUI/sacGXBlWRr2bQIbkHBvgL89/jrz2sEXErJeb1+gB3IlY6/Qnjbnj36VNpFi/TC01OaNNG78rZtq28Lv6KjjVt8iuo5fNhG//7zOXgwFYAmTcJZu/Y22rSJ9HJkQgghhDFUqVB9+eWX6dq1q+v2jz/+yFNPPcXw4cNp164db7zxBs8++ywzZ850W6DeElCQTpvU7dQrSNVHUE0RoPiB7U8oyNIfFBgFQEpOKtuT/iA9L43WZgcNA+vxp2bDbrYTbgrnZNJJsrKy6OLXhfoX1YeOlF58WoD+UwksuUZVCFFztm2D556Dr7/WP5NyB7MZWrUqKkILi9K2bSEszD2vIWqHffvO0r//fI4fTwcgLi6CtWtvo3lzq3cDE0IIIQykSoXqgQMHmDBhguv2okWLiImJ4euvv8ZisaCqKl9++WXtLlSdl6EZk7QGS8YBGmcfRck7DX6hgBnyz+pTdy3BYPYnKz+L7Ul/kJmfSVSAFQuZ7E45yL6odM6GnKX16dbY/Gyk+aWx/aLt9GjbgxCljCnSyejTf+NlRFVUTqBcg6TaNm3SC9Tvvy/7/ssu0zvqVlTDhkXFaKtW4O/vnjhrI8lP3c6dyQwYMJ9Tp/QPOtu2jWLNmvHExoZ7OTIhOSqMTnJU+JoqFap5eXkl/rP88MMPDB06FItFP1z79u15++233ROhN9h26Z17sw7i5x/BwXptCctPJUzNh/x0KLDpa1GDo8GUA4qJo2lHSc9LJyIwgnAtm2QHbLGdJsvfztGoo3TZ3YX0+unUq1+PVCWVo+lHaRfVruTrOtCr09FAGKQ6d1tr7sxFLWU2m2nbtq23w6iVNA1WrdIL1C1byn5Mv3769Uivvlqm4laF5GeRZcv2uYrUTp0asnr1eKKj61Zfh9pIclQYneSoMDqvdf09V4sWLVizZg133nknv/32G3///TfPPvus6/5Tp07V3vWp2Yl6keq8DE26YiZX00gKiiU2bSeKPUcvUk0BEJIFfpCvODiecYoAcwAmIEjNZUFaARkF0OZ0G45EHeG09TQxxJAUmESAPYDj6cdpGdESf7NziMUB7ANaAMP0XTZnSNYa/haI2kdVVVJTU4mIiMBkMnk7HENIT4c5c87f0EjT9NHTP/4o+/4RI+DRR6FnT8/E6CskP4s88sgVnD6dxZYtx1i5chz16wd5OySB5KgwPslRYXSGaaZ011138dBDD7F7926OHz9OkyZNGDFihOv+//3vf3To0OE8RzCwE8sh62DRtVKdTgbEgONXwAGWehAQhZpqIyejFaf3NsMUEEzIRWeIMZ9iX14By1NVItIjiE+JJ71JOqt6rWLIt0NofKwxmSGZHA88TlpOGg38G+jTfW3oRep0IFZ/TZvztWWNqrgQTdM4duwYVqvV26EYwqlTMHAg7NhR+eeaTHDjjTBtGnTu7P7YfJHkZxFFUXjppUHk5NgJDvbzdjjCSXJUGJ3kqDA6w1ye5oEHHiAwMJAVK1Zw6aWX8sgjjxAUpH8qnJKSQlJSEnfffbdbA60RBemQtAb8I0oUqWgq+SYFTEGgaDjONqJg29WwvTeWtAaEOfzpYs5HqXeGY+038XbDFSQpKXQ/czH50flY+lo4aT7J1xO/psNvHWi3vR2NTzfGP88fQtDXpI5GH0mNLXpZmforROUdPw4DBujXL60MPz+47TZ45BFo3dozsQnfs2zZPkJC/OjXr4Vrn6IoUqQKIYQQF1Dl66hOnjyZyZMnl9pfv359fvvtt2oF5TXp+yA3GUKL/qBALQB7NqBBUDRpyf1gQX8CTzVBCU5BiT6IxaRhs1vISmtIwbqbGVfvcswdP4XmEHN5jOvCzLZIG/8b/D+2XrEVda/KP7v+k3pN6kE8cE7XTxVId/7b6vETF6JuOHgQ+veHw4eL9vn5wfn6T4SFwfXXw7/+BU2bejxE4UM+/3wXt9zyFQEBZlavHk/PnpJgQgghREVVuVAttHv3bo4cOQLARRddRPv27asdlNc4ckG165efKVSQDooJFDNZeX3J+WgoltMNOdV8L0f8DqKZcklX65GZHo3DPxGl/glap7Rm4q6JrO+3nnwlv9TLHFWPEnJxCLFDYyGg7FAy0ItVgHpuP1FRF4X5+DVO9u7VR1ITE4v2xcXB2rXQvLnXwhJOvpafH3+8ndtv/xZV1bDbVebN2y6FqsH5Wo6K2kdyVPiaKheqS5cuZerUqRwuPnSB3mjplVde4ZprrqlubDXPHAgmC2gFoDibHPnXBzUfxeRHxsaWnE23sPLSj9hU/y/OmlNRFTsFagCW7FBan21N51OdCbQE0upMK5r8rwkHrztY4iUcqgNbro3R7UYTFlD+G47NuQ3DDZ8miDrPbDbTsmVLb4fhNX/9pRepxRsntWsHa9ZA48bei0vofC0/3377V+67b4Xr9u23d+Htt4d7MSJxIb6Wo6L2kRwVRueJrr9Vahu2YsUKrrvuOgCee+45vv76a77++muee+45NE3j2muvZdWqVW4NtEaEt4HAaH36byFFAZM/pJnYtyeUJy57lSUx68kx5dE8J4rWGY1okBpNriWXrc228lWHrzgReYKM4Awu/vNizFlFPzSH6mBfyj5aRLRgWKth5w1F1qeKylBVlaSkJI90XDO6X3+Fvn1LFqldusDGjVKkGoUv5edLL/1Yokh94IHufPDBNZjN0qXTyHwpR0XtJDkqjM4wXX+feeYZOnXqxObNmwkJKbr+2zXXXMP9999P7969eeqppxgyZIjbAq0RfuEQMwAOzoOgRiUaKmXv1VjcdCnHwxJpk90EMyYsFJBtB7uiEJEbQURBBEmhSXx10VcEZwfT5UQXgg8Ec7bDWZKzkrHl2mgR0YLpvacTGx5bfhzIpWlE5WiaRlJSEg0aNPB2KDVq82YYPhwyMor29egBK1dChLTLNgxfyE9N03j66Y08+eRG175p067guef6u/oUCOPyhRwVtZvkqDA6T3T9rdJHvH/99RcTJkwoUaQWCgkJYeLEifz111/VDs4rGg+HkDi9sZLmcO3+LfsIR0JO0DK3kbNIVbGrkKWC3aSimBVC/UOJy48jNTSV3xv+juJQOJ1ymkO2Q4T4hzCx60SeH/A8HaIvfOkem3Mrf2sLUbbVq2Hw4JJF6lVX6fulSBU1SdM0HnlkTYki9b//7cfMmQOkSBVCCCGqqEojqoGBgaSkpJR7f0pKCoHna7NpZMGx0GE67JoJabsxBTVmT3BrNpt/xWq3YtEsmJUCHJhJK1DJMquAQoAlAJNiwoQJq2rlQMMD5AfnM6brGJpc3YT4yPjzrkk9l825tXrgFIWo7b79Fm64AfKL9SobPBi++gqCg70Xl/BNf/yRxMsvb3XdfuWVQfzznz29GJEQQghR+1VpRPXqq6/mtddeY+vWraXu+/nnn3n99dcZMGBAtYPzGmsHEi95kfe7zOLRtlNZEHwxf4dZsPg1JZ2GnPGPxGYKJlPR52JbNBP+Zn/X0yMKIkhT0vi72d/0H9Kfbo27VapIBVmjKipHURTq16/vE6M3n34K115bskgdPRqWLpUi1ajqen5eckkj5s0bhdms8N57I6RIrYXqeo6K2k9yVBidJ3KzSiOqL7zwAj179qR37950796d+Ph4ABISEvjll1+Ijo7m+eefd2ugNWkXMDOoEQeDGnHGUUBWWgr5FoW0hhrBByxkhYSBuQA1PwfFnkeg6l/i+WaHGc2kkXNZDmFRVWslbnNurdU5EeEzTCYTzZo183YYHjd3Ltx5JxRfBnHLLTBvnn69VGFMvpCf48d3pmfPprRqVd/boYgq8IUcFbWb5KgwOpPJ/U0Dq3TEFi1a8Ndff/Hggw+SmprKkiVLWLJkCampqTz00EP8+eefNK+lFy5MBGYCR4H2QIjZj6yghtjNQdiaW8gOtRNuU1ExoQZHopksmIp/G1UwZZnAH1oNbVXlOGzOrbXKRxC+RFVVjh49Wqe7Ab75JtxxR8ki9c47Yf58KVKNrq7lZ26uneXL95XaL0Vq7VXXclTUPZKjwug8kZuVLlQdDgdJSUmEh4fz6quvsnfvXnJycsjJyWHv3r288sorREdHuz3QmrIcOAi0AQp7/poj20BwA7KVFE5eYiEnRMWaCiF5gSh+YaABKpizzQRkBHDaeppGbRpxxaVXVDkOm3Nrrca5CN+haRopKSke6bhmBM8/Dw88UHLfQw/B+++DBy7bJdysLuVnVlY+I0cuZsSIxcybt93b4Qg3qUs5KuomyVFhdF7t+qtpGo8++igRERHExsYSHh7OmDFjzttUqbZJB9agd9ot/revKSAcvxb9yctNJb++mcM9FPY3T6fAbCe0oB7+9mD8svzQLBo5rXIoiC9gzOVjKr0utThZoyqEPno6YwZMm1Zy/6OPwquv6pc5FqKmpKXlMnjwJ6xZcxCAhx5axdmz2V6OSgghhKibKrxGdd68ecyaNYsmTZowZMgQDhw4wNKlS1FVlaVLl3oyxhqzD0gGWpRxn1+roYQf20Jayj4IaUhqyywON0onLD+CLvvthLcNIDQqlENZh4ivF8+wVsOqFYvNubVW6yhC1F6aBv/6F7zySsn9zz6rF6pC1KSzZ7MZMmQhv/12AoB69QJYuXIckZHSwUsIIYTwhAoXqu+88w5du3Zly5YtBAUFAfDQQw/x1ltvcebMGaKiojwWZE3JBexAWcvdLPWa0rn3dP783yyOJ21HNfujmoI4G2HHHOhHVr0sEjMSaRHRgum9pxMbHlvlOPKBws/o5XKQoiIURSEmJqbOdANUVbj3XnjvvZL7Z8/Wp/yK2qW252dSUiYDBy5g585kAKKigvnhh1vp2rWRlyMT7lLbc1TUfZKjwug8kZsVnvp74MABbrvtNleRCnDvvfeiqir79+93e2DeEIheuRece4eiYDKbiWx4MV37PYPloj5gCUTLOYuWdogk0zFC/EOY2HUizw94ng7RHaoVR5pzawJCq3Uk4StMJhMxMTEe6bhW0+x2mDixZJGqKPDBB1Kk1la1OT+PH0/nqqvmuYrURo1C2bhxohSpdUxtzlHhGyRHhdF5IjcrPKKamppKgwYNSuwrHEXNzc11b1Re0gaIRp/+28S5z5GXTsGZBNT8LJL9gsnyDyUwbiD1WgzAlpKIX2Y6r6zpwCVPDajWmtTiiq9Plc/NREU4HA4OHz5M8+bNMdfi7kL5+frlZr78smif2ax39r3lFu/FJaqntubnwYOp9O8/n8OHbQA0a1aPtWtvk+6+dVBtzVHhOyRHhdE5HA63H7NS11Gt69MNwoEBwDwgPD2RxP3LOXpwDVlZyWiOAn4yWcg1+1FQvzXRbUbiCO/JFT+s56q/u8OOML3SDa9+HDbn1lr9QwkfkpGR4e0QqiUnB66/HlasKNrn5wdLlsCYMd6LS7hHbctPVdUYNepTV5HaqlV91qwZz0UXWb0al/Cc2pajwvdIjgpfU6lCddq0acycOdN1u7ByvvPOOwkJCSnxWEVR+PPPP90QYs0aDnybvIu1W2aipB5EDYzAbG2OioUw7KQm78K0fyOmHSlM3zqZPr/3hfRI+Bf6cOwA50GqvkTVVajK+lThKzIz4ZprYP36on2BgfD11zBkiPfiEr7LZFL48MORDBiwgGbN6rFmzXgaNXLPrBkhhBBCXFiFC9Urr7yyzBHV2nzN1DKlJ8KWmZB2FC2qPYrJDGgoqka+qhGuNuXiQyGkKYf5rv4LREYMp6u9g94qOBn4GNgETAequFTV5txaq30yQtQsh0Pv1lsZ6ekwYgRs3Vq0LzQUli2Dq65yb3xCVEaPHk1YvXo8rVrVJypKuvsKIYQQNanCheqGDRs8GIZxLN+/nJTUg/SPak+iycwOwAFgUshNV+m0M5iILIWGEc35I2wrv8T+wbgzCvijL2xthH6dm5nA81RpZNXm3FqrfzrCRyiKQtOmTb0yPd9uh88/h5degt9/r/7xrFZYuRIuv7z6xxLG4M38rIy9e88QHx9ZIs7LL29ynmeIuqK25KjwXZKjwui82vXXF6TnpbPm4BoiAiMIN5lpBzQDQlEIQSFuTzLW1Dz8wu34YyKkIJg/Gu0mwy+r6CBm9LWqh4AVZb7MBdmcW2vVT0X4GJPJRGRkZI12A8zL0zvxtm2rNzpyR5EaFaVP/5UitW7xRn5W1vff/80ll7zH1Knfo1V2WoCo9WpDjgrfJjkqjM4TuSnZXsy+s/tIzkomOqRoOnNBro3MvV9RsG89EUkW8i15BPsFo6FRLzeMtMB0EqznXJ7HjF5lrgaqsO7d5tzKGlVRUQ6Hg71793qk49q5srL065m2bAn/+AccOOCe4zZqBJs2QZcu7jmeMI6azM+q+OabvVxzzafk5NiZPftnPvnkL2+HJGqY0XNUCMlRYXRe7/pb1+Xac7GrdvxMfq59Z87sRXXYCbHl45/vjz3EjtlkBoeGWTPjUFRyLfmlDxaNPqqaAHSrXBzFL08jREV5+jJRNhu89ZZepJ45U/r+kBC4/XZo2rTyxw4O1jv+NmxY3SiFURn1MmaLF+9g/PivcTj0UdTrrmvHTTdd7OWohDcYNUeFKCQ5KnyNFKrFBFoCsZgsFKgFFKgFHE07SnraUdSCTEz5wWgOjTw1j9TcVCyYcSgOzJqJQEdg6YP5AXagCu8pNufWWuUzEcJ9Tp3Si9O33oKyOuNHRMCDD8IDD0BkZI2HJ0SVzZnzO5Mnf+dqADZ+fCfmzh2FxSKTjYQQQghvk0K1mDaRbYgOieZg6kFOZJ4gPS8dTVNBMeMwa2iKhhkzablpKCjYAjOonxNOfFrb0gcrQP/ullHDXojNuZWpv8KbduyA99+HDz+Esj7EbdgQ/u//4O67IUyu2iFqmTfe+JkHH1zlun333Zfy1lvDMZmkUYkQQghhBPKxcTHhAeF0a9yN3Wd2k5GXQURgBGazH1romYIAAPf9SURBVAqQFpRBnn8eIY4QAswBFGj5pPtn0fVkB8IK6pU+WDL69N/4ysWgISOqovJMJhNxcXHVXshus8E778Bll0GnTvDmm6WL1IsugrffhsOH4d//liJVXJi78tNdZs3aUqJInTr1ct5+W4pUX2a0HBXiXJKjwug8kZvVGlFNTExk06ZNJCcnc91119GkSRMcDgdpaWnUq1cPs9nsrjhrjKZperVY7O8VDSgw53O2/lkiTkeQG5DLqZBTNMiMomPyxXBuO2YHerU5GqjkH/HZ6IOxAGWUv0KUSVEUwsPDq/RcVdU77c6dC199VfboKejdfadPh7Fjwc+v7McIUZbq5Ke7vf76z0yfvtZ1+/HHr+Spp/rKJR98nJFyVIiySI4KozPM5Wk0TWPq1Km0aNGCcePGMXXqVPbt2wdAZmYmzZs354033nBroDUhPS+dbSe30S6qHWH+YaTmpuJw5IOmgqaR2iCVI9YjnLCcIDo3muH7hhJor0e+UqyZkgP9OqotgGGVj8Hm3AZSpVnDwkc5HA527NhRqY5rhw/DU09BXBwMGACLFpVdpF5+OXzxBezaBbfdJkWqqLyq5KenXHddO1q0sAIwa1Z/nn66nxSpwlA5KkRZJEeF0Rmm6++LL77Ia6+9xiOPPEL//v0ZOHCg67569epx7bXX8uWXXzJlyhR3xVkjCi9P07J+S5rVa8bR9KP8fOov9E4bGpl+mQQ0DuCav65h0I4B5Ofmkhp4hjRzGg3yG+jTfW3oRep0ILbyMdicW1mfKiqrIm8QOTnw9df66OnateU/LjpaL0onTYL27d0YpPBZRvnjKjY2nLVrb2PdukPccccl3g5HGIhRclSI8kiOCl9TpUL1gw8+4LbbbuO5557j7Nmzpe7v1KkTK1eurHZwNa345Wn8zf60i2rH9swk8rUkAHo26Yk10IraSGW73zZa/NqcZmnN8c/21y9FE40+3XcYVSpSQdaniopxOOCPPyA9vej2oUOhnD4NZc24z8uD777TR03T0so+ptkMw4frl5gZNkxGTkXdYLerFBQ4CAoqSugWLSK44w75OFAIIYQwsioVqseOHaNXr17l3h8SEkJ64V/QtUjxy9P4m/0BCPILJsvsD5pGg+AGKIqCLdLGH71/JCFqBxefas/Lx+ZS76V6euOkajaWkWuoivPJy4MFC2DWLDhwoPg9ZqBVlY7Zrp1enN56K8TEuCNKIYwhL8/O2LFfkpVVwLff3kxAgDS6F0IIIWqLKv3Wjo6O5tixY+Xev23bNpo1a1bloLyl8PI0yVnJNAlvAugLg02KgqYoJRosqaoDW1AGByL/JPZsLHRzTww259bqnsOJOiIrS79MzIsvQmJi9Y8XFgY336wXqD16lO4HJoQ7mUwm4uPja7RbZU5OAdde+xmrVv0NwPjxX/PZZzfU2OuL2sUbOSpEZUiOCqPzRG5W6YjXXnst7777LgcPHnTtK2xG8cMPPzBv3jxuuKH2/UEQHhDOgLgBehMlteQ6gHP/jneodhyKRlxaMGEO912fw+bcyqQ0Afry6JdfhubNYcqU6hepffvCxx/DyZP6NVIvv1yKVFEz/P39a+y1MjLyGDZskatIDQqycOedsh5VnF9N5qgQVSE5KnxNlUZUn3rqKdavX0+XLl3o06cPiqLw/PPP8/jjj7N161a6du3Ko48+6u5Ya8Tw1sPZdGQT+1L20aZ+G9f+4petcagOTuQkE6CaaJPq3otI2pxbq1uPKmqr//4XZswovd9qhQcfhKFD9ULT4XBw4MABWrZsWe5loZo0gdgqrp0WojpUVWXHjh107NjR45cts9lyGTp0IT/9dByAsDB/li+/hT59LvLo64rarSZzVIiqkBwVRqeqqtuPWaVCtV69evz000+8/PLLfPHFFwQGBrJx40ZatmzJE088wb///W+CgoLcHWuNiA2PZXrv6czcMpPdZ3aTl5eBpqloGuQ78jmdfRpbro36fvWw5J6ifr57LyIja1RFoaQkfS1qcQ0bwtSpcPfdUPxyag4HBAdn07Fj2c2UhPAFp09nMWjQJ2zfrjfAi4gIZNWqW+neXT6hEUIIIWqbKneWCAoK4rHHHuOxxx5zZzyG0CG6A88PeJ4Vf69g+o+voDny0TSNQ7ZDNAxtyOh2o0nbv5NPD/yNWXNvVWBzbq1uPaqojZ57DrKzi27PmAHTpkEt/QxICI86cSKDgQMXsHv3aQAaNAhmzZrb6NSpoZcjE0IIIURVSAvEcsSGxzL5ksnMOZ3A9v3L0VQHLwx4gfbR7QkLCOP9g9MBMGvuXThsc26tbj2qqG2OHIH33iu63bEjPPEESA8FIUpLTEznqqvmceCAPielceMw1q69jbZto7wcmRBCCCGqqkqF6u23337BxyiKwpw5c6pyeEMxWwIw+4cA0L1Jd1fTKLs9HwCLaindaakabM6t1X2HFLXQ009Dfn7R7WefPX+RajKZ6Nixo3QDFIbk6fysXz+Ipk3rceBAKs2bW1m79jbi4qQlnag4eQ8VRic5KozOE7lZpUJ13bp1roKtkMPh4OTJkzgcDho0aEBISIhbAjQK7ZzbdrUAAHPVGieXSQUKrz5rddtRRW1y6hS88grMm1e07/LLYcSICz83Pz+fwED3rpkWwl08mZ9BQX58++3N3HffCp57rj9NmoRf+ElCnEPeQ4XRSY4KX1OlKuvw4cMcOnSoxNfRo0fJzs7m9ddfJywsjLVr17o7Vq/SVLVENyuHww6AWXXf7Ok0igriem47qqgNjhyB++/XL0PzwgtQvHHac89d+BIyqqqSkJDgkY5rQlSXJ/JT00p+fBgWFsD8+WOkSBVVIu+hwugkR4XReSI33TpG6+fnx/3338+gQYO4//773Xlow3E49BFVixubKdmc23BAGrf6hr17YeJEaNUK3noLcnNL3j9hAvTr55XQhDCsH388Ro8eH5KUlOntUIQQQgjhIR6Z6N65c2c2bdrkiUMbht1VqLpvRFUuTeM7/vgDbrgB2reHjz8Gu73k/e3bwyefQB1Y5i2EW61bd4hBgxbw668nGDhwAWfPZl/4SUIIIYSodTzS9Xf16tUEBwd74tCG4XA4ANx6eRqbc2t12xGF0WzZok/lXbmy7Pu7dYP//AeuuabyHX7lAuDCyNyRn8uX7+O66z4jL09//23UKJTAQGleL9xD3kOF0UmOCl9Tpd/wTz/9dJn7bTYbmzZt4vfff2fatGnVCsxoTCZTiTcIh+pco+rGEVWbc2t12xGFEWga/PCD3rl38+ayH9O3Lzz6KAwYcOH1qGUxm8107NixWnEK4SnuyM8vv9zN2LFfUlCgr4G55pp4liy5XgpV4RbyHiqMTnJUGJ0nPkip0m/4J598ssz9ERERtGzZknfffZfJkydXJy7D0dCbd7guT6O6f+qvzbmViyrUDaoK33yjj6Bu21b2Y4YP1wvUXr2q91qappGRkUFYWFipjtxCeFt183PBgj+ZOHEpqqo3ULrppg4sWDAGPz8ZXRDuIe+hwugkR4XRndvk0B2qVGX5Ysexwq6/hZ8W2Au7/rpx9rTNubW67YjCGwoKYPFimDUL9uwpfb+i6OtTp0+HLl3c85qqqnLw4EE6duwoU4OE4VQnP9977zfuuWc5hb//Jk7swocfjsRslmsJCveR91BhdJKjwugM0fU3JyeHqVOn8t1337k9mNrEoRauUZVCVeg0DZYu1RshTZhQuki1WOD22/VOv0uWuK9IFaKuevXVrdx9d1GRet99lzFnzjVSpAohhBA+oNK/7YOCgnjvvfc4deqUJ+KpNeyqnZC8MKIy2ugV5m9AevWOaXNuZepv7bNjBwwcCKNHw99/l7wvMBAeeAAOHNC7+LZp45UQhahVNE3j779TXLcffrgXb7wxFJNJprwJIYQQvqBKw4GXXnopO3fudHcstUciXPa/gQz58046JbcDBfgXEA0MAIYDsZU/rM25tbonSlEDTp+GJ56A997T16QWFxYG990HU6ZAw4aejyUwMNDzLyJEFVU2PxVF4Y03hpGVVUDLlhE89tiVsi5LeJS8hwqjkxwVvqZKhers2bMZNmwYF198MRMnTsRiqftdF11df3cBM6H7r4NINB0j2/8M+AMtgGTgY2ATMB3oULnXkOuo1h75+fDWW/DUU5CWVvI+iwUefBAeewwiamh43Gw207Zt25p5MSEqqar5aTIpfPTRKClQhcfJe6gwOslRYXSeWDtd4am/mzZt4vTp0wBMmDABk8nEXXfdRXh4OK1bt6ZTp04lvjp37uz2YL3Bbs/DkZ+FPS+DX/74hfTn0+EonIg+xOnQEygmTR9R9QeaAO2Ao8BMILFyr2Vzbq1ui164m6bB8uXQsSNMnVq6SB05EnbtgpdfrrkiFfQF7GfPnvXJRmfC+CqSnw6HyoMPrmTbthMl9kuRKmqCvIcKo5McFUbnidys8FBov379+OSTTxg7diyRkZFERUURHx/v9oCMIjE9keX7l3Ng/3IKMo6jaRr/XvlvGoY0ZEDXAUT+YUbJBUU7548oM9AG2AOsACp4lZ48IMf5b1mjaky7d+vF6fffl76vfXt49VUYNKjm4wJ9Pd+xY8ewWq3eCUCI87hQfhYUOBg//muWLNnFokU72LBhIhdfHF2zQQqfJu+hwugkR4XRefXyNJqmuQLYsGGD2wMxkl3Ju5i5ZSYHUw/iUAtQzP74FfjRIrkFpwNO83HwxwTHWxi+uz89TpVRrJvRh0VXAzcDYRd+zcKBOQsQ7KbzEO6RkqKvQ33nHXA4St5Xvz48/TTcdZc+5VcIUTm5uXZuvPFzvvtuHwDp6XkcOJAihaoQQgjh46TH/zkS0xOZuWUmR9OO0j6qPQEBYSiKCWtuGP45/jSxNKGdvR2ngk7zVfwKToWcLftA0ehrVhMq9rrF16fKRDdjKCiAN96AVq3gzTdLFqlms74Odf9+vWGSFKlCVF52dgHXXLPYVaQGBJj55pubGTVK1mEJIYQQvq5ShaovrBVavn85B1MP0qZ+G8ymokXBZs0MKmACM2aaZDYiOeQM65v+XHZl6QfYgdyKva7NubVWJ3jhFseOwX//C/HxejGamlry/qFD9cvRvPaaPqJqFGFhFRi6F8JLzs3P9PQ8hgz5hNWrDwIQEuLHihXjGDastTfCE0LeQ4XhSY4KX1OpQvXWW2/FbDZX6Ks2dgJOz0tnzcE1RARGlChSARwmB4pJ0YtVwISJkIJgNjX7hQz/jNIHK0Cfx1vBTuI251bWp3pHbi4sWQJDhsBFF8Hjj8OhQyUf07YtrFihf7Vr5504y2M2m2nZsqVHOq4JUV3n5mdKSg4DBsxn8+ajAISHB/DDD+O5+uoW3gxT+DB5DxVGJzkqjM4TuVmpanLAgAG0adPG7UEYxb6z+0jOSqaFtfQfS2lBmWhBGkqOAiGgoVEvN4wzwakkRCTQjW4ln5CMPv23gv2mbM6tterhiyr44w+YOxcWLiw9clrIatUvQ3PPPeDnV6PhVZiqqiQnJxMdHY3JJDP6hbEUz8/Tp7MZOHABO3YkAxAZGcQPP4znkksaeTlK4cvkPVQYneSoMDqvdv0F/bI0t9xyi9uDONdbb73Fiy++SFJSEp07d+aNN96ge/fuF3zep59+ytixYxk1ahTffPNNpV83156LXbXjZypdjRSYCyAW2Ife7UjTpwM7FAe5fufM73WgV56jqVAjJZBrqNaks2dh0SK9QN2+vfzHtW4NkybBP/4BkZE1Fl6VaJpGUlISDRo08HYoQpRSPD/XrTvkKlJjYkJZvXq8NE4SXifvocLoJEeF0Xm1629NWbJkCVOnTuXdd9+lR48ezJ49m8GDB5OQkEB0dPl/zBw+fJh//etf9OnTp8qvHWgJxGKyUKAW4G/2L/2ApkASkKZfT9OhODCrFgIdxeb3OtCL2RbAsIq/ts25tVYtdHEBDgesXg0ffQTffAP5+WU/LiQEbrpJL1CvuAJ8YFm2EDVq7NiOnDqVxSuvbGXt2tto3drgnwIJIYQQwisMN3fglVdeYfLkyUyaNIn27dvz7rvvEhwczNy5c8t9jsPhYNy4cTz11FPExcVV+bXbRLYhOiSa5Kxk1z5VMaMGWtGCIjkdAgVdgFAIzQ0nx1JAdHYU8RnxkA8cR79+ajNgOvoIbAXZnFtZo+pemqY3PWreXG+C9NlnZRepvXvrI6xJSTBnjn5bilQhPGPKlMvZufNeKVKFEEIIUS5Djajm5+ezbds2pk+f7tpnMpkYMGAAW7duLfd5Tz/9NNHR0dxxxx1s3rz5vK+Rl5dHXl6e63Z6ejqgF7vhlnD6N+/Px399THhoIxJNJtKtzVE1FVD4SYHgCLiou0bGj0fIdmRx667rCU0JhUOgNlBhFGhDNIgFk2ZCURQc51x8s3BtQfG53CmKAopCPcBxzhxvs9mMpmml5n6bzWZUVS011F7WfkVRMJlM5e4/N8by9ptMFT+n8+2vqXP67juYMqXsxd2NGmmMH69x++0K8fFF51R4akY9p+KKP95qtbpeu7b9nMo6p9qee3JO+v6//jrFvn1nufxy/WO4wv0hIRYcDketPKfi+8uKXc6p9p1T8ffQunJO58Yo51S7z0nTtBK/5+vCOdXFn5Mvn5NXp/56YoHsuc6cOYPD4aBhw4Yl9jds2JC9e/eW+ZwtW7YwZ84ctp9vsWExM2fO5Kmnniq1f9euXYSGhtLC3oKgwBjWpuxDrdcSFQXyswCNYH8rBRYLf/rnk946m/AzZ7kkPZz8rvkE/DeAv5W/yTZnQwqQAnFxcYSHh7N79+4SCRQfH4+/vz87duxw7Tty0UVgtRKUl8eOYudqNpvp2LEjGRkZHDx40LU/MDCQtm3bkpqayrFjx1z7w8LCaNmyJcnJySQlJbn2169fn2bNmnH8+HFSUlJc+2NiYoiJieHw4cNkZBR1L27atCmRkZHs37+f3NyiNbiVOSeAjh07kp+fT0JC0QVla/Kc1q4NAhq77vPzg3790hkx4jQ9e2ZgsUCjRnFA7Tmnsn5OBw4cIDc3F5vNVit/TnUx9+ScdvPnn2e4776tZGfbWbRoNE2aNKn151QXf05yTkXnlJGRUefOqS7+nHzxnNLS0rDZbK7f83XhnOriz8mXz8nPAx1HFc0T5W8VnThxgtjYWH788Ud69uzp2v/www+zceNGfv755xKPz8jIoFOnTrz99tsMHToUgIkTJ2Kz2cptplTWiGrTpk1JSUkhPDycROCeM3v49X+zIPUgNhQKLAGgmGkdHktu1mnyclNJ9QsnqEl/fpjZjO5tbkR5q+xPMyr6KcdQk4kUYCHQSj65cds5zZyp8PjjRTPck5Ohfv3afU7FFe4vKCggMTGR2NhYTCZTnTin2p57vn5O69cfZNSoJWRk6HPte/RoyJYtd5a6HndtOqe6+HOScyoaUS18D/Xz86sT53RujHJOtfuc7HY7x48fd/2erwvnVBd/Tr58TmlpaURGRpKWlkZ4eDjuYKipv1FRUZjNZk6dOlVi/6lTp4iJiSn1+AMHDnD48GFGjhzp2lf4DbZYLCQkJNCyZcsSzwkICCAgIKDUsQqv/7oKSG14Mf0HPE/i3yv4ZecSyDwJqkqGI5/g0IY0bzeaPVm55MR2Y9MVCj1siusYZbnQfg1Ic+6LKOfxiqKUub8w4aq7v6qxV2d/TZzTuXfpzfJq9zmV93ibzUbTpk1LPKY2n1Ntz72a3m+kc/rhhwOMHv0pOTl2AK666iKefbZDuTGWdxwjnZO79ss5GfecCt9Doe6cU3FyTrX7nBRFKfP3fG0+p7r4c/Llczr3g2h3MFSh6u/vz6WXXsratWsZPXo0oBeea9eu5f777y/1+LZt25Ya0n7sscfIyMjgtddec/3Cqah0YA16sRgeHkv4JZPZG9GKlBO/ojnyuTxuENYG7fAPCCPhl/mYs2xsufxi7t5S4avQlCkTvVkwSNdfIUTt9u23Cdxww+fk5+vvakOGtOLzz6/j77/LXr4hhBBCCFEWQxWqAFOnTmXChAl069aN7t27M3v2bLKyspg0aRIAt912G7GxscycOZPAwEAuvvjiEs+3Wq0ApfZXxD4gGf3KMoVM/iEo9VuBptGgcTcU56cHGhqWzNOciQwioRF0q8K5FrI5t8FAGRfFEUKIWuHTT3dy661f4XDoU4HGjGnL4sXXYbFIC20hhBBCVI7hCtWbbrqJ06dPM2PGDJKSkujSpQurVq1yNVg6evRouUPQ1ZUL2IFylwI7h7Q1TUPTNBSHHUeAidzSM4krxebcWqt3GOHDFEUhJibGI9MuhKiIuXP/4M47v6Vwucq4cR2ZN280Fou+BkfyUxiZvIcKo5McFUZX56f+Frr//vvLnOoLsGHDhvM+d968eVV+3UD0b0gBpUc2FUVx/QA09L/ENLMffg6FwGq2o7I5t9bqHcYnHTmiX/c0MbHs+yvYDLrWM5lMZa7jFqImJCVl8sADK11F6uTJl/DOO8Mxm/UPFSU/hdFJjgqjkxwVRueJgURDFqre0gaIRp/+2+Sc+zRNQ1NVFJMJTdMbNtlDGxCdaCc+jWpJdW6t1TuMz1m4EO65B4p17/ZZDoeDw4cP07x583IXzgvhKTExoXz99U2MHLmYe+7pxquvDi7xyarkpzA6yVFhdJKjwujO7TzsDlKoFhMODADmAY0orzcsqJqGpphwhFgZ+GMGYWENqvW6NufWWq2j+I70dLjvPvjkk8o9r3HjCz+mNsuQil140aBBLfnjj7to1y6qzOk/kp/C6CRHhdFJjgpfI4XqOYYDm9AbK7Up5zF2NPKiWhJw5jDDNofBNdV7TZtzG1G9w/iErVth3Dg4dKjk/pgYCAkp/3mRkfDUU56NTQhfoWkaq1b9zdChrUvsb9++eh/aCSGEEEIU8kxXolosFpgONAN2A3kB4WgmCxqQDxwH9qLgbztGzA8v0zRZOU/3pYqxObfW6h2mTnM44JlnoE+fkkWq2azvP34c/v67/K+ff4YhQ7wXvxB1hapq3HPPcoYNW8Rzz232djhCCCGEqKOkUC1DB+B5YBJgduSjhcVCRByHFIUQ4GZ7DrHLnyT05B4Uxa/a49I259ZavcPUWUeOQN++MGOGXrAWatECNm+Gxx7TC1ZfpigKTZs2lW6AwqPsdpWJE7/hvfe2AfD44+vZtSv5gs+T/BRGJzkqjE5yVBidz3T9NYJYYDIwZ8/XbE/5G8z+vDxqDvFAZn4Wi9JOYFYVUCwyoupBS5bAXXdB2jkNq269Fd56C8LDvROX0ZhMJiIjI70dhqjD8vMdjBv3FV98sRsAs1lhwYIxdOgQfcHnSn4Ko5McFUYnOSqMzhNdf2VE9QLMjnzMZ/agnPyDrg4HYYBDcwAaFk0BzG4bUZU1qkUyMmDSJLj55pJFaliY3kRpwQIpUotzOBzs3bvXIx3XhMjJKWDMmCWuItXf38wXX9zI2LEdK/R8yU9hdJKjwugkR4XRSddfg7CrdtDAoiqgmGVE1c1+/x1uuklfW1pcz576JWlatPBOXEaXm5vr7RBEHZSZmc+oUZ+ybp2+ODww0MI339zE4MGtKnUcyU9hdJKjwugkR4WvkUK1ChyqAzStaOpvNb6LdiDd+W+rG2Kr7Q4dgn799EvQFDKZ9HWojz8OFslYIWqMzZbL8OGL+PHHYwCEhvqzbNlYrrqquXcDE0IIIUSdJ3/2X0BwVgBdD7cjIN8PfgPaOaf+ahpmN0z9LazHFPTruPoyhwPGjy9ZpDZrpo+i9u7tvbiE8FUTJ37jKlKt1kBWrRpHjx5NvByVEEIIIXyBFKrlSQSWw7SFY/A7mY9FNWP6zQTRENojhAaZjTCrZ6rdTMnm3NZDFgy/+CL8739Ft3v2hBUrwGr1Wki1hslkIi4uziML2YXveuGFgfz003FUVWP16vF07hxTpeNIfgqjkxwVRic5KozOE7kphWpZdgEzgYMQqPpxIOoQBWY7vVp0gWSot7geD2T+lxXxs/U1qtX4LqY6t9bqxlzL/fGHfvmZQmFhsGiRFKkVpSgK4dJdSrhZmzaRrFlzG2azQrt2Dap8HMlPYXSSo8LoJEeF0Xni8jTyscy5EtGL1KNAezgdlU6BxY6GhuqnQhPIaZlFTEYTbtgxFQr83DKiaq1u3LVYTo5+uZmCgqJ9b7wBzZt7LaRax+FwsGPHDukGKKrl6NE0CgpK5tDFF0dXq0gFyU9hfJKjwugkR4XReSI3pVA913LgINAGMJf9EFVROWLdT8OMiyDdr1ojqjbn1lr1Q9R606fD7t1Ft6+9Fm67zXvx1Fbyy0tUx65dyfTo8SHjx3+Nw6G6/fiSn8LoJEeF0UmOCl8jhWpx6cAa9AuallOkAmiaA82kku1ngwwzFJT/2AuxObe+eg3VNWvgtdeKbsfEwHvvgQdmDwghyvHHHye56qp5JCVlsmTJLp55ZpO3QxJCCCGEj5NCtbh9QDIQXbTLZIewVAjMKdqnqfpoQ0bAaf36MolVf0lfXqOakgITJ5bcN3cuREV5JRwhfNLWrcfo1+9jzp7V3+S6dWvMAw9093JUQgghhPB1UqgWl4teeBZbcxpyRt/65yko6MN8mqYXqpriAE2BaszEsDm31qofotZ69llILFbk33svDB3qvXhqM5PJRHx8vHQDFJWyYcNhBg5cQFpaHgBXXNGUNWvGExkZ7NbXkfwURic5KoxOclQYnSdyU7K9uED09abFpvIqWumHqapemVpUP/0CqNX4m87m3Fqrfohaa/Pmon/HxcELL3gvlrrA39/f2yGIWmTlyv0MHbqQrCz9DW/AgDi+//5W6tUL9MjrSX4Ko5McFUYnOSp8jRSqxbVBn/abXPbdGnrVqjqn/obnNdAL21ZVf0mbc+uLa1TVYv1aunSBkBCvhVLrqarKjh07XLkpxPl89dUeRo36lNxcOwAjRrThu+/GEhLimT+CJD+F0UmOCqOTHBVG54nclEK1uHBgAPrC0fNM59U0FUU1EZJv1Z9jrfpL+vIaVSFEzVuxYj833vg5BQX6L5Qbb+zAV1/dSGCgXFZbCCGEEMYhheq5hgNx6I2VyilWNbuDi2ytSQk+BvWQy9MIIWqNXr2a0rlzDAATJ3Zh0aJr8fM7T5tzIYQQQggvkEL1XLHAdKAZsBsi0sOxOCygAfnAcQg9HEFS2DHWtXoX/CnRfKkycoE857+t1Q5cCCEuzGoN5Pvvb+XZZ69mzpxrMJvl14AQQgghjEfmepWlA/A8sALyXs2naXosJs2EcliBaDg8cCdvZD3OxUkaZFDl76LNufUHgtwRt/BZJpOJjh07SjdAUYqmaeTk2AkOLvpELSoqmEcf7VNjMUh+CqOTHBVGJzkqjM4TuSmFanligcnw4d9fk3Hsb/zt/sz/94fQFv7e9Aen15zEosXqj63iiGrx9alK9SMWPi4/P5/AQM90bBW1k6ZpPProWn744SBr196G1eq9/JD8FEYnOSqMTnJU+Br5WOYCcgPy2dVwD7/H/ol6iQph4HDol3Mwq851XdUcUbVWN0jh81RVJSEhQboBChdV1XjooVXMmvU/fv/9JMOHL8Ju905+SH4Ko5McFUYnOSqMzhO5KSOqVWAvLFRxFqpVHFG1ObfW6gYkhBDFOBwqd921jDlz/nDtGzeuIxaLfDYphBBCiNpBCtUqcNidharm/KNPRlSFEAZRUOBgwoRvWLx4JwAmk8LcudcwYUIX7wYmhBBCCFEJUqhWgd2RDxpYVOe3r4rfRbmGqnAns1kuMeLr8vLs3HTTFyxdmgCAxWJi4cJrufHGDl6OTPJTGJ/kqDA6yVHha6RQrSCFojcIh8MOgEUz66t8qzibzubcWqsZmxBms5mOHTt6OwzhRdnZBYwZs4QffjgAQECAmS++uJERI9p4OTLJT2F8kqPC6CRHhdF54oMUWbBUCZqmAUWFqlkzV6vUtzm3EdULq9ZyfjuFG2iaRnp6uitHhW/Jyspn6NCFriI1ONiPZctuMUSRCpKfwvgkR4XRSY4Ko/NEbkqhWkEaRd2s7Kq+RtWiWarcSAl8e0R17lz4o6jPC3JZsOpRVZWDBw9KN0AfFRhooVGjUADCwwP4/vtbGTAgzstRFZH8FEYnOSqMTnJUGJ10/TUIh8MOmvtGVK1uiKk2efNNeOCBkvv69vVKKELUCWaziQULxhAYaOH++7vTrVtjb4ckhBBCCFEtUqhWgevyNJoZ/Kt+HJtza61uQLXI88/DtGkl9z30ENx7r3fiEaK20jQNRVFct/38zMybN9p7AQkhhBBCuJFMuKwCh1rYTMmvyqW+im+tUdU0ePzx0kXqo4/Cq69Csb+3RRUFBgZ6OwRRQw4dSuWKK+ayb99Zb4dSYZKfwugkR4XRSY4KXyMjqhVUvOuvvXgzpSquUc1EL1YB6lU7Ou86dkwfKT19uvzHnD0La9eW3Pfss3qhKqrPbDbTtm1bb4chasC+fWfp338+x4+n07//fDZvnkTz5lZvh3Vekp/C6CRHhdFJjgqj80TXXylUK6iwmZLJZCo2omqp8nfQ5tyGUK1+TF6XkAD9+0NiYuWeN3u2PuVXuIeqqqSmphIREYFJOlPVWTt2nGLgwAWcOpUFQGioP35+xv95S34Ko5McFUYnOSqMzhPNlCTTK8F1eRq1cES16l1/bc6ttdpRec9ff8GVV1auSFUU+OADKVLdTdM0jh07Jm3r67DffjtB374fu4rUzp0bsnHjRGJjw70c2YVJfgqjkxwVRic5KozOE7kpI6pVYFf1rr/uGFGtretTf/0VBg+G1NSifTEx0LBh+c8JCYF//xtGj/Z4eELUKVu2HGXYsIVkZOQD0KNHLCtXjiMiIsjLkQkhhBBCeIYUqhdQQB455ixUNH478Rvtotvpl6fBOaJaxe9gYX1ndUuUNWvzZhg+HDIyivb16AErV0JEba28hTCoNWsOMmrUp2Rn693Gr7zyIpYtG0tYWICXIxNCCCGE8BwpVMuRmJ7I8v3L+UlZzpnA42hoPLzmYRqGNiQ1/yj5JhUzvjf1d/VqGDUKcnKK9l11FXz3HYSFeS8uAWHyA6hzvvsugRtu+Jy8PAcAgwe35KuvbiI4uPatbJf8FEYnOSqMTnJU+BopVMuwK3kXM7fM5GDqQewU4K/6AwpxEXEkZyWz036C/KACTgRnVnvqr9U9IdeI776D66+H/PyifYMHw1dfQXCw9+ISeqe1li1bejsM4Wa7d592FamjR7fl00+vIyCg9r1tS34Ko5McFUYnOSqMzhNdf6WZ0jkS0xOZuWUmR9OO0j6qPcGEoWACFPzMfjQJb0IEQeSbNb5osYNE/0q2u3WyObe1ZabskiVw7bUli9TRo2HpUilSjUBVVZKSkjzScU14zyOP9ObRR3szduzFfPbZ9bWySAXJT2F8kqPC6CRHhdFJ198asHz/cg6mHqRN/TaYTed8MqAV/SPArpAclMmKwBVVep3atEb1o4/gllvAbi/ad8st8NlnECDL5AxB0zSSkpKkG2Ad9N//Xs0nn1yLn5/7P6msKZKfwugkR4XRSY4Ko/NEbkqhWkx6XjprDq4hIjCidJFajIaGgkJYfiCr/VaTkZdR7mPLY3NurVWKtOa89RbcfjsU/5Dkzjth/nzwq33L5IQwtJdf/pHvv/+7xD5FUTCZFC9FJIQQQgjhHVKoFrPv7D6Ss5KJDok+7+NU5ycG9fNDSFaSSTibUOnXsjm31ko/s+a88ALcf3/JfQ89BO+/Dx6Yhi6Ez9I0jSef3MC//rWaMWOWsGnTEW+HJIQQQgjhVVKoFpNrz8Wu2vEzlTNU6BzU0NCHFy2qBbvJTq49t9KvZXNujbhGVdNgxgx45JGS+x99FF59FRQZ3DEcRVGoX78+ivxwah1N03j44dU89dRGAHJy7PzyS9XWvhuV5KcwOslRYXSSo8LoPJGbtbMzh4cEWgKxmCwUqAX4m/1L3KcAirNSLRxRdShgUSwEWgIr9ToFQKbz39bqhex2mgb/+he88krJ/c8+qxeqwphMJhPNmjXzdhiiklRV4/77V/DOO7+59r366mCmTLnci1G5n+SnMDrJUWF0kqPC6Ewm949/yohqMW0i2xAdEk1yVnKp+zT0talQtFg4LSCHaCWa+Mj4Sr1OmnNrAkKrEa+7qSrcc0/pIvXVV6VINTpVVTl69Kh0A6xF7HaVSZOWuopURYH33x9R54pUkPwUxic5KoxOclQYnXT99bDwgHAGxA0gNTcVh6pfu9DiUInIsROVVQDJp6EgHxUNDY0Mv1wG+g0kLKByF2C2ObdWjPUDmD4d3nuv6Lb+hzNMmeK1kEQFaZpGSkqKdAOsJfLzHdxyy5fMn/8nAGazwoIFY5g8+VIvR+YZkp/C6CRHhdFJjgqj80RuytTfcwxvPZxNRzax7+QO2qT7EX/0KKb8TH3S788/QVAwjey5pIWpNM2KYljQsEq/hs25tbov7Gqz2WD27KLbZjN8/DGMG+etiISom3Jz7Vx//WcsX74fAD8/E0uWXM+YMe28HJkQQgghhHEYaUDPEGLDY5kecwPN9iez+8SfnA3IxxZgwuZvIj8slONKBjlqPp2TNO7beSmxAbGVfg0jXkP1668hP7/o9vvvS5EqhCf8+msi339/AIDAQAvffjtWilQhhBBCiHNIoXquxEQ6vP05z/8VzSStC2bFn6RQlcRwlcMBmYQEhHFloh+PbFHote9PyKh8d06bc2t1Z9zVtGhR0b8jIuDWW70Xi6g8RVGIiYmRboC1QJ8+F/HJJ2MIDw9g5cpxDBnSytsheZzkpzA6yVFhdJKjwuik629NWL4cDh4ktn1HJueaabQ9jR2BRykwwbCLexJvr8emY5+T4+/AP+8s7F4BTK7US9icW6ubQ6+qpCRYt67o9vXXg79/+Y8XxmMymYiJifF2GKKCbrrpYgYObEn9+kHeDqVGSH4Ko5McFUYnOSqMTrr+elp6OqxZow8pms0ABDvMtEz1o+1ZPy7JjyJM89ebKSkKqjkUdq+GjIxKvYzRpv5+/rne8bfQ2LHei0VUjcPh4MCBAzgcDm+HIs6RlJTpappUnK8UqSD5KYxPclQYneSoMDpP5KaMqBa3bx8kJ0OLFq5dij0Ps8OGphTV9K7L1PhZISMZEhKgW7cKv4zNubVWP2K3WLy46N+NGsGVV3ovFlF1GZX8wER43rFjafTvP5/9+1PIzbXzj3/Uza6+FSH5KYxOclQYneSo8DUyolpcbi7Y7eDn59rll5MCgKIVDTmqzvbLiuYHml1/XiXYnFtrdWJ1k0OHYOvWots33+waTBZCVMOBAyn06fMR+/fr7yEzZ24hO7vAy1EJIYQQQtQOUqgWFxgIFgsUnP+PycIRVROA2aI/rxJszm1EpQN0vw8+KHlbpv0KUX27d5+mT5+POHIkDYBWreqzceNEgoP9LvBMIYQQQggBUqiW1KYNREfr03/LoKBfzLawUDXb0yEiGuLjK/UyNufWWuVA3ePVV2HmzKLbLVtWagazMBBFUWjatKl0AzSA7duTuOqqeZw8mQlAhw4N2LRpIs2a1fNyZN4j+SmMTnJUGJ3kqDA6T+SmFKrFhYfDgAGQmgplLAgu/gNQNA2TIwu6DYSwsAq/hIb3C9XMTHjiCZg6teT+f/8b5P2vdjKZTERGRnqk45qouJ9+Ok6/fh9z5kw2AJdc0ogNGybSqFHF3yPqIslPYXSSo8LoJEeF0UnX35owfDjExemNlc4pVlVNQ0VFUTUuStXQ/JtAr2GVOnwOkO/8t9UtAVfM2bMwbx5ccw1ERcHTT5e8/4kn4B//qMGAhFs5HA727t0r3QC9aOPGwwwcuACbTV+z3qtXU9atu42oqGAvR+Z9kp/C6CRHhdFJjgqjk66/NSE2FqZP1+fE7t5Nvew8zoZo2E1Afj4kJxF3ViUxTKF92O34NYqt1OFtzm0A4OmLUxw/Dt98A19/DRs3ljlIDMALL+ijqaJ2y61kUy/hPnl5dm699WsyM/WPoa6+ugVLl95MaKhckLiQ5KcwOslRYXSSo8LXyIhqWTp0gOefh0mTKLCYic3QiLNpKIcOoQYH8+3FFt643A9zQDuoZG8Um3NrdXPIxf3+O/TqBU2bwgMPwLp1ZRepoaF6MyUpUoWonoAAC998cxPh4QEMH96aZcvGSpEqhBBCCFENMqJanthYmDyZhevnkJS3nQA7fPDoC2TFNWbpC2sgy4FZC6j0d9Dm3FrdHG6hI0egXz9ITy/7fqsVRo6EMWNg8GAIllmJQrjFpZc25scfb6d160j8/eUaT0IIIYQQ1SGF6gXk+ZnZU0//o9PUvTuOnBTQQNHApPgZakTV4YAJE0oXqTExMHo0XHst9O1b4jKxoo4wmUzExcVJk4UatGHDYa688iJMpqIOZB06RHsxIuOS/BRGJzkqjE5yVBidNFPyMkVRsKt20DQsqgKKpcojqp64huqrr+prUQtddhn873+QmAjvvAMDB0qRWlcpikJ4eLi0ra8hr732E/36fcz9969A0zRvh2N4kp/C6CRHhdFJjgqjk8vTeJOmd7NyaA7QNMwagLnShWqqc2t1b3T89Rf85z9Ft0NDYfFifa2qfPhW9zkcDnbs2CHdAGvAc89tZsqU7wF4553fWL58v5cjMj7JT2F0kqPC6CRHhdFJ118DsKt2QMOsmqo1omp1Y0y5uTBunN6UuNDs2dCypRtfRBie/PLyLE3TeOyxdTz33BbXvhkzrmT48NZejKr2kPwURic5KoxOclT4GilUK8nuKAANzJpz6q8B1qg+9hjs3Fl0e9QouP12N76AED5O0zT++c/vee21n137nn9+AA8/fIUXoxJCCCGEqLukUK0kh6MAAIuKIdaorl8Pr7xSdDs6Gt5/H2QJgxDu4XCo3H33Mj788A/XvjffHMp993X3YlRCCCGEEHWbFKoVpejdrBx2fX6txaEA5kqPqLpzjerff+tdfov3cpkzRy9WhW8xmUzEx8dLN0A3s9tVJkz4hkWLdgBgMinMmXMNEyd28W5gtYzkpzA6yVFhdJKjwug8kZtSqF5AYH4w7TK7EuAIhN9AC7YD3p36u2MHzJwJS5aAqhbt/8c/YMSIahxY1Gr+/v7eDqHOmT59jatItVhMfPLJGG666WIvR1U7SX4Ko5McFUYnOSp8jRSq5UkElsMtW6eh5vthVi3wL4gJacbo/IkcClsPSuW6/qpA4SVOqzL19+ef4bnn4NtvS9/XqhW8/HIVDirqBFVV2bFjBx07dsRsNns7nDrj//6vF0uXJnDkSBpffHEDI0fGezukWknyUxid5KgwOslRYXRq8dEzN5FCtSy7gJnAQfCzB3Iw7AB2UwGdW1yOchhG7rsVm/9VEFy5qb/p6MUqQHgFn6Np+jrUZ5+FdevKfkyvXjB/vn5JGiGE+8TEhLJ27W3s35/C1Ve38HY4QgghhBA+Qya6nysRvUg9CrSHtODT2M0FoAD+kN8gh4MRe4nOagKnFDhV8UPbnNswLvwJgarqI6c9e0L//mUXqYMGwYYNsGWLXIpGCHdITc0hIyOvxL6mTetJkSqEEEIIUcOkUD3XcuAg0AYoY2aFqjrQTConww5AHrCq4oe2ObfW8zzGbofFi6FLF/0yMz//XPoxY8bAL7/A99/DVVdJh18h3OH06Syuvno+11zzKTk5Bd4ORwghhBDCp0mhWlw6sAZ9AWkZRaqCgqY5J+8qmj7tdzWQUbHD25zbstan5uXBhx9C27Zwyy16w6TizGa49Vb9eqlffQWXXVax1xS+wWQy0bFjR+kGWEUnTmRw1VXz2L49iQ0bDnP33cu9HVKdIvkpjE5yVBid5KgwOk/kpmR7cfuAZOA8l3fRnAuFTZoC/s7HJ1Ts8GVdmiYrC157TZ+6O3kyHDhQ8jn+/nDXXbBvHyxYAB06VOy1hO/Jz8/3dgi10uHDNvr0+Yg9e84AEBsbxqOP9vZyVHWP5KcwOslRYXSSo8LXSKFaXC5gp9wGSRqaa0RV0RR91NXufF4F2JxbK+BwwIsvQvPmMGUKJCaWfGxICPzf/8GhQ/DuuxAXV6kzET5GVVUSEhI80nGtLtu37yxXXvkRBw/qHyO1aGFl8+ZJxMdHeTmyukXyUxid5KgwOslRYXTS9dfTAtG/IwXoo6VlUFUHACYUvcGSxfm8CrA5t2EOuO02WLSo9GOsVnjwQf0rMrISsQshKmXnzmQGDJjPqVNZALRtG8WaNeOJja1oT24hhBBCCOEpUqgW1wZ92m8y0KTsh2iaBujrVbE7H1/BSyvaAE2FT96E388pUhs21EdQ774bwsKqErwQoqK2bTvBoEGfkJKSA0CnTg1ZvXo80dEhXo5MCCGEEEKAFKolhQMDgHlAI8rt+gtgUk36yOtA9OvNVMDpAvj7EKSvLdrn769PAZ48GYKCqhO88HVyAfCK2bHjFFdfPZ/0dP0yNJdd1phVq26lfn35D+hJkp/C6CRHhdFJjgpfI2tUzzUciENvrOQoeZdJMaFpKopqomFmnF6gDqvYYTMy4Mt1kJ6Oaw5wUBAsW6ZP85UiVVSH2WymY8eO8kusAtq0ieTyy/UpE336NGPNmtukSPUwyU9hdJKjwugkR4XReSI3pVA9VywwHWgG7IZ62Q2wOPxAAy1PI+BMCHEpbUkLSoIOzsdfQGoqDBgAyXnOHTZ9eu/338PAgZ46EeFLNE0jPT3dNTVdlC8gwMLXX9/EtGlXsGrVrYSHB3g7pDpP8lMYneSoMDrJUWF0nshNKVTL0gF4HpgEBZZcYjOaE2drB4fA7p/Ht+0X8EPbV6ECjUGTk6FfP/jlF1zXpamnwdq10KeP505B+BZVVTl48KB0AyxHXp69xO3gYD9mzhxAcHA5Lb6FW0l+CqOTHBVGJzkqjM4TuSmFanligcmwsNcsXu35KG90n4H6gsqPd33F0g4fkxVw9oIrfBMT4aqr4M8/0S95EwwWC6xcDJddVgPnIIRg/vw/ufjidzh+PN3boQghhBBCiAqSZkoXkOeXzZ5620EDukHeIf1SFhbNfN7v3uHD0L8/HDzo3GEFPz9o2wYul+VwQtSId975lXvvXQHAgAHz2br1DiIi5D+gEEIIIYTRSaFaSQ6HPoXQfIFCddy4YkUq0KQjWNtCTIB++VUh3C0wsIIX9PURL7/8I//612rX7YED46hXT75H3iL5KYxOclQYneSo8DUy9beiFL2bld1RADgL1XKWt+3cCT/+WHQ7Ph7eXgQBARBRA6EK32M2m2nbtq10A0RfzP/UUxtKFKmPPHIFr78+FJNJPibyBslPYXSSo8LoJEeF0UnXXy9TVRW7qheq55v6u3hxydtffgkBDfV/Wz0XnvBhqqpy9uxZn2+yoGkajzyyhief3Oja98wz/Zg5sz+KIkWqt0h+CqOTHBVGJzkqjE6aKXmTpv8R7HDYQSt/RFXTShaqnTtDhw6uS6dKoSo8QtM0jh075tNt61VV4/77V/Dii0XTGV55ZRCPPXalFKleJvkpjE5yVBid5KgwOk/kpqxRraTCNaoW1VJmofrzz3DoUNHtW27RtzbnbasngxPCR6mqxh13fMu8edsBUBR4990R/OMfl3o3MCGEEEIIUSVSqFZS4RpVi2Yp87t37rTfm2/Wt6nO27JGVQj3UxSIiNCbTJhMCh9/PJpbb+3k5aiEEEIIIURVSaFaUc6Zgw61sOtv6RFVux2WLCm63bs3NGum/9vm3Gf1ZIzCp4WFhXk7BK9RFIWXXx5EQYGDvn2bc9117b0dkjiHL+enqB0kR4XRSY4KXyOFaiWYzeaiy9NQekR1wwY4daro9tixRf+2ObdWD8YnfJfZbKZly5beDsOrFEXhjTeGeTsMUQbJT2F0kqPC6CRHhdFJ118v07v+FjZTKl2oFh9NNZvhhhuKbtucW5n6KzxBVVWSkpJ8phtgenoew4Yt5Kefjns7FFEBvpafovaRHBVGJzkqjE66/nqTs+uv3Tn1t6zL0yQkFP27Vy9o0KDoduEaVatHgxS+StM0kpKSfKIb4Nmz2fTvP5+VK/9m6NCFbN+e5O2QxAX4Un6K2klyVBid5KgwOun6awBFa1T9Sq1RLf7zKb6MQEOm/grhDklJmQwcuICdO5MBMJsVVFV+aQshhBBC1DVSqFaSQ3UA5Xf9LUs2YHf+2+qJoITwAceOpTFgwAL27TsLQExMKGvWjKdDh2gvRyaEEEIIIdxNCtWKUvRmLUVTf0uPqJbH5twGAQGeiE34PEVRqF+/PoqieDsUjzhwIIX+/edz5EgaAM2a1WPt2tto1aq+lyMTFVHX81PUfpKjwugkR4XReSI3pVCtBJPJ5BpRNZexRrU8sj5VeJrJZKJZ4bWQ6pg9e04zYMACTpzIAKBVq/qsWTOeiy6yejcwUWF1OT9F3SA5KoxOclQYncnk/tZH0kypElRV1deoamCm8iOqVg/FJYSqqhw9erTOdQPcvj2Jq66a5ypS27dvwKZNE6VIrWXqan6KukNyVBid5KgwOun6602FXX+1whFVixSqwjA0TSMlJaXOdQPcuTOZ06ezAejaNYYNGybQqJFc8Ly2qav5KeoOyVFhdJKjwuik668BlFijWsHvns25lWuoClE5t97aifT0PD755C9WrBiH1Rro7ZCEEEIIIUQNkBHVSnK4RlQrXqjKGlUhqu7eey9j06ZJUqQKIYQQQvgQKVQrytn116Hp86+rMqJq9URcQqDnZkxMTK3vBrh06V4WLPiz1H6LRd6qarO6kp+i7pIcFUYnOSqMTrr+epnJZNLXqGpVuzyN1UNxCWEymYiJifF2GNWyePEOxo//Gk2DoCA/rr++vbdDEm5SF/JT1G2So8LoJEeF0UnXXy9zOBxFl6dBRlSFcTgcDg4cOIDD4fB2KFUyd+4fjBv3FQ6HhqpqrFy539shCTeq7fkp6j7JUWF0kqPC6DyRm1KoVpSzkVWJNaoVHFGVNaqiJmRkZHg7hCp5442fueOObylsFnfXXZfywQfXeDco4Xa1NT+F75AcFUYnOSp8jRSqlVR4eRpZoypE9c2atYUHH1zluv3Pf17OO+8Mx2SSNThCCCGEEL5MCtVKslNs6m8FRlQdQOHnX1ZPBSVELaNpGo89to7p09e69j3++JW8/PIgaRQhhBBCCCGkmVKFndP1t6JTf9PRZw0rQD1Pxid8mqIoNG3atFYUeZqmMXXq98ye/bNr36xZ/Xnkkd5ejEp4Um3KT+GbJEeF0UmOCqOTrr9epnf9VZ1df/0r9N0rXJ8aBpg9GZzwaSaTicjISG+HUSEHDqTywQe/u26//voQHnighxcjEp5Wm/JT+CbJUWF0kqPC6KTrrzdpzq6/FF5HNaBCharNubV6Ki4h0HNz7969taIbYKtW9Vm27BZCQvyYM+caKVJ9QG3KT+GbJEeF0UmOCqPzRG7KiGoluab+UrERVZtza/VUQEI45ebmejuECuvbtzkHDz5EdHSIt0MRNaQ25afwTZKjwugkR4WvkRHVSiocUa1oMyWbcxvhsYiEMLacnALmzv0DrfD6M05SpAohhBBCiPLIiGolFXb9regaVZtza/VUQEIYWEZGHtdc8ykbNhzmyBEbTz3Vz9shCSGEKMbhcFBQUODtMMQFOBwONE0jNzcXs1m6noia5+fnV+O5J4VqRSmFzZT0UaHKjqhaPRWXEOi5GRcX55GF7FVls+UydOhCfvrpOACvvPITd955CU2bSv9rX2PE/BSiOF/MUU3TSEpKwmazeTsUUUH+/v4cPXrU22EIH2a1WomJiSmzw68n3j+lUK0klaqtUZWpv8KTFEUhPDzc22G4nD6dxaBBn7B9exIAVmsg339/qxSpPspo+SnEuXwxRwuL1OjoaIKDg+WyJ0KIcmmaRnZ2NsnJyQA0atSo1GPk8jTepEG+PR+cI6oWNaBCI6qFl6exeiwwIfQpQbt376Z9+/ZenxJ04kQGAwcuYPfu0wA0aBDM6tXj6dw5xqtxCe8xUn4KURZfy1GHw+EqUuWSJ7WDpmnk5OQQFBQkHyoIrwgKCgIgOTmZ6OjoUu+V0vXXyxyqo6hQla6/wmCM0LL+yBEb/fvP58AB/SOa2Ngw1qy5jbZto7wcmfA2I+SnEOfjSzlauCY1ODjYy5EIIWqTwveMgoKCGvlQTwrVSnBoDnA2LjUr/hXqmWxzbq0eikkIo9i//yz9+8/n2LF0AFq0sLJ27W20aCET34UQwohkZE4IURk1/Z4hhWol2FW7a0TVbAmACvysbM6t/Kku6jJN05gw4RtXkRofH8maNbfRpIlvrfkSQgghhBDu4Tvt7apLcTZSKixUzQEXfEoekOP8t9VjgQmhd1qLj4/3WsdKRVH45JNriY0No1OnhmzcOFGKVOHi7fwU4kIkR0VtEBgY6O0QhCiXJ94/5R25Ehyqvn7FpIHid+HBaJtzawFkFYjwNH9/f6++flxcBOvXT2D9+gk0bBjq1ViE8Xg7P4W4EMlR39C3b1+mTJly3sc0b96c2bNne+T1x48fz3PPPVel58pU7dJ2795NkyZNyMrK8nYowgOkUL2A/MBgspt1JTOuJ78BDr9QLKoClooXqlYqNEtYiCpTVZUdO3agqmqNvea2bSfIy7OX2Ne6dST16wfVWAyidvBGfgpRGZKjtcfEiRNRFKXU199//11jMezatYvrrruO5s2boyhKhYvaP//8kxUrVvDggw+Wum/x4sWYzWbuu+++UvfNmzePiIgIcnJySt2nKArffPNNiX1ffvklffv2pV69eoSGhtKpUyeefvppUlJSKhRnVaSkpDBu3DjCw8OxWq3ccccdZGZmnvc5SUlJjB8/npiYGEJCQrjkkkv48ssvSzxm3759jBo1iqioKMLDw+nduzfr16933d++fXsuv/xyXnnlFY+cl6g4T7x/SqFajkTgfWDd7dNIvO45Tox5mqcDwjg89i1OXzGRxEZFherZs7BlC6SllTyGzbmV9amirlmxYj+9e3/EzTd/SUGB73TKFEII4X1Dhgzh5MmTJb5atGhRY6+fnZ1NXFwcs2bNIiam4pdee+ONN7jhhhsIDS0962jOnDk8/PDDLF68mNzc3CrH9p///IebbrqJyy67jJUrV7Jz505efvll/vzzTxYsWFDl417IuHHj2LVrF6tXr2bZsmVs2rSJf/zjH+d9zm233UZCQgLffvstO3bs4Nprr+XGG2/kjz/+cD1mxIgR2O121q1bx7Zt2+jcuTMjRowgKSnJ9ZhJkybxzjvvYLfby3oZUYtJoVqGXcAjwDygICAQ/zOHCTixhyYFeah+wST3upVH/hHMLuDXX6FpU+jTB3bsKHkcuYaqqIu+/HI3o0d/Sm6unW++2ctbb/3q7ZCEEEJUl6ZBTo53vpz9PyoqICCAmJiYEl+Fl8rYuHEj3bt3JyAggEaNGjFt2rTzFjDJycmMHDmSoKAgWrRowcKFCy/4+pdddhkvvvgiN998MwEBF+5ZAvrlj7744gtGjhxZ6r5Dhw7x448/Mm3aNNq0acNXX31VoWOe65dffuG5557j5Zdf5sUXX6RXr140b96cgQMH8uWXXzJhwoQqHfdC9uzZw6pVq/jwww/p0aMHvXv35o033uDTTz/lxIkT5T7vxx9/5IEHHqB79+7ExcXx2GOPYbVa2bZtGwBnzpxh//79TJs2jU6dOtG6dWtmzZpFdnY2O3fudB1n4MCBpKSksHHjRo+cn/Ae6fp7jkRgJnAUaA+kpZ4my6Jfb8yiOvBPO4Gf/RRHoy9jJhCyUn+PPVdgoFyaRtQ9Cxb8ycSJS1FV/Y+Km27qwH33XeblqIQQQlRbbq7+qbs3bN4MQdVfNpKYmMiwYcOYOHEi8+fPZ+/evUyePJnAwECefPLJMp8zceJETpw4wfr16/Hz8+PBBx8kOTm52rGc66+//iItLY1u3bqVuu+jjz5i+PDh1KtXj1tvvZU5c+Zwyy23VPo1Fi5cSGhoKPfee2+Z91ut1nKf26FDB44cOVLu/X369GHlypVl3rd161asVmuJcxswYAAmk4mff/6ZMWPGlPm8Xr16sWTJEoYPH47VauWzzz4jNzeXvn37AhAZGUl8fDzz58/nkksuISAggPfee4/o6GguvfRS13H8/f3p0qULmzdvpn///uWeg6h9pFA9x3LgIHqRWuIytgpomj732qxqtDkJezqAf8vSxzCZ4Lbb4KTzttWTAQuB3mmtY8eOHu1Y+e67v3HPPctdtydO7MKHH47EbJaJGeL8aiI/hagOydHaZdmyZSWmzw4dOpTPP/+ct99+m6ZNm/Lmm2+iKApt27blxIkTPPLII8yYMaPUz3ffvn2sXLmSX375hcsu0z90nTNnDu3atXN7zEeOHMFsNhMdHV1iv6qqzJs3jzfeeAOAm2++mf/7v//j0KFDpaYzB12gmN+/fz9xcXH4+flVOr4VK1ZQUFBQ7v3ne+2kpKRS52WxWKhfv36JKbrn+uyzz7jpppuIjIzEYrEQHBzM119/TatWrQB9/e2aNWsYPXo0YWFhmEwmoqOjWbVqFRERJRfWNW7c+LyFtvA8T7x/SqFaTDqwBn1NqbmM+zXnImFFA7PJhBVIaAeEApkQGQnffAMtW0KjRjDL+TxZoypqQn5+vsda17/yylb+7/9+cN2+777LeP31oZhM0iZMVIwn81MId/D5HA0M1Ec2vfXaldCvXz/eeecd1+2QkBBAn4Las2fPEt1xr7jiCjIzMzl+/DjNmjUrcZw9e/ZgsVhKjM61bdv2vCOPVZWTk0NAQECpzr2rV68mKyuLYcOGARAVFcXAgQOZO3cuzzzzTInHapp23s6/WiWnUBd30UUXVfm5VfX4449js9lYs2YNUVFRfPPNN9x4441s3ryZjh07omka9913H9HR0WzevJmgoCA+/PBDRo4cya+//kqjRo1cxwoKCiI7O7vGz0F4lhSqxewDkoEyl+NroDovT6MAmBSige1hQDywDQICoHfvoqfIGlVRU1RVJSEhgY4dO7rW6biDpmk888wmnnhig2vfww/3YtasAdImX1SYp/JTCHeRHAUUxS3Tb2tCSEiIa9SttoiKiiI7O5v8/PwSl0KaM2cOKSkpJUYsVVXlr7/+4qmnnsJkMhEeHk5WVhbZ2dmuohzAZrMBUK9ePQDatGnDli1bKCgoqPSoanWm/sbExJSaLm2320lJSSm32dSBAwd488032blzJx06dACgc+fObN68mbfeeot3332XdevWsWzZMlJTUwkP16/N/vbbb7N69Wo+/vhjpk2b5jpeSkoKLVuWMc1R1Bjp+uthuYAdKO+/tuq6jqoCJv1xqgko54NAm3NrdWOMQtSkDz/8vUSR+vTTfaVIFUIIYUjt2rVj69atJUYW//e//xEWFkaTJk1KPb5t27bY7XZX8x6AhIQEVwHoTl26dAH0634WOnv2LEuXLuXTTz9l+/btrq8//viD1NRUfvhBn8kUHx+P3W7nzz//LHHM33//HdALVIBbbrmFzMxM3n777TJjON95rVixokQM5359+OGH5T63Z8+e2Gy2Et/HdevWoaoqPXr0KPM5haOf504XNZvNroKnvMeYTKZSRdHOnTvp2rVruTGK2klGVIsJRP+GFABlXfa7cOqvSVNA0R9nUtEr3DLYnFure8MUosbcfPPFzJnzBz//nMjLLw9i6tSe3g5JCCGEKNO9997L7NmzeeCBB7j//vtJSEjgiSeeYOrUqWWun4uPj2fIkCHcddddvPPOO1gsFqZMmXLBtaD5+fmugjM/P5/ExES2b99OaGhouSO9DRo04JJLLmHLli2uonXBggVERkZy4403lvoAeNiwYcyZM4chQ4bQoUMHBg0axD333MMrr7xCy5YtSUhIYMqUKdx0003ExsYC0KNHDx5++GH+7//+j8TERMaMGUPjxo35+++/effdd+nduzcPPfRQmfFVZ+pvu3btGDJkCJMnT+bdd9+loKCA+++/n5tvvpnGjRsDeqOr/v37M3/+fLp3707btm1p1aoVd911Fy+99BKRkZF88803rsvbgF4AR0REMGHCBGbMmEFQUBAffPABhw4dYvjw4a7XP3z4MImJiQwYMKDK5yCMSUZUi2kDRKNP/y1LYTMlBX1ENRkIygASyn68TP0VNckT09XCwgJYuXIcn356nRSpolp8djqlqDUkR2u/2NhYVqxYwS+//ELnzp25++67ueOOO3jsscfKfc5HH31E48aNueqqq7j22mv5xz/+Uaox0LlOnDhB165d6dq1KydPnuSll16ia9eu3Hnnned93p133lni8jdz585lzJgxZc5Suu666/j22285c+YMAJ9++im9e/fm7rvvpkOHDjz44IOMGjWq1Ejn888/z6JFi/j5558ZPHgwHTp0YOrUqXTq1Mljl6cBveNw27Zt6d+/P8OGDaN37968//77rvsLCgpISEhwjZL6+fmxYsUKGjRowMiRI+nUqRPz58/n448/LrFed9WqVWRmZnL11VfTrVs3tmzZwtKlS+ncubPr2IsXL2bQoEFeWWcrPEvRqrPyug5IT0+nXr16pKWlER4ezvvo108t7Pq7Zf03nLKcBaB3m7787+8NWHP8uCr0NvZcDv4LYcOt+rEaN4bERP3fGtADUIEV6AWwEEZXUOAgLS2PqKhgb4cihBDCQ3Jzc11dZX26gVQNy8nJIT4+niVLltCzp3z46w75+fm0bt2aRYsWccUVV3g7nDrvfO8d59ZU7iAjqucYDsShN1ZynHOfqqp6BYqZfdF606WLdlOmTPQiFWREVXiepmmkp6dXq+Nfbq6d6677jH79PubsWemcJ9zHHfkphCdJjoqaEBQUxPz5812jpJWhaRoOh0Ny9BxHjx7l0UcflSLVADyRm1KoniMWmA40A3YDmREN0Mx+aBrkaSr59RqT3qQNzdL1x4WmlX0cm3MbTNnrXYVwJ1VVOXjwYJU7rmVl5XPNNYv57rt97NyZzJgxS+SXoXCb6uanEJ4mOSpqSt++fRk5cmSVnpuXl+fmaGq/wnWuwvuk628N6QA8D0wC/PJyyY9qTl7jdpwMDMVUkE38+s95fq3+uPLI+lRRW6Sn5zFkyEJWrz4IQEiIH08+2Vc6+wohhBBCCK+Rrr/liAUmA7/OncWm5jmolkBu7zWZj79+kIsPhhB76Qvnfb7NubV6NkwhqiUlJYfBgz/ht99OABAerjdP6tWrqZcjE0IIIYQQvkwK1Qvwz80m+Oh20KBF26GY8zKxaOEX/M7ZnFurZ8MTwqWyDTFOncpk4MAF7Nih97mOjAzihx/Gc8kljTwRnvBx0rBFGJ3kqDA6mekkfI0UqhWlAJreTMmsmcDv/A+3ObcRHg5LCNAvq9C2bdsKP/748XQGDJhPQoLe0TomJpTVq8dz8cXSn1q4X2XzU4iaJjkqjE5RlAte31UIb/LEJb5kjWolFBToi9jNmllGVIWhqKrK2bNnK7SQ/dSpTK688iNXkdq0aTibNk2UIlV4TGXyUwhvkBwVRqdpGna7XRodCsOSZkpekK/YybY4yLQ4SMg8gkPRsEihKgxG0zSOHTtWoV9gDRqE0KePflHsli0j2Lx5Eq1bR3o6ROHDKpOfQniD5KioDfLz870dghDl8sT7p0z9LUdieiLL9y9nXYMDnPIrQAM+SfqepNB8/qqfSqIpkVhiKX4pLFOxst/m3FprLmQhKsRkUpgz5xoaNgxhypTLadw4zNshCSGEEEIIUYKMqJZhV/IuHlnzCPO2z6NAceDvUAiwK0RZwlEVjR1RNh7JeITfju5i+fKi511ySdG/bc6trFEVRlBQ4Chx22Ix8cILA6VIFUII4VP69u3LlClTzvuY5s2bM3v2bI+8/pVXXsmiRYs8cmxf9O6771b5urTC+KRQPUdieiIzt8zkaNpR2ke1J9QRgIKCoiiYUPBXTTTIDuKoepR/fjmTTCXR9dyxY4uOI9dRFTUtLKzsonPTpiPEx7/Jrl3JNRyREEXKy08hjEJytHaYOHEiiqKU+vr7779rLIYPPviAPn36EBERQUREBAMGDOCXX3654PO+/fZbTp06xc0331zqvpkzZ2I2m3nxxRdL3ffkk0/StWtXTKaSf7YfPnwYRVHYvn27a5+mabz//vv06NGD0NBQrFYr3bp1Y/bs2WRnZ1f+ZCvo6NGjDB8+nODgYKKjo/n3v/+N3W4/73P27dvHqFGjiIqKIjw8nN69e7N+/XrX/fPmzSvzZ60oCsnJ+t80t99+O7///jubN2/22LkJ75FC9RzL9y/nYOpB2tRvg9l0bvcqfe61BRNt/Nuw68QhaL0CgOBgKP6Bjs25tXo6YCHQO621bNmyVMe1H344wJAhn3DokI0BAxZw6FBqOUcQwnPKy08hjEJytHYZMmQIJ0+eLPHVokWLGnv9DRs2MHbsWNavX8/WrVtp2rQpgwYNIjEx8bzPe/3115k0aVKpghNg7ty5PPzww8ydO7fc5wcGBl7wEjXjx49nypQpjBo1ivXr17N9+3Yef/xxli5dyg8//FCxE6wkh8PB8OHDyc/P58cff+Tjjz9m3rx5zJgx47zPGzFiBHa7nXXr1rFt2zY6d+7MiBEjSEpKAuCmm24q9XMePHgwV111FdHRegNIf39/brnlFl5//XWPnJuoOOn662HpeemsObiGiMCIMopUUFV9+qSCCVUzY0uyQtxq8M9g1CgICdEfZwcynM+x1kTgwuepqkpSUlKJjmtLl+5l5MjF5OTon2h26RJDw4ah3gpR+LCy8lMII5Ec1UficgpyvPJV2SYsAQEBxMTElPgq/CN548aNdO/enYCAABo1asS0adPOO7KXnJzMyJEjCQoKokWLFixcuPCCr79w4ULuvfdeunTpQtu2bfnwww9RVZW1a9eW+5zTp0+zbt26Mqepbty4kZycHJ5++mnS09P58ccfyzxGQUHBeb9Xn332GQsXLmTx4sU8+uijXHbZZTRv3pxRo0axbt06+vXrd8Fzq4offviB3bt388knn9ClSxeGDh3KM888w1tvvVVuA6gzZ86wf/9+pk2bRqdOnWjdujWzZs0iOzubnTt3AhAUFFTqZ7xu3TruuOOOEscaOXIk3377LTk5OR45P1Exnnj/lGZKxew7u4/krGRaWMv4VE4r6malaArJp0FLj4aIQxCVwNix3VwPTXduTUC458MWAk3TSEpKokGDBgB8+ulObr31KxwOPWfHjGnL4sXXERAg/+VFzTs3P4UwGslRyLXn0uejPl557c2TNhPkV/1rhCYmJjJs2DAmTpzI/Pnz2bt3L5MnTyYwMJAnn3yyzOdMnDiREydOsH79evz8/HjwwQdd00orKjs7m4KCAurXr1/uY7Zs2UJwcDDt2rUrdd+cOXMYO3Ysfn5+jB07ljlz5tCrV69SjysoKMBiKf/3+MKFC4mPj2fUqFGl7lMUhXr16pX73NDQ83+Qfeutt/Luu++Wed/WrVvp2LEjDRs2dO0bPHgw99xzD7t27aJr166lnhMZGUl8fDzz58/nkksuISAggPfee4/o6GguvfTSMl9n/vz5BAcHc/3115fY361bN+x2Oz///DN9+/Y973kIz5Guvx6Wa8/FrtrxM/mVeb+q6Z8UmFBIPAmofmCyExaRy+DBRY8rnFwZjgxZi5o3d+4f3HnntxS+X4wb15F580ZjsUg2CiGEqP2WLVtWorAaOnQon3/+OW+//TZNmzblzTffRFEU2rZty4kTJ3jkkUeYMWNGqSm3+/btY+XKlfzyyy9cdtllgF40llVMns8jjzxC48aNGTBgQLmPOXLkCA0bNiwVQ3p6Ol988QVbt24F9IKwT58+vPbaaxcsHs+1f/9+4uPjK/WcQsXXuZYlPLz8oZekpKQSRSrgul04jfdciqKwZs0aRo8eTVhYGCaTiejoaFatWkVERNmtSOfMmcMtt9xCUFDJDzWCg4OpV68eR44cOe85iNrHkIXqW2+9xYsvvkhSUhKdO3fmjTfeoHv37mU+9oMPPmD+/PmuaQKXXnopzz33XLmPP59ASyAWk4UCtQB/s3+p+zVnoYpm4kwKYCoA1UL/qwLxL/Zwm3NrrXQEQlTPW2/9ykMPfe+6PXnyJbzzznDMZilShRBClC/QEsjmSd5pSBNoCazU4/v168c777zjuh3iXHu1Z88eevbsWWId5xVXXEFmZibHjx+nWbNmJY6zZ88eLBZLiRG8tm3bYrVaKxzLrFmz+PTTT9mwYQOBgeWfR05OTpn3L168mJYtW9K5c2cAunTpwkUXXcSSJUtKTXG9kOqMaLVq1arKz60KTdO47777iI6OZvPmzQQFBfHhhx8ycuRIfv31Vxo1alTi8Vu3bmXPnj0sWLCgzOMFBQV5tFmU8A7DFapLlixh6tSpvPvuu/To0YPZs2czePBgEhISXAuniytc0N6rVy8CAwN5/vnnGTRoELt27SI2NrZSr90msg3RIdEkZyXTJLxJyTsVUDVN76ekKqgaEJoMWdHcOa7kp1c259ZaqVcXouoURWHJkuPMmrXNtW/KlB688srgCzZeEMLTFEWhfv36kovCsCRH9e+BO6bf1oSQkJAaL6zK8tJLLzFr1izWrFlDp06dzvvYqKgoUlNLNzScM2cOu3btKjGlV1VV5s6d6ypUw8PDSUtLK9WsxmazAbim9LZp04a9e/dW6VyqM/U3JiamVNfjU6dOue4ry7p161i2bBmpqamu0dq3336b1atX8/HHHzNt2rQSj//www/p0qVLudOCU1JSfHrqvhF44v3TcMMsr7zyCpMnT2bSpEm0b9+ed999l+Dg4HK7oFVlQXt5wgPCGRA3gNTcVByqo9T9GvqIqqKZcCgOCLLBwYF071KypX3h25BcQ1XUFJPJRIMGka7bjz3WR4pUYRgmk4lmzZqV2elSCCOQHK0b2rVrx9atW0uMLP7vf/8jLCyMJk2alHp827ZtsdvtbNtW9CFvQkKCqwA8nxdeeIFnnnmGVatW0a1btws+vmvXriQlJZUoVnfs2MFvv/3Ghg0b2L59u+trw4YNbN261VV0xsfHc/z4cWw2W4nf67///juBgYGukeJbbrmFffv2sXTp0lKvr2kaaWlp5cZX/PXL+nr66afLfW7Pnj3ZsWNHibW9q1evJjw8nPbt25f5nMLRz3P/z5lMplJNeTIzM/nss8/KHWE+cOAAubm5Za6FFTXHE++fhhpRzc/PZ9u2bUyfPt21z2QyMWDAANfc/Qu50IL2vLw88vLyXLfT0/XWRw6HA4fDwZC4IWw8vJF9KftoXb91iecW/sfRNMiO3AepLWD/MOd+Ew6HXtymKAooCvUAFMW1v/g5FT/ehfabzWY0TStzv6qqpaZ6lLVfURTXf/6y9p8bY3n7TSYTipyT4c6poKCAa69tRHr6lfj7m5k+vU+tP6e6+HPy1XNSVZUTJ06U+YdibT2n88Uu51T7zklVVRITE4mNjcXPz69OnNO5MRY/J4fD4YqrrOmiiqJ4ZX9lnXuMe+65h9mzZ3P//fdz//33k5CQwBNPPME///lPTCZTiXPWNI02bdowZMgQ7rrrLt5++20sFgv//Oc/XWsgy4t91qxZPPHEEyxcuJCLLrqIkydPoigKISEh5Y5MdunShaioKLZs2cKIESMAfZSwe/fu9OnTp9T35bLLLuPDDz/kxRdfZPDgwcTHx3PTTTfx3//+l0aNGvH777/z2GOP8eCDD7rO7YYbbuDrr79m7Nix/Oc//2HQoEE0aNCAHTt2MHv2bB544IFyGy21bNmyzP3Fvwfl/cwGDhxI+/btGT9+PM8//zxJSUk89thj3HvvvQQEBKBpGr/88gsTJkxgzZo1xMbG0rNnTyIiIpgwYQKPP/44QUFBfPDBBxw6dIhhw4aVeK1PP/0Uu93OuHHjSsWgKAqbNm0iLi6OuLi4osanHsw9b/3/MMI5Ff7fAUq9v13ourlVYahC9cyZMzgcjjIXZFd0KsOFFrTPnDmTp556qtT+Xbt2ud5cJrWaxLwD89ieuJ1MU57rh5BvzyffpHIqNAO/o81gy3TIiMVmS6Fhw/rs37+f3Nxc9jZoQHZEBEGKAkFB7N69u8Qvmfj4ePz9/dmxY0eJGDp27Eh+fj4JCQmufWazmY4dO5KRkcHBgwdd+wMDA2nbti2pqakcO3bMtT8sLIyWLVuSnJxcYgF7/fr1adasGcePHyclJcW1v7Dl9+HDh8nIyHDtb9q0KZGRka5zKhQXF0d4eLickwHP6eTJk4wapU9dy8jIqBPnVBd/Tr54Tpqm4XA4aNSoEbt3764T5wR17+fky+ekaRopKSmkpaXRuXPnOnFO5/s5aZrmmkbqcDhKXELEZDIRGBiI3W6noKCgxHECAgLIz88vEYufnx9+fn7k5eWVKJD9/f2xWCzk5uaW+GM2ICAAs9lc6lIihdcIPXd/UFAQmqa5vi92u931+qqqlhh8iIyMZMWKFfzrX/+iS5cuREREcNttt/Hvf//b9VxVVbHb7eTk5GA2m/noo4+4/fbb6du3L9HR0cyYMcP1My7vnN555x3y8/O54YYbSsT66KOP8p///Kfcc7r11luZP38+I0aMIC8vj4ULF/LPf/7TdX9wcLDrnEaOHMnrr7/OjBkzCA8PZ/ny5Tz66KPccsstnDlzhubNm/PQQw/xwAMPlPieffTRR3z88cfMmTOH5557DovFQsuWLRk/fjyDBw/22M/pu+++45577qFXr16EhIRwyy23uAaeVFUlNTWVhIQEMjIyyM3NJSoqimXLlvHYY4/Rv39/CgoKaNeuHUuXLqVDhw4ljj9nzhyuvfZagoODS+wvzL1FixYxYcIE132eyr1CxX9OhRRFISgoqNb9f6rsOeXl5bkK0nPf987XkbqqFM0TvYSr6MSJE8TGxvLjjz/Ss2dP1/6HH36YjRs38vPPP5/3+bNmzeKFF15gw4YN5a4VKGtEtWnTpqSkpLjmyCuKwsnMkyzft5wXljzKKb9UNCAyMJz0nAxG7r+EbT98ze4MfQ1sUpJKw4ZFn4Q+rij8oChMAW6VT6zlnDxwTna7yj33LGfUqLaMGtWW/Px8du3aRYcOHTCbzbXynC60X86p9p6Tw+Fg165ddOzYsdR09Np6TueLXc6p9p1TYY526NABf3//OnFO58ZY/Jxyc3M5cuQIcXFxBAQEcK66NALk7f3FJSUlcfHFF7Nt2zYuuuiiSh1bVVVyc3NdBYhRzulCPB3L7t27ufrqq0lISChx+Z3afE5G/jnl5uZy6NAh4uLiXO+VhWw2G1FRUaSlpZ23S3RlGGpENSoqCrPZ7FqAXejUqVPlLsYuVNEF7QEBAWW+KZvN5hKL1GPDY/lHt3/w25tz2RS2HRXoFdyKP9N3cfXx9mzLKGrUVPiLofD5hSsA6hc7dlkqs19RlDL3lzcfvLL73RFjZffLOVXtnPLzHYwb9zVffrmHRYt2smzZLfTrd5HrtYu/fm05p5reL+dU8+ekKEq5MZZ3HKOfU1X2yzkZ95yKn0ddOafiip+T2WwuUeyUxVv7K8NosV/onBo1asScOXM4duwYzZs3r9KxC99L3R1jbf05nTx5kvnz55fZqbm2npM791dGRY5dPP/OfX8r7/2uOgxVqPr7+3PppZeydu1aRo8eDeifCq5du5b777+/3Oe98MILPPvss3z//fcVWtBeqZg0M8F2/Y29gRKCWVUwaRbONwvb5txa3RqJEJCTU8D113/OihX7AX29dGZmPoqiEBMT45Y3KiHcTfJTGJ3kqKgphX/fVoWfn5/7AqkjznftWlGzPPH+aahCFWDq1KlMmDCBbt260b17d2bPnk1WVhaTJk0C4LbbbiM2NpaZM2cC8PzzzzNjxgwWLVpE8+bNXXOlQ0NDK32h5AtRNX3qjVmzUHCex9mcW6tbX134uszMfK65ZjHr1x8GIDDQwjff3MTgwXqL/gvNOhDCW0wmk+SnMDTJUWF0iqJIoSoMzRMjqobrw37TTTfx0ksvMWPGDLp06cL27dtZtWqVq8HS0aNHOXnypOvxhQvar7/+eho1auT6eumll9weW4FDH0fNz/IrMaJ67gcINufW6vYIhK+y2XIZNGiBq0gNDfVn1apxriLV4XBw4MCBUuuYhDACyU9hdJKjwugKG+AYqLWMECV44v3TcCOqgKuteFk2bNhQ4vbhw4c9HxCABjl5DlQVtIKiqb+tWkFk0eUryQEKWzVZayYyUcedOZPNoEEL+OMPfbaA1RrIqlXj6NGj5KU+ineQFMJoJD+F0UmOCqM7t0mWEHWdIQtVo9q7zwGRYFL1EdXGjeG770qOqNqcW38gqOZDFHXMyZMZDBiwgN27TwPQoEEwq1ePp3NnmaImhBBCCCHqLsNN/TWy3PyiNaqNmsLmzdC2bcnH2JxbKyAtGUR17dlzhv37zwLQuHEYGzdOlCJVCCGEEELUeVKoVoJi0gtVk+rP869AXFzpx9icW2tNBSXqtKuvbsFnn91Aq1b12bx5Eu3aNSjzcYqi0LRpU+lYKQxJ8lMYneSoqA38/f29HYIQ5fKJrr+G5ipULfiVM6831bm11khAwheMHt2WYcNa4+9f9vXyQO+0Fll8sbQQBiL5KYxOclQYnaIoWCzyZ7swLp/o+mtoir6I3aT5EVa/7IfYnFtrTcQj6pzffz/Ja6/9VGr/+YpU0Dut7d27VzpWCkOS/BRGJznqO/r27cuUKVPO+5jmzZsze/Zsj7z+lVdeyaJFiyr9PE3TyMnJka6/51i1ahVdunSRRlMG4In3TylUK0FzjqhaVH+6XFL2Y2zOrbUmAhJ1ytatx7j66o+ZMuV7Xn/950o/Pzc31wNRCeEekp/C6CRHa4eJEyeiKEqpr7///rvGYvjqq6/o1q0bVquVkJAQunTpwoIFCy74vG+//ZZTp05x8803l7pv5syZmM1mXnzxxVL3Pfnkk3Tt2rVUkXr48GEURWH79u2ufZqm8f7779OjRw9CQ0OxWq1069aN2bNnk52dXfmTraCjR48yfPhwgoODiY6O5t///jd2u/28z9m3bx+jRo0iKiqK8PBwevfuzfr160s8Zu3atfTq1YuwsDBiYmJ45JFHShx3yJAh+Pn5sXDhQo+cl/AuKVQrw1moBvr74x9Q9kNszm1EjQQk6or16w8xcOAC0tL0ixt98cVu7Hb5dFAIIYQ415AhQzh58mSJrxYtWtTY69evX5///Oc/bN26lb/++otJkyYxadIkvv/++/M+7/XXX2fSpEllTpGcO3cuDz/8MHPnzq1WbOPHj2fKlCmMGjWK9evXs337dh5//HGWLl3KDz/8UK1jl8fhcDB8+HDy8/P58ccf+fjjj5k3bx4zZsw47/NGjBiB3W5n3bp1bNu2jc6dOzNixAiSkvTL8f35558MGzaMIUOG8Mcff7BkyRK+/fZbpk2bVuI4EydO5PXXX/fIuQnvkkK1Igo/wHJO/Q0O9iv3oTbn1urJeESdsnLlfoYNW0RWVgEAAwbEsXLlOCwW+e8phBCiZmiaRkFOgVe+KjudNSAggJiYmBJfZrO+RGbjxo10796dgIAAGjVqxLRp0847specnMzIkSMJCgqiRYsWFRqZ69u3L2PGjKFdu3a0bNmShx56iE6dOrFly5Zyn3P69GnWrVvHyJEjS923ceNGcnJyePrpp0lPT+fHH3+swHehtM8++4yFCxeyePFiHn30US677DKaN2/OqFGjWLduHf369avScS/khx9+YPfu3XzyySd06dKFoUOH8swzz/DWW2+Rn59f5nPOnDnD/v37mTZtGp06daJ169bMmjWL7Oxsdu7cCcCSJUvo1KkTM2bMoFWrVlx11VW88MILvPXWWyWuezxy5Eh+++03Dhw44JHzE94jq7IrQXWOqIaGSKEq3OOrr/Zw881fUFCgfwgycmQbPvvsBgIDK/df02QyERcX55GF7EJUl+SnMDrJUbDn2vmoz0deee1JmyfhF1T+31YVlZiYyLBhw5g4cSLz589n7969TJ48mcDAQJ588skynzNx4kROnDjB+vXr8fPz48EHHyQ5ObnCr6lpGuvWrSMhIYHnn3++3Mdt2bKF4OBg2rVrV+q+OXPmMHbsWPz8/Bg7dixz5syhV69epR4XEFDOdD6nhQsXEh8fz6hRo0rdpygK9erVK/e5oaGh5z32rbfeyrvvvlvmfVu3bqVjx440bNjQtW/w4MHcc8897Nq1i65du5Z6TmRkJPHx8cyfP59LLrmEgIAA3nvvPaKjo7n00ksByMvLIzAwsMTzgoKCyM3NZdu2bfTt2xeAZs2a0bBhQzZv3kzLli3Pex7Cczzx/imFamWY9GIiNKj89uA259bq8WBEbffJJ38xceI3OBz6J8k33tiBTz4Zg5/f+RsnlUVRFMLDw90dohBuIfkpjE5ytHZZtmxZicJq6NChfP7557z99ts0bdqUN998E0VRaNu2LSdOnOCRRx5hxowZpf6Q3rdvHytXruSXX37hsssuA/Sisaxi8lxpaWnExsaSl5eH2Wzm7bffZuDAgeU+/siRIzRs2LBUDOnp6XzxxRds3boV0AvCPn368Nprr5UqHgtHjcuzf/9+4uPjLxh7WYqvcy3L+f5/JCUllShSAdftwmm851IUhTVr1jB69GjCwsIwmUxER0ezatUqIiL0BXSDBw9m9uzZLF68mBtvvJGkpCSefvppAE6ePFnieI0bN+bIkSPnPQfhWXJ5Gi8oPhlFNamYAIu5/E/9Ci9PI2tUxfm8//427r57GYWznSZO7MKHH47EbK7ap1EOh4Pdu3fTvn37C/4iE6KmSX4Ko5McBUughUmbJ3nttSujX79+vPPOO67bISEhAOzZs4eePXuW+IP5iiuuIDMzk+PHj9OsWbMSx9mzZw8Wi8U1ggfQtm1brFbrBWMICwtj+/btZGZmsnbtWqZOnUpcXJxrlO9cOTk5pUYHARYvXkzLli3p3LkzAF26dOGiiy5iyZIl3HHHHSUem52dTVBQULkFQXU6Ardq1arKz60KTdO47777iI6OZvPmzQQFBfHhhx8ycuRIfv31Vxo1asSgQYN48cUXufvuuxk/fjwBAQE8/vjjbN68uVTBHxQU5NFmUeLCPNH1VwrVC1CLfc81kwMUMJvLHlFVgTTnv62eDkzUWmlpuTzxxAZXkXrvvd14441hmEzV+yRKLqsgjEzyUxidr+eooihumX5bE0JCQmq8sDqXyWRyxdClSxf27NnDzJkzyy1Uo6KiSE1NLbV/zpw57Nq1q8Q1UlVVZe7cua5CNTw8nLS0tFLPtdlsAK4pvW3atGHv3r1VOp/qTP2NiYnhl19+KbHv1KlTrvvKsm7dOpYtW0ZqaqprtPbtt99m9erVfPzxx66GSVOnTuWf//wnJ0+eJCIigsOHDzN9+nTi4uJKHC8lJYUGDRpc+ERFrSKF6gUU/72lKSoK5Y+oZqIXqwDlrwIQvq5evUB++OFWrrpqHnfe+f/s3XlczPkfB/DXzFRT6dJdKpV0IAmLXJWNHOtallDkWnaxjtU6d1k2sdbNClvKse7zF3IWEUKychQpYeXq1j3z+f2RZo2Zjkk1Q+/n7zGPdj7fz/f7fX+nz++r93yOb2ssW+ZRK8MlCCGEkPrEwcEBBw4cAGNM9O/qpUuXoKmpCTMzM4n69vb2KCkpwY0bN0RDfxMSEkQJoCyEQiEKCwvL3e7s7Iy0tDRkZGSIhrbevn0b169fR2RkJHR1dUV109PT4ebmhvv378Pe3h52dnZ4+vQpXrx4AUtLS1G92NhYqKqqinqKhw8fDi8vLxw5ckRinipjDNnZ2eXOU/2Yob8uLi7w9/fHy5cvYWhoCAA4ffo0tLS00KxZM6n7lPV+ftgzyuVyJZ6JyuFwYGpqCqC0B9rc3BytW//3nMiCggIkJSVJnQtLPm2UqFZCbKE4HgM4gJKS9Mnsme9+NgDwaXwnSeTF0dEIt29/B1NTTUpSCSGEkBrw/fffY/Xq1ZgyZQomT56MhIQELFiwADNmzJC60IudnR169uyJCRMmYOPGjVBSUsK0adOgpqZW4XkCAgLQtm1bNGnSBIWFhTh+/Di2b98uNhz5Q87OztDX18elS5fw1VdfASjtTW3Xrh26du0qUf+LL75AUFAQli9fDk9PT9jZ2cHX1xdLliyBiYkJYmNjMX/+fEydOlU0XH3IkCE4dOgQhg0bhvnz56NHjx4wMDDA7du3sWrVKkyZMgUDBgyQGt/H9FD36NEDzZo1g4+PD37//XekpaVh/vz5mDRpkmgBqJiYGIwcORJnz55Fo0aN4OLigoYNG2LUqFH45ZdfoKamhi1btiA5ORl9+vQRHXv58uXo2bMnuFwuDh48iKVLl2Lv3r1iQ/SvXLkCPp8PFxeXal8DUUz1d3m7KmBMvEeVq1z6DQ9PSfrQX5qfSqQRChm2bbsFgUD8G8JGjbRqLEnlcrmws7Or1ytWEsVF7ZMoOmqjn4dGjRrh+PHjiImJgZOTEyZOnIixY8di/vz55e6zdetWmJqawtXVFV9//TW+/fZbUa9ged6+fYvvv/8ezZs3R6dOnXDgwAHs2LED48aNK3cfHo+H0aNHix5/U1RUhB07dmDQoEFS6w8aNAjbtm1DcXExlJSUcPLkSVhaWmL48OFo0aIFFixYgKlTp2Lx4sWifTgcDv7++2+sXLkShw8fhqurK1q2bImFCxeif//+8PT0rPC6qovH4yEsLAw8Hg8uLi7w9vbGyJEjRQsfAaU9qAkJCSguLn0Un76+PsLDw5Gbm4tu3bqhbdu2uHjxIo4cOSKarwsAJ06cQJcuXdC2bVscO3YMR44ckUi2d+3ahREjRkBdXb1Wro9UTW3cPznsY2ZefwbKhkFkZWVJDGsoLgbGDu2EeMM4AIBQSQlKghKcfH0OevvaSxzrPIAfAbQAEFLbgZNPgkAgxLff/g/BwXEYM6YVtmzp99FzUaVhjEEoFILL5VIPLVE41D6JoqtvbbSgoADJycmwsrKSusAPqR1paWlo3rw5YmNj0bhxY5n2ff/P9frQRqvq9evXsLOzw/Xr12FlZSXvcD57Fd07srKyoKOjIzWnqi766lAG7N0awOX1qGa++6lTJ9EQRVdcLIC39yEEB8cBAEJCbuHatWe1ci6hUIjbt29LzOsgRBFQ+ySKjtooqQvGxsYICgpCampqtfbPz8+v4Yg+fSkpKfjzzz8pSVUAtXH/pDmqMuC8+zaLp0yJKqlYYWEJhg7djyNHEgAASkpc7No1CO3bSy7mQAghhJD6obw5oqR62rZti7Zt28o7DFJLKFGthvISVZqjSgAgL68YAwfuwalTSQAAPp+HAweGoE8fWzlHRgghhBBCyKeBElWZlPaoVrbqr06dxEIUUXZ2Ib766m9ERZUO61FXV8bRo1748kvrSvYkhBBCCCGElKFEVQZlQ3+VlClRJZLS0/PRq9dOxMSUzkPV0uLj+PHh6NTJotbPzeVy4ejoSCtWEoVE7ZMoOmqj5FNQ2WNzCJGn2rh/0h25Gjgq0p+Smvnup05dBUIUyrRp4aIkVVdXDefOjayTJLVMUVFRnZ2LEFlR+ySKjtooUXT1/EEdpB6iRFVGSkIOOHzpHdE0R7V+W7nSE82aGcDIqAHOn/dFmzamdXZuoVCIhIQEWrGSKCRqn0TRURsln4KCggJ5h0BIuWjVXwXAEwJQlv6xZb77qVNHsRDFoq+vjjNnfJCbW4SmTfXkHQ4hhBBCCCGfLEpUZcRjHEBKj2oxgLfv/lunLgMicvPgwRsYGjaAtvZ/Dzw2MdGUY0SEEEIIIYR8Hmjor4yUhBxAhSdRnvXuJxeARp1GROThn39eoHPnrejd+2/k5irGvCYeT7JdEqIoqH0SRUdttH5wc3PDtGnTKqxjaWmJ1atX18r5u3btir///rtWjl0fhYeHo1WrVjRs/zNFiaqMlIQAVCQ/trL5qTqgD/Vzd+3aM7i5heDly7eIjn6C2bPPyDsk8Hg8ODo60h9aRCFR+ySKjtrop8PX1xccDkfi9fDhQ7nEs3v3bnA4HAwYMKDSukePHsWLFy/g5eUlsS0gIAA8Hg/Lly+X2LZw4UI4OztDXV0dHA5HVJ6SkgIOh4O4uDhRGWMMmzdvRvv27aGhoQEdHR20bdsWq1evRl5eXrWusSpSU1PRp08fqKurw9DQEH5+figpKalwn8TERPTv3x/6+vrQ0tJC586dERERIVbn7Nmz6NixIzQ1NWFsbIxZs2aJHbdnz55QVlbGzp07a+W6SNXVxv2TcioZcBjAY1xAmSOxLfPdT526DIjUuYsXU/Hll9uQkVG6oEH79o2weLG7nKMq/YcpOzubVgQkConaJ1F01EY/LT179sTz58/FXlZWVnUeR0pKCmbOnIkuXbpUqf7atWsxevRoqY/xCA4Oxk8//YTg4OBy9xcIBJW2UR8fH0ybNg39+/dHREQE4uLi8PPPP+PIkSM4depUleKUlUAgQJ8+fVBUVITo6GiEhoYiJCQEv/zyS4X7ffXVVygpKcG5c+dw48YNODk54auvvkJaWhoA4NatW+jduzd69uyJmzdvYs+ePTh69Chmz54tdhxfX1+sXbu2Vq6NVF1t3D8pUZURj3GlzuzNfPdTpw5jIXXr9Okk9OixHTk5pUN9XV0b4/RpHzRsKP/nmgmFQjx69IiGvhCFRO2TKDpqowAYA0ry5fOS8Q9cPp8PY2NjsVdZb8758+fRrl078Pl8mJiYYPbs2RX27L18+RJ9+/aFmpoarKysqtwzJxAIMGLECPz666+wtrautP6rV69w7tw59O3bV2Lb+fPnkZ+fj0WLFiE7OxvR0dFSj1FYWFjhOfbu3YudO3di165dmDt3Lr744gtYWlqif//+OHfuHNzda+eL9VOnTuHu3bvYsWMHWrVqhV69emHx4sXYsGFDuY99ev36NR48eIDZs2ejZcuWaNq0KZYuXYq8vDzEx8cDAPbs2YOWLVvil19+gY2NDVxdXfH7779jw4YNyMnJER2rb9++uH79OpKSkmrl+kjV0Kq/CkBJSIlqffS//yVg8OB9KCoSAAA8PZvg4MGhUFeX/kxdQggh5JMiKADOVK1nsMZ5RAFKH/+l77Nnz9C7d2/4+vpi27ZtuH//PsaPHw9VVVUsXLhQ6j6+vr74999/ERERAWVlZfzwww94+fJlpedatGgRDA0NMXbsWERFRVVa/+LFi1BXV4eDg4PEtqCgIAwbNgzKysoYNmwYgoKC0LFjx0qP+aGdO3fCzs4O/fv3l9jG4XCgra1d7r4aGhWvsOLt7Y3AwECp2y5fvgxHR0cYGRmJyjw9PfHdd9/hzp07cHZ2lthHT08PdnZ22LZtG1q3bg0+n49NmzbB0NAQbdq0AVCamKuqqortp6amhoKCAty4cQNubm4AAAsLCxgZGSEqKgpNmjSp8DrIp4USVRmVDv2VLH9/jir5vOzZEw9v70MoKSn9pmjAAHvs3j0I/HKep0sIIYSQ2hMWFiaWWPXq1Qv79u3Dn3/+CXNzc6xfvx4cDgf29vb4999/MWvWLPzyyy8SQ24TExNx4sQJxMTE4IsvvgBQmjRKSybfd/HiRQQFBYnNDa3M48ePYWRkJBFDdnY29u/fj8uXLwMoTQi7dOmCNWvWVJo8fujBgwews7OTaZ8ylV2LlpZWudvS0tLEklQAovdlw3g/xOFwcObMGQwYMACamprgcrkwNDREeHg4GjZsCKA02V29ejV27dqFIUOGIC0tDYsWLQIAPH/+XOx4pqamePz4cYXXQD499Je2jGjob/1y7lwyhg8/CKGwdFjS8OGOCAnpD2VlxVtw48NvHQlRJNQ+iaKr922Up1rasymvc8vA3d0dGzduFL1v0KABAODevXtwcXERW3CoU6dOyM3NxdOnT2FhYSF2nHv37kFJSUnUgwcA9vb20NHRKffcOTk58PHxwZYtW6Cvr1/lmPPz86W2sV27dqFJkyZwcnICALRq1QqNGzfGnj17MHbsWLG671+XNB8zR9DGxqba+1YHYwyTJk2CoaEhoqKioKamhr/++gt9+/bFtWvXYGJigh49emD58uWYOHEifHx8wOfz8fPPPyMqKkoi4VdTU6vVxaKIfFCiKiOlcnpUM9/91KnDWEjt69zZAr17N0VYWCLGjXNGYOBX4PEUb2o3j8eDvb29vMMgRCpqn0TRURsFwOHUyPDbutCgQYM6T6zKJCUlISUlRWyuadncPCUlJSQkJEgdfqqvr4+MjAyJ8qCgINy5cwdKSv/9SS4UChEcHCxKVLW0tJCVlQU1NfHfT2ZmJgCIhvTa2tri/v371bqujxn6a2xsjJiYGLGyFy9eiLZJc+7cOYSFhSEjI0PUW/vnn3/i9OnTCA0NFS2YNGPGDEyfPh3Pnz9Hw4YNkZKSgjlz5kjMC05PT4eBgUHlF0pqTW2s+kuJqoyUhBUnqg3rMhhS61RUeNi37xts3XoTEye2rfTbTHkRCoXIyMhAw4YNpa4mSIg8Ufskio7a6OfBwcEBBw4cAGNM9O/1pUuXoKmpCTMzM4n69vb2KCkpwY0bN0RDfxMSEkQJoDT29va4ffu2WNn8+fORk5ODNWvWwNzcXOp+zs7OSEtLE7UzALh9+zauX7+OyMhI6Orqiuqmp6fDzc0N9+/fh729Pezs7PD06VM8e/YMpqamomuLjY2FqqqqqKd4+PDh8PLywpEjRyTmqZatbF3ePNWPGfrr4uICf39/vHz5EoaGhgCA06dPQ0tLC82aNZO6T1nv54f/f+NyuRKL8nA4HJiamgIo7YE2NzdH69atRdsLCgqQlJQkdS4sqTu1sZgS3Y1lxGM8Gvr7GWOM4fVr8aEjqqpK+O67LxQ2SQVK437y5Ak9WoEoJGqfRNFRG/08fP/993jy5AmmTJmC+/fv48iRI1iwYAFmzJgh9QsIOzs79OzZExMmTMDVq1dx48YNjBs3TqLn8n2qqqpo0aKF2EtHRweamppo0aIFVFRUpO7n7OwMfX19XLp0SVQWFBSEdu3aoWvXrmLH69q1K7744gsEBQUBKJ2raWdnh+HDhyM6OhqPHj3C/v37MX/+fEydOlXUkzVkyBAMHToUw4YNw5IlS3D9+nU8fvwYYWFh8PDwkHhG6ftsbGwqfJUloNL06NEDzZo1g4+PD27duoWTJ09i/vz5mDRpEvh8PgAgJiYG9vb2ePbsGYDS5LZhw4YYNWoUbt26hcTERPj5+SE5ORl9+vQRHXv58uW4ffs27ty5g8WLF2Pp0qVYu3atWO/dlStXwOfz4eLiUm6MpPbR42kUQHmLKWW++6lTh7GQmsUYg5/fabRuvQmPH2fKOxxCCCGEyKBRo0Y4fvw4YmJi4OTkhIkTJ2Ls2LGYP39+ufts3boVpqamcHV1xddff41vv/22wqSsung8HkaPHi16/E1RURF27NiBQYMGSa0/aNAgbNu2DcXFxVBSUsLJkydhbm6O4cOHo0WLFliwYAGmTp2KxYsXi/bhcDj4+++/sXLlShw+fBiurq5o2bIlFi5ciP79+8PT07PGr6vs2sLCwsDj8eDi4gJvb2+MHDlStPARUNqDmpCQgOLiYgClQ6HDw8ORm5uLbt26oW3btrh48SKOHDkimq8LACdOnECXLl3Qtm1bHDt2DEeOHMGAAQPEzr9r1y6MGDEC6urqtXJ9RH44rJ5/fVg2DCIrK0tiWENxMTB2aCfEG8aVFnCAdq9MEPj9Q6Dbf/UYgE4AigD8D4BJ3YROapBQyDBp0jEEBt4AANjY6OKffyZCTe3TePyMQCDA7du34ejoWCtzBAj5GNQ+iaKrb220oKAAycnJsLKyokWk6lBaWhqaN2+O2NhYNG7cWKZ9GWPIz8+HmpqaQo/wqmuvX7+GnZ0drl+/DisrK3mH89mr6N6RkZEBXV1dqTlVdVGPqoykrfqbj9IkFaA5qp+ikhIhRo8+IkpSORxg1qxOn0ySWkZTU1PeIRBSLmqfRNFRGyW1zdjYGEFBQUhNTa3W/jR/WlJKSgr+/PNPSlI/U7SYkiwYwBNKJqqZ737yAdD3kp+WoiIBvL0PYt++uwAAHo+D0NABGDGipZwjkw2Px6OHXBOFRe2TKDpqo6SufDhstao4HA71fkvRtm1btG3bVt5hENTOqr/01YyMlJiSxBzVzHc/deo4FvJxCgpK8PXXe0RJqrIyF/v2ffPJJalA6UpraWlptbLiGiEfi9onUXTURomiY4yhuLiYFvwiCotW/ZUzDgAlKav+Zr77qVO34ZCPkJtbhD59/saxYw8AlK7se/ToMAwc6CDnyKqHMYa0tDT6B4woJGqfRNFRGyWfgrKFiAhRRLVx/6ShvzLiMZ5Ej2rZ45tpfuqnobCwBJ6eOxAd/QQAoKGhgrCwYXB1tZRvYIQQQgghhBAA1KMqM2mJaua7nzp1HAupHj5fCa6upavt6eio4vRpH0pSCSGEEEIIUSDUoyojGvr7efD37wYej4NBg5qhVStjeYfz0TgcDnR1dWnJeqKQqH0SRUdtlHwK6sOjk8inqzbun5Soyoh6VD9NAoEQPN5/Awg4HA4WL+5WwR6fFi6XCwsLC3mHQYhU1D6JoqM2ShQdh8MBn8+XdxiElKs2Hp9EQ39lxGNKEuk9zVFVbA8fpsPRcSOioh7LO5RaIxQKkZqaSitWEoVE7ZMoOmqj9VtkZCQ4HA4yMzOrvM/ChQvRqlWrWovpQ25ubpgyZcpHL1hTVFQEGxsbREdH11BkZPbs2ZgyZYq8w5A7WvVXAdDQ30/L3buv0LXrVty79xp9+vyNGzf+lXdItYIxhvT0dFqxkigkap9E0VEb/TQEBgZCU1MTJSUlorLc3FwoKyvDzc1NrG5Z8pmUlFTpcTt27Ijnz59DW1u7RuN1c3PDtGnTaux47ycCBw8eRI8ePaCnpwcOh4O4uLgqHSMwMBBWVlbo2LGjxLYJEyaAx+Nh3759Ett8fX2lPgNWWpJfVFSE33//HU5OTlBXV4e+vj46deqErVu31urKxf/88w+6dOkCVVVVmJub4/fff6/yvm/evIGZmZnULyx27twpuhYTExOMGTMGb968EW2fOXMmQkND8ejRo5q6lE9Sbdw/KVGVkZJQskc1891PnTqOhVQsLi4Nrq4heP48FwDQuLEOGjXSknNUhBBCCKkOd3d35Obm4vr166KyqKgoGBsb4+rVqygoKBCVR0REwMLCAk2aNKn0uCoqKjA2Nv6k5ii/ffsWnTt3xrJly6q8D2MM69evx9ixYyW25eXlYffu3fjpp58QHBxc7biKiorg6emJpUuX4ttvv0V0dDRiYmIwadIkrFu3Dnfu3Kn2sSuSnZ2NHj16oHHjxrhx4waWL1+OhQsXYvPmzVXaf+zYsWjZsqVE+aVLlzBy5EiMHTsWd+7cwb59+xATE4Px48eL6ujr68PT0xMbN26sseshpShRlVFFc1Rp6K/iuHLlKdzdQ/H6dR4AoE0bE0RGjoKxsYacIyOEEEJIddjZ2cHExASRkZGissjISPTv3x9WVla4cuWKWLm7uzuA0p7IgIAAWFlZQU1NDU5OTti/f79Y3Q970rZs2QJzc3Ooq6tj4MCBWLlyJXR0dCRi2r59OywtLaGtrQ0vLy/k5OQAKO2BPH/+PNasWQMOhwMOh4OUlBQAQHx8PHr16gUNDQ0YGRnBx8cHr1+/Fh3z7du3GDlyJDQ0NGBiYoIVK1ZInNfHxwe//PILPDw8qvz53bhxA0lJSejTp4/Etn379qFZs2aYPXs2Lly4gCdPnlT5uO9bvXo1Lly4gLNnz2LSpElo1aoVrK2tMXz4cFy9ehVNmzat1nErs3PnThQVFSE4OBjNmzeHl5cXfvjhB6xcubLSfTdu3IjMzEzMnDlTYtvly5dhaWmJH374AVZWVujcuTMmTJiAmJgYsXp9+/bF7t27a+x6SClKVGXEg3iPqhBA1rv/1pFDPERSZGQKunffjszM0m9WO3Y0x9mzI6Gnpy7nyGoPh8P55L4NJvUHtU+i6KiNAgxAvpxesgwYdHd3R0REhOh9REQE3Nzc4OrqKirPz8/H1atXRYlqQEAAtm3bhsDAQNy5cwfTp0+Ht7c3zp8/L/Ucly5dwsSJEzF16lTExcWhe/fu8Pf3l6iXlJSEw4cPIywsDGFhYTh//jyWLl0KAFizZg1cXFwwfvx4PH/+HM+fP4e5uTkyMzPRrVs3ODs74/r16wgPD8eLFy8wZMgQ0XH9/Pxw/vx5HDlyBKdOnUJkZCRiY2M/etXfqKgo2NraQlNTU2JbUFAQvL29oa2tjV69eiEkJKRa59i5cyc8PDzg7OwssU1ZWRkNGjSQul9qaio0NDQqfC1ZsqTc816+fBldu3aFioqKqMzT0xMJCQnIyMgod7+7d+9i0aJF2LZtm9TFgFxcXPDkyRMcP34cjDG8ePEC+/fvR+/evcXqtWvXDk+fPhV9GVEf0aq/CkCJKYv1qGbjvxssDSqVv/Dwhxg4cA8KCkrnr3z5pRWOHPFCgwYqlez5aeNyuTA2/vQfs0M+T9Q+iaKjNgoUAOgip3NHAVCrYl13d3dMmzYNJSUlyM/Px82bN+Hq6ori4mIEBgYCKE1aCgsL4e7ujsLCQixZsgRnzpyBi4sLAMDa2hoXL17Epk2b4OrqKnGOdevWoVevXqIeNltbW0RHRyMsLEysnlAoREhIiCjx8/HxwdmzZ+Hv7w9tbW2oqKhAXV1drG2tX78ezs7OYklXcHAwzM3NkZiYCFNTUwQFBWHHjh348ssvAQChoaEwMzMDl8v9qGTg8ePHMDU1lSh/8OABrly5goMHDwIAvL29MWPGDMyfP1/m8z148EBivnBVmJqaVjrPVldXt9xtaWlpsLKyEiszMjISbWvYUHLcY2FhIYYNG4bly5fDwsJC6hzTTp06YefOnRg6dCgKCgpQUlKCvn37YsOGDRLxA6WfsaWlZYXX8bmiVX8VAI/xgPe+0Mp891MTlPXL26FD99Cv3y5RktqnT1OEhQ3/7JNUABAIBEhKSoJAIJB3KIRIoPZJFB210U+Hm5sb3r59i2vXrol6CA0MDODq6iqapxoZGQlra2tYWFjg4cOHyMvLQ/fu3cV657Zt21buQksJCQlo166dWNmH7wHA0tJSrHfSxMQEL1++rDD+W7duISIiQiwWe3t7AKU9tElJSSgqKkL79u1F++jq6sLOzg4lJSUftWBNfn4+VFVVJcqDg4Ph6ekJfX19AEDv3r2RlZWFc+fOyXyO6sanpKQEGxubCl8VJarVMWfOHDg4OMDb27vcOnfv3sXUqVPxyy+/4MaNGwgPD0dKSgomTpwoVk9NrfSrlry8vBqN8VNSG/dPyq1kxOMoAe99uUSPplEchYUClJSUroj3zTfNsGPH11BRqT8Pxy6bF0OIIqL2SRRdfW+jqijt2ZTXuavKxsYGZmZmiIiIQEZGhqhH1NTUFObm5oiOjkZERAS6dSt9VnpubumCiseOHUOjRo3EjvWxzyVVVhZftITD4VT6iI7c3Fz07dtX6iJIJiYmePjwYbn7fuyqqvr6+rh9+7ZYmUAgQGhoKNLS0qCkpCRWHhwcLOrV1dLSwuPHko/5y8zMBI/HEw3ptbW1xf3792WOLTU1Fc2aNauwzty5czF37lyp24yNjfHixQuxsrL35Y2WOHfuHG7fvi2ar1z2+err62PevHn49ddfERAQgE6dOsHPzw8A0LJlSzRo0ABdunTBb7/9BhMTEwBAeno6AMDAwKAql0uqiBJVGSl98JFlvvupU9eBEAleXi2Ql1eMqKhUbNnSF0pKNGCAEEIIqQoOqj78Vt7c3d0RGRmJjIwMUQIBAF27dsWJEycQExOD7777DgDQrFkz8Pl8pKamSh3mK42dnR2uXbsmVvbh+6pQUVGR6GVq3bo1Dhw4AEtLS7HEsEyTJk2grKyMq1evwsLCAgCQkZGBxMREqY+UkYWzszM2btwIxphoSO/x48eRk5ODmzdvis2BjY+Px+jRo5GZmQkdHR3Y2dlh9+7dKCwsFEvwY2NjYWVlJUrahw8fjrlz5+LmzZsS81SLi4tRVFQkdZ7qxw79dXFxwbx581BcXCyK5fTp07Czs5M67BcADhw4gPz8fNH7a9euYcyYMYiKihKtFp2Xlyfxeyr7nN7/4iA+Ph7Kyspo3rx5hddAZEN/yctIiSP+7Vnmu586dR0IkWrMGGcEB/ejJJUQQgj5TLm7u+PixYuIi4sTSz5dXV2xadMmFBUViRZS0tTUxMyZMzF9+nSEhoYiKSkJsbGxWLduHUJDQ6Uef8qUKTh+/DhWrlyJBw8eYNOmTThx4oTM8zUtLS1x9epVpKSk4PXr1xAKhZg0aRLS09MxbNgwXLt2DUlJSTh58iRGjx4NgUAADQ0NjB07Fn5+fjh37hzi4+Ph6+srMf8vPT0dcXFxuHv3LoDS4cpxcXFIS0ur8HPLzc0Ve0RMUFAQ+vTpAycnJ7Ro0UL0GjJkCHR0dLBz504AwIgRI8DhcDBy5EjcuHEDDx8+RHBwMFavXo0ff/xRdLxp06ahU6dO+PLLL7FhwwbcunULjx49wt69e9GhQwc8ePBAamwfO/R3+PDhUFFRET1GZs+ePVizZg1mzJghqnPo0CHRMGug9EuB96+5bI6rg4MDDA0NAZSu5nvw4EFs3LgRjx49wqVLl/DDDz+gXbt2YvN9o6Ki0KVLF9EQYFIz6K95GfE41KOqKJYsicKWLTckyuvjqo0cDgfm5ub18tqJ4qP2SRQdtdFPi7u7O/Lz82FjYyNaMAcoTVRzcnJEj7Eps3jxYvz8888ICAiAg4MDevbsiWPHjkksvlOmU6dOCAwMxMqVK+Hk5ITw8HBMnz5d6vzOisycORM8Hg/NmjWDgYEBUlNTYWpqikuXLkEgEKBHjx5wdHTEtGnToKOjI0pGly9fji5duqBv377w8PBA586d0aZNG7Eez6NHj8LZ2Vn0qBkvLy84OzuLFpSSRk9PDwMHDhQlny9evMCxY8cwaNAgibpcLhcDBw5EUFAQAEBHRwdRUVEoLi5Gv3790KpVK6xduxYrV67EhAkTRPvx+XycPn0aP/30EzZt2oQOHTrgiy++wNq1a/HDDz+gRYsWMn2GVaWtrY1Tp04hOTkZbdq0wY8//ohffvkF3377rahOVlYWEhISZDqur68vVq5cifXr16NFixb45ptvYGdnJ1p4qszu3bvFnq1aH9XG/ZPDPnbA+ycuOzsb2trayMrKgpaW+Lq9xcXA2KGdEG8YB6B0WMzcFF8MCv9vpa+VAP4GMBLAD3UVdD3HGMO8eecQEHARHA6wfftAjBgh+ZBmQgghhEgqKChAcnIyrKysZE6+6qvx48fj/v37iIqS10zemvHPP/+ge/fuSEpKgoYGPVu+Jpw4cQI//vgj/vnnH6nDuT8nFd07Ksqpqot6VGXE41KPqjwxxjBtWjgCAi6+ew88f54r56jkTyAQ4P79+7RiJVFI1D6JoqM2Sj70xx9/4NatW3j48KFomPCoUaPkFg9jDPn5+R+9oFLLli2xbNkyJCcn11Bk5O3bt9i6detnn6RWhlb9VQA8mqMqNwKBEBMnhuGvv26Kytav74VJkySXjK+PCgoK5B0CIeWi9kkUHbVR8r6YmBj8/vvvyMnJgbW1NdauXYtx48bJNaaaGgTp6+tbI8chpQYPHizvED5blKjKiMejRFUeiosF8PU9gr//Ll1WncvlICioH3x9W8k3MEIIIYR8dvbu3SvvEAip9yhRlZESV3qiSs9RrT2FhSXw8jqAw4dLn8ulpMTFjh0DMXRo7UzIJ4QQQgghhMgXJaoyKi9R1anrQOqJvLxifP31Hpw8mQQAUFHhYf/+b9C3r52cI1MsXC4X1tbWEsvXE6IIqH0SRUdtlHwK3n9+KSGKpjbun5SoVkK1WB0Or5zBL1FFkVIBVAT/PaS4CEDeu//WkUdw9cCjRxm4fPkpAEBdXRlHjnjBw8NazlEpHg6HU2MrrBFS06h9EkVHbZQoOg6HI/Z4GkIUTW08noYS1fI8AzhHgbGxs8FjyuAJlSDglsCSZwRsBtAHyGxUWpUHgBb4rh0tWhji+PHh+Oabfdi79xt07mwh75AUkkAgwN27d9GsWTP6h4woHGqfRNFRGyWKrmzVXzU1NXreL1FItOpvXbkDIADgJgEqAlWkaiehhFsMJaEymuSYAaEALgB5cwA0L+1NpVtG7enUyQJJST9ATU258sr1GD1WgSgyap9E0VEbJYQQxUKTMT70DEAAgFSAOQAZaq9QwisGOEAJrxjFGvmAQ+l2jQDA4BkN+61J//6bgyVLoiSWYKcklRBCCCGEkPqDEtUPHQPwCIAtSsf0foDD4ZaW2wK8ZKDjcUpUa0pKSia6dNmKefPOYdasMzX2vDBCCCGEkPJERkaCw+EgMzOzyvssXLgQrVq1qrWYPuTu7g4/P7+PPs6bN29gaGiIlJSUjw+KAAA6dOiAAwcOyDuMzxIlqu/LBnAGpc+aKWeKCpfzbgMPyNcBOpwGDHPqJrzPWWLiG3TtuhWPHmUAAPbvv4vMTHr4elVxuVzY2dnRipVEIVH7JIqO2uinITAwEJqamigpKRGV5ebmQllZGW5ubmJ1y5LPpKSkSo/bsWNHPH/+HNra2jUar5ubG6ZNm1Zjx1NSKp2xV1xcjFmzZsHR0RENGjSAqakpRo4ciX///bfSY/j7+6N///6wtLSU2Obp6Qkej4dr165JbCvvWkJCQqCjoyNWlp2djXnz5sHe3h6qqqowNjaGh4cHDh48WKudEJGRkWjdujX4fD5sbGwQEhJS5X0fPnwITU1NiWsJCQkBh8MRe6mqqorVmT9/PmbPng2hUFgDV/Hpqo37J92R35cI4CUAw/KrvP9LyDYEdF8CTRJqPbLPWnz8S3TtuhVPnmQDAOzt9REVNRoNG6rJObJPi4qKirxDIKRc1D6JoqM2qvjc3d2Rm5uL69evi8qioqJgbGyMq1evoqDgvy+4IyIiYGFhgSZNmlR6XBUVFRgbG38yixTl5eUhNjYWP//8M2JjY3Hw4EEkJCSgX79+le4XFBSEsWPHSmxLTU1FdHQ0Jk+ejODg4GrHlpmZiY4dO2Lbtm2YM2cOYmNjceHCBQwdOhQ//fQTsrKyqn3siiQnJ6NPnz5wd3dHXFwcpk2bhnHjxuHkyZOV7ltcXIxhw4ahS5cuUrdraWnh+fPnotfjx4/Ftvfq1Qs5OTk4ceJEjVwL+Q8lqu8rAFACoILpkBzOf12tBcoAtwTQoY6/artx41+4uobgxYu3AICWLY1w/rwvGjWixwTIQigU4vbt2/X+2zyimKh9EkVHbfTTYGdnBxMTE0RGRorKIiMj0b9/f1hZWeHKlSti5e7u7gBKf78BAQGwsrKCmpoanJycsH//frG6Hw793bJlC8zNzaGuro6BAwdi5cqVEr1tALB9+3ZYWlpCW1sbXl5eyMkpHWbn6+uL8+fPY82aNaKeuLLhtvHx8ejVqxc0NDRgZGQEHx8fvH79WnTMt2/fYuTIkdDQ0ICJiQlWrFgBAKKeZG1tbZw+fRpDhgyBnZ0dOnTogPXr1+PGjRtITU0t9/M7fvw4+Hw+OnToILFt69at+Oqrr/Ddd99h165dyM/PL/c4FZk7dy5SUlJw9epVjBo1Cs2aNYOtrS3Gjx+PuLg4aGjUznMyAgMDYWVlhRUrVsDBwQGTJ0/G4MGDsWrVqkr3nT9/Puzt7TFkyBCp2zkcDoyNjUUvIyMjse08Hg+9e/fG7t27a+RaPlW1cf+kRPV9qihdB7m4/Cqc93pUi4sBoRKgplp+fVK+S5dS0a3bNqSnl94M27VrhIiIUTA0bFDJnoQQQgipUQxAvpxeMowGdXd3R0REhOh9REQE3Nzc4OrqKirPz8/H1atXRYlqQEAAtm3bhsDAQNy5cwfTp0+Ht7c3zp8/L/Ucly5dwsSJEzF16lTExcWhe/fu8Pf3l6iXlJSEw4cPIywsDGFhYTh//jyWLl0KAFizZg1cXFwwfvx4UU+cubk5MjMz0a1bNzg7O+P69esIDw/HixcvxJIkPz8/nD9/HkeOHMGpU6cQGRmJ2NjYCj+XrKwscDgcqcl0maioKLRp00ainDGGrVu3wtvbG/b29rCxsRFL5KtKKBRi9+7dGDFiBExNTSW2a2hoiIYvS4tNQ0OjwtfOnTvLPffly5fh4eEhVubp6YnLly9XGPO5c+ewb98+bNiwodw6ubm5aNy4MczNzdG/f3/cuXNHok67du0QFRVV4bmI7OjxNO+zRemw35cAzKRXeX/oL/8l8MIQ4NnVRXCfl7NnH6Ffv93Iyyv9VqBr18b43/+GQUuLL+fICCGEkHqoAID0kY+1LwpAFWf7uLu7Y9q0aSgpKUF+fj5u3rwJV1dXFBcXIzAwEEBp0lJYWAh3d3cUFhZiyZIlOHPmDFxcXAAA1tbWuHjxIjZt2gRXV1eJc6xbtw69evXCzJkzAQC2traIjo5GWFiYWD2hUIiQkBBoamoCAHx8fHD27Fn4+/tDW1sbKioqUFdXh7GxsWif9evXw9nZGUuWLBGVBQcHw9zcHImJiTA1NUVQUBB27NiBL7/8EgAQGhoKM7Ny/jAFUFBQgFmzZmHYsGHQ0ip/RNrjx4+lJpBnzpxBXl4ePD09AQDe3t4ICgqCj49PuceS5vXr18jIyIC9vb1M+wFA27ZtERcXV2GdD3sy35eWliax3cjICNnZ2aLnz37ozZs38PX1xY4dO8r93Ozs7BAcHIyWLVsiKysLf/zxBzp27Ig7d+6I/U5MTU3x5MkTCIVCmutegyhRfZ8WAA8AIQBMIPXhqKIeVQHAzwSuDAB6aNZRfJ8JgUCI6dNPipLUHj2a4NChoVBXp0fQEEIIIaR8bm5uePv2La5du4aMjAzY2trCwMAArq6uGD16NAoKChAZGQlra2tYWFjgzp07yMvLQ/fu3cWOU1RUBGdnZ6nnSEhIwMCBA8XK2rVrJ5GoWlpaipJUADAxMcHLly8rjP/WrVuIiIiQOgQ2KSkJ+fn5KCoqQvv27UXlurq6sLOT3itSXFyMIUOGgDGGjRs3Vnju/Px8iYWAgNJEeejQoaLezmHDhsHPzw9JSUlVmuNb5mMWSlJTU4ONjU2196+O8ePHY/jw4ejatWu5dVxcXERfcAClC285ODhg06ZNWLx4sahcTU0NQqEQhYWFUpNiUj2UqH6oD4ALKF1YScr/XzhcHiAo3f7UCojuDUgf0U7Kw+NxERY2HF26bIWzszH27BkMPp+a4sfgcrlwdHSkb/GIQqL2SRQdtVGUTn+S18hFGaZQ2djYwMzMDBEREcjIyBD1iJqamsLc3BzR0dGIiIhAt27dAJQO2wSAY8eOoVGjRmLH4vM/bhSXsrL4F+wcDqfSeXq5ubno27cvli1bJrHNxMQEDx8+LHffD4fNliWpjx8/xrlz5yrsTQUAfX19ZGRkiJWlp6fj0KFDKC4uFkt0BQIBgoODRUOetbS0pC6ElJmZKVot2cDAADo6Orh//36FcUgTFRWFXr16VVhn06ZNGDFihNRtxsbGePHihVjZixcvoKWlVW7ieO7cORw9ehR//PEHgNJEWygUQklJCZs3b8aYMWMk9lFWVoazs7PE7yk9PR0NGjSo10lqbdw/KTv4UCMAcwAEAJx7QMN8A+SoZKOEWwwloTKUcvnAPYBZAX/NAV41oueoVoeFhTYuXRoDI6MGUFYu51lARCZFRUVSvyklRBFQ+ySKrt63UQ6qPPxW3tzd3REZGYmMjAyxZ4t27doVJ06cQExMDL777jsAQLNmzcDn85Gamip1mK80dnZ2Eo9okfbIlsqoqKhAIBCIlbVu3RoHDhyApaWl1PmaTZo0gbKyMq5evQoLCwsAQEZGBhITE8V6/sqS1AcPHiAiIgJ6enqVxuPs7IwdO3aIle3cuRNmZmY4fPiwWPmpU6ewYsUKLFq0CDweD3Z2djh16pTEMWNjY2FrawugNFHx8vLC9u3bsWDBAolhxrm5uVBVVZV63R879NfFxQXHjx8XKzt9+rRYb+iHLl++LPb7OXLkCJYtW4bo6GiJLzXKCAQC3L59G7179xYrj4+PL7eHnnwEVs9lZWUxACwrK0t8w1PGijcydqXRGXbN5DyLNb7ErpmcZwUtMxjbzFjuU8basNJXgRzi/tQcOnSP5eUVyTuMz1ZJSQm7efMmKykpkXcohEig9kkUXX1ro/n5+ezu3bssPz9f3qFUS3BwMFNTU2NKSkosLS1NVB4aGso0NTUZAPbvv/+KyufNm8f09PRYSEgIe/jwIbtx4wZbu3YtCwkJYYwxFhERwQCwjIwMxhhjFy9eZFwul61YsYIlJiaywMBApqenx3R0dETHXLBgAXNychKLa9WqVaxx48ai9+PHj2dffPEFS05OZq9evWICgYA9e/aMGRgYsMGDB7OYmBj28OFDFh4eznx9fUXtb+LEiaxx48bs7Nmz7Pbt26xfv35MQ0ODff/990woFLKioiLWr18/ZmZmxuLi4tjz589Fr8LCwnI/t3/++YcpKSmx9PR0UZmTkxObNWuWRN3MzEymoqLCwsLCGGOMJSUlMVVVVTZlyhR269Ytdv/+fbZixQqmpKTETpw4IdrvzZs3zN7enpmZmbHQ0FB2584dlpiYyIKCgpiNjY3oM65pjx49Yurq6szPz4/du3ePbdiwgfF4PBYeHi6qs27dOtatW7dyj7F161amra0tVvbrr7+ykydPsqSkJHbjxg3m5eXFVFVV2Z07d8Tqubq6skWLFtXoNSmiiu4d6enp0nOqj1CPx7hUohHAxgJBzkuxymUu1rX7Batd5qJg2EtgPJDx7osWNQC0/E/FVqyIxsCBezB48D4UFQkq34EQQgghpBzu7u7Iz8+HjY2NWC+bq6srcnJyRI+xKbN48WL8/PPPCAgIgIODA3r27Iljx47ByspK6vE7deqEwMBArFy5Ek5OTggPD8f06dNl7nGfOXMmeDwemjVrBgMDA6SmpsLU1BSXLl2CQCBAjx494OjoiGnTpkFHR0c0dHL58uXo0qUL+vbtCw8PD3Tu3Flstd5nz57h6NGjePr0KVq1agUTExPRKzo6utx4HB0d0bp1a+zduxcAcOPGDdy6dQuDBg2SqKutrY0vv/wSQUFBAEoXoLpw4QLu378PDw8PtG/fHnv37sW+ffvQs2dP0X66urq4cuUKvL298dtvv8HZ2RldunTBrl27sHz5ctEw4ZpmZWWFY8eO4fTp03BycsKKFSvw119/iRaIAkoXe0pKSpLpuBkZGRg/fjwcHBzQu3dvZGdnIzo6Gs2aNRPVefbsGaKjozF69Ogaux5SisPYR8x8/gxkZ2dDW1sbWVlZEmP7i4uBsUM7Id4wDkDpqJgLTvFo8J0V4gH4onTNpf/VbcifDMYYFi06j4UL/1v+fefOrzF8uKMco/o8lQ1FcXR0BI9HQ6mJYqH2SRRdfWujBQUFSE5OhpWVVf0e7iyD8ePH4/79+3J7BAljTLR6LYcjZbXPKjp27Bj8/PwQHx9fv+dk16BZs2YhIyMDmzdvlncota6ie0dGRgZ0dXWl5lTVRXNUZcR7N/E+8917HXkFouAYY5g16wyWL//vm73ffnOnJLUW1Yc/rsini9onUXTURsn7/vjjD3Tv3h0NGjTAiRMnEBoaij///FPeYX20Pn364MGDB3j27BnMzc3lHc5nwdDQEDNmzJB3GJ8lSlRlxFNRAQCUrZnWUH6hKCyhkGHKlOP488/rorJVqzwxbVoHOUb1eePxeHB0pC8BiGKi9kkUHbVR8qGYmBj8/vvvyMnJgbW1NdauXYtx48bJLR4OhwN1dfUaOda0adNq5Dik1I8//ijvEBRCbXzZR4mqjKhHtWIlJUKMG3cUoaG3AAAcDhAY+BW+/bZNJXuSj8EYQ05ODjQ1NT9qSBAhtYHaJ1F01EbJh8rmcSoK9u7RKVwul9ooUUi1MZuUBqfLgMsArmrpM7My35XpyCsYBVRcLMCIEQdFSSqPx8G2bQMpSa0DQqEQjx49qvT5bYTIA7VPouiojZJPQWFhobxDIKRctXH/pB5VGfCEHIBf+pFlvivTkVcwCmjp0ovYu/cOAEBZmYvduwfj668d5BwVIYQQQggh5FNDPaoy4DEA/NLx12VzVHXkFYwCmjHDBZ07W0BVVQmHD3tRkkoIIYQQQgipFupRlYGSkAsol84LyHxXpiOvYBRQgwYqOHZsOO7ceQkXF1pJrq7RIwaIIqP2SRQdtVGi6GhuKqlvKFGVAZdxRJ9Y5rsyHTnFogjevMlDYaEApqaaojItLT4lqXLA4/Fgb28v7zAIkYraJ1F01EaJouNwOFBTU5N3GISUqzZW/aWhvzLgCblA6VpK9T5RTUvLhZtbKL78chtevnwr73DqPaFQiDdv3tBCIEQhUfskio7aKFF0jDGUlJTUysqqhNSE2rh/UqIqAyUhF1ACBACy35XVx+eoPnmSBVfXEMTHv8T9+68xatRheYdU7zHG8OTJE/oHjCgkap9E0VEbrd8iIyPB4XCQmZlZ5X0WLlyIVq1a1VpMH3J3d8fUqVM/+jhv3ryBoaEhUlJSPj4oAgDw8vLCihUr5B2G3NHjaeRMiZX2qGa9e88BoCXPgOQgKSkdXbpsRWLiGwCAhYU21q3rJeeoCCGEEPK5CwwMhKamJkpKSkRlubm5UFZWhpubm1jdsuQzKSmp0uN27NgRz58/h7a2do3G6+bmhmnTptXoMcssXLgQ9vb2aNCgARo2bAgPDw9cvXq10v38/f3Rv39/WFpaSmzz9PQEj8fDtWvXJLaVdy0hISHQ0dERK8vOzsa8efNgb28PVVVVGBsbw8PDAwcPHqzVL4MiIyPRunVr8Pl82NjYICQkpMr7Pnz4EJqamhLXAgCZmZmYNGkSTExMwOfzYWtri+PHj4u2z58/H/7+/sjKypLYl3wcSlRlwHvXo5r57r0mgJofja247t17ha5dQ/D4cen/EW1sdHHhgi9sbHTlHBkhhBBCPnfu7u7Izc3F9evXRWVRUVEwNjbG1atXUVBQICqPiIiAhYUFmjRpUulxVVRUYGxs/EktVmRra4v169fj9u3buHjxIiwtLdGjRw+8evWq3H3y8vIQFBSEsWPHSmxLTU1FdHQ0Jk+ejODg4GrHlZmZiY4dO2Lbtm2YM2cOYmNjceHCBQwdOhQ//fRTrSVzycnJ6NOnD9zd3REXF4dp06Zh3LhxOHnyZKX7FhcXY9iwYejSpYvEtqKiInTv3h0pKSnYv38/EhISsGXLFjRq1EhUp0WLFmjSpAl27NhRo9dEKFGVSdkc1cx373XkGEtdi4tLg6trCP79NwcA0KyZAS5c8EXjxjryDYyIaGpqVl6JEDmh9kkUXb1vo4wB+fnyeVWxl83Ozg4mJiaIjIwUlUVGRqJ///6wsrLClStXxMrd3d0BlM6dCwgIgJWVFdTU1ODk5IT9+/eL1f1w6O+WLVtgbm4OdXV1DBw4ECtXrpTa27Z9+3ZYWlpCW1sbXl5eyMkp/TvJ19cX58+fx5o1a8DhcMDhcETDbePj49GrVy9oaGjAyMgIPj4+eP36teiYb9++xciRI6GhoQETExPRsNL3E+nhw4fDw8MD1tbWaN68OVauXIns7Gz8888/5X5+x48fB5/PR4cOHSS2bd26FV999RW+++477Nq1C/n5+eUepyJz585FSkoKrl69ilGjRqFZs2awtbXF+PHjERcXBw0NjWodtzKBgYGwsrLCihUr4ODggMmTJ2Pw4MFYtWpVpfvOnz8f9vb2GDJkiMS24OBgpKen4/Dhw+jUqRMsLS3h6uoKJycnsXp9+/bF7t27a+x6SCla9VcGPCbeo1pf5qdevfoUPXvuRGZm6TeVzs7GOHXKB/r66nKOjJTh8XhV+taYEHmg9kkUHbVRAAUFgJQepToRFQVUcUVbd3d3REREYPbs2QBKe05/+uknCAQCREREwM3NDfn5+bh69SrGjBkDAAgICMCOHTsQGBiIpk2b4sKFC/D29oaBgQFcXV0lznHp0iVMnDgRy5YtQ79+/XDmzBn8/PPPEvWSkpJw+PBhhIWFISMjA0OGDMHSpUvh7++PNWvWIDExES1atMCiRYsAAAYGBsjMzES3bt0wbtw4rFq1Cvn5+Zg1axaGDBmCc+fOAQD8/Pxw/vx5HDlyBIaGhpg7dy5iY2PRqlUrqb2+RUVF2Lx5M7S1tSUSKPGPOQpt2rSRKGeMYevWrdiwYQPs7e1hY2OD/fv3w8fHpwq/kf8IhULs3r0bI0aMgKmpqcT2ipLUqKgo9OpV8VSyTZs2YcSIEVK3Xb58GR4eHmJlnp6elQ69PnfuHPbt24e4uDgcPHhQYvvRo0fh4uKCSZMm4ciRIzAwMMDw4cMxa9YssVVu27VrB39/fxQWFoLP51d4zs9Vbaz6S4mqDHis/vWoPnjwBh4e25GbWwQAcHExw/HjI6CjQ8+bUyRCoRAvX76EoaEhuFwaKEEUC7VPouiojX463N3dMW3aNJSUlCA/Px83b96Eq6sriouLERgYCKA0aSksLIS7uzsKCwuxZMkSnDlzBi4uLgAAa2trXLx4EZs2bZKaqK5btw69evXCzJkzAZQOs42OjkZYWJhYPaFQiJCQEFFvvI+PD86ePQt/f39oa2tDRUUF6urqMDY2Fu2zfv16ODs7Y8mSJaKy4OBgmJubIzExEaampggKCsKOHTvw5ZdfAgBCQ0NhZmYGoVAIxpgoWQ0LC4OXlxfy8vJgYmKC06dPQ19fv9zP7vHjx1ITyDNnziAvLw+enp4AAG9vbwQFBcmcqL5+/RoZGRnVetRT27ZtERcXV2EdIyOjcrelpaVJbDcyMkJ2djby8/OlPtrnzZs38PX1xY4dO6ClJX3VmUePHuHcuXMYMWIEjh8/jocPH+L7779HcXExFixYIKpnamqKoqIipKWloXHjxhVex+eqNlb9pURVBjzGE+tR1ZFjLHXFxkYXXl7N8ddfN+HubomjR4dBQ0NF3mGRDzDGkJaWBgMDA3mHQogEap9E0VEbBaCqWtqzKa9zV5Gbmxvevn2La9euISMjA7a2tqKe0dGjR6OgoACRkZGwtraGhYUF7ty5g7y8PHTv3l3sOEVFRXB2dpZ6joSEBAwcOFCsrF27dhKJqqWlpdiQcRMTE7x8+bLC+G/duoWIiAipvYtJSUnIz89HUVER2rdvLyrX1dWFnZ0dBAKBWP2y+ZivX7/Gli1bMGTIEFy9ehWGhoZSz52fnw9VKZ91cHAwhg4dCiWl0rRg2LBh8PPzQ1JSkkwjDT5moSQ1NTXY2NhUe//qGD9+PIYPH46uXbuWW0coFMLQ0BCbN28Gj8dDmzZt8OzZMyxfvlwsUS1LhPPy8mo9bkVVGwtlUaIqg7LFlDLeva8PQ385HA4CA7+Cg4MBvvuuLdTUlOUdEiGEEEJqGodT5eG38mRjYwMzMzNEREQgIyND1CNqamoKc3NzREdHIyIiAt26dQNQuiowABw7dkxsARwAHz1EU1lZ/G8iDodTaa9Sbm4u+vbti2XLlklsMzExwcOHD6t8/gYNGsDGxgY2Njbo0KEDmjZtiqCgIMyZM0dqfX19fWRkZIiVpaen49ChQyguLsbGjRtF5QKBAMHBwfD39wcAaGlpSV0IKTMzU7RasoGBAXR0dHD//v0qX0OZjx36a2xsjBcvXoiVvXjxAlpaWlJ7U4HSYb9Hjx7FH3/8AaA00RIKhVBSUsLmzZsxZswYmJiYQFlZWWxYq4ODA9LS0lBUVAQVldLOm/T0dACo31921QJKVCtRpKaOPAtnCJVVkamhiex6MPQ3M7NAbGgvj8fFjBkucoyIEEIIIaSUu7s7IiMjkZGRAT8/P1F5165dceLECcTExOC7774DADRr1gx8Ph+pqalSh/lKY2dnJ/GIFmmPbKmMioqKRC9o69atceDAAVhaWop6MN/XpEkTKCsr4+rVq7CwsAAAZGRkIDExER07dqzwfEKhEIWFheVud3Z2lliZdufOnTAzM8Phw4fFyk+dOoUVK1Zg0aJF4PF4sLOzw6lTpySOGRsbC1tbWwAAl8uFl5cXtm/fjgULFkgMM87NzYWqqqrU6/7Yob8uLi5ij4wBgNOnT4uGe0tz+fJlsd/PkSNHsGzZMkRHR4u+1OjUqRP+/vtvCIVC0bSAxMREmJiYiJJUoHSBLDMzswqHXpNqYPVcVlYWA8CysrLEyp8yxv4sZszi4hmmcf88a/DgEjP+5yr7poQxd8aYI2Psf/IIuJYFBcUyPb1lLC7uubxDITIQCATs8ePHTCAQyDsUQiRQ+ySKrr610fz8fHb37l2Wn58v71CqJTg4mKmpqTElJSWWlpYmKg8NDWWampoMAPv3339F5fPmzWN6enosJCSEPXz4kN24cYOtXbuWhYSEMMYYi4iIYABYRkYGY4yxixcvMi6Xy1asWMESExNZYGAg09PTYzo6OqJjLliwgDk5OYnFtWrVKta4cWPR+/Hjx7MvvviCJScns1evXjGBQMCePXvGDAwM2ODBg1lMTAx7+PAhCw8PZ76+vqykpIQxxtjEiRNZ48aN2dmzZ9nt27dZv379mIaGBps8eTITCoUsNzeXzZkzh12+fJmlpKSw69evs9GjRzM+n8/i4+PL/dz++ecfpqSkxNLT00VlTk5ObNasWRJ1MzMzmYqKCgsLC2OMMZaUlMRUVVXZlClT2K1bt9j9+/fZihUrmJKSEjtx4oRovzdv3jB7e3tmZmbGQkND2Z07d1hiYiILCgpiNjY2os+4pj169Iipq6szPz8/du/ePbZhwwbG4/FYeHi4qM66detYt27dyj3G1q1bmba2tlhZamoq09TUZJMnT2YJCQksLCyMGRoast9++02s3qhRo9iYMWNq9JoUUUX3joyMDKk51cegRFVKohrPGBvBGOsgYKzRtYtM92Io0z3/F7M9dYD1FjKmzxjTZYxtk1PMtWXt2isMWMiAhczA4Hf29GnNNTRCCCGEKIZPPVFNTk5mAJi9vb1YeUpKCgPA7OzsxMqFQiFbvXo1s7OzY8rKyszAwIB5enqy8+fPM8YkE1XGGNu8eTNr1KgRU1NTYwMGDGC//fYbMzY2Fm2vSqKakJDAOnTowNTU1BgAlpyczBhjLDExkQ0cOJDp6OgwNTU1Zm9vz6ZNm8aEQiFjjLGcnBzm7e3N1NXVmZGREfv999+Zq6srmzp1KmOs9Pc3cOBAZmpqylRUVJiJiQnr168fi4mJqfSza9euHQsMDGSMMXb9+nUGoNz9evXqxQYOHCh6HxMTw7p3784MDAyYtrY2a9++PTt06JDEfpmZmWz27NmsadOmTEVFhRkZGTEPDw926NAh0TXWhoiICNaqVSumoqLCrK2t2datW8W2L1iwQOz38yFpiSpjjEVHR7P27dszPp/PrK2tmb+/v+hLBcZKfx/a2trs8uXLNXQliquie0d5nX8fg8NYLcx8/YRkZ2dDW1sbWVlZ0NLSwjMAswCkArARABfPHka66hsAgFGeFjr3/AYnUDpP1RXAJgCNyjv4J2Tp0ouYM+es6P306R2wYkWPT+rh1/WZUCjE06dPYWZmRitWEoVD7ZMouvrWRgsKCpCcnAwrKyupi+sQSePHj8f9+/cRJacFpxhjojmRH/O32bFjx+Dn54f4+Ph60dbrwsaNG3Ho0CGpQ6M/NxXdOzIzM9GwYUNRTlUTqIV+4BiARwBsAXz4NCAOSm8MRQD4ANIAHMenjTGG+fPPiSWpP//clZLUTwxjDOnp6bWy4hohH4vaJ1F01EbJh/744w/cunULDx8+xLp16xAaGopRo0bJNaYP57tWR58+ffDtt9/i2bNnNRARAUoX1Vq3bp28w5C72rh/0mJK78kGcAalq/nyAHy4bhuHcSAAIADAAaAP4DQALwCa+PQwxjBjxkmsXn1VVLZ06ZeYNauzHKMihBBCCJGvmJgY/P7778jJyYG1tTXWrl2LcePGyTusGjFt2jR5h/BZ+VzahSKiRPU9iQBeArAqZzsHHBS9+28uAGMAKQASALSt9ehqllDI8N13Ydi8OVZUtm5dL0ye3E6OURFCCCGEyN/evXvlHQIh9R4lqu8pAFACoLwnhXIYF2WLfqu8e5W82+9TwhjD6NFHsG3bLQClj077669+GDNG+oOvieLjcDgwNjam4dpEIVH7JIqO2ij5FHz43FZCFElt3D9pjup7VFGauReXs50DjihR5b+rp/Ruv08Jh8NBu3alz7bi8Tj4++9BlKR+4rhcLoyNjWlhBKKQqH0SRUdtlCg6DocDZWVl+jKFKKzauH9Sj+p7bAEYonT4r5mU7RxwRUN/Vd7VMwRgVzfh1ahJk9qhoKAENja66N/fXt7hkI8kEAiQkpICS0tL8HgfLgNGiHxR+ySKjtooUXSMMRQWFoLP51OyShRSTSz29SFKVN+jBcADQAgAEwAf3gben6OqDCATwAB8GgspCYUMXK74Ff34Y0c5RUNqQ05OjrxDIKRc1D6JoqM2ShSdUPjhMp+EfN5ojMsH+gCwRunCSgIAgpI8lGSnoDjzAfLeJuFtYTYYSlcItgLQW46xVlVmZgFcXUNw4MBdeYdCCCGEEEIIIZWiHtUPNAIwB8DP2c8QmXgMz5/sRknBv4BQgKdMDc+OXkKRtQfMm/bBHK1GaCTvgCvx6tVb9OixA3Fxabh69SmOHFFGr15N5R0WIYQQQgghhJSLelSleXkHODMLiAsBivPAGlqDGTQDGlqDFb0F4kKhfGZWaT0F9u+/OXBzC0VcXBoAoGFDNTRqpCXnqEht4HA4MDc3p3krRCFR+ySKjtpo/RYZGQkOh4PMzMwq77Nw4UK0atWq1mL6kLu7O2bPnv3Rx3nz5g0MDQ2RkpLy8UERAECHDh1w4MABeYchd7Tqbx14lv0MARcD8DorFW56zdAo6Sk0HseiwePraJyQgkZaZtDUd0B+VioCLgbgWfYzeYcs1ePHmejadSvu3n0FAGjUSBPnz/uiZUsjOUdGagOXy4Wenh6tWEkUErVPouiojX4aAgMDoampiZKSElFZbm4ulJWV4ebmJla3LPlMSkqq9LgdO3bE8+fPoa2tXaPxurm5Ydq0aTV2PC6XKzUZmDhxIjgcDlavXl3pMfz9/dG/f39YWlpKbPP09ASPx8O1a9cktpV3LSEhIdDR0REry87Oxrx582Bvbw9VVVUYGxvDw8MDBw8eBGOs0hirKzIyEq1btwafz4eNjQ1CQkKqvO/Dhw+hqakpcS0hISHgcDhiL1VV8ed9zJ8/H7Nnz673c4hr4/5Jd+QPHHtwDI8yHsFW1xY8Lg9cQQmUct5AOeslGmTnoAQAh8uDta4tkjOScfzhcXmHLOHBgzfo0mUrkpIyAABWVjqIihoNe3t9OUdGaotAIMD9+/drZcU1Qj4WtU+i6KiNfhrc3d2Rm5uL69evi8qioqJgbGyMq1evoqDgvyfbR0REwMLCAk2aNKn0uCoqKp/Ec3RLSkokEr1Dhw7hypUrMDU1rXT/vLw8BAUFYezYsRLbUlNTER0djcmTJyM4OLjaMWZmZqJjx47Ytm0b5syZg9jYWFy4cAFDhw7FTz/9hKysrGofuyLJycno06cP3N3dERcXh2nTpmHcuHE4efJkpfsWFxdj2LBh6NKli9TtWlpaeP78uej1+PFjse29evVCTk4OTpw4USPX8qmqjfsnJarvyS7MxplHZ9BQtSF4XMnl6Tngip6jqsblQUdVB6eTTiOnUHFWCrxz5yW6dg3BkyfZAAA7Oz1cuDAaVlYN5RwZqW3v/wNNiKKh9kkUXX1vo4wx5Bfny+VV1V42Ozs7mJiYIDIyUlQWGRmJ/v37w8rKCleuXBErd3d3B1C6Wm5AQACsrKygpqYGJycn7N+/X6zuh0N/t2zZAnNzc6irq2PgwIFYuXKlRG8bAGzfvh2WlpbQ1taGl5eXaPVoX19fnD9/HmvWrBH1xJUNt42Pj0evXr2goaEBIyMj+Pj44PXr16Jjvn37FiNHjoSGhgZMTEywYsUK0e/ofc+ePcOUKVOwc+dOKCsrV/r5HT9+HHw+Hx06dJDYtnXrVnz11Vf47rvvsGvXLuTn51d6PGnmzp2LlJQUXL16FaNGjUKzZs1ga2uL8ePHIy4uDhoaGtU6bmUCAwNhZWWFFStWwMHBAZMnT8bgwYOxatWqSvedP38+7O3tMWTIEKnbORwOjI2NRS8jI/HRiTweD71798bu3btr5FrIf2gxpfckvknEy7cvYaVjJSrLVM17rwZH7Dmqhg0MkZyZjIQ3CWhr2rYuQ5UqNvY5evTYjjdvSm8ujo6GOH3aB0ZGtXNTIIQQQsjnoaCkAF22Su9Rqm1Ro6OgpqxWpbru7u6IiIgQzdeMiIjATz/9BIFAgIiICLi5uSE/Px9Xr17FmDFjAAABAQHYsWMHAgMD0bRpU1y4cAHe3t4wMDCAq6urxDkuXbqEiRMnYtmyZejXrx/OnDmDn3/+WaJeUlISDh8+jLCwMGRkZGDIkCFYunQp/P39sWbNGiQmJqJFixZYtGgRAMDAwACZmZno1q0bxo0bh1WrViE/Px+zZs3CkCFDcO7cOQCAn58fzp8/jyNHjsDQ0BBz585FbGwsmjdvLjq3UCiEj48P/Pz8xMor/JyjotCmTRuJcsYYtm7dig0bNsDe3h42NjbYv38/fHx8qnTc92PavXs3RowYIbWHt6IkNSoqCr169arw+Js2bcKIESOkbrt8+TI8PDzEyjw9PSsden3u3Dns27cPcXFxOHjwoNQ6ubm5aNy4MYRCIVq3bo0lS5ZIfObt2rXD0qVLKzwXkR0lqu8pKClAibAEytz/vpUq4pZA6d2Qcw64KPsuSwUAl6uMEmEJCkoU41vYzMwC5OaWptJffGGK8HBv6OpW7cZPCCGEEKLo3N3dMW3aNJSUlCA/Px83b96Eq6sriouLERgYCKA0aSksLIS7uzsKCwuxZMkSnDlzBi4uLgAAa2trXLx4EZs2bZKaqK5btw69evXCzJkzAQC2traIjo5GWFiYWD2hUIiQkBBoamoCAHx8fHD27Fn4+/tDW1sbKioqUFdXh7GxsWif9evXw9nZGUuWLBGVBQcHw9zcHImJiTA1NUVQUBB27NiBL7/8EgAQGhoKMzMzsXMvW7YMSkpK+OGHH6r82T1+/FhqAnnmzBnk5eXB09MTAODt7Y2goCCZE9XXr18jIyMD9vb2Mu0HAG3btkVcXFyFdT7syXxfWlqaxHYjIyNkZ2cjPz8famqSfw+/efMGvr6+2LFjB7S0pC82amdnh+DgYLRs2RJZWVn4448/0LFjR9y5c0fsd2JqaoonT55AKBTSXPcaRInqe1SVVKHEVUKxsBgqPBXJCpzShqcEgAegSFgMJa4SVJVUJevKQbduVjhwYAhWrryCQ4eGQkuLL++QSB3hcrmwtrammyNRSNQ+iaKjNlr6N1DU6Ci5nbuq3Nzc8PbtW1y7dg0ZGRmwtbUV9YyOHj0aBQUFiIyMhLW1NSwsLHDnzh3k5eWhe/fuYscpKiqCs7Oz1HMkJCRg4MCBYmXt2rWTSFQtLS1FSSoAmJiY4OXLlxXGf+vWLUREREjtXUxKSkJ+fj6KiorQvn17Ubmuri7s7OygpFT6Z/uNGzewZs0axMbGyjSvNj8/X2IhIKA0UR46dKjo+MOGDYOfnx+SkpKqNMe3zMcslKSmpgYbG5tq718d48ePx/Dhw9G1a9dy67i4uIi+4ABKF95ycHDApk2bsHjxYlG5mpoahEIhCgsLpSbF9UFt3D8pUX2PrZ4tDBsY4uXblzDTMpPYzt4lqmUp7Mu3L2HYwBB2enZ1GGXF+vSxRe/eTRV+QQBSszgcTrnfBhIib9Q+iaKjNlr6GVR1+K082djYwMzMDBEREcjIyBD1iJqamsLc3BzR0dGIiIhAt27dAJQO2wSAY8eOoVGjRmLH4vM/7gv9D+eFcjicSld+zc3NRd++fbFs2TKJbSYmJnj48GG5+5bNdY2KisLLly9hYWEh2iYQCPDjjz9i9erV5T56Rl9fHxkZGWJl6enpOHToEIqLi7Fx40ax4wUHB8Pf3x9A6YJC0hZCyszMFK2WbGBgAB0dHdy/f7/8D6AcHzv019jYGC9evBAre/HiBbS0tMpNHM+dO4ejR4/ijz/+AFCaaAuFQigpKWHz5s2ioePvU1ZWhrOzs8TvKT09HQ0aNKi3SSpQO4+noUT1PVp8LXhYeyAkLgQmGibg4IMFld79AvgABEIBMgsyMcBhADT5mpIHqwP799/FvXuv8PPP4sNWKEmtfwQCAe7evYtmzZqBx5NcCIwQeaL2SRQdtdFPi7u7OyIjI5GRkQE/Pz9RedeuXXHixAnExMTgu+++AwA0a9YMfD4fqampUof5SmNnZyfxiBZpj2ypjIqKisRKqK1bt8aBAwdgaWkp6sF8X5MmTaCsrIyrV6+KEtGMjAwkJiaiY8eOYIzBx8dH6nxMHx8fjB49utx4nJ2dsWPHDrGynTt3wszMDIcPHxYrP3XqFFasWIFFixaBx+PBzs4Op06dkjhmbGwsbG1tAZT2qHl5eWH79u1YsGCBxDDj3NxcqKqqSr3ujx366+LiguPHxZ/Ecfr0abHe0A9dvnxZ7Pdz5MgRLFu2DNHR0RJfapQRCAS4ffs2evfuLVYeHx9fbg99fVEbq/5SovqBPk374MLjC0hMT4SNjq3YtrIeVWWhAInpibBqaIXeNr2lHabWbdt2C6NHH4FQyKCqqgQ/v05yiYMoDnqsAlFk1D6JoqM2+ulwd3fHpEmTUFxcLJZ8urq6YvLkySgqKhKt+KupqYmZM2di+vTpEAqF6Ny5M7KysnDp0iVoaWlh1KhREsefMmUKunbtipUrV6Jv3744d+4cTpw4IXNHgKWlJa5evYqUlBRoaGhAV1cXkyZNwpYtWzBs2DD89NNP0NXVxcOHD7F792789ddf0NDQwNixY+Hn5wc9PT0YGhpi3rx5YsMq9fT0oKenJ3YuZWVlGBsbw86u/FF+np6emDNnDjIyMtCwYenTIIKCgjB48GC0aNFCrK65uTnmzJmD8PBw9OnTB9999x3Wr1+PH374AePGjQOfz8exY8ewa9cu/O9//xPt5+/vj8jISLRv3x7+/v5o27YtlJWVERUVhYCAAFy7dk3q6skfO/R34sSJWL9+PX766SeMGTMG586dw969e3Hs2DFRnfXr1+PQoUM4e/YsAMDBwUHsGNevXweXyxX7LBYtWoQOHTrAxsYGmZmZWL58OR4/foxx48aJ7RsVFYUePXpUO34iXf2djFGORlqNMKfzHFhoW+Dem7so4QrA3v1PwGUoyn6K7Nf3YKFtgTmd56CRlvRvXGpTYOB1jBp1GEJh6VyAe/de1+oDlAkhhBBCFIW7uzvy8/NhY2Mj1svm6uqKnJwc0WNsyixevBg///wzAgIC4ODggJ49e+LYsWOwsrKSdnh06tQJgYGBWLlyJZycnBAeHo7p06dLnd9ZkZkzZ4LH46FZs2YwMDBAamoqTE1NcenSJQgEAvTo0QOOjo6YNm0adHR0RMno8uXL0aVLF/Tt2xceHh7o3Lmz1NV6ZeXo6IjWrVtj7969AErnut66dQuDBg2SqKutrY0vv/wSQUFBAEoXoLpw4QLu378PDw8PtG/fHnv37sW+ffvQs2dP0X66urq4cuUKvL298dtvv8HZ2RldunTBrl27sHz5ctEw4ZpmZWWFY8eO4fTp03BycsKKFSvw119/iRaIAkoXe0pKSpLpuBkZGRg/fjwcHBzQu3dvZGdnIzo6Gs2aNRPVefbsGaKjoyvszSbVw2H1PMPJzs6GtrY2srKyxOanPMt+hv8lHIffwSkApxgMgEGJOTK/aIfuTbpjlU1vuSSpK1dexo8//jf0YtKkL7B2bS9wuTTctz4rG4ri6OhIw9aIwqH2SRRdfWujBQUFSE5OhpWVlczJV301fvx43L9/H1FR8llwijEmWr32Y6Z4HTt2DH5+foiPj6/Xi4fVpFmzZiEjIwObN2+Wdyi1rqJ7R0ZGBnR1dSVyqo9BQ3/L0UirEca2Go+V2+eDy7IgBOBW0AvX+v2OXnxN1HWKyhjDb79dwC+/RIrKfvqpI5Yu9aA5qQRcLhd2dnb0jw5RSNQ+iaKjNko+9Mcff6B79+5o0KABTpw4gdDQUPz5559yjakmvlTo06cPHjx4gGfPnsHc3LwGoiKGhoaYMWOGvMOQO1r1Vw64jAv14tJvV42YFXh8TTSs4xgYY5gz5yyWLbskKlu0yA3z53elJJWIqKhIeaQSIQqC2idRdNRGyftiYmLw+++/IycnB9bW1li7dq3EvMS6VlN/802bNq1GjkNK/fjjj/IO4bNFiaoMSt4tQ65Th+cUChmmTj2B9ev/W21uxYoemDGj/FXMSP0jFArr1bA18mmh9kkUHbVR8qGyeZyKpGzoLyGKqLJHM1UHJaoyKH73batOHZ7z5cu3OHjwv+dRbdzYBxMntq3DCAghhBBCCCGkbtFkDBmUqNR9j6qxsQbOnPGBsbEGQkMHUJJKCCGEEEII+exRj6oMivilPap1PUfVwcEADx5MgYYGzZ8hhBBCCCGEfP6oR1UGAmVlcAFo1uI58vKKsWRJFEpKxMd5U5JKKsLlcuHo6EgrVhKFRO2TKDpqo+RTQPNTiSKrjfsn3ZFlIFBShhZq70PLzi5Ez547MG/eOfj6HoZAUPOTksnnq6ioSN4hEFIuap9E0VEbJYqOMSbvEAipU5SoykCgolJr81PT0/Ph4bENUVGpAID//S8RSUkZtXQ28rkRCoVISEiolRXXCPlY1D6JoqM2Sj4FBQUF8g6BkHLVxv2TElUZCJRUamV+6osXuXBzC8G1a/8CAPT01BARMQq2tnq1cDZCCCGEkPopJSUFHA4HcXFxVd4nJCQEOjo6co+jrri5uSn8s1YTEhJgbGyMnJwceYfy2fDy8sKKFSvkHYYYSlRlIFCu+R7Vp0+z4eoagtu3XwIoXeU3MtIXrVub1PCZCCGEEEI+fU+ePMGYMWNgamoKFRUVNG7cGFOnTsWbN28q3dfc3BzPnz9HixYtqny+oUOHIjEx8WNCrhY3NzdwOBzs3r1brHz16tWwtLQUvQ8JCQGHw0HPnj3F6mVmZoLD4SAyMrJW44yMjASHw0FmZqbM+/r7+6Njx45QV1eX6cuAOXPmYMqUKdDUlFw5xt7eHnw+H2lpaRLbLC0tsXr1aonyhQsXolWrVmJlaWlpmDJlCqytrcHn82Fubo6+ffvi7NmzVY6zOvbt2wd7e3uoqqrC0dERx48fr3SfwsJCzJs3D40bNwafz4elpSWCg4NF2+/cuYNBgwbB0tISHA5H6mcwf/58+Pv7IysrqyYv56NQoiqDEhV+jSaqyckZ6Np1KxISSm+s5uZauHDBFy1aGNbgWUh9QQ+pJ4qM2idRdNRGPw2PHj1C27Zt8eDBA+zatQsPHz5EYGAgzp49CxcXF6Snp5e7b1FREXg8HoyNjaGkVPUHX6ipqcHQUD5/m6mqqmL+/PkoLi6usJ6SkhLOnDmDiIiIOoqsZhQVFeGbb77Bd999V+V9UlNTERYWBl9fX4ltFy9eRH5+PgYPHozQ0NBqx5WSkoI2bdrg3LlzWL58OW7fvo3w8HC4u7tj0qRJ1T5uZaKjozFs2DCMHTsWN2/exIABAzBgwADEx8dXuN+QIUNw9uxZBAUFISEhAbt27YKdnZ1oe15eHqytrbF06VIYGxtLPUaLFi3QpEkT7Nixo0av6WNQoioDQQ0mqgkJr9Gly1YkJ2cCAJo0aYioqNFo2pSG+xLZ8Xg8ODo60h9aRCFR+ySKjtookJUFXLwov1dVO3EmTZoEFRUVnDp1Cq6urrCwsECvXr1w5swZPHv2DPPmzRPVtbS0xOLFizFy5EhoaWnh22+/lTrk9ujRo2jatClUVVXh7u6O0NBQsR7CD4f+lvW+bd++HZaWltDW1oaXl5fYMNTw8HB07twZOjo60NPTw1dffYWkpCSZfy/Dhg1DZmYm/vrrL6irq4PD4Uit16BBA4wZMwazZ8+W6fhv377FyJEjoaGhARMTE6lDP7dv3462bdtCU1MTxsbGGD58OF6+LB0JmJKSAnd3dwBAw4YNweFwRAlkVT6DX3/9FdOnT4ejo2OVY967dy+cnJzQqFEjiW1BQUEYPnw4fHx8xHoUZfX999+Dw+EgJiYGgwYNgq2tLZo3b44ZM2bgypUr1T5uZdasWYOePXvCz88PDg4OWLx4MVq3bo3169eXu094eDjOnz+P48ePw8PDA5aWlnBxcUGnTp1Edb744gssX74cXl5e4PP55R6rb9++Ej34VVUb9096jqoMipWVamyOqp/faTx7VnpDc3DQx5kzI2FqWpsPviGfM8YYcnJyoKmpWe4/YoTIC7VPouiojQK3bwNdusjv/FFRQOfOFddJT0/HyZMn4e/vL/GoFmNjY4wYMQJ79uzBn3/+Kfo9/vHHH/jll1+wYMECqcdMTk7G4MGDMXXqVIwbNw43b97EzJkzK403KSkJhw8fRlhYGDIyMjBkyBAsXboU/v7+AEoTwBkzZqBly5bIzc3FL7/8goEDByIuLk6mx3hoaWlh3rx5WLRoEby9vaUOdS2zcOFC2NjYYP/+/Rg8eHCVju/n54fz58/jyJEjMDQ0xNy5cxEbGys2DLa4uBiLFy+GnZ0dXr58iRkzZsDX1xfHjx+Hubk5Dhw4gEGDBiEhIQFaWlqi301NfQYfioqKQtu2bSXKc3JysG/fPly9ehX29vbIyspCVFQUusjYsNPT0xEeHg5/f380aNBAYntFQ5R37tyJCRMmVHj8EydOlBvT5cuXMWPGDLEyT09PHD58uNzjHT16FG3btsXvv/+O7du3o0GDBujXrx8WL14s8yON2rVrB39/fxQWFlaY0EpTG6tSU6Iqg2J+zc1RDQkZAHf3UHC5HJw65Q0DA8n/IxBSVUKhEI8ePar3PQJEMVH7JIqO2uin4cGDB2CMwcHBQep2BwcHZGRk4NWrV6Khut26dcOPP/4oqpOSkiK2z6ZNm2BnZ4fly5cDAOzs7BAfHy9KOMsjFAoREhIiShx9fHxw9uxZ0X6DBg0Sqx8cHAwDAwPcvXtXpvmxQGnv3po1a/DHH3/g119/Lbeeqakppk6dinnz5mHAgAGVHjc3NxdBQUHYsWMHvvzySwBAaGgozMzMxOqNGTNG9N/W1tZYu3YtvvjiC+Tm5kJDQwO6uroAAENDQ7EkriY/g/c9fvxYaqK6e/duNG3aFM2bNwdQujhQUFCQzInqw4cPwRiDvb29zLH169cP7du3r7COtJ7gMmlpaTAyMhIrMzIykjrftsyjR49w8eJFqKqq4tChQ3j9+jW+//57vHnzBlu3bpUpflNTUxQVFSEtLQ2NGzeWaV9a9VfOanLor66uGk6f9sG5cyMpSSWEEEIIqSJZem6kJTTvS0hIwBdffCFW1q5du0qPa2lpKda7aWJiIhoOC5Qm1cOGDYO1tTW0tLREix+lpqZWOfYyfD4fv/76K9asWYPXr19XWHfWrFl49epVlYa9JiUloaioSCyx0tXVFZvbCAA3btxA3759YWFhAU1NTbi6ulbpWmryM3hffn4+VFVVJcqDg4Ph7e0teu/t7Y19+/bJvDLwx/QMampqwsbGpsKXrL2clREKheBwONi5cyfatWuH3r17Y+XKlQgNDUV+fr5MxyqLLS8vr0ZjrC7qUa3Me221ULX6PaoXLjxGixaG0NX9r3EaGlKCSgghhBD5c3QsHX4rz/NXxsbGBhwOB/fu3cPAgQMltt+7dw8NGzaEgYGBqEza0M2aoKysLPaew+GI9Sj17dsXjRs3xpYtW2BqagqhUIgWLVqgqKioWufz9vbG8uXL8dtvv8HKyqrcejo6OpgzZw5+/fVXfPXVV9U61/vevn0LT09PeHp6YufOnTAwMEBqaio8PT0rvZaa/gzK6OvrIyMjQ6zs7t27uHLlCmJiYjBr1ixRuUAgwO7duzF+/HgApUOppa1qm5mZCW1tbQBA06ZNweFwcP/+fZlj+9ihv8bGxnjx4oVY2YsXL8pdAAko/ZKkUaNGoviB0tEFjDE8ffoUTZs2rXL8ZYuRvf//IXmiRLUSnPcy1WJ+9XpUjx5NwDff7IOTkxHOnBkJLS3ZxnwTUhXSvl0kRFFQ+ySKrr63UW3tyueIypuenh66d++OP//8E9OnTxfrmUpLS8POnTsxcuRImeYZ29nZSTz+49q1ax8V55s3b5CQkIAtW7aIEpKLFy9+1DG5XC4WLVqEYcOGVbpC7pQpU7B27VqsWbOmwnpNmjSBsrIyrl69CgsLCwBARkYGEhMTRb2m9+/fx5s3b7B06VKYm5sDAK5fvy52HBUVFQClSWGZ2vgMyjg7O+Pu3btiZUFBQejatSs2bNggVr5161YEBQWJElU7OzvcuHFD4pixsbGinmRdXV14enpiw4YN+OGHHyS+7MjMzCx3nurHDv11cXHB2bNnxZ5je/r0abi4uJS7T6dOnbBv3z7RUGwASExMBJfLlRjGXZn4+HiYmZlBX19fpv1qCw39rdR7iaqqmsyJ6u7d8fj66z0oKhLg2rV/sWrV5RqNjhCgdKU1e3t7mltFFBK1T6LoqI1+OtavX4/CwkJ4enriwoULePLkCcLDw9G9e3c0atSo0rmlH5owYQLu37+PWbNmITExEXv37kVISAgAVHthrYYNG0JPTw+bN2/Gw4cPce7cOYkFcmTF4XDw9ddfo3379ti0aVOFdVVVVfHrr79i7dq1FdbT0NDA2LFj4efnh3PnziE+Ph6+vr5iCx1ZWFhARUUF69atw6NHj3D06FEsXrxY7DiNGzcGh8NBWFgYXr16hdzc3Cp/BqmpqYiLi0NqaioEAgHi4uIQFxeH3NzccuP29PTE5cuXRYlxcXExtm/fjmHDhqFFixZir3HjxuHq1au4c+cOAGD69Ok4duwY/P39ce/ePcTHx2PevHm4fPkypk6dKjrHhg0bIBAI0K5dOxw4cAAPHjzAvXv3sHbt2gqTxo8d+jt16lSEh4djxYoVuH//PhYuXIjr169j8uTJojpz5szByJEjRe+HDx8OPT09jB49Gnfv3sWFCxfg5+eHMWPGiM5VVFQk+myLiorw7NkzxMXF4eHDh2Lnj4qKQo8ePcqNryK1cv9k9VxWVhYDwLKysiS2FRUxZj/JkDlPUC993XjLhDIcOygolnE4CxlQ+vL2PsiKiwU1Fzwh7wgEAvb69WsmEFD7IoqH2idRdPWtjebn57O7d++y/Px8eYdSLSkpKWzUqFHMyMiIKSsrM3NzczZlyhT2+vVrsXqNGzdmq1atEitLTk5mANjNmzdFZUeOHGE2NjaMz+czNzc3tnHjRgZA9Pls3bqVaWtri+ovWLCAOTk5iR131apVrHHjxqL3p0+fZg4ODozP57OWLVuyyMhIBoAdOnSo3Dg+5OrqyqZOncoYY0woFLLi4mJ26dIlBkDsXB/GxxhjJSUlrFmzZgwAi4iIKPccOTk5zNvbm6mrqzMjIyP2+++/i52XMcb+/vtvZmlpyfh8PnNxcWFHjx6ViH3RokXM2NiYcTgcNmrUqCp9BowxNmrUKIbSXiGxV0UxFxcXM1NTUxYeHs4YY2z//v2My+WytLQ0qfUdHBzY9OnTRe9PnjzJOnXqxBo2bMj09PSYm5sbO3/+vMR+//77L5s0aRJr3LgxU1FRYY0aNWL9+vWrMLaasHfvXmZra8tUVFRY8+bN2bFjx8S2jxo1irm6uoqV3bt3j3l4eDA1NTVmZmbGZsyYwfLy8kTby9rbh6/3j5Ofn8+0tbXZ5cuXy42tontHRkZGuTlVdXEYq4W1hD8h2dnZ0NbWRlZWFrS0tMS2FRcDTtMNoVryFgDAGZ+FG22qNlp6/foYTJlyQvT+229bY+PGr8Dl1s9l70ntEggEuH37Nq1YSRQStU+i6OpbGy0oKEBycjKsrKzq/ZBnafz9/REYGIgnT57IOxQRxhjy8/OhpqZWbx+h9L4NGzbg6NGjOHnypLxD+Wxs3LgRhw4dwqlTp8qtU9G9IyMjA7q6ulJzquqiOaqV4LyXx6ugav94/f77JcyadUb0ftq09li50pNuLIQQQgghCubPP//EF198AT09PVy6dAnLly8XG2pJFM+ECROQmZkpev4x+XjKyspYt26dvMMQQ4lqJRoUCdE0XQB+CcCNvw40tQPK+ZaAMYYFCyKxePEFUdm8eV2weLE7JamEEEIIIQrowYMH+O2335Ceng4LCwv8+OOPmDNnjrzDIhVQUlLCvHnz5B3GZ2XcuHHyDkECJarlefYMnKPHsCgiF/p5JeAJAU6qH3DMEPDwAPr0AT5YtWv37nixJHXJkm6YM0e2hwwTUl30jSJRZNQ+iaKjNlp/rVq1CqtWrZJ3GJV6f5EjQuoDavHS3LkDzJoF7rYQqBUzPNPk4FFDDl6aWAFv3wKhocCsWaX13vPNN83x9dcOAIA1a3pSkkrqDI/HQ5MmTerF3Cry6aH2SRQdtVGi6DgcDlRVVWmEHlFYtXH/pET1Q8+eAQEBQGoqmEMzvNTgoITHATgcAMqAmRng4ACkppbWe/ZMtKuSEhe7dg3C8ePD8cMPFT9DiZCaJBQKkZaWJvawcUIUBbVPoujqaxut5+tpflIYYyguLqbfGZGritpfbdw/KVH90LFjwKNHgK0t8ME3A0plzzHm8QBbWwiTHuH19gNidVRUeOjVq2kdBUtIKcYY0tLS6B8wopCofRJFV9/aqLKyMgAgLy9PzpEQWRQXF8s7BFLPld0zyu4h76uN+yfNUX1fdjZw5gzQsGFpMipE6VOG3uEJ/vvvEsZBbFI+0n4NRote/WHt1LjOwyWEEEIIkRWPx4OOjg5evnwJAFBXV6chpQqOMYbCwkJwOBz6XZE6xxhDXl4eXr58CR0dnTqbJkGJ6vsSE4GXLwErK1HRDT0V/NU+FwVKgGrJFky43hALrb9G+MkkvHoFWCMTP/XfgN0Pl0JJiTqoCSGEEKL4jI2NAUCUrBLFVjb0V1lZmRJVIjc6Ojqie0ddoET1fQUFQEkJoKwMj6wtOGvHgPcW9n0LYIlbBpawIHzZBfhmT2uocIF5P35BSSqRKw6HA11dXfrHiygkap9E0dXHNsrhcGBiYgJDQ0MaUvoJKJtHbWxsTKv/ErlQVlausCe1Nu6flKi+T1UVUFJCY/4WpNpXUI8DnLUHHkyOxT+XOkDbxaqCyoTUPi6XCwsLC3mHQYhU1D6JoqvPbZTH49Fqx58Ia2treYdASLlq4wsUhfxKZsOGDbC0tISqqirat2+PmJiYCuvv27cP9vb2UFVVhaOjI44fP169E9vawsP4PFL1qlY9VQ8YZHsFsLOr3vkIqSFCoRCpqan1bsVK8mmg9kkUHbVRouiojRJFVy9W/d2zZw9mzJiBBQsWIDY2Fk5OTvD09Cx3DkV0dDSGDRuGsWPH4ubNmxgwYAAGDBiA+Ph42U+upYWzMuacZ+0A0EPCiZwxxpCenl5vVqwknxZqn0TRURslio7aKFF0tdE2FS5RXblyJcaPH4/Ro0ejWbNmCAwMhLq6OoKDg6XWX7NmDXr27Ak/Pz84ODhg8eLFaN26NdavXy/zuX8c0BaQdXg1B5g1sJPM5yKEEEIIIYQQIp1CzVEtKirCjRs3MGfOHFEZl8uFh4cHLl++LHWfy5cvY8aMGWJlnp6eOHz4sNT6hYWFKCwsFL3PysoCAGRkZCDU5ka14g5qEo152dkQCARi5VwuFxwOR2o5INlFXl45j8cDY0xquVAolPgGQ1o5h8MBl8stt/zDGMsrp2tSzGsqKipCTk4OMjIywOPxPotr+hx/T/X1mgQCAXJycpCVlSWx2MKnek0VxU7X9OldU1kbzcjIgIqKymdxTR/GSNf0aV9TcXGx2L/zn8M1fY6/p/p8TWU5VU32rCpUovr69WsIBAIYGRmJlRsZGeH+/ftS90lLS5NaPy0tTWr9gIAA/PrrrxLllpaWaDCrenEXKAHa2trV25kQQgghhBBCPgNv3rypsbxIoRLVujBnzhyxHlihUIj09HTo6emVu6xydnY2zM3N8eTJE2hpaUk/8NzaiJaQqqlSGyVETqh9EkVHbZQoOmqjRNFlZWXBwsICurq6NXZMhUpU9fX1wePx8OLFC7HyFy9elPtwWWNjY5nq8/l88Pl8sTIdHZ0qxaelpUU3B6LQqI0SRUbtkyg6aqNE0VEbJYquJh9To1CLKamoqKBNmzY4e/asqEwoFOLs2bNwcXGRuo+Li4tYfQA4ffp0ufUJIYQQQgghhCg2hepRBYAZM2Zg1KhRaNu2Ldq1a4fVq1fj7du3GD16NABg5MiRaNSoEQICAgAAU6dOhaurK1asWIE+ffpg9+7duH79OjZv3izPyyCEEEIIIYQQUk0Kl6gOHToUr169wi+//IK0tDS0atUK4eHhogWTUlNTxbqUO3bsiL///hvz58/H3Llz0bRpUxw+fBgtWrSosZj4fD4WLFggMWSYEEVBbZQoMmqfRNFRGyWKjtooUXS10UY5jJ4cTAghhBBCCCFEgSjUHFVCCCGEEEIIIYQSVUIIIYQQQgghCoUSVUIIIYQQQgghCoUSVUIIIYQQQgghCoUS1Xc2bNgAS0tLqKqqon379oiJiamw/r59+2Bvbw9VVVU4Ojri+PHjdRQpqY9kaZ9btmxBly5d0LBhQzRs2BAeHh6VtmdCPpas99Ayu3fvBofDwYABA2o3QFLvydpGMzMzMWnSJJiYmIDP58PW1pb+rSe1StY2unr1atjZ2UFNTQ3m5uaYPn06CgoK6ihaUp9cuHABffv2hampKTgcDg4fPlzpPpGRkWjdujX4fD5sbGwQEhIi83kpUQWwZ88ezJgxAwsWLEBsbCycnJzg6emJly9fSq0fHR2NYcOGYezYsbh58yYGDBiAAQMGID4+vo4jJ/WBrO0zMjISw4YNQ0REBC5fvgxzc3P06NEDz549q+PISX0haxstk5KSgpkzZ6JLly51FCmpr2Rto0VFRejevTtSUlKwf/9+JCQkYMuWLWjUqFEdR07qC1nb6N9//43Zs2djwYIFuHfvHoKCgrBnzx7MnTu3jiMn9cHbt2/h5OSEDRs2VKl+cnIy+vTpA3d3d8TFxWHatGkYN24cTp48KduJGWHt2rVjkyZNEr0XCATM1NSUBQQESK0/ZMgQ1qdPH7Gy9u3bswkTJtRqnKR+krV9fqikpIRpamqy0NDQ2gqR1HPVaaMlJSWsY8eO7K+//mKjRo1i/fv3r4NISX0laxvduHEjs7a2ZkVFRXUVIqnnZG2jkyZNYt26dRMrmzFjBuvUqVOtxkkIAHbo0KEK6/z000+sefPmYmVDhw5lnp6eMp2r3veoFhUV4caNG/Dw8BCVcblceHh44PLly1L3uXz5slh9APD09Cy3PiHVVZ32+aG8vDwUFxdDV1e3tsIk9Vh12+iiRYtgaGiIsWPH1kWYpB6rThs9evQoXFxcMGnSJBgZGaFFixZYsmQJBAJBXYVN6pHqtNGOHTvixo0bouHBjx49wvHjx9G7d+86iZmQitRUrqRUk0F9il6/fg2BQAAjIyOxciMjI9y/f1/qPmlpaVLrp6Wl1VqcpH6qTvv80KxZs2BqaipxwyCkJlSnjV68eBFBQUGIi4urgwhJfVedNvro0SOcO3cOI0aMwPHjx/Hw4UN8//33KC4uxoIFC+oibFKPVKeNDh8+HK9fv0bnzp3BGENJSQkmTpxIQ3+JQigvV8rOzkZ+fj7U1NSqdJx636NKyOds6dKl2L17Nw4dOgRVVVV5h0MIcnJy4OPjgy1btkBfX1/e4RAilVAohKGhITZv3ow2bdpg6NChmDdvHgIDA+UdGiEAStejWLJkCf7880/Exsbi4MGDOHbsGBYvXizv0AipMfW+R1VfXx88Hg8vXrwQK3/x4gWMjY2l7mNsbCxTfUKqqzrts8wff/yBpUuX4syZM2jZsmVthknqMVnbaFJSElJSUtC3b19RmVAoBAAoKSkhISEBTZo0qd2gSb1SnfuoiYkJlJWVwePxRGUODg5IS0tDUVERVFRUajVmUr9Up43+/PPP8PHxwbhx4wAAjo6OePv2Lb799lvMmzcPXC71RRH5KS9X0tLSqnJvKkA9qlBRUUGbNm1w9uxZUZlQKMTZs2fh4uIidR8XFxex+gBw+vTpcusTUl3VaZ8A8Pvvv2Px4sUIDw9H27Zt6yJUUk/J2kbt7e1x+/ZtxMXFiV79+vUTrQxobm5el+GTeqA699FOnTrh4cOHoi9RACAxMREmJiaUpJIaV502mpeXJ5GMln2xUrreDSHyU2O5kmzrPH2edu/ezfh8PgsJCWF3795l3377LdPR0WFpaWmMMcZ8fHzY7NmzRfUvXbrElJSU2B9//MHu3bvHFixYwJSVldnt27fldQnkMyZr+1y6dClTUVFh+/fvZ8+fPxe9cnJy5HUJ5DMnaxv9EK36S2qbrG00NTWVaWpqssmTJ7OEhAQWFhbGDA0N2W+//SavSyCfOVnb6IIFC5impibbtWsXe/ToETt16hRr0qQJGzJkiLwugXzGcnJy2M2bN9nNmzcZALZy5Up28+ZN9vjxY8YYY7Nnz2Y+Pj6i+o8ePWLq6urMz8+P3bt3j23YsIHxeDwWHh4u03kpUX1n3bp1zMLCgqmoqLB27dqxK1euiLa5urqyUaNGidXfu3cvs7W1ZSoqKqx58+bs2LFjdRwxqU9kaZ+NGzdmACReCxYsqPvASb0h6z30fZSokrogaxuNjo5m7du3Z3w+n1lbWzN/f39WUlJSx1GT+kSWNlpcXMwWLlzImjRpwlRVVZm5uTn7/vvvWUZGRt0HTj57ERERUv+2LGuTo0aNYq6urhL7tGrViqmoqDBra2u2detWmc/LYYzGBxBCCCGEEEIIURz1fo4qIYQQQgghhBDFQokqIYQQQgghhBCFQokqIYQQQgghhBCFQokqIYQQQgghhBCFQokqIYQQQgghhBCFQokqIYQQQgghhBCFQokqIYQQQgghhBCFQokqIYQQQgghhBCFQokqIYSQWhMZGQkOh4PIyEh5h1KrOBwOFi5cWKW6lpaW8PX1rdV4Phfff/89unfvLu8wAADFxcUwNzfHn3/+Ke9QCCGkXqBElRBCiISQkBBwOBypr9mzZ8s7vAp9GLuqqipsbW0xefJkvHjxok5iiI6OxsKFC5GZmVkn56sKS0tLsc+lQYMGaNeuHbZt21btYx4/frzKCbqskpOT8ddff2Hu3LmispSUlHLbZYcOHUT1fH19xbZpaWnByckJK1asQGFhoajewoULxeopKyvD0tISP/zwg8TvTllZGTNmzIC/vz8KCgpq5ZoJIYT8R0neARBCCFFcixYtgpWVlVhZixYt5BSNbMpiLygowMWLF7Fx40YcP34c8fHxUFdXr9Fz5efnQ0npv39So6Oj8euvv8LX1xc6OjpidRMSEsDlyud74latWuHHH38EADx//hx//fUXRo0ahcLCQowfP17m4x0/fhwbNmyolWR1zZo1sLKygru7u8S2YcOGoXfv3mJlBgYGYu/5fD7++usvAEBmZiYOHDiAmTNn4tq1a9i9e7dY3Y0bN0JDQwNv377F2bNnsW7dOsTGxuLixYti9UaPHo3Zs2fj77//xpgxY2riMgkhhJSDElVCCCHl6tWrF9q2bSvvMKrl/djHjRsHPT09rFy5EkeOHMGwYcNq9FyqqqpVrsvn82v03LJo1KgRvL29Re99fX1hbW2NVatWVStRrS3FxcXYuXMnJk6cKHV769atxa5DGiUlJbE633//Pdq3b489e/Zg5cqVMDU1FW0bPHgw9PX1AQATJkyAl5cX9uzZg5iYGLRr105UT0dHBz169EBISAglqoQQUsto6C8hhBCZPX78GN9//z3s7OygpqYGPT09fPPNN0hJSal03wcPHmDQoEEwNjaGqqoqzMzM4OXlhaysLLF6O3bsQJs2baCmpgZdXV14eXnhyZMn1Y65W7duAEqHlAJASUkJFi9ejCZNmoDP58PS0hJz584VGxoKANevX4enpyf09fWhpqYGKysriSTl/TmqCxcuhJ+fHwDAyspKNKy07LN5f47q9evXweFwEBoaKhHvyZMnweFwEBYWJip79uwZxowZAyMjI/D5fDRv3hzBwcHV/kwMDAxgb2+PpKQksfKoqCh88803sLCwAJ/Ph7m5OaZPn478/HxRHV9fX2zYsEF0/WWvMkKhEKtXr0bz5s2hqqoKIyMjTJgwARkZGZXGdfHiRbx+/RoeHh7VvrYPcblcuLm5AUCl7bRLly4AIPG5AED37t1x8eJFpKen11hshBBCJFGPKiGEkHJlZWXh9evXYmX6+vq4du0aoqOj4eXlBTMzM6SkpGDjxo1wc3PD3bt3yx1aW1RUBE9PTxQWFmLKlCkwNjbGs2fPEBYWhszMTGhrawMA/P398fPPP2PIkCEYN24cXr16hXXr1qFr1664efOmxHDaqihLOvT09ACU9rKGhoZi8ODB+PHHH3H16lUEBATg3r17OHToEADg5cuX6NGjBwwMDDB79mzo6OggJSUFBw8eLPc8X3/9NRITE7Fr1y6sWrVK1FP34dBUAGjbti2sra2xd+9ejBo1Smzbnj170LBhQ3h6egIAXrx4gQ4dOoDD4WDy5MkwMDDAiRMnMHbsWGRnZ2PatGkyfyYlJSV4+vQpGjZsKFa+b98+5OXl4bvvvoOenh5iYmKwbt06PH36FPv27QNQ2vP477//4vTp09i+fbvEsSdMmICQkBCMHj0aP/zwA5KTk7F+/XrcvHkTly5dgrKycrlxRUdHg8PhwNnZWer2vLw8iXapra1d4TEByTZQnrJE9sPPBQDatGkDxhiio6Px1VdfVXgcQgghH4ERQgghH9i6dSsDIPXFGGN5eXkS+1y+fJkBYNu2bROVRUREMAAsIiKCMcbYzZs3GQC2b9++cs+dkpLCeDwe8/f3Fyu/ffs2U1JSkigvL/YzZ86wV69esSdPnrDdu3czPT09pqamxp4+fcri4uIYADZu3DixfWfOnMkAsHPnzjHGGDt06BADwK5du1bhOQGwBQsWiN4vX76cAWDJyckSdRs3bsxGjRolej9nzhymrKzM0tPTRWWFhYVMR0eHjRkzRlQ2duxYZmJiwl6/fi12PC8vL6atrS31d/LheXv06MFevXrFXr16xW7fvs18fHwYADZp0iSxutKOFRAQwDgcDnv8+LGobNKkSUzanxJRUVEMANu5c6dYeXh4uNTyD3l7ezM9PT2J8uTk5HLbZVkbY4yxUaNGsQYNGoiu9eHDh2zJkiWMw+Gwli1biuotWLCAAWAJCQns1atXLCUlhQUHBzM1NTVmYGDA3r59KxHDv//+ywCwZcuWVXgNhBBCPg71qBJCCCnXhg0bYGtrK1GupqYm+u/i4mJkZ2fDxsYGOjo6iI2NhY+Pj9TjlfWYnjx5Er1795ba83rw4EEIhUIMGTJErNfM2NgYTZs2RUREhNhKsOX5cNho48aNsXPnTjRq1Ei00u2MGTPE6vz444/4448/cOzYMbi7u4t6bsPCwuDk5FRpj111DB06FAEBATh48CDGjh0LADh16hQyMzMxdOhQAABjDAcOHMCQIUPAGBP7XDw9PbF7927ExsaiU6dOFZ7r1KlTEj27o0ePxvLly8XK3v/9vn37Fvn5+ejYsSMYY7h58yYsLCwqPM++ffugra2N7t27i8Xapk0baGhoICIiAsOHDy93/zdv3kjtzSzz7bff4ptvvhErc3JyEnv/9u1biWvt2LGj1N5fOzs7sfeOjo7YunWr1PZZFteHPbqEEEJqFiWqhBBCytWuXTupiynl5+cjICAAW7duxbNnz8AYE237cK7p+6ysrDBjxgysXLkSO3fuRJcuXdCvXz94e3uLktgHDx6AMYamTZtKPUZVk8WyJFtJSQlGRkaws7MTrbb7+PFjcLlc2NjYiO1jbGwMHR0dPH78GADg6uqKQYMG4ddff8WqVavg5uaGAQMGYPjw4TW2KJKTkxPs7e2xZ88eUaK6Z88e6Ovri+bVvnr1CpmZmdi8eTM2b94s9TgvX76s9Fzt27fHb7/9BoFAgPj4ePz222/IyMiAioqKWL3U1FT88ssvOHr0qMSc0op+v2UePHiArKwsGBoaVjvW99vUh5o2bVrp/FVVVVX873//A1C6gJWVlRXMzMyk1j1w4AC0tLTw6tUrrF27FsnJyWLJurS43p+PSwghpOZRokoIIURmU6ZMwdatWzFt2jS4uLhAW1sbHA4HXl5eEAqFFe67YsUK+Pr64siRIzh16hR++OEHBAQE4MqVKzAzM4NQKASHw8GJEyfA4/Ek9tfQ0KhSjOUl2e+rLNngcDjYv38/rly5gv/97384efIkxowZgxUrVuDKlStVjqUyQ4cOhb+/P16/fg1NTU0cPXoUw4YNEz3ypuwz9fb2lpjLWqZly5aVnkdfX1+U4Hl6esLe3h5fffUV1qxZI+pdFggE6N69O9LT0zFr1izY29ujQYMGePbsGXx9fSv9/ZbFa2hoiJ07d0rdLm2+7vv09PSqtOhSRXg8XpUXY+ratatoLnHfvn3h6OiIESNG4MaNGxKPEiqLq6w+IYSQ2kGJKiGEEJnt378fo0aNwooVK0RlBQUFyMzMrNL+jo6OcHR0xPz58xEdHY1OnTohMDAQv/32G5o0aQLGGKysrKQOO64JjRs3hlAoxIMHD+Dg4CAqf/HiBTIzM9G4cWOx+h06dECHDh3g7++Pv//+GyNGjMDu3bsxbtw4qceXtbdt6NCh+PXXX3HgwAEYGRkhOzsbXl5eou0GBgbQ1NSEQCCo0ZVw+/TpA1dXVyxZsgQTJkxAgwYNcPv2bSQmJiI0NBQjR44U1T19+rTE/uVdZ5MmTXDmzBl06tSp3J7Jitjb22Pnzp3IysoS9bTXFQ0NDSxYsACjR4/G3r17xX4PwH+rRr/fbgghhNQ8ejwNIYQQmfF4PImhmevWrYNAIKhwv+zsbJSUlIiVOTo6gsvlih4L8/XXX4PH4+HXX3+VOAdjDG/evPno+Hv37g0AWL16tVj5ypUrAZQmcEBp79mHMbRq1QoAJB5j874GDRoAQJUTdwcHBzg6OmLPnj3Ys2cPTExM0LVrV9F2Ho+HQYMG4cCBA4iPj5fY/9WrV1U6jzSzZs3CmzdvsGXLFtG5APGht4wxrFmzRmLf8q5zyJAhEAgEWLx4scQ+JSUllX4uLi4uYIzhxo0bslxKjRkxYgTMzMywbNkyiW03btwAh8OBi4uLHCIjhJD6g3pUCSGEyOyrr77C9u3boa2tjWbNmuHy5cs4c+ZMpY/9OHfuHCZPnoxvvvkGtra2KCkpwfbt20WJGFDaG/fbb79hzpw5SElJwYABA6CpqYnk5GQcOnQI3377LWbOnPlR8Ts5OWHUqFHYvHkzMjMz4erqipiYGISGhmLAgAFwd3cHAISGhuLPP//EwIED0aRJE+Tk5GDLli3Q0tISJbvStGnTBgAwb948eHl5QVlZGX379hUldtIMHToUv/zyC1RVVTF27FiJIadLly5FREQE2rdvj/Hjx6NZs2ZIT09HbGwszpw5U+3nevbq1QstWrTAypUrMWnSJNjb26NJkyaYOXMmnj17Bi0tLRw4cEDqUNyy6/zhhx/g6ekJHo8HLy8vuLq6YsKECQgICEBcXBx69OgBZWVlPHjwAPv27cOaNWswePDgcmPq3Lkz9PT0cObMGdE83bqkrKyMqVOnws/PD+Hh4ejZs6do2+nTp9GpU6dK2zohhJCPJIeVhgkhhCi4ske8lPdYloyMDDZ69Gimr6/PNDQ0mKenJ7t//77Eo1c+fDzNo0eP2JgxY1iTJk2Yqqoq09XVZe7u7uzMmTMS5zhw4ADr3Lkza9CgAWvQoAGzt7dnkyZNYgkJCR8Ve5ni4mL266+/MisrK6asrMzMzc3ZnDlzWEFBgahObGwsGzZsGLOwsGB8Pp8ZGhqyr776il2/fl3sWPjg8TSMMbZ48WLWqFEjxuVyxR5V8+FnVObBgweiR61cvHhRaswvXrxgkyZNYubm5kxZWZkZGxuzL7/8km3evLnCay07b58+faRuCwkJYQDY1q1bGWOM3b17l3l4eDANDQ2mr6/Pxv+/vbtHTSAIAzA82wgWYuUJtLCx8gAWnsViBS3FM+gNxHt4Dnu1tLHRWuGzCAbEoCGBOITnKWd/mPaF3fkGg1iv13f3RERcLpcYjUbRaDSiKIqHUTWLxSK63W5Uq9Wo1WrR6XRiMpnEfr9/ud/xeBytVutu7TaeZj6fP332Np7mldt4msPh8HDtdDpFvV6PXq/3uXY8HqNSqcRyuXz5bgB+p4h4cqweAMAb7Ha71G6302q1Sv1+/93bSSl9fCo+m83Sdrv90b+3AHyfUAUAslSWZdpsNl8e5PTXzudzajabaTqdpuFw+O7tAPx7QhUAAICsOPUXAACArAhVAAAAsiJUAQAAyIpQBQAAICtCFQAAgKwIVQAAALIiVAEAAMiKUAUAACArQhUAAICsCFUAAACycgUaKOqosIg78wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275941a6",
   "metadata": {},
   "source": [
    "### Ensemble prediction using voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "586c430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Ensemble ROC Curve by iterating through FPR values ---\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0000\n",
      "Soft Voting -> Achieved [TPR: 0.4067, FPR: 0.0000]\n",
      "Hard Voting -> Resulted in [TPR: 0.4200, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0204\n",
      "Soft Voting -> Achieved [TPR: 0.4900, FPR: 0.0133]\n",
      "Hard Voting -> Resulted in [TPR: 0.4767, FPR: 0.0067]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0408\n",
      "Soft Voting -> Achieved [TPR: 0.5167, FPR: 0.0400]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0612\n",
      "Soft Voting -> Achieved [TPR: 0.5333, FPR: 0.0600]\n",
      "Hard Voting -> Resulted in [TPR: 0.5300, FPR: 0.0600]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0816\n",
      "Soft Voting -> Achieved [TPR: 0.5467, FPR: 0.0667]\n",
      "Hard Voting -> Resulted in [TPR: 0.5433, FPR: 0.0700]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1020\n",
      "Soft Voting -> Achieved [TPR: 0.5533, FPR: 0.0933]\n",
      "Hard Voting -> Resulted in [TPR: 0.5467, FPR: 0.0833]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1224\n",
      "Soft Voting -> Achieved [TPR: 0.5767, FPR: 0.1200]\n",
      "Hard Voting -> Resulted in [TPR: 0.5500, FPR: 0.1133]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1429\n",
      "Soft Voting -> Achieved [TPR: 0.6033, FPR: 0.1333]\n",
      "Hard Voting -> Resulted in [TPR: 0.5933, FPR: 0.1367]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1633\n",
      "Soft Voting -> Achieved [TPR: 0.6367, FPR: 0.1600]\n",
      "Hard Voting -> Resulted in [TPR: 0.6467, FPR: 0.1600]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1837\n",
      "Soft Voting -> Achieved [TPR: 0.6600, FPR: 0.1800]\n",
      "Hard Voting -> Resulted in [TPR: 0.6333, FPR: 0.1600]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2041\n",
      "Soft Voting -> Achieved [TPR: 0.6733, FPR: 0.1967]\n",
      "Hard Voting -> Resulted in [TPR: 0.6567, FPR: 0.1833]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2245\n",
      "Soft Voting -> Achieved [TPR: 0.7067, FPR: 0.2233]\n",
      "Hard Voting -> Resulted in [TPR: 0.6933, FPR: 0.2133]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2449\n",
      "Soft Voting -> Achieved [TPR: 0.7433, FPR: 0.2433]\n",
      "Hard Voting -> Resulted in [TPR: 0.7167, FPR: 0.2300]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2653\n",
      "Soft Voting -> Achieved [TPR: 0.7567, FPR: 0.2633]\n",
      "Hard Voting -> Resulted in [TPR: 0.7467, FPR: 0.2567]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2857\n",
      "Soft Voting -> Achieved [TPR: 0.7900, FPR: 0.2833]\n",
      "Hard Voting -> Resulted in [TPR: 0.7767, FPR: 0.2800]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3061\n",
      "Soft Voting -> Achieved [TPR: 0.8100, FPR: 0.2967]\n",
      "Hard Voting -> Resulted in [TPR: 0.7767, FPR: 0.2833]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3265\n",
      "Soft Voting -> Achieved [TPR: 0.8100, FPR: 0.3100]\n",
      "Hard Voting -> Resulted in [TPR: 0.7867, FPR: 0.2900]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3469\n",
      "Soft Voting -> Achieved [TPR: 0.8367, FPR: 0.3467]\n",
      "Hard Voting -> Resulted in [TPR: 0.8133, FPR: 0.3300]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3673\n",
      "Soft Voting -> Achieved [TPR: 0.8433, FPR: 0.3600]\n",
      "Hard Voting -> Resulted in [TPR: 0.8400, FPR: 0.3633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3878\n",
      "Soft Voting -> Achieved [TPR: 0.8533, FPR: 0.3867]\n",
      "Hard Voting -> Resulted in [TPR: 0.8433, FPR: 0.3667]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4082\n",
      "Soft Voting -> Achieved [TPR: 0.8667, FPR: 0.4033]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4286\n",
      "Soft Voting -> Achieved [TPR: 0.8733, FPR: 0.4233]\n",
      "Hard Voting -> Resulted in [TPR: 0.8567, FPR: 0.4067]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4490\n",
      "Soft Voting -> Achieved [TPR: 0.8867, FPR: 0.4467]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4694\n",
      "Soft Voting -> Achieved [TPR: 0.9033, FPR: 0.4667]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4898\n",
      "Soft Voting -> Achieved [TPR: 0.9200, FPR: 0.4867]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5102\n",
      "Soft Voting -> Achieved [TPR: 0.9400, FPR: 0.5100]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5306\n",
      "Soft Voting -> Achieved [TPR: 0.9567, FPR: 0.5300]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5510\n",
      "Soft Voting -> Achieved [TPR: 0.9700, FPR: 0.5467]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5714\n",
      "Soft Voting -> Achieved [TPR: 0.9800, FPR: 0.5700]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5918\n",
      "Soft Voting -> Achieved [TPR: 0.9933, FPR: 0.5733]\n",
      "Hard Voting -> Resulted in [TPR: 0.9867, FPR: 0.5733]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6122\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6100]\n",
      "Hard Voting -> Resulted in [TPR: 0.9867, FPR: 0.5733]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6327\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6100]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.6300]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6531\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6100]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.6300]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6735\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6100]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.6300]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6939\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6100]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.6300]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.7143\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6100]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.6300]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.7347\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6100]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.6300]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.7551\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6233]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.6300]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.7755\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6233]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.6300]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.7959\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6133]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "\n",
      "--- Filtering curves to be monotonic ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Loop through all the FPR values to generate the ensemble ROC curve ---\n",
    "\n",
    "ensemble_results_soft = []\n",
    "ensemble_results_hard = []\n",
    "\n",
    "print(\"\\n--- Generating Ensemble ROC Curve by iterating through FPR values ---\")\n",
    "# We iterate from a low to high target_fpr to trace the curve\n",
    "for target_fpr in np.linspace(0.0, 1.0, 50): \n",
    "    # 1. Assign the function's output to a single variable first.\n",
    "    result_tuple = predict_ensemble_and_evaluate(\n",
    "        list_folds_best_models=list_folds_best_models,\n",
    "        test_loader=test_loader,\n",
    "        target_fpr=target_fpr\n",
    "    )\n",
    "    \n",
    "    if result_tuple is not None:\n",
    "        \n",
    "        for voting_method, metrics in result_tuple.items():\n",
    "            # Create a dictionary for each point and append it to the list\n",
    "            if voting_method == 'soft_voting':\n",
    "                point_dict = {'fpr': metrics['fpr'], 'tpr': metrics['tpr']}\n",
    "                ensemble_results_soft.append(point_dict)\n",
    "            else:\n",
    "                point_dict = {'fpr': metrics['fpr'], 'tpr': metrics['tpr']}\n",
    "                ensemble_results_hard.append(point_dict)\n",
    "            \n",
    "        \n",
    "# Ensure the curve starts at (0, 0)\n",
    "    if not ensemble_results_soft or ensemble_results_soft[0]['fpr'] > 0.0:\n",
    "        ensemble_results_soft.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if ensemble_results_soft[-1]['fpr'] < 1.0 or ensemble_results_soft[-1]['tpr'] < 1.0:\n",
    "        ensemble_results_soft.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    if not ensemble_results_hard or ensemble_results_hard[0]['fpr'] > 0.0:\n",
    "        ensemble_results_hard.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if ensemble_results_hard[-1]['fpr'] < 1.0 or ensemble_results_hard[-1]['tpr'] < 1.0:\n",
    "        ensemble_results_hard.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    # --- NEW: Post-process the lists to make them monotonic ---\n",
    "print(\"\\n--- Filtering curves to be monotonic ---\")\n",
    "ensemble_results_soft = make_curve_monotonic(ensemble_results_soft)\n",
    "ensemble_results_hard = make_curve_monotonic(ensemble_results_hard)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bae1a225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Plotting all ROC curves for comparison ---\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6oAAAOqCAYAAACVfKgeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOydd3wcxfn/37t7XdfUuy25SC4YV2xc6KYZ25hiME7onQRC4EfACQESkhiSQIAUCF9CDSGQ5AtfWiAYTDHdYINxt+UiS7bVddLp6u78/ljprJNOttziA+bNS8ianZ2d2Xt2bj47M8+jCCEEEolEIpFIJBKJRCKRpAnqoa6ARCKRSCQSiUQikUgk3ZFCVSKRSCQSiUQikUgkaYUUqhKJRCKRSCQSiUQiSSukUJVIJBKJRCKRSCQSSVohhapEIpFIJBKJRCKRSNIKKVQlEolEIpFIJBKJRJJWSKEqkUgkEolEIpFIJJK0QgpViUQikUgkEolEIpGkFVKoSiQSiUQikUgkEokkrZBCVSJJQVlZGYqiJP3Y7XZKSko4/fTTefnllw91FfeJrrZ8U/joo4+47LLLGDp0KG63m4yMDIYMGcKll17KBx98cKirlzYce+yxKIrC22+/fair0i9isRiPPfYYc+bMYcCAATidTlwuF4MGDeLss8/m6aefJhqNJp3zdWvjN4XNmzejKAplZWUH/Vp33HEHiqJwxx13HPRrASxbtgxN07j22muT0t9+++1e3w+KouB2uxk5ciTXXXcdmzdv3mP5QgieffZZzjzzTEpLS3E4HGRmZjJmzBh+9KMfsXXr1n7Vs7GxkYULF3LsscdSUFCAzWbD6/Vy2GGHcfnll/PWW28l5W9tbSU7O5tJkyYhhOj3/UjFvjyrkt3z+OOPoygKF1100aGuikRyyJFCVSLZDVOnTuXCCy/kwgsvZMaMGVgsFl588UVmzZrFDTfccKir960lGo1y6aWXMnnyZP7yl78ghODkk0/m1FNPRVVVHn30UaZOncoll1zyjR8k/bcH7webzz//nMrKSi655BJefPFFsrOzOe2005g5cyY5OTm88MILfPe736WiooKOjo5DXd204Jsg0rvE37HHHnuoq5Lg2muvxel08tOf/rTPPF3fDxdccAGTJk1i8+bN/P73v2fUqFF8+OGHfZ5XW1vLkUceybx583jhhRcoKChgzpw5HHXUUdTU1PCb3/yGiooK/vjHP+62jk899RRlZWX8+Mc/5qOPPqKiooKzzjqL448/nng8ziOPPMIJJ5zAOeeckzjH5/OxYMECPvnkE5588sm9vzGdyGdVIpEcdIREIunFwIEDBSAee+yxpPRYLCa+//3vC0AA4pNPPjk0FdxHVq9eLVavXn2oq7HfnHHGGQIQ2dnZ4qWXXup1/NVXXxW5ubkCEGeeeeYhqOF/j9tvv10A4vbbb+8zz5YtW8Tq1atFMBj871VsH/jss8+Ey+USgJg5c6aoqqrqlaeurk4sWLBA2Gw20dzcnEg/5phjBCAWL17836twmnAo2x6NRsXq1avFhg0b9qucxYsXC0Acc8wxfeapr68Xq1evFvX19ft1rf7wj3/8QwDipptu6nWsq66phlBbt24VQ4cOFYAYMWJEyrKbmprEoEGDBCDGjh0rvvrqq6TjsVhM/Pa3vxWapglA3H///SnLefDBBwUgFEURN998s2htbe2VZ+XKlWLu3LlizJgxSemhUEjk5uaKwsJCEQ6H+7wPfbE/z6pk97S0tIjVq1eL2traQ10VieSQI4WqRJKCvoSqEOYXvNfrFYD46U9/+t+v3Lechx9+WADCarWKTz/9tM98n3/+ubBarQIQjzzyyH+xhv9d+iNUvw5Eo9HE4H3OnDlC1/Xd5v/kk09ER0dH4m8pVL/ebe+PUP1vMmXKFAGINWvW9Dq2O6EqhBBPP/104vjGjRt7HZ8/f74ARHl5+W4F3B/+8IdEX7dq1aqkY6tXr070b/fee+8e2/POO+/0SvvBD34gAPHEE0/s8fzu7O+zKpFIJP1FClWJJAW7E6pCCDF+/HgBiCuuuCLl8UWLFokzzjhDFBQUCKvVKnJzc8WcOXPEBx980Oc1g8Gg+N3vfiemTp0q/H6/sNlsYsCAAWLmzJni6aefTnnOP/7xD3HyySeLnJwcYbVaRVFRkfjOd74jVq5cmTJ/z8FVc3OzcDgcQlVVsW3btj7rdtZZZwlA3HfffftVh02bNglADBw4UMTjcXHPPfeIMWPGiIyMjD4Hfd0xDEOUl5cLQFx77bV7zH/dddcJQAwaNEgYhpFI7z4oDgaDYsGCBWLw4MHCbreLwsJCcckll+z2fjQ1NYnbbrtNjB49WrjdbuF0OsVhhx0m7rzzzpSzlt3F5JYtW8Qll1wiSkpKhMViERdeeGEi37/+9S9x6aWXipEjRwq/3y/sdrsoKysTF198ccoBc9fnmeqne7l9CZkLL7wwYedVVVXiu9/9rsjPzxc2m00MGjRI/OQnP+lztqVr1mfkyJHCbreL3NxccfbZZ4uVK1eKxx57rFcd9sTjjz8uAGGz2cT27dv7fV6qNi5btkycccYZIjs7W9hsNjF8+HDx29/+NskGuqirqxP333+/OPXUU0VZWZlwOBzC4/GI8ePHi7vuukuEQqGU1+v+LD366KPiyCOPTLzA2rRpkxBCiM2bN4u77rpLHHfccaK0tFTYbDbh8/nE1KlTxUMPPbTbAX5TU5P42c9+JsaPHy+8Xq9wOByivLxczJ07V7z66qtCiGTBlOqnZ/91MOy2+zPdk3Xr1omLL75YlJWVCZvNJjIyMsSAAQPEjBkzxKOPPtrrs0v1073cPb2UWbt2rbj66qtFRUWFcDqdwuPxiOHDh4urr75arFixos973ZPPP/9cAOLII49MeXxPQnXFihWJ4z37/I0bNwpVVQUg/vWvf+22HoZhiNGjRwtAXHTRRUnHLrroIgGI0aNHp7Tr/rBs2TIBiIkTJ+7Vefv7rAphft8tXLhQjB07NmGLI0aMED/5yU9EU1NTr/zd7UzXdXH//feLUaNGCafTKQoKCsSVV14pGhsbhRBChMNh8fOf/1xUVlYKh8MhCgsLxXXXXSfa29t7ldvdpjZv3izOP/98UVBQIOx2uxg6dKi4/fbbU4rsaDQqnnrqKTF//nxRWVkpPB6PcDgcoqKiQlx77bWipqYmZbu791PvvvuumDlzpsjJyRGKoiSe1931n2+88YaYOXOmyMvLExaLRfj9fjFkyBDxne98J+XLiFgsJh588EExefJk4fV6hd1uF0OGDBHXXnttn99x3W37n//8p5g6darweDzC5XKJKVOmiFdeeSXleRLJwUAKVYkkBXsSql1Lu1LNqN54440CEKqqiokTJ4q5c+eKSZMmCUVRhKZpSQO0LrZu3SpGjBghAOFyucSJJ54o5s2bJ4466ijh8/l6DQJjsZg455xzBCDsdruYMmWKmDt3bmJQ43Q6xb///e9e10k1uDrvvPMEIBYuXJiyrQ0NDcJmswmbzSYaGhr2qw5dg40BAwaI2bNnC5vNJk444QRx3nnnicMPPzzl9buzfPnyRBt2N5vaxdKlSxP5v/zyy0R610Bz8uTJ4sgjjxQul0vMmDFDzJ07VxQWFgpAFBQUiHXr1vUqc+XKlaK0tFQAorCwUJxyyili1qxZIj8/XwBizJgxoqWlJemcrsHQ/PnzRVZWligoKBBnnXWWOPPMM8WNN96YyKdpmnC5XGLChAnizDPPFLNnz07MXGRkZIj3338/qdwLL7wwcb9Hjx4tLrzwwsTP//zP/yTy7Umo/uAHPxBer1cMHDhQnHPOOWL69OnC6XQmZkx6ouu6mDlzZmKwetJJJ4lzzz1XDBo0SLhcrsTy+L0Rql3LuWfNmtXvc7rT1cZbbrklIU7nzZsnjjnmmMQSyh/84Ae9znvqqacEIIqLi8Uxxxwj5s2bJ0444QThdrsTNpJKrHfZ1fe//32hqqqYNm2aOO+888SkSZPE5s2bhRBC3HnnnYmZsxNOOCFRH5vNlliWnkpkLF++XBQXFwtA+Hw+MWPGDHHuueeKyZMnC6fTmZh1XL16tbjwwgsTtnfyyScn2cB7772XKPNg2W1fQnXFihUJ4V5ZWSnOPPNMMXfuXDF58mThdrvF6NGjE3kXLlwoTj75ZAGI/Pz8pDZ0fz52J1SffvppYbfbE/3LWWedJc444wwxevRooSjKXq04uO222wQgbr311pTH9yRU33///T5nVO+77z4BCL/fL2Kx2B7r8tvf/laAuc2hy1YMwxDZ2dkCEPfcc0+/25WKri0Se7PMdH+f1cbGRjFmzBgBCK/XK2bPni3OOusskZOTk3heul72dNHdzs477zzhdDrFKaecIubMmSPy8vIEmMuo29vbxbRp0xLlzpw5U/h8PgGIU089tVddumzqggsuENnZ2SI/P1/MnTtXzJw5M/ECderUqb1eWFVXVyeezyOPPFLMnTtXzJgxQxQVFQlA5ObmivXr1/e6Xlc/dc011whVVcWIESPEvHnzxEknnST+9re/CSH6FqqPP/64UBRFKIoiJk2aJM4991wxe/ZsMW7cOKFpWq/+LRwOi+nTpwtAOBwOceqpp4pzzz030Q/k5OSIzz77rFcdu2z3tttuE4qiiKlTp4pzzz038V2jKIr43//933580hLJ/iOFqkSSgt0J1VWrViUGvj3FUtey1CFDhogvvvgi6dg777wjPB6PsNlsSQJI13UxYcIEAYiTTjpJ1NXVJZ0XCoV6vcH88Y9/LAAxadKkXnuD/vGPfwhN00RmZmavZWWpBldvvPGGAMSwYcNS3ov7779fAOKss87a7zp0DTYAUVJSItauXZvymn3xl7/8JSGO+jPIi8ViCVHQ/QVB94HmkCFDxJYtWxLHQqFQYga554xKR0eHGDx4cGIQG4lEEseCwWBC9F988cVJ53UNhgDx3e9+t89Zyr///e+93vobhiH++Mc/CkCMHDmyl7Dpz9LfPQlVQPzkJz8R8Xg8cWzFihWJgVrPWaEumygsLEya6Y3H44nlhHsrVLsGTz//+c/7fU6qNgLioYceSjr25ptvJl4UVVdXJx1btWqV+PDDD3uV19TUJE466SQBiF//+te9jnddy+v1pjxfCHPJY6qZvJqamsSg77nnnks61t7enrgXF1xwgWhra0s63tLSIt54442Ube9r6e/BtNu+hOrFF18sAPGLX/wiZX16zv70Z+lvX7a+dOlSYbVahaIo4oEHHug1U71582axdOnSPsvtybRp0wTQ58zRnoRqV984atSoXs/r+eefLwBx3HHH9asu77zzTuJaXf3sxo0bE2nvvvtuv9uVitmzZwtAPPXUU/0+Z3+f1XPPPTfx3dH95WdbW5s49dRTBSCmTJmSdE73747BgwcnXgYJYb5M7Xp5PGrUKDFx4sSkcquqqkRmZqYAxJIlS5LK7W7jp59+etLsaXV1taioqEi8AOtOIBAQ//d//5f0LAlhzrQuWLBAAGLGjBm92t69n/rjH/+Y8v70JVS7VhN1fwHVxc6dO8Xnn3+elHbzzTcn7ld34R+NRsWll16aeCnQsw1d9fP7/eKjjz5KOtZ1vyoqKlLWXSI50EihKpGkIJVQbWlpEa+//roYNmxYyrftuq4n3qb2NSj69a9/LYCkWYIXXnghMejvOShNRWNjo3A6ncLhcPS5dOeaa64RgPj973+flJ5qcGUYRqK9qZYmd735fvnll/e7Dt0HG08++eQe29qTu+66S4A529lfCgoKBCDuvvvuRFr3geYLL7zQ65ydO3cmHIV0n8Xscl4yc+bMlNdqa2tLLMnqvnyt68s9Kyur16xVf5k8ebIAei2pPhBCdfz48Sln9q666qqUA9KuWd4///nPvc6JRCKJ2cC9EaoOhyOlyOwvXW3sy3nWKaecstd2t3btWgGII444otexLvvZ18H666+/LgAxd+7cpPSuGbcxY8YkvTjYHXsSqgfTbvsSqjNmzBBAr8FzX+yPUJ0zZ46A/m0H6A9dL2hSOQjqXtfufalhGGLr1q3iN7/5jbDZbCIzMzOls70uO5w3b16/6rJmzZrEtT7++GMhhBAfffRRIi3VloC9oUtU/fCHP+z3OfvzrG7ZskWoqioURen1MlcIIbZt25Yov3vf2/27I9ULhHvvvVeAOduX6uXQtddeKwDxs5/9LCm9y6acTmfKZcwvvfRS4oVUX9sAUlFUVCRUVRWBQCApvetZPf744/s8ty+h6nK5hM/n69f1Q6FQYlXIiy++2Ot4MBhMrKboubWo6z4/8MADvc4Lh8OJGeqtW7f2qy4Syf4gw9NIJLvh4osvTsTI8/v9nHzyyaxfv56//vWv3HnnnUl5ly1bRm1tLYMHD2b8+PEpy+sKvdA9xudrr70GwPz583G73Xus0+LFiwmFQkydOpXi4uJ+X6cvFEXhwgsvBMz4bd1Zvnw5y5cvp7CwkFNOOeWA1uGss87aY90OBGI3cQL9fj+zZ8/ulZ6Xl5dob/eQH6+88goA5557bsry3G43EyZMIB6P8+mnn/Y6Pn36dHw+327ru2HDBv7whz9w/fXXc+mll3LRRRdx0UUXsXPnTgDWrl272/P3hZkzZ6aMrzt8+HAAampqEmnbtm2jqqoKMG22JzabjbPPPvuA17G/zJo1K2V6qrZ0oes6b775JnfeeSfXXHMNF198MRdddBG//OUvgd3f8z21NRKJ8NJLL3Hbbbdx1VVXJcr+85//nLLsrv7g0ksvRdO03ZbdX/4bdtuTiRMnAnD11Vfz+uuvEw6H97LW/UPXdd544w0Arrjiiv0uLxgMEgwGAcjOzt5j/q7vB1VVGTBgADfddBOlpaV8+eWXHHHEEftdn931XweCrjZ29S8Hm3fffRfDMBg7diyHH354r+PFxcWcfPLJgPk90xOLxcJJJ53UK33o0KEADBgwgMMOO6zP47W1tSnrddJJJ1FQUNArfebMmWRnZxMIBPj88897Hf/iiy+49957ufbaa7nkkksS/XU8HscwDDZs2JDyevvSR06cOJHW1lYuuOACPvvsMwzD6DPv0qVLaW9vJysrK2Wf6HK5mDdvHpD6PkPqvtRutzNo0CAgdV8qkRxoLIe6AhJJOjN16lSGDBkCQH19Pe+99x5tbW1cffXVDB06NDEYAxKD940bN6Yc9Henvr4+8e8tW7YAMGzYsH7Vqes6b7755l5dZ3dcfPHF3HnnnTz77LPcd999OJ1OAB577DEALrjggqRB8/7WIS8vD5fL1a+6dScnJweApqYm4vE4Fsvuu7B4PE5TUxMAubm5vY6XlZX1Wf/y8nLAFGZddLX7/PPP5/zzz9/ttVO1u6ysrM/8uq7z/e9/nz//+c+7HZwGAoHdXndfGDBgQMp0r9cLkCQyuu5HTk5Ony9WdtfOvsjNzaW6upq6urq9Prc7e9MWgPXr13PGGWewcuXKPsvc3T3fXVs/+ugjzj33XLZu3drvsve2P+gPB9Nu++Kmm25iyZIlLFq0iFNOOQWr1cro0aM5+uijmTdv3gERcQCNjY0JYVlZWbnf5bW2tib+7fF49pi/6yVfLBZj48aNfPzxx2zcuJH58+ezaNEibDZbUv6uPqy/wrD789DVh3Xvy+rq6var3V3PRXNzc7/P2Z9ntUvcdPWvqRg8eHBS3u4UFham7Pe7+qK+nv+uz7KvFya7q09ZWRmNjY1J3wXBYJDzzz+f559/vs/zoO++Y1+eqT/96U/MnDmTp556iqeeegqPx8MRRxzB8ccfz/nnn5/U9v29z7D3falEcjCQQlUi2Q2XXXYZF110UeLv1tZWzjjjDBYvXsw555zDqlWrEoKr6+1mQUFB4o1wX3QNVvaFrusMGTKEqVOn7jZvfwe7ZWVlHHfccbz11ls8//zzzJ8/n1gsxt/+9jfAFLIHsg5dQnhv6ZqpjkajLFu2bI+D3eXLlxOLxZLO3Vu6i8audp9yyink5+fv9ryBAwf2Sttdu++//34eeughCgoKuPfee5kyZQr5+fk4HA7AnL185plnDsoMi6ru/eKa3b2g2NPLi1SMHz+e6urqlDN6e8PetuXss89m5cqVzJw5kx/96EeMGDECr9eL1WolGo1it9t3e35fn2lHRwdz5sxh586dXHzxxVx99dUMGTIEr9eLpmmsW7eOysrKgz5jBgfXbvvC5XLxxhtv8Omnn/Laa6/xwQcf8MEHH7B06VLuvfderrnmGv74xz/udbkHG7/fn/h3W1tbYlDeFz1Xobz//vuceuqpvPfee9x66638+te/Tjo+fvx4/vrXv/L555/362XbJ598Apgzn13ipqysjKysLJqamvj000856qij+te4FHQJ88zMzH6fc6Ce1X1hT8/3vvRl/aX7s7pgwQKef/55hg0bxl133cURRxxBTk5O4sXElClT+PDDD/t8vvflmRo+fDhr167lP//5D2+99RYffPAB7733Hm+99RY///nP+ctf/sJ3v/vdfWtcCg7mvZRI+osUqhLJXuDz+Xj22WcZNmwYW7Zs4d577+XWW28FoLS0FDAHFD0HL7uj663lmjVr+pW/6zqVlZV7dZ09cfHFF/PWW2/x2GOPMX/+fF566SUaGhqYMmVKrzf2B6sOe2L06NGUlZWxefNmnnzyyT0K1SeffBIwB3ajRo3qdXzz5s19ntt1rKSkJJFWWlrKmjVruPTSSw/48tbnnnsOgD//+c8plyOvX7/+gF5vX+la6l1fX08wGCQjI6NXnt3d1744/fTTeeGFF3j99dfZuXPnHgXVgWDNmjV8+eWX5OXl8fzzz/cSDftzz99991127tzJuHHjePTRR3sd76vsAQMGsHr1atasWcP06dP3+frdOZh2uyeOOOKIxHMaj8d54YUXuOCCC/jTn/7E2WefzXHHHbdf5WdnZ+Nyuejo6GDt2rUpl33uDS6Xi4yMDILBII2NjXsUqj2ZOnUqv/vd77jsssu4//77ueqqqxJLJcFcTnnjjTfS2trK//3f/+12C4QQgqeeegpIXp6vqiqzZs3iiSee4Mknn+SGG27Yh5aaNDY2AuzV87Y/z2pX/9E1y5+KrmN9bSs5GGzatKnPY6m+C7r662effTblEuaD1V9bLBZmzJjBjBkzAHPG9t577+VnP/sZV155JWeccQYZGRmJe7e7dh2K+yyR7C3ydYlEspfk5uYmxOlvf/tbWlpaABJvVFetWrXbZYQ96doL+cwzzySWsO2OE044AZvNxttvv73fyyS7c9ZZZ+Hz+Xjrrbeorq5OLPvtOZt6MOuwJxRF4ZZbbgFMQbd06dI+8y5btoyHHnoIMN9+p5rla2lp4aWXXuqVXl9fn9gr2LXXFuDUU08Fdg1SDiRdS5RTzWitXLmS5cuXpzyv6w1+PB4/4HVKRWlpaWJm55lnnul1PBqN8q9//Wuvy/3Od75DWVkZ0WiUq6++erf7rwA+++wzQqHQXl+nO133vKioKOXM1l//+tf9Lruv5XN9ld3VHzz66KPout6va+3JBg6m3e4NFouFs88+O7HipLtN76sda5rGiSeeCMD//M//HJB6jhs3DoBVq1bt0/mXXHIJY8aMIRqN8rOf/Szp2ODBgznnnHMAc3l01/dHKv70pz/x5ZdfYrFYuOmmm5KO3XzzzVitVr744gvuu+++PdbpvffeS5n+1VdfAXu34mR/ntWjjz4aVVVZvnw5X3zxRa+827dvT/S9+/sSY2/4z3/+k/K77NVXX6WxsRGPx5N0j3bXX7/++us0NDQcvMp2w+v1cscdd+D3++no6GDdunUATJgwAbfbTVNTEy+++GKv80KhEH//+9+B/+59lkj2FilUJZJ94JprrmHAgAG0trZyzz33AGC1Wrn99tsRQnDGGWewZMmSXufpus5bb73FRx99lEibPXs2Y8eOpba2lrlz5ybecHcRDof597//nfg7Pz+fa6+9lmAwyKxZs1ixYkWv60QiEV588cV+z9KCuRRp3rx5GIbB3XffzWuvvYbL5UrpgOVg1aE/XHHFFcyePZtYLMYpp5zCyy+/3CvPa6+9xsknn0wsFmP27NlcfvnlfZZ34403Ju09ikQifO973yMYDDJx4sSkpc1XXHEFAwcO5B//+Ac333wzbW1tvcrbsWPHPg2Yu5z9/PGPf0wa+G3fvp0LLrigzwF811v+vXk5sr9cd911ANx+++2JgRGYS0wXLFhAdXX1XpdptVp57rnncDgcPP/888yZMyflbEBTUxM//elPmTp1KpFIZN8bAVRUVKBpGitWrEhymgXw0ksv8bvf/W6fy+76PN98881egufhhx/m2WefTXneZZddRklJCcuWLePyyy/v9fIqEAiwaNGipLQ92cDBtNu++NOf/pTSCdWOHTsSL5i6D/K72rB+/frEcv3+8pOf/ASLxcIf/vAH/vSnP/VabrllyxY+++yzfpfXNXD/8MMP96oeXSiKwq9+9SsAnn766aRnBMxnvKysjE2bNnH88cf3+tzi8Tj33nsvP/jBDwC4++67GTlyZFKe4cOHc++99wJwww038OMf/zjl57pu3TrOO++8xDPbk642Hn/88f1u3/48qwMGDGDu3LkIIbjyyiuTvu+CwSBXXHEF4XCYKVOmMGXKlH7XaX8JhUJcffXVSS+/amtrufHGGwG46qqrEtswYNfz/fvf/z6pnLVr13LVVVcd8Pp1dHRw7733ptxD/t5779HS0oKmaYnnyOFw8L3vfQ8wv+O69r6DuZ/6Bz/4ATt27KC8vPyQOr+TSPbIoXE2LJGkN7uLo9rFo48+KgDh8XhEY2NjIv2mm25KuHcfOXKkOP3008W8efPEscceK/x+vwDEgw8+mFTW5s2bRWVlpQCEy+USJ510kjjvvPPE0UcfLXw+X6/QD7FYTMyfP18AQlVVMXbsWHHWWWeJc889V0ydOjURXuHf//530nld9eqL7mEP6Izj2Bf7Uoe+QlnsLeFwOCkG6JAhQ8RZZ50lzj777EQ8PUCcf/75KWM/doWXmDx5spg0aZJwuVxi5syZ4pxzzkmEGMrLy0sZ+uGrr74SZWVliThzRx99tJg/f76YM2eOGDFihFAUReTn5yed058QMh999FEi5uuQIUPEOeecI0455RThdDrFyJEjxRlnnJHSJnfs2JEUmP6iiy4Sl156aVLc2D2Fp+nLzvsKkxCPxxPxDu12uzjllFPEvHnzxODBg4XT6UyEJrr88sv7bG9ffPLJJ4nnT1EUMW7cOHH22WeLc845R0yaNCkRw3jQoEFJMQ/3FKKlr8+gK+6rqqrimGOOEeedd54YN26coDMEVV/PzJ6eJSGEOP300wWYcX9POukkMW/ePDFs2DChKIr4yU9+0uez8PnnnyfCKvn9fnHaaaeJc889V0yZMkU4nc5eIVxefvnlxHVmzpwpLrnkEnHppZcmhfc4WHbb1zPdFSe2vLxczJo1S3znO98RJ510knA6nYnwHD1jIXfFk66srBTf+c53xKWXXipuvvnmftXniSeeEFarNVGXs88+W5x55plizJgxQlGU3bahJ59//rkAxMSJE1Me31Mc1S6OPvpoAYj58+f3OrZt27ZEexVFEUcccYSYN2+emD17tsjNzU18nvfdd99ur/Hoo48mnn+HwyGOPvpocd5554kzzjhDDB8+PFHPVOFw9tTOPbGvz2pDQ0PCPnw+n5gzZ444++yzE+0uLy9PivspxJ6/O/YU3qivvqzLpi644AKRlZUlCgoKxNy5c8WsWbMS93Xy5MlJ9RdCiH/9619CURQBZuzWefPmieOPP15YrVZx/PHHiylTpqTsj/bUT/VV1+bm5kQ/NXr0aHH22WeL8847T0yePDlRj9tuuy2pnHA4LE444YRE+J0ZM2aIc889VwwYMEAAIjs7O2UovT3Zdn/aIJEcKKRQlUhS0B+hGo/HxYgRIwT0Dgb+/vvvi+985zti4MCBwm63C4/HIyoqKsScOXPEI488khSrsIu2tjZx9913iyOOOEJ4PB5ht9vFwIEDxezZs8Xf//73lHV49dVXxZlnnimKi4uF1WoVfr9fDB8+XMybN0/87W9/E8FgMCl/fwZXI0eOTOTrzxfR3tThQAnVLt5//31x8cUXi8GDBwuXyyWcTqcYNGiQuOiii3oFdu9O90FNe3u7uOmmm0R5ebmw2WwiPz9fXHTRRbuNERcIBMSvf/1rMXnyZOH3+4XVahWFhYXiiCOOEDfddFOveLT9GfALIcSXX34pZs+eLQoLC4XD4RBDhw4VP/rRj0QgENitqHz33XfF9OnTRWZmplBVtdcg50ALVSHMoPG//vWvxYgRI4Tdbhc5OTnijDPOECtWrBA///nPBSAWLFiw2/b2RSQSEY888oiYNWuWKC4uFna7XTgcDlFeXi7OPvts8cwzz4hoNJp0zr4KVcMwxF/+8hcxfvx44Xa7hc/nE9OmTUs8c/sjVKPRqPjNb34jRo0aJVwul8jKyhInnXSS+M9//rPHZ6G+vl7ceuutYtSoUSIjIyNh2+eee6547bXXeuX/n//5HzFu3LhE/N9Un+vBsNu+2vHyyy+Lq6++WowdO1bk5uYKm80mSkpKxLHHHiueeOKJXp+fEGaMzfnz54vCwkJhsVh6lbun+qxcuVJceumlory8XNjtduHz+cSIESPE97///V7xh/dEl9BYtWpVr2P9FaoffPBBQlykKkfXdfHMM8+I008/XRQVFQmbzSa8Xq8YNWqUuPHGG3uJtb6or68Xv/jFL8RRRx0lcnNzhcViEW63Wxx22GHiiiuuEO+8807K86677joBiCeeeKJf10nFvjyrQphxPBcuXCjGjBkjXC6XcDgcYvjw4eLHP/5xyu/Hgy1Ub7/9dlFVVSXOO+88kZ+fL2w2mxgyZIi47bbben2PdvHuu++KE044QeTk5AiXyyUOO+ww8ctf/lJEIpE++6N9FaqxWEw89NBD4rzzzhPDhg0TPp9POJ1OMXjwYHHWWWeJN998M2VZsVhM/OlPfxJHHnmk8Hg8wmazicGDB4trr722zxjoUqhK0glFiP+Cy0GJRCJJI95++22OO+44jjnmmF5LPiX7z/HHH8/ixYv517/+xZlnnnmoqyOR7DX//Oc/mTt3LjfccENie8c3iXA4TGlpKVarlU2bNu3Ru/U3lTvuuIOf/exn3H777dxxxx2HujoSiaQHco+qRCKRSPaa5cuXE41Gk9Ki0Sh33HEHixcvJi8vL+GZUiL5unH22WczdepU/vznP/c75unXid///vc0NDSwcOHCb61IlUgk6Y8MTyORSCSSveb6669n+fLljB49msLCQpqbm1mxYgXbt2/H4XDwxBNPJDkfkUi+bvz+979nwoQJ3HnnnfzhD3841NU5YLS2tnLXXXcxceJELrjggkNdHYlEIukTKVQlEolEstdcfvnlPP3003z55Zd88sknCCEoKirikksu4cYbb2TEiBGHuooSyX4xduzYfocI+jrh8/l6eZeXSCSSdETuUZVIJBKJRCKRSCQSSVoh96hKJBKJRCKRSCQSiSStkEJVIpFIJBKJRCKRSCRpxbd+j6phGNTW1uLxeFAU5VBXRyKRSCQSiUQikUi+VgghaGtro6ioCFU9MHOh33qhWltbS2lp6aGuhkQikUgkEolEIpF8ramurqakpOSAlPWtF6oejwcwb6rX602ZR9d1tmzZwsCBA9E07b9ZPYmkX0gblaQz0j4l6Y60UUm6I21Uku40NzdTVlaW0FYHgm+9UO1a7uv1encrVLvyyM5Bko5IG5WkM9I+JemOtFFJuiNtVJLudNnogdxKKZ0pSSQSiUQikUgkEokkrZBCVSKRSCQSiUQikUgkaYUUqv1AURRKS0ulV2BJ2iJtVJLOSPuUpDvSRiXpjrRRSbpzMGzzW79HtT+oqkp2dvahroZE0ifSRiXpjLRPSbojbVSS7kgblaQ7ByokTVKZB7zEbyC6rrNmzZrEJmGJJN2QNipJZ6R9StIdaaOSdEfaqCTdORi2KYVqPwmHw4e6ChLJbpE2KklnpH1K0h1po5J0R9qo5NuGFKoSiUQikUgkEolEIkkrpFCVSCQSiUQikUgkEklaIYVqP1BVlUGDBh2UTcISyYFA2qgknZH2KUl3pI1K0h1po5J052DYpvT62w8URcHr9R7qakgkfSJtVJLOSPuUpDvSRiXpjrRRSbpzMMLTyNcy/UDXdVasWCE9rUnSFmmjknRG2qck3ZE2Kkl3pI1K0h3p9fcQIjsGSbojbVSSzkj7lKQ70kYl6Y60Ucm3DSlUJRKJRCKRSCQSiUSSVkihKpFIJBKJRCKRSCSStEIRQohDXYlDSSAQwOfz0dra2ucmdSEE4XAYh8NxUDYKSyT7i7RRSToj7VOS7kgblaQ70kYl6U5rayt+v3+3mmpvkTOq/cRmsx3qKkgku0XaqCSdkfYpSXekjUrSHWmjkm8bUqj2A8MwWLFiBYZhHOqqSCQpkTYqSWekfUrSHWmjknRH2qgk3TkYtimFqkQikUgkEolEIpFI0gopVCUSiUQikUgkEolEklZIoSqRSCQSiUQikUgkkrRCev3tp9dfwzBQVVV6WpOkJdJGJemMtE9JuiNtVJLuSBuVpDvS6+8hJBqNHuoqSCS7RdqoJJ2R9ilJd6SNStIdaaOSbxtSqPYDwzBYu3at9LQmSVukjUrSGWmfknRH2qgk3ZE2Kkl3pNdfiUQikUgkEolEIpF845FCVSKRSCQSiUQikUgkaYUUqv1E07RDXQWJZLdIG5WkM9I+JemOtFFJuiNtVPJtQ3r97YfXX4lEIpFIJBKJRCKRpOZgaCo5o9oPhBAEAgG+5ZpeksZIG5WkM9I+JemOtFFJuiNtVJLuHAzblEK1HxiGQVVVlfS0JklbpI1K0hlpn5J0R9qoJN2RNipJd6TXX4lEIpFIJBKJRCKRfOOxHOoKSCQSiUQi2QtiAQisAz0MmgO8FWDtez9QIBJgXeM6wvEwDouDiuwKvHYz/+r61Ty38jlaI6347D7OGXkOw3OH7/acvaWvsvpKr6+vZ+kXS+kId+ByuJgwegK5ubl7bAuBAKxbR7CxkS2trbSWlGD1+6koKcEbCMBbbxFqb2e7203D8cejlpRQAeypVQFg89+epODuu7EGWrFqFpT588mYfSaBigrWeb2EAQeY5W3bBm+9Be3t4HbD8cfzeP0i7nr/LoLRIE5bBudNvYUTx16065x9urMSiUSSHmRdp9DsA249sOVKZ0r92Pir6zrr169n6NCh0uOaJC2RNipJZ6R9HiA6aqD2FdixCMJ1YMRBtYAjDwqmQ9Fp4CpOZK8J1PDK+ldYVLWIumAdcSOORbWQl5FHviuf96vfZ03jGqJ6FIFAQcGqWilwF1DiK0FTtKRzpg+azmlDT6PYW7ybSu6ir+t7bB58Dh+t4Vbaom2JdIfhQK1T2Vm/k6AeREdHQyNLzWJC8QRyhufwVfCrXm2ZnjWB09YJMl9dQkt1NQHDIGS10pSdTU1pKUM3bmTEqlXYIxEMIdBVlQ6Ph2XHHMPi669n8IQJnKLrdPSw0Rqg+rrvMfbBh7HF473aZwC1Q4fw9/93E++fdhp527fznfvuY/w77+Bsa0MzDK44LsRfDo9jaIDSswSV/HGXcvSsh5kOnAb0785Kvo3IflSSjii3KGAnqX9rveHAOVOSQlV6/ZVIJBJJutOyElYuhGAV2DJNcapYQcRM0RptgYxyGLkA/CNZWbeShUsWUtVcRaYjk7yMPKyqlZgR4+NtH7O2cS0GBhbVglNzoigKcSNOKB5CIFAVlSMKj+Dw/MOJGTHqgnW0hFsozyxnwbQFjMwbudvq9nX9uo46Pq35lLZoGx67h4lFE8l15bJtxzY+2voRHUoHTt1JZbwSHz7iRpwao4YaRw2KpjAyfyTDSoYl2lK3s4qWTasobdA5e8sAHBllaIA7GqVk40aKN21CNQwCHg9NWVlYNA2HELhaW7GGw7RmZ/O7++6j5vTTWQB0tWolED7+OMYtfnuPH03Q62XbmDHkbdiAIxAg7HQS8fmYc2I1n+RFkjP3EqvgK57MyMs+oByS6iCRSCTpjHKrknJt7oEUqmm1R/Xdd99l1qxZFBUVoSgKL7zwwh7Pefvttxk3bhx2u50hQ4bw+OOPH/B6GYZBY2Oj3MAuSVukjUrSGWmf+0lHjSlSO7aCbwS4SkC1gaKYv10l4BtuHl+5kJqdS1m4ZCFbW7cyImcEJd4SbJoNRVHY0baD9U3rTTGKioKCoiqgQMyIoSoqFsWCIQw+2/EZ1W3V2DQbJd4ShucMZ2vrVhYuWUhNoKbP6tYEalJevyPWwcq6lRjCoNBdiCEMvqr/iu1N21m2ZRmGYZAtssECW21biSgRdE0n4Apg0Sygw+btm+lo70BRFGyRGCVra6moh1V++MPIJsJakAzDwNXWRkF1NYoQxCwWLLqOKgTxzhnVYHY2LYWFeJua+H/XX4/900+5Ixym2jCoAdb88Lp+iVSAjECAoUuW4K2roz0vj3B2NjceUddbpAKkmBporfmQ+peuYCuwEHMmVyLpiexHJemEcktqkXqgSas9qsFgkNGjR3PJJZdw5pln7jH/pk2bOO2007jqqqt4+umnefPNN7nssssoLCzk5JNPPmD1EkJQXV2N3+8/YGVKJAcSaaOSdEba535S+4o5k+obAUofS/4Uzdyr2rqaVz6/n6rmKkbkjEBTk/N/tv0z4iKORbGgKiq60InpMQAMYaAqKoqiYBXmjOXntZ8zwDsAAE3VqMiqYHXDal7d8CqXj7s8ZVVeWf9Kyutvbd1KIBog05GJoij47D5awi180fIFHaIDj+pBQSHDyCCoBqnX6gHoUDtwG25Qoc1oY331eo7wHQFbt0IgQNDhIj+mst3aysfeOmY1DqR40yas0SghpxNDVbFFo7iDQVp8PmKGgV1VQVVpLSjAv307lzzwANc8+CD/ttkAuOCPD+7VR6QaBlGrFXtHB7rVyt+HBPrOLOg1s7r+878wdcYfWAO8CFwK5lJszQqxGPRY/BbTY4hUqrcnigJWa3LS17XceBx6iLS4EccQ/RRunZ9tUpJmS1mubujoQt+/cnXd/NnXcq1W8350navrbN26Fb/H0yurIQziRu/l6f0pF8CiWlAF5r3Y13ItFlCT578sqgUVxbSJbgghiBnJaX2iaeZP9yRFQ1PUXuUCRPXo/pWrahDtXUa/y1VV8150T1JULKolZbn9fjZSlHtIn2X7nos+EKSVUD311FM59dRT+53/oYceory8nHvuuQeA4cOHs2TJEn73u98dUKEqkUgkEskhIRYw96TaMvsWqV0oGgE1g0Ub3ybTM7KXSG0ONdMUbkJFRe0cUCooplBVQFEUlM4BrKIoqKg0hhppDbfic/gAU6z6HX7e2PgG80bOw2NPHjQHIgEWVS0i05GZdP2oHmVb2zbsmj3pGpqiURerw4ULpVO9KShYhIV6tT4hmhUU3BGDygZwVW+iQM+lZVs1HVYbQVXBaoBHt7LUW88p27PwNzaiqypGZzsNVcXZ0UGbx0NcUbAJYdZDVYk5HAx7+23Ktm3j1YoKJv31Keyxfg7Ou2GNRrHu3Mm/cncg9rReref4UTF48q5crI4MlgM/By4afSELpy+E2bPhiy+Sss87sZkP8/sxcHY6occSvJkVM3l41sNwySXw5ptJx75/VCsvDQzvuVy7HXq8eJpcOpl/nfMvuOkmeO65pGO3TwzweEVoz+VarZCVlZQ0NHso71z0DixcCA8mv0C4//B27jk8uOdyNQ1ycpKSspxZfHXNV/Dww/CLXyQde6qigx9PbNtzuYoCeXm9kmtvrIV//hN++MOk9FcHhrnyqNY9lwtmuT0E5dPTnobFi+Hii5PSP8qPcvaJzf0rNyenl0BbfOFiKreFYMaMpPQNvjjHzmrsX7lZWb0Ezz/P+SdTKIVJk5LSm+wGo+bW969cv9+0t248NPMhZpdOhyFDemUv++7O/pXr84HDkZT0y+N/ycVjL4bhwyGUbK/jz66n0dGPlyIeD7hcSUk3Tr6RG6fcCNOmwbZtScdOnNXIOl8/+puMDNM5WzcuPER9xLO5HZD8OB000kqo7i0ffvgh06dPT0o7+eSTuf766/s8JxKJEInsWo4TCJhvPXVdR+9886UoCqqqYhgGQgh0XUcIgWEYaJqWyNdFV/6e6apqvplOlQ694w31la5pWuL6PdO76rin9J5t2lPdZZu+fm3qstVvUpt61lG26evZpi777G6jX/c27a7uB7RNrWtQOrYjbJnQthEl1ooSCyBiARDdBzemzFsViLKjtZ2i5hBBZQWOjDghNc7KUIj1oTB65zVinbMDiSuKrlJ2ITr/99Lq58joNrA1hCAiBEdWvUiGZkkqIKjrbI3GsCsKn3YbZMeEIKjrqHTeZwGWuMDQVeIWQSyu0NY5w6IKA6uhE7Sb7RvQZGX65gDHbdHJ6RBoBljefgNFFXxRYmVxRS6tDkFmHGrtQZoDVWixGBGbzZy87Fzua43HyWiLELW5iBEnagfV0BGair++nhuvvAyhqExa8gH7ROe9/fW0fTkXjHgAJa6iKxrRaButH93PlqV/Ia+qBWt7su2JuJFyGXGvYqNBjPbkAXf78qfYsvIFsr8K4GhPnpEyYv0sNxbCaE9e2tyx9mW23JVH5qftuHocM6L9LDcewWhPFhrhYANb7srD924Qd3uyiDYioteMT0p0A71HubFgHVvuysP9YQhfe0dy9v6WK+hVLsCWu/JwfRkmsz1ZROuhfpYL6MG6Xmn+t+bSsDFOdnuyiI5796LcjvpeArjm4cl4dkBee7KIjlv7X64RakREksvd8dRpbAuoFLS3JJcb34tyw82IWHK5df88n626jaL2pt4n9HOG3Qi3IOLJ5Ta8+gO2vH4zRS2NKD0ma4XRPxs2wgGEkfz5NL91O1vevZuC7c1o7cn1E3o/n41IOwbJ9nSo+ojWzD2Xe6D4WgvVHTt2kJ+fn5SWn59PIBAgFArhdDp7nbNw4UJ+9rOf9UpfuXIl7s43FVlZWQwYMIBt27bR1NSEEIK2tjbq6+spKipi8+bNtLXtMsLS0lKys7NZv3494fCuTnTQoEF4vV5WrVqVNMCprKzEZrOxYsWKpDqMGjWKaDTK2rVrE2mapjFq1Cja2tqoqqpKpDscDoYNG0ZzczPV1dWJdI/Hw+DBg6mrq2PHjh2J9J5t6qKgoICCggLZpq95mzZs2EBbWxsrV65EUZRvRJu+iZ/Tt7VNQgicTieGYbBq1aqvTZtUvR17dAslhTlkeLJZUx0jxq7vlQP+OW3diiXegD26FX9oC7k7NxNvWormrsKw2cGioioq73bEub+hg1ZD4FXh2kwH02wu1oYG8aR9EFus79LUUUrGtjBGLEiju5X2bI24xQFxc0CSYvVpEt3HN3Gri5jdjRZpBT1mim1FpS1zKLonHyUWxta0Di3aRkRzErfaUO1uFGGghVtR9CiGMBehqTpkRAXOKGgCIqpB2AIZ8QhWQ8diGFgNAwVB1AbDGuCWJTrFbdDo1NjkU4lpBv6YwpAWwbQNBmWNrfxzTAbbfCq6AlFMu+uaTVWEgiWuYI2CrxksRj2KiKKKKEIxEIq5dHf08i8JZmSg7qePyfbeK0H7jSIARen0wQyqYtZld5/V7gtMfRFVEShK78P9vk6KjF31VRSx7/Xt41J91Xd/URWBuj/3YTflKvtdTu+n1Cy39/3dm+so9NYvqrKrzvtabsprHaT7q3TZ8H6W0xMV0edn199rKUqKBRPKwXmW07qPOEB8rYXqvrBgwQJuuOGGxN+BQIDS0lJGjhyZ8FDVtSyppKSE4uJdzuK70svKypLK7EofOnRoUnrXW/URI0akTB81alSvdIfD0SsdzIFYqvTMzMyU+77y8vIScedkm775baqsrKSysvIb1aZv4uck2/Q1aVOxC2X7O7BjEUqkDtbpoFoYbsuFgumIwlPBVbx/bdIj0L4R2lfDqpfICqwjq309bG+CT1thWQBa41jz4nBCDDWscL/Lyp2RAE09ZgxeDAaxWFTsk2ciyo4i/HY1DCxHrVRwNrZhbw0Tz3Sh6uuhfgUoGoqiomIOeg3DAAXTuVLnPTAAA4EwdCxZQ7EXjMWBIMuIo+sxtgW24Tv+V9hyx6JE4tg7wjhaQ4SbvkL58lcIVylgQQnH8Ne1YKvfxvaMLfhDcSzCDIYjFAWBAULHYoA7br65F4CuqBS1GfzwIyhsgyo/GJqBYbMjMDA0J3XuMDGLheKAzllfdPDgtCzsIo4LJ4aiYKgqqlCxR0DVDUAhblWwhYMoQgcBqgDROfLSFAVLt7/3FXc/t7L1RkVodlAUFKsHik5EGX4Fyos3I5o2JmfV2ug15ZOySDvYM5LFSd6RiMNugLcXQvUy6HZMaO2g9KMBqhW6LftWAOEfgRh3B2LZHxFr30kMaAWA1gFKP5YUqxboGa83oxhl8v2IqicQy15KuiaWECj9WFKsqih2f7KAsHrg6EdRml+E959KPmYJg5I8y5oaBeyZifok7uNxz0J8MbxhLlVOlG2NgtLej3LpXO7ftRzeLENM+x+EewPi/+5OpAMIawyUfixVBrD5oMe2AHXy7xDVIcTffty9ZWDTQennUmWrt9ceSjH2dtR4ATxyddL9FXYDlJb+lWtxg82WbMMjr0f4xsEDF5jldc+vpJhlTVluRq8lxaLiEkTJKYjffxfUaJINC7UFlH7M1mousCcvKVYGnQPlc+HJqxHhBjOt66DaCko/9i1rDhS7K7mtxScdmj6CFI7iDhJpG55GURSef/555syZ02eeo48+mnHjxnHfffcl0h577DGuv/56Wlv792D1JzyNYRjU1dWRl5eXGJhIJOmEtFFJOvO1ss+9DAOzR4SASCO0rYO29ebvwDoIbsGUg93YEoJnd0IdkJkJBYXg9sBhX3F5x04e0SN7fJ3trDgTRQ8RiUQR/gEYFgsKgoxABEdrIw1Nr4MQKF1LdoWBKnatBFQUFZ3OgZkeB0WhdMBMNCWDNk0l4LRhtNfgDGmMcN+MTXfQluVk8/hSwm4H9sY6lBcvQw23Y7XmEXda0W0amQ316DvfxUAnI66Zs0IKtFkMmhyQFRJ4OvWRQKHNoTL/S4NzvxKszQYNBYQgrimEHU4srnwGb92OJ6zjiCvkt8UJWsGuK2QYVrS4jqGoqMKJaoBQYghUQq4CXB3bsei7xI0iDAQKzVmZxCxgDYXJauvHvscexGw2DKuVh4+w8YNj9rBfMMXnOOmk3+EcPgcXcDdQYHOT48qB2tpeTlh2hOoJ6/0YLDqdkJ2dnGRxku/Oh507e+3Dqws10KH3c49qt5dCAA6LgwJ3AdTXQzD5/jWGm2mL9+OeWq3QY6WcRbVQ4i2BpiYIJDupaokGaInuxnFVF6oKRUVJSQoKA/0DobUVmpM/r0C0jaZoPwVaSUmvpDJ/GbS1QWPy/s5grIP6SD+FVFFRknMiwzCwhW0Uef2oDQ1JWcN6hB2hfu75zM/vtZe0yFOELS5g+/ak9JgRo6ajn3s+c3N7Cb8CdwEOoUFNsi9r3dCp7ki+Vp9kZ5t23I0cVw5ui8t0qNaDze3beqWlxO/vteczy5mF1+6FzZt7Zd/aXoPRn7W0Xm+vPZ9+hx+/ww/V1b0cbNUEdxAT/dij6nb32hfuPkR9xLA/HUFz8ilJHMjwNF/rGdXJkyfz6quvJqW98cYbTJ48+YBeRwjBjh07kt7USyTphLRRSTrztbHPnmFgujsvUjrDwDgLTaG5ciGMvRtcu2ZqMeLQvmmXIO0Sp9E+RIvVb3rq9QyF9ix47F8Qy4IjK5OcndwXWM0jaiQxraJ2ipzkRYCm6A2t+19sg2Yioq2AQEVgoBDy2LF3+LBafMRiTWAYKIpiLslVrGjxOHFFx1AEKGrn/jEDC5nEGiBsCRHMdSPiMUSoGcrmQbOLuEWwc0QeqirI29lAyOfGGHEirHgCvysL1QpCE/jiQYyYnS3eGG7DiqJoCAXiWpSiQIw2i46B+ZJaILDFdE7eqBK2QlwTqDpkhRXKmgWZkRCueDWaYaAYhjkDaZjLiUN2C0JRCTltuNs7EMLAsCiohk7M5kEoGoZqAz158PV5YQ5/Ob6SdwZtodahsP3WII69fI0vFIWwx8PcHX6uN5r37FApCY3DJl/PamA+cFj3Qz0EFkABZXtXuVT0EIQAeQei3NzcXiI2mzJ2M67tH1lZvRwt+Tt/9gufz/zphrfzZ7/weMyfbmR0/uwLuq6zYusKCvMLocdqEAdQRmXK8/qNRq9yrUAZQ1Pl3jt6lKsBZQw+4OUClB0IG05R7oADUW5paa+k4gNR7n+5j2j6vUC5/SCsxU9BWgnV9vZ2NmzYkPh706ZNLF++PLHPaMGCBdTU1PDkk08CcNVVV/GHP/yBH/3oR1xyySW89dZbPPfcc7zyyiuHqgkSiUQi+bqyN2FgmlfAuj+Zs6qBTlHaXtXDwVEXKmQMAE+nKPVWmP+25+yaynz4YahugBEjennkvFPsmiFQu9Zn9doHpdIlVqPV72EtO5l4y3oU7xAsqkbcohJ0W3A1DaWVTxEijhAKChpCtWAIEIowCxcGoAMaHlsFmiqIeG3oVtCa1mH3DMB2+ExsihfsVgy3mzwhUHI8uDSNxknzUdq+INC6FV9WBVZdp3hZPe14qVOCtFpjeA2NgBrDE7dwWF2UFTnQ6gBPVNBmhyOroaAddrhVrIaBPS4oa4L3yqDdKnDHdI7ZAqUB84boClgE2HUVVEHcYkUoDlQRAl3F0OzErRmgQMySgaFo6IqGLRYgYvPzwPHH8vLARZChY7fY+OM0Bze+14+ZxU4MVUXTdaIuc2nevA1enqnoY6YvxeBu6LhLWAeUAzN6H5ZIJJL0IoL5huQgk1ZCdenSpRx33HGJv7v2kl544YU8/vjjbN++na3dpvnLy8t55ZVX+OEPf8j9999PSUkJjzzyiAxNI5FIJJK9o68wMEJAvB1irRBtNX93/bStA3dZcn5Lxi5B6qkgQjmNtV7iMQ1L3EJ2bjZ2b48AdIEALFpkLvftEqm6Ds3NLDY20VQYM2dSgaRNU0pPxdMpVqOtnPVpEys9rWzIXkbYXwTuPByRIJU7WtjqcLPdGQBFdMbZE8RtVnNzphE2y0DFWzAOV+EodCNOMFiHaGtBzRuCe9oC9LyhrAU8gQAT31/GkHXtIOxsGlrB8vEFtE9bgLpkIY21qyiqU7E2BXE7vBTbrWx0NlCjBvFEFYbX6uS0G4w04NMi2OEGdwQqG8AWB9VQqM2AxeWwvMB0VCQU05OvJwpHbYHvfQITtpvOmQwBQqhY4lYilgFo+lesyIvxSYlGra+JW97PBWFDNTqwGB2EHVl8fMSvyLVH0fQ3UHQVzQK/Pj2Tw7fXc+KGPS/JC3q9bBszhrwNG3DX1RF2Ornn0zw2+iN8ktdj6V0KkeornkzurIcZACwAintnkUgkkkNObW0bDz20lDvuOBZxl0C5VTnoSjKthOqxxx7byz1/dx5//PGU5yxbtuwg1spcipSVlZVwMiGRpBvSRiXpzNfCPgPrzD2o7vJdafEQ1L9nCtUuYgKCuqnl7AKyKmDgCZ3itMJcGqwoBGoCrH9lPVWL1hGsC2LEDVSLSkZeBoOmD2LoaUPxFncuLly3DnbsMPcfrV5t7vFrMpfnPnBKi5mnx1djb4c/AsXoDO+uQEftIl78j8orFSovjaii0Rk343zqBlO3Q34bLBkAa/IMIoQ6BZQCmh3FXYjmK6ZD0ehoWG3OuGbkoQ6fgzFkBq3eYgprapj715c5+9k3GLh1J7ZoHLASteWypfQ4PpgyA3f9L2lq/A8f5j3DDkeIuACtWWFsvZfMUDvNzgjN1jhNOabIHLsTfGGNgF2hxaETtAneGhjnkQkQtIEjBrkdoBpgqNBqh5cr4f0BKgvf9HHW2jg7PPksLbLwRV6I5Xk7+aLASVSLooowqgjxo3dieGIaQnETsp/MloFXIFwljG9cwZM5IhExwwJcf+MIbnklwjn/Xodd7z02MYDaoUP4+00/4v0ZM8jbvp35DzzAhMWL8dXX8/FfbVxxnM6jh8fRNVKIVI38cZdw9KyHORFzJlWKVElffC36Uck3ls2bWzjhhCepqmqmoaGDP/5xBpPfEnx4tAJ2Dtoy4LR1pvTfoj/OlCQSiUTyDSYWgC3PwdoHwD0Y7H4zve5d85iiQdwFDQbUhyBqepAlKwLrx8O4eXDaadDpWbhuZR1LFi6huaoZR6aDjLwMVKuKETMI1gUJt4TJHOBj2pm55LWsg5dfhsWLwWZLzJJuc+m8NQh+Ma6d9Z5uM6p0eaCERIoQiZAqBmbVjtqi8uI/M8joCBKyGKzNgaBVAc3BkBYNX0zBFg5T5Y3x17EW/nP8NL6afCzFh52HI6cCPdJGtHEtRjxMxOKgObsSh92DAgxbuZKf/ugXTPh4M5qeSbsrh5BTAyWOq6Mef0srzvAgBLfQ7h1Bvf9d6riBkCUPV9TByJ0+PDGDLUO3saqgFvfWKqyKhWH1NjLbNNptBuuzwjQ6BJedHqPFaXr+7b7lU1ctGIodQ4E6VwhfWOHH77r47TQrgQwFRYAlbs4Sm9EbdFAiPPzq+YyvH4uuTcFhFGKLKoSdIbYO2MpPRvyEsiPLOOWoUxhfOJ4BvgEoikIbUPXc3yn85Z1YA61YNQvqBRfimjGLtspK1no8hDFXwVUCntpac4a8vd10gDJ9On+rf5ufv/dzgtEgTlsG5x91G8eNnr/rnINg1hKJRHIgWL++kRNOeJLqanM7Q3m5n08+uZzZs118+KGZJ+tKhabOremtNx04TSWFaj+9/m7bto2SkpL091gp+VYibVSSzqStfXbUmPtSdyyCto3QtgE0J1icprMdI2Yu5bWOgRWrzSW6drvpJVETYA/Ax4OhCigvhwULCPhLWXTzIlq3tpJVkYWqdbZXN0zPog31GHUNNNWE8Vk7mF68Gm+sEbZtA4+HT4e6ubeylXezArRpcYJqHKO7T6eub2wFhKICAtXY9TXeJVRnrNd45nkb7lAoabVwyOnqFMRdJxg42tuJOJ386LnnCM6YQc8woPXAR4AbKKyp4cffv4mxS7agq5W0+lWUzuXDAI6wQmENWIx1GMoAwvZf0O614Wv9PhAibi3BqetYYlawKzC1Hd57AREzIOborGcMULlgToT/GxalqC1ZpEcsplDVFQPR+V/AAQObNZoz8ojazRlna8Scfd118+Cyr67n/HU/wBluw6KaLwBcQRcxYmwcuJFh/xmGLy/ZsY5Ekg6kbT8q+Ubz1Vd1TJ/+JDt3ml67KyuzefPNCygu9jJlCgmhOnMmPPVUC5mZmQd08k9aej8QQtDU1LTbZckSyaFE2qgknUlL+2xZCctuhqrHIR4E3zCwZ5txHCMNZkiZeAfYh5gitb3d3EOakWGGjLCGId65H3X4cDNMwsKFrH/6U5qrmska4kdtaYY1a2HJEnj5JXj3XVi1GrWhnixbG826l69yj6Vq9g9oKBnD4+VOzhi/lRdzGwgZcTKDGjmBZMdKXUt+u3SmYvS4p53Olr631IEzHN4Vf7HzkCPSI8SNqhJyu7GHQnzvzjupS3GrfJizhWHg6FdeofKLKgQVBHxm6aLbUkR/s4pmaMS0CqAKW/R1LNFMIs7jUUQrKALDohCxR4mHdLZ/2c42t4GIxeiM3IqCTrXHzjvlOs5474FKVANd0Tvzgl0HTYcN2QJdxLHEOu+TsmtF85DmCs5dOY/xtRNQDQNNjyfuV4erA2fIic1vw53tRiJJR9KyH5V8o/nss1qOPfbxhEg9/PB8/vnPi7jkEi/Z2fDJJ8n5D4ZtptUeVYlEIpFIDjp9haFxFkPzMjPMjGIxZ1MbvoKQAF92N+dFAqxR2FEGus2MtTBkCJFPv6RqyWs4hAW1qt6cRe2GsNkJu3MJWT2EdDttDRHe+9zA1wSK080vJ26h1SHIC9qwaBqKTcGh2akXgaQ9qV0iDJI1Z9fVskIwpVZBE6JX1D/V0FF1HaObZ2FDVRGaxpAvviBj3Tr0igq6y2MbUALUBAIc9e83sHf4iTg0FOIoAnTFggJYYuDqUDAUQFEx8KOIRdjCc2nMPoms2AdYwysJqwNB0bApAl+jl1WleRTXNQIhFFQEdhaXC9psBrk9Qm8qmE6W4ppAEebEdkxViGoQVwVRS5TckJ/82DiOXzOeKRvHMWbHWJzCg0VXMFSFpox2lM4BlRACW9BG2BWmOF4MbRyAeCcSiUTy9eb997cyY8bfCARMh3BHHFHEa699lwcecPKf//TOf7C2TkuhKpFIJJJvF32FodHDIMyZPeyFoDogsBX8LtC7iVRXK4TcsNED29aazo8aG2ls9xIMN+P36WYcGbuNiCeXVt1DR8xCOKhDU9fFIghDYMQN3AVu/nZEiGYBhSErWoY96VvfF1Fo6RHUUwAqvZf8IuCmD23Yo9HEbGr3cxRAi0Qw7KbnYUMxBa2iqmjhMOfcdx8PLFhARVMTWqeYi6KTYTGo3NlE7qbtIAYRthuo8ZhZsKJijat4AgLVgLgGCIFQclHEZqzx9ViM8bS7bya34S7ssc2g+EHJQ4k6GFt7DLASha8Q6AC029swFIHW6wW9gl0XWA1zCXDArhLVbDh0B4oS5opl13LH23ewYZhGaQ1ELXGcusAaU9A1BS0KTiWObgc1pGKJWYi5YjjGOLDV22AtMKlfViSRSCTfSN58s4rZs/9OR4fZxx911ABefnk+Xq+dulTLboBJB6nflEK1HyiKQkFBgfS0JklbpI1K0pm0ss++wtC0bYSOzaC5zH2qRgRiUdPLryeK3hInqkRRLBGMrQLLq+3Ytieve4o73BgxK+qgAbT7immqDdNR39F51BRgml3Dme3EleXCnmknuCPI0BuHsmLFRpxhL5quQzRihqnRLIT1MG5dIRoVdHRtHu28jUbXMqtuGvr8ryxc9YUDxQj1eQsUw8AQ5pJdTdexR6No8TgIwbGLFvHCzJmsKi7G2dFKKLSDHdYQHVaVw+va0WJxEFYMEcUaNcgIWXCGQRUqlpi5h9aig6EqGNhQ0FGUCNa4gj80Gpt2D/AqGG+AsRWIm4qTwcApKCwHFuOORFEFnfFRFczhSpe4jiOUGDbdRlaoAFXYiStxGjLqKW8disXQ8LSBqoPusBDwG1gjBq4OgSUusCsWYgjizjiRARH8Q/w4fU6iTVGUSBrYqESSgrTqRyXfWAxDsGDBmwmRetJJg3n++XNxuay98rrdcOWVUFkJl1wCbW0H3jalUO0HqqpSUFBwqKshkfSJtFFJOpNW9tkVhiZjIITrzX+Hd0KsxTyeORpcJRDcCk0bMRSBocUIiACtdVls+2oo25fmo7QqDHLWMrS4A2+hG3JzUYN+xCILNVsF7Ubn1KkCniIPnmIPziwnVqc1ISz1qE64KcxHbR/RFmkjNyMXXJj7YdvbiYWDYOhYFCjWXLQoKg0ESSzo7SZQs0Jw00d2rvrSgVBNodhFz5lVQ1VRFAWbEFiEQLNYzH230Sg5FRXc3djII/YYjxa5aCkeiKbasAlwbvsILdqKEm/FEXaQGXBhjSkYKsQ1HcVQsMZVEKAZCqqIIVQLGDa8io4j04IZgOVyMOZBeC20h6HCASsqweHB0P/MTvsKomoDGdE4rQ7IDjnpvlNVExYQdiCKIIRQ7QQcrXiiHk7cNB1FgYgXYh0Qc4KmqNjsKja7jhIQiDKBVqzhzfVic3aq/yjYnXbz/kskaUha9aOSbyyqqvDii+dx9NGPMWJELs8+ezZ2e2q56PfDb3/b/dwD7/pICtV+oOs6mzdvpqysDE3T9nyCRPJfRtqoJJ3ZZ/uMBUxhqYdBc4C3Aqz76ElQCOiohtpXIbAeWtfQNcuZoCsWqqKAbzih+gyaNq7GkdPB+g/H0bB2KMamndiMOEFvIcvVAWyJ6hzpasFSXUfr+tVYo4NoDWaielT8ZX4yB2dizej9JhogWBckIy+D1pxWjDUGmqKBphB1u2igHaIqqlDxOv1obj8+VUUDmiNBIm01uN2lHLd0K9d/KJjY6scB6LEowjASGjbVsEGzWLBqWvKxYBAcDrj3XijIYP2imymurWfMgGlgsaPpcfKVrYSzomjbt5HbPgSIE9XiaELDEu1aWGxHQel0dFSPYuQhrIOxey0kbXzFA5EJkAM8AJwKTZbNrMv5FW2WOpyGxrAGC5+URDFCqdqhgKKiiCAGbsKWMKdsPoUhgSIMG+RWgisAnoi51VjTgJgGuRr+CX7o8ZEYdYbpVGmIEw3Zh0rSD/k9L/lvUVDg5t13LyY724nV2n9b03V9z5n2EilU+0lbW9uhroJEslukjUrSmb2yz+5hY8J1pnMj1QKOPCiYDkWngat4z+XE2qHpU2j4EBo+glCt6eE3HgDVZi7xdeSBI9/8rTkSp0aDUXZsjhELubGHY0RbchFNYRRhoNlseHNsOCNh6rYrvF6tcrirnRy9kUJ3Lq05WZRMG4ilj7fQAIZuEG4JM3zOcELeEKqiogudjkgHTSFzNlazW8nOyMNusRMFGoAooFrsWO0eKqf/nFuf+yPjqpfS4TaIqCr2eByLrpszpIpiCnSSnS5ZrD1VmgG6DuPHQ0UFr3z2MFXNVYzIGYEW2LYrmx2+HJ/PwK8ascZVQtZIp0thAWgIVaCrBhZDQwgdc0Pu6ahWX++BtYHpRvgU4Bj46KiP+L37Qr73yQ4aXAARjt6sszpHZYcnREGbE7WnXFUsGETYmbGdnHAuP1h2HeiglkK2H9MD1Fp2zZJGgTJ6iVR0UJoVmqY3Uezph11JJIcI+T0vORj885+rOPnkwXg89kRaQUF6eECXQlUikUgk6UPLStMjb7DK3EfqLgfFajo5CtdB1ROw810YuQD8I5PPFQa0rjJFacOH0LKCXb5wMT355kyGlq/A4to1e5qC1q2tRNpj+AviRJrttNf5IGB6kYg5PUR2tBMPx3EJCOgZNNnyGZnThP/8E2hbkUdLVUtyHNVuGLpB07omMsszGTJjCHmePDKsGdS01SSW9bosLnIyclAVlTimSI1h7tKMRFqx2T0Eyqdzz+05PHbOOWS0t9PhdhOxWlEMw5wTdDqhoyP54hZLcpsNw1xq7HTCT39KIBJgUdUiMh2ZaGqyuAxEAzzpa+BkSwlCWYtVH0LMomMoBqpQwVCIqzE0Q6CyHsEgDOVkrMJqfgxdt8IAdgDZoF+r8/uPfs9vj/41E1a0YjGixDvzDW6BHy1RuH+KjVpPB864BV/YiiYUdFXQ6ogRtkTJDuVz36L7mLB5ghlH57DO6wwAtgMtnX97OtO6owPrQJQL2qZJESCRSL5d3HPPB/y///cGxx5bxquvzsfpTL0C6FAhhapEIpFI0oO+wsYAKDZz76iz0FwOvHIhjL0bVOuuGdPGj83lwt1xDTDFac5kyBpnCtQND5vxUzEgxTJPPaoT2NaGZlew+QRbvxiMXt1MJKoSwYERMOgSwHaPDZ/FQkvcizJyBL7vzmJai5UlC5fQsKoBR6aDjLwMVKuKETMI1gUJt4TJLM9k2oJpeIu9bNy+EYEgEo9g1axku7Lx2nctcW7HnAy0A8IwiMfD5A05hWZvEYtnFPGPhQs5d8ECXO3t6KpKVFWwGDqKYkVVVVSjm1jXNFOcCgHhsDmT6nTC7Qshbwa1/15D5leZZFdmY3TGNY23xLFutNLR0MHw+uk0eo7GajyGJ7QGRyyLmJqFIhQUdFRjOwZ1qBQBs1A0L6quQgRzJrMVcyY1G+p/U8f3P5/PezUfQiRC2GoQV8FigNVQmFpto7BdY1rNAB6YGGNx+XbqMyIYikBFwRO1cMrGHK774i4mbDndFMKVmIFfRef1CtklVIs60wSm6q/rPFYO4keCmBHbO3uVSCSSrylCCO68811uv/1tAN5+ezPPPruSiy4ac0jr1RMpVPuBoiiUlpZKT2uStEXaqCSd6bd99hU2pjsCsPqhYQm8c3rymlYAixuyJ0LOkZB9JLiKepdRdJo5KxtYZ+577XGtcGuYeDhCdkEDwUghW1qOIdi+BothoFoMhCKwex3Y3FbUaAR7uIUWNYvGM8+jqLiYvGKYfvd0Nry6gY1vbKRlUwtG3EC1qGTkZTB8znCGzBiCu8jNXz7/C3/+7M/47D5awi1oiobbumvJlQEEMeW0MAxC7TtwuLLRJl0HwEDgg2uvZcfAYmb89KcMXrsBayyOIgwIdRC1qHQU5OGpa8EaiUGs80dRwGaDUeNhyk/h0xnwChQGC7kycCVBf5BlJctoi7Zx2NbDyGnPwWJY8MQ8lLaUUu8oJmR5g+zQ5zijtSgiBASADsCJYWlEVR9E0/8XItNh52lgLzZnNY8PsKRiId//6PfUqbu8E1dlQYMLKhtVhjfYcMZVwMqEWi9PvjSa2oIgiwbX0K7HcHdYmV6lUhTMhrwz4HRgGLAO2ATEMUc4BcBMTDv5tMexPGAOMAOUQoXSZtmHStIX+T0vOVAIIbjllkX8+tcfJNLuvPM4Lrxw9H6VezBsUwrVfqCqKtnZ2Ye6GhJJn0gblaQz/bLPvsLGAEQDpmfe8E6INphLfI0oRFvBPQgyDzdFac5k8I0EdQ/OH1zF5tLhlQvNpcK2THOPaucSYyWyHb+/lmB7ER+8Oo1tnwssSiFeazv+TAWbGgcRho4IOJ2oAwdiRLzEiwcmLuEt9jLu8nGMnDeSxrWNxMNxLA4L2ZXZ2D12Gjoa+N4r3+PT2k8BmDtyLiNzR3LLoluoba/FaXHis/uIKRoxoSMirUTiYRyubIaefB/VRRNQMCcQm0NNPDLKz72P/pih62uY/f4aKr94B73Iw6sTfKy2NlP+VZzbqgZScdRsCATA54MJ58EzFYjPBEF3O9t929mkbWKHsYNBdYOYv3I+CFiXv44deTuwOWzY2+0oDQq5gTFYlAnErc208RLu2LOoRhhhH4iiFmMRNrDGwF4H7U/AoHfhhLPQo+9xX80T3BtuQfRYFd1hU3BpNsY2GihZWeCqhIwycFhhCBT5MriAClO5V+uQtRrOPBF+4TFnSwHaMPelhjGXAVdiiuM9HFORfagkvZHf85IDgWEIrrvu3/zxj58m0u655yRuuGFyr7xCwKZNEOoW7aypqVe2BNLr7yFC13XWr1/P0KFDpac1SVoibVSSzvTLPrvCxrjLk9PbNkDLl8lpmhNcpSB0GHcP5B+795XyjzSXDte+CjvegPZNCadNQnew8v1RbP6slGCrghYJ4ndGyJo6CrWoAFpaQY+DZgG/D0OoqJtasDh6f6XaPXaKJiTP6n5Q/QG3v307zaFmnFYnt0y9hdMqTgNgcNZgHvj4ARZvXkx9Rz0xYRBTVOx2D6VDTiFv0nWsL5oAwBCAaJBlO5bTHm0nM6rSUJDPvdcezaR/t1MwKBMNGL7iC9Y5ovz86Dh3//Byir3FdGzqIPDDAJFNW1iVuYpQOARhMISBw3BQ1FYEmingBocHozk0Io4IwfYgYS2MO+5GQ0MoQTT9dVQRQ1WPBGfn5yuAqA30EsgthIaXCT36T35wKrw8vPcS2/yQyoMf53DklNOgrBba2qByUKe73h44dBDrYEo53Dljl0gFU3hO6OMz380x2YdK0h1po5L9RdcNLrvsJR5/fDlgLqx58MHTuPLK3h2jYcCJJ8Jbb+1N+dLr7yEjHA4f6ipIJLtF2qgkndmjfephUygqPRw5BLeYv+054CwyPfRaOpfGtq4yHSTtK65iGHI5DJwHgbWI7VtpfOo/NP9tOdu2F4EIUWhpxEoU1eGB7CywWiE3J7mK2wJk5GWQXZlNIBJgXeM6wvEwDouDiuyKxH7TmB7jwaUP8uQXTwJQkV3BwhMWMtC/ayZ2QtEEnjzjSWoDtSzatIiV0Xb+z+ZmdPl02r1FfIqpAcswfQatad1KIBIg0+5HibagaxZUQ0eLRxNlajvrGRq080VpB7e+dStWzUrZP8o4bcVpVBVWIQyBqqjkZuRSkFGAdZ2VjFgGEU8EBQVX0EVmfSY7Cnegt+vE1TgWYSFij2CLvIEqalGVw3rsKQZsmCuBHRrbC7LYUb0TTxv0DDZzXCCLB8YsIPvOS8zAfCtXwsKFsGoVZGZCXp5532MxqKuDlhYoL4cFC6D4wHnplX2oJN2RNirZV2Ixne9+93mee24lYMZLffzx0zn//NTLfVet2rNItdkOdC17I4WqRCKRSA49msMMQSNipuMkgHgIYq2AAtmTQNvlOh8jaubvFlJmn7F6aFzSQccP78datw2b5iLPG2KrGIA1HEDVDYjH4ZNPYOwYUzx1VaMzzEz2rGyeWPcEi6oWUResI27EsagW8jLymD5oOuMKx/H7T37PyjpzkHDOyHO4/sjrsWmpv+mLvEVcMPoCApjbKjd3/u4SqWOBmB6lJrANu2ZHicdBCMLeXJyBenx1VcSGZNHYWI2ncQcxEacqFmXj2hcYaRvJ3FVzifliDMoZREFGATmuHNPLbxTirXFarC1EjSg2zUbcEiezMZN6Sz3EwaJYiFviqLF2FN5EEdm9l2sLTA9QViACdVlOGhrgmM3w4jBB0Kag2Z0sGHklV53za9Tuy7VHjoS774ZXX4U33jDXnsXjpsfivDyYMwdmzDigIlUikUi+ydx774cJkWq1qjzzzFmcddaIPvP3dBifinnzDlTt+kYKVYlEIpEcerwV5j7RcJ3p3RcgvN38bctKFqlg5nPkgbdyvy4bagqx/FevkPPYb3BHm2h1F5MzIo8jC3x0vBmgqd1HlqMdNT8PWgOwbDlMmgQZrkSYmbbKNh5zP0b18moyHZmU+8uxqlZiRoy6YB33f3Q/DaEGcpw55LnzuO3o2ziu/Lj+3RbMla2vYm6rLMMUqQrQGm4lFA/hsXmhowOhqERcfoqXvkhr02aWrNtBYX2YSj1KIEPDYnNg02xc6r6Uox1HYx9qN2c9wfTaVANUg6XZgtvmJhKPEIlF0IWOO+jG2eJEKAJFVWh0N5Id3ISmN6AwyCxDNIKRbYZ8MTBFaiYQhVGu8SzOWEtOa5DBIRcNFYN5aM5fmFDUx1rc4mK4/HJzJLR2remh2OGAykrweFKfI5FIJJKUXH/9kbz11mbeeWcz//u/5zJjxtC9Ov/nP4fR3SZfCwthQl/bLA4gUqj2A1VVGTRo0EHZJCyRHAikjUrSmX7Zp9ULBdPNsDHOQnOGLtQpVJ2FyXmFDtEWKJkD1mTREglEaFzXzXlRRTZ2bw+RCxhxg5XPreSzP39G+eZFeCIN6EOHMejwAqwOC8SiTBOfsEQdRYOlGEeHhQyPD7W1GaNqC8HMYsItYYwhBkumLaEuVseInBFJsUc1VaO+o56dwZ1E4hHC1jD3nHgP44rG7fGedS0hfi8e5lWbB2vucDI0G6PZ5ehYN+IYwly2G4+EaM0vJ3PLZo7892YsofEEnBqe8BrsFoPM8qHMqhjH2sa1jPeNx449MdvJZqAKCGGGbekAR8RBnppHu9ZOUAtiGAZBLYhiU1BRcXlcWOxxlAYdYioYHwPrITwN7GXmflA35igjDKquMPnwGaz56BWmDZzG9y5+hkxnZs9m98bj+a+MhmQfKkl3pI1K9ge73cLzz5/LihU7mTSpZK/PnzIFTjhh93mkM6VDhKIoeL3ePWeUSA4R0kYl6Uy/7bN72Bj3IAjXm+nOgl15hN55vByKZiSSAzUB1r+ynqpFVQTrgknhYAZNH8TQ04biLTbrUPNJDR/89gOaq5qx6iEGswn/2EE4RnT78t64kTyxk+n5sKEsn401Gi3tVoyYH3V9AxlHlTL8orEsGbSE2s21jMhOFqmBaIBPtn1CIBpAURRG5Y8C4LMdn+1WqNYEanhl/SssqlrE2mAdVZ0OnvIKx5Ez4Wq+8A0g32InD1AUlagQbBU6AzrKuPiZGNP/nUlx/Y/QVDvGZg/B0AZWFy7mqwkd1IkoFtWCxWUxBeonwHa6QsKagVrzgG2ADayqlUwy8QovuqEz3DscLV/D1+pDtamAG7Q4xF8D0QIqCONDlOxMcPjMMg3MLakauGwZjCgcxdgT70Tpj0j9LyL7UEm6I21Usjc0NYUIBCKUlfkTaS6XdZ9Ean+R4WkOEbqus2rVKkaMGCE9rUnSEmmjknSm3/bZPWxM46dghMHqA81t7kkN15kzqe5yGLHAzA/UraxjycIlNFc148h04C/3o1pVjJhBsC7I8ieWs+XdLYy9dCwb/r2BTW9tAsDhd3D0KVkUv2RFGdTty1sI2LgRAO9hAxhXGmLk4DCNrRZzpnZnDdk/OJPIkUO468W7yHRkJkSqQLClZQtf7PwCXejYNTtjiidic+WyI7CN5za+wYyR8yi2mzPBAczQn2Ggpmkj/7vkLqrrV2I4Mqnxl2NXrZQaMYoa1rLzP/8PS8UswsPn8IEeY2dHA+0ZOYxcHuJXv4oxeIuNDp+DZu9WdLuK5s/D0+pg8sb5DH1e54lTniDPnUfpm6WwAVNE2jCX5w4GijGX7YYwY41mmLdDC2poHo2ccTnm3tP1nRU2qiGy0txXrGkErQYfFEcY1/Qm2fbTO2fFASfgB3bW4SgaAMOG7Yc1HRxkHypJd6SNSvrLzp3tnHjiU7S3R3n33YspKfnvvOCQXn8PIQfj5kskBxJpo5J0pt/22RU25pOrIVQLqhUCq03HSY48c7lv0YyESA3UBFiycAmtW1vJGZGDqu1aeqTZNLwlXjLyMti6ZCsbXt+Ap9CDxWFhxNwRTLhyAvYvP4UX4qZX2S4aGiASMV0adjrssdsERbkxU8QGmkGLs6JxHXXBOsr9ZkidlnALK+pWUN9hzgRneUvIKhjLatVqar+MPKItm7iwcS0ndsZBXQrUAcF4hK16FGPUeeS3VLO9YRVquIUBwHjNhuItwRlq5NP37qT9vV+QWXIkBdYMfNs1FjwyiyHbMqjzrULk58KOOCg29FgbLRmttDrbydsykjlPzKFhYAOeBo8pHGPAJKC7E2MNKMGMN+rqTItibo7tukXFcVh2F4T/hBkM1aDaLfigJEZUg/dcMWbEDWyGtutcVTe99c6Zk7Z7TGUfKkl3pI1K9sS2bQFOOOFJ1q1rBOD8859n8eIL93heOJwcI7W+/mDVcO+QQlUikUgk6YWzEIwQuMug8npwDza9+3ore+1JXf/KepqrmnuJVAAEtNW2UbeijmgwSjwcx+F3cPqjp5M1JMvM43CY3mRjsV2+9mtqzN+FhdBzz00sZuZ3OAjHw8SNODE9xhc7v6A6UA2AqqgMzB9Ds38gVSjYMbdsKqqVZiNOfTzMbzuLGwEMAjY0V2E0b0TxlrLWNwA1t5LB619jbHsNNYFaNjZvpDHUiBCCSDxMTstmfnr0T5m4aSLNTXWszfoUr2YnaeVVewjiYAQdrHOuo7KxkonWifB9YDJwN7AVc0a1+wTNAKAmAPXrQIQhwwGFFYAXOnbClqsh/BEYELPYWZ3TQYcWI64ooNlpU2J8pHzEUXXTUDwKFOuwbp0ZUmbGDCQSiURy4KmqauaEE55k8+YWAEpLvTz88Mw9nvfcc3DBBeb72XRDClWJRCKRpBctX0G02Vz2W/YdczY1BZFAhKpFVTgyHb1EajQQZceXO+ioM33sW11WsoZk4S5wk5GfsStjRYUZ8qSuDkpKzBnTLqFakmIvT12dmb+yEr3xc3a072Bt49rE4VJvKeV5h/GlxUk7pgbc5fwoBqqFJosjoQtrgQI9Sm1gG6qiEYi0okUCaBl5NAyYwqtv/oRY62YAFBRKfCW4bW4K3YUcnXk0ng882F1NbNOh2a5jj4dwGgK1I45h6IQsgog9glfzUVBSgLfcC+dhKucFwEJgVWdF84BoDWx6BQKLIFCHqXQt8HEe+Mphy0sQbgEFtvp1rjotQIemc+2nGhUtKi12QYNL0GQ0EMlox1HUCltbDkrcU4lEIpGYrFnTwPTpT1JT0wbA4MGZvPnmBQwc6N/jub/97Z5FquUQKUYpVPuBqqpUVlZKT2uStEXaqCSd2Wv7rHuXSNBCY3gq8Q9q+/Te27iukWBdEH+5P5EWbgnTtKGJQHUABCiqQnZFNlkVWQhD0LKphca1jRRNKDJP8Hph+nR4/HFzBrW52fzGtlohNze5Xrq5fDV++iz+ueUVHlz6II2hRgxhUOQpYlTeKDIdmazG3HvqEzoRPYoQAkVRiAXrMTLyCGdXkt1ZZAuwPh6hJR4iaPMihIEWD6PXfkpzVgX2AVPxr9rOoMxBlPnLcFqcRPUom1o2Ub20mhF1I/CKFiY1ZbDVksf2wE6UWBWKEUNRrdiVAZSVDGNA4QAyyDCDsa4FJgAjMWdVXwXeAL5aCZsXQrQKXJkwuhw0K+yMQv2nsOUFUDWwuHl1pM4NxwYIWAGLl18eb+e4jWGO2RRlXJOfwY6BWHJrIT8PTpyT9nFPZR8qSXekjUr64ssvdzJ9+pPU15svZkeMyGXRovMpLOy9zWLFCnj/fTCMXWlbt+6+/OJiGLdnZ/XS6++hxNa1JEwiSVOkjUrSmf7aZ6AmwPq/fEnVR4cTjGVjaIv69N4bD8cT3n3bt7fTtL6JjoZdUcrdhW7yD8/HmmFurhRCYMQN4uF48kVPOw3efddcnhoKmWlFRcnLfnUdsXYtO3Kd3Kq/wBcfNAAwyD+IiB5hUvEkLKqFKLDFiBOLh9gRbkUXOkIIQGAEarFMuAKfxZmYZbUBW1QLLSgg4qjRDtRwMwpgiwVxDz+T4/UYTmNXna2qlbgRJx6MQytQ3UxGRwvD26qpiC9GNzYiFB1F1dA8pWgFBsROA1eG6SQp3K3txcDlwNE1cP1CiG6F8hGQpXWGr4lAw/tg1ILNgiHifJHbzK2TDQJOC/h8YLGywwf/Kslk/PkLqCgch2KJfO3inso+VJLuSBuV9OSTT2o45ZS/0txsduxjxxbw+uvfJTc3o1fezz6DyZPNHSx9MWUKXHHFrr/tdjj++EPXjUuh2g8Mw2DFihWMGjVKelqTpCXSRiXpTH/ts25lHUvufIPmL5043DH8w0tR7fZe3nunLZhG3sg8AEJNITa+vpF4qFPIKeAt9pI1NAtHpiO5HjFT1FocPb76iovNZam/+hW88oq5/Dc/3/wdi0FdHcG6Gr7MaON3YxxUaU6ynFlcNeEqJhRO4Mdv/Zj1TeupyKqgOhakTugQCaApKlbVioGgo3UrhreYyMBjCQXraHJloWg24oZODMCWgRYJYIkEcFvdeO1eNM1GuyuHdk8xztYtierG4jEszRYsL1pgfRxCG0A8B0YMLcONFirA3HSqg9WAdU/A9ndNj8qWkZB8W0zeeQVaq+CIEdD1GTU2mgI+GAQV2myC9wri5LYLjqu28MzgbLo2xZbnlfPwzIcZmTey/4aRRsg+VJLuSBuV9GTz5hamT3+StrYoAJMnl/Dqq9/B70/VycPixbsXqWDOnF64Z99LKTG6T9MeIKRQlUgkEskhJ+G9t6qGnAFtqM4cc0aOXd573YVumtY1sfi2xeQfnk/VG1W0b29HGAJrhhV/uZ+swVlYnKm/2oJ1QTLyMsiuzO59cORIOP98WLLEnFVtb4dVqwijs1Zr5sVhIT44zEdbrpfLDv8uF4y+AJfVdIu7YNoCFi5ZyPKdy9kcCRDPGY5LtaIInXhHA6FoG3iK0MZfge4fiBFqIhKsB2eWuf9W1dAUC149Ro63dFeoG6FjKCq61tmeMFAFdbV15IXyKN1WCsoa4EWwNEHZkRCJQniHmV+1gX8ACANa18GnC2Hc3VDZYwluIACLFkFm5i6RalYgMcO82R3no7wYMVVgFRrHbLPwYkQQdCicMewM7j7xbtw29z599hKJRCLZewYO9HHZZeP43e8+4rjjynjxxfNwu81Z93ffhQceMLv3LjZt2lN5cPXVB7HC+4AUqhKJRCI55CS89xY1okYxPf/2INISIdwSZvvn26ldWktGbga+Mh+xjhglk0uw2Pv+SjN0g3BLmOFzhmP32FNn+vJLc1/qSSfRdtqJvPzlP3mt5m025TkJO73MqpjFVROuIjcjee/qyLyR3D39bm5ZdAvrq5egtG8nGg+jKCoxZybqwGlYio/E5SmkRY+AoYMeRdOjOGweLA4fA70lbA83oSq7lhsbioYqDLTmOHwK1IAudFo8LcyJzMFzjQcefho+3QkZg824pd1xOgHFTPdWwPbVkPkqeC5Pzrdunekkqrw8OT0nh/j4sXy25UPWeePm7KnNToNdZWCjzvAmlXkX/ZbzDjvvoAR6l0gkEknfKIrCPfecxJAhWVx88RicTnObSywGp59uRgTbHc3NJHmK93qT/04HpFCVSCQSySEl0lhP89I3KB3ajkNfQ7DNQ9xRYB4U5mxr04Ymwk3mHhxVU1EtKsf/8nhyR+Ty5oI3aalqIasiq3eIGkyR2rSuiczyTIbMGJK6EoYBb75JVDH4+1iVR9f/jHatHQY4mVI6hesmXceQrD7OBTx2DxE9wvjcw1k74iyiGIT0KKqvFFQbSkc9wZbN4C5EsTrQ4mFsmhW/KxubqlHpzifY6qU10orP7kNBISw8OLe14Xt1B4RBR2ddwTrKi8uZcd4MsATgrldBs4HhBdGjUk5n4h4S0MDjh+Y3oG1e8oajcBjiPWLJdrK9wM26Nsx4qTY7KApxIXCrDh449teUjZrf5z2RSCQSyYGlsbGD7GxX4m9FUbjmmiMSf+s6bNu2Z5FaVma6GEg3YdoTKVT7gaqqjBo1Snpak6Qt0kYl6Uyf9tlRA7WvoK96iZEV67HZY4hYB5Gom4aQn62bRrHh7Y7E/lNFVfCWevEN9BFqDOHKduEr9TFtwTSWLFxCw6oGHJkOMvIyUK1qYm9ruCVMZnkm0xZMSzhi6omx7HNe06r40+QmdjT9GxSFiuwKrj/yeiYWT+yzbYFIgHWN61i+YzkbmzYyPHc4YUXh89KjyKjZwcivNFwtAaI2N1VlQToirUT95dhQiRkxOoROORp+WwZjC8awbNtympuasYUdRHILKVu2HGJtbBtYR0t2C+VF5SyYtoDirGJYuhRatptOktwKNAOKaopKDLC7IAhEMcPRHJYHzZtg7VqYMGFXI1LFku2k1FfKkLxhbGipSqQN9ZYx0p6NVjis3zaQ7sg+VJLuSBuVPProMm644XVee+27HHlk7/BpzzxjLt1tbU1Or6w0ndp3kZUFt9xy4EWq9Pp7CIlGozgcqTcnSyTpgLRRSTrTyz5bVsLKhRCsgriTttYcbPYOVEPF7lYp9b2JI/ox9b6jaTGKyRyUib/cj8VhQQhBcGcw4b03b2Qe0++ezoZXN7DxjY20bGpJeAPOyMtg+JzhDJkxpE+R+mnNp9z/7ytZU1kLPh957ny+d8T3OHXoqUlLcbtTE6jhlfWvsKhqEXXBOppCTWxp3UJjqBn3TgcXtk7ihA8PI782jC2ugE2jJUfnvaPb+N8zomwtdRETcbINnQEq0AiZG7OYtGMSm51bWVsGamAToeD/smlSC3m+POYMnsOMITMo9nbuMW1rM/eQ2g04UoE6YLMKugssNujQwAmUAQMAlxXq4+YMahdCwMcfm3tyu2LJ9uCIkok0hBtpj7YzsWgigzvs4M8wRz/fIGQfKkl3pI1+e/nDHz7h2mv/DcCppz7N8uVX9oqR+rOf9RapAD/+MVxwwX+hkgcBKVT7gWEYrF27Vnpak6Qt0kYl6Uwv++yoMUVqx1bwjUDEwgixDREPIxSVcKyQkG7F5drApOmL2dx6FYY1Z1d5Kbz3eou9jLt8HCPnjaRxbSPxcNyMv1qZ3eee1KrmKh74+AGWbF0CrRtx6SoXj7iQ+Wfegd3Sxz5WYGXdShYuWUhVcxWZjkzK/eVkOjLZGawju7aMGxadTFlblJaiDrYMtqFawBGNk9Ng4ex/5DJ+qeAXCzS+Gg65TTGsq52IJohZoDkrA1E4nBNcUc7w6BTP/n84LA4qsyvx2HvEB2gwQ+RgtUKWHbKBIVaodoDVbnr39WOGmQGIxsyZ066BbjgMN98M//gHdHSYfxcWJjtUAiyqhaMHHo0Q4Le6oXY1zJnztQk70x9kHypJd6SNfnu5++4l3HLLm4m/L754DAMG+HrlS7Xc1+mEqVMPYuW6Ib3+SiQSieTrT+0r5kyqbwQoGg6fA4vdIN6hYHNooDmId8QI1OWSU1xPzPMl1Tt3rVvanfdeu8dO0YSi3V6+saORP3/2Z95Y9i9KdnQwLhhh2io7M2PlZN3zc7D03qvZxZpALf/vq79Ta/dRNuRUsjoasMXDuBx+vMFybnjze5S2lrDG/wma7sYbHUXEkkPIaWdrqYKmGwxdp/Gzm7bzwLzleMvnsCkT4plg8UNeFszxwAxsFHPY7u9jPG4KT5tt1xouKzCoDwFZVwd5eeZM6LZtcOmlZvR34MUKwYStmyhakQGjRvUSqz67z9z8tG6d6XRpxozd100ikUgk+4UQgttuW8wvfvFeIu3WW4/i5z8/bo8O7I46Cs45B044AQYPPtg1PXhIoSqRSCSS/x6xAOxYBLbMhJdazabhzYnQuFFFZNhQgFgohhAqMd1NbtZyahuOQtdd/fPe2wehWIinvnyKf7/zCOM/38mP1wQYFHVTHBA4GkMwoB0eewxOO82MrdqNGuAV4OF4iPXDz8Bh81AvDByRNgoaVlNT9yWnbJhFWUMJa3JXY7NaEfEwlqb1ZIWaiFpdGDEFtU0QbO+gvNrLbX/KZ+xQK2svhPCx4MiASsztpP2iutp006iqpojc3SyLrpuv2+fMMb0bX3klNDURtBj8eGIb/xgUZtx2+PuGOO5Vq8xQNXl55mxtZyxZWlpMkbpgQa/7I5FIJJIDhxCCG2/8D7/73UeJtIULT+CWW6b16/yxY+H73z9YtfvvIYVqP5HLLCTpjrRRSTqTsM/AOgjXgbszFIoRh7b1+HzbaHd6iQTd2O2CeIe5/zQussiwNuF21tDcOnjP3ntTYAiDF9e+yENLH8K7oZrL/72Doa0aeSWH4SsZbMYQtdlM0ffEE2YAugULzNiqwEpgIbDeiFMTbsHT0Yg72o6haHTYPXxeOhmHZQjTN1lodTSiaWDTbMT1OMFoEG/MiyPQBlEQCFqtrfhdLiZ4JuD6H5jQewVX/1i71nTbmJ1tznRWVJhiNRo1Nyp1iVe3GzZvNt08NjXBvHmg66z2x7jy6AAbOkPPfD7cxzWT/Dxqm4tl0Vtm0L2uWdu8PFPkzpjxjRWpsg+VpDvSRr8dGIbg6qtf5uGHP0+kPfDAKVx77aRDWKtDgxSq/UDTNEaNGnWoqyGR9Im0UUlaEQuYglQPg+ZA81bssk89bIpTLNC+CVpXgxHGZoeC4So7trjpaAgRj+qoqoJqt6MQJ9zYQsP6hoT3XnJgae1SwvEwDouDiuwKvPZkZ0lCCD6o/oD7P76fquYqcpujXLOoldFGEf6pE1EsFnOfZyRCIMPCujF5hBUdx5aVVNz9c7wL76WmuJiFwFagMNRMdVsNGTavOesbD9EQ6yCCyqiaMvKjPtqK2nFEHUTiEVRUYpEYkXAEu2EnZAkRcUbwerwMLBiIa7sL1gMT2HsMA9avNwX2zTfDX/8Ky5aZIrWtDSIRM0+8M/5pebmZfv/9CAR/GxLm1iPaiGgCLBr4/aBZWBRZzWsnlTDzvL+YQjgcNve0VlZ+o/ak9kT2oZJ0R9rot4dLL32Rxx9fDpjd9yOPzOaSS8bu9pwVK1I7UvpvcjBepEih2g+EELS1teHxeGRQc0laIm1UkhZ0hpthxyJz1tSIg2pB2PMI+6fhGHQmimqHeBB2LoJ4u3melgH+w3A6iygujFG7dDvRtghoCrG2DqKqQLW5GHvRWFzHuHih7QUWvWh6240bcSyqhbyMPKYPms5pQ0+j2FvM2oa13P/x/XxS8wkAXruXOzoGcYS+EnX0yMQy2ZqGTbwyIsSiSit1mZ8Sx8DiU8hrqWb6P26h5coHqHJmMgKoN+IYwiAUDxGIttFmcyNUK6qI49+5FbsyiZasYvLaBO0d7bQH24kpMQLWAHaHHafbSZm/jAHeAWRYM2BTAJav2yUGKyrMWd09EQiYs751daZQnTTJ/L1ggTlzCmb7NM0sz243RedXX9Hhz+D/HRXihbJOz792eyKYntvm5rcn/ZaZFTPNYxP2RUF/PZF9qCTdkTb67eHYYwfy+OPL0TSFv/71TObN272/gqVL4eSTkx26F+3eVcNBQYiewbz3HylU+4FhGFRVVUlPa5K0Rdqo5JDTPdyMLdNc2qtYQcQQHXXoG/6CaHgDRbNBcDNggMUN3mGQUQ6qabe2DBuqpmDz2PCXZeLPD4JlKEddehkbYjv5xZJfJHnbtapWYkaMumAdTyx/gtc3vE5uRi6fbf8MIQRWzcq8kfO4ePBZeL93gxlArvMZWak1srB0DVXuGJnODMrjbqyoxDCos7fwl8b32FG/mrL8w4hrdrYFamgJt4CiEnPlIFQrmqJQgIrP78PQDCKWLLzRevyNFtzCTbOjmRGlI8jx5+Bz+LBpNgjWwNqnoWoRPFgHzm7La6dPT7lHFoCaGnjlFXOp8tq1pkOkjAwz7kBdnZln5kxz5rRr2W84DB9+CPE4QSXOEncTH2UDKOaS4IwMAEblj+LPM/9Mmb/sIBtKeiL7UEm6I23028OFF44hFIpTWOjm9NN3H6962TLTYVIgsCtt4kS45pqDXMkUSK+/EolEIkk/eoSb6XKSBIBiA3smqrERpf5tUG1g8ZjCNO8o0JxJRRlxg47/z955x0d1Xvn7uWV60YzKqCIQRaIbDLZj3GOcONhOSNmEdG8SssmmrON44x9pm07wZjfZOJvsOpviOL06BVzAjo1xL4CpEiChLo3aaHq55ffHKyFEsYUNljDvkw+RdOfOnXdGx/fqe88539OfRlEUSmYX4bIHYOYaOrUc6/++nrbhNuaXzkdTx17DqTkp95czlB1ic/NmHKqD6mA1N9TfwMcu/BhVgSpxyzkaFSWwQKeaYr3zSdq8BeYP6WiBMCCyFE40avQwuruOvYpOovkB9mJh2WBqTizdg6q7cSgaVYqCAzhcl2GoOEuo300+6cVtJch5cwSLg8yqmCUEKsDgHtixHvqbwR2G+XXgOcqw6AQ9sgDs2QPr10NzszA68nhEFra6WmRRW1uF0M1koKxMzEfduxe2b8fGpilksr3EYNYgXNWi8KvLQyKbCnxg6Qf44hVfHFujRCKRSF4xTNNC08bP7P7IRyZW0bJ+/XiRevnl8Ne/vno6NU48yVwikUgkkokyOm4mWD9epFoFiO1B6dmMw+gFxQWaF+reD6WXQPIw2Oa4Q6X609iWje7RcHJYZGarVrHxwEaah5qpL64fJ1ItLA4NHeK+Q/dxYPAATs2Jrum8bf7b+PrVX6fK9guR+tRTMDQkBBywkSaa81HqYxqazz823gWwgZSRIWkXMCyTeDZGQveRnX45emQRqqLgPEqkAqT8Jo+fN0hoUMNGxQ7Y5II5akI1YwIw1SlEaqINnPNhTg14R0bLOJ1QUwPz5kFbm/jro7NTPK+zU/zc1gbz54v9UinxvKIi8f3o1+3bxdcnn4Tt28mrNo9UFHiqLE9BhZhH4YouJz7bQdAV5P/e+H987bVfkyJVIpFIJoFYLMvll/+Un/1s50t6/tF9qfX1cM89E+sgOVuQGdUJ4h4dkC6RTFFkjEomhROMm8G2hFFSfB9YebDBchRjl56PYqUh2Qhzb4HG78LwXvFcdwQUB+neGF7/EKEqG8W3BOavI64F2NK8hbA7fESk2th0JbrY07eHZF70ugacARZGFmJaJrtbnybxP98l8OA2kakcGhJZx3iceFUJW2btIazaaA4XhIsBMC2LRD5BPBfHMg3Molos1Ynlq8BSVfyuIjSHFzPdh5obRneJ3k4sIAoPLRtmyfPlzD0QojnSRtAVpDZYO/ZZtW2EeDMo8yGowVEPHUHTxF8b+/bBpk2wdq0o921uFiJ1tORvdLK7qoryXr9ffB+LCUFbU8NAexOPVOZJ6NaRY/eHHUwftFhlzeLT7/0VtUUnWsS5iTyHSqY6MkZfXfT3p3nd6+5i+/YenniiA5/PwVvfOv8lH6+yErze07jAKYAUqhNA0zTmzn3hGnGJZDKRMSqZNI4eN2PbkOmC4T1jRkl6ACW0EJe7YkTU+YWIVVRYugG6NkHPZrHNMlBSgxgFL4Xyt8GS94K3mqauZ4imotSFRNnuYGaQXdFdDGQGAHBpLuaXzWdGaAYKCvmBKC37HqNxZyvLtWmi3HfGDHHrOZGgqaODaINJXdYjruyaSrqQpi/Vh6koWA4vbkXFzMRQMNEDVejxVubkhlngKyNesYTtPTsYyg7hwoVnwINaUGmZ7eS7Hz3Auq/FaOhtoKK2Ah++kRRtHA5sgXwYSjVYCnht6I2Kst9jMQy46y7RQ/rzn4ue0+5u8ZhpjrlmuN3C3VdVxzKznZ1kL7mI+2faGIURkepwgMOBYdtUe8v5j8u/ji5F6hHkOVQy1ZEx+uqiuzvBypV3sXdvHwAlJR5mzy6e5FW9PKTr7yRhWRZDQ0OEw2FUVVZLS6YeMkYlZ4xjRs0QrAfHUXVFo+Nm8gkY3gX5QbFddYl+Vd8MbCCXy+FyuVAUh9jfzIK3GmavJV6xiqa2BxiMRtnx2B6CvfP5wGf+RZTFAlkji2EZ5M0823u205kQJbGaojGneA71JfXo6sjlLJ3C8fwuDCtLdmYtmEeZEpWXQ3c32SIwVHCgYtsW8VyS/nwS0x0ChwdN0fDEhhkoK6ZysJHEtIvRbIhYBhoQ9hRzUfVFtHW30dneQYI4phuyZcWkco8z8MUAFx1YRvCRILQABpBpAiMK8+pgJpDphwd3nnyegGWJUTOf/SwMDAgB2tw8fh+/X/SZqqrYX9NE72oigTuZZfG05TzX9uQRB2Cn5uTSigup7s+Bz//y4uJVhjyHSqY6MkZfPbS2xrj66p9x6NAQAFVVAbZseS/z5pVN8speHtJMaZKwbZv29nZCodBkL0UiOSEyRiWnnZOMmsEdgYqVUHWdEJqFYWGiFN8nsqSKBoE5EKgX+wO2ZZNMpnA6XSgUxHbNTWe8k40HNrKlWYyaiUfjJMuTROoOoO4vOjJqxjANupPdNPY3jvodMb1oOvPL5uPRx5sx0dZGITGMXurFbThhtAU2mYT2dgDcloru0MlbBdKxAaJFAWxPKZqqoqMRjg+jB4MsrK1ldnQ3jxXPYjA0HUUdu2T6+nzM2z6P2fYsBouHaVnioEo1+E7xe2hw+eFa4EagEcgC+7PwIwNmGbB7h3DsBZHpPNF/t7YtyninTRMzUUOhcX20KArMnCmakdxukWH1+cZEq2kyv3w+valeOhNdlHlLuaz2MnzRIYgUibmokiPIc6hkqiNj9NXBgQMDXH31z2hvFw5IM2aEeOCB9zFzZviUjxWLHX//cjKR42kkEolEcuZ5gVEzZKPQfCd0bwHfdOj9OxQSgAX+ORCcD8eKx6PJRsEdYU/OYv3Dt44bNdPT1IM77UapUbhzx538/fDfWRxZzMYDGxnMDGLZFtOC01gYWUiRq+j4Yxfy0NFJ1KcQsbw0GCP7JJPwyCNQKGBHIkxzaoSTPXS6LcoyOZRgEU5FoTiTw5fLowcDsGQpeH34sjFqdt6FueiddEcWULAhcgAcu6GgQ3SWk9jcMhZpsA4YJ/8CwKhxo6bBUD/cf0AISRAlyfPnH3HfHUc+Dy0t8IEPwI9/LPZ1HmN4lM0Kh2C3W2RdvV4hcFUVNA1FUVgxbQVNA00siCxEs0bE7+rVrx5LSIlEIjlL2LMnysqVd9HTI1pj6utL2LLlvUybdoLr2YvQ3y9mpx48OLattPR0rXTqIIWqRCKRSMZ4sVEz7kooJKHnfvGYtxrCSyE/BOEl4/c/FtuEfIzO4itY/8R3x42asS2bTDSDbuvMqJ5BlCj3HbyP+w/eT3WwmtnFs8kaWS6qumic6+84hocxM2liJbA6W02goEJzEzQ1kbNtWhsaODx3LvlMivrs42wp66IykaNmcAiP24vi8Yhe1tpa8Ir5oqZlYvbv5mPTLyVs6WxuhJYsGHWgl0KkBlYrsAo4weRTwSOPwDe/Cb29QqRWVMCSJSfOpI4SjYpxM1dfDX/7m/i5pmbs8VgMHnqIoUKC5ypsrnaViTJiXRflvyPHdutuFpcvFn2tTU1C8K5adfLXlUgkEslp57nnunnd6+5iYCADwMKFEbZseS/l5RNrwzBN+NSn4O67ha1BMin+jVJaCl/5yhlY+CQjheoECci7z5IpjoxRyWlhdNTMsSLVtiHdIYySzDQoI5ePquuh/mOw/VbRy3rsiJoRHA4VEk3gr2NjCpqHmsfNQ033p7Esi4w/wxNDTzCUHUJVVAzL4PLpl3PrJbdyy7238GzHdmp803FoOkU+H07HWJbRLBRo8qaoM8pYtdfA3n0v/V4vLXPm0FVRgRUIYGCR1gyqlVKCDNBcaTK3Zj5KeQUUhUQp7ujxLJOmwSbqwnW8u+RKqj8Ba/ZAYx1k3w/upSKDetL/8tra4D/+Ax59VPxcWSk+xxUrhKA8GaY5lvmsroaVK+GnPx0xftJECfOjj/JMaY6PvK5Ar9fmnruHWKiWwOAgTJ8uXse2x+azxmJCpK5bJ44pOQ55DpVMdWSMnr3kcgbZrAHA8uVV3HvvuykpmbhF78MPw+23n/ixykrYskUU6LzakEJ1AmiaxqxZsyZ7GRLJSZExKjktnGjUjGVCrk+MkSnExDbNI0p8FQ2SB4W50oJ1IhN7zLgZ7AJqNkqRHQN/HfFZn2DL1v8YN2oGoKenh0OhQ6SKUjiyDnRVp6GkAY/uoXWgjT89s5tY+Aa6Er/kUPwQDkeQYCZIja1SFfCRtBPEUq3UDNtc2zzMVofGwCV1hPRyvK4gOBy4jAyF6C4CiR5qXH5WBC7jO85n2etJEnbmiKg2DtumYBWIpqLEsjHqwnWsm7OO6k9UQysEvLD8w8AlL/A5ptPwox/BL34h3Ht1Hd71LpHJ/NKX4MABMYLmRA6JJ8p8XnedKPFtbIRCAWvX8/xgqcE3LzIwRzxVbnx9hi1PeAlVVEBZmSgbHn3tSESI3lWrpEg9CfIcKpnqyBg9u7n44mn87W/v4hvfeITf/e4fKCo6tVFDvb0n3l5bCw88ALNnn4ZFvkzOhOuvYp+JzteziHg8TlFREcPDwwRPMiHXsiyi0SiRSEQ6rUmmJDJGJaeFgWdg+y3gKhWlvNleIVLtkZ5KRYdgA/hng6qJGanJFlj6LShZPmLANDJu5igDJtsVIe69iEDD23ku3sst999CXagOy7Zoj7fTNtxGNBrFtmycPiezI7OZVzYPl+YiGuvnscFmypfeyjT3THzxDnr6H6d98FniZowCNh4L5mVs/AMJEskB4k6brNuJqmiEbS9X5qq5rE8l1b4XgHJ/ORdWX4Sjq4fOIpVNH38dmzsfIZqKYlgGuqoT8UW4ZtY1rMqvovrz1TAQB28TfCwL9W4hNI+9Ztg23HsvfPe70CdGDrBiBXz60yLLCbBnD6xfLxwwwmEhIh2OE2c+FywYO/Yzz8A738lA9DCffL3F32stYah0VE/q2zMz+c7aP4i/XBobRQ+r2y2Mk2Qm5gWR51DJVEfG6KsD27ZRjjbGmyC/+pW43znK+98vLisf/ajoJpkKxGIxwuHwC2qqU0VmVCeAbdv09PRQVnZ220ZLXr3IGD1HebHRMRMlPwwDT0Hrr2Fop8iUHn0h1dzgqYbgXNCE8U+8kKcpFSMbH8TdvYN6fz3BkXEzTF8D8cYj67J8s2nZf5hFnirifQfoS/fRl+qjL92HjY1t2WBCOBfm4sUXE/KFAEil0+zKFMiqUBvrpzpUBc5SwlU3MCtyNcOpVrKpGAfKIuzz6GR2/5jKbp25bQOYjmI8qk1SzfJXfTtbAwXe4vNypbOexeXnoVoWxGJUr76RtSvWsiZ3I40DjWSNLG7dTUNJA4GHAvDZTui/A9gC3ih8/6gs5cqVIttZXS2E4W23wc6d4jOrrhYC9bLLxn+WCxbAhg2waRNs3jyxzGdnJ3z2szzhHeCj77Ho9YzcOBgVqU4nlwTms+4DP4I5I+J2+XIkE0eeQyVTHRmjZxd//OM+nnyyg29+c+U4YfpSROqJ+NKXhKXCVEK6/kokEolk4qNjToZlipmn/U9A/+OiXBcbjBTYI8dyRcBdLv45AkfEVmc2xcZoG1sGOojm0hhGBn3oB0T23c/KmSuPjJShZEwo2YbB/th+/vLIX7i78W7ahttwak5URaXYU0xJtgSiECwOHhGpAG3Dwww7VLwZG6c61otqWxZm1gKqSJXWkvDGSJXPoHToGkqDeygefgpnPI4ZDJBLJigzDLq8Fn9vcPEPuTmoBeu48tqAK8DyqpE128CPgG/vgZ714GqGxWGorBuf/bzzTtEYVFUFjz0mjJLcbuHU+573HO/SO0p1NaxdC2vWvHjm86mnMD/0QW6vbONbr0tiKQAj2RSPB8Xj5eaLbuKmK249ucmURCKRSF4xfv7z57nxxrsxTRu3W+fLX75qspd01iKFqkQikZxNTGR0TO9W0TMaOqp0NN0lROnAEyJ7aqTGH9c/U7j39mwR7r7+2uNeek9ikPWHdtCciRN2uKhz6jjcJRRK5hPNDHLnjjvZ2rqVdZeuY0FkAR3xDjY2beRvTX/jUPQQXq8X27YJOAOUeEtYHFmM3+mn/Yl2knYSX7nvyGvlC3k6VRUl04fXEabIW4sNJNJp4kDB4QCHgz5ngpyaJ5hKoVaeR73ZgXPJUoznnibZ0waahcOpsYRKWj1ZNg3tZO3B4MmNhfLA14C7O4VIDbXBlfNBP0oEOp3iedks3H+/6DWtrobrr4d/+RcoL5/Y7zIQEJnPeFwI5507hWAdLSv+1a/o+9K/8vGLBnikIj/2PEWBUIhIuIb/XvXfXFL7Qg2zEolEInmluOOOZ/nIR/7GaHKxrS2OZdmo6svLpDY1nYbFnYVIoToBFEWhuLj4tKXrJZLTjYzRc4QXGx3jrQFPpSgH3v1VqP0HSB4SmdN02/hjOYJQ8hooHfnnjojtrhJo/qkYJXPU8TuzKdYf2kFbNsl8fxgNIB8D30ycDi81Di+V/kr29u/loxs/SpW/ioNDYwPeAu4Aq+pXcUPDDTzd9TR37rgTj+7BtmzSfWkA/EfZ9A+nUqQ1BXLDVFe+AafuZTiRYHAkS6kALsUm7coSQMedjpEMVTGMD9UdZXt5lmLVQeWwSZXtR0/lCZkmm0tirFnxYQLXv+V4kToM/CvwHBDfCKXNcNn8402P+vuFqBwdBwPwpjfBV796Cr9MREnvxo0iKxuNjpUAl5ZCJsNTrY+x9vVJ+tzW2HN0HUIhLp95Fbe/4XbKfLIM8HQgz6GSqY6M0anPt7/9ODfffP+Rn//5n5dz++2rXrZI/c53RKnv0RSd+ujVM86ZiE0pVCeAqqrU1h6fXZBIpgoyRs8RTjY6BkZGkQwLA6RsFAa3iwyqe1TIqBBeDKUXi3/BuaCcwJCj6jqRkT1m1MzGaBvNmfiYSC0Mi5Jgby0WFtFklNbhVroSXaQLaVo9rZT7y7mo+iKuq7+OK2dciVsXLoflvnIeaX2EpsEmqu1qLMNCd+m4Qq4jyyiYBqlUG+WeKmpLXkM2FmPQ48FQLFQlj8flIKEWyCoGRZYTBRNL1ejPxWlsewRLt1DrKphffgF6KguGSW3OhdUbpLP8GuZ2V4u5MqMtvW3AvwDtgCsOs7aAOzxepGYysGsXdHSInx0OMQ/A5RIlvInExE2LjjVVqhspK87nsTbfT3eql/Yqi3BSoc89cvF3uVBDYf71ks/wiYs+gXqi35/kJSHPoZKpjozRqYtt23z964/whS/8/ci2f/3XFWzYsPIlibd77hEzUYeHRUdJY+P4xz//eXHZmGqcCZMvKVQngGVZdHR0UFNTI53WJFMSGaPnACcaHWPbkOkS/7JRsHJj+6uqKAeuuh7Kr4SSC0D3nfDQ4/BWHzdqJq6H2NLfQVh3oJlpMPPgCJAJzOXA4CHah9vJmWOvHXAFqPBX8Ou3/Zq6cN1x8VkdrGbdpetYv209O/fuBDfURGrAhryVJ5qK0p7swuOpZEHVO3AnVZp9Kj2uBMOONLZmY2FjYJNUCigqeG03tlmgZaAJy7ao9FdyQdUF6KpOKD2NhTsXMnfHXPQ+ncp7K8EHRICVQC1wGxAHKoEPNsF3ohCpG/tchobgkUdE1hOEsBwVqfm8MEVqbJyYiVFnpxCpbW3iGEeLYZeLrbXQmbSYNQSfeMLm61dAT4Wf8vJZ/OD6H/Camte8+GtITgl5DpVMdWSMTk1s2+azn32Ab37z0SPbvvzlK/nCFy5/SSL1F78Qjr6meeLH/+3fxL+piGVZL77TKSKF6gSwbZvBwUGq5fw5yRRFxug5QLxJiFH/UeIpvg/i+8d+VnRwlYkyXmcx5KJQff04Y6MJEVoASzccGTXT1LefaGaAOpcHFB8EZ5B2lvJQx9NkjSwALs3FtKJp1AZr8Tg8HI4dZiAzQF247oTxuSCygA0rN/DV+77KM/YzDBYNkuhPHBkNs3bpB7g/V0tBCdJMjH3+YbKaQQAdj6WjopBWDJJKgZiSJ+YvwZ/oJp9qYXbxbBZFFqGgUNlWybW/u5ay3jKSviQdZR3UTK8BJxAFvg30AeXABcB/AnuzQpA6HGOfyf79Yls4DEuXQig09pjDIR7LZif2+W7cKDKpx4rUEWZOX0L7gT4OhQ3qB+Gqbje917yR/7r2vyjxlpzSr1IyMeQ5VDLVkTE6NbBtaG0V9ycty+Yb37iXu+566sjjt956DWvWrODAgVM/9ubN8IlPwMnMczdsgM985iUu/BVAuv5KJBLJucboCJqBp8RsU3uG2J44NCZS/bPE+BhX8Vg572i21ZygeDqWo0bNZPf/BiP6XRzFs8AZJmdbbGt9mKyRJeAMsDCykHJ/OeqIG61t2xiWcUTEnoxQNsT5z57PAscCzr/lfGy3PTYaxuHD9T//w3+/popedw851aTUdo+7aLltDScqedvC8IZIN/6ZZcW1zCudJ44/EOLa311LSV8JXdO6SBpJnJqTIk+RMM6NI0TqaDL4i0AxwtBI14W7r9MJuRz09Ih9li07fn5qoSD2d09ggHs8LnpSw+ETilSA2qJpzK1YyP6e3QwHVD6anMvMlf+N6p2CTUkSiURyjpDNwlVXwRNPjG7JAEe7HK1iw4YL2LDh9Lze1VdDZaW4vLzxjfDmN5+e455NSKEqkUgkU5FjR9DkhiDdKoSr7hciVFEhOA+K5h3/fLsgxsxoExBPL4QjgLtkCbqrmIIjhIrCY+2Pkcwn8epeLq29FI/uGfeUglVAV/UjPakno/2xdgBq59ZySf1RzrWWBbfdxtx9+8gtqSURqaV8oBOdY+7W2qAZYFbU4xxowdmxDfylRx5e+MxCynrL6JrWhaVY5MwcM8IzcOKEp4EOhCvTopEnPADMRLjuRiLC4KimBtrbhfAPh48XqSD2i0TEeJkXo6lJ7F9XJ97nSUr4zq9eRspIs3B2PaW9CWg6IGejSiQSySTy+ONHi1QAL/A+4E7gSmDJaXutm2+Gb31r/BjucxFZ5D4BFEWhoqJCOq1JpiwyRl9lxPbA9luF+66REuW+xUvBGRJOu/H9Yru7QpginYhsVJQABycgnl6E+pJ6Ir4Ivalenux8kqHsEE7VySW1lxwnUgGiqSgRX4SGEvHaJ4vPUaFac3HN2EbbhttuI37PPXzjxncSa/8jvuEeUiV1pHylmIqGDRRQiHmCUDoXx1A77ue+j7+QoDPeScEq4E67mbdjHil/CkuxGM4NE3QFqXXXwiOMidRlCKEaBjYDCYQYXblS9KUaBhw+LNY2ffrxH45pQiwG11wzMSOl7EhZcTrN0L13jxkzHYOmaFw540pKiypPraxY8pKQ51DJVEfG6OSTSp1oaxj4GKdTpH7xi2enSJWuv5OEqqpUVFRM9jIkkpMiY/RVxAuNoHGWinmoqGK7mQUzfbxJkm0KQVuzWjjzvkyCriBXz7yar239GplCBl3VWVG7goDz+GOblkksG2P1vNUEXOLxE8WnNRgju2Ub5ekMdUUzRElsIAAbNmD//vd85aabaK1yYbQ2c0XbZvo8dXRGFpIMVWEqCpaZR09EKTu4mRlGDy2ZPobNHOlCmr5UH7O6Z+GP+WkrbiOdTRN0BVkSWILvUR+kAAfwGmDUFDkCtACNwHLguutg69axMTSaJrKr496sKTKkdXWwatXEPky3G2t4mOfbn2ZXcZ5LdzxEXfCNJ87UwqmVFUteMvIcKpnqyBidfLLZArANuAzQ+Y//GL1/6XjB550Ks2fDeeedtsO9okjX30nCNE0OHz7MjBkz0E7SUySRTCYyRl9FnGwEjZGCTOfILVZN9KQacUi1jS/9tU3R0+qvg6oJiqcJ0J3oJp1PkzfzrKhbQbG7+Lh9TMukabCJunAdq2aPvfa4+OzpgY0byf3uryw70IimQfj7T8EfIiJzePAgv77hBh66/nrU+G5qLYMSzaK00MysjlYGLDe7+5soGCmKlTQXVC5CcwWJVF9E23Abe/v30pHooLO/k0KugOJUaChqoLZQi+9xHxQQjr8rEONpRnEABjCauKyuhnXr4D3vEdnM0T8QbVuIx2hUZFLr6sR+EzE4sSy6Nv6GQ8m9ZDXhjvhESYbibQ9QdM31482bRjmVsmLJS0aeQyVTHRmjk0s8nuNLX/olYpZZFHgb11yjsWjRizzxHMI8mVXxy0AK1QmSSCQmewkSyQsiY/RVwIlG0Ixu738cbANc5aA6xBxTbEi3CzMlBVHum48JkTp/nTBEOg3ctfMu/tb0Nyr8FUR8EfrT/ZiWScQXwaE6KFgFoqkosWyMunAd6y5dR3Vw/GsnEgkxO/S226C5mWxcIeEsxV8bRqkrE40/HR3ESkr4y3XXQSjEe9Ju7lN1ClYBp+bEqZj0DTxOYuggAWeAC+uuPjJL1Of0Mat4FhYWH172YRZXL2b6Q9NpqGrA2euE7eLjohi4GHAd8yYLiCvi0YnLOXPA64WSEnHbvKVFiGldF+Jx9WqRSZ2ISI3Huf+WN/Mv3oe5rt7iHbsh6gNDtXkkFOcN+SzasUJ1tKx49eqJz2eVvGTkOVQy1ZExOjn89rcZPvzhXzA83DmypQUYZKwkR3KmkEJVIpFIpgpHj6Axc5DuEBnTwpB4XPNC5ErAFNvT7cIJeGi76F91R0S5b9Wq0yZSNx3YxH89+V8A3HrprVxddzWbDm5i86HNtMRaMCzjyEiZ1fNWs2r2quNEKoAjGkW5805hTDR/PrGH27DULP6KAOzbBwMD5P1+Oioree/3v89z06fzz6X1bPdFiKai1ARrSOQTHBo8BMDi8sVHROoo0VSUqkAVb577ZgJ1AeFv8Szi5jdADaIn9UTJiCii/PfoxOXWrcLxd8EC+NWv4MABkV11u0WGc4LisbBvN1//xhu4o7ILgAdnKlzcbjNrCFrKdGbPvBDV6x//pJdSViyRSCSS00p7e4o1a+7CtntHtniA9yBF6iuDFKoSiURyJhgdK2NmhfNusB4cJ+lDPPKcBOT6ITcA2V444nKrCOOk8GIYddItmgf+mTC4HWZ/GEouFMZJp6EndZTH2h/jyw9/GYB3L3o37138XhRFYe35a1mzYA2NA41kjezYSBnXyV878MgjKM3NsGABhYJNNiZqbH3RFmhrxgaeu/JKuv1+5u7bx2s3bcK9di0rZ67kpzt+SoW/gp29O7GxqfRXUu4rH3f8E/XGkgBaEVnS+cBc8VEehwnEgNWMLwf+y1/E1+uvh6Kil+S62/bHH/ORez/BjsoxM6SegMLtr4H/95yXN+qz8OUDopzY4XjpZcUSiUQiedkYhvDRA+jujvOmN/0M2x4YedSHcPmN4HTCjBmTs8ZzCSlUJ4CiKEybNk06rUmmLDJGpxDHjpWxDDEmxh2BipVQdd34bKdtw/Ae6PwbtP8eUq2gOsXoGUcIfNPBWwPasbWqiH5VV1iI1JLTO7pkd3Q3n9n8GUzL5A2z38C/vOZfxsVXwBVgedXEXlNJJCh//nkoLgZNI9UxDIDbzqC3HQag+bLL6CoqQgFqQiHcmzfDmjVcN+c6trZu5ZmuZ+hN9qKpGovLF487/nG9sYPAp4AuhEitAOo5uUhtAuqAoxOX0ejYHILrr3/hNxiPi+znaLa1vh58Pjat/wA39/+CeOiYsTqqytxLrueSz6/H98AjYsr7yykrlrxs5DlUMtWRMXrm2bpVnHqFUB0Cfoa4iwkQBN7HeeeVUF8Pa9fKjoxjka6/k4SqqpSUlEz2MiSSkyJjdIoQ2yMce1PNos/UXweKQ8w0zUah+U7o3QoL1oGrGLruEQI13Saeb5vCwddZIrKnL5aBPY0jaIAjgqu7r4X/fuo2tJDBxXMu5YtXfPG4MttTQT14ENfQkMhK7t1Lau8wxMHnToAbhi66iOfLRBnVIiAQiQjh1thI9fLl3LLiFq7/5fVkjSwzQjNwqA5s2z5xb2xfNdwEdAOlwBeAPwN7EVMEIgjjpAKi3DeGEKnrgKM14T33iDmn550HtbUnfmOdnbBxI2zZIoTtiNA0i4r4S+IpvtrQSzww/sLt1J185XXf5L1XfFJc1GfOhTVroLHxJZUVS04P8hwqmerIGD3zfPvboyK1HyFSR3uCw4hMaohbb4V3vnOSFjjFka6/k4Rpmhw4cIA5c+ZIpzXJlETG6BTghcbKKE6RFXWVwcDTsHU16B6ROQVRGlz+WpFtHdoBLXceP3LmWE7nCJqjBFe+u4PB6H4+ZBcwyopZ8p4GHD3RU8/s5XKwaxc8+yzW3/6G/eyzqB4PKArJRDmg4PdB/vwLeLK6GhuoAmYBcadNk3eIbM9TuLvgyY4nKfYUE3aHqS+pP3lv7N5quBUxfqYW+M7I1xXAJsSc1BaEu6+OEK2rEZnUo9+ebY+V/b7xjSd+f3v2wPr10NwM4bAo03U4SHS3sWfHJmoMg8/1wO2vgaZSIVbrXOXc8U8bWVCzdPyxAoGXVFYsOX3Ic6hkqiNj9MwTj49+93fGRGopQqQGCAbh0ksnY2VnB9L1dxLJymHrkimOjNFJ5mRjZWwbclFhfpTpEqXAZhZcJVD1Bqi+XohU3Sv299ZA9BHR3xqsH3+sI8c8jSNojhJchaIAj+rdDEVUirRiLnM34Pz5r+DRJ0Sv5IIFJz9OPn9EmPLMM+L7QgEAJZUS3bYuF5lgOVbegep24b7hYp5SFdKAFyhXU/zQ3cYWRxtRTwyj+X+xen9O00ATPoePr1/9dd7U8KYT98b+EfgmYAHnA/8OFI2srRpYC6xBzEnNIkqCGxjfkzpawrt7N+zdKzLA11xz/Hvt7BSfWVsbzJ8vZqwCHQMtbGt9gELIQrVg1hB84gmbr18BF8++ig0fvxv/C/TxSiYXeQ6VTHVkjL5SvBG3e5iyMpNPfeo9BAI+dB2uvBKmTZvstZ1bSKEqkUgkL5cTjZWxDIjvFxlW86g/LhwB0aPqmw5L//34bKi3WpQG71kPw3vFMd2R8SXEp2sEzVGCy5zbwGNdjzNkJnE7PLxmxmU4Hb4x99n162HDhrHM6rHCdPduse1oyspg2TKsuXNJ3nEHAb+fVMIN/f34qoK0qApdiNbRoD7IF/w7aNbihNM2dXYYR/X5PBF9loJVIGtkuefgPSytWDq+N9YCvg38YuTn64DPAc4TvN8AcKLE5bElvC0tMDgoeoB//nO47rrxGeWNG0Um9SiRCuDxFmG6dMjnsVQ4FIaGQfiBcgMX3ny37C2TSCSSswIXF174bu6+G8Jhz2Qv5pxGClWJRCJ5uRw9VmaU5CFINInv1ZHSX+90MUbGLkCyBeKNJzZBCi2ApRugaxP0bBb7Hm3KdLpG0IwILmvePJ7qfpqB9AC6qnPJtEvwOUZKjzVNmAPt2QP/8z/idvKzzwqReqwwLS0VJazLlol/06YJsWeaDDc2EtyyhWS/OK5VHWTX6NPUFN/376BNSzK/EEJLDkPDNPqNON3Jbpyak8umX0b7cDvrt61nw8oNYgROBvg88PDIgT4KfIATmyadjGNLeGtrYf9+cDqF+dOddwqHjdGMcjwuBG04PE6kApR4illW+xqePvwYGAYB1UXD7KUE+l2QTMq+U4lEIpmCPPTQYebNKwXGxoQ5HB7C4clbk0QgheoEUFWVmTNnnpEmYYnkdCBjdJIxs0JIKo6xbbl+8TVQD8F5oB4tahxjJcAnw1sNs9fC9DVC0B4Zc/PSR9DEc3GaBppE2WzWoP7BewiEw+zoe57uZDeqonLxtBUUuYtEJnVoCPr6oL8furuFgJsxY0yglZaOidLly8eE6TGoqkr43e/G3H8A9+5nSfkq2VvhwwIqgV3uNpq1uBCpw3EIBrCnTWNn75MA1IXqKPGUEHKF2Ne/j00HN7F22lq4GdiHyJ7+G/D6U/xATlTC294u3rvfL7ZZ1viMcne3yLrW1Z3wkA0lDfQmenDE4lyw8PU4bOWIMZTsQ526yHOoZKojY/TM8Ne/NvK2t/2OhoYSQqH3IxpRJC8FaaY0SSiKQjD4Iu6bEskkImN0ktHcIttpF4Rxkm1DblA85q0+RqQi9lN18bwXwxF42aNnOuOdbDywkS3NW4imosKIKJUhUtLOQo+fyo4YJehcUH0BZWng2UdgYECItFFUVbyvJUvghhteUJgei6IoBObOpfXq95F/sAU9lMDX3YUWiTDHafNtRxvhtC0yqcEA1nnn0ZTpYDg3jEN1ML9sPgCaqhFyh9i8YzNrvriGQE8AQsB/AotfaAUn4UQlvK2t4uv06eK9jWaU9+2DTZtg3jzMQg4lk0F1Hl9frCgKl864HG3UJdm2hRuw7C2b0shzqGSqI2P09GBZY5e23/52N+9//58wDItdu6LU1j4OXD2p6zubkeNpJgnTNNm7dy/z58+XTmuSKYmM0UkmWC9KcrNRUeJrJEZEqwaOouP3P91jZV6APdE9rN+2nuahZsLuMHWhOhyqg0Khkw6rkV+GBom4ND6XWka1IwIP3zdW0utyiT7TsjIoKRHZxg9+cMK2h/tycX6b7mfINMj3D7A8ptP4jptwzB7kyice5uKWFvZ7h4h6YtTZYQpzKmkL2jQNPkXGyAAwv2w+rqNmyEZSEVr2ttCYaWT5jOXC2bfmJXwwJyrhTadFthTGj6TRNAiFYPNmWsucDHVuR2t9lkUXXi8+m2PQjh7lUyiI2ajuCdyUkEwa8hwqmerIGH353HwzfP/7wpQetgN/BUbnXC+ire3KyVraqwLp+juJnIkPXyI5ncgYnUQcQahYCc0/BU/lWDbVGYZj54+ezrEyL0JnvJP129bTNtzG/NL5aEdldmP5YQKJHLUFjcGwm7uK+li43aY6nxdlrxdfLL6O3iHN5ycsuDYle/lyNsYubwl5bxnYKngr+dHaDMpwlMpgmIVr34e/sZFsz1Mkm77LbpebtswhrKS41e3SXMwuns3M8MyxAzeDY6cDw2+QXZCFryFmsL8UmprGl/DatuhXBSE+fceMB4pE+M3wY3zj4b/wVVcOrwqlTz5A5WvfCN4XKBWLRiESEbNRJVMaeQ6VTHVkjL502tvFnFTBU8A9Rz26FLgeGLteywrrqYH8NUgkEsnpoOo68M0Uxkq5PrHNecxw9tM5VmYCbDywkeahZuqL68eJ1L50H0+lGsk5VYrxcJ5SSYsaZ5OxT+wwb54w/jm6jGeCguv2WBtvR+GZQA2W4SDQmyXYmcTfk0G13RiRWfTgojXayf3hQW5L3EtjrpPmVDuWbRF2h1letZxrZ19LQ0kDyqgz0vPATigoBfQSHfct7pcuUkGU4hoGOEb6ihsbxV8yigJz547bNaUU+Bf/I3xq1gH69DxbZ0BRDh4ripPZ9vfxJdJHY5oQi4kRN9JISSKRSCaNoaHR7x5lvEi9CLiBYyXRa1/7iixL8iLIjKpEIpGcDo4eK9N9D9iGKPu17dM/VmYCxHNxtjRvIewOjxOpw7lhHu94HEODfEWEYDSPYkMoabC5KsOa9iICNcfU0o4KrtWrX1BwbUr2sk53k9N9BHuSaIaCrdqgg21bOJIZHPEM2dIAX3UXM/PPG9DUdhyqg7A7zNKKpYQ94TFxCmAATwM94sdofZTIzAgN5S8zQ+l2iwxxoSBE+N69YvuSJePKeffpQ/yTazMHtWHxu1RVHpwJF7fbzBlSMBpqT3zrfXSsT10drDrzNyUkEolEcnJs2wYeArYe2fba117K61//2uN6K2fNEpc7yeQjheoEUFWVhoYG6bQmmbLIGJ0ihBbAws9C3yNitmphGIaHT/9YmQnQNNBENBWlLjTenXZ3dDeGZVDqLWV6zVKUp5+GoRiRVIaWgEXjkhqWH33RPgXB9eVsjEygZkyk6jYoYtSpNSI+FcXANTBItrSEVO0HuUXbRSaU4fd7f0+Rq2i8SM0CjwHDgArmcpOYI8bqWasJuF5mhrK+XmSIDx4U7w9g9uwjpcA2Nr90HeDz7sfI2QUhUkfoCSi0zixmtbUcLRaHjg5xLIdjTPjGYuJY69aNn8EqmZLIc6hkqiNj9OXxwAP7OVqkvu99r+XOOy+bvAW9CpGuv5OI8wTujhLJVELG6BQhNwDuMggvgYVfOC1jZV4KWSOLYRk41LGROYZl0JcWZclLK5aiOQOwZClsfRhHLo9RpJItDgpRdoqCa18uzi5vCY6ccUSk2tjYto0xKlJNGxQbFQWtUCB6/gKqNjtZfkk1z3U/R9Ng01iZcgx4HCFWXWC+xqTJaqKuqI5Vs09DhjIYhAsugK9+VWRES0qgogLyeZIuhc94H+Vux6HxZb2Kgr+g8K3YBbzxp38VjhybNsHmzWIEjWGILG0kIm7Hr1olRepZhDyHSqY6MkZPnUOH4Pbb4cCBuQh7+OeB1/P2t79mklcmmQhSqE4Ay7LYtWsXixYtkk5rkimJjNEpROx58bV42cseK/NycOtudFWnYBVwauKPm95UL5Zt4Xf68TtHBpuP9KIWPG50l4a7OQpDiVMWXD+NtZMrqsU/lMbEwrSE6Yc9UnasWDaqbaNqOoqioKazpIN+7h5Icq1SyrpL17F+23r29u8lnA4T2RXBYTgoBApEz4sSM2LUhetYd+k6qoOnQfw1NcFdd42NjXG54MknGfZq/GDWIE/UpSEwkt0dyaYuGnTwv9X/xIzb/mOst3XtWlizRvS4ZrOipLihQfaknmXIc6hkqiNj9KXx1rfCzp0ACvAmhFidNalrerVincyv4WUghapEIpGcToZ2iq/h8yZ1GfUl9UR8EaKpKDVB0XPanegGoNpVhtLfD4YJnR1QMIhW+Iksu5iGd94Ehnac4MrFcww0DWBkDUzdpL+kn8ZMI3uie9jdt5unKpdjX3Qz5E1MffRipYz8A9W0UTXlSC+QYtnYqkLSgIHGARYsX8CGqzew6Zeb2LxrMy2uFowyA32mTiQQYfWs1ayaver0iNSdO+Ef/gG6uoS7b1ERdjrNAW+WdjvG1btt5rTB7RfZNJWKp3zgYIAvvvsOnP+w5vjjBQJirqxEIpFIpgT5vMnhwzGef/5oU0OVUZEqi13ODqRQlUgkktOFZcDwyIiT0OJJXUrQFWTlzJX8dMdPqfRXoqoqscFOZvRlmd3aBfkOsIRJkqnYxGpKWF2+gsBrrhh3nFhHjCd+/wSN9zUy3DNMKpMiY2fIBrL0z+0nuihKNpxFK02j2DaKpqMqJtiiN9VGQbFsFAWUo/pXbFUB28KVKmBkDTCh+gfVrP39WtZoa2i8oZHsu7O4XW4aShpefk/qKB0d8P73Q3e3EKlXXklegycOPUxrLga2TY8XZg3BJ56E/1qh8P86ZrDqW3+GRYtOzxokEolEcsbIZg3e9rbf8sQTHdj2jUAEgNJSIVDf+U44b3LvJUsmiBSqEolEcrpINIGVE3NVfdMnezVcN+c6trZupWmwiUjeSf3BGP6shTOkQtAH8QSmAk3FUNdnsOpnjzNUtI2dpQZ7onvY//R+Cj8v4Iq6KHgL5AI5bL+NYioE0gEWbF/AxYMXs+yWZYQuWMCl+Ty5oBt3LAWArY1kUxVQNJVxPkk+N850nqU7B9BX6nAToidVgcAnAyx/1/Jx+582vvQlYaDkdsOFF0IohFFI06OkjpT4WiocCsPSKPxp90JK7nkIiovPwGIkEolEcjpJJvO86U2/5sEHW0a2/Br4GKBx003wuc9N3tokp44UqhNAVVUWLVokndYkUxYZo1OEoZH+1KJFoEz+76I6WC16P+//Ant2349fLaCHisDnJW9Z9BqD9JeaVBDgut4QQ3sfYuf+h7n9LdUkCDLvj/NwD7pJV6cJe8NM80yj2FNM2B3Go3uwLIvBxkE6vtHBYGSQ8g9W0HHRMmxbQdFsUBUUBVRlnJcvFmA4Hcx94jC1loOSb5dAG+AGvgZceYY+kHvugT/+ETQNFi+GqioAvA4vl8y8kgeb7hMmUkBDXKehaAZabcNYP6rkVYs8h0qmOjJGX5zh4SyrVv2Sxx5rB8Dvd5JMvhGQPb2vBNL1dxLJ5/O43e7JXoZEclJkjE4BRo2UJrk/9WgWRBawIXERP957H/fM0OhyF2i3OrHzOfyqwbIulfPTCq5cjAOlKjO7s6xucdEbeB2evIfKiyoJeoPHzZmzDIvY4RixthiZgQyeEg83eNP8eEE96fIg3qHEkYyoAmBzZFRNqjiAN57i9Xc2MuvgLFxeF5QC3wbmnaEPorFROBcXCmI0zezZ4x6uDlSxoPI8DnTsZEW3zrTzLhNCtqVFPFf2oL7qkedQyVRHxujJ6e9P8/rX/5znnhNeDKGQm3vueTcrVtQcPV1McpYhheoEsCyLxsZG6bQmmbLIGJ0ixEaMlCbQnxrPxWkaaCJrZHHrbupL6gm6gqdtKdFUlN3R3TS1PMOSu77PBQNZimMKybCGodo4EhbVcZWwO0xxcRXFRcWEPcWEgynm9ob4S+8c8lUWQd/4NRVSBYYODRE7HMMyhGmS5tbwlnj58mdvoDbdz1ctjVRJEWo+jzOdxTZtTEUhH3BjOB144ynWfO1JLnxAY3blbJgDfAcoP21v/5gPIwqf+hRks9heL8rcuaAcX1d8XuUSGoJ1+OYA4bAoBTaMMWdgyasWeQ6VTHVkjJ6cnp4kK1f+jD17xPi10lIvmze/lyVLKiZ5ZecW0vVXIpFIpiqZXsj2AioUzT/pbp3xTjYe2MiW5i1EU1EMy0BXdSK+CCtnruS6OdedsrNtupBmb99e4cAb3c3uvt30pcQFe97hFEuiUaJFCkHbyaIhL8X9KcJZP8WOAJ4L3jBetOlBos/3k6Kf0OJp415n6NAQvc/3iuwo4PQ7KZ5TjL/Cz3DbMJnBDLcsn8O0XQf54t4uOufXkAv6yY0YJznTeeY+fpjX/28jF27TuLTiUoJXBWE94D2ltzxxMhm4+Wbs7i7+WD7A4sEhZj/7LMoVVxy3q6ao+PzhsQ2FghjTIzMYEolEMiVpbx/m6qt/xoEDgwBUVvr529/ex5YtZfz4x8hs6lmOFKoSiURyOhgt+w3Wg35i1bUnuof129bTPNRM2B2mLlSHQ3VQsApEU1Hu3HEnW1u3su7SdSyILDjhMUzL5NDQISFIo7vZ07eH5qFm7GOuxqqiMrt4NtcU/ASUbjyqwpI+F3PiBcAJfj8sW358ZtHhwCjYWJiojqNcek2bvj19YIO3zCsEarkfFLBtG8uwhHsv8PZFs7mzOM6MzfspHkhSMEAdSnPhnmGmNzuZlZjF7OrZBN8ThE9z5tqHLAs+9zmGnt7KTed183ilybd6bDzRQ9QMLnpxg6RoVMySbWg4QwuUSCQSyUslmcxz+eU/5fDhGADTpxfxwAPv47bbirnjjsldm+T0IIXqBJFlFpKpjozRSWZUqJ6k7Lcz3sn6betpG25jful8NHXs9+XUnNQEa6j0V9I02MT6bevZsHIDVYEqelO9QpCOZEv39e8jaxxfilrhr2BhZCELyhawMLKQuaVz8RRsUt/8KvuzSVwpqEx5hECdOxemTTth+SuFArpDQUXDKlhoTrHORGcCy7BweB3UXlo7zpHXKliouoruFpeUFiBaHcT1/gv5QyLH0N4ozTuamdW0hDJHGa5ylxCo73hJn/TEsG342Md4esudfOTqDN1BFVDYOsOmOmHg2/444deuOvFnAGCK0T2sXn1klqzk1Y08h0qmOjJGx+P3O/nEJy7k05++nzlzitmy5X3U1hbx9NMn3r/8TLWXSM4YUqhOAE3TWCTn50mmMDJGpwBDo/2pJzZS2nhgI81DzceJ1KOxsAh7wjzR8QQ33n0jqqoykB44bj+f03dEkI6K0xLvUUPN02n41e/gZz/jCaUFywPVGR3/0gtPLlBHiUYpqQ3go5RUNEWwRvSoxlpjABRNLzpubEwqmsIX8VHSINbwzMj28wB/wIV/2jSmfWsatAJ+RKnvpSdfwgsSj0NTk+gbdbuFMVLwmN7eZ5/F+uhH+L7+HBveaGGqYwt+cKbCxe021YmUKO11Oo9/DdMUr1FXB6tWvcSFSs4m5DlUMtWRMXpibr75Ynw+B29601wqKvzHPe5yQUkJXHGFmJ8qOXOciRspUqhOANu2SSQSBAKB45wvJZKpgIzRScbMQqJRfB8+PqMaz8XZ0ryFsDs8TqTG83EG0gMMZgYZzAySyCcAyJt5BjIDzCiagVN3Mqd4zjhhOj00HfVE428yGfidEKjEYgA8eIGOJ1jMB5t8YtL5C8XHSBbRdeNqZtr17PjpDvyVfsycSbovDYwI1aOwTItsLMu81fNwBVwAPDvy2HKA58H+tI3Vb6FWqijfUaD+RT/R4+nshI0bYcsWUZJrGKJ/NBKBlSvhuusgl4P16xm494988jVD/H26Ld7vUe/ZCBcx/dbPULF5j3DzDYfFMRwOIVyjUfHZ1dUJl+DqU+sXlpydyHOoZKojY1QwPJylqGi8b8A//dPJXdlvuEFcFiVnnmNbkE4HUqhOAMuyaG5ulk5rkimLjNFJohCHeJNw+y3EwVMD7jGXwVFn3x09Ozg0eIh5ZWL2io3N3r69NA40HndIr8NLpb+SglXgXy/5V9467624dNcLryOTgd//XgjUoSHiuknTnCDJN17LvfHfUzyk8zFmiCxhfb2YI3osx2QR5xCgdWsrg02D2Ja4+HjLvDi8YzNFLdMisTdBXVEdDaUN8AzY9fDsSILzivuBLwF5GK4cpuhHRWiVLyE+9+yB9euhuVkIy7q68cLy//4PvvtdGBjgibIcH70+Rq/vGJHqcHBJzcV8772/ptxfDis7YdMm2LxZjKA5WviuXi0yqVKknjPIc6hkqnMuxWhfH3R0HL/9mWcOc8stv+ErX3kzl19+8jue6fQZXJzkpEjXX4lEIpkKpDuhayP0bIFsVPyc7RF9kYd+SHfgfP7a8dwRZ9/BzCCtw60MZYaoClYxlBkimo4CEPFGKPYUE/aEKfYU49Jc2LbN3v691BbVvrBIPUagdrrzbDxPZctiP9EgxIZ/w6GhQ3h1L799/9u4/g+7qN67d0JZxCBw6bpL2faNbRy45wC2aROsDgrjpIKF1WZRdriMZcYyIoUIzv9wgg6pCFy5EoIJqPuVWKZ9qU37O9opihSd/L2cjM5OIVLb2mD+/PEiW1VhcBD278fKZmkssfn4awx6fSOPKwpoGkogwM1XrOOmiz81ltGuroa1a2HNGpFZHS0lbmiQPakSiUQySfzkJ/CRj0A+f+wjB4HfAAY33fRb4Eag5hVeneSVRgpViUQiORVie2DPekg1gzMM/jrIDoDqBM1DqvH7HEoM83C6iJSrmrpQHWF3mGgqStbM8mz3s9i2jc/h48LqC6ktqhXHLeRhaBgMk4JqoQNu/SRjUbLZMYE6KCz598wKsP4Sm2ZfjrC7iDpfhH39+3BqToLuID/r28Ij15Sz7qLXs+ChPRPKIkYWRFj0nkW0bmvFSBsYOYP+vf0U54pZFl1GiV6Ca7YLR60DHEABEr3woa+CPw1qBfAhsD9uY+95iSVBGzeKTOrRIjWVEgI2mYRdu8g4FB6bbhJMW1xxGH61GLGv30+kdDr/fd33uaT2khMfPxCA5ScvG5NIJBLJK8Ptt8MnP3miR/YBvwdGM3YzgYnNSHW9SEGSZGojheoEccs5epIpjozRV4B0pxCp6TYxK1XRRBa1MAiKSspdzVPR/RQbg3zcp3G3O0xMdRJyh3BqTvrSfdi2LYSq0ycMkNIpkS3s6BQZUtsi6i4QcXhpKDwGN1SOicdsFv7wB7jzziMClepqOt+7mvVspi3RwfziBWiqho1Nb6oXVVFpKGmgwlchHIUrDrDhO1+luisxoSxi55Od+Mp8zF41m7lvnIvdbhO+I4zb4Uadrx43WkZtAWcGnHmgBHg7oL7E+IzHRU9qOCyEZ18f7NoF3d0iE2zbdHtMHq22yDjAMuGKVvjL+V5SpUEun3EFt7/hdsp8Zaf+2pJzDnkOlUx1Xs0x+s1vioKe43keuJsjA7yZD7yFicw1UxRRNCM5e5FCdQJomsbcuXMnexkSyUmRMfoK0bVRZFJHRSqAkQIrD4pKW2aY4XwCzVVBlT3MAqONR53ziGVjxLIxDNPApbso95WTKqRo697PvEPDQpC5XBAMYKoKMW2Q1V0hAnf9BrY9BTffDPv2jReoVVXwoQ/BqlVs3PljmnccHuconMwnSeaTqIpKua8cTdWoL65nX/8+NvVsZe3ytS/6dgvpAs1bmgFY8LYFlC8uh+eAYcTfCkf/nZAE+zFwJaHggPQKcA4Am0BbOxKfE3HsPZrGRpH51TQhTB9/XDxX18HtxlIVnq1Mkhlpm+33wvSkypycj2svW8fHL/z4iU2nJJJjkOdQyVTn1Rqjtg1f+AJ8/evjt3/601AoPMvtt/+NUY+elSvP46ab3oimTey8PncuzJhxetcrOTnS9XeSsCyLoaEhwuEwqir/6JFMPWSMvgIU4qIn1RkeE6kAOTE+Jq8X0ZHowqW5QFVJW07mm538IabzeM9udFXH6/Di0T04NAfOgkZnVyOzU14c4TAoCiY2TfowdWYRq7znQb1DiLPrroOyMjFK5SiBiq6f1FG4O9kNQJm3DF0Vp3pN1Qi5Q2w+tJk1C9YQcL1wL2bzlmaMrEFoeojIogjEgS1AmPEidQB4XOj1jBd2XwyvLQJMYDNYl7aTvvf3+B57DKWv78SOvaNZY9OEZ56Be+6B3/wGDh0SvaijYtXnO2KQpAKX9jjZVJ3BVMFQwZO3+ffaD7HgohPWj0kkJ0SeQyVTnVdjjNq2uA/7ne+M3/6Nb4DX+wQ33XTfkW0f/ehyvve9Vajquet4PNWRZkqThG3btLe3EwqFJnspEskJkTH6ChBvEsZJ/rrx2/NCqA4rHjKFPoIj4i+huAkUBkgNDGDjoC5Ux4zQDJ7vfZ6h7BCOTJ6UlWUoVEzItoiqWWJqnjozwLrhxVQf6BbZx0xGZBEjEXHb+brrhMgboWmgiWgqSl1o/Lq6E0KoVvjH9/FEfBFaYi00DjSyvOqFezMb/yJcietvqBfjEJqAKDD6UjZwANgLWJAOw7MXQ5F7RMdGgN174FPfgO7d2DU1KMc69t55Jzz0kBCs+/bBffdBf//IZ5sXorRQEP8CgfHjdUyTUDrPharK49UWtRmdhf0Wji074VMv+NYkknHIc6hkqvNqi1Hbho99DH7wg/Hb/+u/IJd7lJtu2nJk26c/fTH//u/XnNNjec4G5HgaiUQimSzMLFgGKGPjWbBMyAhBaOgBbLsXFXGn20Qlb6RxKy5mF89mUWQRCgoXVV9E22ALHYM7SOhwyE5SbBWImB5Wp6azqsmmevdTQpyCyCDOmCEceV/72nEiFSBrZDEsA4c6tq6+dB8DGSGgKwOV4/Z3qA4MyyBrZF/w7Q63D9OzowdFVZizas7IiwEGwjgpiRiYOjDyhGrYvxzyGpSOHiTfCYfXQ76N7KxZeEtLx4Smoojs6dAQPPcc/OlPogz46NIhXRf7Wdbx818tS4h4YFZSx93noDoOimrAjh3Q1SWyzxKJRCKZcjz11HiRqijwwx/CBz8I995bjsOhUihY/Nu/XcG//dsVUqSeo0ihKpFIJBNBc4Oqg10AxSm2pdvByoHmQXeVoijNWFioqJhmjpxlkMfD3JK5KIiLrM/pY55eTu2gj31hNx/NLGCJUUqDUUTgqZ3Q3i6O7fWKBpvaWlEq29IiejaPcah16250VadgFXBqTkzbZHvPdgBmhmbi1b3j9i9YBXRVP6GjcC6eY6BpACNr0PjXRizTYvqK6fgiI/Ne3IirxgGECaMJeTcMLwWjAjoU4cl4xLqoZSPkm2HGPFCHhbjs6BDvpatL/AziLxTDEOLc5xtbkKqCqpLX4PlKhaXJkUytbUMuJ56vqiguNzVpBcycELuplDBhet/7Tv33LJFIJJIzSjQKO3eO33bHHUKkAlx77Wx+85u3cejQELfcsuKVX6BkyiCF6gQJyLl6kimOjNEzTLAe3BFR/uutEWIpcUA85p9NkSeMx+EhU8jgc/pwFIboM1VS7hqcmnP8sQyTIb3ALCvMO7KzCNhOUeY6OuF8yRKRRR3tQ3I4xoTcMdSX1BPxRYimotQEa9jfv59kPolbd7MgsuC4/aOpKBFfhIaShiPb4p1xDmw8QPOWZlLRFJZh0bevDyxQrlCId8YJVgdFb2oH0AepILTNh446yOgi0RpDCMlewJOP42vZAt4whDWcSVAefBB6e4//bBVFvNd8Hjwe8f28ebBqFdvaH2Xonj9RlrZ4vijD0qgmPgvD4IjDRjotjuFyifLgvj4xukYiOQXkOVQy1TmbY9Sy4K9/Ff2nTz117KM2l1wyPmP65jfPe8XWJpm6vDq6sc8wmqYxa9asM+JmJZGcDmSMvgI4glCxEvJDYJuQ7QUjAYoO/hk4NSc1gWpyZg7bMnFZaR7KOYiEZh13KFNTiDktrklXCpEKYuSKbUNREcycOSZSQfRnjjjdHkvQFWTlzJUMZYcYzAzSNNAEwJKKJePKgQFMyySWjXHNrGuOGClF90TZcusWdvx0B/lUnlBdCE+JR2SANTGeZstnthD9QRQ+CBQg5YSnVkDjbDB0CAJOxAXlSMJ1sAkzHYW6CKpLIVhcjPJCBiCqKrLI738/PPYYhfvv5WsXZHh76d/5jxXQGQSjkKdPzR5fCmxZoozYtoWAVVXw+1/0VyqRjCLPoZKpztkao4YBv/gFLF4sxnUfL1JN4E/8+MfbXvnFSU4rZyI2pVCdAJZl0dPTc0bcrCSS04GM0VeIquvAN1MYK8WF0RD+OhgRhLVFtRQ5A/iyHRwuKDxmFlHmHT/D07RMmqwodXaIVe1HCc/RbOqo++3RRKPCTKmh4fjHgOvmXEdduI6trVuxbIsqfxVV/vH9maZl0jTYRF24jlWzVwEik7pt/TaG24YpnV9KsCaI5tSIt8VRVIXiWcWUzi5l+OFhtn1+G/HBON3XwPbXQnE3FFvgQ1xIsoACBIBiE0KHsySdBqk6B7Ztk85ksC+5RIjRURQFKirgggvgLW8RWdQbbqCjWOctv30L33/6++By0lSm8vVL4dcLYF/pyDS9o00bXC5RMmxZImPr9QpzJolkgshzqGSqc7bFqG3Dj38sLlvveQ/s2XOivQzg98AuvvWtB7j99idf2UVKTitnIjalUJ0Atm3T09NzRtysJJLTgYzRVwhvNSxYB44iSHeAVQDvdHFFtvL4jCEuDPjpMDVui2lkHSUUzAK2bZM383TEO9jXv4/a4pmsm/2PVEczIhOYzwsxCscLVdOEWAyuuUaUtZ6A6mA151ecj2EZFMwCEV+EvJk//nWLall36Tqqg+I1Dmw8wFDzEMX1xagjc+msgkWiKwFAsbcY9e8qxdlihvJDHFx6kL/eAT/4IqRroXovhDpAy0PWBj0PVR1QtQ/SVW66Zuh0OAvYIISqywWXXQY+H/FLlvPMu65k26qFPLOwmLjTBl3n8b7tXHPXNTzb9ax4c6oGmkZPAIaDDpakAigejyiHVlUxssflEiZMo27C06dLIyXJKSHPoZKpztkWo7fdJnpOm5vHb3e54KMfhZ/8pMDixb8G9gPgdGrMmBF6xdcpOX1I11+JRCKZbEILRBY19jzoPsh2C1MlVQd3hGztO/le+0/pc2Q4L1RHS6wFwzLQVZ2IL8LqeatZNXsV1Qng8YNiBI3bLcRuMDhejJqmeLyuTsxNPQm9yV7+3PhnqoPVrJi2gsHM4Mlfd0Sk5uI5mrc04w67j4hUgHhHHEyoMCtw7hZlyWqRinuam120cr95HpkFGndvgAWbYP5mCLeAZoCpgx2Bx68vcOCqeq75YgRvNErhKPHdWe5l4zsb2OJuJ6plMbDQUSlTbRZUwZ17vkLOc1TJsm3jQONLW21u3GGjeBBl0IYhMrKjJcCjLsCj2dVE4qTCXiKRSCRnlvvuG/+zzycE6s03g9+f4/rrf8Xzz7cC4PU6+POf17By5cxJWKlkKiOFqkQikbwYhbgo9zWzYCSh71Fwl8GFd4Btie2aG4IN/OK5nxBTfaye+3q+etVXaRxoJGtkcetuGkoajvSGEgTWrYP16+GBB0RWtaJCCNbRGaOxmBCp69aduCQYcQdzw6MbSBfSLK9azvev+z6pfOrkrzvCQNMAqWiKUF1IbLBgsHmQ5M4k1fFq3G63GEMzB5gHPtPHdqdGZ8ZgSSZFUXcTPfOy9Na76bbradKDeFw2N+z8JRff+T88t+YvHFy5kgt++lNiFRVowB59kA2BnTRrccKWi7qsB0cqTcbK0WbFeLQGhhQnftOPQxNidYajjP95vprF/iC4nhbGSSCEqW2Lf9msEK5utygjNowTOiRLJBKJ5JXBNMe+P+88ePBBKC6GoaEMK1f+gqee6gQgEHCyadO7ufTS2klaqWQqI4XqBFAUheLiYjnDSTJlkTF6hkh3QtdG6Nki3H4tQ2RQc4MQOg/c5aIceATDMvhb098AWD13NQFXgOVVLyCWFiyAz38eHntMiC3ThL17RcYwEhHOE6tWnVSkAvz98N/Z2roVXdX5/OWfR1XUF39dwMgaWIaF6lBJR9P07ujFF/URyUdQNRU9rMMFQInYX1VV3JlBrv/Jj3jdow8RjEZRDYO0rnM4EsFx+eVctn07l95zDwDv+OQn+dM3vkHV1q3UNDXROz3MNwP7aNeSzE960AaHIJ0mqZpkNBuXC3IKmPkcScsi6A7x5nlv5jb/mwn+7qtQUQyVldDaKoS8bY/NYnU6oaYGFi2C0lLxGZ7AIVkiORnyHCqZ6pxNMXrgAOzbN/ZzRYUQqdFoite97i527hTu7+Gwm/vuew8XXHDya5zk7OFMxKYUqhNAVVVqa+WdHsnURcboGSC2B/ash1QzOMOi3NdmZCSNBfkB2H6r6FkNiTEw29q2MZgZpNhTzKW1l07sdQ4cEFfwJUvgs58VAsvtFg4UL1K6msgluO3R2wC4ccmNzAxPvGxKd+vYpk37Y+2YnSal6VKcthPdq6PN1WAh464QvuhhVu35I0pjDru0mGhdHb0OB7lCgdrDh/n85z6HK58n6/djORzMfeABFt19N79at47l69fzcO5xWsxB5g970KKdmKZJ3GVjqJB0wu4IZB2gmzamnee6okX84Nrvofzv/8KhQ+KvHlUV5dGhkHD19XqFSK2uHpu/ms+f1CFZIjkZ8hwqmeqcLTG6Z4/wsuvrG9tWVwednXFWrryL/fv7AYhEfGze/F4WLy6fpJVKTjfqCzn7v0SkUJ0AlmXR0dFBTU3NGfklSCQvFxmjp5l0pxCp6TYomg/KiOV6vAmwwFUKJRcK0bpnPSzdAN5q7t5/NwA31N+Ark7w9Lpli/j6hjeccqnq9576Hv3pfmqLavnA0g9M+HlG1qB1WysDTQN4014qjUp0l44W0lCWK3DM3w3u1AAzn/4NHmOIXZddTMahkwQKwLTubpY+9xyOQgHFNHEnk2SCQWxNg6Eh0gsWkPnyZ9n4yzWE+4bRenrBskFXibtMugLQFVTIjLSlBgsqDf02yeZHSP7hUgLx3Fh2dMYMmDNHjPA5GS/ikCyRnAh5DpVMdc6GGD10CK64AgYGxrYtXAhf+QoMDuYZHMwAUF0d4IEH3kdDQ+kkrVRyJpCuv5OEbdsMDg6eNU5rknMPGaOnma6NIpMarB8TqbYFyYPie/8cUHXyvhkkhp7nwO7vcv+h+3mk9REA3jT3TRN7nUQCnhyx4z/FcSo7enbwh31/AODzl38ep+Z80efYtk3Lgy389m2/pe3/2liUWYTDcODwO9AbdJTXHS9SAUoPP4U30YM2pwG3Q6cfME2TZU89xYpHHsExYmxk6TrqSGPSnT/8IT/44hd5rWXQ6UzQGXZSpgZEua7Pi+b2cCCic6hkTKTOSDpYddjBzEGIOvI09u6FkhJR/jxnDixd+sIidQIOyRLJiZDnUMlU52yI0R/9aLxIXbYMHnoIysqgoaGUzZvfy/LlVTzyyD9KkfoqRLr+SiQSyZmmEBc9qc7wmEgFMY5mxDQp5SimrW8fHYlOfIUYmaEf8f9if6Ql3c/CsoVoygSHXj/8sDD+mTVL1EZNkLyZ5+uPfB0QvbDnV57/os8Zah7isW89RteTXdQP1LNgeAFUQCaTYahsiOKlxePcf0dRM0lCjU9jBkK0zQjRa1lU9fSwcOdOyo7+iwRAUcgEgzSdN5f/c+6g72f/ycHpVzCv9grMXAZHT1SMkNGFMq3MOejxmqgWXNirMavfQEHBBgxNIetQ4P/+Tzzn1luFA3J9vRhFcywTdEiWSCQSyZkhlRr7PhgUPoFH31tcvLicp5760FnRZyuZGsiMqkQikRxNvEkYJ7kjY9tse6Q3FQadFTzZ9TSNA40YZgHTWUyNw0ElcSzbYiAzwK1bbmVP9ITTzcczWvZ7itnUO3fcSXtXO7XdtbzVeCtdz3SRi+dOuG8ukePx/3yc36/5PbFtMa5ov4Ll9nJKZpZQ+pZSLv3DpRQtLqJ/bz/plh4CXY2Eu/cQ6Gok3dKDsXMvHjVNZ0ME/77nueaPf+S1Dz5I2cAAFqJt18ZmwG3xWH2AP9crpA89QdHGb2P17WPbgU24NBeuZJqCWRCi0zQgn6N2wKBmGFYdUpjdb6OggK5R8HnQHS7ceRO2bhU9qOvWQW2tMErq6BC9qLYtvnZ0iB7W2toXdEiWSCQSySuDrnexbt1GTHN8OagUqZJTQWZUJ4CiKFRUVMj/uCRTFhmjpxEzK9x9laNmeRopKAyTsmBHfJBkIU3YHUZRFGzbxjTzKJaJz+HjouqLODR0iPXb1rNh5YYjc0uPI5GAJ54Q35+CUN2zZw/3/9f9LN67mHnaPB7f/DiqruKL+Ji5ciZzrptDsDqIbdk0/rWRp7/3NJnBDDOHZrIst4xgZRAtpMFngFUQUSJc45zP4H/9HPWhB9ETg6iWiaVqzAoUMzR3FoHmNhY+0YKiKDgADTCwiXos2v0mHX6LpEfH0hNg2Tgtm2JDXGDaBlvgka1U92focxWoSZqAiNMAcGWbKn50OsDhBFUl6ikQyek09APJpHjjCxbAhg2waRNs3gwtLSIbfQoOyRLJyZDnUMlU5+yK0TaGhn7JD36QI5cz+OEP34iqng3rlrwcpOvvJKGqKhUVFZO9DInkpMgYPY1oblB1sAugjPR95kWJa5upEc8nj4hUAA2LtJEja+tMC07DqTmpL65nX/8+Nh3cxNrz144/fjwuSlQfeACGh2Hu3AmX/fbs7uHOj99JVXsV/hI/dfPqUJ0qVsEiFU2x484dtG5tZf7b5rPvj/uI7WojkoxxXqqBcqcPR0QjviJF00eayBZlcXe7qY+aBL9zO4HmZswFRWQd07AUDds26S7EcXc/j2YYqLaNoqt0eS3a/CYdPpO8aoOqYjudaKqKZts4DQsbi3w2CQNizumTT9/O62MFfjodKlM2mqKK8t3Rf+pYKa+JTcxpsrotQMDMC3ffUaqrYe1aWLNGzEk9BYdkieSFkOdQyVRnqsXoli3wk59AJjO2bedOgGbg19h2AYCDB4fIZg28XseJDiN5FSFdfycJ0zQ5fPgwM2bMQDtRb5REMsnIGD2NBOtF2W82Ct4asS03SN6y6cgbuDTvuLuGfivN4bzBQcPFRaEZAGiqRsgdYvOhzaxZsIaAKwCdnbBxo7i6R6NCrCYSYqzKHXfAdde9YDYw3hnnN+t+Q6YzQ7Y6y4rZK9Ac4netOTWCNUE8xR7atrbRvfEZFnhbuTjZQWnBQlM301VksnF2gS3TIPqYA8OhoRdMIge6WFlwcF3NbKrDtfiAOPAkkCCEI1JGpL2ZVmeSvREFQxkxS1BV0HRQFBTTRBmZbVqasOl3Q8al8qHWEKuGSllWfQGNNQoP99xFU5lFfcaHxvF3Xk1smoJ56lJOVjWaQnyeKNscCJyyQ7JE8kLIc6hkqjOVYjQWEwUshcKxjzQBvwWEqd7rXjeLP/3pHVKkniOYI2aKpxMpVCdIIpGY7CVIJC+IjNHThCMIFSuh+afgqRSGSvkBhk2TjK0SdHiO7KrYNpqR4O85HYermJA7dOSxiC9CS6yFxoFGlg95YP16aG6GcBimTRO9lk6nEF133il6MdetEyWuJ2D7n7bTuq8Vs9TkKsdV1AzUYGomqaIUhm4w2DxI/95+QplOLkr+nZpMnqBzBqonwp6ZCdZf+hzN2hDhdqiLFuNYvIRCeyPRwV7uLCqwNd7GOuUG/HYp2wELcAMXeDw458+n0PwUlm2DPuqCbAsDo6MI5RTmJV3Yy5fz0BUfR1m8GGbPxlQUjF27+H/f7WHD8H3sLcsRzmtEsjoOGwoKRN0GMadJXcrJuj1hqgcGYfVVUFV1Wn+9EsnJkOdQyVRnqsRoc/OJROoe4I+IqweEQg385S9vw+WSUkPy0pHRI5FIJMdSdR30bhXGSv46KMQxsLHRUEc86BTbJmLF2J0r8EDWTV1kfPmuQ3VgWAbZ7nb49h+grQ3mzxelrm1tQuiFQsLFdtSxdv160Yd5TGY1F8/x5M+fZFlmGQsOL6BGqUGxFWzVJq2kaco1kbbSeBni8vyjBEkzYNUQcFXSuTTLV5Y+R5Mep8YM4HCZ0NuL8te/4TQNaoBKVeH5MoObnNt4e+EaSkwv04eHWTQ4iHNwEKJRsk6FWUM2h4pNrKPcgUvwUOsuZ1pRLUXxHJw/8/j3MCJo53/ki2z4x51sCvWxuUGhxZ/HUEG3IJLTWd3iZ1Wnl+qWATGW5pOfPCO/XolEIpGcPsrLd9Lb+2eEvR5UVS3kL39ZjcslqxMkLw8pVCUSieRYvNWwYB3sWQ+Dz4GVx6G6UVQVxTYosnN47TwH8ybfjrtI6kVML5o+7hAFq4Cu6rgff1rcfh4VqSBcamFMzGmaEKz79gmzoLWirzUXzzHQNMCOX+7gtbteS0gN4S5yk/amsRSLbH8WR8LBXHsu1Xo1pvt/KCnEGdZqMdQCzRcN8uUFu9ji7MRpWHRbQ6iqhacMquNQloauoEp7wGTQA8HCAJd2buPdj+XwGMa44tyBGjdGLkPDkAqBIMGamVRXNuBTXaKUORaDmTNf2HV32TKqv/E91t50E2v29dFY6SJb5MONTsOQRmAgAdl+IVK/8x1Z3iuRSCRTnqfp7d105KcPfGAJd9xxA9oJxp1JJKeKFKoTQFEUpk2bdpY4rUnORWSMngFCC2DpBth+K6Q7CDlczDHSFIxB8o4QT1DB9/oO0W3prKhZjKqMvyhHU1EirjAN9+4T5b6jIrVQEMIOxgs6TRMZ1s2biV9+HQce7qZ5SzNGm0HDrgbCmTBD7iFM00Q3dTIDGcycSU7LYbgNIik3nuFmUnoQJaxxIDTIT6p287A6iJa1CeYUVBtMBRJO2F0GbgPiLgtLBcWGlGayy9OFqQRQHC6x7pISKC5mRbGbR3ufYu686/C39Yr3cKhtQq674+LzTW+C6moC3/0uy//+d+hMgGWJntdAAK69VmRSpUiVvILIc6hkqjMVYtQwhFn900+PbjGB7Uce/8QnLuQ737lWOvyeo0jX30lCVVVKSkomexkSyUmRMXqG8FaDMwj+Gei1a2gaHODPB+7F41vCtrZnyAxbzHEVUZHVwJUX41UA0zKJZWOsDl9FoGebcPW1LGhtFW61liWmoQeD418vEiG6u5dtN21kaFjFHXZTlCqiiCL69X7c5FEG92P2ZXEoLtDr8LkrUbMqeZ4nyCBqoIy4/yA/X3SIQ5qBowCBPKg22ApkdfG9uwA5XWyzR64tpgLNYWi8chHL/fVw1EWnLJ9ndaoW1rxfuOyeguvucfG5fDn87GfQ1SXMpZJJ4e67cqXsSZVMCvIcKpnqTIUYvfFG+MUvjt6iAe+mtvZO3vWuer7xjavlzZ5zGOn6O0mYpsmBAweYM2fOpDutSSQnQsboGcK2ILZbGCpNewvLp3n5XetBnn/+QaoOR/HkodilQ+sT4PFATTXmtGqaMp3UhetYFVwGhb8Lx9/GRkinxXHdbjjvvONeLp53se3wNIbzKUovqCOdTBPpiZDVD1FuPEIg9yS6NYC4i62hWOXkjMvJaFeh+HLY6QKB+B62zergcMikMqnS7bdQbLAUSOs21ujfEKoQsEmnEKoOGxy2SiboJUsR5I/5YyMaFZnTUVF6ChnPk8ZnVRW8732n9CuRSM4E8hwqmepMdoxaFvzmNyd6xMcPf/hBXvc61yu9JMkUQ7r+TiLZbHaylyCRvCAyRs8AiYNgpkHzQmAW1Xv38ZkHsnzOjtISMCkJBilyhlEtKGTTRA/vIjawj7qG17Du4n+l+hebYf9+cSxVFQK1vl5kWE/wh8aBFgdDeQeldUEUVaGrpYuLMn6KrB/gMbvIW35yVKPgAAxc1jA+fofL9QQZ7zUUChqDrloeqGsjlFVwmmPlvjndxlTBHuk8VW1heqHb4DQUVuQilGpBWvUkbvuYtZmm6EFdvfolzyuV8SmZ6sgYlUx1JiNGh4fhP/8T2tvBMGzgMWAZwhceLrwQrrhCilTJmUEKVYlEIjkZseeJGyZNWjnZ5/6M+/t3ULTnAG8K+Hi+HLqmhWjRkhhY6E6ViBlmdYvGqmf7qP7lLdDfL25DaxosXnxSgQqQyys0tyi4vQpqcYimwQM4E32U5raiK1HS1kxslCP/s3GQU8uwfeU4jBacqXtJ+EMcDMToDWjMHBIjAnRUhjwWztFUqi3+T7fAaSvU5BwkHDYu3U2/kiViemgwisYWNupIXFcnelAlEolEcs7wiU/AXXeBGDvzF2An0MjHPvYebrrJyaxZ47pEJJLTihSqEolEcgI6451s3P5TtrQdJqqnMIa2o/p6sZYXWDSo84/qBcwbnkGjPkxWMXGbCg2HkwR2N8HgbmFC1NAAy5bB7t0vKFIBBgYVUmmF0IJyUnaefX37eGO8F6fVRcqegaqoaGhYdgIXhyioVRhKMZatkHfUgdVMRp+NobSR8XqwMxb9fh1PYZi4ExyWjWIriJyqihMVLRyCQAAr1k1hYJiYF1bn5hOwHFDIj7n51tW9sJuvRCKRSF6V7NgBot3kj8Deka0deL3tzJ49a7KWJTlHkEJ1AqiqysyZM89Ik7BEcjqQMXp62RPdw/pt62lufYywalEXmIljfxP9aYVWj8Uj1SZxvYPPJktZnisRNVH790MqJQ7gdkNFhXCdyOfJ3byOgWe7MaqnoztVSooMXE577AVNE+NwF5ZzAWrdNJ5pfQZlOMG02H4KdjVO24WNhZNDONiLgoVmp0hwIWbBAl0l5yuhKBNHKa1Ep4P2gI1tJCnOqsScJhkdPAUxCdaFg7zHhRoOgaqi+AN0uF0s6FdZ1WhBeu+E3HwnioxPyVRHxqhkqnOmYzSdhg9+UPjbWdbY9qEhA/gd0DS6Eq655m189atSpErGI82UJglFUQge684pkUwhZIyePjrjnazftp62oUPMd6loigY5J4VUgjR5SnIa5Y5KWrUk65VH2fCoSnVfTjzZ5RI9qDU10NZG/OlGDnR4aB6+glRXE9ahHKpDwxfwMnNanjmVSYKpbojF0CrnUsiV8+xz++nUO5mVGaY4b5BR/BTZBVT7CTT6GR1u6qAfp57AEa7A8DpIqm6KoofJX/R+/M4D5LPd+PMWqg61cYX2oE3OoeC2NAzNyXBJCSFVIZMdwlIsGuovYd27bqZ6QJ2wm+9EkfEpmerIGJVMdc50jP7hD/DrXx+7NQ/8BmgGQNN0/vrXt/OGN8w5Y+uQnL3I8TSThGma7N27l/nz50s3QMmURMboyyQeF32Y2Swbo/fQ3H+A+UWlaHkF9CC2BalcEssNAacfb7ZAfU+CfcEcm0pdrI2HxkySdB1sm2jcxbbv7GYo6cAddhO68jzUrg6sjk5S8Tw7duq0NjlYsTiEufBCnjpUSn9fjO5AN0pAYaZZhd9uBaUDnWYUjCMiFQAb3PYh9OAMLEXBG9MwXAat186BwD/T+uj3qG/pJpC1KMpApOClu8RDZ5FCwqmSt9PoOQXFtlg1ZxXrr15PdbAa6k7/xyvjUzLVkTEqmeqc6RgdHe89Rhb4JdA+8rODj370XbzhDTNO+2tLXh1I199J5Ex8+BLJ6UTG6EugsxM2bhS1TtEocTvLloXNhN0aWrAfghaUlNA11IvTNtBMlfBgBgpJNCCU19i8yMua+tcS0DxHDhuPWWzrnMmwnad0WSWqNlIOE5qHNmc2wdgw7kSGrn3D/GKnirc3iObUONhwEF+Hj4grQkN7MT7zT+h2GlQx7FSxFeGFpEBOn4FStBA1o+DIw5CvQLxYpzWikC/MQymqY3uDhjsxQKRsMY5QOYWiECHVxpMdJmnmKU10sqSkfkyknkFkfEqmOjJGJVOdVy5G05SX/4Le3i4AXC4Xt9zybr7ylWmv0OtLJAIpVCUSybnJnj2wfj00NxMv8dPUEGCHx+KQ12ReQofmLnDb9M+N81y8i6WKSUnSRrNV0FQoKiIS8NPiTNIYT7K8MCZUD+wzGDKKKV1cNSZSR8gkDAZbciQ6U9iWhpE18GkKvk/4aOpoYv6v53PNfoWFmR/hIAUq2KoCto2YKOMjr14AegSn6sR0WKgzVAYdUfr8RbR1dFDpcOAvfyuN2S2kyvoZ8IRw+4pQVR2sAhkzh5KNsTSygC9cuu6Mi1SJRCKRnE08dkSklpZ6uf/+97B0aeUkr0lyLiKFqkQiOffo7IT16+nsPcDGCxxscR8kqmUZVLK0akmGivLUOAxqBk3y25vQylUMp443DZSEIFgEqoIDGwOLrDJ2lzuXsWju9uCuKkZ1j82WS/Wm6N/XT2Ywc2SbL+LDVeTCX+3n17Ffo/Sl+VDyIIszO7EUC0PR0a082MKrN+Eto99dh9etUTJb4YDzIPsye3ld1eUUbT/In9asIe90YgeDVC17LSXq22g7uInOQ5tJxlqwLANF1bF8EVbNW8362aukSJVIJBLJMVzFG94QZceObrZseR/z55dN9oIk5yhSqE4AVVVpaGiQboCSKYuM0VNk40b29O5m/dIkzXqCsOWizvATVp1EtQx5M0ej26A9AnN6YOmgk4rZS1B6e4U14kivaAELHRW3PdIvZJoM7OompS0kNL9WbLNhoGmAvj19ACiqQnBakOLZxbiKXJg5k92P7qYi2cn6HYdpGHZD2IVhGJhZG/IFsGwG/LWkS6YRmlaMt8bL00NPczh2GLVg0PzwnylRSmmeM4cDF1/M8kgEXVXRCTHv/LXMWrCG4YFG8kaWTt1NfUkD610BXimJKuNTMtWRMSqZ6pzJGLVt2Lv36C0av/712xkcTDJjRui0v57k1Yl0/Z1EnE7nZC9BInlBZIxOkHiczof+yvq5fbTpFvONMNqI8gwlCnjcBbK6SdCGmAYHIzorjFKUhrlQXQM7tsPQELhcRP0WEdNNQ9oLvR0Qi2GUzcNSpqEW+cGGnp09xJpj4vgzQ5TOLUV3j5x6CxB/bphFvffyT527CGp+1JACtoXTKGAreayAHwUoM3shkyKer+SB9g5S2QQVsTxFGYt9xQp7zgtz3eWXY1ZUsA8IAxHAAeAKkKtaTgxYAKyDV0ykjiLjUzLVkTEqmeqciRi1bbjxxj5+9jMVKAHA7we/XycYDJ3215NITgV563ACWJbFrl27sI4eLCWRTCFkjJ4CTU1stBtp9heoN4qESE0moaMD+vvxZU0Kmkiahm0XaY9OG8MwHINwGC66CBoaMHWdWCHBNS0qgeYO8PngxhvRb/o4atCPmTXpeKLjiEiNLI5QsaRiTKTGwH7QZkd2Jy5yuFQHroATTEO4EGezKA0NaG9+E9r1q1DPW0yXK8v+rh2UH+5nem+OtG7zq0UqX7guQOqf1vD22lo2AP8I+IAWxHj2lpGfbwQ2IMTqK4mMT8lUR8aoZKpzpmJ0zZoefvaznwI/A2IAfOtbIIsLJKfKmTh/yoyqRCJ5dXHUqBncbjE25qjZc/HkAFtCg4RtL1oyDbEhKBikNYuUr8DFLpVht0Vcgb68ThbodOWYXciJ7KTXh1lfT1PYoM5uYNWqD0No2pGZoyXxHO479tPyYAtmzkRRFaouqCJQPTKP1AYOAzvhkOcQWSPLPTPP5yqPBi2HhWj2eGDlSgiFAMi7dP7t4jS/V7PM6lVx502yOuyrcJGuquaHN/w3q2dfC4hM6VpgDdCIGDDgBhqAlz8RVSKRSCSvFn7xiw5++9tfIK4UAJu5445/YO3ayVyVRDKGFKoSieTVwTGjZjAMMdM0EoGVK4lfczlNriQ7+h/mkCvFvI4M5MTdPy1gcn6VyfmlCiVOBU2FuAo9VoZtSY3NcZshM0XIzBNNRYllY9QVz2TdpeuojozPT2aHs8RaY2RjWZxBJ7UravGUjDgCG8B2oB3SWpq9ob14414Wv3UZrjd9DK6+GsrL4aqrwOEAoE1L8uGirTyvRqFgsLMcbFRsRaE2NJPf/OMmZoZmHPdxBIDlZ+7TlkgkEslZzMMPH2bt2l8B+ZEtNfz7v98gRapkSiGFqkQiOfs5atQM4TDU1QmhVyjQOdTGxi0b2NL0daLFLgaHe2j1Zhkqg5q0gwVenbdOM6nw2GRMnWHDgVnIYmsqZW6VNUUFlvvg13TQEoOIL8LqeatZdQLH3OjuKPfedC+2aeMOuQlUBXCFRpx/4+B5tI9MpgwU2DF9B+5BN+5aN2/7x7dBUIEVK4TAHhGpm10dfCKwjbiZhoKFDViKguF08q6+Sr51eB4ureSV/awlEolEclZz330HefObf0MmY4xsmQG8k8svl33akqmFFKoTQFVVFi1aJN0AJVOWczpGR0bN0NYG8+eDph15aI83yfpIG83GAOH+NHVtCuEiF9FijbxuM1BhsrKsQImq0JN149BcYGYBBcXWMfIucnmYE4bbykuJT7+ZYGIerrQLpUkhV5/DFRRCtHVrKw+sewAjZ1BxXgXLPrKMZ37wDP17+wlkLJbv/yPl+R08Wvpl9k3PkO5Pk4/k+eD6D1JUUwTPPAPDw1BXh4HFBv8O/tuzG/LibrcFmLqOrrn4dvwi3pergd4WaGyE5VM7d3pOx6fkrEDGqGSqc7pi9O679/OOd/yefH50rNoc4B8Ysd6TSF4y0vV3Esnn87jd7slehkRyUs7ZGN24UWRSjxGpnUqS9epjtMUHmD8Amq2CZREKluEuzZIZ6OEGl0WNC/bnVCK6Q/SP2iMXb0WDfJ6sU8emjNmDKWIPb+TRpwexDAtVV/FFfMxcORNseO5Hz2FbNtNWTGPlN1fi8DoIVYbofv/viOxaj8saAsVmbuG/+RuX0L6im2vffS1LLl4iXi+bBcOg11Xgn0MP8bjWDfnCuCxqjRnk54NXsMgIgcMW2ddslrOBczY+JWcNMkYlU52XG6O/+tUu3vveP2GaNgCXXTaPRx55K6C98BMlkklC3jqcAJZl0djYKN0AJVOWczZG43HRkxoOjxOpRKNsbLmf5kKU+gHQFE3sU14OuTyJQgrLC5cUQbqgkMcmSQGwhVA1bSiY2A4HlhqkuKOcWLtCpHgHpbNdlM4vJVQXIp/Ks+2b29jy2S3kU3nmrp7L67/9ehxeBxzIEnzTf9Dw5BcIKVlcPhfOsIuw1Uxl7V9JXJOgoaGBZ7qeIZ6LC+MnXecn7n08rnZBYUSkqioFl4uVuRlsG1wlRCpAoSB6cM+CP6zP2fiUnDXIGJVMdV5ujO7Y0cO73/3HIyL1Pe9ZzOc//zakSJWcLs7E+VMKVYlEcvbS1CSMkyKRsW25HPFnHmVLWZxwXkMLhWFaDYRCpB0K8VgvwazNXK+TYo/OoOpCQyFFHiuXAcMGVcUuKiLh9lLcU4Yz58R2leELpgkWdaMoCqqukuxOkovnMPMmroCL8248D1VT4Ue74YJrofGHoIASAi2g0l5U4HtLM/xkzhCxbIzP//3z3HL/LXzoLx/ijtxjdFb6+fTmNEu7bWzA1DRsh5svxC/g18OXErCPKs0afd8NDa/0py6RSCSSs4zzzivn1lsvAeCf/mkZd965Gk2TMkAytZGlvxKJ5OxlpFx21HworuRp6nmOHXVpDhXDPGc1qE5sIJ6LM5geIGDbVDiLuax6Gq7806Q0G1feib/HwGOo6LrGYI2HlBtK+ooJGAG8JV4AFNXEWUgQ7G5i4PlOPDGDrF5G5cUzyKfyHPpLE+ff/zhs+hZgiJafAKDC7nCBT1+a5clqFxXFNSyKLMKhOihYBaKpKHfu+xVbS1r512SM2x70ccM78jhULz8cupzLC6Xj37dpQiwGq1dDQA6dkUgkEskLoygK3/jG1Vx0UQ2W1cBVVyn09Ez2qiSSF0YK1QmiabI0QjK1OSdjdKRcttOKsTHQwxa9jWhtF4Mui9YihSE7So3lJ5AsUMimUG1wOdwsrDoPv0elaNDHkmdzFO3K4hw20K0CigbVIQNrWYCsrwjT70JRFPR4Euezw8x8+o/kO1PMMkxsRcUuK2Mou5zuXBkVt/wAu9CFogAewCeW2RnWuOmtLp50Zyhyh1gxbQUOVYhrp+akxhOhYsdB9jDM11aY/MuBCF9MzGOVHSJiu8a/Z9MUmeS6Oli16hX9uF8O52R8Ss4qZIxKpjqnEqO2bXPo0BCzZxcf2aYoCr29c/noR8G2z8QKJZLTi2Lb53aoxuNxioqKGB4eJhgMTvZyJBLJqRCPs+dj/8D60G6aAwbh4TyR/gwxv8bj1Ra6rZC28rgKNnVJnZkFP15vCOWKK5jRNciHf7MFd2+BjF8n4ckRcoLL9qCn/CixPCmnRvJ1s1E1lfBD+1D78nT1V5E0g9iahj/iwWcm8Q524U4NYuDA6fCiBVUYdflfuJBvfngBX2/6P1y6i4trLqYyUMmBwQNU+CoImhrmo4+RTiZI6zrPzArykdYwn9uhooTDorx3ZNQO0ajIpNbVwbp1sGDBC306EolEIjkHsW2bm2++j//932e57773cNll0wH49rfh5ptP/Bxdh54eKJETzyQvkTOhqWRGdQLYtk0ikSAQCKAoymQvRyI5jnM1RjtJsH5hjLauBPOzEbS+LrAVQt4SPNYgaSOLx7JJ69Ad0pk5oKLUVBOK57nq93sw+jWMGoMM4CwouLJuCoafvKlguR04+lP4/7IfTVfRjDS9VBC3wqhOlUC5H10x8PV04c72o2DhwMT2OsHpBFWFT3yC2D9/gP/50QWoqkp1oJqgK8iDLQ/SneimSPexstVBPpsn4/aw+5JLqCHO85UqyfNeR+CBR6ClRZQ367oQratXi0xqdfWLfTxThnM1PiVnDzJGJVOdicaoaVp89KMb+eEPnwPg+ut/xaFDn+S3v/UeJ1KvugpCIfB44P3vlyJV8vI4E7lPKVQngGVZNDc3s2jRIlkaJJmSnKsxuvHARpqDJvN7I2i9UbAtcLmwHQ58qQJDHguHpVKKhwQ52kIq82prWfhIG2W9cVpryphu9+HNpyHpJWfpqA4V1aGiaAr5sAd/xzCqbhKvCBKPhtDdOr6ID8WyiTQ/i2bmAAVbUVBsC8XIw/Q5cPvtsHw5P3hkPQOZAby6F4/Dw1+b/oppmWCZxFIDPOFxMttZxaFLLuFCtwe36aYl1kLjDRez/F03ijmp2awoc25oOCt7Us/V+JScPcgYlUx1JhKjhmFx441384tf7AJAVRW+853XU1rq5TvfGb/vl74EX/wiyPsyktPFmXD9lUJVIpGclcRzcbY0byEcLEebXwPt94FpknWq9Ca6KFYh5tQwHApa3sDpctBZ7GShBfN2dJDyu8ioOvuTbhYkTIr60ig5BZv02IuYBbS0ia0o9OXLKRScBMu9KHkFogoJZRohDoIKNoq4y11ZCX/6E1RUEE1F+fXuX2NaJgWrwK7eXSPHNbALBjbQ6jew6xdymduDA7BVB4ZlkDWyQpQuXz4ZH69EIpFIziLyeZN3vvMP/PGP+wDQNIWf//wtrFmzEID0UZe2d7wD/u3fJmOVEsmpIYWqRCI5K2lqfY5ozyHqnBXQ1gIeNymXypCZxJuxCKtOIpqHnaEsQwEVh8dHigLe5g78sTRtxTrpbIyyPj+ew0lU2xq5s2ygKCNGE5YNJlgoqKqGoioU+vJoeTG7NOWpxmMP4MoOYqKTnrOIooibZEcH+8rL2bDz57QaGXJmDmxhZGEbBrZhAKBpLmbPvpKLgxWM3tQuWAV0VcetT/35qBKJRCKZfDKZAm9962+5556DADidGr/97dt405vmnnB/WeIrOVuQQnWCuN3yj0bJ1OacidHOTti4kexjv8YIH8QRbxcGQ4pCfyRMY8BLhauERSXzUXSdi7wO2tLddMQ7SKQHSAy2oueShB1BZrsrKerpwGnmsRVNZEWxsW2wLRssGxUTUNAdCkpOIZ/P43K4UAIKlCgMGg34uw8QL59D8Pw6ug8f4PvZLL86eO//Z+++w6O4zsWPf6dsL9pVWXWBaAKJblywcQXHMcQ2aY7j2L7O74ZUpzeT3onjFN/kpt/k2nGqU28SbMfguOGGGxgDlkASCNVF0vY+5ffHgEAUW2BAKzif5+FBO5qdOTN7dHbfPee8h87Nd2JkhpBlGwXTQNUN0HQASh01zJm9jEmKfdTlhVNhQp4QTWWn1/qoZ0z9FCYsUUeFYnekOppI5Lj66t/z8MO7AHC5VP72t+t43eumnuLSCcKJJwLVMVAUhZkzj/ytlCAUgzOmjm7dCmvWQEcHzjoJtcpFQdaxSzKGquDrG2ZmRMZ/7hSkqmrAWiFmljvAPF85ofizvNPhpMopMUUpYIbbkbJJTFkCVEykA0GqaQWt7Ovr1NLWj4ZpoJXoKAEFLV1Az5toNS04z6rmRRt4ZXjhuR/QmVuPaZrYZBVDcaAV0uiSTMC0U102l7nT5nNoTjzd0Ilmo6yctRKfY+LNRT2aM6Z+ChOWqKNCsTtSHTUMkxUrfstjj3UB4PPZWbv2+pEsv4JwKp2M+f3yCT/iacgwDIaGhk7KJGFBOBHOiDra02MFqV1d0NzMjNIZhHQnYT0OkkQq6CbmlvHloWR7J6RTI0+t1od5U+5prnWmqJxeixoqQ447kF5OgwmyZCBJGqZp0ifV0KfU02dvYLh0GpriwsAJSgmSLGEoBjktRz6RQ7YplM0oJ3BeHdv8DsyOF+lKbeGJ+HowTWRJwiYpqKaMgozqrECafQ2zjxKktg230RhsZPm0ibM+6licEfVTmNBEHRWK3ZHqqCxLvO99i5AkCAadrF9/kwhShXEjkimNE9M02bNnD4FAYLyLIghHdEbU0bVroaMDmptBUfCbCst2K9xZalDtcJAgD5KEHAwgJRJWQDtzFgEjxRW5F3AZCYzSudgqpsK5efjpRqScvq8XVQbJJF9pI54MItm8uAJOMsPgMaKYsoTD70YNQjaWpaK5AneZC2fAiWJT2A4M7HmKxt3beWCRk5jdStGuSipGPk+ZczoNoeV0KFtJp7rYpgdZ5Alhk20UjALhVJhoNkpjsJHVS1ZT6584S8+MxRlRP4UJTdRRodgdrY6+/e1z0HWTuXMrmTu3cnwKJwicnOVpiq5H9Yc//CGTJ0/G6XRy7rnnsnHjxlfc/4477qCpqQmXy0V9fT0f/ehHyWazp6i0giCcEvE4rF8PwSDsH1qSy7Hi+QRTYjLbKmUyeg4Ar90PDjt090ChQHNhF75CmIgtREPJZOu5igTJPBhWw2oCBZcNaiUqJmXwlLiR+8GT6CFmayReNhmPvQc9l8fhd1A6NYinwoNiU8gDPbpO8yDsKlNY22SVT5ZkbLqNOZXvYGHLV6hY+QkuX3EHkxe8k6jdw85oJ9sGt9EZ7cRj93Dzgpu5bdlttIRaTvntFQRBECaGVCp/2LYbbpgrglThtFRUPap/+MMf+NjHPsZPfvITzj33XO644w6uuOIKWltbCYVCh+3/29/+lltvvZVf/vKXnH/++bS1tXHzzTcjSRLf/e53x+EKBEE4oeJxaGuDTZugvR1mzbK2GwY8/zy1MZPVOyr5VCjNTo9OmelCl01kl5NCIk5iYBt1np0U7D7mVS/EY/fAUBrzV5vAYUIWJB1MCbK1fmyqiUcdwux1YdMypOyV7FzyVvDDtBfuwR/eg2NSDYqpgylDoUA6HKYqGiU+Yw4/O3sSPdkNANS45jEvdD1G5VS8ixfjdzgAL4sWrmJHy3WsGmplipbFqTppKms6reakCoIgCCfe7t1JrrnmJ3z+8xfzrnctHO/iCMJJV1SB6ne/+11WrVrFO9/5TgB+8pOfsHbtWn75y19y6623Hrb/E088wQUXXMD1118PwOTJk3n729/O008/fcLL5vOJD5FCcTut6ui+zL6sXw/hMAwPw+7dEIlAbS0MDlr/ZJmZkxbx1pef4OmAg546H51qEg0D1ZnhPEVjlq+MkrL5eJwBDN0g8+ALuJJJJFnCdAAFmXylFzVVQI6DrBaQnAZd7qXsvWAR2WAZhm7wRNk1TCvfwdyKfujsBE0DVaUQCvHPlSvpWnoRLyWfQXmsg5nBFcx0nkuiupqqs8/Grh5oam0ADh9TahaxZLzu7zg4reqncFoSdVQoZi+9FOZd73qcwcEs7373Pygrc/HGN84a72IJwklVNIFqPp/nueeeY/Xq1SPbZFlm2bJlPPnkk0d8zvnnn8+vf/1rNm7cyDnnnENHRwf33nsvN95441HPk8vlyOVyI4/j8TgAuq6j69ayEZIkIcsyhmGMjLeePHkykrXI4sh+++3f/9DtsiwjSdIRt8Phk46Ptl1RFEzTPOL2g8v4StuPdE2vVHZxTRPrmsCqo2DVzwl9Tdu2Id92G2Z7O2ZpKUyeDIEAUjiMlM9jPv886Dp4PJjnn0+vLYs/o3NVIcj5JZfRlo2T1bK4esM0r/wP3IXfYyou0l1bMIZ3oMzMkv+IE9vvcsgDKlw+BXPlXKL3dqJlsviqouwIX8Ng2UIMzSDdHScbyRKYNomed03jnsj9fKP2VpRCAcNuZ9eMGdzn99O353EowJRZn2Rm1EvflCk0zJmDTZIwTdNaQ9UwyAOKJGEzDMyJ/Dod49/TlClTgMPbz4l8Tafj63QmX9P+NhQ4ba7p4DKKa5q417R5c5jXve5uhoasqW1z5oQ499yakWOM5Zqs2X7W51jTNNB1c1yv6XR8ncQ1SZxoRROoDg4Oous6lZWjx9hXVlby8ssvH/E5119/PYODgyxZsgTTNNE0jfe+97185jOfOep51qxZw5e//OXDtm/duhWv1wtAaWkpDQ0NdHd3Mzw8jGmaZLNZJk2aRE1NDbt27SKRSIw8t76+nrKyMnbs2DFqfuyUKVPw+/1s27ZtVAVqamrCbrezZcuWUWWYM2cO+Xye1tbWkW2KojBnzhwSiQQdHR0j251OJzNnziQSibBnz56R7T6fj6lTpxIOh+nv7x/Zfug17VdVVUVVVZW4pgl+TW1tbUSjUZxOJ5IkTdhrsoXDTP35z3EODBCtrUUHSCaRTJOA04kyPIyhaUiGQUFViWQMNg9ESWWq8bnKSQ9kmGJTsA0k8VVNIR8qJ/vibszul0DXkSUwsWFMm0zq69U47uvBmDMN11YPFfXNxKS95Mqz9HRnGHiuC9WuUj6pHP+lfn7j/w0PPv0gAHWls/jgJR+ku6uLXFcXsTI7/ZkMrmyOGfESdjS34KuuJheJkAM8Xi9Op5NYLEavLOMyDLQ9e0hMnjwhX6eD695Y/p5M06SsrIzq6mq2bt16WlwTnH6v05l8Tfvf5z0eD3Pnzj0trul0fJ3OxGvavj3Je9+7gXjc6mRpaQnw/e+fRSYzCJSM+ZoMYw5g5VAYGhpiy5aecbum0/F1EtcEqnriw0rJPBkpmo5Db28vtbW1PPHEEyxevHhk+6c+9SkeeeSRIw7nffjhh7nuuuv42te+xrnnnsvOnTv58Ic/zKpVq/j85z9/xPMcqUe1vr6e4eFh/H5rwYhDv+XQdZ2tW7cye/ZsbDbbhP2W43T85kZck7U9n8+zdetWWlpaUBRlwl6T9D//g3TXXUjNzRjyQbneDAPpvvuQwmFMRSFe1sjOeCU7HE3sKVhrnZa6AvjcMKUmw/Tk0/iWesn6dqLkBpBsJtmAF6N0Gr5pLcg2FVMDaTPQte/clRJmSze66qTf9TUKeSeKQ+EZ5zN8+ckvM5geHCmO3+Hn0Xc+SrmrnL197Vz49E/pXfAWZu3sIj1zMd66OuYdfG8kCUmS0AyD7ZLEzabJf5rmhH2dXmn7ka5pfxs6Z86cw75xnajX9EplF9c08a5pfx1taWnBbrefFtd0aBnFNY3/NQ0Owje/KdHbu79nc3QZJUkGzJHt4XAnGzb8AV0vABAI1HDxxe/AbneO7G/te/BxrPebQ7f/4x8S2ax13ve9z+AHPxA9quKaTuw1RaNRysvLicViIzHVa1U0Parl5eUoisLAwMCo7QMDA1RVVR3xOZ///Oe58cYbede73gVY3xKkUine/e5389nPfnbkxTiYw+HA4XActl1RlMMWqj34+QcPsTzagrYnc7skSUfcfqRrPJ7t4pom/jXtP/fB+0yoa4rH4cEHRzL7juxtGPDMM5DJgKKw11HPhsS5RPJu1EIapz+Dw+6gzF1CKplnx3MRJNVgRvJZHGYOU5eQHeCp8qJc4IDyPLhsSE8DcayRULOAGTpSPIracDN102bRE+9h9YOrWd+x/rAyx3Nx7tp0F59sfAd3fOMNOCt0ArXnsfu81+P3+VnM4UNgdGCHLDMFWCFJHHxHJ9TrdJzbpX3B+ul0TcezXVxT8V7TwddxulzTwcQ1jf813XIL/OlPB//mSEMlpX3/2oB7sN49AKYQjb6N//s/+1H2P9pxjvAbSebQoorXSVzTa72mo+33WhRNoGq32znrrLN48MEHWblyJWBF+w8++CC33HLLEZ+TTqcPuyn7b3CRdBQLgjBWTBcYzwABAABJREFUbW1W4qTGxgPb0mkr429/P9hsxM+6hIdeqmRAs+H0DVLQciimQqniRIntoiY9xFRjB/ZcnuH+IGZZiIqWShzSNhiMwD9bYUMfzJoPwVJwAGcDFTrE28DbiF51BXc+/wu++fg3SeVThxXTa/eyeslq/sNxDo996BrW1XcjpWzU+mvZ5fMTAPqAEFbipAIQBqJAI7AaOL1WSRUEQRDG4pCZD69gO/AnYH/vVhPwFk7Ux/b6+hNyGEE46YomUAX42Mc+xn/8x3+waNEizjnnHO644w5SqdRIFuCbbrqJ2tpa1qxZA8BVV13Fd7/7XRYsWDAy9Pfzn/88V1111VG/QTgekiRRWlp6UiYJC8KJMCHq6P6lZrJZcDphxgw4eGhINmtl0rXZrAC1tRV27QLTBFmm56L53BMJ0OfxEA2GMcwCsm7gNA1SuRjTzSxTzJ3YZI29Uh0oDqpqy/A89zTUhqBWIp6M0hYfIPvy4zgvmsuMC8vwq1GIRcHbyPaqa/nk39/P833PH/ESXjf1daxZuobqLZ2kP7KKb7a0oTkcZJd9HNusxXwfq5N2HdAJaFiNbAhYCSznzAxSJ0T9FM5ooo4Kr1U2C+95D/zlL1AoHHmfg2aeEQjApElH3i+dLqG93YZh5AgEWmhoeCOSJFMo5LHZbBytp3QsFi2yenYF4UQ7rZMpAbztbW9j7969fOELX6C/v5/58+dz//33jyRY6urqGtWD+rnPfQ5Jkvjc5z5HT08PFRUVXHXVVXz9618/oeWSZZmGhoYTekxBOJGKuo4eutTMvmVdCIVg2TJYscJacsbptLL5PvccdHdbQ34BQiG2LqzjtrI9eF4K4XBm8EuAYWIYkHHLbPdIVIcjSHmDiG8K3jI3WlbDtnUzZiFJb3ectQ4b65tUwt4CmhlGNR8h9LKPZRUNLJvxJu6JJvjR/92CZmiHXULIE+Jrl32NFdNXIP397/D1r/PjyX30lTrom3k2tZd8nGuBt+3b/zqgFcgCTqzvws/khS+Kun4KAqKOCq9NMgnXXAP//vfYn3P11XDXXUf7bQ2PP349v/3tFr7//StRlP2ffQ8d9isIxeNkDP0tmmRK4yUej1NSUvKKE38Nw6C7u5u6urqT8iIIwmtVtHV061ZYswY6Oqy5p6GQ1WNqpCC3CzJxqKyDt3wQHnoKfvhDK5C12619Z82is8TN1wovkww7mPrcbLTgINgKGJqOYcpk1BLUvMQNgw/jkSVcFdNQZRVHYi9lfS/xcpXEbedpdAQNgjknoUAttkKcgk0mPG8yXfk4/akwmGBTbFYPrqZZ/0sS75j9dj504ScZSPaT/cs9OP/2T3RMbrkwwa7qKspW/JCz6s7jfxEfIY6maOunIOwj6qhwvGIxWL4cnnji2J7385/DvhQrACPLmB2NqKNCsYtGowSDwdMzmVIxM02T4eFhamvPxEF7wkRQlHW0p8cKUru6oLkZFAXsKShth2A32LJgFCC2A9b+G/rLocYJe3VYvJi4p4oduxTWv5DGk59NVdqJkixBzjnQvEk0NUZGVdElJ1Ndccplgz6bCz2fpNTuoXRvGz1ek2+ep7GnBJoHFZSGWnCq4Ahgjydw5my0RzrRTA1FUvAbNpR8AQyDKWkHn9rTQH/HE3z8pZWEU2G0WASlWaIzZCPp9WGbdCGhuvP4JiJIfSVFWT8F4SCijgrHa+XK0UFqSYk1tPaVZqDNmwdvfKP1s2mafPWrjxIOp/jBD648arAq6qhQ7E5G36cIVAVBODnWrrV6UvcHqe5haNgEzjhkVejNQywJsgluDRYmYeVZsN5N+OkYG4bKGEyYhEsKGL4kuupGyXqRDBvqcBBZ9ZItT+Op9ODOJZFNAxSVZCHF5GgfciHPfbMNOgMmzUMySmXIClIBZBlMgzJ7gHJPOYPJMJqWI6vlKTHs3JKaw+WFer4zZTMdRjfBtgyNSbC53GyfXcWw3ksmF8Wf6OHG8FbqQy3jeqsFQRCEU29oCB5++MDj8nJ44AFYsGBszzdNk1tvXc+3vmVFuh6Pjdtuu/zEF1QQJigxdkAQhBMvHrfmpO5bagZ7ygpSbTHYY0D7MERTYEpgd4MSgkwZOPaSPvcl1uU8dMVMEiUDxP0JnIoDw61gKBo2zUaVHKKh0ERLfB4+w4cmqxiSjE2S8aTjuGP9xOwmD041COYlFK8XSg4ahmIYIMlIqsp5ZfOQCzqyAR7JwV/jV/KO/Ey+43uJLiVFc79BXULCrploLie784PkFTue2vMIJAd4ZMMaeuI943arBUEQhPFxaNKkr31t7EGqYZh88IP3jQSpAJWV3hNYOkGY+ESP6hhIkkRVVZXIBigUraKro4cuNVPaBfIQtKbB2FdGl9NKe+h0QC5BKtVDV5+MLW9DnRVjq8NJwZRISQZoeWqyJczR59NUmIdL8qBICsQhsSVBR/Umcurz+JNpavbNN91RZrLXC1MSCtSHRpcvkwGXC0oCBNt3MjfuRHa5USQZE1jr7KKDCM27syiaDoqCWV1DJtJPyZDC3qkNhAKTuNAwaBvczr0772XVwlWn8g5PKEVXPwXhEKKOCieCfYxzQHTdYNWqf/C//7tpZNuPf7yC97530VGfI+qoUOxORt0UPapjIMsyVVVVYvK6ULSKpo7G4/Dss7BxI0QiVkIiJQ+unRBOWkGq0wHVVVBZAXIWUnsYNgd5OlCgLW+QjZQws2WAqtpavMEqTJuKx6hn6dD1zNMXo0g2IlKEQdsgw+owjqyD+X0X4UmupCYVwakXQDLJ2kGXJWzBMlAPmixkmpDLQ10tYEJ3D3MKQZr1IDomQ1KW9XQQ3Ju0glSbCjU1JOUCCVmjOlogWNbCuUjYZYWAM8C69nUkcolxu+3FrmjqpyAchaijwqlSKOi84x1/GQlSZVnirrtWvmKQau0n6qhQ3E5G3RQ9qmOg6zq7du1i8uTJJ3R9VkE4Uca9jh66BE0kArt3W4HrDBUq90JCAY/byuZr5CHdDZikZINNTsjlvZSnqslGHQSrI1SUDJMphKgYDvHG3jdRVihnl3sXDsWBK+0CDQzJIG7GMXWTWm0OhprhhUqDrA22V0ok3Qo9bhXVTGHPG5SqXitFo98HDQ3Wz5kM+H0UMFCRGAh3EC4J05iSweGAykoKksFgapiCTabEcHJORsPrsS495AnRGe2kdaiVRTWv/EHjTDXu9VMQXoWoo8KR9PfDqlXWqmlHyhOj68d2vGxW49pr/8g//tEGgKrK/O53b+Ytb2l+1eeKOioUO/1Y/yDGQASqY5RIiN4SobiNWx09dAmaxkaYPNkKArMR0BLgNKDEAYFy0DXI9AMmecNFu+bDFrXjKdiQJAdmVkLJgmPQJNefY0F4AZX5SvY492AqJqhglBhIGQkpI4EOex0DPD7z8zw+xaDbbzLo1ok6IeGU2EEfds3EqRjUp21M81bjm78A3B6IJ8A0QJYJm3FCAymqdqTRzjaxuTxQUYFmGvQl+8mbBtgceDQnXu1AY2yTbWiGRlbLjs/9nyBEGyoUO1FHhYPt2QNLl8KOHWN/ziuNfEyl8rzxjX9g3boOABwOhT//+VpWrJgx5uOLOiqcaUSgKgjC8TvSEjRgJU+6UIPSOFSaUAaUZEDphqQGecjk/PSmqklrOopUwHSbIJkohompy2h7VPxdfuYb80mqSVBAlmQKegGbzYakSGCHXeW7+O2F3yDs6cBmSIS9Mim7gRMVTTdJqjqmBJIKW4MFttr6WSLFmEzQGhIsyeiJOFH2snKHnVLNierxUSgpQzFNBlIDZA0NZBWvK4QnmRo1lLhgFFBlFafqHJ/XQBAEQTih2tutIHX37rE/R5Jg4cKj/z6RyNPZGQWs7L5///vbueyyxtdWUEE4zYlAVRCE43foEjRgLUNT8SRU9kMC6JPBL4Okg5kFv4nuVBnaU0q6IJF3ZLBJCthtmJh4S1IkYm569nqpLlRRapSy17sXRVbQTR3DNNDTOqqhste9lzuX/JS4p5WGuMwL1ToZFYK6A6mhAVs2SSrdR1aFjN0KdGXJYMfwDio8FXjcbvRMmjZngsakyvJ4CN/8swnZniEsZVDiSdJ6HlNSsHurqMzkkPYlYdovnAoT8oRoKmsal5dAEARBOHG2bYNly6Cv78C2qVNh+fKjP0dVrd/PnXv0faqqvDz44E1cddXv+PGPV3D++fUnrtCCcJoSgeoYSJJEfX29yLQmFK1xqaOHLkEDVk9qxZOgh2FABYcTVBOG01BhQsYEU0G3qfhCYTL5IKYMksMJsgSGgd2V5qWn55HN2cAFtqQNJa/g8roo6AVyhRwFqYAu6zw+9XEGS15kblhiR6lB3G4SzMhIlZWgKgwaCUxZwcQaqmuaJiFviFQ+RUf3FoId/UR9GRoHJVbHWqg9ZxFIEstytfxAfZ4KTcdARvVWUiEpqLm8NazZZgNAN3Si2SgrZ63E5/Cduns/wYg2VCh2oo4KAJs2weWXw+DggW3NzdZbXXX1az9+Q0MJL7zwHmT52OuZqKNCsTsZdVMEqmMgyzJlZWXjXQxBOKpTXkfjcfjb36zJO3V1kM9befnVl8AcgAHFmgNaEQJNg2Q35DVwglGQyeQc2F15vJU6UsyFKctIuk6Ze4hwxMvW1gZUU0W2yRiSgZJTMDwGNs2GaZgE9ABpT5pN0zdR7p6D6dtDj283sinRWyJTIIwZMdENHUmSUEwFHR1FVjAMnUI6yY7INi7MeLk5PY1lhWrKM3n6DANFlqntSREs0+h2m9TJVZTINrwHJ2HCClLbhttoDDayfNorfNUuiDZUKHqijp6ZOjvhj3+EaNRaXvunP7V+3m/BAnjgASgvP/Zjd3fH+fKXH+b7378Sl8s2sv14glTreaKOCsVNZP0dJ7qus2PHDqZPny4yrQlF6ZTV0YOz++7YYU3k6e8HtxvK3HBxG6SkA0GqBBgxsANJG5SYmAEHSgYM1YkvmMWZduK0RXErWQYjfu7bOI8Of5qKtIdoPkpSTuLVvESzUTRdw67Zsdvt7KrfRTqUZipTidUESSlDROQYpixZ6RkPytAoSRJOxYlfcTMzbOJKKgw4bFw/7R0Mf+g7/GDnTq5cs4aqbdsY9LuIeCu4fGgaD9RFGZRjuNIx8t5SbPPmU3DYCMe7iWajNAYbWb1kNbX+2pN3z08Dog0Vip2oo2eWbdus9Aq/+93RM/cuXgz33mst932sOjsjLF36Kzo7o/T2JvnrX9+G3f7a6pWoo0KxE1l/x1E2KzJ6CsXtpNfRQ7P71tVZQarXa/WwyrvBZUDGZy1BY+YhNwz6vnJJlTCUp+APYZgD2JQCqpykLiDTNWjnhR0zeLm7kbBsI+uNk5iawJl00r6nnYXJhcSTcSRVwuV0Ud5STv+MfgzV6mXNkSeipjFQkI70bbUEVfjIxKP4E24qDS/9kyv42RuvI+lwEGxpwbztNur/9Csa719LQ/cwjbKXOTE/7ZMLPD0VOgM2NL0PNaoS8oRYOWsly6ctF0HqGIk2VCh2oo6e/p59Fr7xDfjrX195v0svhb//3Xp7O1atrYMsXforenoSI48HB9PU1Lz26SGijgpnGhGoCoLw6np64PavQKYNFtcCdoi5wOWygtR4HEIyKCZoOqQHgMyB59vLIS+B6kX3t9DfXoKnpIBL7eH5fy/ivl1+kqpERVkFmWQvAA6vAy2o8ZLvJSZtmoTX6SVcEWbKOVPwe/34bD5UVPLk2Wrbii7pSEhWL+4oJuUFB/Z0nJxqogRKic0/j55ML6bq5CxAAXb44Neva8J5QQONETs+VzVepxNfUxNftUNiqJWslsWpOmkqaxJzUgVBECaIWAxuuskKPo/E4wFZtpIiXX01/PjH1tvbsXrxxQEuv/xuwuEUALNmlbN+/U0nJEgVhDORCFQFQXhl6R7416eh8UEot4HcB4YMBac1N/X+ITBVUJygZkFLQTIHXhVUD9iDgALJKEyejLPci2J3EuvV0H0Ohvc0MMM3lV3uXQxlh8jpOWRJxqk6MUyDwcgg/wj9g6X2pSzyLsIT9YAdZjCDkBZio7SRMGEkJEzJRELCrtgpc5ch5XLYoglsmkFKNXH5Sgm0XMwzqTC6J8ScsiYUYG9qL8/0PoMBxGub2X7WfCZJEtXAduBRYFXNonF8EQRBEITj9f3vHzlIXboUPvMZqwf1teaBeeaZHq644tdEIlav5/z5VTzwwA1UVHhe24EF4Qx24me9noZkWWbKlCknZZKwIJwIJ62ORrfCMx+D1H3gkiHrg1QAsl4rIJ3RD9ea0KBDqgAJHfwS5CRwVIGjAlCsr7N9+xIRSaBlNexqhFTCg61qNlNapnBe7XmUu8qRkFAkhVguRjwaxx614y/zM+XrU/C83wPZp2FnEv9WP5d0X0KPowdU6x6YmEiSRLW3Ck88i3swjk0zMe028kEftTVNaJJCXzZK9dTLcTl8xLJRnux+EsM0kHw12Kvm45ck5lslJwCsw1ppRzg+og0Vip2oo6e3PXtGP77qKnjySSvdwmWXvfYg9bHHdrN06a9GgtTzzqvjoYf+44QGqaKOCsVOJFMaJ5Ik4ff7x7sYgnBUJ6WOpntg6xoYaoOwHXx+MPc1QlkN+uJgk6Feh6sM+HMBtsuwWIKEAnkDcimr19Xng/kLKMh29jzahZ4r4PHn6G49G3dNJQBuuxtZkvHavUwJTqFKqSL7YpZKuZIr33gl/rf5YWAAvnUTKB5Y9Q2uOfcaHtnzCA93P0w8G8fAwKe4UfsHoLBvSRq/j5hbxufwUeurZctwG0qwkVnTlpPKp3h8z+NohobiLkerORtFkjgXK0gFCAGdQCsg+lSPj2hDhWIn6uiZY/Lkow8BPh7r1rVzzTW/J5PRALjkksn8/e/X4fM5TtxJEHVUKH4nY3ka8bXMGOi6zpYtW05KNitBOBFOSh3tXQupDlDqwDCtCTz7RfeCJw8eA7I2qFPgsgpynfWkB9xkgxKpeB5dtsGMGXDuueRUN7se3k0unqasahDfjLmk7RczuG2QeHecXCbHYHoQRVeozdSibFCok+q49MJL8X9m35vz5z8PqQTE++E7/4/aX36eL1y8mmVTlxHyhpiilFESzRAhS8Jukij3EXFJuO0earw1dMW6CJU0ULtkNS53GY/v2UBWyyE5/Gh15yHJCvOBg2cT2QANECksjp9oQ4ViJ+ro6cs0YfPmA49ttqPvezy+//2NI0HqlVdO4957rz/hQSqIOioUP5H1dxyJhkEodie0jhbi0L/eml9asFlBqmGAZEAqDDYrUQSqHWwBCthITHbyyIblSA9EmL30Kfy1WWKKHzsl2IYKDGzZjcMWJVCdp6R5PvZFX2DJBfXsvHcn7eva2dO6B8+QB7vdjj/tZ6p7KtPqpuH/sd9qqdatg3/+c3Q5fT5aaubzrbkf595H97AuvYU9LpW9ARdxj4opmQScJZS7y6n0VnL51MupnbacNd4qHu/aQDKfwrC5of4CZMVOCzDp0FuBdXrnibu7ZyTRhgrFTtTR09M//wkbNx54fOmlJ/b4v//9m3n9639DKOTht799Ew7HyftoLeqocKYRgaogCIeLt0E2DN7GfVGaCzJpYBgK+/oWZTd4asjkbQz0yDj8cZxlEXJ7fHQ8soSK5Sql/k2YvS+T0TQ8ThUclQQufQe2qVeDuxZ/ABauWkjLdS1887ff5OX2l7leup6rH7gaR4UD1gBVQCplZbw4WDAIX/wi3H8/td/8JquSaa7zzaL1PW8hu/hsdNMAQJGVUZl6h/QCff2b2SvJyIoduf4CZJuLFqDpCLcijDX890i/EwRBEIqXYcBnP3vgsc12+FvJa+Xx2Ln33utxuWyoqhioKAgnkghUBUE4nJ4FQwPJBnYJ6mph22ZwaKADGTvU1JDXVfqHbOQL4LPr+L15hrUsuZKZdA/NZNvzC9DD28DM4iwLsOwnH8A2/dA+S7B5bTzufhypQuJNf3sTDsUB1wMX7dvh29+Gnh6eLc8zb9iGzZDgU5+C73wH/vUva5+5c/F95SssqqsDIJ6L0zbURlazAmsTE8M0+O7DX6KgusjPvAZHqAXZ4TtqkKoDUWAlo4cDC4IgCMXvD3+ALVsOPH7ve2HS4W9Bx+TOOzdx+eVTqK09MF/0ZAz1FQRBBKpjIssyTU1NItOaULROeB1VnCCrYBZAskN9HbQ/B4mCtRSNpwQUhVhUIZeXcLkKmIaEHs2Crxrq6xl4cYBIewKoJ9AYoJCR2fXwEKVHCFRfHnyZWDLGF/7+Bbw5L0yLw/ltsCEL3d3w05/yXHmBN78uyqK9Nn42cA5l99xjJVeSZVi1Cv7f/wNFoSfew9oda1nfsZ5wKoxmaKiySsgTwjRNWodaMUsasC16D7qrlLkcPUhtAxqB5Sfmrp6xRBsqFDtRR08/hQJ84QsHHrvdr7039bbbNnDrrQ8yc2Y5jz568yldekbUUaHYiay/48hut493EQThFZ3QOuqfAc6QNfzXXQcMwyTFSn0bN6HEhl4wiKcUFNnE6UyQi9pIpmsx586j96UoiV5rQZfQnBCl00qJ98RpX9dOy3UtOA759nlD1wbe8shbWNATQlb/B1Lr4daw9Ulj+3Yy+TT/nJmnLAVPhnJcGXiG/93cSEvddPjqV2HOHAC2hreyZsMaOiIdBJ1BGgON2GQbBaPA8/3P0z7cDoqD0kXvp95TgR8rUVI31vBeG9ac1DBWT2ojsBqoPXF39owl2lCh2Ik6enr5179g584Djz/8YaiqOr5jmabJF7/4MF/96qMAvPzyIH/84zbe//6zT0BJx07UUeFMI76WGQPDMNiyZQuGYYx3UQThiE54HbX5oWQJDO+B3h7YswXMHPjdUF8PdgfZaBYtq6OSxebJsze6kHzLYrpeSpDoTSDJEjXn1FA6vRQk8IQ8pMIphlqHDjtd/wP9vOmRJsqHbwfbnWCkoLERFAUtl+HFYJ7lrSaffdhkxhB0uzX+elkV/Pa3I0FqT7yHNRvW0BXrorm8mTp/HXbFjiRJ9CX76E30gupE81SQ2rOB/xfv4U/AOwEP1hI02/b97wFuBm4DWk7MHT2jiTZUKHaijk5M+Tzs3Xvkf1u3jt73lluO7xymafKJTzwwEqQCrFmz9JQHqaKOCsXuZNRN0aMqCMJoPT2wdi1sWAdTB8DVDnuzgAm6Hf3SBWR1G6k9Q+i74vjqh0npM+jVr2D3M4Pkk3lkm0zd4jrc5e6Rw8o2GUMz0LLaqNNFdkd4wy8WUBb/GUrFMCxuBkWBVApz82aeqtTo9JnIBkyNwAc3Sqx/+yJuXf0va3jyPmt3rKUj0kFzeTOKrIxs70/283zf89byMmVNeMtnERjcjn/nvdQuXMUq4DqszuIsVnbfJsScVEEQhGL2xz/CzTdDOj22/T3HMUrXMEze//61/PSnz41s+6//ej0f+tC5x34wQRCOmQhUBUE4YOtWWLMGOjqsrLr+xVDzEFQZFCI2YjEfsfU70D1uHM4U/kCcvT0VvPTipXS9GMfQDFS3SsP5Ddj9o4coGQUDWZVRnQc1OzrEPxmnavh5ZKUT5dLzrCDVNOGZZ9juzdDpswJbQ4b2cpk5CRdXll6HelCQGs/FWd+xnqAzOCpIHcoM8XTP02QwMfwNuEMtNCPhdQZY176O61quw+fw4QMWndQbKwiCIJxI3/zm2INUsN5ajoWmGfy///d/3H33iwBIEvz851fxn/+58NgOJAjCcROBqiAIlp4eK0jt6oLm/b2aUdgIcZ+feFkJSjn45EEkWSFnq2H7xmZan51CpFdBkjN4Qh4mXzwZ1XV405IKp/CEPJQ1lR3Y+DNQn0vjym8gPkvFb9/3SaKzk97BTp6vLRzYV5ZR3F6mVCzA/dAGuOGd4LP6PduG2ginwjQGGgHIG3leHnyZjuEO0hhonkq8NQtpRmImkPeE6Ix20jrUyqIaEaIKgiBMNPH42Pe9+GLwese+fz6vc/31f+bPf94OgKJI3H33G3n72+ccYykFQXgtRKA6BrIsM2fOHJFpTShaJ6SOrl1r9aTOmQbeYZB1iLxMfFBl/cNLSallNMxJoaoF9EiaZMkiOvtKGe4ZQpJBUiQUm4JpmIcd2tANstEss1bOwuFzWEvHPNpG5q8Z8vYnqAu8RMW0fUOpBgaIP/EwjzVqmNK+A0gSht1Gc0UzWYcPZ18vamsrLLKCzKyWRTM0ZElmx/AOXh58mYJRIAto3io8NecwC5mZ+w5nk21ohjaydI1wcok2VCh2oo5OLOk0JBIHHp9/PrzznUfet6QEXv/6Yzv+XXdtGglS7XaFe+55C9dcM/NVnnVyiToqFDuR9Xcc5fN5nE7neBdDEI7qNdXReBw2/AMWJWDKBrBlQdKgahitwk+Fqx/PUIB4/76UiakUud09pDUFWZaR7TK+ah+5eI5YV4zyWeUjhzZ0g+G2YYKNQbwXevnZcz9j/fb1hJ8Pk2vKMal0Dx99ehA9O4Qjp2N78UUebtDJHzRMq6BIuFQHndFOdpm7mB4u0Lb5HhbNqKbWX4tdsRPPxXmg44GR4FN2+FFCc3B6KpkFzDrocgtGAVVWcarib/pUEW2oUOxEHZ0YEgm46iprdbL9Fi6Ed73rxJ3jXe9ayMaNPfzmN1v461/fxhVXTDtxB38NRB0VzjQiUB0DwzBobW1lzpw5KMc6yUEQToHXXEe33AdTN0KFCZoTsl7IRtEzElkczLyojVxqkB1PnEdybznplAnxJE5vFv/sWnLxHLlYDtM0ie2JEZwaBKzhvtlolmBjkKp3V/GVbV+xlo7ZGaQx1kjUEaWjagubqmTSseeZulfD7oSYQ4J9PbO6DA67iypPFYosIxU0CtIwf9/1L/64vpdrmq7hz9v/zJ74HgzTwO/wE6hoob+kARvSYUEqQDgVJuQJ0VR2pBVUhRNNtKFCsRN1dGKIxeCKK+Dppw9s8/ng3e8+seeRJImf/OQNfPjD5zF7dujEHvw4iToqFDuR9VcQhBMrHoetG2DHd8CZhEQtKAq6bpCN50jnA0RTpbiyEr5QlGnnP8Vzv19EPuXADpRPD+JdUEM+lSfeFSe2J0Y2kqX/hX6cASeekIdZK2fhvdDLV7Z9xVo6ZqiZ7GCWdm87m8s3U9By/GihgU0roEw1aRqEhUN2AikN0zSx2V3U+uuQJWsccEk8R74sgDZ9Kg/vepj7dtxHrb+Wclc5Bga19ReyXbXWaT1SkKobOtFslJWzVuJziNy+giAIE8WaNaOD1GAQ7r9/ZJWy4zY4mGbPnhgLFlSPbFMUuWiCVEE4U4lAVRDORPuXoFm/HoKbYGoP7C6Qt+0lppQSzypoRhWaoZI3HegZyPWWUVoxQOWMXSQHmnCUOFDqAgDYPXbKZ5UTmBJg4IUBznr3WdSeU0tZUxkOn4OfPfcza+kYqZlYe4xt3meQjX688QKqbhLMyQRTBh0BeLwB2srzXLlTYlLaRrW/ZiRIlQwTVyLLP2Yp3DewAcM0yOk5pgan8tXLvsp7NnyTF6IdOEpn0CwrRwxS24bbaAw2snza8lN5xwVBEISjME3Q9Vffb8eOAz/7/fDwwzB37ms7d19fgmXL7qa3N8HDD/8H8+ZVvbYDCoJwwohAdYzEMAuh2I25jh68BE2FF5ryIAfJKBn6M0Fyhg1F0rDb8iiqjJaXME2TbEYmkXBT2dzLcNs0DMUHgZJRh5YkCZ/PZLJ3kIpsDlp7iU+qspaOUYLkNqbp5RF8ySGmDxvkZXihViZS6saupZgcM4g4oM8L900z+WB3BTZzXzNlmPh39bHZl+f3DRomCjW+Gsrd5dgUG0+VTCK6ZDX2DWsoGdyGzxkk7wlhk20UjALhVJhoNkpjsJHVS1ZT6689wa+A8EpEGyoUO1FHx8fvfw8f+AAMDx/b86ZOfe1BaldXjKVLf8XOndbJb775/3j++XcjSdKrPHN8iDoqnGlEoDoGiqIw57WOKxGEk2jMdfTQJWhKhsGRIx9z0a+7yRsSTjmNZAK6BA4VuWBg6CYyJqm4l9KqGK7SKCnvLLDZRg7tTA3h2/wYtdHtlP5cBdMAVUXzqZxd2oWRaySz9z5ap8RoGjJRTHAZUJex0Tetlr3BNBVtvZRmNVwF2F2usKlcY3Kfji+WhUiEVn+e/7rETa6ynItCcyh3l5PX8zwV7WTLUCuemkV8ctltlO28l3Xt6+iMdqIZGqqsEvKEWDlrJcunLRdB6ikm2lCh2Ik6On4+//ljD1IBXmuC0Z07h1m69Fd0dcUAmDw5wJ//fG1RB6mijgrF7GR8kSIC1TEwTZNEIoHP5yvaBkw4AxTiEG8DPQuKE/wzwOYHjqGO7l+CpqkRst2gtENhmFgkSM4I4pQzVpAqS2DKkMsjG6ChokggyxJIBhm7CxoaRg7rHe5i2gv3YA9345hUgzJtqhXEFgrQuZ0bH9uNkm/n3VebBLJWkGoCpgSVKRgwTLJ+NwOzJyHv6aF8OEsoLbPVHuW6Ich6XPxhgcwDTR6qZpzFJcFGJKzr3C3b2GNo1GlZ3gW8x1+LtHAV17VcR+tQK1kti1N10lTWJOakjhPRhgrFTtTR8ROJHN/zli49/nNu3Rpm2bK76e9PAjBjRhnr199IfX3Jqzxz/Ig6KhQ70zx8ecLXSgSqY2AYBh0dHSLTmjA+0j3Quxb610M2DIYGsgrOEFQtg5oVGI6qV66jeg66NsBffgQMwMD+iT4FdB0SOTcKGpIsgamAaTU4Zr6AKsvoKJiShEwB05SJU47b7kTG6kmd9sI92Pb2kQ41EpxXD3a7dfihIXybd6AlC2yuNBlyQX3MClINGcK1AXqmhjAU600377SRnhSiLdDHJClIt6Tzi5mz6PQWeDaZpMRRQuNBQepOYLNRQJJVVqpO3gPsf/v2OXwsqll00l4WYexEGyoUO1FHi8OFF1pLz7ya+np4y1uO7xzPP9/H6153N0NDGQBmzw6xfv2NVFZ6j++Ap4ioo0KxE1l/BeFME90KW9dAqgPsQfA2gmQDs2AFrR13wcCjMOtTo59nmpDsgMGnYPBJiDwPL0egtxuq7IBsHY8ycrF2bE4NKSuBy40pyRiZHJKhIZsGdklDtcmkdTuOkjzpTIBwXwWV1RmcASe+zY9hD3eTDjVStbAGu8cOuRw89xy0d6DmNHTJJGWzlpqxGRD1yOyeWU229PAeTt3Ukex24k4bmiHRVePhpYHNAEwvmz4qSH0R0FJhpntCfKasCfEdsyAIwsR19tnwyU+evOM/+eQerrzyN8RiOQDOOquaf/3rBsrK3CfvpIIgHDcRqApCsUr3WEFqugtKmkE66BtUyQ7uOnBVQ7wNaftt2JU3Q38fDG+0AtTc3kMOWAJKCkKzwVkJihVQZp7fg/3sHHrWg6ZL6HkNUJBkGVXWkctKkV0uPLKMx5Fgy1MzSUcVIu0R/H6ojW7HMamG4Lx6K0gdHISHHoJsFrIFJNNAkSUchjXkN+qCZ2eX4vV5DwssTdNEMzSqfdVEs1FkSWV3Lk7C5sHpCBDy1QEHglTT0CnLRnnfrJX4xbBeQRAE4SjC4RRXXPFrEok8ABdcUM/atddTUuIc55IJgnA0IlAdI6dTNGTCKda71upJPTRI3c80IBcBQ0Pqe4Bp5sPIkeoDY19lO5SeBeWLofw8KBuCv3wSbPuCVIC2NvI9bpKTwVcWJd5fAkjIqozqUJC0Arhc4LTjd/eQydWR8y+ldJrJ2e87m3r7AKU/V605qXa7NSf14YchnYZ8wRpCDCDLBHMGumwy6JXRosP0kqPaW428LyOGaZrEcjF8Dh/TQnN5sucpMlqOqDOI4Q6BzcUGScYOhAHJ0AkMt3GeWGpmQhBtqFDsRB099XQd8vlTc65QyMM3vrGUD37wPpYtm8Lf/vY2PB77qTn5CSLqqHCmEYHqGCiKwsyZM8e7GMKZpBC35qTag6ODVKMA6W7I9kN2L5gaAJKZx44GnkkQutAKToMLDgSkAE3lEApBOAx1dVZvalsXiUSALf9sZu4bNhOsi6IVXBQyHsy8hmSXcPgS2OxpUtlKdna9lWi/h9Kpdlre1oJjc9oKmPdn/33xRUgkQNP3RagSmt3O5skKnRUqs+M5Hi/PIBsS6UKankQPVd4q8nqevJ7H5/Axpfosdti8FNwV2GSF7FArit1HWUUzUdMkZhSQU2Eqs1HOE0vNTAiiDRWKnaij4+P3v7feMvarrj6557vllnOorvayYsUMnM6J9RFY1FGh2Imsv+PEMAwikQjBYHCk90cQTqp4mzUH1dtoPTYNSHZC/GUwcgf2k+3gDGHaStHyCZTmTyOXn3PkY/r9sGwZ3HknWmkF4Ue2E4sFQVFxDis89ffLmH1+J6Gpu3AHY0hGHtPhJWeW0te/mL3Di0hngmSjg8xaOQuHzwFOJ6iq1ZO6dy9s3gy6sS9IVch7yljXkifnkGksaWBu3zY6ndAVBMM0yBQyDGeGCTqDTA5MprxkEi8qDvYOt1Edmo0x6WLC/c/jGO5gOLabpKEhySp2T4iaWSv5yLTltIggteiJNlQodqKOnnqFAnzhCwceezxw440n9hy7d0eZNCkwatub39x8Yk9yiog6KhQ7kUxpnJimyZ49ewgEAuNdFOF08grLzaBnrey+qJDuhdhLoFlp9FG9Vs+pMwS2AEgSpm6QSzyLS8u84imN119J7Fd/J/d/jxNLO0CS8E8KsHiOl4c3+9n0yEJCW5vwObtQ/Hb0mfNImlPRdTeGbjDcNkywMci05dOsA86YARUV8Pzz0N1tLWynGyDZMSSZR5s0cg6Zen89bUNtzIiaXI2dJ6dJKOjUldQxu2I25e5yAJ5NhRnIRqkMNjLt7A/wXLIP95TLmXbxBWyL78GjZZmkOplX1kS7w8cLgMjrW/xEGyoUO1FHT71f/tJaLW2/j3wEKitP3PF/9rPnuOWWe/nd7948YYPTg4k6KhQ7sTyNIJwOxrDcDIrT6jnd+wjk9y0yJzugZBZ4JoN04NtUPa+TicQpJA2SrQmC7hwOv+Ow0/Y+28vj33oKIouYr+8hRD+eUjvOxWeBXWJJS4QNzzjo360S9U3DU9eCXCjFKBikwnGy0SzBxiBLVi/BX7svoE6loL8f2tut3tWqmTBcjpHZTGdIJ+6BOn8d7ZF2TF0nkDbobHHhdjm5rP48HIqDcCpMJBsBWSXqCTF51krmTVvOtkQvAB5/PTu8ldi8lcwAWrCm4QaAdcB1gEijJAiCMHFkMvCVrxx4HAjAJz5x4o7/ve89ycc+9gAAb3/7n3nuuTLmzDmBUbAgCKeECFQF4VQay3IzvfeD6oPETsAAxQXeaVaPq2wbOVQ+lSfWFSPencAuh8lmFJ66qwtn6d+ZsmwK01dMx1/rJ9mf5Kk7nqJjvfXVtbO8HnI1lBaiSFOnwq5doGmEVJVlC2vYGTyH9kgp0YiBsXcQWZXxhDzMWjmLacunHQhS77sPvvlNiMXA7QZ/BcQWkbebbK4dpLeshxpfDbuiu9C1AlP3anSVKTw0y8kNc2/g26/7Nsl8ktahVrJalg7Vyc/Kmpju8KEX0nT3PI0BxEqnocCoIBUgBHQCrYheVUEQhInCNOGLX4Te3gPbPv1pK1h97cc2+frXH+Pzn39oZNuHP3wus2eHXvvBBUE45USgOkY+n+izEV6jV1tuxhmC7CD0r7Pmnqoeq+e04kKwjV6IPDOcoX9TP7l4DsUh4S7P0R25AG9dNem9aTbdtYnOhzqpmFlB+wPtaDkNSZZofkszi3gWxz17ofli+O//hrY2aykZpxN/UxMLfT5aEjmGWofQshqqU6WsqcyakwpW5otvfhP+9S/r8aJF8OYb4D2/RE9vJezO0lfaTYW/moFIN8FohkDaoKtM4QeXeVl09jV86/JvIUkSPoePRTWjw0wb0Drcjgk43RXkXUHKGR2k7t9PA7In9EUSThbRhgrFTtTRk8804dZb4fbbD2yrrIQPfvBEHNvkM595kG9+8/GRbV/60sV84QsXI0mnxyrboo4KZxoRqI6BoihMnTp1vIshTHRHW27G0CHZYSVKMgvWEF/ZBpOuh0yvFdj6Z4w8J5/K07+pn3wyjzNox+vpJZ2rIpm5ENWh4q/1IyHR/kA77Q+046/1U3deHed/4nzKKmS46tPWeVetshIsLTq8P9Lhc1CzqObwa3juOSv7xcCANR/13e+Gm98Jn1XIlDTQLf2cPeW/pCnhILt3Nxh5Bn0y97e4eGiWkxlzL+W/l/83inx4ZjgnVoOU0Qt0RjsBkMumA1APh625Wti3v0jWX/xEGyoUO1FHD9i5E37xC2tmx4m2axf84x+jt33721YipdfCMEw++tH7+f73N45su/32y/nEJ85/bQcuIqKOCsVOZP0dJ4ZhEA6HCYVCItOacHyOttxMuheiL4Keth7b/FAyxwpY07tg5ieg9fsQ22Y91xki1hWlkExREspht6WsZWN2v5VI1I2s5Qi/GCYVTiFJEoZu0Li0kSu+e4X1jfIPfmD1ns6aBUuWHEP5C/DjH8Pdd1tfidfVwde+BrNnw58g90COXdkCX/zPTspnvh7j5e30D+4iqzpor1BJOWXOqjmLX1z9C+zKkdetm4E1nHdLagDN0HDbfaQ9lUjAEUJmwvv2bxr7VQjjRLShQrETddSycSNccQVEoyf/XJJkva3ccMNrO46uG7znPf/kF794YWTbj360nPe97+zXWMLiIuqoUOxE1t9xYpom/f39VFRUjHdRhInq0OVmwApeh54GzH1Zf1vA02C9ext5azkaSYYFt0HvvdC/Dj3aDvEwJWUSmlFGV/957B1eRCoZoP/FLnJ9OTBBkiXKppdh99pJ9CTIJ/M4tDTcc4917lWrrPOMRWcnfO5z0NpqPb7mGvj4x2FoCC5ZQSH8CXZna/nNpb/BNtdGVzbC875e8B0ISGeWz+TuN96Nx370r839wKWGxrpcHAUJf9l00pJEBXBoaigdiAIrEYmUJgLRhgrFTtRRePRReMMbRq9rerLIMtx554lZjua97z0QpMqyxC9/eTX/8R/zX/uBi4yoo0KxE1l/BWGi2r/cjHQgGRKpLsAERwjKF8PBw2Elm7W/ngV3LUxbBZOuY/jpDTyz4THcVaWkC/XouptsJMueJzrIpXKoqoq32ktoTgi7146e14l2RhlqHaLmyT9bqRZnzoQLL4R4fNT8VGbMsIYC72ea8Mc/wh13QD4PJSVWwHrppdbvP/QxzKdeQNKuQwk1EV3ow29v4KHOA0ksTEwq3BV85LyPsHN4JzPKZuB3HHSOQ3h2PYKs59BLp5Lx1wNw6CqpOtAGNALLj+OlEARBEEZ75BG48krrLWK/khJwuU78uUpLYc0auPrqE3O8666bzd13v4ium/z2t2/irW9tOTEHFgRh3IlAVRBOBcVpLUFjFqzESaYJ6T3W77yNo4NU2DdXVbWet5/NR4YW+nv6KC8pt4bymtD3fB96Tkd1q9SdVYe3+kDiJdkmY2gG2t7Igd7UN74Rfv5zWL8ewmHQNFBVCIVg2TJYscL6dPLlL8Pj+5JSnHeelaZx/ze5T2/E/MP/oWsGuqQTTD/Dt/a8n/7rP8Czfc+yJ7aHrJZFkiTcNjffevxbqLJKyBNi2ZRlrJi+glr/6BDUNE3uf+EXVBkazqXfoFVWUIEKwMSakxrG6kltBFZzeBArCIIgHLtPfnJ0kPr618Nf/nJyAtUTbenSKfz5z9diGCZXXSUmgwjC6UQEqmMgSRKlpaWnTdY4YRz4Z+zL6hsGdx3kBkHPWD2nzqrD98+Grf39o990VaeKrMoYBQPFrhDdHSUXyyHbZKrOr8IbHJ0d2CgYyKqM+tA661NIVZX16aOzE4JBaGwEm82agxoOw113Wb2oyaS1zW6HD30Irr3WGqsFYBgY7/kcRsbAxCTjyuCrrMN26+eZEghw+7LbufZP15LX85xdczZTglOwyTYKRoFwKsxdm+7i0d2PsnrJalpCB775fqb3GdqG2giqTt7gqeTHWA1UD1Z2XxVrTupKrJ5UEaROHKINFYrdmV5H9+498PMFF8Df/gaOw5fjLgrZrIbDoYx6rVasmDGOJTo1zvQ6KhS/k1E3RaA6BrIs09DQMN7FECYymx+qlkHHneCqtjL5ghW0HtabqkM+CnUrwTZ6BmbZjDI8IQ+pcApvlZe9W61PF+Uzy/GXHj6kNhVO4QnaKXvsb9bw3VwO9uyB5mY4ODub3W4FsQMD8OKL1uMlS+C734VDsgxq3/89bN2MiUnWkcXr8aJ+ejUEAvTEe/ifF/6HqcGpVHurqfAcmEtjV+zU+euo9lbTNtzGmg1ruG3ZbSM9q3dvvhuAa5quYYvDRwXwEWAm1hI0TqzESWJO6sQj2lCh2Ik6ekBzc/EGqcPDGa688jcsXz6NL37xkvEuzikl6qhQ7E5Gki+RNmwMDMOgq6vrpGSzEs4gNSvAMwViL0Oq29rmOeRNx9StxEveRqg5fAamw+9gyrIpZCNZBrcPoud07F47gSkBksmkNUZ2H0M3yEazTHX14igkrTFcqZQ1F/XQFOKRCPz737B7t/UJxe+3JiwdGqSGYxQ+9xVM00RTNJw+J+r0ppGMGGt3rKUj0kFLRcuoIPVgiqwwo3QGnZFO7t15LwDtw+082f0ksiRz2Zzr2YbVOC0HFgFL9v0vgtSJSbShQrETdbT4hcMpLrvsLjZu7OFLX3qEH/zg6fEu0ikl6qhQ7E5G3RSB6hiYpsnw8PBJyWYlnEHctdCyGmQ7aElABtVrzVc18pDuhth2K3htXm3tfwTTV0zHW+Ul/FIY0zQJzQ4hyRK5XA5zX6Rq6AbDbcMEaz1Ma/8X6Dq43dZw34ODVNO0svk+/LA13NflshItNTdbgetB6R8N02D3lZ9CzQ5jSibbG01UWYEvfQlsNuK5OOs71hN0BkfWSTVMg+54N3k9P+oaFFkh4Aywrn0diVyCX7/4awAua7yMrft6WBcCpSfkxgvjTbShQrETdbS49fTEufjiO9m8eQCAykoPl1wyeXwLdYqJOioUO5H1VxAmukALeBoh2Q6OckjtsrL7yqo1J7VupdWTepQgFcBf68dV5kK2yciKjGEY6Hkd0zTR8zrpvWmy0SzBxiBLJu/B3xGxEiXlctb/+2Wz1qJ5g4PW49paWLDAGvabz1vzWFtbYdEiYtkYd371NuYO/4W91RrtNTqfvijFO3O1fPnSS5CBtqE2wqkwjYEDS/C8OPAiHdEOppdOZ05ozqjrCHlCdEY7ear7Ke7beR8AN8y9gW/t+/2y13qvBUEQhAmvszPC0qW/orMzCkBdnZ8HH7yJGTPKxrdggiCcdCJQFYRTKTcMsS3grIDzfgV62lqCRnFaiZNshw9uzcVzDLUNoWU1VKeKntfpf6GfkroSmt/azMCLA0Q7oyTjSfCDt9LLrJWzmLakEv977rAO8oY3wB/+YCVOAiux0mOPWb2oqgrz5kFDw4G1VW020DR6ontY+9zz/OKxX6AOdHDPZVGSDpMdpTo2A35W3kf8/o/ynSu+Q1bLohkaNtk6RyQboSPaYV2DnjvsumyyDc3QuHfHvWiGxoKqBZSGZo8M+73sBN96QRAEYWJpbR1k2bK76e6OAzBlSpAHH7yJyZMD41swQRBOCRGojoEkSVRVVYlMa8Jr1/cAYEBJCwSaX3HXeE+cHWt30LG+g1Q4haEZyIpMdHcU0zRpubaFiz53EblEjr3b9zLYvpvyfJqKahuOUgPu/T2k09ac1PPOgz//2crkq+sHglS320qa5B2dLZhCga3+HGs6f8bTW3dSsc3BtMEEMbfEi5UahgQZu0xeS/PbLb/lokkXMSkwCVVWKRgFbIqNTf2bXvH6CkYBSZJ4tOtRJCRunHcjD+773QLEsN/TiWhDhWJ3ptVR07Rmd/zwh9DRAT09412iw7344gCXX3434XAKgFmzylm//iZqas7MbAVnWh0VJh6R9XecyLJMVdURlhARhGPVayUPombFK+4W3hpmw5oNRDoiOINOAo0BZJtMbFeMbCSLaZpEd0UJbw0TChSo23QvdQeviwrWsF23Gz79aWhqsob9dnfDzp0HgtQLLwSPh7yeJ5aNoZk6qqSQig+xpinMC5kEFTsqmBnuJOGARyZrGDIoSMiqHc3QCXlCnFt7Ln6nn5AnRDgVpmAUiGQjr3yNqTAFvYBhGDQGG1nSsIRf7Pvd5a/xNgvFRbShQrE7U+qoYcA//gHf+IY186NYPfdcL5dffjeRSBaA+fOreOCBG6io8IxzycbPmVJHhYnrZGT9FYHqGOi6zq5du5g8eTLKodlSBWGskrsgvg0kBaqPHorFe+JsWLOBWFeM8uZyZMX6wzd1k8GXB1HsCuWzykkNpNjw6X+yzP4Ivr42Uk4n7smTke12a4mZfN762vxvf7OSI51zjvXpRJbB44ELLyRlg6692+lO9JApZDAxkA2JF7xxNnpU6HfQOGCSsUX5d2OevLxvorxqQ5JkpgYmU+Is4b72+1i1cBXLpizjf57/H7pjVlZjj81DqpA67Bp1QyeSjZAupLErdm6YewMDksxWxLDf05FoQ4ViN9HraDYL/f2vvM8TT8CaNfDSS6+83+zZJ65cxysQcOJ0Wh9Rzz23lvvuewfBoGucSzW+JnodFU5/uq6f8GOKQHWMEgdlPxWE47K/N7X8fLAHj7rbjrU7iHRERgWpAEM7htAyGqpbpWxGGWYqzeD6TewMZJl/UTPZWAy33W4N792920qKdM451rqpX/iCtaK7JFnB6wUXMCzn2dTzAvFcHIfiwO/woZgS7v5hbm/W6CVPRSaDZG7l31PyZNV9Qaosg6pS469hScMSehO9rGtfx3Ut17Fi+gp+uPGHJPIJQp4Q9SX1bN27ddT16YZO23AbLtVFMp8k6AqyYvoK/rjv92LY7+lJtKFCsZuodfS+++DNb7ZSDxwrRYHXvQ58+0bTLlwI73//iS3f8Zg6tZT162/iC194iP/932vw+Yp0YddTbKLWUUE4XiJQFYRTwTSg18pse6T1UffLxXN0rO/AGXSOClK1jMZQ6xCAtRyNIiH17MGpJWjXJzNLjx44yM6d1vDfkhIrk28yCfffb30SmTsXSkvJtbexW+sj49IIugOoholvOIM7mefBRpkXKwxKMiFkM8VTtSmS9oPWxrLZqPBUcFHDRciSPJK9t3WoFYfiQDM07Iodr8NLJBvBMA1M0ySv5wmnwkSzURqDjcRyMew5O9c2X4tDdbBu3+FFtl9BEISxyWZh1apjD1IdDvh//w8++UlobHz1/cdDc3MFf/rTteNdDEEQxpFYR1UQToXIJsj2geqB0EVH3W2obYhUOIUntG8ejgnRXVE6H+zE1E1cpS78tX7IF6CnG49HIpVVGIrt+84pn7cCVYBZs6xkSo8/biVQ0jT4n/+B73+fpy6fxbCcY1pUpqY7RvlAkrzDxoMX1fPtRTkM04XLcJF2O+gsBUNVAAkUhYCnjEsbL0WVrXPuz96bLqS57fHbcNlc/Mf8/+CWc27BqTjJ63kG04N0Rjvx2D3cvOBmbph7A32JPuyKnbe2vJU+YKt1BjHsVxAEYYx+/ONjS4Tk9VrBaWcn/OhHxROk3nPPVq677k9omvHqOwuCcMYQPapjIEkS9fX1ItOacPz2D/utXArK0YcwaVnNyu5rk8kMZRjYPEA2aiWTsPvsVJ9VbUVzsRhkMsheP0YcdF3C6/cgHdybWlJiZfdNpyEQsHpXIxHic2bww3k5jMlnsTDuQS3oaDaFnSGFx7s20LDbRcGTwaWl6FMHQYKCBHanA4di59LJl2KX7SNlLhgFVFnl8a7HeXnwZbx2L5+76HOUukoxDIM7nrqDxfWLef/Z76eprAmfw8dH7/8oAFc3XU3AGeCf+461ABAr451+RBsqFLuJWEcTCSvtwH6hEHzvewdWGTuUywUXXwzBo888GRd33rmJ//zPv2MYJqoqc9ddK1EU0Y9yqIlYR4Uzi8j6O05kWaasTHx8Fo6Tnof+9dbPta+c7Vd1qpimSc/GHpI9SQBkVaa8uZzSKaXWGIh8AYYGIZfDsOWRUbGp4BwchLY260CTJx8IUr1eawmazk7IZmkbaiOcCtNY3sjuSivgtPWFqfj7g3x7W5ZQ1M2XLs0Qc8S4IAY9fugqAc0F5zcswWMbnXUxnAoTcAZYu2MtAO8/+/2UuqxZpi6bC4/dQ0NJA4tqFgHQGenksa7HkCSJ6+dcD8C+uyOG/Z6mRBsqFLuJWEfvuAMGBw88/uxn4frrx604x+VHP3qGD3zg3pHH+xMoCYebiHVUOLOIrL/jRNd1duzYwfTp00WmNeHY7X0MtCQ4qyC44Ki76QWd3ud7GWobwsgbKHaFkkklhGaHUBwKpNLQ1QU93RCPQyJJKinjsSUo3f4CWv9uFFVFqqmxAtZMxgpSL7zQypihquB0ktWyaIaGTbYB4Grt4MLfbaBhUAOzlJyrhPp4ip2TTfxDMH0QqhImkZlV1PnrRpfZ0Ilmo5S5yshqWZrKm3hL81te8Xb8ZstvALhk0iU0lDTQD7yE1VG89LXcZ6FoiTZUKHYTrY4ODcG3v33gcX09vOc941ee43H77Y/zqU+tH3n8oQ+dw/e+93pkWfQYHslEq6PCmUdk/R1H2Wx2vIsgTFQ9Vk8jNVeCdORvm/Y8uYcnv/0k0d1RbG4bGhqTLp6Eq2xfOv5IBF7YZAWoDgcEAhjZHNmck1nSNhw7t2JKktWTOjxsZdjYH6S6XNb6qaEQNDXhTLSiyioFo0ChaxeX//ZJaiI6YX8F3nwJOTXLjOECL4YkOkpNqhJQmpOo7dWgMQVuq0d1f/begDPArtgu7IqdWy+4Ffko1wgwlB4a6Xm9cd6NADy473di2O/pTbShQrGbSHX0V7+y3g72+9KXrLeGicA0Tb70pYf5ylceHdm2evUSvv71y8Sw1lcxkeqoIJwIIlAVhJMpH4XBx62fa6487NfxnjhPfvdJdj+yGwBXqYuzP3A2nes7ie2J4Qg4kLNZK0hNJq3JRZKEYcKwHCJIP9PyW0FRMCUJqacHnE5rfuqFF1o/6zpEo7ByJfh8zLDPIOQJ8Wzvsyx7pJOGIZ2B8jJKkiXIpklzLI4arCTXEeYfU3R6/SZZw0FJJou5ezeFGdNGsvdODkwmko1gV+ysnLmSOZVzXvF23LP1Hgp6gTmVc5hbORcQw34FQRCO1a5dB34uKYGbbhq3ohwT0zT55CfX8Z3vPDmy7etfv4zPfObCcSyVIAjFSgSqgnAC5eI5htqG0LIaqlOlzPkIDlMH/0zwThnZT8tqvPC/L/Di3S+i53VkRablbS2c9e6zsHvt1J5Ty4Y1GxjcNogzsRdPNIFcGsAwJFJZmWxeJuhKsiSzAb8Rw/R6rV7UfB7c7tFBalubldpxubUsjlN1kswlGezv4OIdGprPT0nayq5Rlx6iYjBO+VCc2no/AT3LiyGT3bUedvsNtMHtqGUQ8lezctZKclqOOzfdid/h55ZzbnnFe5MpZPjjNmu11BvnWr2pA8AWRLZfQRCE4+V0WjM7ip1hmNxyy738+MfPjmz73veu4CMfOW8cSyUIQjGbAE3b+JNlmSlTppyUScLC6SHeE2fH2h10rO8gFU5ZmXtVGY+yjSmzG5j+9tfhx/o2uWN9B0/f8TTJAStZUu05tZz/ifMJTjmQijHUEmLZbcvY+ZcttH9rK1HDjxGzIcvgcenMKulhWu+j+D0pMD2QTiObpvVpxe0Gw7CG+0ajVpC6ejXU1hLJRPj4Ax+nO9FNS9RGTQbyjjIwoCyboHpvFCSQTJi8O87ypI1Z9lqavQvptqXJ9nfjfN0qmi58Izk9x5v+8CYAbjnnFgLOwGH3JVPIkMqn6Ip1ccdTdxDJRGgINHDJ5EuA0cN+y0/WiyOMO9GGCsVO1NGTL5Mp8OyzvYCVmfinP30Dq1adNc6lmjhEHRWKnUimNE4kScLv9493MYQiFd4aZsOaDUQ6IjiDTgKNAWSbjJFJkGpNsmldPbvDNuZEdvDy316m77k+AHzVPs776HlMvnTyEefl+Gv9LFzsoGXSZoaC09DkPKpiUlbox/H0oyCbUFMHQ0NImmY9yeOxgtNt22DqVGu47/LlUFtLZ6STD9//YXoTvZS5y7h10Zso+b8fst0RpUKTmRIeso5hmpiYGBIMNFYwv2oBpbYAVWYJDEXAOQUcPm77922kC2laQi2snLlyVNl74j2s3bGWX7zwC7oT3azrWMffW/+ObuqcXXs2fYk+av21YtjvGUK0oUKxE3X05PN47Nx//w1cfvndfOxj5/GOd8wd7yJNKKKOCsVOLE8zTnRdZ9u2bTQ3N4tMa8Io8Z44G9ZsINYVo7y5HPmgtd+UQg/+8iyeKj+7nwqz44G/4K/1Y/famf/O+cy7aR6q41X+BLNZHOSoqTZByoNpwkObrf9DISvJUqGAWVnJ7uaphL058v3dON96JTOufR/+8loANvZs5LY/3Mb8LfO5UrqSt5zzFiriu8lF/4Ws5amKvgSGwf6l1iUkoi1TmTPjbDz2fcvRFAojmYOf632O+3fejyRJfPqCT49KoLQ1vJU1G9bQEekgp+ewK3YMw8DEREFhy8AWPr3+06xaspoXQy1i2O8ZQLShQrGbaHV0aGi8S3B8SktdPP30u1BV0St4rCZaHRXOPCLr7zg6GTdfmPh2rN1BpCNyWJCKCaS70HMa/TsVcokcek7HW+Nl5f+uxFftG9sJ9k8+KhTAbof+fqvHFEaC1J4qD/+8OMS9tm1EHRp6VQZVv4/QQ20sm7KMyu2VqP+t8sPWH+LL+3DJLuQ/y5B1oBBiqORejBKZaVGbVW5JgukzqFl0yLyhcBhCIbTpU7ntAWsdhDfPejPNFc0ju/TEe1izYQ1dsS6ay5tpj7bTm+glb+SRJZmZ5TNpKmuibbiNz25YQ37ZbZzrrxXDfs8Aog0Vit1EqKOmCV/7GvzmNwe2ud3jV55XkkzmufXW9XzlK5dSWuoa2S6C1OM3EeqoIJxIIlAVhOOUi+foWN+BM+gcHaQCub29SJEIWl4iGfXjKHFQ3lSO0+/E7rWP/SQzZlg9p+Ew1NbC9u1WgiTD6vvc2uBizWUyHbYOPDmZxqSKXSmjUNVMOD/MMz96hs/95XOUZcowXSaFSQW2B7aTjWRxJGy8WPEkcwc0ni2DAZfKeWEb9lA1nHPO6HIclDn4t7v+QUekg4AzwPvPfv+o3dbuWEtHpIPm8mYUefQ3vrIkM7V0KoqsMKN0Bn8f3I5r570sW7hq7PdDEAThNLV3L3z1q1Z6gaOJxeDf/x697SMfOanFOi6xWJbly3/LE0/sYePGHtavvwm/f4KsnyMIQtEQgapwxjosQ++MMhzH8EY61DZEKpwi0BgA0zpesj9Jsi+JW2nFV2KQyZRTMaeK0iml6JpOtDPKUOsQNYtqxnYSvx+WLYM77wRZtsZ7pVLg89FT5WHNZTJdtgyztCBaIYc9m0ZqmoLicOB73sfn/vI5AukAW2q3sGnmJh6qfoiwEkYzNIadbfR59vK2l2D5Dtjj1qDOxkXnXWSda7+DMgcPXnIOP99gZff90Lkfwu84MF8mnouzvmM9QWfwsCAVoKGkAYdi3d+8rJBzBtDa13FOy3XgGGMPsyAIwmnqllvgnnuO7Tm33w4f+tDJKc/xGhxMc8UVv+b55618DG1tQ3R0RJg/v2qcSyYIwkQjAtUxkGWZpqYmkWntNHHUDL0hD1OWTWH6iun4a189YUEuliMzlCGfypMaSKFl9iU0kgwqGqMoDoXA5Lko/lIAK8GSZqBltWMr8IoV8MgjcP/9kEhYq7oHg6y9pIIOWzvNWhDZACWdAb+fXE0lT+x+lK/+66uUpkt5eurT/PeC/6Y30EtFroLGwUZStu1sDu2lIMPv5sK2EHzwaVhUMd86p2law43D4VGZg7+9+24yhQxzK+fyhhlvGFXMtqE2wqkwjYHGI17G9NLpIz/3AKonhD3aydBQK401i47tnggTimhDhWJXDHV0+/Zj2/9HP4L3ve/klOV49fcnWbbsV2zduheA8nI3DzxwgwhST4BiqKOC8EpE1t9xZLcfw3BNoWgdNUNvwSAVTrHprk3sfnQ3S1YvIdQSOuz5id4EXRu66NrQxa6HdxHdFUWxKzhcOaomDeKtUHGX6OgpA50S8B14czYKVkCsOo/xz662FubNs75qNwzw+YgvXsh69zMEdRtKKo2Zy4HPT7p5Oo+FN+If9LOkYwl7yvbwo4U/otfby9ShqfjyPnSzn8fqn8GQQDGhIMPz1XDnonrOT5bh7uwETbPmxoZCI5mDnza7Wf/4emRJ5tYlt45KoASQ1bJohoZNto1ss8vW3021txqf/UCvaTcgyTb8hkZWyx7b/RAmJNGGCsXuVNXReBze9jZYt25kFgdgfT+4XzBoJW4/Erfb6kV985tPbjmPVVdXjKVLf8XOncMAVFd7Wb/+JpqbK8a5ZKcP0Y4KZxoRqI6BYRhs2bKFOXPmiExrE9grZui1K/jr/HirvQy3DbNhzQaW3bYMb5WXgc0DI8FppCMy8hxJkSitzTB9wQ6mze/E7U0iyQZmPkUuLTM4PJ9wdohsvgyAVDiFJ+ShrKns2Are2grf+54VOFZWwoIFtEV2Eg4O0Zh1gdMDkycT8Xp5Id1GWkvz5l1vJlAI8Lum39Hl72L68HQkXcIw4myseYC448CnIwmYGm8g6qzj3gWvY9WFiyGbtRI5NTWBz0dez3Pbnz4IwLUt1zKjbMZhxXSqTlRZpWAUsCvWm2l9ST2SJFHjqyEPxIA0EAZko0CZrOJUncd2P4QJR7ShQrE7lXX0L3+xBsi8kiuvHJ0wqdjt3DnM0qW/oqsrBsCkSSU8+OBNTJ1aOs4lO32IdlQodsbB37ydICJQFc4YR83QexBZkSmZVELfc338Y9U/0DIauURu5PeSLFE1v4qGJQ1MXphCe+7vaIOtmLYg6WwVpiEhZXbjcKapb9xKWS7Cjq63Ek/UkY1mmbVyFg7fMSSUaG2F66+3voL3+awhwKWlZJ/8A9q272PzT4VAEFSV7u4txHIxbLKNeZ55JG1JHql/hEA2gGqq6GaezpIH6AjmRp2iNOfj7Pjl9NHHutxjXDfnZnyHzBn99Yu/pivWRamrlPcueu8RizqjbAYhT4hwKkydvw4ARVIoL5nETqzhvhmsQDUF2FJh8p4QvrKmsd8PQRCECW54+NX3ueSSk16ME2bbtr0sW/Yr+vqSAEyfXsr69TfR0FAyziUTBGGiE4GqcEZ4pQy9hyZCykQy6DmdZF+SkskluEvd1F9QT8OSBurOq7MSLqV74IXb0cqj7OlrJB/RcJQoSFoS05TI5oJk5Wo87h6m1d/DE+uuIdg4mWnLp4290C+/DO9/P+zaBS4XfPKTMGkSAM7Z81F7SykEAtgVG3ktR3uiHWRormhG79ZpK2tjyDlEQ7IBUzeJOONsrM2MOoVq2rhwaAWKoRDKheiUOmkdamXRQXNG+xJ9/OKFXwDwkfM+gtfuPWJx/Q4/y6Ys485Nd1LtrUaRFSLAC0AccAA+rEBVNnTkbJTIrJV81eFjNdAy9jsjCIJw2vjSl6wBM/vNng1XXz1uxTlmP/7xMyNBaktLBevX30RV1ZHfJwRBEI6FCFSFM8KoDL0HSfYn6X+h/0AipH1cZS5kReaCT13A7LfNRpKl0QfsXQupDtTyZqrm5+nf1E82kkUhhWqTkOxeTEMisrcCv7ebafN2UH/jDWNK0gRYWTXe/37o69u3rul0+M//HPn1ob2X2we3UzAKBJ1BGoONvDz3ZarWV2FiomoqKTXFU3VPYcgK4AAzD0gsHroIn+aHPNgUG1rJ4XNGv/Pkd8hpORZWL+TKaVe+YrFXTF/Bo7sfpW24jdrSGbwgKySBINYQYx3IGjrGcBuhYCPnTFtOF7AGuA2oHdvdEQRBOG3cequVI2+i+t73Xk9vb5Jdu6L86183UF5epAu7CoIw4YjUYWMgyzJz5swRmdYmMC2rWdl9bQe9hib0P28FqZIi4a32UrWgimlXTqNxWSOeSg8l9SWHB6mFOPSvB3sQJAVXqYvac2spm+5DlnPk0yrZhI18Ioes2nBUVDN3aT+hGS7GZNs2K0hNJKykRvX1cN11UHpgrs/+3stINsJwZpjOaCeqqjKvch4yMrHyGP2N/dg0GxkpwxP1T5BTc1a0KCkgOZiRmMmk9FQwAQ0KNQVU5+g5o493Pc7Dux5GlmQ+fcGnkSTp8PIepNZfy+olq2koaWDj4DYG49349DyYJrqeZzjejT64HXdJA2ctWY3fX8sMoBO4d2x3R5iARBsqFDtRR4+fqsr87ndv5t//vkkEqSeRqKNCsRNZf8dRPp/H6RRJXyYq1akiq1Z2X8VuJSFIDiTRshqKXWHq66ciqwf+wPS8fvQMvfE2yIbBe2AZFrvHTkVdnFL3ENl8JUZJPbIi4Sxxoqg6JDsh3gplr7IMy/4gNZmEqiprDVO3G2688bBdV0xfwSO7H+HfHf/GMA1qvDVUeA5kV+y8pJOS50p4ou4JEo4EEgeCzKpsDYui51tBagZwQnh6mJAnRNO+OaN5Pc/tT9wOwPVzrmdq6VFSUB6iJdTC55bdxg077yXdvo5ktBPD0JBllZwnhGPWSuZMW06p3+o/VYAAsA64Dmt4sHD6EW2oUOxEHR2bBx5op67OPyqbr92uYLeLBD8nm6ijwplGBKpjYBgGra2tItPaBFY2owxPyEMqnMJfZw2/je22shP6G/yjglR4lQy9ehYMDaQDy7CQHYREK4pq4gnVgeeg+TmmbO2vv8oyLC+9BB/4AKRSMHcu5PPQ3w9vfetIb2o8F6dtqI2slsWpOllcu5j7d9xP3sjjMl3ktTx2xU7BKPC85zm2h15m0DOITbdZvakm+DU/F4UvQs7KoAFO0BfrRO1RVk5dOZJI6c5Nd9Id76bCU8G7z3r3Md3vpL8W78JVLG25jvRQK7qWRVOdPFXWhOzwMeWQ/UNYvaqtgFhR9fQj2lCh2Ik6OjZ//et23va2P1Fe7uaxx94psvqeQqKOCsVOZP0VhOPk8DuYsmwKm+7chLfai6mbJPclfwhMCoza19CNV87QqzhBVsEsgGSHfAwGnwTTAGc1uOtH728WrP2VV/gWdMsWuOUWK0hdsADe/nb41KesiUs33URPvIe1O9ayvmM94VQYzdCQJZkdwztwqk4urr2YZCJJZ7QT3dTx5+DL3+3kL3PO44ezB8mqWVRdxak5uXTXpdgLdrABk0GfrdMmtdFY0sjyacsB6In3cOemOwH46HkfxW07tuFcWawY2O3w4alZhAFswJprUA4cOgjatm9/saKqIAgT0aZN8O53Q3v7q++bybz6PsXot7/dwk03/RVdN+nrS/L97z/Nf/3XK+ctEARBeC1EoCqcMaavmM7uR3cz3DaMrMqYhokz4MRRciAYNXSD4bZhgo3Bo2fo9c8AZ8ga/msPwuDjVjDqKIOyc6zkRwfLhq39/UdZhuXFF60gNZ2GhQutNVM/8AHrd299K1u1PtY8vIaOSIeVLCnQiE228dLel0gX0siSjF2xc9PUm5g+fTqFQobmG79BYLfB2Xue5aKL389NuV8Qz8Vp9jbjmO/AtJkUqguEzTDRbJTGQCOrl6ym1l+LaZrc/sTt5PU8Z9eczeVTLj/me+3EalwKWEHoJmBw37YFR9i/sO93YkCTIAgTzZNPWuuexmLjXZKT53/+53ne/e5/YJrW45tumsd3vnPF+BZKEITTnpiRPUZimMXE56/1s2T1EkoaSghvCaPndXy1PkzTRM/rxLvjDG4fpKShhCWrlxw9Q6/ND1XLILsXwhusIb02P5QvBvmQemLqkI9C1eVgO8Lsy82bDwSpZ50F//VfVuD60kvgcNDzpmWs2bCGrlgXzeXN1PnrsCt2MlqG9kg7dsXO4rrF9CR6+P2u31PtrWbJT9ZR+txLyEjgLHDlbb/iIf8H+dC5H6Jmag2dVZ1sC26jM9+Jx+7h5gU3c9uy22gJWQvEPNb1GBu6NqDKKp9e8uoJlI5kBtZw3jDQDuzCGnl8Lkeegxret79YUfX0JdpQodgdTx196CG4/PLjD1IXLCj+jL//9V9PsWrVgSD1ve89i//932tQVfER8lQT7ahwphE9qmOgKApz5swZ72IIJ0CoJcRZ7zmL3Y/txjRMDM1gcNsgsirjCXmYtXIW05ZPe/VlZEKXwdZvQn4IbEEovwBk++h9TN1KvORthJrlhx9j0yb40IesIHXRIqsn1emEn/3M+v1b3sLavU/QEemgubwZ5aAgeEt4C4ZpUO4up85fh2EYbB/cTsd/fZGGn/0LDKyvodxARQWzr/pPbq+tJZFL0DrUOjLHtamsaWROKkBWy44kULph7g1MDkw+1lsMgB9YBvwA6N+3bQ5QeYR9dSAKrEQkUjpdiTZUKHbHU0fvuw/e9CbIHjRnYfFiOP/8sT0/GISbbz6mU55y3/jGY3z2s/8eefzxjy/m9tsvP64vMIXXRrSjQrE7GV+kiEB1DEzTJJFI4PP5RON8Guh9phdPhYeGNzYw94a5aFkN1alS1lR25DmphzI0aPs+KC5Q3eCssAJWOWQlWDIL1nDffNQKUptXg/uQFUJfeMEKUjMZOPvsA0Hqk09a81UdDuLXvZH1Gz5F0BkcFaTuTe+lJ9GDhMS8ynlISMiyzLntOWb/9A8Y6RKrN9UL2O3wy19CrXV+n8PHopqjpyv65Qu/pC/RR6W3kv9c8J9H3W8sZmP1lGaxeliPlDNYB9qARuAIobxwmhBtqFDsjrWO/uUv1qphhcKBbStWwJ/+ZDXlE51pmnz2s/9mzZoNI9u++MWL+eIXLxZ/w+NEtKNCsTP3D7s4gcS4jTEwDIOOjo6Tks1KOLX0gs6Oe3cA0PyWZmoW1dCwpIGaRTVjC1JNA176Cgw+AfYAnP8bmP5eUD3WEjSxbdb/qgem3Azzb4NAy+hjPP/8gSD1nHMOBKmmCT//OXFV59mV53BP33rah9sJuoIjT41kI2zs2QhAY7CREkcJAGU9Efbs2syvZ+TRJM2aGGrHOvZZZ43p3nTFurj7xbsB+Pjij+OyjXHd1yOIAd/CSpxUta8oPUAea0WcPNANbAcagNVA7RGPJJwORBsqFLtjqaO//jVce+3oIPWtb7WC19MhSAV4+OFdo4LU225bxpe+dIkIkMaRaEeFYiey/grCa9S1oYtsNIu7zE3d4rqj71iIW8N29ayVrdc/w5qH2voD6L0XkGHBt6DiAmv/SddZ66SO7N905Dmpzz0HH/6wNVbs3HPhu98dmaDU88g/WBt9kPULUoQDGxl++kF2x3YTyUSoK7Hmpr4Ufgnd1Kk1fSyPhXAN9aMUNHqee4jHpmk8Vgt9vhRff7EE9SMfhTe+8YiXd+gyN9NLp/Otx79FQS+wuG4xl06+9LjvcQH4FFYgOhX4JvA41jqpnVjZfVWsOakrsXpSRZAqCMJE8LOfwXvfCwd3HNx0E/ziF6CeRp+oLr20kS996WK+9KVH+O//vpIPfOCc8S6SIAhnoNOoWRWEV9f2jzbAygAsK0cYUJDugd610L/eGr5raNbSMs4QqF4YftaaizrniweCVLCC0rJXWQH0mWfgIx+BXM6ayPSFL1jDfLNZtua7WbN2NR31QwQrGmismEEwGyWcCpM38mzu30xOzzEl7eCtuzy8YbeJP/4cimagDA6xpVRDTsH6KXD3vBzZeWX81yc+cVgRjrTMjSpbzUBnpJNyTzmfvOCTx/2tuQncDjyHNT32DmAK0Axch7VOahYru28TYk6qIAgTx/e+Bx/72Oht730v/PCHIJ+G49O+8IWLWb58OmefLb5KFARhfIhAdYycp8t4njNYZjhD14YuAGZcNePwHaJbYesaSHVYy854Gw/MOY2+BLHtoDhg5sehdsWxnXzjRvjoR60gde5caG62lqAJh+lRUqxpbKdLitOcdqGc1QKKnYAzgNvmZigzRE7P0TSg8bkNJvPSdrJ+lcFKL+7dfbxcqVGehmu3wnnd8NPzVW78zE8O++S0NbyVNRsOX+Ymq2W5v/1+0oU0ld5KErnE8d5i/gD8BSvD7zewgtT9fMCrhPLCaUy0oUKxO7SOGgZs2waPPQbr11tDew/28Y/D7bcfviLZRJTLaWzePMA55xwISiVJEkFqkRHtqHCmEYHqGCiKwsyZM8e7GMJxyMVzDLUNoWU1Ov/diV7QqZpXRbAxOHrHdI8VpKa7oKQZpIMyl2UjkNptDem1lUBsq7X/oQmSjmbjRqsnNZ+HmTOtual3322lfGxsZK1/Jx1amuYBCcWOlQ14/gKkEi+ZQoZ0Pk19UuYLT9iojeq01iuUuD14ewbZ7kqiS9DvgwEPTIvAL/cspN7ROKoIPfGeUcvcHJycqT3SjolJqasUu2JnzYY13LbsNmr9x/YB5Sngu/t+/jCw5JieLZzORBsqFDtFUZg6dSbPPguPPmoFp48/DsPDR97/i1+0/p0OQWo6XeDNb76Hhx7q5N5738FllzW++pOEU060o0KxE1l/x4lhGEQiEYLBIPLpOL7nNBTvibNj7Q461neQCqcwNIOh1iEMzaDu3DriPfHRS9D0rrV6Ug8NUnPDMPQUYIKnAYILIP6yNU912qpXL8hTT1ljxfJ5mD8fUino6bF6VBWFuJRnvdRBMGWgyCpUVUEyifb8MzxZY5Azc6iKytU7ZRqHDVpDNtDSVA3KtBuD6Pv+gk3AlME+bSb1SRnuvRdWHSjf2h1rj7jMTSKfYMewlVxqftV8Qu4Q2we3c+/Oe1m1cAzXt88u4FasVXGuBt4x5mcKZwLRhgrFKJ+HDRv2B6YmTz0F6fSrR57f+hZ88pOnoICnQCKR46qrfscjj+wG4Lrr/kRn54fxeOyv8kzhVBPtqFDsTkYyJVHTx8A0Tfbs2XNS0i4LJ154a5j1n17Ppjs3kU/lCTQG8FZ7MQ3r9evf1M/6T68nvDVsPaEQt+ak2oOjg9RCwsrua+rgrITSs6z5qvYA9K+zfv9KnnzyQJB60UVW9t3du2HGDNj3rVObEiWcjxDKyOD3g6pi+P0kBnvx9g/jtXu5suICXtcpMeTU0WXQ9AI9qX6y6r4AFWuobY1cwfzpSyAQgHXrIGGVL56Ls75j/WHL3JiYbOrfhIlJlbeKam81iqwQcAZY175uzEOA48BHgSQwHytgPQ06GYQTSLShQrGJxawmeelS+PKX4d//ll4xSC0rg2uugbVrT58gNRLJcPnld48EqT6fnT//+VoRpBYp0Y4KxU4sTyMIryLeE2fDmg3EumKUN5fjr/Oj2BViXTEkWSIwOUDF7ApiXTE2rNlAvGdfdt9s2EqYtJ+eg72Pg5EHWxDKzgVp35+LM2TtH289ekGeeMKawLQ/SP3sZ+Ghh6zhvgcNjcjGhtD0AjYTKLGWmonl42QVk+qYwSW1F7Ao6acx7yFfFkSWZLJGniG3FaCCFRRW6AHmTllijUMLhSAchlarfG1DbYRTYUKeA9eX1tK8FH6Jvem9yJLMvMp5I78LeUKEU2Fah17h+vbRgE8De4BqrCVpxEccQRCK3f33w0svHf33DQ3wjnfAT34CW7daTerf/gbLT5MFn8PhFJdeehdPP90DQDDo5MEHb+LCCyeNc8kEQRAOEEN/hdPKjrU7iHREKG8uH8nqa+om8T1xAEomlyArMqUzShncPsjOe3ey8Jqsld1Xsh04UGIH6Gkr02/F+VZP6n6Szdpfzx65EI8/Dp/4hLXI3sUXw2c+Y30Nv2MH1NVZwavdDokEzu2tqGdDwe/DrigUDI1YNopkk6kynThSOdSCjs2U8HkCpFLWwn2yagPTQNI1/AUXl8y/mmQ+ZZ3fZgNNs5bAAbJaFs3QkJDYHdtNV6yLvem9I8WdWTYTj80z8tgm29AMjax2lOs7yHeAZ7Ay/H4PKH3VZwiCIIy/eHz045kzTVpahrj66lIuvlhm0mkcr/X0xFm27G5efnkQgFDIw7p1NzJ3buU4l0wQBGE0EaiOkc8nFtIodrl4jo71HTiDzlFLzyT6EhgFA9Wl4qmwAjJZkXEGnLSva2f262uxy6qV3Veyg1GAZIf15MAcK9PvwcyCFbgqR8i+t2GDNS6sUIBFi2DaNHjf+6wgtb0d+vvB7YbycujqYoakESo4CIcc1JkwnBnGBBx2F/aCDTQdzaagKzKJVIR4LoaEhCopYKo4DDuXlV+F3evAlshbZSgUrAX9nE4M02Dn0E72xPbQNtSGyYFhGRXuCiYFJlHvrx91CQWjgCqrONVXzi74x33/JOBrwLRXf4mEM5hoQ4Vi9vDDBslkjMmTg5yEfCBFY9euKEuX/oqOjggAtbU+HnzwJpqayse5ZMJYiHZUONOIQHUMrGyAU8e7GMKrGGobIhVOEWgMHNhoQrQjCkBJQ8moyZOekIdoZ5Sh3jKq9w/ndddZGX5NDVQfOKsOP9H+YcL+ptHbH30UPvUpqzdz7lzrK/v92X3r6qwg1euFdNrK7CtJ+CsqWOZp4k6lnUA2Q7qQBqDMEUTJZ5izZYDW82cSdpvIewcx/aDKCmgSsilzSXYZvibrukr8+5JDhcMkgx7ujv+bv//28/Qn+onn4ximQamrlEklVnDqtrmPeB/3DxNuKms64u8BNmKtlwpwC3DRUfcUBNGGCsXvTKij+bw+KkhtbAzw4IM30XhoFnyhKJ0JdVSY2E5G1l8xR3UMDMOgv7//pGSzEk4cLathaAay7UC1TvYnSQ+mrfmpBwewgGyTMTSDQsEFVcsgH7F6UxM7rR180w5fe8DUIR+FqsvBdtA3mwcHqeecYw277e62svvW1Vk9qC6XFaTGYtZxJQkUhZWdDq7YraL19+LMG/gdfsqjOd7zUJzrf/0iU57t4J6aCIGMgWqAggI6nB9ZTKg5BLI1gT2SiLJjbxtt7Rv5nvclfrHzHvam9hJ0Bbl08qU0Bhq5bPJlNJU1HTVI1Q2daDbK5VMvx+c48je3XVjzUg1gBXDTsbxIwhlJtKFCsTsT6qjdrnD77ZejKBIzZ5bz2GPvFEHqBHIm1FFhYjsZdVP0qI6BaZr09/dTUVEx3kURXoHqVJFVGaNgoNgVMCC8xcrsG5wWxOa2jdrfKBjIqozqVKFmBQw8CkMbQUtZw3rdDaNPYOpW4iVvI9QclFHj4Yfh1lutIPXyy2HSJPjVr0aWoAGsOakVFSM9qQmXwlDAjifSi/OpQT6gwB5Vo98LyWCKC1ozuA0VU1W47q5nueWmELs7+5g5DB0BmBOfS6O/Eb1Spz/ez+7YbnqHu5kypNFfaufpuaVcPOli3jDj/7N35vFRVXf/f99llsyWmSyTlUCAJBBEERE3sBVxAxdci9ba1tanm63Vai21Wn+tFmnVavs8j22trctTW+tWF3ABtSJaF0QU2QJJICQhmWwzk8w+997fHzcJhLCTkBDO+/WC5N65c+ecO9+cmc893/P5ns9pJafREmnh1mW3sql9E+VZ5X3cf3vQdI2q9ipKfaXMGb97x5Aw8EOgEzgWuA3h8CvYN2IMFQwnEgnTGGlnjpYYveSSiTz77BWccsoo/H7nvp8gGDYcLTEqOHIZDNdfIVQFI4bs8mycfieRQARPsYeO2g6SXUkUm0LObtbfRAIRnH4n2RXZ4LDBpJ/A2xeYJkkZhYBmFic1Uma6bzJoitTKBeAoMk/y1lumSNU0OPtsc33qt77Vz92Xri7Yto0Gl8F7hRp5UY2sSIzGTOiwp0nL4E1KTG1RyKqOoEkQy9DRDLBoMr/7t52au39P+x0LOKXOTo6h8mnpSuqqGjGSSXydacZ1pYiU5CHfdD3/d8438Nq9vS9f5CliwYwFLFyxkHWt6/DZffidfiyyhZSeIhAJEIwHKfWVsmDGAoo8Rf2ulwb8FHNGNQ+4F+HwKxAIjiyiUbjkEnjttR37cnLMIXv79qFr12CxfXsnBQV9s2MuumjCELVGIBAIDgwhVAUjBpvHxtjZY1n96Goc2Q5a1pvOtrmVuX3SgQF0TScejDNx3kRs7m6zJC3enc4rg3scdNWa7r6yaq5JLZ5nzqT2iNQ334QFC0yRes458ItfwCefmHUMSkt3vFgiAe+8w1p3jD+crHD+5xpZEZ02l4wkyWSk07TZDcKqwVqfjtMJFR0KnpSMZneijClF+fNfMIpzebGigVrXS1S0fU5WXZpi3UCx2LAXjiU+ZwanfO8WlJJdZoK7meSfxKLZi1iyeQlLq5dSG6wlradRZRW/08+8ifOYM37ObkUqwP3A+4Ad4fArEAiOHHQd3n8fnnsOnnnGLGfdg8MB//gHI9JA6Y03arjoon+waNFsvve96UPdHIFAIDhghFDdDyRJIisrC2nX9YqCYUfZ3DK2Lt9K3Yo6tISGPdOOd4y3zzG6ptNe1U5umY3ymWEIrDBTfTf/GWQrlH0Zyr5r1knV4uZjnoq+a1KXLTPLzug6nHce3Hmn+U0nHjdTgC07pRnX1NAgd7HwpBTHBlTGdRls90pImkbApvGJ32BdLrQ5ISWDRYe8qMFZNWnOyRjN2nt/xL/q/odVS1aZU5lFKlmjJ3Cpegwz805kQvEUKK+gPhRCKi7e6/Up8hRx3dTrmD9pPhvbNhJPx7GrdiqyK/a4JhXgOeCp7t9/CZTv/1siEIgxVHDYSaXMhJfnnzfTfJua+h/jdsOSJTBjBuj6yIrRl1+u4rLL/kkioXH99a8wdqyP884rG+pmCQ4BMY4KhjuDEZtCqO4HsixTsodZKsHQkwgnaKtqIx1Po9pVJl42kc2vbiYdT+OscKKlNNM4KaUTCUSQU9s57tRqKmc2Yq8PQV3aTO8NV4ElE/yzIGZALRDHnEIsN6BHey5dCrfdZorUOXNMkSp3z9ja7WZpmFTKXJeq61Bby+KxSZoyVW74QCNqVzFsFmpdaZ4e00VrBvjiMCZoitS4Au0OnYenqfwztY6OFb9AsrmQWiRODJ7I3LPmcsblZ/QzRCrJzNzva+a2uZlWOG2/jl0JLOr+/bvAGfv9KgKBiRhDBYeD5mbT1+6ll8x/weCej83OhldfNauIwciK0aefXstVVz1HOm0am1x0UQWzZpXu41mC4c5IilHByESWB96jVwjV/UDXderr6ykuLh6UN0FwcIQbwmxavImaZTVEAhHT8VeV6WzsNNelTszBXeAmWBvsfaxgXDvTTn+TzOw2VGcO2EtBskD7R4AOrXH4zfVQ5YOO7tlRVQW/H2bPNsvLPPCAKUDnzoWf/3yHSAUoLzePDQRMt9+GBsJalGVjdCaF7XiiYVozrbTYdZ4pjRK0wsQWULrvQkVUg2YnKEh4kzJttjSJriDfDH6Lq96/irwJeTCffn7dgxWj24AfY65PPRf4+oCdWXA0IcZQwUBjGFBbC++8s+NfVdW+n3fSSXDxxfD1r5tDdQ8jJUYfe2w11177IrpumprMn38Mjz8+D4tlBOY2H2WMlBgVjFyE6+8QYRgG7e3tFBXtfu2e4PATWBtgxcIVdNR0YPfZ8ZZ6kS0yXY1dRJoj6LqOI9vBKTefgizLpONprEoLucl7UZJd4JkMUvcHdzoO0UZokGGxBRrXQ6Ybxs8Ae6Y5OxoImAK1uRny8+GKK+D22/uKVACPxxS0jz4KBQVQXU2VTyPgszAlYEHRQZNhTWaMFrvOxBZTcxqGQUKBZhekJUhLBg5ZYXLcxSY1B9cqF3mpPLiZ3RaVGowY7QJuwnT6nQTcjnD4FRwcYgwVHCq6DmvX9hWmDQ37fp6iwBe+YBooXXSRef9wd4yEGP3f//2I731vSe/2tddO4U9/ugBFEaJmJDASYlQwshGuvwIB5kzqioUrCNWFyKnMQe75EDagdUMrilUhuzSbWHuMD3/3IbMXzcZT5IHNr0LNVsis3CFSAbqqoS0F/9IgmIbxBZAOQXI7ZHjNFF7DgJYWSCbNbz7XXttfpPYwd66Zf/bJJ9DWRrxIIm23YqgKmgxKMsVnvhS+GMiGKVy7rNDugLRsikEDSKYTgB1fs5eluUuZP3U+7so9ryMdSHocfmsBP3AfYDssrywQCAQmhmG68/7xj/D229DRsX/Ps9lMf7uLL4YLLjDTfEc69977HrfcsrR3+/vfn84DD5yLLIvbiwKB4MhF3GYTHHFsWryJjpoOssqzdohUILglSCKUQLbK5E7KJas8i47aDjYv2QypMDQtA6uvr0jV0xCphVVJaFVgdKYpQGUrxBpAT0FdHaxcaR5fXm6m/7766p4bWFRkugEnkxCPY7e7UJGpcWuElTRGJEqrAzwJaHFCXSa0OkGTJSQk6P7fa9iwyT78oVICjgAbL9s4KNdzdzwIvIcpTu8H+hf3EQgEgsFB1+HZZ831o+edZ5oh7U2kulxmdbBf/tIsa93RAS+8AF/72tEpUn/yk9N48EEhUgUCwZGPmFHdDyRJIj8/XzitDQMS4QQ1y2qw++x9RKqe0mlZZ5ajyZmQg2I1xajda6d6aTXHnBvHGg+YdVB3pqsGuuKwxjDTfXs+2JUMSHdC3XpYtdncN2YMHH+8mW+2dCnMn2/aRu6OggKwWOjIz0S1O7G11FIlp/kgTyc7Aq0OczZVBnQJjD6xZaBKCtm4kBJFWCwZpAvSxJ3xPV6XgYzRF4Anu3//JSAq7gkOFTGGCvaHVAqefBLuuQc2bNjzcTk5MHPmjn9TpphWAofCkRyjZ501Fp/PTkdHnLvuOoPbbjt9qJskGASO5BgVHB0I198hQpZl8vPzh7oZRzU9zr5Nq5tor24nd2LujgcNaFnXgpbQsLqs+Mb6eh9y+p1E6rcT2bgVa6IdLD6webtnTJsgtBYaNTP3dpS993lhWadKDhPvWIPdr1KeOQ7PMceDJJkOHLW1hD//mKrRrt4SL+XZ5XhsHrqSXSz72+0snrKNT/INHPl+QgE31WqIBo/E1z/SsGmg053mu8sftoxMgeZAljJBLiHlTqH6VeyqnT0xUDG6CljY/fu3gVmHfEaBQIyhgn2zfTucdZa5DnVXVBUuvRTOPNMUphUV5lA8kBzJMXrccfm8+urVfPhhA9dfL+qljlSO5BgVHB0I198hQtM0tmzZwpgxY1BGYlXwYcyuzr6x9hihrSFiHTEyizPxjPLQvrmdYE0QAP9kP1L3rKjd2kZu/kd4Sj/E0REDYxvEA2BxgsUL0TrzRZQ8IASqTIMlxWJbO8scYQI2jXSRgmpx4M/oYHZyA3PjJWAzWJxXz7LVvyCwUSetp1EkBUVWsCt2miPNSHWbITMNvkKa5SgBt4aWVtniSfDksWbab1oBVwJiFjAksEoW7GkDh65g82RD1/GgOAmU1+N3+anIrtjjdRqIGG0AbgHSwNnANw7qLAJBf8QYKtgXTzzRX6RmZMB118GPfgSDXZXjSIpRTTOdNXc2SZo+vYjp04XJzkjmSIpRwdGJpmkDfk4hVPeTzs7OoW7CUcfunH3tPrtZiiap07axjeY1zUhIyKqM/1g/rgIXAC5HHWUlT5NhayIaspG2l2PTo6AnTZffyBqQZHCMgpyJoHzIWiPEQm8rNXYNXxpKIzIWq5+U3UVAivNYRhUv2raAYdDuCOMjn+yMPBo6G6gJ1RBJRdB0DZsuc0IULuksYey37+PxtU/yWvVrqLJKggQbcyWyEjJqSmNyi4QvpaIgoWOg2W2opRWobRMg5kQr1Ajag8wbNw+3be9GSocSoxHgRiAEVAI/Rzj8CgYWMYYK9kZ7+47fZRluvRV++MO+JWQGmyMhRpNJjauvfg6Px8af/nSBWId6lHEkxKhAMJAIoSoYluzJ2dfutWNxWNCSGql4inQ0jaRKlJxWgm+cmfJrt7ZRVvI0dlsL7S35yKoFuy8LYsUQWg9a1BSpSIAOmSkarJ0s9Eaos0Flp2SucXVlgS0TK1CsO/EYFt6wNWJoGqdE3GyMN9Je121wZIDL6qLIXUS8djMhS4LFE1Xk1+5imy1OKB5C0zUkScKu2LG5vUSTUVZ60+SlbDgkGzkeP/7CcpxBL1SDJmtUjaqi1FfKnPFzBu1a68BtQA2Qi3D4FQgEh5dQCFat2rHtcsGvfjV07RmuxONpLr/8aV5+2SwY6/Xauffes4e4VQKBQDB4CNdfwbBkT86+ilXBkesg2hJFS2jIVhmrw4qW3JFu4M9aicPeTFekEC1p4Cn2mMIzIx/0mDmrKqlgL4RgADYtZ3F5khqHQXncgpJhBWsGWHbMYBqGQY3RQVpLoWkpPnN20Z4272xaZSs6OrNLZzNGziKairDOFce3NcD/3LeeefFSMtQMkCBDzeCscWfx/BXP84fz/8CJJadgzSvEP24yRaVTcNgySX6epN5ez/rS9ZTklrBgxgKKPIOX0vV7YAVgxRSpuXs/XCAQCAaM55+HykrTn64Hl2vo2jNciUSSnH/+k70i1W5XmTWrdB/PEggEgiMbMaO6H0iSxKhRo4TT2mFiT86+APH2OKGtIXPDAFe+Cz2lE24IkzU+C6s9To5vNcmUk0Qohc1tI7PEA7oGwc9AsoCkQ0qCYD0YOmEHLBtnw9dqoEQNsFnBmoMhqyTScTqTXYRTXWz1JrEmdTRZpsNtId+eRUNnA1EjCsCG1g20N2wmouiMiVrp7GzDSFi5buFrrLhEYtUYH18c80UCkQC/+/B3LJq9iBklM1iyeQlLq5dSG6wlvT2Niopf9TPvzHnMqZyzXyL1YGP0JeCJ7t/vxEz7FQgGGjGGCnalsRGuv94Uqrvyox8d/vYM5xgNheLMnfsk7767DQCn08JLL13JGWcIoXo0MZxjVCAA4fo7ZMiyTPbRUIxtmNBW1UYkEMFb6gXA0A0SoQTRligt61swNANnnhNZlUl1pZAtMqlIyjRYKqlHNdoItWRhdVnJn5KP1ZqA1tUQb4NWCVpcYIuCG7CrVNkhkJQodeVCbQpiBvFUF21GhKSRRjYgKaXRMHDJNuScXDpJUBeuQ94pKWFD63rsyRhjQxJj25JszYTNPp3KxiSP/N3gmz8dS3ZGNl6bl/Wt61myeQnXTb2O66Zex/xJ89lYtZH4T+LY43Yqbq7AffLe16TuzL5iNAxUAXHADpQDtcDd3Y9fh2mgJBAMBmIMFfSg6/CnP5lrUMPhvo+NGwd//KPp7nu4Ga4x2tYW5Zxz/o+PP94OQGamjVde+TKnnDJqiFsmONwM1xgVCHoQrr9DhKZpbNq0ibKyMuG01k1PuZh0PI1qV8kuz8bmGZiVjZ3bO4m2Rkkn0sQ74sQ74hi60fu4d5RM+ek6hhYh3JikYZ2TYKNOR3UHHms78ngD3/g8MosysKY3wvYaCKZgSxySGWYBU7Jh/ATIySC+fQ1pm4ylaAaJ/C4a176PpSmALaljR8Kq2pC8bhRXEps7F0m1kIp0YRhGr+OQgUEkGSE3LlEW0JAkmbRkEJV1DMPgvrNdFJQdD4AiK3jtXpZWL2X+pPm4bW7cNjfTnpwGzcBU4NwDu2Z7itEGYDGwDAhgOvqqmBp9M2ABzsMUqgLBYCHGUAGYtVGvuw5WrOi7X1Hg5pvh5z83nX6HguEYo01NXZx11hN8/nkAgJwcB6+/fjXHH18wxC0TDAXDMUYFgp0Rrr9DSDweH+omDAt2LRejp3VkVcbpdzJ29ljK5pbhKfLs9/m0pEbrhlYCnwdo/qyZwJoA7TXtdNZ3oliV3lIzslUmpyRB2ZRNjK7YhM0SQpI1jAkKsVPc1Hw+lqyZV5NfMYasruUocjOEa6AzAVti0CmB4gSbHSZUwNix5rcjPYnd5kW1Qk14G+tb1pP0JbF4PFRaChnjHoVisRK3pJGbV6IrMpKhIyFh0cCb0FB0QFGQEjIn16WRkUnJoBqgpNL8+bQM1syZxnhlh5AvkUrQP9dpsDQwoXiCabu7FHPV+M0clOXurjG6FrMmag3gA0oxhWm8+6U6MdejfgmxWF0w+Igx9OjmySfh61+HZLLv/mnT4OGHYcqUIWlWH4ZTjNbXhznzzMepqmoDoKDAxbJl11BZKVwEjmaGU4wKBIeDAxaqW7Zs4YUXXuDdd99l3bp1tLa2IkkSOTk5TJw4kdNOO40LL7yQ0lKxdmKksbtyMbJFRk/pRAIRVj+2mq3LtzJjwQz8k/rXFDAMg0hzxBSk3cK0bWMbWqrvHRiLw4LdZ8eSYcFb6iUjO4Os3CbKRr+Ew95MKuUiGs/DMBQkSUPWW5l0wkf4xqdRsk6AwGaIR2GrBq0aKBlgtZp5ZRUV5u89xAMUu3JprKuiuW0zVsVKpi2TEwpOwGv39h6WqSWxt9mJp+PYExplLRq+thT2FEgGSKTIjOrIBuiqREuGQXZEZ2Ohjb+c4+fMrLEAeNu8HLPyGCasnoDaolKwpAAcmGpSBq7CzMs9RBowRWod5rrTnnuvBrAac2bVC+QB9wOLAFGBTyAQDAaNjfDNb/YVqQ4H3HUXfP/7oIpb5v2w2RQUxbxjWVKSyRtvXMP48VlD3CqBQCA4vOz3x8PLL7/Mvffey4oVKzAMg3HjxjF27FgmT56MYRh0dHSwevVqnn32WW666SZmzJjBLbfcwvnnnz+Y7RccJvZULgZMJ15PsQdXgYv2qnZWLFzB7EWzceQ4aF3f2keYRluj/c5t99rJOzYP/2Q/eZPzyK3M5bP/+4zVj67GXezGkdFB2Wiz3ExnZBQ7z//pukI0lIktKxul5Q3Y/hpU66BGIegAiwOKi2HSJHA6+7yuoadpDW7i0ZBOQtfQDZ3KnErKc8r7rD0FsCpWit3F1DauZWxtBF9KJgx02iQMCawJjSy9u+CNphG0QmlI4X8vLOTUklORkSmoK+Dcp88ltzmXLmcX9bn1FI8uhkbMRaQA1ZhToZMO7f1ajKl9dxapAOuA7d1X8BQgE1gPLEGk/woEgsHh7rshFtuxfc458Ic/wJgxQ9akYU9urpNly67hG994kT/+8XxKSjKHukkCgUBw2NkvoXryySfz6aefctFFF/HPf/6T2bNn4/HsPr0zHA6zdOlSnnnmGa644gqOO+44/vOf/wxoow83siwzduzYQVkkfKTQUy5mV5HaiwFaXMPisFD3Th3/vOyfoIOu6X0Ok2SJnIoc/JP9vcLUXeTu5xRWNreMrcu30l7VTskXPsJhb+4nUg3DINERwWbtItPWBE1x89tQtRsKPTDaBmNPg6z+5gOhWDvbty+nJpHm7WQRM0omE01FaYu1methd9PFiWkf6rYIrXYNt9NHZ6yFqGqgGzpWCfwRc/nr5iwYFYaq44o5bdwXscgWvG1ezn36XLJbsmkc1UhXusucvVUyTZcjK3As0IQ5FXqAU5w7x2gYc02qj74itQ7orvrKCUDPvXkvZirwfMy1qwLBQCPG0KOXmhrTPKmH446DJUtguIXCcIzRwkI3r7zy5aFuhmCYMBxjVCDYmSEzUzrjjDN44YUXyMvL2+exHo+HSy+9lEsvvZSmpiYefPDBQ27kUCNJ0h6F+dHAnsrFJLuSdDZ0EmuPEWuPoSXMFF4tqZEIJ8gck4nL78J/rClI/ZP95E7MRbXvO+w8RR5mLJjB+795nUz1I6KdNnQkJNl0AU5HE2jRLmy2LvK9bVg3hCFpAY8DJjjh+NvBsRwitRCNgd0PkgVNi1Pf8gmh8BbqdStPUcp1M37KvAnzWN+ynoUrFrKudR0+uw+/049FtpDSUwQiAWau2MCFGzJ46HQHH9o6CDnM/uqAYsAWLzhSMLEVvrIxg1DuKN6TLQAcs/IYcptzaRzViC7pJLQEY3xjsG60QhJzanNc98kOYopz5xitwjRO2jn5vgFY1f17BbCzX6Qf0wF4IzBt/19SINhvjvYx9Gjm//0/SKd3bN999/ATqTD0MfrBB/Xcffc7/P3vl+J0Wvf9BMFRx1DHqECwL4asPM3ChQsP6uT5+fkH/dzhhKZprFu3jsrKyqPSaW3XcjEAyc4kW97agp7eacZUBnumHZvXhhbXOHPhmYw/Z/xBB65/kp9ZPynG+EinZZuPVCyBoetIehxV6cLr6yIz0oG1XgPFBY4MGF8OORpMPQEyzofGJdC0FLpqiSRCbAnX05hM876WhZ5/Dr/5wl34neZ62kn+SSyavahvXVM9jSqrjJZ8XL7dR7AwB6saMBd7Yv6QoNf8SAfaXQqa18Ok1Y18PHM8Eh4mrp5IxBVBl3RCiRAem4cSqcRUiADHdZ9D4aCmOHeO0biikMY0TjIwBei67uOK6F8r1YK5ZlVYNAgGi6N9DD0aePllePVV2Nn0UdPgiSd2bJ96KsyZc/jbtj8MZYy+/fYWzj//73R1JZk37yleeulK7PtxQ1dwdCHGUcFw54hy/a2trR1RhkqDcfGPFNLxtOnuazFvgxuaQcMHDehpHVumjcySTDKyMrB77UiKhGEYtK5rxeay7VukpsIQrgItDoodPOVg2XHH0JWlQl4GjjFjiDdtQQ9vQ07Gsbd2orRqoNrB5oSyMigvN518Q+vM8zmKYPx1RAsv5Jn372Z50+skjBzCtgK+P/OnnFl6Zr/2FXmKdtQ1bdtomiepdiZuiRCUfsJvy5ppleOc0mKnMR0jagFNAqsG5e2Q9Gez3hnh9xUd3PZRguxtrajSeFxBF3VZdUTjUTw2D1M8U3CucZpKshjI2akRBznF2ROjdsw/7DiwBqjvfnw8MJn+hsKp7uPt+/9SAsEBczSPoSOdV16BCy7Y93G/+hUMwg33AWMoYvTVVzdz8cVPEY+nu9ugk07r+3iW4GhFjKOCo40BF6qfffYZ99xzD8888wzJXX3oBUckql1FVk13X8Wq0LS6iUQ4gWJTGHXaqH6pvHrKLFmz1xTfaAM0LoamZRAPgJ4GWTVTdPNnQ+FcU2jKNkh3obS9iVPrgvY4NKdBzgBLBoweDZWVO4rv6UnzPIopu96te5dfrfgVzV3NgIsLyi/gxlNuxGPbe/qM2+ZmWuE0wokwVW1VVG9fy9vubVSrSSals4jFt6Eq4E6awk/VwJJViMPl4Xi8fOYJ8J/8FK3t9WhGA6lECskiUSFVULK9BOcn3cZOCnDMLi9+iFOc5ZiZxG8CCcz2TaFvKvDOBDC1ccXBvZxAIDiK0XW49dZ9H3f22fCFLwx+e44k/vWvDVxxxdOkUqYwnTOnjGeeuZyMDMsQt0wgEAiGBwckVNeuXctDDz1EdXU1Pp+Pyy+/nIsvvhiAVatW8bOf/YzXXnsNi8XC1VdfPSgNFhx+ssuzcfqdRAIRDM0gtDUEEhRNL9qtGI0EIjj9TrIr+psYARBcC2sXQqQGrD5wlYJkASNlitaax6B5OZRcDvXPQddWaI3DFh0MG6gOyMuDY46BzF2cEOMBsPvpsPi5782f8ermVwEodBfys9N/xvSi6fvV54ZwA4s3LWZZzTICkQCjalppymzG6FIJSwppZwZGPNo7OylJViydHoiB3Wmh0ONhzZg4Pz7121jiJzH6+dFUVFdgjey09igfmIBZnmZnDnGKczumeXAQ8AAnY9ZL3R1a93HzEEZKAoHgwHnqKVizZsd2dnY/g3UmToRHHjm87Rru/P3va/jKV55H08x1JJdeOpEnn7wUq1WkdAoEAkEP+y1U33//fWbNmtWn2PBTTz3F/fffTzqd5tZbb8XtdnPLLbdwww03UFBQMCgNHgpkWaaiouKodVqzeWyMnT2WlX9YSbjBrKOSMzEHR+6uCst0+Y0H40ycNxGb29b/ZNEGU6RG6yCzEqSdPpQlKziKzdTfwNvm+tKqTKhOQIUOsgsyfTB5Mvj712nF0DASHXxuGc8P//V1QvEQsiRz5TFX8u1p3ybDkrFf/V0bWMvCFQup6ajBZ/dR6i0lOtZFW2gzhWGDTqMTOSWBRcFAN8WqrJgzod3Kz98FtX4JadUEprw6BZoxF7A6gDHAWMC1hwYcxBRnT4wul2VuxzQtzgIK2OHuuysapvFSKTBMl40JRghH+xg6Ukml4I47dmw7HPD555CfP3RtOlgOZ4w+8sgqrrvuJYxur4Orrz6Wv/71IlRV/H0I9owYRwXDnSFz/QX4xS9+gd1u5/nnn2fmzJnU1tby9a9/nTvuuINYLMZNN93EbbfdRuauM1wjBKv16HbhK51VyvK7lpOKpvCM8pBTkdPvGF3Taa9qx1fqY/yc8bs/UeNicyZ1V5EKZtpueCN0VkMwAaEuWKtB/RgYG4Tjs2D0SWZq764YGomOz/msM8gddW8RMqyMzxrP7affziT//hclbQg3sHDFQupCdVTmVKLIZhvbbQpdLisZgThqKpO0nCauxjEkCSQJm2HrzgEGMLBEUqS7vMQ/VUxX31Igglm8dDf6vZeDnOI0gCdtNh7q3j4duAb4HaaRkg9T+1owJ2wD3S9TCizggCrhCAQHxdE+hh7p1NdDQ0PffcuWwebNO7ZvuOHIFKk9HI4Y/d3vPuCGG17t3f7Wt07gf/93LrI8jBfvCoYNYhwVHG3st1D94IMP+N73vsc555wDwKRJk7j//vs5/fTTuemmm/j1r389aI0canRdZ82aNUyePPmodFozDINPH/8Uq9tqGii5bIQbwjj9TmSLuXY1EogQD8bxlfqYsWAGnqLdrAFNhc01qVZfX5Gqa9BVA50boSsGW2KmivJmwAQrnHU9nH8KVN0H4fXm87vLzWCkMGIB2kKb+bizg0cSuQRlJ985/ptcc9w1WJQDW+uzeNNiajpq+ohUAAODgDVFXM4gJx0nodrxR3KI2qJ0WaP4NJ+pAJMGaCFSigvVyMHutcM9mErwJ0AN5iLS3YXRQU5xJoFfGAbPxeM4MjK4AvhR90sswqx0sxTTnymN+Ufvx9TCcxAiVTD4HO1j6JHOAw/AjTfu/ZjMTLjllsPSnEHhcMSorhu8/np17/ZNN53MvfeePSglHQQjDzGOCoY7uj7wRnD7LVSDwSDl5eV99vVsz5o1a2BbJRhWbHxhI5uWbMLqtHLO/ecQrgtTvbSaYG3QdANWZZx+JxPnTWT8nPG7F6lguvvGA+aaVADDgFgDBD+HWBfUxaFFA9kOVivklUCJHU6cDtnHg3NRn3Iz6Glieoo1oQCvRXTe0/Ip9J/Ik6f/jFLfgTtOhxNhltUsw2f39RGp4z6oYoWrmhQyLY5RZCVC2NJhNFnFnXKTnfJjScpgRIAkSG4C/kL8Sh4VtgqzHowbc+pyIQM6xdkO3Ax8JknIhsGPdZ0rdvoAK8Isxzof00Q4jrn0tQKxJlUgEOybhgZYsGDfx/34x+DzDX57jmRkWeLppy/n/PP/zowZo7jzzi8KkSoQCAR7Yb+FqmEY/e7g9Gzb7aKwxUilraqNd3/9LgAnfu9Exp9jpvROmj+Jto1tpONpVLtKdkU2NnvCFKOB3ZeaQYub7r6SBeKtEFoDsXZoSEBjErCbRkmFhaZRktO5o9QM9JabYfR80sG1LNnwHM9veoXqtBcsbr5/6ve5tPJSZOnAcuR7nH1XN62mur2aibkTex8r/HA9X/nvdzndJ/OjC8YSsauEXGOxR5uwakGUdBRZT4KhgpIBrjFoWUUEHXXM6zwLd5N7R5mZSQzoFOcm4EagCXO56w8bGrh03LjdHuvmgCrdCAQCAQB33QXxfTiQT54MP/jB4WnPkU5GhoVXX/0yFouYERMIBIJ9cUCuv0uWLKGpqal3OxqNIkkSTz/9NKtXr+5zrCRJ3LivXCHBsCYZSbLsJ8vQkhqjThvFcV85rvcxm9tG4bRCcyPaAI2P7bvUjGIHIw2t70GsGZoTsC0BmhVkt2kXOXmy+RP6lZrp4fOOrfxy+W+pbq8GbMwomcGCGQvIc+UdUP92dfZtj7WzNbSVjlgHxZnFlDYnufoPK5F0KG03eOilVu6cMZFqTzOj0vkoyhiMdBhfyoPidYLbi6bIVKlVlGqlzEnN6V9mZoCmOJcDtwExoAS4T9cJRaMH1H+BQCDYG9XV8Oc/79ieMgXuu6/vMXY7nHAC2Pa29v4oRdN07rjjLf7rv05g9Ghv734hUgUCgWD/kAyjx3du7xyok5MkSUdEYeJwOExmZiahUAiPZ/cpq4ZhoOs6siwfNWk6hmHwxk/foGZpDa48F5c8eQn2zN3MnO9aamantaPEA5AMgrMUyr9rpuxueBDCSahNQbxbhLrc5gxqYWHfavDRelCdcNIjYHETS8V4aOVD/P3zv2MYBl67l1tOvYWzxx34Gp9dnX39Tj/BeJD/1P8HVVZRO0I89WiEkhAoskLKquJOqKzOv5y7T95Ig7sVV9KHK+GiIKMA1aMSkAME5SClWikLuhYwKTrJnDW9lwGbzjSAJ4Dfd/8+HXMJrPsojFHBkcPROIaOBL7yFfi//9ux/corcO65Q9eewWSgYzSd1vna1/7F3/62hvHjs1i+/GsUFIgFF4KDR4yjguFOKBTC6/XuVVMdKPs9o1pbWzsgL3ikkkwmj6oU53XPrKNmaQ2yInPmPWfuXqTuT6kZmx9a3oXlr0OHDz5LQlEC0i7IcMDECTB2LOx6I8TQTJFbPA8sbt6vf59fvfMrGjsbAZhTNoebTrkJr917wH3bk7Ov1+7FYXEQ7mzlL89EGRUykJBRZZXrzkkR89i5/r2Z3Pyfs3l97Ed8UPQRLZ4WYu4YFiz4NT/zYvOYE59DkV50UGVm9kYSc4nrS93bl2GuT1UxRevRFqOCIwsRn8OfTz6B+++HVatMC4ENG3Y8NnMmdHspjlgGKkYTiTRXXvkszz9vXsDa2g5WrmzkggsG6MNAcNQixlHB0cZ+C9XRo0cPZjuGNbqus3HjxhHptJYIJ2ir2mmtaXk24YYw79//PgAn3XASeZN3k1IbDsMb/wO1qyFrHCgauHa6NoYBkToIr4NoF7R3wYoI1BeCNwgTPDBuBth2M+AamrnW1VVKOHsG9//7Tl6uehmAfFc+P535U04ddepB93lPzr5IEE1GuH1xF9MajN61ri+OTfOfYog443xyzg+5buW3OHfLeUxtnYZarlJAAXbDTkW6ArfRfcf8IMvM7IkO4BZgNWaN1JuBK3Z6fCTHqODIR8Tn8GbFCvjVr8wZ0z1x9919E15GGgMVo7FYiksu+SevvmrW7bFaFf75z8uESBUcMmIcFQx3htT1F6CpqYnHHnuM2tpasrOzufTSS5k6deqAN0ow+IQbwmxavImaZTVEApFe994MXwbtNe1gwLizx3HMlcf0fWJDAyxeDK+/AtUrIJ0GSztk2WF6MZxaAp4IBNdALAj1cWhKgdsCFVaYcAlcfR40/xkim0Dbfbqw4SzlPffp/L+Xb6A91o4kSXxp0pf47onfxWFxHHy/9+DsG0qE+KDhA65+t5Mr1hpISMhIhK06C0/ViDptoGnElATPT3iJC6suIT9fYbptOs6ks++LHGSZmT1RjWma1IhpmnQPcPKhn1YgEIwADAPq6iCROPDnbt4M99wD77yz9+POP9+cURXsnc7OBBde+A/+/e8tAGRkqPzrX/M5++zdm9wJBAKBYO8cUOrv9OnTaW9vp2dZ66JFi3j88ce56qqrBq2BgoEnsDbAioUr6KjpwO6z4y31mvVQkzpbl28lEohg99qpvLyy7zqItWth4UKoqQGnDHkK2HymMGuPwoufwXur4UIFLBrUJ0C3guIBVxaM98Bpl0P2NCgs61dqpseAKZx7Jr/duoGX1v4JgLG+sfzs9J9xbN6xe+1Xj3tvPB3Hrtopzy7HY+ubI1/VVkUgEqDUW4qBQWNnI9Ud1bRGW/liVZKb30piUWyk9TQ6Br89Cbb4QMZAShtoskFBPI90QZrpkek4A84BKTOzJ1YAPwWiQDHwADDm0E4pEAhGCOEwXHIJvPHGwJ531izTMgCgpMQsPSPYOx0dMebMeZL3368HwO22snjxVcycefRmowkEAsGhst9C9c4776Szs5MHH3yQWbNmsXnzZm644QZuuukm5s+ff8BmS0caIyXNItwQZsXCFYTqQuRU5mC1xnFm1KDIKTrqYpBUsDjsuPJcfPj7D/EUe8y6qA0Npkitq4PKSki2QNtm0BOgdYErChkG1KXgL8AMG2S6wZsJk48Bvx/C63dbaobwRtDi6LKVl7ZXcd+HfyKaiqLKKtcefy1fm/I1rIp1j33a1b03radRZRW/08/ssbOZWzaXIo+pGOPpOPF0nNqOWmqDtUTTplNuRbPGfS/EsSlWJElClmQ+zU7x6FSdlGygaGlkZAoiuVx5zJcZd/M4nO84B6TMzO4wgCcxhakBnAD8Gsjcy3NGSowKRiYiPgeW9nZzzejKlQNzPkmCyy6Dn/7UdPc9GjnYGG1piXD22f/H6tVmVQSfz86rr17N9OmHeKdSINgFMY4Kjjb2W6iuWLGCb33rW1x//fUAVFZWoqoqF1xwAevXr2fSpEmD1sihRlEUJk+ePNTNGBA2Ld5ER00HxVMk8nOXkuNbjc0SwtBSxFwpxpe4aI9MpZOZ1H/aweYlm5l63VQz3bemBiZOBC0MXdWQ7AAk8xtOUocuA+wytBvQYIMzpsLoMSBLeyw1g8UN2dPYGtzK3e/czartqwCYnDeZ20+/nbG+sXvtz67uvaXeUiyyhZSeIhAJ8Njqx1i+dTkLZizAolh44tMnWN+yHlVRkSUZq2LleLmI3/+rGo+mQvcEsi7DDy9zY9jiqHoKR8yOM+lgybY/U3nvueZC0QkccpmZ3ZHCTO99oXv7YuDHmJO2e2Ikxahg5CHic2BpboazzoI1aw79XKpquvveeitUHMXLKA8lRp944rNeker3O1m69Csce+yBlUsTCPaFGEcFw53BuJGy30J127Zt/dajTp06FcMwaG1tHfCGDScMw6CzsxO3231EW4InwglqltWQN6aVSWWv4LA3k0q56Ir6CddHkAwNT06cCWPfJxqvJRU8j+ql1UyaMwrbay+DLQItb0G6E3OeD9ANiCgQ1wEFVAly7BDNBH+RKVLBXHtq94On7zehtJ7m8U8f58+r/kxSS5JhyeB7J36PKyZd0WtmtCf25N4LYFWsFHuKyXfl82HDh1z0j4twWBwokoIsy9hVO5P9kxmTUcB3F72Jr6NvRftfn5/FJlcHuqGjpBUyUnZu/eRKKp86wxSpPbgZsNIzYGYN/xhYhfkyN2Jq4X1F3UiJUcHIRMTnwFFfD2eeCVVVO/bl58O995o1TQ8EVYUTT9yR5ns0cygxeuONJ1Nb28Hzz29g2bJrmDAhZ5BaKTiaEeOoYLiznxVPD4j9FqrpdBqLpe+cTs/2kVAv9VDQdZ2ampoj3mmtraoNo6ue42YtwW5rpTMyCi1pEGuLYaRBslgw7Fl0RgycjgaOm7qY/7z6RcIPP03uprcg3wpp2SxDo/ihoxWMFkhoIMngdoPXCzrQ2AV1IZiY26/UTA/rWtZx1/K7qGozv3GdUnwKC2YuoNC9f9+a9ujeCyS0BFuCW6jpqCGaihJPx8l15HLl5CtRZZVlNcsodhXxpYffp6S6742WTyZm8acJnaCBruk4UnbKOkr4zqnHQc7gVbWvwRSmDYATsxTN/nobj5QYFYxMRHwODDU1pkjdsmXHvlGjzDWqZWVD1qwRwaHEqCRJPPjgedx22+nk57sGqYWCox0xjgqGO0Pu+rty5co+9Zs6OzuRJIkVK1YQDAb7HX/JJZcccgMF+8fuyszYPH1FVTqeprBoNU5nM+2tBSRCUdKxtPmgBE6/E0mWQEsQ6bDidm6kwG9BbwmDZoAjF2zFUB+B6lqQU5CvmGVpPPlg7V5HKhug6aaA3anUDIWmBW48HeePK//I39b8Dd3Q8dg83HzqzZw3/rz9vku4J/fezmQnVW1VbAtvQzfMPxi7aqfAVcBY31gWzFhAOBGmpqOG+sb15G4P9TlvR46Tmy5xkIy0kNY11LSCPW3hV+vHYrnrvIN5a/aL9zC9lyKYS1t/C+w96VkgEBwtGAa8/jp84xumXUAP48aZIvUorh43JHz+eYBQKM5pp5X07pNlSYhUgUAgGGAOSKg+8MADPPDAA/3233nnnf32SZI04mdahwN7KjPj9DsZO3ssZXPLTDMkQNI7yc9bQ7BRJtIeM08ggcVhwZ6poBA2a54apnhNJKwUj6tH8cwFrwxtVqhZD8mk+dzMHBh1PLAV0mFI20DJgLQBCmC0QqjVFKmVC8BRxEcNH3H3O3dTHzadEc8Zdw4/OvVHZGVkHVC/d3bv7SGhJfj3ln+T0lMA+Ow+xmWNo8hdhKZr1AZr2di2kWmF01gwYwELVyzk+us0bvu7hZM/bSWtWvnvmRPZEHwXTdJRNQlXEi7dIDPDFYZBiGcD+AemMNWB44HfAN4BfyWBQHCkoevwr3+ZNU4//rjvYxMnwrJlIm33cPPxx42cc87/kUxqvPnmV5k2TbwBAoFAMFjst1B96623BrMdwx77gS7+OQzsscxMSicSiLD6sdVsXb6VE/7rBJo/a6bprZeZMjlIR2sWyBI2txWbx4asByG188yiDKqLSCwLT04Ij8MD1VshFjNnTT0e0/m3oMA0UkrnQ6QOYg3m+tWWmFk3tdQPY+dA4RzCipsH3/4lL2w0LYL8Tj8LZixg5uiDK84XT8dJ62ks8o509JqOGlJ6CrfVzQkFJ+DL8CF1r+6UZZm0niaeNteiTvJP4jeVv2HTqk2oKZmw5Rm65DG8rTyGM+EBKY2qa2TG4ecfJiCvyXQbWbAABsg4LI3p5Ptc9/aFmLOqezNN2hvDMUYFgh5EfO4/qRT84x+m0fr69f0fnzLFnGHNzT3sTRvR7CtG3323jjlzniQcNovW3n77W7zyypcPR9MEAkCMo4Kjj/0WqqWlpeTm5pKRkTGY7RmWKIrChAkThroZfdi1zIys7HD4UawKnmIPlgwLW9/eyuZXN5M1RqXsmFqc3gQpLYnq8YBkNQVqj0hVHKC6Qc3AMCDdESLD0Yb1jX+AzWZWlJ861cwz2zlFV3VC5kRwj4dYOzRvhovnwRm3gsXNm7VvsujdRbRF2wC4vPJyrp9+PU6r86D7b1ftqLJKSk9hVayk9TTV7dUAVOZW9s7Q2qNJ8hpCEI8jJWI4elKd10LBwgIKagpIZXQRyorweOkz1HvrsOoqGBZA4ycrc/E7kzBtGmzaZH5zXLQIig6t7EAIuBVYiWmU9EPgKvZtmrQnhmOMCgQ9iPjcfzo6zHWon3zS/zFVha9+1TRO8noPe9NGNPuK0TffrOWCC/5ONGpm7MycWcJTT112uJonEIhxVDDsGVLX39LSUp544gmuuuqqAW/EcEfXdTo6OvD5fMOmXmxPmZldRSoGdDZ20r65nVhbDKcnSPmktVSe2kDBhBhWoxOHJ0IqsZ1kOpN43EBDBWsWWMwqnUY0SiIQxi5FydDi4MiEn9wAy5ebC6R0HXYXjIYMde1QMQUu/w6tqQSL3voFb20xZ+NHe0dz++m3MyV/yiH3vzy7HL/TTyASoNhTzJbgFpJ6EpfVRaG7EG9bhGNW1jFxdT3uUJx0MgaqSvnaB2F6Fbw/F1qLoBIsVdtIphr48+QlyIYE3Wtbj2kZzzWrboTp/zK/IZaXm9MbS5bAddcddNu3YJombQMcwN3Awc0r72A4xqhA0IOIz/3nxRf7i1S7Hb75TbjlFigp2f3zBIfG3mJ08eIqLr30nyQS5vKPs88ex/PPfwmH42DzXwSCA0eMo4LhzmCYKe13pA+G5fCRgmEYbNu2bdhcg54yM3afvY9IDW0NUf1aNQ0fNBBri5Fd0MRZVy5j2tmfY3NqWPzHINtzsLocKKqGw9aIx9eKardiWDLRY3GS25qIN3Zg1eMU5AVRi8rhjy/Cd74DP/uZ+S1p3TqzRkIyabp8JJPm9vr1UFKC8ZOf8K/Oj7jsn5fx1pa3UGSFa4+/lr9f+vcBEakAHpuH2WNn0xHvIKWl2NS+CYCyrDIK6zq4+NEPOPWNjVgTaVr8Ljb7LWRbMrF0xeCPj8E7t0LuWtCS0FBPrp7Ljesux54yDaEkCRb9ey6KPhaMc80XVRRzGmPpUujsPKh2fwB8DVOkFgJ/5dBFKgy/GBUIdkbE5/4T6uvvxs03my6/v/+9EKmDyZ5i9Jln1nHxxU/1itQLL6zgxRfnC5EqOOyIcVQw3BnS8jSC4UNbVRuRQARvqbd3XyQQYfvH2wGQrTJFx8CpZ63E4eiis6uUZGeKzIiK01GMklqL3RknGVWw2HRcNNNSA1rEQJU1vBkJMstysY7JhPJvQmZ34fJJk8y01yVLTLFWWwvptDnb6PfDvHk0zpjCL6r/m5WNKwEzDff202+nLHvgayfMLZvL8q3L+aDhA6KpKBmWDI5NZ3Pu0yvJbumicZQPXYJQIkRlwMC/rRFakyDPBK0OPlsI438MsRgWp4frl1/CRStncPsZj5AfsXF8oAScSWicBOM/BmvC7GdtLWzcaKYDHwD/BO7FNE06DtM06cAspAQCwdHGnXeC8+BXSQgOgccf/5Svf/0FdN388vWlL03iiScuxmIRpUEEAoHgcHBAQlUUGB4epONp093X0j2bakDgswAAmaMzyZ+Sz+ii13E5A3RGRiHJMoaeQtcMsPogHUWR0mQ4LehRFasliC07hSY5sZcWoFROhfQ2cJb0lpTppajITHudP98Ua/E42O1oZeP525YX+cN7N5DUkthUG9+d9l3mHzO/X43TgaLIU8Stp93K3CfnEk/HKfIUMemjreQ0hWkYlUk0HSWhJRkbkhi7rQtZkqGtDdKvQf5MaK+CTc9DYhIkDNBgVMzPo//+NqmuVkCCrDTEciCUD7lbwWIxxXk83qctYaAKiAN2oBzw9LxfwH3A093b5wM/BayDclUEAoFAcKhUV7dz7bU7ROrXvz6Fhx++AEURKZcCgUBwuDggofrDH/6Q2267bb+OlSSJ6urqg2rUcMTtdg91E3pR7Sqyarr7KlaF4JYgiXAC2SqTNzkPizVGjm81qZQLkDF0A0kGmSR0fAK6FWI66FFkTQIMlAIDpp0I1iQkt/QpKbNb3O7eGcWqtip+8cb1bGjdAMD0ouncNvM2ijyHZji0P7TF2vDavdhVO5Ntoxmz8n0CthShVBcZlgwq5FzGVG80RSqAboAWg7bt5u+dr4GRC3oSZBdk6BAOYUGF7CywSBCRQev+U0mlzBnkbue9BmAxsAwIYIpSFfADs4HTgd8BH2IaJX0f+AoHb5q0N4ZTjAoEuyLiUzDc2TlGx43L4g9/OJ/rrnuJ668/kQcfPA9ZFjfrBUOLGEcFRxsHJFSLioooOkS3033xP//zP/zmN7+hqamJ4447jt///vdMnz59j8cHg0Fuu+02nnvuOdrb2xk9ejQPPPAAc+bM2eNzDhRFURg3btyAne9QyS7Pxul3EglEcOW5aFnXAkDuxFxkq4wzowGbJUQ0bqbspmMpVLuCPb4S6tthexqsDvCkIEcxS8mQMtNh1XFQPM+cSd2TSO0mkU7w8KqHefzTx9ENHbfNzY0n38gF5Rccltl3wzB4dPWjWBUr3572bb6amoSm3ES0Ip8yq41MWybW15aaghRME6h0GuRjQcoGmw6pRtDaQXOB1gGhbiGakwNuD2gKyDoo3W7BgYCZ/ltRwVpgIVAD+IBSzNIyKUzR+ifgl5gzq1mYpkmnD9K1GG4xKhDsjIjP/ScSGeoWHJ3sLka/+c2pTJyYw6mnjhIZZYIhR4yjguHOkLr+Atx8882D6vr71FNPcdNNN/GHP/yBk046iQceeIBzzjmHjRs34vf7+x2fTCY566yz8Pv9PPPMMxQVFbF161a8A+zbr+s6gUAAv98/LJzWbB4bY2ePZfWjq4m1x9ASGla3FV+pD1WJ4nHWYLF0Ykk7SaacaPE0XnsDysoG0DBL0Hhy4JhJkJ0JiSB0VUPZd2D0l8Cy7zt2q7av4q7ld1EXqgNg9tjZ3HLqLWQ7sge38zvxSdMnfB74HKtiZf4x83F+vA6UDDzeItMNaetWs9YDmKZPqRTYHSCXYBgKnZYOPCkdDMV8XDLMn4oCDof5vLgbMjohswk0DYJBmDePBrebhUAdUAns/Kdp7f7XAHRhrkn9AwNjmrQnhluMCgQ7I+Jz/0gk4I9/3LGdnQ1HYUW4IUHTNF5/fS3nnHNMnxg97TThYCUYHohxVDDcGQzX32FlpnT//fdz3XXX8fWvfx2AP/zhDyxevJi//OUv/OQnP+l3/F/+8hfa29t57733sFhMB74xY8YMeLsMw6CpqYncYVRdvWxuGZtf3UzNshoUq8Lo6Solha+R41uN096Ew9aCVQ2Riso4MlQyu0KQNiCrAI45DgoKdtRCtXkhlQW+KfsUqV3JLn73we94bv1zAOQ6c/nJaT/hC2O+MLgd3g2Prn4UgAsrLjTrptrt5mxoT3ru6tU7DtY0wnaJqsk+4vGttCcNWi3rmFWfhb/TigMViEKG3RSrXV2Q6YOkA8asBiUKVVVQWgpz5rAYcyZ1V5EKUAusBgygAPACGxhcoTocY1Qg6EHE5/7x8MPm/bUerr8exPfRwUfXDX7wg1d56KGVPPGEwZe/fNxQN0kg6IcYRwXDnRHt+ptMJvn4449ZsGBB7z5Zlpk9ezb/+c9/dvucF198kVNOOYXvfe97vPDCC+Tm5nLVVVdx66237nH6OZFIkEgkerfD4TBg3k3VNNN+XpIkZFlG13UMw0DTNAzDQNd1FEXpPa6HnuN33S/LMpIk7XY/9L/zsKf9iqJgGAaxumbCb61E74wiux3YLUlki0xuUYBjj/kPmVltpNIuQp1FKHoHkpFEMXSy8uLI2YDvWIyx0zCQTBVlGEgSSPEAujUXwznenDXcQ5+Wb13Or9/7NS1RM9V4XsU8rj/xetw2d29wHmifdre/57rvbX9VWxXvbXsPWZL58jFfNts5bhxSbi5SIICUSGB0l5BpcOosKUmxbIKFgKeFpNRKiAQ5EZ2PCwN8UPQg9/z765zZMG5HmnBnFPQKcAYwLMuQ1m3GKC3F+PGP6SosZJlh4DMMZMxL2d1ZPjUMaro3RwHHGwZNssxSw+ByXce9lz7tfN33tH9vsdcTqz3XfSBj72Dfp0Pt065tFH06MvvUE587x+iR3qe9tf1g+tTZqXPXXRI9K9izsgxuukk6ovt0JLxPmqbzzW++yGOPfQbA17/+IjNnjmHUKM8R26fd7T/S3yfRpx1t3/k1Rkqf9rVf9OnI6NOInlFtbW1F0zTy8vL67M/Ly2PDhg27fU5NTQ1vvvkmX/7yl1myZAmbN2/mu9/9LqlUip///Oe7fc7ChQv5f//v//Xbv3btWlwuFwBZWVmUlJRQX19Pe3s7hmHQ3t5OS0sLhYWFbNmyhc6d6miOGjWK7OxsNm3aRHwnN9ixY8fi8XhYt25dnwCqqKjAarWyZs2aPm2YPHkyyWSSjRs39u5TFIUxCQvN9/4V6d9vYI+EkHSNNDLlSQeZ2aMYe2EzFkeIprpcSGmoiSCxHAve/E6UtIakyuheJ0pGF9HOVmKpHSLekWHFkQrS6j6Nxg1bdtun5nAzj21+jPcD72Oz2RiTNYb5BfOp8FSwpWrLQfVp8uTJdHZ2UlNT07vfbrczYcIEOjo62LZtW+9+t9vNuHHjCAQCNDU1AfD7db8nmUxywcQLMMIGa7aYr5s1YQL5S5Zg3boVQ9f5PEdn0clpajMNvJJKaZeFdqKoioYmw/MTJToymtlU1M7MxMlIkSRKxIkcc2FYNiGNepqQ0kTn7Nl0zphBStdJ6DpNgC8YpL37DzSlKGz2+Wju/hAZF48zOpGgS1Hw+3xUpdMsrqlhUiy2xz7tLvZ6yM/PJz8/f4+xt3nzZtrb21m7di2SJA1Y7B3q+3QofRqsvyfRp8Pfp54vV7qus27duhHRJ9j9+9TRoRAKVRKLpWloaOzdL8syo0ePJhqN0dzc3LvfarVSVFTE4sVJmpvtvfv/67/a8HhyaGoa+j7ByHufACZMqOQrX3meZ54xv2PIMtx55/GUlGQSDoePyD6NxPdJ9MnsUzAY7PM5PxL6NBLfp6O5T6o68LJSMvZznnbr1q3k5ubi6Fm7N8A0NjZSVFTEe++9xymnnNK7/8c//jFvv/02H3zwQb/nlJeXE4/Hqa2t7Z1Bvf/++/nNb37D9u3bd/s6u5tRHTVqFO3t7Xg8ZkGRXe9y6LpOQ0MDxcXFqKp6WO9ydLywguiPbsfW2kAqw006MwtklUhjCFssRE5mK/axSbRLj8NItWMEQ8gY2OwRlLERyADsfrC4kVJBDHc5hnuCeXJDQ+qsQnKNRpv8qz7mSZIkIUkSL2x4gQc/eJDOZCeSJPGVY7/Ct074FqrUNxgP552b+nA9lz1zGYZh8OSlTzLeN37H8Q0NyJdfjvTJJ9R7FW79YpI6t0F5UEGx2UkqsE2J4I4bRK3wcb6KgouzGmaw6P0fUxT1gy0I6VfgO2Pg7EnoZWWmy3E378kyC4CJhoEEtAAfSRIJSUIxDE4wDPrYUMky6wyDu3WdGfvo68HeYUulUjQ0NFBUVIQsy8PqDttIvGso+nRgfdJ1ncbGRoqLi9mVI7VPu2t7XR2ceqpMU9OhGe8UFhps3Kjjcg19n/a1/0h8nwDi8TRXXvkcL71UBYDFIvPgg6fzzW+eisViOSL7tLf9R+r7JPq0Y386naa+vr73c34k9Gkkvk9Hc59CoRDZ2dmEQqFeTXWo7Jf0/fvf/878+fMP2PXOMAz+8Y9/cOWVV+7z2JycHBRF6XOnGaC5uZn8/PzdPqegoACLxdInzXfixIk0NTWRTCaxWvtXqrTZbNhstn77FUXply6880Cw89rXPaUVD/T+zpUbiP7odqztTcQKxyLJChKQ7EqSTksYGW7UsW3QnML4y2dYZ1mxZskwKht8CVBcIFvBSIMWBUlFitYjOUdDsh2Swd4yNIq7r2FEY2cjdy+/mw8azBsEFTkV3HH6HVTkVOy2zQfTV0mSdru/57rvaf+Tnz+JYRicOupUyrPL+x6UnW0aKCkKS0oS1HoMKlslFEPD0KKE7TqZKeiywue5MkkV5nTksqXwU175wgNcFzwBHNugfj2ccy9Mm9ZvDWoG5h9OSpKoBdZjpv96gOmShGeXv5MkoEoSTkXpd6599XVX9nR9LRbLbtdnD0RMHuz7tL/7D9ff086IPh3ePimKwujRo3d73N7OM5z7tOt+XYdrr4Wdbi4fNHfcIeFyma8lYm/g2x6JJLn44n+ydKk5c2CzKTz33JeYM6es99gjrU/7s1/06cjuk6qqu/2cP5L7NBLfp6O5T4Mxo7pfNg0//OEPKS8v59e//jW1tbX7PH7z5s386le/Yvz48dx444371RCr1coJJ5zAG2+80btP13XeeOONPjOsO3PaaaexefPmPuq/qqqKgoKC3YrUg0XXderq6gYl93pvtD3wBLbWBuL5o5FkM3AMwyDWEUMyNLzOEIoRIeWyIIdTJLY7YNZp4G8z6396KiB/tvlTspiCNdEGoXWgOmHs12DKIvBO2tFXQ+fJNU9yxdNX8EHDB1gVKz846Qc8Pu/xfYrUw0FbtI2Xql4C4GtTvtb/gEcegWCQsNVg2VgDXwwU1QKSRFwxiKqw2Qer8iGUAce0Z+F1KHgVWJq7mk7/Juio6y1BszvKMQ2S3gLWYYrU0cAXMcXqrgQw66oO5tUbqhgVCPaHoyE+778f/v3vQz/P2WebglcwOITDCc4992+9ItXptLBkyZc599xxIz5GBUc2R8M4KjiyGbI1qjU1NTzwwAPcd999LFiwgDFjxjB16lRKS0vx+XwYhkFHRwe1tbWsXLmSbdu2kZ2dzQ9+8IP9FqoAN910E1/96leZNm0a06dP54EHHiASifS6AF9zzTUUFRWxcOFCAL7zne/w3//939xwww18//vfZ9OmTfzqV7/iBz/4wUFcij3Ts0Z1sGvI7kyivgXl7bdIZbh7RSpAoiOKNdGJRU+g6gkkyQCLFd2lItXE0dpqUVQdbH7wHms6+2ZOJJwxiqqOBuLJbdizzqN80nfwuPr2Z3P7Zn65/JesDawF4ISCE7jt9Nsoyew72zqU/OPzf5DUkkzOm8zx+cf3fTAUgt/9Drq6qMrVCLhlShNOKMwmFQ7ybmaQVgeku2/PuBMSk2Ju8IBft1OrdrFRamdadwka9lBYe3P3vzbACRyPKVR3hwYEgXnA7s82MAxFjAoE+8tIj8/PPoPbbtux7XTCa6/BgZpzZmRAcfEOQ3bBwGIYBpdc8hQrVphl1TIzbSxZ8mVOPXUUmqaN6BgVHPmM9HFUcOSzn6tJD4j9EqpOp5PbbruNW2+9lZdeeokXXniB9957j+eee663UZIkMW7cOL7whS9w0UUXccEFF/SWjNlfvvSlL9HS0sIdd9xBU1MTU6ZM4dVXX+01WKqrq+szzTxq1Chee+01brzxRo499liKioq44YYbuPXWWw/odQ83iXCCtqo20vE0ql0luzwbm6dvOnL4zZWone0kcouQAC2lkwxGsHQEwDBQLDKGxY5hsYNqQ7eA0tJFcm0jGccBmRNBkmiIR1gcqGNZWz2BRJR0Ooba+Qr+uipmj53N3LK55DpzeWTVIzz66aNouobL6uKGk27gogkXIUvDpzZCV7KLf677JwBfO+5r/VPR//IXaG2FdJq4TSEt61iys8FmZ42SpKlnebUEGBLTGxUUSwTwYkEmjUa8fguUToY5c/q9vg48BjyEmYqQBeQD/VfdmWhAFVAK9D+bQCAYCcTjcPXVkEzu2Pfgg3DaaUPXJsHukSSJn//8C7z33jYcDguvv/4Vpk4tGOpmCQQCgWAPHFAysaqqXHzxxVx88cUAvXcgwXSv2lMe9IFw/fXXc/311+/2sX/vJq/qlFNO4f333z/k1z0chBvCbFq8iZplNUQCEfS0jqzKOP1Oxs4eS9ncMjxFZvKo3hVF1jXSSYNEaxfpeBp7qtOs8WmxIBXmkXKo6IRR5CSaYkPSdIy4DtYssGWztrOdhdWrqYmF8VlslFpVLPZsUtmVBGLtPLb6MV7Y8AIpPUV7zHwfvzjmi9x62q3kOodfna7n1j9HJBmh1FfKzNG7qUp61VXwxBOwaRN2LYVqtZOyWUh0trEhK9pT9QGAUWGFgogKjgikXaSSMVQljt1fCDctgF3uWHYAdwA9hZIuBi4EfouZ/uvDTO+1ACnMdN8gpkhdAIj7nwLByORnP4OdTRUvvFCk7g5nZs4czUsvXUl+votJk/xD3RyBQCAQ7IVDWvWqKMpRUXhYkiTy8/MP2ExqZwJrA6xYuIKOmg7sPjveUi+yRUZP6UQCEVY/tpqty7cyY8EMssZn0bQhiC+mE02EMWQVWU9jJYlkUZCK88Fqw9AhnsjG6WgkrakYko5sA9xlNMQjLKxeTV28i0qXzzTxSQbBORarxUG+YiUQDbB863KsipVJ/knc+cU7OWPMGYfUz8EiqSX525q/AfDV477ad6Y3HIaqKli92syZmzOH8oZq/PYAgVgrNdYQuoRZe0CSkNMGU5ttoOiQiENHkECWit9fRsUVD0Bp39Wkq4GfYopPG3ArcAGm7l0ELAGWArVAGvOPyo+Z7juHwyNSByJGBYLBYqTG51tvmWtTe/D74eGHRerucKKlJUJOjqNP7J155th+x43UGBWMHESMCoY7gxGbw6aO6nBGluU9Og/vD+GGMCsWriBUFyKnMgdZ2SGyFKuCp9iDq8BFy+ctvPD1F1CsCkY4zKk4cehdpL152GNRpJQMLhdYd6QJxxK52Kwd2KIdpNwq1goHZBSyeNsGamLhHSI1FQKLGxwlNHU18UnTJ8TSMWyqDYfFweWVlzOrdNYhXKXB5eWql2mLtpHnyuOcceeYOxsaYPFiWLYMAgFob4etW6GjA09xMbO3KPy+MMxWt44ky9Atbis6fLj1LMhLQiSMNnECQW+KedO+gXsnkaoDjwP/2/37GExhOm6ndhUB1wHzgY1AHLBjGicN5prUXTnUGBUIBpORGJ/BIHz1q2aSSw+PPGKKVcHwYMOGVs4883GuueZYfvWrM/f6JWokxqhgZCFiVDDc2ZM78CGdc8DPOALRNI3q6up+NYr2l02LN9FR00FWeVYfkdpDPBin6ZMm2mvaaVnXQmhbCMeYfBInzcRtT2G3pJBSCVNo+bJ2aZudUGg0elhCnaqhZGcTTkVY1lqPT7WgaFFzJlV1kfRM4qPAOt6rf49YOobT4mTm6JlM9k/mnbp36Ex09mvbcEA3dB7/9HEArp58NRbFAmvXwq23wqOPQiQCpaUwbpzpRpJMwurVnPd2A212nbQiYXR/QbFqMpPbssAhg8OKZrNSZe+iNGc8c8bvWEkaBG4E/htTpM7BFK3j2D1uYBowo/vn4RSpcOgxKhAMJiMxPn/0I9ip/jn/9V9w/vlD1x5BXz79tInTT/8rjY2d3HPPu/zhDyv3evxIjFHByELEqGC4MxixKWZU95POzoMTcYlwgpplNdh99r4i1YCu7V20b24n2hoFQELC7rPjK/Vx8RMXk9p0PB2XrcHeUENcdiBlZcIu64ANXUNpDNDu8ZN1ig2cY6lq2UAg1kapLQMkJ3jGoGUU8e9t79OV7EJCYnzWeCpzK1EkhaSWpDZYy8a2jUwrnHbQ12iweKPmDerD9XhsHuZNmGfOpC5cCHV1UFm545p4veBwmFMdySQfjtZIyaAgkZZ0ZENiUms2Fl0i6dEIpIMEvTqleRUsmLGAIo+ZpPsp5rrSAGDFTPW9kD5LXIclBxujAsHhYCTFZ1sbPP74ju3x4+G++4auPYK+fPhhA+ec838Eg3EAjj8+n8suq9zn80ZSjApGJiJGBUcbQqgOEj3Ovk2rm2ivbid34o61vMlwkvoP6kl2dttESuAp9pA1PosMSwpjw0a6nn6VnCnFpM45ha5HG8nQukilHaTTKVBU0NKooTYssS4SbhvObzrJOPsbMObLxDc8RTrwOyxZ48DqA9lCVet6upJd2FU7pxSfgs/u622PRbaQ1tPE0/HDfZn2iWEYPPbpYwDMP2Y+GZYMM923psYUqanUDqFqtYKqQmcnKAonxbK5rLaL58aniVvM2VRFl1iXHUR1SfhDOvPGzGHOeQsp8hShA//HjlnUEsxU37LdtkwgEBytPPsspNM7th94wFyVIRh6li/fyvnnP0ln9+fryScX88orX8brtQ9xywQCgUBwoAihOsDs6uwba48R2hoi1hEjszgTq8tK0+om9JSObJXxlfrwjfXh0kP4694mp341clsLrt8tAbeVrKoqMnxO2sbNwKirx9bSgKRrGLJC2p1F/IzTyDrtQ9wTLFByBVjc2LOnoNqySFm8WGULXckuNrZtBOC4vOP6iFSAlJ5ClVXs6vD4IA8nwlS1VRFPx9nctpm1gbU4rU6umHSFaZz0yiumW0l1NXzwgTmdcdxx5gxra6tpmmS3U6xm8dD7dr5Zq3PnLJnrVk+ksN5JvCSJfVsDFVnluC9fCJ4iQsDPgRXdbTgHuA1w7LGVAoHgaOXvf9/xe24unH320LVFsIPXX69m3rx/EIuZdxG++MUxvPjifNxu2z6eKRAIBILhyCEJ1UQiwapVqwgEApx22mnk5OQMVLuGFZIkMWrUqH26We3O2dfus5ulaJI6gTUBUrEUlgwLTr+T4lOLUawKrvY6ylY/jSPcTMLipDMjF8+40bB1PSSTZFiheIyF5F2/JrStE70riuJykDX7RGxN90DAgMK5YDPXr5Znl+N3+glEAhR5ivi0+VN0Q8fv9FPoLuzf7kgAv9NPRXZFv8cOJw3hBhZvWsyymmUEIgHSepqajhpi6Rhnlp5JbMtmvE88D+++a4rRUMhcj7p2LaxbZ86oOp2maO3oMP9ZLJywLc2La06Gj71IqRawB2HiJPiJWYbmM8xU32bMVN+bMcvPDPdU353Z3xgVCIaCkRSfDQ3w9ts7ti+/HA6wZLhgEHjhhQ1cccUzJJPmGqnzzhvPs89eQUbG/r05IylGBSMTEaOC4c6wcv393e9+x5133kkoFAJg6dKlzJo1i9bWViZMmMCvf/1rrh0hxeRkWSY7O3uvx+zJ2dfutWNxWIiH46RiKQzNtIjMn5qPYlWwR9ooW/009q4WOn2jSEbTKE4Fu5wynTqsVpg5E7Ztw/rIH8hdtGhHjc9IHXzW/Y1pzJd72+KxeZg9djaPrn4UgOZIM7IkMyVvCtIu8kvTNYLxIPMmzsNtO9wWQDtYG1jLwhULqWndhE+zUCpnEtPibEokMGQDZf0Gqv/7cjytKs5UCtxuU6Qaxg7bzWQSJk2C4483DZbq6ggHg1RlZRG3Z2KvtFEezMHz7XkwZw5GURF/A34PaJipvvcA5UN1EQ6B/YlRgWCoGEnx+dRTfZ1+r7xy6NoiMPnXvzZw2WX/ROv+fL3kkok8+eQl2Gz7/xVnJMWoYGQiYlQw3BkM19+DEqp//etf+eEPf8j8+fM5++yz+wjSnJwcZs2axT/+8Y8RI1Q1TWPTpk2UlZWh7GJm1EOPs2+/8jMWBcMwSIQSyIqM3WdHkiQ6GzqxeWz461biCDfT6RuFgYSW1PCO8aKs/9w8QXGxmVuWlQXr18OSJXDddeZjW/4GGJB7OrjG9GnP3LK5vFn7Jq9Xv44syZRll+Gy9l1EpekaVe1VlPpK+zjeHm4awg0sfP126urWUNmsocTiYOjEU11Mk1N4XTlcv6oLR6CDD/1upodUnM3NoOs7TiJJ4PGYRkqRCA1FRSw+5xyWlZURUFXSSjFqyoE/P4PZJRZOB/4ELO9++tnAzzhyU333J0YFgqFiJMXnzmm/o0bBqacOXVsEJscfn09hoZtt28JcffWx/PWvF6GqB/aFaSTFqGBkImJUMNwZDNffg5K+9913HxdddBFPPvkkF1xwQb/HTzjhBNauXXvIjRtOxON7Nhrak7OvoRnUf1BvilRZRrWrZGRloNgUwg1h5EgXOfWrSdlcGEgkQglsbhuZ9gS0tJjprZMmmSdTFNPVdulS0ywo2QENL5mPlV7dr01FniLG+8YjIaEZGm6rm6SWxDAMklqS+nA961vXU5JZ0sfxdihY/PbD1Hz+DuU1IZR0GjxuUh4XHWoaRTM4e1UIf00TobxMQvEQrfEOc/YUTIEqy5CXh+H3o3WGaQiHufXii3n01FOJyDKlLWEqq7MobfEQKbLwv8CZwGuYqb4LgLs5ckVqD3uLUYFgqBkJ8blpE6zcqcrJlVeaw49gaBk92subb36VW289jccem3fAIrWHkRCjgpGNiFHB0cZBzahu3ryZH/zgB3t8PCsri7a2toNu1JFGW1UbkUAEb6m3d5+e1tm2Yhux9hiKRSH3pFy6tncR74gjW2RSkRRqfQ3WaJCQmkU6GMfmtpE/zoF1w2rzJGVl5prLHvx+qK2FjRvBuwr0JHgqwXd8vzZtDW5lWe0yijxFnDPuHLaGtlIbrCWtp1FlFb/Tz7yJ85gzfs6QitRw7QaWvf1XfAkNxec3hScQjLajyxJOi4tJgSQRKQ2NjXglicyohgFIsmx+S1RVyMykXo1S7e5Aa6shYLFQ2dCA0t4OtgqQrVgKIa5AAxDHvEvzEHD6kPVeIBAcSTz0UN9tkfY7dKTTeh9BOn58FvfcM3sIWyQQCASCgeaghKrX66W1tXWPj69bt478/PyDbtSRRjqeRk/ryJYdH5qd6xrwNFeRo+pkTSpEG+0kWpJJuC5MuD5MojNBdFs7eiyBlGUhO8sgM7IN68fd19Vuh/JdVktaLGZNhEgYQv8095V+pVfc9WAYBoveXURaTzOrdBa/PuvXvc6/8XQcu2qnIrtiUNek7uzca1ftlGeX47F5+h1XtfhxAskgpfY8kCQMIJKM0JXsAsOgvEXHHYzR6jDwRKGsHWRDQlcklJ51YllZaJLEx5ZWOq1Qsr0K+ckv0zbtG/hzT4BQCYYEn46Bmu6nlGLOoG5ECFWBQLB3DAPuvht++9sd+yZMMH3bBIcXwzC44463+OSTJp577ktYrSIFUiAQCEYqByVU58yZw5/+9Ce++93v9nts7dq1PPzwwyNmfSqYi4PHjh27x0XCql1FVmX0lI4zFSR78weUrX4Ph9aF3a0ib7CS2JJJa/EUAiXTCJcU07q+lYln+vE+/TI5qU0o22M9L2auS50wob+VZCrVXSd0JahByCiEvFn92rOsZhkfNnyIVbFy86k3I0kSbpubaYXTBvjK9Gd3zr09M7izx85mbtncHTO44TDxle+TzpGRDehIBOlMdKLpadA07ClwhmMoukFOVGJ0h46EhC5L5nVIa+b1kmWqlA465RQJRUHVNdLhRqJKDHKnkA47acmEGq85i3osplBtAJYC84Ghs5EaGPYVowLBUHIkx6euw223wT339N3/k5/0u0coGGQMw+BHP3qd3/72fQCuvvo5nnrqsgFxmjySY1RwdCBiVDDcGTZmSnfddRcnnXQSxxxzDBdccAGSJPHYY4/xl7/8hWeffZaCggLuuOOOgW7rkCFJEh5P/9nAHrLLs3H6najVG5m4/RXUxm1EdCsRZy6GPxNJ17DFQ4yqeoPs7Z+zOutMsjSJ0n+/hi0YML8JuVwwdqz5z76HeqaBgJn+q75jbo++CuS+d5OjqSj3v38/AF+b8jWKPcUDcg32h17n3o4afHYfpc5iLJ0RUokkgVgjj3U8wvKty1kwYwGT/JOgqgqjuYlYVootkToUHdA0lLSOOy2TmVbQrAq+hIYrpnV/KzTAkECRITcLRo8m0dLEZ0oTumFg0UGTwZ5bRuF5NxH7wEUcqBsDTglOArzd7fUDtZizqoMv4QeXfcWoQDCUHKnxuWED/Nd/wTvv9N3/m9/AV786NG06WtF1g+9+dzF//OPHvftmziwZsHIIR2qMCo4eRIwKhjvDpjxNYWEhH3/8MT/96U956qmnMAyDJ554ArfbzZVXXsk999wzomqqaprGunXrqKys3K3Tms1jo+IEF457n8dmhNiuZWMoMq5st5nOqqjEndnE5QycjTVMqG0iljcGW0EMxo2Dri445RSzFM2eG2E62s6qBN4C1Q3FF/Y77OGPH6Yl0kKRp4ivHnf4vkk1hBtYuGIhdaE6Kp2jUbY1QP0GiMWwGjrFkkxBhp2qvHbujtzGnOMuY+vrf+MLW7ZiG5MiqGgURiU8KRmnZkWyWrF7PZy1Oog7pvfqU4NuvTpqFMyYCarKZ9viJNuaAcgJ67R4VDxfu5/WtAs1DLoM0iiYBew8R20B0pjrVY909hWjAsFQcqTFZzIJixbBXXft8G3r4X//F77znaFp19FKOq1z7bUv8MQTnwHmZ8Cf/3wh117b35/hYDnSYlRw9CFiVDDcGQzX34Ouo+r3+/nzn//Mn//8Z1paWtB1ndzc3BGbkrCvi18mbSJKBw2RTHQkbC4rqlUBDLOmZyiMkUjQlnaRQxtFY4rg3t+bgusnP4HqanNN6u4GH02DqiooLYXyBnNfyWWg9vWpremo4cnPnwTgllNvwabaBqLr+8XiTYup6aihUi1E+XAlhMNgs4HHbabn6jpEIxRXhfg0sJWq6g+ZGHdzblzjjC2wdIxEXkJFsdggx4tkz+Bbz2yjsDVJWgFrGjTDwJCgsyQf/xe+CJJkroXt2AyyjKwb+GIGi2dPp6v8C3R8AgVAvAhOtMKu93lSmH8Ae5i/PuIYjAFCIBgojpT4/M9/zApguxrXOxzwxz/C1f1N1gWDSDKpcdVVz/Lss+sBUBSJJ564mCuvnDzgr3WkxKjg6EXEqOBo46BU5bXXXssHH3zQu52bm0teXl6vSP3www9H1BrVfRIOk7FyBUp+LrohYegGik1BD4Yw6urRA60kYxpxzYo104FrajkZRdlwzDHmetQFC6CkBNatg/p68xa+YZg/6+vN+qklJfC9y8BSBZIKJV/q0wTDMLhnxT1ousYXRn+BGSUzDl/3E2GW1SzDJ2WgfPqpOUPs84HTiSHLxNMJWmJt1KXbaLWkyIpouBpamL0mxjFhO9/9zEZ5NIOqEgdaUQE4HBiyxDvHeQFIKTJ6d9ZvdYEN50kzeheHrdq+Ch0DWTcoa0mzNcfKyu/ey0dp8G8zy88UjukvUgECmOm/FYflKgkEguFMOAzXXw+nndZfpJ59Nnz+uRCph5tYLMXFFz/VK1KtVoVnn71iUESqQCAQCIYfBzWj+uijjzJ79mxOOumk3T5eW1vbu2Z1JJMIJ2irakNevQrvpm20tluwOK04sjPQo3GSrZ0YSEiyFTUzA295PpmlWVgt7CgzM22aWSt10SJYssSsk1pba7r7qqq5JnXePJgzB1p+DyGgcA7Y+6ZWv1b9Gqu2r8Km2rj51JsPS/97nH1XN62mur2aiUHV/Lbn84EkEU8naIu1kdS6c+cMA5su440rNNs1Jm1PYhtbRlE0yoKMChYqa1indODTbfh1Ox9XuMnuSHDGJx00eWTanQplai7Oji6wOGhKtLG9Yxv5XTreqE5dlsI7X7oWo+1EZm6GzDBIuSDtJgtdA4LAPI58IyWBQNAXw4DGRtN/bn9YtQp+8ANoaOi7PycHHngArrpKGCcdbrq6klx44d95660tAGRkqDz//Jc455zxQ9swgUAgEBw2Djr1d280NjaSkZExGKceEmRZpqKionfGONwQZtPiTdQsqyESiJDbvpHjNwXo0rKxuKwUnFCIpaWReKQD3e1FnnoM9iwHiqU7rdcwTCG6c+HmoiIz32z+fFPAxuOgpiFfAocCqU9h+1Lz21Lp1X3Kv+iGzm/e+w0A3zj+GxS4Cwb1euzq7Nsea2drcAsdnRrFmTZKZA0jEaclapbakQCnpuKJpLFpBgYyjW6IjyqAex6Hu+9m0ro6Fk2cxhJHA0utDdSqXaTR2XSahbThQfd6OcM+Aef0WfDRRxg1NbRs/5TRmkarS+bV4zL4eFQBd756F/YXQE2CYYEN58Lnx0Bwp1KxGlCF6fw7Z1Cv1OFj1xgVCIYThzM+W1vhoovgvfcO7TzXXAP33WeKVcHhR5LMtF8Al8vK4sVXcfrpowft9cQYKhjuiBgVDHeG1PX3hRde4IUXXujd/tOf/sSyZcv6HRcMBlm2bBknnnjiwLRwmGDtNjoKrA2wYuEKOmo6sPvseEu9ZDh9aBtAMkzTn+0rG8l3R3CqSch3Qt4uc3Y9ZWZ25+7rdkNlATQuhqZlsDkAehpi2yHZToOjksVrnmFZ/cre8i/bO7fTHm9nTOYYzhhzxqBeh37Ovt5SfHYfgWADST3BRofOVq2eoqSOy5Bw6Co5ER1FS3dfSAspXyaqK4W9QTbX795yC/zmNxStqeE6n4/5eaewMSNCXEtgbw9RIWm4M8ebKdKTJkFnJ0uX/J7/fWctcclNdYZKlyLzjYafEi7xYE1CVwAscThhCYzbCK8tgLpJZrpvEFOkLgCK9tjTIw/r3sy4BIIh5nDE5/btcNZZ/VN3D4TSUnMt6llnDVy7BAeO02mK08svf5q77prF9OmDP1qLMVQw3BExKjja2G+hum7dOp5++mnAtB/+4IMP+Pjjj/scI0kSTqeT008/nfvvv39gWzqE6LrOmjVrGJ01mhULVxCqC5FTmYOsmHcO6rbbKZRceCwxpLxsEqEETW1xiiQFq9PZ/4Q9ZWYqdrM6MrgW1i6ESA1YfeAqNWdgO6tYG0+xsGktNVVV+LIqKfWOJZqKsqF1A7qhkzbS3P7W7TvKvwwk4TANn61g4ecPUJdsobJwMorNnDX32r04ZDtpOslI6YTkFEknnBBQ8Eclc32o1QJeHzgdBOQIfsNBRdgCW7eaNprf+IYpWpcuxV1Tz7Te1Oci+MpZMGcO4aIiqoAOm8z3g08THm1FCoOhQbZRznEZV+EHpm+E2Daoq4CGCsitglMXwtpF4Cwy033nMLJEak+MTp48WbgBCoYdhyM+6+rgzDNh8+aDe76iwE03wZ13msZJgqEnM9PO669/5bC8lhhDBcMdEaOC4Y6u6wN+zv0WqgsWLGDBggWAObX7yCOPcNVVVw14g4Yzm1/ZTEdNRx+RmgglaNmWYItlPNNsnxPBwJZpI741REjNIHfXbzw9ZWbmzTNnT3cm2mCK1GgdZFaC1D0QhTfSkEqzsEOizrBTaQcl1YhhFPNp86dIkkSpt5RpBdOoaq9i4YqFLJq9iCLPAEixhgZYvBiWLWOxspqa/CYqI06U6jAUF0FJCVaHk3xbNlVsx542cBiQVCFsg6K0Bbxe6BbsGgZBOcm8zlG4O2Pw4x9DLAZ33AEvvtg39dluh4oKGtxuFgPLMGdEt3z0v2zvaiYjDrY0pCxwecfPGYXKdB3kOnAmYKIDxikQKocx66FiCWRfJ9akCgQjjc2bTZFaV7dj3+jR8Mtfmve79oUsmxXCSkoGr42CvbN1a5Af/OBV/vznC8jN3c0NXoFAIBAcdRzUGtXBUMzDnVRXitpltdh99l6RigHNn5n1O1tGn0g82YYz1EAkswiFNOGknSxrBr33vXYuMzNnN6sjGxebM6k7i1Rdg87NLO5MUqNZqPR4zfMlg7S3fUpbrA1VVjk271gUWaE8q5z1retZsnkJ10297tA6vXYtLFwINTWEs10sm5jEJ3tRlAxTXG6sgu3biVSMpSFUhy1lEFMhKyGhyDIN2VbGewuwdJtLaxhUqSFKNTeXvh+CjbXg8ZiLkaJRc1HYkiWmwVRPE4CFQA3gA/I6G1m18iFUA9QEpGWoSJzBF5JnMB2QtwMJzJoz+abrb64CeCFzKTAfoVQFghHEunUwe7aZ9ttDWRksWyaE55HC5s3tzJr1GNu2hTn77BBvvfVVvN6RUjhMIBAIBAeLWJG9n3Rt7SISiOD077jTG2uPEW2JIskSzqnlbJpyOXFXLu6OOlxaEE2DeFLqX2ZmwQLTPGlnUmFzTarVt0OkAkTrCadiLIvo+KxuFEkCSUKXLSQ6q1ExmJAzgQzVTMNVZAWv3cvS6qV0JjoPvsMNDaZIrauDykqqRrsIqEn8ut2cfnA6MTweEs2NdKxYht7VRV5MxpeQCTstOCQr41s08htDFDZFaEt1sl4NMjrl5L63rGR9WgUWS18rTbcbEokdTcAUqXVAJVAMkAiTmV2OlAZ0MGSZSzrvQANiaaC6+8mj6VuTxo85Hbvx4C+JQCAYXnzyCXzhC31F6jHHwPLlQqQeKaxdG2DmzL+ybVsYgGg0RSSSHOJWCQQCgWA4cNCuv6+88gr3338/q1atIhQKYRhGv2NGSmFiWZYZUzyGWq0W2bJD28faYwC48l1YHBa6HCWsP+lr5G56j9zgUtx0omzbAhFn3zIzu4pUgHAVxAPmmtQeDAO6NlGV1AgYNkptO+4wd2ppLEaaPKuN8b6+dv1+p5/aYC0b2zYyrXAa+2JnB2G7aqc8uxzP4sVQUwOVlaAoxCWNNDoWZDQtTVeohXCyk7Ri4EkYjOu0MaZ8Ou4NtYxa08KkxiSeqI5Tb0OSZc7KsKDn5zG1LoGjYVt/M6kzzzTXqrrdEAaqYGUcrHY4thxSHvMwb84Epn55CfXPPUvXe79ionQOJ8YrCCahbhNMbO0+35hdOmkB0kCcEYksy0yePFm4AQqGJYMRn//5D5x3HoRCO/adcAK89hpkZw/YywgGkVWrtnP22U/Q1mZ+lk6e7Gfp0q+Ql+c67G0RY6hguCNiVDDcGVLX35159tlnueKKK5g0aRLz58/noYce4qqrrsIwDF544QXKysqYN2/eADd1aDEUA1mV0VM6itWc8YwHTdVj9+0QXHFnNtsKT6Z+UxxDh1N+cAn2KcWmcdKua1J3Roub7r6SZce+eDOkwsQNhbSsYpF2BIBm6EhAjt2LLPUNDItsIa2niaf3rsp2LTOT1tOosorf6mP2ym3M9WdS1L1g324ooGls76gnmYxhYIAEsiRjzcig3JpLoZzNuZ9vJXcLhFWZOo9EjpFFrmbHG0qgbt4Kug5WK7hc5swswLe+BT/7GTQp8HdgGaQDUJGGH6qQ9MP62fD5XNhYBO9LMpNLLud3v51LxJdGToDNDvU5MK4NrBOAXZc4pTCjfQRnkyWTSey7c5IWCIYBAxmf//43nH++6b/Ww6mnmisHMjMH5CUEg8x//rON8877G6GQmUUzbVohr776ZbKzh87JSoyhguGOiFHB0cZBCdWFCxcyffp0VqxYQUdHBw899BDXXnsts2bNYsuWLZx88smUlpbu+0RHCLqu00YbjlwHkUAET7E5vRcPmULQlmnr+4RIhJDmwur34v7SeeC27XrK/ih2kFUwUiB12493bgLA7ixCDbaSMnSs3WnBEmAAutT/7kVKT6HKKnZ1z4PZ7srMWGQLKT1FYPsmHnNtYnlmNrdGfGS1dtHS+An6xDYaFYNsJKwoeDK8uNzZSIaBd3uQcz9aSXY4TeOEYroi7ThiSca1SVjjXRAOmzPEsmym+0qSOat6zz1w1VX9FqMGS2G1NUwnVViCcTzP2zl5RTkf3uSh0A0F9WDVHbgbIZgNGTKEsyFUBLnSbjocwEz/3Y3R8khA13U2btwo3AAFw5KBjM9XXoFLLulbhnrWLHjhBfP+l2D489ZbtVxwwd+JRFIAzJhRwssvX0lm5tB9ARdjqGC4I2JUMNwZUtffnVm3bh0LFy5EURTUbkvFVMr8wBkzZgzf/e53WbRoEddcc83AtXSIsbgslM4u5bPHPsNV4EJCItlprqOx7/LhqndFiGsWJh7rxLY/IhXAUw52v5n+6yiGZAckWgCJ8pxK/C0fEkjGKbabU4WqniRiyCTkjH6nCkQC+J1+KrJ3o8r2UmYGwKpYKVazyQvb+Mzbyg/SL3HVVp3sKBzXBCvGKPilHBxu344loJLEMXUxcgMpGsf50SVI2K2MKZiINSMNa9aYorRnPWo6bQrWf/zDnAbZZTFqg6WBJ+2L+Zd1GRElQCI7jaSrFLf7OWHRbFq/MBerv4gNx8OpKyBUALLdFO7p3V1bDbN46jyEkZJAcATz3HOmMXj3xw0Ac+fC009DRv+hUDAMWbJkE5de+k/icXO0nj17LP/615dwOkV9SIFAIBD05aCEqsPh6C067PV6sdlsbN/JzSIvL4/a2tqBaeEwYvx549n2zjbaq9pNUyUDFJuCat9xGXVNp70+hs8WYfzphft/cosH8mdDzaOQUdA7m4pjFB57JrOzi3m0YSMFNgcKIBtpAoYVVep7V03TNYLxIPMmzsNt20mV7UeZGRxOgvEg29s3kBttJyupUZcJn+XKfLvax7HSBDodzdQpXZSnDZRuqWqPpZjYkCLidqBLEEqEyE/bGL8+APWNO2ZQe3C5YOpUmDzZ3F6MOZNaCWtta1noWsgGpQZd9+GNl2JLWkBPEbIHeNP6GPZtyyk6cQGf3zKJshDk10JjuelB1S+gNaAKKMUsnioQCI5I/vY3+OpXTfP0Hi67zNxvFRrniOGllzb2itQLLijnn/+8HLv9oO0yBAKBQDCCOahPh4qKCtatW9e7PWXKFJ544gmuvvpq0uk0Tz75JCUjzHJRURQ8RR5mLJjBioUraFzZiJbUyMjOwMBAT+pEAhHiwTg+S5QZ+ZvxHHPlgb1I4VxoXg7BNRCpN/N73WUAzPWXsLx9O1WRIOUWSMl2mgzddMLtRtM1qtqrKPWVMmf8TqpsL2Vm7KEIeSvWoqvr2ZCv8qG3k7iWwC3ruFMyhXGFptIsSorOxY2NBV0FLHSt5jO1DYuhkGlYGBOMgKHT5FGIxoN4bG4myXlY6j/p38eCAjj5ZNMFeeNGKJ9mFkj1mTOpd7sWUiXXUdxeSVxVSEoJPnO9wbjoZPxGMWq6gNpUFZ9tXoitbBGvLiji3IWQuw5cPsj0YxonpTDTfYOYInUBMABlZYczIhVIMJw5lPh8+GFzKfvOnn3XXAOPPLJ/dVIFw4f//u85BIMJDMPgiScuxmIZPuOWGEMFwx0Ro4KjjYP6iL/44ov53e9+x7333ovNZuO2227joosuwuv1IkkSkUiEv/zlLwPd1iFDURQmd8/++Sf5mb1oNq98/xUizRH0tE7rulZkVcbpdzJx3kTG/+0FPF1dpig7EBxFMGkB/Oca0GJgywY1AwyDIquFBUUFLNwSZF0ComomUaMDwzBIakkCkQDBeJBSXykLZiygyNOtynYtM2NvJ6AmOb7DztSaEBO2RHF0xZGTKVIy1HlhVYlKS7abhFXGk5lLrbWLjeEw01K5eDUrU8IO6tUm2oixPlPi03yd6tNhYjrBvPQ4TnSU4dRk+GAXoVpRYdpySpKZ/huPm7OdAUiVwqMsZn2ihknbK1F1hU43bPR/Soe1iZW2JvK0UZQnpjIuWM6HTeup27wE59TreGYRZC+BK5aCtRYz/1fFXJM6D3Mm9SgQqT0xKhAMNw4lPh94AG68se++b38b/ud/dvixCY4cFEXm8cfnIcsSijJ83kAxhgqGOyJGBcOdwbiRclBC9eabb+bmm2/u3T7//PP597//zXPPPYeiKMydO5czzjhjwBo51BiGQWdnJ263G0mS8BR5sHvtZI7JZOo3ppI/JR/VrpJdkY3NJsEfG80nFh5A6m8PzhKQVFOkusdDV63pBiyrTMrMZ9HM81kSlXho9d9Jas00R5qxq3b8Tj/zJs5jzvg5O0QqmOm+u5SZGdWS5EvvdpETTNGhJNnm0NEc5gRuOEOhvNPOKIuDqlyF9mCIEtJk1tSwtusTFo5rpMaVwtclMSYKlREHcaeVuDPBBx6JVqOd3K4Ek9JZpstxZ6cpTE88EcrLzTYlk6CqaFYL24LNbE1vZ319Nc+WPUwXYT7Oe5+4NUbUFiWshjEw29asbEO2qZxknIZD8dJQvZQxk+azvshNyXWQMR+zTmoc0923gqNmTequMSoQDCcOJD6XLIGnnjKHjkgEXn+97+M33QT33tt3NYFg+PI///MhM2eO5thj83r3DadZ1B7EGCoY7ogYFQx3dleq9FAZsKSpmTNnMnPmzN7tnj+mkYCu69TU1PQ6rRm6QVtVG7IiU35+Od4x3h0H19WZPx2O/a+TkAqbdVS1ODS9AUYSck6G6Q9DZ/d+xQ6eCoosbq4DmhJxHvnkEY7PP555E+ZxZumZfQUqmE67y5aBzwfddzncnUmu+SiCtyNNtStNWoLWDPi0UOKTAolgBqAkyYi3kBuF0zfrnF1toGph/t8ZOnVOqGyTUHTAAJtugSkz4bPP0DqTVGV2sdC1moWh6YwqKzNdT0pLwePpbdb69e9Ql2rj2y9fQiRtoJwCKTlJ2NaJYijIkkSPU5PEDodjBZmyxBQMCTIy/LREavm0bSOTC6exACh0A/suGzsi2TVGBYLhxP7E5/bt8P3vw7PP7vk8d9wBd94pROqRgGEY3H33O9x++1v4/U7efvtrTJiQM9TN2iNiDBUMd0SMCoY7w8b1d28EAgEeeOABHnroITo6Ogb69MOC0LYQ6Xga1a6SWbKLGG3snk0tKNj3t6loAzQuhqZlptuvnoLwenMhVs5pkO6E7L7Kq6f26XPrn6Mt1sYnTZ/QHmvn5aqXmT12NnPL5pqCNRyGf/0LNm2C4mJzFtNqpXxzB7bWJOt9OlYd6jLhpYkyTU6D7KjO5EawGBop2RSwT1fC+8USlW0GNR6dylYJBYmUDG0umU6fQdTYjsuRIHtbK/aUxEfOFn4X7eI3lRf263KqQ0Nq7OLVY3QiKYOe6VJDASSj3yWTABnzsJJ0JY6ok0gGtHgtSKE056Tj3MCIz+wVCEYsug5//jP8+McQCu35uEWLzGMEwx/DMPjpT9/gnnveBSAQiPDqq5uHtVAVCAQCwfDjgIRqIBDg8ccfp7q6Gp/Px6WXXsoJJ5wAQENDA3fffTePPvoo8XicL37xi4PR3mFB28Y2ALLLspHkXZRV436m/QbXwtqFEKkBqw9cpRDdDkggK9D+MXxyq7lm1TsJ6Fv7NKklsSpW8px5lHpLCUQCPLb6MZavf5UFoWOZ9PY6U6RWV0NTkznDm5uLtPYzUg6dhAqdFonXx0uE/z979x0fRZ0+cPwzM9vSN4UUQi+hSxHFho1gASzoKVZETz096/m7U/HuvNM7xXK28+zlUKx3dgVRwIKcvSMt9EAgJCTZ9G0z8/tjUiFA+k6S530vbtjZzewzm8dln/1+5/k6DMbuBK12xF4Bl6HQu8IkrRJWp8GX/UySq1R+7K1QEG1S7KkpLrVK2LWSKJfBBGeY6AqTKAd8FV9GeThInOkCE8I7oXyDjnt7DuXJaSwblI+hgRIFigFKNdZUliZmDShAhpHO4cHRKAGoGgDjtRA+1cHZDo8UqUJ0UWvXwuWXw2efNd6vaTBunPVdn8djNVK64IKIhChayDBMrr9+MQ8//HXdvn/8YyrXX39YBKMSQgjRFTW7UF27di1HH300RUVFdXOQ77nnHl544QUUReHSSy/F7/dz5pln8oc//KGugO0uPJ76tVJ3r9sNQFJW0t4PbDiiui9VeVaRWpULCSOtdVVMEyrWg6JCwijr+tSyHOtx4+8mLwzzVswjtzSXkSkjWbN7DQVVBSiKYq19Gt+HjHAUOSuXM8/3GXcHDyKzTx+rSI2NBb+fwI/fQThMtBNiTQfv94OtXp2D8hsUqUDtvNsqJxjArmiTvBiT/BgFl+qwOpgojZtgVLtUfsl0MjovRN9Sg+2JAdaFdjN+YwZVG0MoZQW4dR9B90A+mJrFjj6P43JaP+swHaRVpbErsAuHw0EvoxdRZhTRZjTRZjSxZiwxRgyUAvGQ0A/KKwvI2NdasT1UwxwVwm4a5mcwaI2Q/v3v1t8bmjDBGmEdP76TAxRtpusGl1/+Ls8++2PdvkcfncaVVx4SuaBaQN5Dhd1JjoqeptmF6p///GcqKip49NFHmTx5Mps3b+Z3v/sd119/PaWlpZxyyincddddDBo0qCPjjQhN0xg+fHjd7aIca0Q1ZVgT05hqC9XM/Yzz7VhojaTWFqkAgQLrWlXFYY2uKhrEZ0HpGtixiIWlJptKNjEyZSSa2sS1CVWV6D/9QFJA58cUg8fiirmxOJ34qChMv5/iqt0EnGFSQpBZ7UAjjX+k7kI1FXbHacT7DaID1txyE5OQQ8UXreAOmfjdGig6BgqmpqHQ9JTm0iiV7/s5ySgJoxsGZZ9vJ7CtBFVx4I9KZdWU01H/MI3zBoU4tOgw0mPTSY9NJyU6BXW1ypOPPMl813xGhkaiRWnWnF8DqAYCQDwwDnSPjm93E2vF9mB75qgQdtIwP7/4Ai67zFo1q6GoKPjb3+C662TJma4oFNKZPfstXnnlFwBUVeHZZ0/loovGRTawZpL3UGF3kqPC7iLa9Xf58uVceeWV/OY3vwFg5MiROBwOTj75ZC666CL+/e9/t3twdmEYBiUlJSQmJqKqav3U32HJez94505ru68R1VCZdU2qK7G+SAUoW29tYwaAWrN6vaKBy0vZ9kUs3QWJnsQmi9TKUCW5G78iz5lHdYxKtaLzZPRaVmklnDRR45hPd+A2DFwqKA4HblNjt+ZHdznoWwlBVccXpRBUIOxyoEd7iNHiifPrBEKFmIaCYiqYprVerKZq4LCm6no9XmJcMUQ7oomuiiaqIhrCLgoduyhLvIaf+wxmzUke+l40jONT4qgdhx3kHdD4JEbB9Ouns/zN5eQU5ZDly0IzNWtwNwoYAPSzitQm14rt4fbMUSHsxDAMcnNL+Mc/knj0UYU9GwOecAI8/rjVd010PX5/mFmzXuOdd9YB4HCovPTSGZx11qgIR9Z88h4q7E5yVNhdRJspFRUVcdBBBzXaN3bsWMBaV7U7M02Tbdu24fV6qdpdRXVxNYqqkDS4iam/eXnWdl/XqJblWI2TYht8IgtXWSOqKBA3uPHjPank7PyZgjIY2Kv+9Q8ZIQCqQ9V8te0LyqrycGsKcaaTWNNJmRokX6nk4bRiFh9n8H+fwzi9F07TD6EQ/lAVJtBLd2NgEgwHMF1ulMQk3ESjFquEAqWUehSqXRqggwLJwWT6Vfcj1ZFKyugUHLEO2ALmGghUWyvD5Hu2404YxLKHzuDkiXHMVqA537FkZmUy9+K5zPt4HqvzV5OoJZIalYrT6ySkhay1Ync3sVasaJSjQtjNO++YXHFFHLt2NZ6NkZxsrZN6/vnSybcre//99XVFqtut8dprZzNjRlaEo2oZeQ8Vdic5KuwuosvTGIaB0+lstK/2dmxsbPtGZWO10369A7w4PHu8fIEAFBdbf99Xoar7rXVRlQavZcA6Jq5EcMQ0frzixK+HCBvgVK2fMTHZUb4DwzDYXbUbPeAnMaiiOF2AgomJaRiYJSWk+w02JsEjR3v4x+cGsdUOCAbx+A0cukLICOEKmUS53JCUApoLCoCgiUPRCcWmMdYYRFmojC2OLRxiHEKaIw2KgI/AVCGgWAVq0AXbB+hs9fo459DTeWBCXLMK1IZGpY7i7pPvZtGGRSzZuITNlZsJl4ZxqI59rxUrhLCl/Hy49lr473819vy66sIL4f77IUUawXZ5M2eOYN68Kfztb8t5551zmDKl+10CJIQQovO16Eqgb7/9ttGF3OXl5SiKwooVK/D5fHs9/owzzmhzgHaze63VSCk5az/TfmNiYF9ryGoeUB1ghkCpmeIbrC1UmxihNUN4UHD4A4R25uFyuSl0BAjoAQzTIGSESHTEoJhV1pCEYRAKVhFyhDENcJsq47Xe7OhVxdeDo5i5MgSVlWTlh0gtd7ApxiDNiMIbn4ricIAPCJpAKYorniFRkyAcwwZ1Az7VR0G4gJRdKah+DVMHvxuK0mHbEKjorRPjy2FqwkBuGjKtxUVqrcz4TC6bcBnnjDqHdUXr8If9eBwehiUPk2tShegCTBOeeQb+8AfY85+GAQPgiSes6b6i+7j55qM477wx9NtzyTYhhBCilVpUqD744IM8+OCDe+3/61//utc+RVHQdb21cdlOXE3hWTui2mSh2nBpmn3NY4vPAk+qNf03uo+1r3ZE1b3HMSsrYdtPZO0sJnVbgAJ20ScYhYNq+saGyO3lxK25UQzV+mRYXU1ID1HqMnDpkBx2McKVxticIAO2VpNUVYXud6GpKvFhjWO2O3hsdDVqtY6/WiXN0wu11A9GEDxxkDweHDHoho4/7OeS1ZeQE7OeXxJWE+9IxBtKJRDnZO0RIZKDBcQV+xjUjtNy49xxTOw98cAPFEB9jgoRSTk51pIzn37aeL+qmlx3ncnf/qYSE9P0z4quoaCgkh9+2MmJJw5ptL+rF6nyHirsTnJU9DTNLlQ//vjjjozD1jRNY/Bg69rRuo6/TS1c3pylaZzxkJ4Nm+ZDVIZVYIbKrPsajqgWl8CP34NzF/F5A8hW4pgft5G0QAzBoiISfTo7osNEqbFQWQbBILpiUu0wCWvQNxDFIUo6J39eRK/SIPmxCksHGBTuqCS2WqdvGUzcFGZoBmz1GsSXllJSXkWSmYniHQDx/awiNaCTE8hhYOlALvj5Uipd8N/xi/ik3xJ2aZvxBML0zXeQlp7KVJmWGzENc1SISAgG4d57rc69gUDj+8aPh6eeUjj4YLkQtavLyytjypTn2bSphHfeOZeTThpy4B/qAuQ9VNid5Kiwu4h2/T3mmGPa/cm7CsMwKCgoIDE2kdLcUgCShu5nDdV9XZ9aq/d02LXcaqzkSgRM0KLBEWXdX1lpFamOQlDSwBzL9DAs1wv5RSsi3qVQ5XJCKIiatwOcTkxNJWyGqXIpJODmSH8qJ39ZRCgc5PEJ8G16iDJNxzPUxGGAoUBWIWRvUnhzpMIX/RX6eDKJ23YkzqQoQoQoCG6nJOCjf+lALl03l/wRmRRkwlHaZZxTfg6V2jqCW/14pnoYNkWm5UZSbY6mpqZKN0DR6b76ylpyZuXKxvujouC22+C66wyKiwswDMnPrmzz5hKmTHmezZt9AFx33WJWrfotDkfX/53Ke6iwO8lRYXcR7frbk5mmSX5+ft0vICY1hqjEqL0fWHuN6oEK1ehMGDUXVs2Doi+sqba1o6tmCLb9BM5dVpG6bTwEY8gE5laM43fmYrZGBYkJWdej6gCaym6vA6NKJyGocIiWxqSNfkpUPw8cZbIj1iAuCCMKTKLCsCMO8uJg+UBYm6Fw/s8KfZL7UzXgYDaXbCOshtH8DnrtTuXE3NMZXz2NovGZeBwwAegLqGYcVE2ECiAVcLfXqy1aozZHe/XqFelQRA9SXg5/+hM8/DB7LTmTnW0tOTN4MOi65GdXt27dbrKzF7B9uzUDaNCgRD744IJuUaSCvIcK+5McFXYX0a6/osH1qU2tnwrNH1EF8I6C8XfD57MhUGx1Ai5dDQaQ74PtA8AcC8Gai7kqKhi0dh1nqdV8nw55SRrbEhR2u8Ft6lSjE+v2cEiVl8zCSpJ3VPCvCTq7omGgTyGhKoxHh3I3VDshyQ/ekMrOWHh7lMoTeUNJvvpBVq/YgW+TH5fPw+CSYZT2i2PHeBinQD+g0UeSAqwidVgrXkwhRJe2cCFceSVs29Z4f1ISPPCA1dVXlpzpHn7+eRdTpy6goKASgBEjUli6dDa9e8ssGiGEEB1HCtUWKFq3n0ZK0LJCFaxRVHSIHQAj/whR6ZCzCZY8CX2GgqumK/C2bfDtt2yLriY5TmHWdi8HxxzDvNAW3lG2kFZYzZYMDzEZ/UgecRBp/1vFd6m/sDXeYHAJJFaZaAYEHFBQ28REUVAVld6V4EuJ48OqTQzcuoPU3IlM/gn8UZA7FryDYSp7FKhYYeMDTgfks4oQPcauXXDddfDqq3vfd955VpGamtr5cYmO8c03eZx44guUlPgBGDcunQ8/vIBevaQjlhBCiI7VPebsdDBFUUhKSqJ4vbVGasqwJhopVVdDSYn19/01U2qocguEK6y1UxOmQK4Hfq6AgvL6eXQ1RSqmSW6iCvFx9B86kbiEVK6qHEWWP4YSZwinCWNSx0B0DOHeGXwxQCMp7CClCjQDDBV2NfxcUXN9Q3psOlFKDG/GF+P6WzFRJRCMBrU3HDQABrCPIjUHGAhMa96pio5Vm6OKDGGJDvTcczBixN5Fav/+sGgRvPhi00Wq5GfXtGJFLlOmPF9XpE6alMlHH83ulkWq5KiwO8lRYXcdkZsyotoMqqrSp3cflmxcAuxj6m/t9amxsfteQ3VPJT/B7iCsjoGnfgMFBVaxu3UrlJVZx9qxA1SV0gHp5MfuID/GJDHFQZFayOBQLCev1XkzVWVj3xh8fh8uzUW+UolPCzFklwEm6KpCfqxJuLbiVFVQFKI8XnyuWKIqw5TrZZRX5zO8D8TOA8fLwGogEWt6rxMIYU339WEVqXMBafBrC6qq0q9fv0iHIbop04Q//hHmzWu8X1Wt0dXbb7fervZF8rPrKS8PcNppr1BeHgTgmGP68+675xIX1z0bEkiOCruTHBV21xFNvqRQbQbDMFj9+Wr0kI4rxkVcRhOFaHMbKTX07VJ4Ng9KKqB3LAwcCAMGQGmpVbBu3w6aRt7o/jx5UBVL3BX4o5y85f4eBypR1WFGa2WcnhdH6Nc38Gn+V+zauZ6pH6/kx0wDpwG6prIj1qgvUjUNQ1FQHB5C0SlEVUBSgZ+yJAfxWemk3Qv0AsYBi4AlwGYgjJUtqVjTfachRaqNGIbB9u3b6dOnj3QDFO3KNOH66+Gf/2y8f+xYeOopOOSQAx9D8rPriYtz89xzpzNz5qtMmTKQN96YRXS0M9JhdRjJUWF3kqPC7jqi62+rMz03N5crrriCYcOGkZSUxPLlywHYvXs31157LT/88EO7BRlppmmy/aftgDWaqqhNDG3n5Vnb5haqeXnw6DtQEISRo6BPH+uaVLfbGpqorARVZVW6yo2jdvBa/DYCmslQI5GRYS/9gtHsDvtY0i/EO5NTOXbYSTw74mZe/XcFk7YrOBWVkEZ9kaooGJqGriiYqgNHbAYJPuhVaGISwBmbTPStSVaRClYRehnwDPAP4K6a7TM1+6VItRXTNCkuLu6Qjmui59J1uPzyvYvU22+Hb75pXpEKkp9d1YwZWXz00Wzefvucbl2kguSosD/JUWF3tun6u3r1aiZPnoxhGEyaNIkNGzYQDocBSElJYcWKFVRWVvLMM8+0a7CRVLGlAthPI6WWjqi+8xrklUA/D0Q3uOZ12zbrWKpKXpKDecdqbHVVM7TQxB/jJiEqBgWFiqoS+pWZhKKjKUlN4O5P7+Cpf+Tg3l7AaKeHtICfnOQA6eVQFqWiayomoKpOouIySSvScFWYKHopO9OdpI7NYlhmE+1744CJzX6ZhBDdRCgEc+bASy/V71NVePppuPjiiIUlOtBPP+Uzdmx6o32TJ/ePUDRCCCF6ulaNqN544414vV5ycnJ44YUX9qqgp0+fzmeffdYuAdpF5VarLf8BO/42p5FSWRksfgtiNXDFg1rT3Xf7dqtxkqrC0KEsHBfDJk81g0tMYv0msVoUimESLPOhlpZR5daIOeRIhmWMYWPZVhZfmQ2aRnxIJTvPTcDjojzKQXwAooMGDsVJemwmfXepuMsqUXQfekoMvhG9mDrmVOLc0r5XCAGBAJx9duMiVdOsZklSpHZPjzzyNePGPcF9930e6VCEEEIIoJWF6vLly7nyyivp1atXkx2e+vXrR17tVNhuIrjTaiiRMryJjr9QP6KaeYA5sWVl8NZbkLMBVAXUBGv/9u3WXDrThP79KTtyIktHRZHoiEXRYkh1ZzEwNJi4qiTKDYOtaR7Kxg0nPr0/mqrh9Xh5MWYTFbfcRDXQN2YcuyZN57uDR5KT5kZ1uhlkxJOQW45SVQ6qE33UEHImJDMwczTThkj73q5MURTS09OlG6Bos6oqOO00622qlssFr78O55zTumNKftrbvff+j6uvfh+A3/9+Cf/7X26EI+p8kqPC7iRHhd3ZpuuvYRhER0fv8/7CwkLc7u7RGTBQFiD381wCRQFUh0pUclTTD6wtzPc1opqXBwsXwtKllG1eS05wJ/4KE09uLllbA8Tn7rJGUvv3hwkTyHHuxu+M4/DSYYzZXUFKaRUOAgQ1lV3eIXw6PIZgYn33t+SYVNbs3MW1/Y/jsEsT+fLEMxmdsRH/j/Moc6qEA0noP0WjRimEokwKJoTwOcsZmDiUuUfNJTNeLjrtylRVJT09/cAPFGI/ysthxgyoaTkAQFSUVbSecELrjyv5aU+mafLXv37C7bfX/8JvueUojjiibwSjigzJUWF3kqPC7mzT9XfChAksXLiQ3/72t3vdFw6HeeWVVzjssMPaHFwkleWVsX7hejYt3cTudbsp3VaKK8bFwisXMih7EEOnDyU+M956cFWV1akXmi5UV62CefPIy1vDwv5Blh6+m4Jqg7AGDqOM1NISsl0q0/VBZE6YAIrCDtXNhT8l0S9/J6UxHrb3iqXSraGZJoO3F3P+/yrZlavw8YzB7FTj6P/NKE77OpO+WiYxjlHMXA5JqaPIP+5uFoUXsWT1EjZHFxDuFcYx2EGqN5XTB5/JtCHTpEjtBnRdZ8uWLQwYMABN0yIdjuiCSkrgpJPg66/r98XFWd+vTZ7ctmNLftqPaZr84Q9LuO++L+r23XHH8dxySxt/2V2U5KiwO8lRYXe6rrf7MVtVqM6dO5cZM2Zw5ZVXck7NXLBdu3axdOlS7rzzTtasWcO//vWvdg20MxWsKmDFvBWUbCrBk+jBGe1EcSrE9o4lWBnkx+d+ZOvyrRw19yhSR6XWT/uNj997McG8PJg3j1VFa5h3SCmbHOUkhhQGFoIzDCHdoCAGnhtrsjywk7nhHSR5+hGTU0hyUSnre3tRUEABFIWDNuQxbMN2Vo3OoteOIk54ycEPnkPY7PmamOC5eIaHGZ4AWs2ap5n/yOQy32Wc0+cc1k1bh//XfjzRHoYlD5NrUruZ8vLySIcguqiCAmvE9Kef6vclJsLixXDooe3zHJKf9mEYJlddtZDHH/+ubt+DD57Iddd17S+Y20pyVNid5KjoaVpVqJ588snMnz+f6667jieffBKACy64ANM0iY+P5/nnn+foo49u10A7S1leGSvmraA0t5SUkSmomkpZbhmKohCdFE18n3hiM2IpzilmxbwVZN+dTXxtI6WmOv4uXEhenlWk5joqGRlORAuXg0MBv4HLVOjjd5OBi3XR1dxufs6pJTAiv4BVfRPQFQWXAU5T4ajv1pNaUIQJjFi9ni/GH8zwletYMmEFb2Q5CMdX8IT6BJoCaMAOoBQIQpwrjom/nQg9b0aXEGI/8vIgOxvWrq3fl5oKS5bAQQdFLi7RMcJhg0sueZsFC34GQFHgySdP4dJLJ0Q4MiGEEKKxVhWqABdeeCFnnHEGS5YsYf369RiGweDBgznxxBOJi+u6I3XrF66nZFNJXZEK4C/1A+D2WtfdqppKUlYSu9fsZsOiDUyI30ehWlYGS5eysH+QTY5yq0hFAX8FOEzrE4KiYrrd6EaYfiUGW5NDJO4qpjI6CpehUu0wifWHOOKHtURXVVO7lK5imKRv/J4NsWGO3qry+kiNRb0X8WjVo/yu+HfwBVCM1S7rcKASWIy1BqoQQmAVqUcfDZs21e/LzISlS2H48MjFJTrOdde9X1ekaprC88/P5LzzxkQ4KiGEEGJvrSpUTdNEURRiYmI4/fTT2zmkyAmUBdi0dBOeRE9dkWoEDcLVYVRVxZPgqXusqql4vB42LtnIqPF5uGHv61Nzcigr2sHSAeUkGm5igtWkmaU4POWEPSY7lGgqqgyoLkdXwFRgcLgP8RXVBL3JxAdCRFVXc9T3a3EHQjRcBCgnyWBlLwPN0OhfqjO0xGB1tEZhuBDzExOlUgEncBjQC9gOLAHOwVobVXQriqLQt29f6QYoWuTGGxsXqQMHwrJl1rY9SX7ax1VXHcqrr66irCzAq6/+ipkzR0Q6JFuQHBV2Jzkq7M42XX8zMzM566yzOPvssznyyCPbO6aIKcoporKgEu9Ab92+4ko/BaPjMONcOFNUMitMog3rFxGTGoNvs4+iNQX0hr1HVCsryQnvwtAL+ZUSZExvgziPieYwCZuwK+TnxyKFlTsU9HKIMjUSg2403aBKM/H4qznip7U4gyFMTKwLVWFlOqxOVtB0jZBmoBkQrWtcVXQVf3zrjyghBWKAI6gvSlOBzcA6YGIHvogiIlRVJTl5H2v8CtGEsjJ4443621lZVpHap0/7P5fkp32MHNmLJUsuZNeuSk46aUikw7ENyVFhd5Kjwu5s0/X3mGOO4dlnn+Vf//oXmZmZnH322Zx99tkc2l5dNyIk7A9jhA1Up0qRy+Tbvi6+Hz4EX0I0hlPFCSSUVDFu1S4mbguSZKoYYYNw/m7rAL17g67Dd99Zc+feegvVvY3L+gQZ7ICqkMLuoAM9FMbAxOOEE3rDxF5uPtzVi/xSE4JOwk4dZ3U5h/ywCrduYqoqpmmCafBNXwfrvWEUU0EDHIaCriqcWj2bS5fVFKlJWNN9G64Q5ATCgL+TX1TRKXRdZ/369QwdOlS6AYpmeftt8Dd4P7jrro4pUkHyM5LKygJERztxOOo/QIwfv49l1HowyVFhd5Kjwu46outvq0rfl19+mYKCAl555RUOPfRQHnvsMQ4//HAGDx7MLbfcwo8//tjOYXYOh8eB6lDZ4jGYn53JsuOGEIpx0buwjD6bC0nb4SPgcbDs2CHMz85ki8dAdag4igqgstJabPDEE+G3v7WGKtyV9D/KIN0NeeFofI54dE3DRCFkKhQHVXaHYkl1m5ycUYLXGcIXVYmJwVFf/YwzHK4ZRldAUfhqoIeNSQaKqqEqKgoKvSpNol2juejb21ECCniBo2hcpAKEsL6W8CC6Kb9fvoUQzffyy/V/j4+Hk0/u2OeT/Ox8u3dXcdxxz3HJJW9jGOaBf6CHkxwVdic5KnqaVo/RRkVFcdZZZ/Haa69RUFDACy+8wJgxY3jggQc4+OCDGd4FO3EkZyUT6B/Dq8f0pTAtjr5bikjeXYlDt67Jdegmybsr6bu1iMK0OF6d3IeAvovknP9Bbi58/DH4fJCQADNnwq2nkTCiN4XVTqrqxq71mv9X0BQVE4X8gIsUV5BRsRWkVVYzevU6nGHdWpYGMDH5bKCTTfEhUFSreFUVFNNkeGlf0pUrcJXHQTTWdN+mxskLsKb/DuvoV1EIYXeFhfDhh/W3zzgDPPIlVreSn1/BscfO5/vvd7Jgwc/cfPPSSIckhBBCtEi7TCaOiYnh3HPP5YUXXuDee+8lNjaW9evXt8ehO5U73k3uZC/5mUn0zi1BbeobaF1Hra6m95pt7OrtZfs4FbfhB7cbzjwTHnkEPvgAbrwGojbgSB1MJgkE9CCmaYBhYGJiAJpqVZQmUOU3OKwwyLVv5KGjo2sqmm5gmAafDHaRGxe2ugTXUEyTQ8r74w1Pwls+zZraewRNj5jqgA+YijRSEkLw2mvWVQq1zjsvcrGI9pebW8rkyf9m1apCADIyYpkzZ1xkgxJCCCFaqNXL09SqqqrinXfe4T//+Q+LFy8mEAgwePBgrr322vaIr1OVlZWxelgc3ooKQgEF1WWiAGFDRwuFoLoaTKutUch0k1Baxi8njKF8RRZxo0bBH/9Yf7CiHPAXgHcg/YZHsXPDp5QaVcTrBoZqYprWiCrhEOgGztUqA94OUGU6CKomfreGJwQbE8EM+3HqKroKTgNSKkzS3QMoG3gwvavmEl2ZCVOA+CZOSgdygIHAtE54EUVEqKrKoEGDOuRCdtH9NJz2m5oKxx3Xsc8n+dl5NmwoZsqU58nNLQWgf/8Eli2bzeDBSRGOzN4kR4XdSY4Ku7NNMyW/38/ChQt59dVXWbRoEVVVVQwYMIBrr72WWbNmMX78+PaOs1PkbN9OSaybrEAZRU4H/oAKhAk7AKeT2FCYEE501YnbBWODhThLd5GXkMBwVbXaaEYBZTlQ9DUES8AcQEyvTMYpR/Hj5o/xKWEcYXDoJqqiY2gaRbFuqvQA/Q2sy1EBl8vNjbNTIX8Xk9cHGVik4zBMDE0lnDWJinEXMPSLacQnZcIIYBcQxJre68S6JrUAayR1IDAXyOz811R0DkVRiI9v6psKIRrLzYXPPqu/ffbZ4GjzV5b7J/nZOVavLiQ7+3l27qwAYOjQJJYunU2/fgkRjsz+JEeF3UmOCruzzfI0vXr1oqqqit69e3P55Zcza9YsJk2a1N6xdTp/OExY04hz6XhSDcoqNAorVPQwYCoEnDE4nSqDA/kc8f0KRv/wLY6yMjJycyFvC5xzPIwGJjghrgqqtkKoDKL6kKTvYlKvGDZWaayuDGKoGn7NzXdBnV+qQlSPdXJ2hc4FS631Un86aRzHXnE1Nyz5P14cFyCrMEyq6eaSqbcxRZtF3K1x1pzhG4FsYBHWOqmbsbr7OrCK1tOxRlKlSO3WdF1n9erVjBw5UroBiv36978b3+6Mab+Snx3vhx92csIJL7B7dxUAo0ensmTJhaSnx0Y4sq5BclTYneSosLuO6PrbqkJ1zpw5zJo1iwj4VMIAAQAASURBVKOOOqq944koj8OBIxAgpCi4HCYp3jB6PJQFVAzDpI+qMGhHDtNeeoFeO3dSERfH9vR0+lTuhrRqKNpoFYw/JcLsMRBbCuFKKPkeTJ0YRxxa/EAc5BN0JfOer5JtoSpSPNEM0uD7491UBiqINhy8dUyQgeveYu7kP3Ht8r/x45AE3p/5AscVHQJXYBWpvwJmYw3BXgacg7VOqh/rWtVhyDWpPUhHvEGI7qW4GO6/v/72oEFw2GGd89ySnx3n++93MmXK8/h8VkfQgw/O4IMPLiA5OTrCkXUtkqPC7iRHRU/TqkL14Ycfbu84bCGrTx9Sf/mFArebPjUtwBUVHFEGhmHQu6iIaS+9QHJBATsGDKDC6cQVqCYhtghcbkhKAwPYWgoLVsPsVNDWgBEGDHB42F1dRolu8L6vkt1hnbHxqWgAQR+bdIUlx0QzNm0sI7wDySnOYdnWT+l93N+JzRjHMYGD4HdYU3yPBv4ANBxljwMmdupLJoToQu65x7pCodYttzTq0Sa6qAEDvPTtG4/P5+eII/qyaNF5JCRIG2chhBBdW7MK1eXLlwNw9NFHN7p9ILWP7yri4+PJDoWYHxdHht/PnhMrRn/5Jb127mTHgAEYqkrA4WBAUR4uRwBcaYBi9VHunwCbffC1DocFAQM8aeh6gNhAFVu3Gez0OhgVl2Q9R6iUkBbFpmAZiqLRJ6EvmqqRlZTF97vXYBoBspwHoV4OlAIjgTtgrwCFEGIfdu6Ef/6z/vbQoXDRRZGLR7SfpKQoliy5kD//+WPuv/9EYmNdkQ5JCCGEaLNmFarHHnssiqJQXV2Ny+Wqu70vpmmtO9oVpyhMz8pi+caN5CQkkFVaWrc/trqaEd9+S2VcHIaqUupyER8M0C+wDQwFnM76g6gKROvwdR5MiIJYDxghwqEgA1+u4jffg+/SOELRVaAHKVc8rAqo+FFJj0nDrbkB0FSNaI+X3JwlXPbPcyAvDnoDD2I1bRKihqqqDBs2TLoBin264w6rcXmtv/2t45so1ZL8bH+GYaKq9f8Op6XF8uSTp0Qwoq5NclTYneSosLuIdf39+OOPAXC5XI1ud0eZGRnMraxkXn4+qxMTcVVX4/D7yczNJbakhG19+lDldhMfDDJOLyeGSjBcjefP6dUQXQ67DCjrD0PGQOkWuP9bYr4x0Q2YO7+IJ6/MYF3fviwt2IgvUEa0M5p+Cf0axRMbk0qvbzcT2rYO4ifCw4CsMiCaUPvfpxB72rwZnnyy/vbYsXDWWZ0bg+Rn+3nppZU8+ug3vP/++cTFuSMdTrchOSrsTnJU9DTNKlSPOeaY/d7ubkYNGcLdMTEsWr+e1xwOdsfFUel2EwYUTWNYIEC/hARiSoqsa0S1PV7GQFHNtFw3OPuD4YF/FcC3YXQARSUm4GTyW+X86+xKKsKVmJhUhioxTKPRoWJWOokqCxNw+2Ee0L8zXgHR1RiGwcqVKxkzZox0AxR7ue02CIXqb99xB3Tml/KSn+3n6ae/5/LL38U0YcaMl1m8+HyiopwH/kGxX5Kjwu4kR4XdGYZx4Ae1UKs+qhx//PEsW7Zsn/d//PHHHH/88a0Oyg4yMzK47OijOXjMGNJcLmIUhX5OJ8fExzMiI4OY6GgwVav7bu2rGNJhdwkUB6EEcMRYhextH2N+nYeJ9QtUFJXv0uH808JU637CRhgAh+pgdeFqTNO0jrceXFtCaKaDtb/xwNjOfhWEEF3d6tWwYEH97SOOgGnTIhePaL2HHvqSyy6zilSAkSNTcLs7af62EEII0cla9S/cJ598wqWXXrrP+wsKCvj0009bHZSdKHFxFIwcSWFyMnHvvYdaXAzRtS3/oyGsghKCLSVQUAXVVWAaoGvgqYB7VkBxNYZq1ayqovJVX40LzoCg0yQYDkLN/rSYNI4feLx1/e924Bco9BRQMSCVmJOGReolEEJ0YbfeCg2/5LzzTun02xXdeedn/PGPH9Xd/r//O5x7753aIQusCyGEEHbQ6slf+/vHccOGDcTFda8FPCvj4yE7G0pKoLZJlKlCkQa5AWtJmnAIPKbV6EhVoSIIW31QGcIIhVGBj4a4+PUsD5WaTtgIY2J9NZ4Rm0H2wGxcmgt2A9+Bjs6ODB9Vx00l3d29Xk8hRMf79lt4/fX62yecAN38yo1uxzRNbrllWaMi9S9/OUaKVCGEEN1es0dUn3vuOZ577rm623//+9956qmn9nqcz+fj559/Zlo3m1sWHRWFMn06fPYZ5ORAVpbVQnOXDk4FEgAMax3VSg38NcWspoJuolXrLB4Fl5zuArcH1e8nqFujqemx6UwdNBWH6oBy4EvQDZ2cPjmERw4kYcg0vJE5bdFFqKrKmDFjpBugqFNSAr/7XeN9d9wRmVgkP1vHNE2uv34x//zn13X77rknmz/84cgIRtU9SY4Ku5McFXYXsa6/AFVVVRQWFtbdLi8v3ysgRVGIiYnhiiuu4NZbb22/KG3AME3IzIS5c2HePOvCrx07rOtSo6JBMaDKD0EgAHVrqpompmpS5IaFfRUMlxuHUv+6eRwexqaNxTANzGqT0BchCrQCfEk+Bo4ZSNzkueyKz5RCVRxQMBjE4/FEOgwRYaYJ//0vXHst7NpVv/+MM2DixMjFJfnZMrpucMUV7/H00z/U7XvkkWn89reHRDCq7k1yVNid5KjoaZpdqF555ZVceeWVAAwcOJCHHnqIU089tcMCsxu/34/hdqONGgV3323Np7v9dutTYUAHTQFFhVBNlwvFtBotobAh1cGGqCDHboIPJ6kUqlWoYZVhxjAuH3Y5X5hfsLloM+H1YRw4SHWlcvr005l20DQui88EIDFiZy66AsMwWLdunXQD7OG2bYOrroJ33228PyoK/v73yMQEkp+tYZpQVGQtfKuqCs88cypz5oyLbFDdmOSosDvJUWF3HdH1t1XNlDZv3tzecXQtmZlw6EGQEguaH7wJkFwFG4JWsaopWFWqwtp0B1+mBCGsMLhEYVBuiOIkjTM3nckDGx4gZXkKl6ZdyrrqdfjL/Xi8HobdN4y4QXGYgK/mKb2ROlchhO3pOjz2mDXho6Ki8X1ZWfDvf8OIEZGJTbSOw6Hy8stnctZZ/+X888cwa9boSIckhBBCdKpmFaq5ubkA9OvXr9HtA6l9fLdSlQc7FsL3r4BZAAOC4AwBJpTpoGpWsQr8kuHgh5QQhmFgoOAKq7gqDE7xncZvS39LysEpEIS4L+KYmDfRasL0NDDIeqpqrJnEIIWqEKJpv/wCl10GX37ZeL/DATffDH/8I8hMsa7J7Xbw9tvnSNMkIYQQPVKzCtUBAwagKArV1dW4XK662wei13bH7QYUgNJVsOYeqNxkjZqqTqjSIdqAoAmYYISs/YqKOnIEFK7ENEw8YQdhxWR88eEcGvgVYweNtQ66BSjGKlJ7A/8FJgKZ9aOpLkA+Z4oDkalAXZ9pQl4erF0La9bAhg0QDO778RUV8OqrEAo13n/YYfDUUzDaRoNwkp/7V14e4PLL3+OOO45n0KD6iz2kSO08kqPC7iRHRU/TrEL12WefRVEUnE5no9s9hqLQjxK0NfdAVS4kjIShOsSvh8JKiFaglwd6pYGvBKo1iOnPyIyxVJkhfs5bSWqliZNMJpaez8EDDsatuSEXWFXzHGOBAcAaYBFwWX2hmkhNoSzEPmiaxpgxYyIdhmimcBg2brSK0TVr6gvTtWuhvLz1x42NtXq9XXkl2OnzjOTn/pWUVHPyyS/y1Vd5fPnldpYvn0PfvgmRDqtHkRwVdic5KuyuI75IaVahOmfOnP3e7vZMk8O3v4dZsQnFOxIUDWI1GJkAHxSCoYErAZwuiEmFoA/iogFIc6UzyFdO/5IKilNOonfyMDLiMqAA+K7m+FnA4Jq/e4ElwDngi6vfJcT+mKZJeXk5cXFxPetLJJurrIR16+oL0tpidP36vUdB2+qUU+CRR6Bv3/Y9bnuQ/Ny3goJKTjhhAT/9ZLVoLisLUFhYJYVqJ5McFXYnOSrszjTNdj9mq5op7UswGCQUChETE9Oeh424mFAZh+74ANOZiKJolIWC5FSV4s8K4lkHWbsN4jNiax6tgOpCr9pGsealaPsuxu+MoiQ6FV/q4UxOOwi2A99i9VvqA4xq8GSpwGZgHfhqlpLwdtqZiq7KMAw2bdok3QA7yObN8I9/wPvvW8snN4euQ4MVvVolIcH6sz+ZmXD99XDWWWDXzy6Sn03LyysjO3sBa9fuBiA1NYalSy9kzJi0CEfW80iOCruTHBV2Z5uuv6+88gpfffUVDzzwQN2+2267jTvuuAPTNJkxYwYLFiwgNjZ2P0fpOvqV5ZAUKCTPmc77uWtYWrSdgkA1YX03jqOhV7HKsTu2c3pFAqlRUVSG/Rj+MnZuLca5SyGgTuL7jKPITBxGKCeEa43LOnAGcDCN5/U6gTDgl46/QkTamjXWVNqXXrIKz47Sp4/VlXf4cGtb+yc11b7Fp2ibLVt8TJnyPJs2lQDQp088y5bNJisrOcKRCSGEEPbQqkL1vvvuY/z48XW3P//8c2677TamT5/OiBEjePjhh7njjjuYN29euwUaKe5QGVklP1JQtpOHdm9hcyBAotPDQC2EExO/Cp+mK3zpreaTMoPf/VjEsGIDjwaK183bWbEcu/lSjBiFnfk7qaysZJxzHEn9k2AMe198GsL6rXgaX6MqhOg8330Hd94Jb75pNThqD5oGQ4bUF6G1Renw4RAX1z7PIbqGnJwipkx5nu3bywAYNCiRZctmM2CAN7KBCSGEEDbSqkJ148aNXHTRRXW3X3rpJdLT03nzzTdxOBwYhsHrr7/etQvVmmVoZuYvpahoDY9t38qOsMJIjxvNDIARIKQorHAq7FYNjFiFRTEBdqU5+LPai6HOIHdHeVi028ewYpWhhUPwOX2UOkv5sf+PTBo+iRiliSnSBVjTf4fJiKpoGY+sQdJmy5dbBeoHHzR9/yGHWB11mystrb4YHTIEXK72ibMrkvy0/PJLAdnZz7NrVyUAw4ensHTphWRmxkc4MiE5KuxOclT0NK0qVAOBQKP/WD788ENOPvlkHA7rcCNHjuTRRx9tnwgjwbcKVs2Dyk04XYm8HohmY1hjnFtFM8OgBwiaCh8ZCrsV07rWFAhj8p0WZnlqNZ74KJZuLaLSFSY3JZdxq8dRllRGQlICJUoJuWW5jEgZ0fh5dazq9HQgDkpqdns76bRF16VpGsOHD490GF2SacLixVaBumJF04857jhrPdLjj5epuK0h+Vnvvfdy6orUgw5KY8mSC0lN7V59HboiyVFhd5Kjwu4i1vV3TwMHDmTp0qVceumlfPvtt2zYsIE77rij7v5du3Z13etTq/KsIrVmGZodYZ3vitfgcUWjmpVghgmaCkuqTErMmouGDRPVALcOI0tMfq4sp6yfSXkIsgqz2JqylUJvIemkk+/Jxx12s71sO4MTB+PSaoZYdCAHGAhMs3b5akLydub5iy7JMAxKSkpITExEVdVIh2MLZWXwzDP7b2hkmtbo6Q8/NH3/jBlwyy1w+OEdE2NPIflZ76abjqSwsJIVK7bx/vvnk5QUFemQBJKjwv4kR4Xd2aaZ0m9+8xuuu+46Vq9ezfbt2+nTpw8zZsyou/9///sfo0aN2s8RbGzHQqjcZK2VqmhsqyqmNFhNhjse/KWAyU9BlRLDGkk1UcEwcIfh+G0KsSGTVYkmP5eESSxLZFjxMMr6lLH4iMWc9M5J9N7Wm4qYCrZ7tlNaXUovVy9ruq8Pq0idC2RaofhqQpJrVMWBmKbJtm3b8Hq9kQ7FFnbtgqlTYeXKlv+sqsLZZ8PNN8PYse0fW08k+VlPURT+8Y8TqK4OEx3tjHQ4oobkqLA7yVFhd7ZZnuaaa67B4/GwaNEiDj74YG666SaioqxvhYuLi8nPz+eKK65o10A7RagM8peCK9FaKxUI6DqGaaCoKijWy1UYNDDDGhgqiqkQFQoyZbOThAAYqs5OU6O8SuWI3aMJpgZxHOtgp7aTN+e8yahvRzHixxH0LuyNK+CCGKxrUk/HGknNrA9Hpv4K0XLbt0N2trV+aUs4nTB7Ntx0Ewwd2jGxiZ7nvfdyiIlxctxxA+v2KYoiRaoQQghxAK1eR/Wyyy7jsssu22t/UlIS3377bZuCipiyHPAXQGz9Bwq3YqJiopsGOKIIVvemwp+LouigmKAYHLpDIz4AJgpBU8NbPoDBVWm4ertIPyy9bmFmX7KP/534P7448guMtQa/G/87EvokwDBgj66fBlBW83dvZ5y7EN3Apk0wZQps2VK/z+mE/fWfiIuDX/0Kfv976Nu3w0MUPch//7uK8857A7dbY8mSCzn8cEkwIYQQorlaXajWWr16NVu3bgWgf//+jBw5ss1BRYzuByMMSv033X1dCgkuN6WhAGEjA39ObwKpmzFVAxMDxTSJDioYgInJzjiVtIpMfv3Lr/nyiC8JKsG9nibXyCVmdAyZJ2eCu+lQyrGKVYCEdj9R0R3F9fA1TtautUZS8/Lq9w0aBMuWwYABEQtL1Ohp+fnccz9yySXvYBgm4bDB/Pk/SqFqcz0tR0XXIzkqeppWX4399ttvM3jwYMaMGcOMGTOYMWMGY8aMYciQIbzzzjvtGWPn0TygOsAM1e2KjU5jbHJfKsIG/h2x+IwgYS1MUAkTUnV0RccV1gmpYUJqmN3RKoPKBjG0aCh9/tdnr6fQDR2f38fUwVOJc+/7DcdXs42jHb5NEN2epmkMHjy4QzqudQU//wxHH924SB0xAj77TIpUO+hp+fnoo98wZ87bGIZ1vc4ll4zj0UenRzgqsT89LUdF1yM5KuyuI3KzVYXqokWLOPPMMwG48847efPNN3nzzTe58847MU2TM844g8WLF7droJ0iPgs8qdb031qKwoS0gaQ541kVKOGH5FXoNdN+FVPBHVZwGgq6YrA+2cCjm2SEMyiPLmf0T6PRKut/abqhk1Ocw8DEgUwbMm2/ocj1qaIlDMMgPz+/Qzqu2d0338Cxxzbu7jtuHHz6KfTuHamoREM9KT//8Y/PueqqRXW3r7nmUJ566lQ0Tbp02llPylHRNUmOCrvriNxs1b+cf/vb3zjooIP4+eefuemmmzj11FM59dRTuemmm/j5558ZM2YMt912W3vH2vGc8ZCeDcESMPW63cmeGKYFx1LiqMLnLrfWTTWtqb7RQZMdsSbrk6Fvmcrw3dEsy1jGuuR1JJYlEr0xmqAeZHvZdtbsXkO/hH7MPWoumfGZ+44DWZpGtIxpmuTn53dIxzU7++wz65rUkpL6fZMmwUcfQa9ekYtLNNYT8tM0TW677RP+8IcldftuvvlIHnroJFRVFt+1u56Qo6JrkxwVdtcRudmqQvXnn3/moosuIiZm70XKY2JimDNnDj///HObg4uI3tMhZpDVWKlBsZofKCcpEE9KKN7a0eBzR3QIzl2p8ZdPHcRrWZTElvB92vcoukJhcSGbfZuJccUwZ/wc7s6+m1GpB166x1ezlaVphGjakiVw4olQXl6/75hjrP2J8h+O6ESmaXLTTUv5618/rdv3978fx7x52XXN9IQQQgjRMq26/NHj8VBcXLzP+4uLi/Hsr82mnUVnwqi5sGoelK5GjerNmuihfKZ9Q3KwF9WeSlymw/rWwDQ5aYPJbZ9oxIWsmn+XNwGvYbIxbSPB6CAzx8+kz/F9GJY8bL/XpO7JV7P1tvsJCtH1vfMOnHUWBBv0KjvxRHjjDYiOjlxcomf64Yd87rvvi7rb999/Ar/73eERjEgIIYTo+lo1onr88cfz0EMP8cUXX+x131dffcU///lPsrOz2xxcxHhHkTfhXp4cdxe3DL+BBdGj2RDnwOHsS6lmYioaoOHUFSbsVIgNWt+Yl0a7qXI7SQwlUqqUsqHfBqacNIWJvSe2qEgFuUZVtIyiKCQlJfWI0ZtXXoEzzmhcpJ5+Orz9thSpdtXd83PChAzmzz8NTVN44okZUqR2Qd09R0XXJzkq7K4jcrNVI6r33HMPhx9+OEcddRSHHnoow4YNA2DdunV8/fXXpKamcvfdd7droJ1pFTAvKoNNURns1kNUlhYTdCiUppkM3DGcwvgyAko5vUq2M7jYj1IzDzgvIRYATdcwVZPqQ6qJS2ldK3Ffzdbb5rMRPYGqqvTr1y/SYXS4Z5+FSy+FhpdBnHcezJ9vrZcq7Kkn5OeFF47l8MP7MmRIUqRDEa3QE3JUdG2So8LuVLX9mwa26ogDBw7k559/5tprr6WkpIRXX32VV199lZKSEq677jp++uknBnTRNSHygHlALjASiNGcVEalEdai8A1wEK9lMLpgBIP9h/DXFakcllf/EuZ5Y8AAtVIFFww5eUir4/DVbL2tPoLoSQzDIDc3t1t3A/zXv+DXv25cpF56KTz/vBSpdtfd8tPvD7NwYc5e+6VI7bq6W46K7kdyVNidLbr+6rpOfn4+8fHxPPDAA6xdu5bq6mqqq6tZu3Yt999/P6mpqe0eaGdZCGwCsoDahWW05CyI7kWVUszOCQ6qYwy8JTCguBIaDHPvjI7HXe6m0FtIRlYGRx58ZKvj8NVsva0+guhJTNOkuLi423YDvPtuuOaaxvuuuw6efBJkSTn76075WVkZ5JRTXmbGjJeZP//HSIcj2kl3ylHRPUmOCruLaNdf0zS55ZZbSExMJDMzk/j4eGbOnLnfpkpdTRmwFKvTbsPPvqo7HufAKQT8JQSTNLZMUtjQvxQwUFBRTAXFVNieGEP1kGpCw0LMPGxmi69LbUiuURXCGj299Va4+ebG+2+5BR54oNH3REJ0uNJSPyee+AJLl24C4LrrFlNUVBXhqIQQQojuqdnXqM6fP5+77rqLPn36cNJJJ7Fx40befvttDMPg7bff7sgYO00OUAAMbOI+55CTid+2gtLiHIhJo2RIFYf/ZTSpFXGc9F0pQ6MDlB+dSZm+nWEJw5g2ZFqbYvHVbL1tOooQXZdpwu9/D/ff33j/HXdYhaoQnamoqIqTTnqRb7/dAUBCgpv33z+f5GTp4CWEEEJ0hGYXqo899hjjx49nxYoVREVFAXDdddfxyCOPsHv3blJSUjosyM7iB8JAU5e7ORL6Mvaoufz0v7vYnv8jhubCUKPYnhZHbp8UcsdW4/NvZWDiQOYeNZfM+MxWxxEEar+jl+UgRXMoikJ6enq36QZoGPDb38ITTzTe/+CD1pRf0bV09fzMz69g6tQF/PJLAQApKdF8+OEFjB+fEeHIRHvp6jkquj/JUWF3HZGbzZ76u3HjRmbPnl1XpAL89re/xTAM1q9f3+6BRYIHq3IP7XmHoqBqGom9hjP+uL/h6D8ZHB7M6iLM0s3kq9uIccUwZ/wc7s6+m1Gpo9oUR2nNVgVi23Qk0VOoqkp6enqHdFzrbOEwzJnTuEhVFHjqKSlSu6qunJ/bt5dxzDHz64rUjIxYPv10jhSp3UxXzlHRM0iOCrvriNxs9ohqSUkJvXr1arSvdhTV7/e3b1QRkgWkYk3/7VOzTw+UEdq9DiNYyXuf/IWKip0EXLE4o5IxBh+GR0vi/qWjmHBbdpuuSW2o4fWp8r2ZaA5d19myZQsDBgxA68LdhYJBa7mZ11+v36dpVmff886LXFyibbpqfm7aVMKUKc+zZYsPgH79Eli2bLZ09+2GumqOip5DclTYna7r7X7MFq2j2t2nG8QD2cB8IL4sj7z1C8ndtJTKygJMPUT1rp/RjSCoDkyHh7j0GRy/IsAxGw6FlXFWpRvf9jh8NVtv2w8lepDy8vJIh9Am1dXwq1/BokX1+5xOePVVmDkzcnGJ9tHV8tMwTE477ZW6InXIkCSWLr2Q/v29EY1LdJyulqOi55EcFT1NiwrVm2++mXnz5tXdrq2cL730UmJiYho9VlEUfvrpp3YIsXNNB94pWMWyFfNQSjZheBLRvAPQTRV2/Wi1Xg4HIWRw+dPRzPr8cChLht9jDcdm1xyk9Zeo1hWqcn2q6CkqKuDUU+Hjj+v3eTzw5ptw0kmRi0v0XKqq8PTTp5CdvYB+/RJYuvRCMjLaZ9aMEEIIIQ6s2YXq0Ucf3eSIaldeM7VJZXmwYh6U5mKmjERRNcBE8ZdhmCYqGq4QuMMhtKIH2ek5mfHB/jDQY80Zfg5YDswFWnmpqq9m62372QjRqXTd6tbbEmVlMGMGfPFF/b7YWHjvPTjmmPaNT4iWmDSpD0uWXMiQIUmkpEh3XyGEEKIzNbtQ/eSTTzowDPtYuH4hxSWbmJIykjxVYyWgA2a4CtMER0jBqeukVBlc++VaPPpm0D8C1/fWha0ZWOvczAPuplUjq76arbc9Tkj0CIqi0Ldv34hMzw+H4b//hX/8A77/vu3H83rh/ffhsMPafixhD5HMz5ZYu3Y3w4YlN4rzsMP67OcnRHfRVXJU9FySo8LuItr1tycoC5SxdNNSEj2JxKsaI4B+QCwKrmAVWthANU00DHqXK6iohNQwIVeDlVc1rGtVNwOLmnyaA/LVbL2tPxXRw6iqSnJycqd2AwwErE68w4dbjY7ao0hNSbGm/0qR2r1EIj9b6oMPNjBhwhPccMMH1iUeokfpCjkqejbJUWF3HZGbku0N5BTlUFBZQGpM/XTmkN9Hxdo3CO/4CVUHExPNMMksV1BMBUMxKIjd42pSDavKXAK04rp3X81WrlEVzaXrOmvXru2Qjmt7qqy01jMdPBguvxw2bmyf42ZkwPLlMG5c+xxP2Edn5mdrvPXWWk499RWqq8M8+OBXvPDCz5EOSXQyu+eoEJKjwu4i3vW3u/OH/YSNME7VWbdv9+61GHoYd7WOiYKpWIVq73IVpWbxmPLo3nsfLBVrVHUdMLFlcTRcnkaI5uroZaJ8PnjkEatI3b177/tjYuCSS6Bv35YfOzra6vibltbWKIVd2XUZs5dfXsmFF76JrlujqGeeOYJZs0ZHOCoRCXbNUSFqSY6KnkYK1QY8Dg8O1UHICBEyQuSW5lJWmosRqsAwHTVdYkwU06B3hYqJ9cHGcAza+2BOIAy04j3FV7P1tuoshGhfu3ZZxekjj0BTnfETE+Haa+GaayA5udPDE6LVnnnmey677N26BmAXXngQzz57Gg6HTDYSQgghIk0K1QaykrNIjUllU8kmdlTsoCxQhmkaoGjoqo5mqGg1H2jSy8BUTFRTpW9gyt4HC2G9up6Wx+Gr2crUXxFJK1fCk0/C009DU1/ipqXB//0fXHEFxMmqHaKLefjhr7j22sV1t6+44mAeeWQ6qiqNSoQQQgg7kEK1gXh3PBN7T+Tez+9FUzQSPYmUG7sh7CeshtEMF5phVaq9y8FQTIKOBFL0JrpCFmBN/x3WshhMZERVtJyqqgwaNKjNF7L7fPDyy/Dss/Dtt00/pn9/uOkmuPhia61TIQ6kvfKzvdx11wrmzl1Wd/uGGw7jH/84Qbpp9mB2y1Eh9iQ5KuyuI3KzTYVqXl4ey5cvp6CggDPPPJM+ffqg6zqlpaUkJCSgaVp7xdlpTNO0qsW9Pq+YGKqBFrYK1fQKazQ1qPWDPT/c6FjV5ulAC0eaqrAGYwESWvajogdTFIX4+PhW/axhWJ12n30W3nij6dFTsLr7zp0L554LTmfTjxGiKW3Jz/b2z39+1ahI/fOfj+a2246VIrWHs1OOCtEUyVFhd7ZZnsY0TW644QYGDhzI+eefzw033EBOTg4AFRUVDBgwgIcffrhdA+0MZYEyvtv5HSNSRhDniqPEX4KuB8G0ulgZqoFqGrjDkFKl4gm7qXT2JagE6w+iY62jOhCY1vIYfDVbD62aNSx6KF3XWblyZYs6rm3ZArfdBoMGQXY2vPRS00XqYYfBa6/BqlUwe7YUqaLlWpOfHeXMM0cwcKAXgLvumsLttx8nRaqwVY4K0RTJUWF3HZGbrSpU7733Xh566CF+//vfs2TJkkZrziUkJHDGGWfw+uuvt1uQnaV2eZrBSYOZlDmJYcnDQFGp7bRhXZNq0KdcJT4Yj1N3Ue7KpFQrhSCwHViDtfjqXCCz5TH4arZyfapoqea8QVRXWwVpdjYMHAh//Sts3br341JT4fe/t4rTL76AM88EmW0k2sIuH64yM+NZtmw2Tz99CjfddFSkwxE2YpccFWJfJEdFT9Oqqb9PPfUUs2fP5s4776SoqGiv+w866CDef//9NgfX2RouT+PSXIxIGcGPFfkEw37Qg7hUJ5oRJLNSIeQMooUcxAYn4Aq7rKVoUrGm+06jVUUqyPWponl0HX74AcrK6m9v3hxLYSE0NeM+EIB337WK1NLSpo+paTB9urXEzLRpMnIquodw2CAU0omKqk/ogQMT+fWv5etAIYQQws5aVahu27aNI444Yp/3x8TEUFb7CboLabg8jUtzARDljKbCEQWqg8nOwQxZv5qsYpWAK0BYreD2Y57ijvyjSPhHgtU4qY3dT2UNVbE/gQAsWAB33QUbNza8RwOGtOqYI0ZYxekFF0B6entEKYQ9BAJhzj33dSorQ7zzzjm43dI/UAghhOgqWvWvdmpqKtu2bdvn/d999x39+vVrdVCRUrs8TUFlAX3irU6+iqKgaQ5MzcHpJamc99kGAMKEyIs3WZX+C5llmTCxfWLw1Wy97XM40U1UVlrLxNx7L+Tltf14cXFwzjlWgTpp0t79wIRoT6qqMmzYsE7tVlldHeKMM/7D4sXWe/aFF77Jf/5zVqc9v+haIpGjQrSE5Kiwu47IzVYd8YwzzuDxxx9n06ZNdftqm1F8+OGHzJ8/n7PO6nofCOLd8WQPyraaKBmNrwNQgPS8xnMmc5JhUGk0cXr7LSLpq9nKpDQB1uXR990HAwbA9de3vUg99lh47jnYudNaI/Www6RIFZ3D5XJ12nOVlweYNu2luiI1KsrBpZdO6LTnF11TZ+aoEK0hOSp6mlaNqN522218/PHHjBs3jsmTJ6MoCnfffTd//vOf+eKLLxg/fjy33HJLe8faKaYPnc7yrcvJKc4hKymrbr9pmpQkx7A5K5XUPB/O0gCbEhWyStqvSAUZURWN/f3vcOute+/3euHaa+Hkk61CU9d1Nm7cyODBg/e5LFSfPpDZymunhWgLwzBYuXIlY8aM6fBly3w+Pyef/CJffrkdgLg4FwsXnsfkyf079HlF19aZOSpEa0iOCrszDKPdj9mqQjUhIYEvv/yS++67j9deew2Px8Onn37K4MGD+ctf/sIf/vAHoqKi2jvWTpEZn8nco+Yyb8U8Vu9eTSBQjmkamCZ8Nrk/bxwcja+6hPiCUipyNzJ1S/suIiPXqIpa+fnWtagNpaXBDTfAFVdAw+XUdB2io6sYM6bpZkpC9ASFhZWccMIL/PhjPgCJiR4WL76AQw+Vb2iEEEKIrqbVnSWioqL405/+xJ/+9Kf2jMcWRqWO4u7su1m0YRFzP78fUw9imiabfZtJi03j9BGnU7r+F17ZtQXNbN+qwFez9bbrUUVXdOedUFVVf/vWW+Hmm6GLfgckRIfasaOcqVMXsHp1IQC9ekWzdOlsDjooLcKRCSGEEKI1pAXiPmTGZ3LZhMt4Mv8XyjcuBtPknux7GJk6kjh3HE9umguAZrbvhcO+mq23XY8qupqtW+GJJ+pvjxkDf/mLrGUqRFPy8so45pj5bNxozUnp3TuOZctmM3x4SoQjE0IIIURrtapQveSSSw74GEVReOaZZ1pzeFspKlpLyLcZVAe3Lb+NEwafwPWHXU84HATAYTisTkvtxFez9bbfIUUXdPvtEAzW377jjv0XqaqqMmbMGOkGKGypo/MzKSmKvn0T2LixhAEDvCxbNptBg6QlnWg+eQ8Vdic5KuyuI3KzVYXqRx99VNflt5au6+zcuRNd1+nVqxcxMTHtEmCk+f0lmKYBepCv875mcOJgAMJGCACtdY2Tm2QAtavPetvtqKIr2bUL7r8f5s+v33fYYTBjxoF/NhgM4vG07zXTQrSXjszPqCgn77xzDlddtYg775xCnz7xB/4hIfYg76HC7iRHRU/Tqipry5YtbN68udGf3Nxcqqqq+Oc//0lcXBzLli1r71g7VV5ZHk9+9yRFRevANMDUKQ+U81nuZ9b+gA8AzWi/2dOlgFnz94R2O6roCrZuhauvtpahueceaNg47c47D7yEjGEYrFu3rkM6rgnRVh2Rn6ZpNrodF+fm+ednSpEqWkXeQ4XdSY4Ku+uI3GzXMVqn08nVV1/NCSecwNVXX92eh+5UqwpWcdPSm5j/43z0mim+zjBoYR2tcDfPffwAC3etoFozcLRjMyVfzTYekMatPcPatTBnDgwZAo88An5/4/svugiOOy4ioQlhW59/vo1Jk54mP78i0qEIIYQQooN0yET3sWPHsnz58o44dIfLK8tj3op55JbmMiJlhDXtF3CYoOg6/TbuZsQ3Wynzl5LvCVHu1NvtuWVpmp7jhx/grLNg5Eh47jkIhxvfP3IkvPACdIPLvIVoVx99tJkTTljAN9/sYOrUBRQVVR34h4QQQgjR5XRIobpkyRKio6M74tAdbuH6hWwq2URWUhZhIwwYqA1mmMWEFDQUEtxeAqrB6qSSfR6rpXw1W2+7HVHYzYoVMG0aTJgAr70Ge8xeZOJEePNNWLkSzj+/ZWuiygLgws7aIz8XLsxh2rQXqay0egRkZMTi8UjzetE+5D1U2J3kqOhpWvUv/O23397kfp/Px/Lly/n++++5+eab2xRYJJQFyli6aSmJnkQ0VcNXcx2qUlNMKCZE6wrExmBqCpqpsCbJR7mvnDji2vz8vpqtt81HEnZimvDhh1bn3s8+a/oxxx4Lt9wC2dkHvh61KZqmMWbMmDbFKURHaY/8fP311Zx77uuEQtYsl1NPHcarr/5KClXRLuQ9VNid5Kiwu474IqVV/8L/9a9/bXJ/YmIigwcP5vHHH+eyyy5rS1wRkVOUQ0FlAQO9AwGoDFYCoNQMe8WEVRRTgQQvphnGYSiUO0Osi1rHRCa2+fl9NVtZVKF7MAx46y2rGdJ33zX9mOnTrQL1iCPa9lymaVJeXk5cXNxeHbmFiLS25ueCBT8xZ87bGIb1Xjxr1igWLJiJ0ymjC6J9yHuosDvJUWF3ezY5bA+tKlS7a8cxf9hP2AjjVJ0AhE3rwsHaqb/O2tP2JmCYhSiAoYBf9e99sFbw1R6+XY4mIiUUgpdfhrvugjVr9r5fUazrU+fOhXHj2uc5DcNg06ZNjBkzRqYGCdtpS34+8cS3XHnlwrpp8nPmjOPpp09B02QtQdF+5D1U2J3kqLA7W3T9ra6u5oYbbuDdd99t92AizePw4FAdhGrWSK1VW6jWfX+V4MU0TUxAM1U8RvusaeWr2Xrb5Wiis5kmvP221Qjpoov2LlIdDrjkEqvT76uvtl+RKkR39cADX3DFFfVF6lVXHcIzz5wqRaoQQgjRA7T4X/uoqCieeOIJdu3a1RHxRFRWchapMakUVBY02r/XBAtvAoZpYJoaqVUpDNs5DL4Fytr2/L6arUz97XpWroSpU+H002HDhsb3eTxwzTWwcaPVxTcrKyIhCtGlmKbJhg3FdbdvvPEIHn74ZFRVprwJIYQQPUGrpv4efPDB/PLLL+0dS8TFu+PJHpTN/B/nkxGbAYDS1Ci2I4GU/N7oegynrT6XuLVx8HsgFcgGpgOZLX9+X83W24rYRWQUFsJf/gJPPGFdk9pQXBxcdRVcfz2kpXV8LB5P+4zsC9ERWpqfiqLw8MPTqKwMMXhwIn/609FyXZboUPIeKuxOclT0NK0qVB988EGmTZvG6NGjmTNnDg5H9+m6OH3odJZvXU5OcQ5OzYk7bJBUBaoBsWET3NHo3ylUhMJkVvbmyLxREAMMBAqA54DlwFxgVMueW9ZR7TqCQXjkEbjtNigtbXyfwwHXXgt/+hMkdtLwuKZpDB8+vHOeTIgWam1+qqrCv/99mhSoosPJe6iwO8lRYXcdce10s6f+Ll++nMLCQgAuuugiVFXlN7/5DfHx8QwdOpSDDjqo0Z+xY8e2e7CdITM+k7lHzaWfM4XCzb8wvMDgoHwYnw9Diky2U8GawMckB11M23gsGdUp1txgF9AHGAHkAvOAvJY9t69m6223sxHtzTRh4UIYMwZuuGHvIvWUU2DVKrjvvs4rUsG6gL2oqKjbNjoTXVtz8lPXDa699n2++25Ho/1SpIrOIO+hwu4kR4XddURuNnso9LjjjuOFF17g3HPPJTk5mZSUFIYNG9buAdnBqEL46/vV/MdXxeJU2JQIugruMAwoDXHG6jImb0mg1IG1XE1DGpAFrAEWAc1cpScAVNf8Xa5RtafVq63i9IMP9r5v5Eh44AE44YTOjwus6/m2bduG1+uNTABC7MeB8jMU0rnwwjd59dVVvPTSSj75ZA6jR6d2bpCiR5P3UGF3kqPC7iK6PI1pmnUBfPLJJ+0eiG3k5eH7y02EV3/HsEQXh66B/FgIaJAQVEj3J1AUq+Kp3kic/hqa0cTiyxrWsOgS4Bwg7sBPWzsw5wCi2+lURPsoLrauQ33sMdD1xvclJcHtt8NvfmNN+RVCtIzfH+bss//Lu+/mAFBWFmDjxmIpVIUQQogeTj5a76Hk9RcpXPkV69M0Ul2JTMjzgWmgmAoaGr8MTMCLi5ykfIbt3kyQpcDMvQ+UCmwG1gETm/G8NVsvTXQZFhERCsHjj1tFaklJ4/s0zWqU9Je/WMWqEKLlqqpCnH76KyxZsgkAt1vjjTdmMW3a0AhHJoQQQohIa1Gh2u2vFSoro/jd/1DoDhMflUx0RRAFa73UWtVuFwoK0XoMRdE+XJUfgVnOXsOmTiAM+Jv31L6arbeNpyDabts2eO45ePZZ2Lx57/tPPtm6BnXEiM6PbX/i4poxdC9EhOyZn2VlAWbMeInPPssFICbGyTvvnMvxxw+MRHhCyHuosD3JUdHTtKhQveCCC7jgggua9VhFUQiHw60KKlIqfvke/46tVCbH4FEUQk6NX/pEEVMZILEKonUXRs0afgoKpW43ydX5VCrfE8MxjQ8Wwnp1m9lJ3FezletTI8Pvh7ffhn//Gz780GqatKfhw+H++61C1W40TWPw4MGRDkOIJu2Zn8XF1Zx00gt8843VOCk+3s3775/PEUf0jVSIooeT91Bhd5Kjwu46outviwrV7OxssrKy2j0Iu9hesAEjGMTlscrFoMfBlswoAkEDxVDIqupnjZI6AExU04mhVLItdj3D9yxUC7Cm/zaz35SvZutth/MQzffDD9bI6Ysv7j29t5bXay1Dc+WV4HR2anjNZhgGBQUFpKamoqrNbuYtRKdomJ+FhVVMnbqAlSsLAEhOjuLDDy9kwoSMCEcpejJ5DxV2Jzkq7C6iXX/BWpbmvPPOa/cg9vTII49w7733kp+fz9ixY3n44Yc59NBDD/hzr7zyCueeey6nnXYab731Vouf1+8AUwWnYXX5bchQDGu91FLqXjWHAWEVzD2LFx2r8jydZjVSAllDtTMVFcFLL1kF6o8/7vtxQ4fCxRfD5ZdDcnKnhdcqpmmSn59Pr169Ih2KEHtpmJ8ffbS5rkhNT49lyZILpXGSiDh5DxV2Jzkq7C6iXX87y6uvvsoNN9zA448/zqRJk3jwwQc58cQTWbduHamp+/4ws2XLFn7/+98zefLkVj+3MXQIpQluknxVlKY0UWHGYq0hEwQTSPQH8XmcJLoaNP7QgRxgIDCt+c/tq9l6WxW5OBBdhyVLrKm9b70FwWDTj4uJgVmzrAL1yCOhu1+WLURnO/fcMezaVcn993/BsmWzGTrU5t8CCSGEECIibDd34P777+eyyy7j4osvZuTIkTz++ONER0fz7LPP7vNndF3n/PPP57bbbmPQoEGtfu4hAyaQM74fztJKFMOkIlhJwF+KoYcwjTDb/DswkgEnuEJOYkIh1vbqzdCqCRAEtmOtn9oPmAtkNv+5fTVbuUa1fZkmPPQQDBhgXVv6n/80XaQedZQ1wpqfD888Y92WIlWIjnH99Yfxyy+/lSJVCCGEEPtkqxHVYDDId999x9y5c+v2qapKdnY2X3zxxT5/7vbbbyc1NZVf//rXfPbZZ/t9jkAgQCAQqLtdVlYGWMVuvCOe6FN/xbaf7qNfno/8FBWjwTB2tRFmpxviUkx6797N1gSNmPDpxBbHwmYwehlwGpgnmZAJqqmiKAr6Hotv1l5b0HAud7GigKKQAOh7zPHWNA3TNPea+61pGoZh7DXU3tR+RVFQVXWf+/eMcV/7VbX557S//Z11Tu++C9df3/TF3RkZJhdeaHLJJQrDhtWfU+2p2fWcGmr4eK/XW/fcXe331NQ5dfXck3Oy9v/88y5ycoo47DDra7ja/TExDnRd75Ln1HB/U7HLOXW9c2r4HtpdzmnPGOWcuvY5mabZ6N/57nBO3fH31JPPKaJTfzviAtk97d69G13XSUtLa7Q/LS2NtWvXNvkzK1as4JlnnuHH/V1s2MC8efO47bbb9tq/atUqYmNjSUuawCszx3LyWz/TN6+aKM2kIMYkpIJLN0ktqiS23M+aTI1HJqrct7wvwfFB3H93s0HZQJVWBcVAMQwaNIj4+HhWr17dKIGGDRuGy+Vi5cqVdfu29u8PXi9RgQArG5yrpmmMGTOG8vJyNm3aVLff4/EwfPhwSkpK2LZtW93+uLg4Bg8eTEFBAfn5+XX7k5KS6NevH9u3b6e4uLhuf3p6Ounp6WzZsoXy8vK6/X379iU5OZn169fj99evsdOScwIYM2YMwWCQdevWReScli2LAnrX3ed0wnHHlTFjRiGHH16OwwEZGYOArnNOTf2eNm7ciN/vx+fzdcnfU3fMPTmn1fz0026uuuoLqqrCvPTS6fTp06fLn1N3/D3JOdWfU3l5ebc7p+74e+qJ51RaWorP56v7d747nFN3/D315HNydkDHUcXsiPK3lXbs2EFmZiaff/45hx9+eN3+G2+8kU8//ZSvvvqq0ePLy8s56KCDePTRRzm5Zs2QOXPm4PP59tlMqakR1b59+1JcXEx8fDx5wJW717DtnVs55qP/cdTKQtIqQTPAdDgpTUnio+HRvDm+LyUHTefDef04NOtslEea/jajud9ynKyqFAMvAkPkm5t2O6d58xT+/Of6Ge4FBZCU1LXPqaHa/aFQiLy8PDIzM1FVtVucU1fPvZ5+Th9/vInTTnuV8nJrrv2kSWmsWHHpXutxd6Vz6o6/Jzmn+hHV2vdQp9PZLc5pzxjlnLr2OYXDYbZv317373x3OKfu+HvqyedUWlpKcnIypaWlxMfH0x5sNfU3JSUFTdPYtWtXo/27du0iPT19r8dv3LiRLVu2cMopp9Ttq32BHQ4H69at22vNKbfbjdvt3utYmqahaRqLgZK00Yya9TBLM/7G/K+eZVihgScEerSbykMOwzt6GpWVfvTMiSw/UmGST6k7RlMOtN/EaiYM1jWqTT1eUZQm99cmXFv3tzb2tuzvjHPa8y6rWV7XPqd9Pd7n89G3b99Gj+nK59TVc6+z99vpnD78cCOnn/4K1dXWWtrHHNOfO+4Ytc8Y93UcO51Te+2Xc7LvOdW+h0L3OaeG5Jy69jkpitLkv/Nd+Zy64++pJ5/Tnl9EtwdbNVNyuVwcfPDBLFu2rG6fYRgsW7as0QhrreHDh7Ny5Up+/PHHuj+nnnoqxx13HD/++GPdPzjNVQYsxSoW4+Mz6TMom6q4eL7rH83/hkSzaexIDp71PCMmXIbqTkCr9LHisEzKY9t23hVYzYJBuv4KIbq2d95ZxymnvFxXpJ500hDee+8cYmJsugixEEIIIWzJViOqADfccAMXXXQREydO5NBDD+XBBx+ksrKSiy++GIDZs2eTmZnJvHnz8Hg8jB49utHPe71egL32N0cOUIC1skwdRQHVepmc7nhcbmvZGhMTR0Uhu5OjWJcBE1v8bPV8NdtowNWG4wghRCS98sovXHDBG+i6NRVo5szhvPzymTgc0kJbCCGEEC1ju0J11qxZFBYWcuutt5Kfn8+4ceNYvHhxXYOl3NzcfQ5Bt5UfCAP7/t7f+rBlmiamaaLoYXS3in/vmcQt4qvZett2GNGDKYpCenp6h0y7EKI5nn32By699B1qL1c5//wxzJ9/Og6HdQ2O5KewM3kPFXYnOSrsriNy03aFKsDVV1/N1Vdf3eR9n3zyyX5/dv78+a1+Xg/WCxKi6ZHN2tffxPokZmpOnLqCp43tqHw1W2/bDtMjbd1qrXual9f0/c1sBt3lqara5HXcQnSG/PwKrrnm/boi9bLLJvDYY9PRNOtLRclPYXeSo8LuJEeF3XXEQKItC9VIyQJSsab/9mni/trOVqZpNWwKx/YiNS/MsNImHtwCJTVbb9sO0+O8+CJceSU06N7dY+m6zpYtWxgwYMA+L5wXoqOkp8fy5puzOOWUl7nyyok88MCJjb5ZlfwUdic5KuxOclTY3Z6dh9uDFKoNxAPZwHwgYz+PM0wTU1HRY7xM/bycuLhebXpeX83W26aj9BxlZXDVVfDCCy37ud69D/yYrqxcKnYRQSecMJgffvgNI0akNDn9R/JT2J3kqLA7yVHR00ihuofpwHKsxkr7ulY1jEkgZTDu3VuY9lkcnNq25/TVbBPbdpge4Ysv4PzzYfPmxvvT0yEmZt8/l5wMt93WsbEJ0VOYpsnixRs4+eShjfaPHNm2L+2EEEIIIWrZankaO8gE5gL9gO2ASf3IgFmzby0KLt820j+8j74Fyv66LzWLr2brbdthujVdh7/9DSZPblykapq1f/t22LBh33+++gpOOily8QvRXRiGyZVXLmTatJe4887PIh2OEEIIIbopKVSbMAq4GziudoeqgapRjUIMcE64msyFfyV25xoUxdnmcWlfzdbbtsN0W1u3wrHHwq23WgVrrYED4bPP4E9/sgrWnkxRFPr27SvdAEWHCocN5sx5iyee+A6AP//5Y1atKjjgz0l+CruTHBV2Jzkq7K4jclMK1X3IxLpe1RGuhmAlBCsZpsAzwLnBSlylO9AMBRSHjKh2oFdfhbFjYcWKxvsvuMDq6Hv44REJy3ZUVSU5ObnDlm4SIhjUOffc11mw4GcANE3hhRdmMmpU6gF/VvJT2J3kqLA7yVFhdx2Rm5Lt+zE0aShpaeNweLxo7gRmZ51OHKCbOmDiMBVAa7cRVblGtV55OVx8MZxzDpQ26KocF2c1UVqwAOLjIxef3ei6ztq1azuk45oQ1dUhZs58lddeWw2Ay6Xx2mtnc+65Y5r185Kfwu4kR4XdSY4Ku5Ouv51sbPpY+vU/muJwNYZhcPnBlwMQNsJggsNQQNFkRLWdff89zJplXVva0OGHW0vSDBwYmbjszu/3RzoE0Q1VVAQ57bRX+Ogj6+Jwj8fBW2/N4sQTh7ToOJKfwu4kR4XdSY6KnkYK1VbQDR1Ms37qbxtexTBQVvN3bzvE1tVt3gzHHWctQVNLVa3rUP/8Z3BIxgrRaXw+P9Onv8Tnn28DIDbWxXvvncsxxwyIbGBCCCGE6PbkY/8BRFe6Gb9lBO6gE74FRtRM/TVNtHaY+ltbjylY67j2ZLoOF17YuEjt188aRT3qqMjFJURPNWfOW3VFqtfrYfHi85k0qU+EoxJCCCFETyCF6r7kAQvh5hdn4twZxGFoqN+qkAqxk2LoVZGBZuxuczMlX802Ablg+N574X//q799+OGwaBF4vRELqctQVZVBgwZJkwXRru65ZypffrkdwzBZsuRCxo5Nb9VxJD+F3UmOCruTHBV21xG5KYVqU1YB84BN4DGcbEzZTEgLc8TAcVAACS8ncE3F31k07EHrGtU2vIolNVtvW2Pu4n74wVp+plZcHLz0khSpzaUoCvHSXUq0s6ysZJYunY2mKYwY0avVx5H8FHYnOSrsTnJU2J0sT9MZ8rCK1FxgJBSmlBFyhDExMZwG9IHqwZWkl/fhrJU3QMjZLiOq3rbG3YVVV1vLzYRC9fsefhgGDIhYSF2OruusXLlSugGKNsnNLSUUapxDo0entqlIBclPYX+So8LuJEeF3UnX386wENgEjISPoj7ijqF/IRiqBmBl1HIeKnsIQzHY6l3PiIKREHa26VX01Wy9bYu6S5s7F1avrr99xhkwe3bk4umq5B8v0RarVhWQnb2AY47pz4svnoGmte/3mJKfwu4kR4XdSY6KnkYK1YbKgKVYC5pqUKwWszF6LYZpvTGsMZMAME0dUzWocvqgXIPQvg54YL6abU9dQ3XpUnjoofrb6enwxBPQAbMHhBD78MMPO5k6dQFFRdW8+uoqhg9P4a9/PTbSYQkhhBCiB5Opvw3lAAVAauPdqgGKWX/bNAwAyt2F1voyea1/yp58jWpxMcyZ03jfs89CSkpEwhGiR/rii20cd9xzFBVZM0cmTuzNNdccGuGohBBCCNHTSaHakB+r8Gxwzalq1aQoJihYw3ymae00FR1MBdowE8NXs/W2/hBd1h13QF6DIv+3v4WTT45cPF2ZqqoMGzZMugGKFvnkky1MnbqA0tIAAEce2ZelSy8kOTm6XZ9H8lPYneSosDvJUWF3HZGbku0NebAmQx9gKq9hWJWpw3BaC6C24TOdr2brbf0huqzPPqv/+6BBcM89kYulO3C5XJEOQXQh77+/npNPfpHKSusNLzt7EB98cAEJCZ4OeT7JT2F3kqPC7iRHRU8jhWpDWVjTfguavtvEmv9r1Ez9jQ/0sgrbIa1/Sl/Ntideo1rzMgIwbhzExEQslC7PMAxWrlxZl5tC7M8bb6zhtNNewe8PAzBjRhbvvnsuMTEd8yFI8lPYneSosDvJUWF3HZGbUqg2FA9kY104up/pvKZpoBgqMUGv9TPe1j9lT75GVQjR+RYtWs/ZZ/+XUMj6B+Xss0fxxhtn4/FIbz0hhBBC2IcUqnuaDgzCaqy0jy8GzLBOf99QiqO3QQKyPI0Qoss44oi+jB2bDsCcOeN46aUzcDq1CEclhBBCCNGYFKp7ygTmAv2A7aAYDdZJMax9sVsSyY/bxkdDHgcXjZovtYQfCNT83dv6iIUQotm8Xg8ffHABd9xxPM88c2q7r5cqhBBCCNEe5BNKU0YBdwPHAQpohoZmaCh+BWJgy9RfeHjyn9kdu9F6fCtHVH01WxcQ1daYRY+mqipjxoyRboBiL6ZpUlXVuENcSko0t9wyGVXtnAWLJT+F3UmOCruTHBV2J11/O1MmkA1V7moq3JVUuiqtZkvPwIapP1AYuxOHWTNdrpUjqg2vT+2cj4uiOwsGg5EOQdiMaZrccssyJk/+Nz6fP6KxSH4Ku5McFXYnOSp6GilUD8BUIKyGCWlhzHgT4kDXrdEJzagpVNs4oupta5CixzMMg3Xr1kk3QFHHMEyuu24xd931P77/fifTp79EOByZ/JD8FHYnOSrsTnJU2F1H5Ka0eWyFcG2hSttGVH01W29bAxJCiAZ03eA3v3mPZ575oW7f+eePweGQ7yaFEEII0TVIodoKerimUDVrPvTJiKoQwiZCIZ2LLnqLl1/+BQBVVXj22VO56KJxkQ1MCCGEEKIFpFBthbAeBBMcRs3L18pXUdZQFe1J02SJkZ4uEAgza9ZrvP32OgAcDpUXXzyDs88eFeHIJD+F/UmOCruTHBU9jRSq+9EvoR99zWHsDuUCMGXgFAB0PQxgNVNSafWVvr6arbdNUQph/eM1ZsyYSIchIqiqKsTMma/y4YdWN3K3W+O1185mxoysCEcm+SnsT3JU2J3kqLC7jvgiRS5Y2o9DMw/lEPNEMqr7kVHdjxuPvBGoL1Q1U2tTqe+r2Sa2LcwuyzQjHUH3YZomZWVlmPKi9kiVlUFOPvnFuiI1OtrJe++dZ4siFSQ/hf1Jjgq7kxwVdtcRuSmFajOZ1HezChvWNaoO09HqRkrQs0dUn30Wfqjv84IsC9Y2hmGwadMm6QbYQ3k8DjIyYgGIj3fzwQcXkJ09KMJR1ZP8FHYnOSrsTnJU2J10/bUJXQ+D2X4jqt52iKkr+de/4JprGu879tiIhCJEt6BpKgsWzMTjcXD11YcycWLvSIckhBBCCNEmUqi2Qt3yNKYGrtYfx1ez9bY1oC7k7rvh5psb77vuOvjtbyMTjxBdlWmaKIpSd9vp1Jg///TIBSSEEEII0Y5kwmUr6EZtMyVnq0t9g551jappwp//vHeResst8MAD0ODztmglj8cT6RBEJ9m8uYQjj3yWnJyiSIfSbJKfwu4kR4XdSY6KnkZGVJtJob6bVbhhM6VWXqNagVWsAiS0ObrI2rbNGiktLNz3Y4qKYNmyxvvuuMMqVEXbaZrG8OHDIx2G6AQ5OUVMmfI827eXMWXK83z22cUMGOCNdFj7Jfkp7E5yVNid5Kiwu47o+iuF6n78L/d/fK68S3F0HgC3fnQrtx9/e4MRVUerX0FfzTaGNvVjirh162DKFMjLa9nPPfigNeVXtA/DMCgpKSExMRFVOlN1WytX7mLq1AXs2lUJQGysC6fT/r9vyU9hd5Kjwu4kR4XddUQzJcn0/dhZsZN8ZTOVjnIqHeV8mfclUD/1V2tD119fzdbb5igj5+ef4eijW1akKgo89ZQUqe3NNE22bdsmbeu7sW+/3cGxxz5XV6SOHZvGp5/OITMzPsKRHZjkp7A7yVFhd5Kjwu46IjdlRLUVwobV9bc9RlS76vWp33wDJ54IJSX1+9LTIS1t3z8TEwN/+AOcfnqHhydEt7JiRS7Tpr1IeXkQgEmTMnn//fNJTIyKcGRCCCGEEB1DCtUDMGv+ByZlgTLKAmXW8jTUjKi28hWsre+87RFkJ/vsM5g+HcrL6/dNmgTvvw+JXbXyFsKmli7dxGmnvUJVldVt/Oij+/Pee+cSF+eOcGRCCCGEEB1HCtV9yCvLY8nGJYQIYCg6JpBTlMOl71xKSTCXoGqg0fOm/i5ZAqedBtXV9fuOOQbefRfi4iIXl4A4+QV0O+++u46zzvovgYAOwIknDuaNN2YRHd31rmyX/BR2Jzkq7E5yVPQ0Uqg2YVXBKuatmMc3ed/UjKZaXX+jHFFUBiv5JbyDYFSIHdEVbZ76622HeDvLu+/Cr34FwWD9vhNPhDfegOjoyMUlrE5rgwcPjnQYop2tXl1YV6SefvpwXnnlTNzurve2Lfkp7E5yVNid5Kiwu47o+ivNlPaQV5bHvBXzyC3NpU98HxQUqPmjKAp94vuQSBRBzeS1gSvJc7Ww3W0NX822q8yUffVVOOOMxkXq6afD229LkWoHhmGQn5/fIR3XROTcdNNR3HLLUZx77mj+859fdckiFSQ/hf1Jjgq7kxwVdiddfzvBwvUL2VSyiaykLFRlXy+PiTusUBBVwSLPolY9T1e6RvXf/4bzzoNwuH7feefBf/4DbrlMzhZM0yQ/P1+6AXZDf//78bzwwhk4ne3/TWVnkfwUdic5KuxOclTYXUfkphSqDZQFyli6aSmJnkQ0dd8fCk1MFBTigh6WOJdQHijf52P3xVez9bYq0s7zyCNwySXQ8EuSSy+F558HZ9e7TE4IW7vvvs/54IMNjfYpioKqKhGKSAghhBAiMqRQbSCnKIeCygJSY1L3+zij5huDpGAMBUoB64rWtfi5fDVbb4t/svPccw9cfXXjfdddB08+CR0wDV2IHss0Tf7610/4/e+XMHPmqyxfvjXSIQkhhBBCRJQUqg34w37CRhinuv+hQhNreNFhOAirYfxhf4ufy1ezteM1qqYJt94KN93UeP8tt8ADD4Aigzu2oygKSUlJKPLL6XJM0+TGG5dw222fAlBdHebrr1t37btdSX4Ku5McFXYnOSrsriNys2t25uggHocHh+ogZIRwaa697rcaK9WPqOoKOBQHHoenRc8TAipq/u5tQ7wdwTTh97+H++9vvP+OO6xCVdiTqqr069cv0mGIFjIMk6uvXsRjj31bt++BB07k+usPi2BU7U/yU9id5KiwO8lRYXeq2v7jnzKi2kBWchapMakUVBY0eX/tUjW1FwuXuqtJVVIZljysRc9TWrNVgdjWBtsBDAOuvHLvIvWBB6RItTvDMMjNzZVugF1IOGxw8cVv1xWpigJPPjmj2xWpIPkp7E9yVNid5KiwO+n628Hi3fFkD8qmxF+CblhrFyqAapqopgnBEISCGJiYmJQ7/Ux1TiXO3bIFmH01Wy/2+gXMnQtPPFF/2/rgDNdfH7GQRDOZpklxcbF0A+wigkGd8857neef/wkATVNYsGAml112cIQj6xiSn8LuJEeF3UmOCrvriNyUqb97mD50Osu3Lidn50qcJaVouo5S+8KX+uDT5WSE/ZTGGfStTGFa1LQWP4evZuttp5jbg88HDz5Yf1vT4Lnn4PzzIxWREN2T3x/mV7/6DwsXrgfA6VR59dVfMXPmiAhHJoQQQghhH3Ya0LOFzPhM5qafRb/1BewqyiUuqBIfUIn3qyQpMWxXyqk2gozNN7nql4PJdGe2+DnsuIbqm29CMFh/+8knpUgVoiN8800eH3ywEQCPx8E775wrRaoQQgghxB6kUN1TXh6jHv0vd/+cynWhgxlVEkdylUqiXyUJNzHuOI7Oc3LTCoUjcn6C8pZ35/TVbL3tGXcbvfRS/d8TE+GCCyIXi2g5RVFIT0+XboBdwOTJ/XnhhZnEx7t5//3zOemkIZEOqcNJfgq7kxwVdic5KuxOuv52hoULYdMmMkeO4TK/RsaPpaz05BJSYdrowxkWTmD5tv9S7dJxBYpg9SLgshY9ha9m623n0FsrPx8++qj+9q9+Ba69mx4LG1NVlfT09EiHIZpp1qzRTJ06mKSkqEiH0ikkP4XdSY4Ku5McFXYnXX87WlkZLF1qDSlqGgDRusbgEifDi5xMCKYQZ7qsZkqKgqHFwuolUF7eoqex29Tf//7X6vhb69xzIxeLaB1d19m4cSO6rkc6FLGH/PyKuqZJDfWUIhUkP4X9SY4Ku5McFXbXEbkpI6oN5eRAQQEMHFi3SwkH0HQfplJf09ctU+P0QnkBrFsHEyc2+2l8NVtv2yNuFy+/XP/3jAw4+ujIxSJar7yFX5iIjrdtWylTpjzP+vXF+P1hLr+8e3b1bQ7JT2F3kqPC7iRHRU8jI6oN+f0QDoPTWbfLWV0MgGLWDzkaNV2AFdMJZtj6uRbw1Wy9bYm1nWzeDF98UX/7nHPqBpOFEG2wcWMxkyf/m/XrrfeQefNWUFUVinBUQgghhBBdgxSqDXk84HBAaP8fJmtHVFUAzWH9XAv4araJLQ6w/T31VOPbMu1XiLZbvbqQyZP/zdatpQAMGZLEp5/OITraeYCfFEIIIYQQIFN/G8vKgtRUa/pvnz585yzkXxPKqVKtOddbY1byu8oxdYWqFi6DxP4wbFiLnsZXs/W2X+St8sADMG9e/e3Bg1s0g1nYiKIo9O3bV7oB2sCPP+YzdeoCdu+uAmDUqF4sWXIhGRlxEY4sciQ/hd1Jjgq7kxwVdtcRuSkjqg3Fx0N2NpSUgK6zWStnaX8/K/qZrOhn8oFne91DFdNE1Sth4lSIa/4HUJPIF6oVFfCXv8ANNzTe/4c/gLz/dU2qqpKcnNwhHddE83355XaOO+65uiJ1woQMPvlkTo8uUkHyU9if5KiwO8lRYXfS9bczTJ8OgwZZjZUatsLFmvJrYKAYJv1LTExXHzhiWosOXw0Ea/7ubZeAm6eoCObPh1NPhZQUuP32xvf/5S9w+eWdGJBoV7qus3btWukGGEGffrqFqVMX4PNZ16wfcURfPvpoNikp0RGOLPIkP4XdSY4Ku5McFXYnXX87Q2YmzJ1rzYnd/g3qUBMDQAEME7ZvZ1CRQV6cwsi4S3BmZLbo8L6arRvo6MUptm+Ht96CN9+ETz+FfeXPPfdYo6mia/O3sKmXaD+BQJgLLniTigrra6jjjx/I22+fQ2ysLEhcS/JT2J3kqLA7yVHR08iIalNGjYK774bjjsNUQDNBM0CprsaIjuad0Q4ePsyJ5h4BLeyN4qvZets55Ia+/x6OOAL69oVrroGPPmq6SI2NtZopSZEqRNu43Q7eemsW8fFupk8fynvvnStFqhBCCCFEG8iI6r5kZkJ2NtUvP4thhsAEs18WlX9+iLfvWQqVOprpbvEr6KvZets53Fpbt8Jxx0FZWdP3e71wyikwcyaceCJEy6xEIdrFwQf35vPPL2Ho0GRcLlnjSQghhBCiLaRQPQATCKlWhyElIQE9JhpMUExQFaetRlR1HS66aO8iNT0dTj8dzjgDjj220TKxoptQVZVBgwZJk4VO9MknWzj66P6oan0HslGjUiMYkX1Jfgq7kxwVdic5KuxOmilFmgJhIwymicNQQHG0ekS1I9ZQfeAB61rUWoccAv/7H+TlwWOPwdSpUqR2V4qiEB8fL23rO8lDD33Jccc9x9VXL8I0zUiHY3uSn8LuJEeF3UmOCruT5WkizDRNdFMH00QzAbQWF6olNVtv+4bGzz/DH/9Yfzs2Fl5+2bpWVb586/50XWflypXSDbAT3HnnZ1x//QcAPPbYtyxcuD7CEdmf5KewO8lRYXeSo8LupOuvDYSNMGCiGWqbRlS97RiT3w/nnw/BYP2+Bx+EwYPb8UmE7ck/Xh3LNE3+9KePuPPOFXX7br31aKZPHxrBqLoOyU9hd5Kjwu4kR0VPI4VqC4V1q7GSZtZM/bXBNap/+hP88kv97dNOg0suaccnEKKHM02T3/3uAx566Ku6fXffnc2NNx4ZwaiEEEIIIbovKVRbSNdDADgMbHGN6scfw/33199OTYUnnwS5hEGI9qHrBldc8R5PP/1D3b5//etkrrrq0AhGJYQQQgjRvUmh2gIKCnrYml/r0BVAa/GIanteo7phg9Xlt2Evl2eesYpV0bOoqsqwYcOkG2A7C4cNLrroLV56aSUAqqrwzDOnMmfOuMgG1sVIfgq7kxwVdic5KuxOuv5GgGIqOA0HTsMJZWAWh4HITv1duRLOOw+GDYNt2+r3X345zJjRhgOLLs3lckU6hG5n7tyldUWqw6Hy0ktnSJHaSpKfwu4kR4XdSY6KnkYK1X3JA5ZAVCiOmGA8McE4WAfpf+jH6SvnkFrRG5SWdf01gNolTlsz9ferr6zrTw86yOroaxj19w0ZAvfd14qDim7BMAxWrlyJ0TApRJv93/8dwdChSbhcGm+8cTazZo2OdEhdkuSnsDvJUWF3kqPC7joiN2Xqb1NWAfPA6/MyNGMQVVoVpmIyOHowShWcknMBPtcxEN2yqb9lWMUqQHwzf8Y0retQ77gDPvqo6ccccQQ8/7y1JI0Qov2kp8eybNls1q8v5vjjB0Y6HCGEEEKIHkMK1T3lAfOAXMjOysbzaQW7HEUAzDzqYnb3ymNT4VqGFwyDcgV2AX2bd2hfzTaOA7/whgHvvQd33mmNpDblhBPgllvg6KOleZIQ7aGkpBqHQyUuzl23r2/fBPr2TYhgVEKI7sowDIIN15YTYh90Xcc0Tfx+P5qmRToc0QM5nc5Ozz0pVPe0ENgEjASa+F0Yho6pGuyM28iIgiNgMXBZ8w7tq9l69/OYcBj++1+YN8+6FrUpM2fC3LlwyCHNe14hxIEVFlZywgkv4PV6WLToPKKiWngBuhBCtEAwGGTz5s0ylVM0i2maqKrK1q1bUWR0QkSI1+slPT2903JQCtWGyoClWBeQNlGkKiiYZs0/KIppTftdApyDNUx6AL6abVPXpwYCsGAB3HUXbNy49/2aBueeCzffDKNGHfi5RM+iqipjxoyRboCttGNHOdnZz7NmzW4ArrhiIc89d3pkg+pGJD+F3XV2jpqmyc6dO9E0jb59+8p/G+KAzAZLPEihKjqbaZpUVVVRUFAAQEZGxl6P6Yj3MSlUG8oBCoD9XIpm1nzzqZoKuGoevw6YeODDN7U0TWUlPP003Hsv5OXt/TMuF1x8Mdx4Iwwa1IxzED1WMBjE4/FEOowuZ8sWH1OmPM+mTdZ/oZmZcdxyy1ERjqr7kfwUdteZORoOh6mqqqJ3795ER0d3ynOKrs00TUzTRFEUKVRFRERFRQFQUFBAampqp0wDlq/wGvIDYfbZIMnErBtRVUzFGnUN1/xcM/hqtl5A163idMAAuP76vYvUmBj4v/+DzZvh8celSBX7ZxgG69atkylkLZSTU8TRR/+7rkgdONDLZ59dzLBhKRGOrHuR/BR219k5qus6IMuNiJbx+5v5gVOIDlL7xVooFNrrPun629E8WK9ICGu0tAmGYf3joqKAUvP4Zn4B66vZxukweza89NLej/F64dprrT/JyS2IXQjRIr/8UkB29vPs2lUJwPDhKSxdeiGZmc3tyS2EEG0jI2NCiK6ks9+zpFBtKAtIxZrO2wdWOlby/KjXqFCrACiJNjnBPAKwrlclXPP4Yc07vA8wDXjhX/D9HkVqWpo1gnrFFRDXjOtdhRCt9913OzjhhBcoLq4G4KCD0liy5EJSU2MiHJkQQgghhAApVBuLB7KB+UAGrPOs442sRRiKNZS9W6kg25gEgGqo1sjrVJrVSAmgMAQbNkPZsvp9Lpc1Bfiyy6Bm6rcQrSLt6ptn5cpdHH/885SVBQA45JDeLF58AUlJ8h9gR5L8FHYnOSqEEPYi16juaTowCKux0h5TrWu7/iqGSlrFIKtAnda8w5aXw+sfQVkZdXOAo6KstVKvvVaKVNE2mqYxZswY+aDVDFlZyRx2WB8AJk/ux9Kls6VI7WCSn8LuJEc7x7HHHsv111+/38cMGDCABx98sEOe/8ILL+TOO+/skGN3NEVRiI6OttV08dWrV9OnTx8qKysjHYqwgY54/5RCdU+ZwFygH7AdVFMFs+ZNwQD37hgGFQ+nNCofRtU8/gBKSiA7GwoCNTt81vTeDz6AqVM74iRET2OaJmVlZY3a14umud0O3nxzFjfffCSLF19AfLw70iF1e5Kfwu4kR5tnzpw5dV1nG/7ZsGFDp8WwatUqzjzzTAYMGICiKM0uan/66ScWLVrEtddeu9d9L7/8MpqmcdVVV+113/z58/F6vU0eU1EU3nrrrUb7Xn/9dY499lgSEhKIjY3loIMO4vbbb6e4uLhZce6LaZrout5kjhYXF3P++ecTHx+P1+vl17/+NRUVFfs9Xn5+PhdeeCHp6enExMQwYcIEXn/99UaPycnJ4bTTTiMlJYX4+HiOOuooPv7447r7R44cyWGHHcb999/fpnMT3UNHvH9KodqUUcDdwHFWjaqZGprhgGoIuwK8M3IBHw5/AJrRGLSgAI47Dr7+mrp1aRJMWLYMJk/uuFMQPYthGGzatEm6qu5DIBBudDs62sm8edlER++jxbdoV5Kfwu4kR5vvpJNOYufOnY3+DBy4n3X92llVVRWDBg3irrvuIj09vdk/9/DDD3PWWWcRGxu7133PPPMMN954Iy+//HKbOuv+8Y9/ZNasWRxyyCG8//77/PLLL9x333389NNPLFiwoNXHrRUIBJrcf/7557Nq1SqWLFnCe++9x/Lly7n88sv3e6zZs2ezbt063nnnHVauXMkZZ5zB2WefzQ8//FD3mBkzZhAOh/noo4/47rvvGDt2LDNmzCA/P7/uMRdffDGPPfYY4XC4qacRPUhHvH9KobovmUA2VLvKqXSVUeksx8wy+fw3b/D2qOeodBcd8ArfvDw45hj46SesJW+iweGA91+GQw7phHMQQvD88z8xevRjbN9eFulQhBCiaaYJ1dWR+dPCURC32016enqjP7VT/j799FMOPfRQ3G43GRkZ3HzzzfstYAoKCjjllFOIiopi4MCBvPjiiwd8/kMOOYR7772Xc845B7e7eTNidF3ntdde45RTTtnrvs2bN/P5559z8803k5WVxRtvvNGsY+7p66+/5s477+S+++7j3nvv5YgjjmDAgAFMnTqV119/nYsuuqhVxz2QNWvWsHjxYp5++mkmTZrEUUcdxcMPP8wrr7zCjh079vlzn3/+Oddccw2HHnoogwYN4k9/+hNer5fvvvsOgN27d7N+/XpuvvlmDjroIIYOHcpdd91FVVUVv/zyS91xpk6d+v/s3Xl8jNf+wPHPM5NdNkEkISSkEktEVGlsSQixNFe1/SGWiqLVUlW1dKF1uYpaLqqWVmKvvcW1L0k0xK5R+xJLFKEkEZF9Zn5/TDKMmWwkmQnnfV9zp3OeZc4zOSb5Puec7yEpKYn9+/eXyfUJrzaRTKkIKlTkyPK+ZO0gy1Q9Dt9EJS/007t+Hdq3h6tX8wrswdQUvOrBm2I6nCCUiwULjvHJJ9sBCApazqFDA6lcWfwDFATByGRmGm6YVUxMqSTKuHXrFl26dCEsLIzly5dz4cIFBg8ejIWFBRMmTNB7TFhYGLdv3yYqKgpTU1OGDx/OvXv3Xrguz/rrr794+PAhzZo109m2ZMkSunbtip2dHX379iU8PJzevXuX+D1WrVqFtbU1n3zyid7tBQ0fBmjYsCE3btwocHubNm3Yvn273m2HDh3C3t5e69qCgoKQyWQcOXKE7t276z2uZcuWrF27lq5du2Jvb8+6devIzMwkICAAgCpVquDp6cny5ctp2rQp5ubmLFq0CEdHR15//XXNeczMzGjSpAkxMTG0b9++wGsQhOchAtUSUijUQau8iEC1T5+nglSgpjfYe4GTuXr5VUEobRYWxVzQ9xUxc2Yso0bt0bzu0KEOdnbiMzIU0T4FYyfaaPFs3bpVa/hs586dWb9+PfPnz8fV1ZV58+YhSRJeXl7cvn2bsWPH8u233yKTaQ/iu3TpEjt27ODo0aO8kTfMLDw8nPr165d6nW/cuIFcLsfR0VGrXKlUsnTpUn788UcAevXqxRdffMG1a9dKPJz58uXL1KlTB1PTkk8p2b59Ozk5OQVut8y7kaAvkVJiYqLOdZmYmODg4KA1RPdZ69ato2fPnlSpUgUTExOsrKz4/fff8fDw0LzX3r17efvtt7GxsUEmk+Ho6MjOnTupXLmy1rlcXFwKDbQF4XmJQLUEJEkiV6H+IpGr5OrhvHqcOQOxsU9ee3rC9F/h3+ZQWf8hgvBC5HI5Xl5ehq6GUVCpVEycuJ8JE54MQxo7thVTprQ3qmyJrxLRPgVjZ/A2amGh7tk01HuXQGBgIAsWLNC8rlRJvf70+fPn8fPz0/qebdWqFWlpafz999/UqlVL6zznz5/HxMREq3fOy8ur0J7H55WRkYG5ubnO74A9e/bw+PFjunRRL+FQtWpVOnToQEREBJMmTSrRe7xIIpnatWsXaz/LUlwiYvz48aSkpLB3716qVq3Kpk2b6NGjBzExMXh7e6NSqRg6dCiOjo7ExMRgaWnJ4sWLCQkJ4dixYzg7O2vVKz09vdTqJlRMZZH1VwSqJaBSqchVqgPVwob+rl6t/XrjRrhVXf3f9mVXPeEVplQqSU5OpnLlyjp3rV8lKpWKsWP3Mn36kztFkyYF8s03bUSQakCifQrGzuBtVJIqzDp1lSpV0vS6VRRVq1YlPT2d7OxszMzMNOXh4eEkJSVpBYBKpZK//vqLf//738hkMmxtbXn8+DFKpVKrbaSkpABgZ2cHQL169Thw4AA5OTkl7lUt7tBfhUKBXC7X+n3m5OSkM1w6NzeXpKSkApNNxcfHM2/ePM6cOUPDhg0B8PHxISYmhp9++omFCxcSGRnJ1q1bSU5OxtbWFoD58+ezZ88eli1bxpdffqk5X1JSEnXr1i3RNQsvH5FMyQgoFLmgKrhHVaXSDlR9fKBhQ83SqSJQFcqESqXi5s2br/TSCkqlimHDtmsFqbNmdWTcuLYiSDUw0T4FYyfa6IurX78+hw4d0voMDx48iI2NDTVr1tTZ38vLi9zcXE3yHoCLFy9qAsDS1KRJE0C97me+Bw8esHnzZtasWUNcXJzm8eeff5KcnMzu3bsB8PT0JDc3l7i4OK1znjx5ElAHqAC9e/cmLS2N+fPn661DYde1fft2rTo8+1i8eDEA2dnZOsf6+fmRkpKi9TlGRkaiVCpp0aKF3vfL7/189qaMXC7XBBsF7SOTyXQCkjNnzuDr61vg9QmvhrL4/hQ9qiWUP0fVRGmiN1A9cgSuXXvyOn8+fkrea/uyrJwgvKKUShUDB25h6dI4QN05sXDhW3z44euFHygIgiCUik8++YTZs2fz6aefMmzYMC5evMh3333HyJEj9fZSe3p60qlTJz766CMWLFiAiYkJI0aMKHJ4a3Z2tibgzM7O5tatW8TFxWFtbV1gT2+1atVo2rQpBw4c0AStK1asoEqVKvTo0UPnZmaXLl0IDw+nU6dONGzYkI4dO/LBBx8wc+ZM6tSpw8WLFxkxYgQ9e/akRo0aALRo0YIxY8bwxRdfcOvWLbp3746LiwtXrlxh4cKFtG7dms8++0xv/Yoz9LegIKB+/fp06tSJwYMHs3DhQnJychg2bBi9evXCxcUFUCe6at++PcuXL6d58+Z4eXnh4eHBRx99xIwZM6hSpQqbNm3SLG8D6gC4cuXK9O/fn2+//RZLS0t++eUXrl27RteuXTXvf/36dW7dukVQUFCR1yAIJSV6VEsof46qicpEb5j/7LDfXr3Uz8l5r8UcVUEofZIElSur51nJZBLLl3cXQaogCEI5qlGjBtu3b+fo0aP4+PgwZMgQBg4cyLhx4wo8ZsmSJbi4uODv788777zDhx9+qJMY6Fm3b9/G19cXX19f7ty5w4wZM/D19WXQoEGFHjdo0CCt5W8iIiLo3r273hE37777Llu2bOH+/fsArF27Fn9/fz766CMaNmzI8OHD6datm6anM9+0adP49ddfOXLkCMHBwTRs2JCRI0fSuHHjMlueBtQZh728vGjfvj1dunShdevW/Pzzz5rtOTk5XLx4UdNLampqyvbt26lWrRohISE0btyY5cuXs2zZMq35ujt37iQtLY127drRrFkzDhw4wObNm/Hx8dGce/Xq1XTs2LHY82wFoSQk1Ss+ziU1NRU7OzsePnyoGYOfb8O5DfRf3ZtsSd2LGvhaEO1Tq7D+whYGn23LR0E74Osn++fmQs2acPeu+nXr1k9yI3wF7AFGAb3K/KqEV41CoeD69eu4ubmVyWT2ikClUjF8+A4CAtx4990Ghq6O8BTRPgVjV95tNDMzU5NZVmQbLh8ZGRl4enqydu1a/Pz8DF2dElOpVGRlZelNCmUo2dnZvPbaa/z666+0atXK0NURykFh313Jyck4ODjojamelxj6WwKSJD1ZngbdHtXo6CdBKkBo6JP/Tsl7ti/D+gmvLrlc/sonMpAkiR9/7GLoagh6iPYpGDvRRl9+lpaWLF++XNNLWtFIkmR0NzUSEhL4+uuvRZAqAGWT9VcM/S2EpYklVgozTJVgqoQqllXIVeYnU9INVNeuffLfcjn83/89eZ2S9yyG/gplQalUkpiYWCYZ14xRamoWXbqs4vDhvw1dFaEYXrX2KVQ8oo2+GgICAggJCTF0NZ6LSqUiJyfHqBJ+5c9zFQQQWX/LXdd6Xel5ywevB5Z43bdkxdsr1IEq+penuXjxyX+3bAnVqj15nT9H1b5Mayy8qlQqFYmJiUb1C6ysPHiQTvv2y9mx4wqdO68iLq7gBc0F4/AqtU+hYhJtVKgIcnJyDF0FQSiQyPprBBR5gapcZaqT9ffpn4+NzVPliKG/glAaEhPT6NBhBWfOqNeMk8sllErxh6UgCIIgCMLLRgSqJaRQKoCCs/7qkw7k5v23fVlUShBeATdvPiQoaAWXLj0AwMnJmr17+9GwYeEZIgVBEARBEISKRwSqxSWpJ7I/Gfqr26NakJS8Z0vAvCzqJrzyJEnCwcHBaDIBlrb4+CTat1/OjRsPAahVy459+97Hw8PBwDUTiuNlb59CxSfaqFARiKzpgjEri+9PEaiWgEwm0/SoyvXMUS2ImJ8qlDWZTEatWrUMXY0ycf78PwQFreD27UcAeHg4sHdvP2rXtjdsxYRie5nbp/ByEG1UMHaSJGFuLro7BOMlk5V+6iORTKkElEqleo6qCuSUvEfVvozqJQhKpZKEhISXLmNlXFwi/v5LNUFqgwbV+OOPMBGkVjAva/sUXh6ijQrGLn8dVZHwSzBWIutvObv04BJnbBK5b5nDfcscNp7bSK4qv0fVRASqgtFQqVQkJSW9dL/Azpy5xz//pAPg6+tEdHR/nJ1tijhKMDYva/sUXh6ijQoVgUKhMHQVBKFAZfH9KQLVQvx19y+OVb7JHetc7ljn8sufv2jPUS3m0N+UvGexhqoglEzfvo356acu+PnVJDKyP9WqVTJ0lQRBEITnFBAQwIgRIwrdx83NjdmzZ5fJ+7dt25Zff/21TM79Klq4cGGFXZdWqBhEoFpCCk2PavEDVTFHVRCe3yefvMEffwzA3t7C0FURBEF4pYWFhSFJks7jypUr5VaHX375hTZt2lC5cmUqV65MUFAQR48eLfK4LVu2cPfuXXr16qWzbcqUKcjlcqZPn66zbcKECTRp0kSn/Pr160iSRFxcnKZMpVLx888/06JFC6ytrbG3t6dZs2bMnj2b9PT0El1nSSQkJNC1a1esrKxwdHRk9OjR5ObmFnrMpUuX6NatG1WrVsXW1pbWrVsTFRWl2b506VK9P2tJkrh3T71E3AcffMDJkyeJiYkps2sTXm0iUC0hhUo9/vp5elTty6JCgoA6yYKTk1OFz1i5efMFVqw4pVNuYiK+qiqyl6V9Ci8v0UaLr1OnTty5c0fr4e7uXm7vHx0dTWhoKFFRURw6dAhXV1c6duzIrVu3Cj1u7ty5DBgwQG/Cl4iICMaMGUNERMQL1a1fv36MGDGCbt26ERUVRVxcHOPHj2fz5s3s3r37hc4NYGqqO+dMoVDQtWtXsrOziY2NZdmyZSxdupRvv/220HO99dZb5ObmEhkZyYkTJ/Dx8eGtt94iMTERgJ49e+r8nIODg/H398fRUb0snJmZGb1792bu3LkvfG1CxSey/hqYJEnqOaqq51uexr6M6iUIMpkMJycnQ1fjhaxefZp+/X5HpQJLS1Pee6+BoasklJKXoX0KLzdDt1GVSkVmbqZB3tvCxKJEf2Cam5sX+Fnt37+f0aNHc+rUKRwcHOjfvz//+c9/MDHR/+fmvXv3GDhwIHv37sXJyYn//Oc/Rb7/qlWrtF4vXryYjRs3sm/fPt5//329x/zzzz9ERkYyZ84cvXXOyMhg4sSJLF++nNjYWFq2bFlkPZ61bt06Vq1axaZNm+jWrZum3M3NjX/961+kpqaW+JxPkyRJb6C6e/duzp07x969e6levTpNmjRh0qRJjB07lgkTJmBmZqZzzP3797l8+TLh4eE0btwYgKlTpzJ//nzOnDmDk5MTlpaWWFpaao7J/wzDw8O1zhUSEkKHDh3IyMjQ2l949ZRF1l8RqJaASqV6sjwNokdVMB4KhYLr16/j5uZWIddZi4j4k0GDtpA/D3/HjssiUH2JVPT2Kbz8DN1GM3MzabOkTbm/L0DMgBgsTV88wLh16xZdunQhLCyM5cuXc+HCBQYPHoyFhQUTJkzQe0xYWBi3b98mKioKU1NThg8frhlWWlzp6enk5OTg4FDwutoHDhzAysqK+vXr62wLDw8nNDQUU1NTQkNDCQ8Pf65AddWqVXh6emoFqfkkScLOzq7AY62trQs9d9++fVmwYAFZWVmYm5tr3Vg4dOgQ3t7eVK9eXVMWHBzMxx9/zNmzZ/H19dU5X5UqVfD09GT58uU0bdoUc3NzFi1ahKOjI6+//rreOixfvhwrKyvee+89rfJmzZqRm5vLkSNHCAgIKPQ6hJdbWST7EoFqCWnNUS1mj6qYoyqUh0ePHhm6Cs/lxx+PMHz4Ts3rjz56nfnzuxqwRkJZqKjtU3h1iDZaPFu3btUKrDp37sz69euZP38+rq6uzJs3D0mS8PLy4vbt24wdO5Zvv/1Wp7fl0qVL7Nixg6NHj/LGG28A6qBRXzBZmLFjx+Li4kJQUFCB+9y4cYPq1avr1CE1NZUNGzZw6NAhQB0QtmnThjlz5hQZPD7r8uXLeHp6luiYfE/Pc9XH1tYW0L/8R2JiolaQCmhe5w/jfZYkSezdu5e3334bGxsbZDIZjo6O7Ny5k8qV9af+DA8Pp3fv3jq9plZWVtjZ2XHjxo1Cr0EQnocIVEsof3kaMUdVEF7c1KkH+OqrfZrXn3/+JjNndhTzxARBeKVYmFgQM8AwCWksTEqWqC4wMJAFCxZoXleqpM7Gfv78efz8/LS+v1u1akVaWhp///03tWrV0jrP+fPnMTEx0erB8/Lywt7evth1mTp1KmvWrCE6OhoLi4KvIyMjQ+/21atXU7duXXx8fABo0qQJtWvXZu3atQwcOLDY9YAXW5rDw8OjTM+v71xDhw7F0dGRmJgYLC0tWbx4MSEhIRw7dgxnZ2et/Q8dOsT58+dZsWKF3vNZWlqWabIo4dUlAtUSyuWpob/F6FFVAPn3aO3LqlKCUMGoVCrGj49i8uQnf5iNH9+Wf/87QASpgiC8ciRJKpXht+WhUqVKxQqsytqMGTOYOnUqe/fu1cyzLEjVqlVJTk7WKQ8PD+fs2bNac2iVSiURERGaQNXW1paHDx/qHJuSkgKgGdJbr149Lly48FzXUtyhv/o4OTnpZD2+e/euZps+kZGRbN26leTkZE1v7fz589mzZw/Lli3jyy+/1Np/8eLFNGnSpMBhwUlJSVSrVq3QaxCE5yEC1RLKz/pb3KG/qYAKkICCZycIwouRJAlXV9cKEeSpVCpGjtzF7NlHNGVTp7Zn7NjWBqyVUJYqUvsUXk2ijb64+vXrs3HjRlQqleZzPHjwIDY2NtSsWVNnfy8vL3Jzczlx4oRm6O/Fixc1AWBhfvjhByZPnsyuXbto1qxZkfv7+vqSmJhIcnKyZmjr6dOnOX78ONHR0VrzW5OSkggICODChQt4eXnh6enJ33//zd27d7WG2J48eRILCwtNT3Hv3r3p1asXmzdv1pmnqlKpSE1NLXCeanGH/upLjOTn58fkyZO5d++eJhvvnj17sLW1pUED/bke8ns/nx0KLZPJdIYXp6WlsW7dOqZMmaL3XPHx8WRmZuqdCyu8Wsri+1Os+VAC6qy/yrysv2bFCvPz79/ZACKFiFBWZDIZVapUKZOMa6UtPj6ZX345qXk9d24nEaS+5CpS+xReTaKNvrhPPvmEmzdv8umnn3LhwgU2b97Md999x8iRI/V+rp6ennTq1ImPPvqII0eOcOLECQYNGlRk5thp06Yxfvx4IiIicHNzIzExkcTERNLS0go8xtfXl6pVq3Lw4EFNWXh4OM2bN6dt27Y0atRI82jbti1vvPGGJrttcHAwnp6ehIaGEhsby9WrV9mwYQPjxo3js88+0yTf6tGjBz179iQ0NJTvv/+e48ePc+PGDbZu3UpQUJDWGqXP8vDwKPTh6OiIJEmYmJjoBAMdO3akQYMG9OvXj1OnTrFr1y7GjRvH0KFDMTc3B+Do0aN4eXlplvDx8/OjcuXK9O/fn1OnTnHp0iVGjx7NtWvX6NpVO0fE2rVryc3NpW/fvnrrHhMTQ506dahbt26B1ye8Gsri+1N8I5eASqVCQf46qubFClRT8p7ty6pSgoA609qFCxfKJONaafPwcGDr1t5UqmRKePi/+PTTFoauklDGKlL7FF5Noo2+uBo1arB9+3aOHj2Kj48PQ4YMYeDAgYwbN67AY5YsWYKLiwv+/v688847fPjhh5pewYIsWLCA7Oxs3nvvPZydnTWPGTNmFHiMXC5nwIABmqVtsrOzWblyJe+++67e/d99912WL19OTk4OJiYm7N69m1q1ahEaGkqjRo347rvv+Oyzz5g0aZLmGEmS+PXXX5k1axabNm3C39+fxo0bM2HCBLp160ZwcHCh11UUlUpFRkaGzlxVuVzO1q1bkcvl+Pn50bdvX95//30mTpyo2Sc9PZ2LFy+Sk5MDqIdC79y5k7S0NNq1a0ezZs04cOAAmzdv1szXzRceHs4777xT4Nzh1atXM3jw4Be6NuHlUBbfn5KqNGdnV0D5QzEePnyoGVqRb8O5DfRf3ZtsKReAwNeCyDnzF49SH7HxyApqb3oHnsoN0KYNHDig/u8uXWDbNogExgCNgRdbRloQCqZQKDh9+jTe3t4VZvmPe/ce4+hYydDVEMpBRWyfwqulvNtoZmYm165dw93dvdAkQELpSUxMpGHDhpw8eZLatWsbujollh+oWlpaGs0Q9bNnz9KuXTsuXbpU6PI7wsujsO+u5ORkHBwc9MZUz0v0qJZQfo9qcZMppeQ960/2LQgvv4yMHCIi/tS5CyyCVEEQBKG8ODk5ER4eTkJCgqGr8tK4c+cOy5cvF0GqUGZEMqUSys/6W9w5qil5z/ZlVSFBMGKPHmXxr3+tITr6OjdupPDvfwcaukqCIAjCK+rtt982dBVeKoWtXSsIpUH0qBZCJsmQqSQk1Fl7zeRm5Ob1CpW0R9W+bKooCIB6AnudOnWMKhFISkomHTuuJDr6OgCzZh3m5k3dFP/Cy88Y26cgPE20UaEiyE+OJAjGSCRTKmfv1H+H/jeb0egfSxr9Y8n/Qv+HUjP0t2Q9qmLor1CWJEnC1tbWaOat/PPPYwIDl3H48N8A2NtbsG/f+7i6iuFBryJja5+C8CzRRgVjJ0kScrlctFHBaInlaQxJBdm52ZDXo2qiNC9Wj2r+8jT2ZVYxQXiSCMQYMlbevv2IgIBlxMUlAlCtmhXR0f1p3ryGgWsmGIoxtU9B0Ee0UcHYqVQq0tPTdfI9CIKxKIvvTzFHtQQUSsWTQLWEPar2ZVUpQchjDH9g3biRQvv2y4mPV9+iqVHDhr1738fLq6qBayYYmjG0T0EojGijgiAIxkUEqiWgUCkg70aWXDIrVn90St6zfRnVSRCMxeXLD2jffjk3b6YC4O5uz7597+PuLga+C4IgCIIgCCUjAtUSyFXmanpU5Sbm6gxLRUjJexZ/qgsvM5VKRf/+mzRBqqdnFfbufZ+aNUtnHS1BEARBEATh1SLmqBaXhDqRUn6gKi8681oWkJH33/ZlVjFBUGda8/T0NFjGSkmSWLnyHWrUsKFx4+rs3x8mglRBw9DtUxCKItpo+QgICGDEiBGF7uPm5sbs2bPL5P3btm3Lr7/+WibnLg8WFhaGroKWnTt30qRJE5RKpaGrIhgBkfW3nN1IuUF8pQekmOeSYp5L1LUoAGQqkEyL7oxOyXs2AazKrJaCoGZmZmbQ969TpzJRUf2JiupP9erWBq2LYHwM3T4FoSiijRYtLCwMSZJ0HleuXCm3Ovz22280a9YMe3t7KlWqRJMmTVixYkWRx23ZsoW7d+/Sq1cvnW1TpkxBLpczffp0nW0TJkygSZMmOuXXr19HkiTi4uI0ZSqVip9//pkWLVpgbW2Nvb09zZo1Y/bs2aSnp5foOvUpKKtqQkICXbt2xcrKCkdHR0aPHk1ubm6h57p06RLdunWjatWq2Nra0rp1a6KiorT22bdvHy1btsTGxgYnJyfGjh2rdd5OnTphamrKqlWrXvjaBEEfEagW4tjtY/xR9RoJlVUkOMCUYz+hMLXGRCmBSfEDVXuKNUpYEJ6bUqnk9OnT5XpX88SJ22Rlaf8ifO21Kjg4WJZbHYSKwRDtUxBKQrTR4uvUqRN37tzReri7u5fb+zs4OPDNN99w6NAh/vrrLwYMGMCAAQPYtWtXocfNnTuXAQMG6O31iYiIYMyYMURERLxQ3fr168eIESPo1q0bUVFRxMXFMX78eDZv3szu3btf6NwAGRkZOmUKhYKuXbuSnZ1NbGwsy5YtY+nSpXz77beFnuutt94iNzeXyMhITpw4gY+PD2+99RaJieqM/adOnaJLly506tSJP//8k7Vr17Jlyxa+/PJLrfOEhYUxd+7cF742oeIri+9PEagW4BawB8iyskFpaYvSwoZ4mQnXQ3/in1Zh3HJ+Eqg+eAAHDsDDh9rnSMl7FvNThZfN9u2Xad16Cb16bSQnR2TKFARBeFWYm5vj5OSk9ZDL5QDs37+f5s2bY25ujrOzM19++WWhPXv37t0jJCQES0tL3N3di9UzFxAQQPfu3alfvz5169bls88+o3Hjxhw4cKDAY/755x8iIyMJCQnR2bZ//34yMjKYOHEiqampxMbGFuNT0LVu3TpWrVrF6tWr+frrr3njjTdwc3OjW7duREZGEhgY+FznLcru3bs5d+4cK1eupEmTJnTu3JlJkybx008/kZ2drfeY+/fvc/nyZb788ksaN27Ma6+9xtSpU0lPT+fMmTMArF27lsaNG/Ptt9/i4eGBv78/P/zwAz/99BOPHj3SnCskJITjx48THx9fJtcnvNpEoKrHWWAsEJ1foFCAIhdzlRKlqRX3WvZl7IdWnAWOHQNXV2jTBk6f1j6PWENVeBlt3HiOt99eQ2ZmLps2XeCnn44ZukqCIAgVmkqlIicjxyCP0lqX89atW3Tp0oU33niDU6dOsWDBAsLDw/nPf/5T4DFhYWHcvHmTqKgoNmzYwPz587l3716x31OlUrFv3z4uXrxI27ZtC9zvwIEDWFlZUb9+fZ1t4eHhhIaGYmpqSmhoKOHh4cV+/6etWrUKT09PunXrprNNkiTs7OwKPNba2rrQx5AhQwo89tChQ3h7e1O9enVNWXBwMKmpqZw9e1bvMVWqVMHT05Ply5fz+PFjcnNzWbRoEY6Ojrz++usAZGVl6cyJtbS0JDMzkxMnTmjKatWqRfXq1YmJiSmwjoLwvETW32fcAqYACUBN4KpKSf6aNDKVCrOHtzHNvUuC4xtMASrtAD0jMbCwEEvTCC+fFStOERa2GaVS/W+iZ8+GDB36hoFrJQiCULHlZuaypM0Sg7z3gJgBmFqaFnv/rVu3Ym39JA9B586dWb9+PfPnz8fV1ZV58+YhSRJeXl7cvn2bsWPH8u233+oMub106RI7duzg6NGjvPGG+vdIeHi43mDyWQ8fPqRGjRpkZWUhl8uZP38+HTp0KHD/GzduUL16dZ06pKamsmHDBg4dOgRA3759adOmDXPmzNG6xuK4fPkynp6eJTom39PzXPWxtS04OWFiYqJWkApoXucP432WJEns3buXt99+GxsbG2QyGY6OjuzcuZPKldXjAIODg5k9ezarV6+mR48eJCYmMnHiRADu3LmjdT4XFxdu3LhR6DUIwvMQgeoztgFXgQbAs//kVHkBq1ypot4dON8QzOrqnkMmg/ffh/x/xvZlVltBUJPJZHh7e5dpxsqFC4/z8cfbNK/DwpqweHEIcrkYmCEUrjzapyC8CNFGiy8wMJAFCxZoXleqVAmA8+fP4+fnp5Xwp1WrVqSlpfH3339Tq1YtrfOcP38eExMTTQ8egJeXF/b29kXWwcbGhri4ONLS0ti3bx8jR46kTp06BAQE6N0/IyNDb8bc1atXU7duXXx8fABo0qQJtWvXZu3atQwcOLDIejztRXqmPTw8inV+S8vSyQGhUqkYOnQojo6OxMTEYGlpyeLFiwkJCeHYsWM4OzvTsWNHpk+fzpAhQ+jXrx/m5uaMHz+emJgYnX8nlpaWpZIsSqjYyuL7UwSqT0kF9qKeUyrXt0Ped5CkArlMhj1wsT5gDaRBlSqwaRPUrQvOzjA17zAxR1UoD9nZ2WWWun7WrEN88cWTRBBDh77B3LmdkclEmjCheMqyfQpCaTBkGzWxMGFAzACDvXdJVKpUqViBVVmSyWSaOjRp0oTz588zZcqUAgPVqlWrkpycrFMeHh7O2bNnMXkqQaZSqSQiIkITqNra2vLw2SQkQEpKCoBmSG+9evW4cOHCc11PUb23ffv2ZcGCBahUKp3Mv05OThw9elSr7O7du5pt+kRGRrJ161aSk5M1vbXz589nz549LFu2TJMwaeTIkXz++efcuXOHypUrc/36db766ivq1Kmjdb6kpCSqVatW/AsWhGISgepTLgH3gIJy1+X3qEoAMglHIM4G8AROgLk5tG79ZH8xR1UoL0qlkosXL+Lt7a1JalEaVCoVkyb9wXffRWvKxoxpydSpQQWmyReEZ5VV+xSE0mLoNipJUomG3xqj+vXrs3HjRq1g6uDBg9jY2FCzZk2d/b28vMjNzeXEiROaob8XL17UBIAloVQqycrKKnC7r68viYmJJCcna4a2nj59muPHjxMdHY2Dg4Nm36SkJAICArhw4QJeXl54enry999/c/fuXa0htidPnsTCwkLTU9y7d2969erF5s2bdeapqlQqUlNTC5ynWtyhv5mZmTq9qn5+fkyePJl79+7h6OgIwJ49e7C1taVBgwZ6z5ff+/lsD5hMJtPJ3CpJEi4uLoC6B9rV1ZWmTZtqtmdmZhIfH4+vr2+h1yC8/ETW3zKWCeQCBf6qUOXPVZVApt5PKQMKuAGbkvdsX3pVFIRytXjxSa0gdeLEABGkCoIgCDo++eQTbt68yaeffsqFCxfYvHkz3333HSNHjtQ7JNDT05NOnTrx0UcfceTIEU6cOMGgQYOKHN46ZcoU9uzZw9WrVzl//jwzZ85kxYoV9O3bt8BjfH19qVq1KgcPHtSUhYeH07x5c9q2bUujRo00j7Zt2/LGG29okioFBwfj6elJaGgosbGxXL16lQ0bNjBu3Dg+++wzzY2NHj160LNnT0JDQ/n+++85fvw4N27cYOvWrQQFBemsUfo0Dw+PQh/5Aag+HTt2pEGDBvTr149Tp06xa9cuxo0bx9ChQzE3Nwfg6NGjeHl5cevWLUAd3FauXJn+/ftz6tQpLl26xOjRo7l27Rpdu3bVnHv69OmcPn2as2fPMmnSJKZOncrcuXO1buYcPnwYc3Nz/Pz8CvuxCcJzEYHqUyxQdzHnFLjHU4GqpN5PpkQd4eqRkvdsX2o1FITy1atXI1q0qAHAzJkdGT/eXwSpgiAIgo4aNWqwfft2jh49io+PD0OGDGHgwIGMGzeuwGOWLFmCi4sL/v7+vPPOO3z44YeFBmUAjx8/5pNPPqFhw4a0atWKjRs3snLlSgYNGlTgMXK5nAEDBmiWv8nOzmblypW8++67evd/9913Wb58OTk5OZiYmLB7925q1apFaGgojRo14rvvvuOzzz5j0qRJmmMkSeLXX39l1qxZbNq0CX9/fxo3bsyECRPo1q0bwcHBhV7X85LL5WzduhW5XI6fnx99+/bl/fff1yQ+AnUP6sWLF8nJUf+FW7VqVXbu3ElaWhrt2rWjWbNmHDhwgM2bN2vm6wLs2LGDNm3a0KxZM7Zt28bmzZt5++23td5/9erV9OnTBysrqzK5PuHVJqlKKy95BZU/FOPhw4dga8sg4DF5GX/PbSB684coUHdlV63eGJVnf+wyTGlv+T5/t4KLJyHeH0gDFxfIu1kFQEcgCfgVqFfeFya8UhQKBefOnaNBgwalPmwtOTmD3bvj6dmzUameV3h1lGX7FITSUN5tNDMzk2vXruHu7i7mbpeTxMREGjZsyMmTJ6ldu7ahq1NiKpWKjIwMLC0tjeaG8f379/H09OT48eO4uxc0cU54mRT23ZWcnIyDgwMPHz4sNFN1SYge1afYAkGo55Yq9O2gejJHVSFX95i6ngfS9OyK6FEVyo9cLi+VuVU5OQru39fO3Fe5sqUIUoUXUlrtUxDKimijLz8nJyfCw8NJSEgwdFWeiyRJWFlZGU2QCnD9+nXmz58vglQBoEy+P0UypWd0Bf5AnVhJ71xVFYCcS47qpEsm5/SfJw3In1JsX8p1FIRnqVQqHj16hI2NzXP/EsvMzKVHj/Vcu5ZCdHR/qlQRw3iE0lEa7VMQypJoo6+GZ4etViQqlQqlUolMJjOaNtqsWTOaNWtm6GoIRqIsBumKHtVn1AC+AmoBfwMqSUZenl+UKhXZdi6k1qxHrVT1fta6GcuBJ72pVoBZ2VZZEFAqlVy9evW5M649fpzNv/61mv/97xJnztyje/e1ZfKFI7yaXrR9CkJZE21UqAgKy2wsCIYmsv6Wk4bANCAwv0AuB7kJWXITZDnpeEatZ9o+9X4FEUvTCBVFamoWnTqtYs+eqwBUqmTKhAkBRnPHVhAEQRAEQXj1iEC1ADVQz1c1T3+ELCMVWeYjaqQl4/brJzTas4EaBWT6zZeS92xfprUUhBeTlJRB+/bLOXBAPWfH1tac3bv70a6dmG8iCIIgCIIgGI4IVAvRzbMbfRJ8aXjXhIZ35PzbtSfyrDRMVPIiZ/em5D3bl3EdBSFfSTNH3r2bRkDAUo4fvw1AlSqWREX1p2VL17KonvCKE5lNBWMn2qhg7MRIJ+FVI5IpFcJUboqZSo5cpf5isJCZggrkKlkBmZaeSMl7rlymNRQENblcjpeXV7H3//vvVIKClnPx4gMAnJys2bOnH40aFb5+nSA8j5K2T0Eob6KNCsZOkiQsLS0NXQ1BKFBZZP0VPaolkJOjnsQuFz2qgpFRKpU8ePCgWBPZ795No23bJZog1dXVlj/+CBNBqlBmStI+BcEQRBsVjJ1KpSI3N1ckOhSMlkimZADZUi7pJgrSTBRcTLuBQlKJob+C0VGpVNy8ebNYv8CqVatEmzbqxc7r1q1MTMwAXnutSllXUXiFlaR9CoIhiDYqVATZ2dmGroIgFEgsT1OObqXe4ucTPxNZLZ5bNjnctslhZeIurltn85dDMrdktwC4f//JMbKnPs2UvGf78qqwIBSTTCYRHv4vRo9uyR9/DKB2bXtDV0kQBEF4BQQEBDBixIhC93Fzc2P27Nll8v5t27bl119/LZNzv4p27txJkyZNxEgEocyIQFWPs/fOMnbvWJbGLSVHUmCmkDDPlahqYotSUnG6agpjH43leMJZtm17clzTpk/+OyXvWcxRFYxBTo5C67WJiYwffuiAi4uNgWokCIIgVDRhYWFIkqTzuHLlikHqs2bNGiRJ4u233y5y3y1btnD37l169eqls23KlCnI5XKmT5+us23ChAk0adJEp/z69etIkkRcXJymTKVS8fPPP9OiRQusra2xt7enWbNmzJ49m/T09JJcWokkJCTQtWtXrKyscHR0ZPTo0eTm5hZ6zKVLl+jWrRtVq1bF1taW1q1bExUVpbXPvn37aNmyJTY2Njg5OTF27Fit83bq1AlTU1NWrVpVJtclCCJQfcat1FtMOTCFhIcJuNu5IyGRK1ORK1fxWJGJmVJGtXRLEpQJfL5xCmnSLc2xoaFPziPWURXKm42N/qDzjz9u4Ok5j7Nn75VzjQThiYLapyAYC9FGi6dTp07cuXNH6+HuXv5Lml2/fp1Ro0bRpk2bYu0/d+5cBgwYgEym+6dvREQEY8aMISIi4oXq1K9fP0aMGEG3bt2IiooiLi6O8ePHs3nzZnbv3v1C5wb01l2hUNC1a1eys7OJjY1l2bJlLF26lG+//bbQc7311lvk5uYSGRnJiRMn8PHx4a233iIxMRGAU6dO0aVLFzp16sSff/7J2rVr2bJlC19++aXWecLCwpg7d+4LX5sg6CMC1Wdsu7yNq8lXqedQj3vp97hl+ZBHZkoemSm5nq3+x2uCjHpm9Th7+xq8th0AKysICXlynpS8Z/tyrb3wqpLL5dStW1cn49ru3fF06rSSa9dSCApawbVryQWcQRDKTkHtUxCMhcHbqEoFuRmGeZRwXpm5uTlOTk5aj/zPbf/+/TRv3hxzc3OcnZ358ssvC+3Zu3fvHiEhIVhaWuLu7l7snjmFQkGfPn3497//TZ06dYrc/59//iEyMpKQp/9Qy7N//34yMjKYOHEiqampxMbGFqsOz1q3bh2rVq1i9erVfP3117zxxhu4ubnRrVs3IiMjCQwMfK7z5pMkCQsLC50lanbv3s25c+dYuXIlTZo0oXPnzkyaNImffvqpwDmt9+/f5/Lly3z55Zc0btyY1157jalTp5Kens6ZM2cAWLt2LY0bN+bbb7/Fw8MDf39/fvjhB3766ScePXqkOVdISAjHjx8nPj7+ha5PqPjK4vtTLE/zlNSsVPZe3Utli8rIZbofdv53uYQMpUpOSqI91NkDZ3rRrZsNlSqpt+cC+f+E7cuh3oKgVCq5d+8ejo6OmjuumzdfoEePDWRnq4f9NmniRPXq1oaspvCK0tc+BcGYGLyNKjJhb/F6BktdUAyYvPiyJ7du3aJLly6EhYWxfPlyLly4wODBg7GwsGDChAl6jwkLC+P27dtERUVhamrK8OHDuXev6NE/EydOxNHRkYEDBxITE1Pk/gcOHMDKyor69evrbAsPDyc0NBRTU1NCQ0MJDw+nZcuWRZ7zWatWrcLT05Nu3brpbJMkCTs7uwKPtbYu/Hdz3759WbBgAbm5uZiYmGgFq4cOHcLb25vq1atryoKDg/n44485e/Ysvr6+OuerUqUKnp6eLF++nKZNm2Jubs6iRYtwdHTk9ddfByArK0tnbWFLS0syMzM5ceIEAQEBANSqVYvq1asTExND3bp1C70O4eVWFnOVRaD6lEsPLnHv8T3c7QsawqKOVCWVxL1/QJXqCJWvQdWLhIY20+yVmvcsA2zLtMaCoKZSqUhMTKRatWoArFlzhr59f0OhULfZ7t29WL36XczNxT95ofw92z4FwdiINlp8W7du1QqsOnfuzPr165k/fz6urq7MmzcPSZLw8vLi9u3bjB07lm+//VbnBsClS5fYsWMHR48e5Y033gDUQaO+YPJpBw4cIDw8XGtuaFFu3LhB9erVdeqQmprKhg0bOHToEKAOCNu0acOcOXOKDB6fdfnyZTw9PUt0TL6irsXWVv3XZE5ODiYm2r/HExMTtYJUQPM6fxjvsyRJYu/evbz99tvY2Nggk8lwdHRk586dVK6szq4SHBzM7NmzWb16NT169CAxMZGJEycCcOfOHa3zubi4cOPGjeJdrPDSKousv+Kv1qdk5maSq8zFVGaqd3v+xy9D4tYdQGkKslxsKmcSHPxkv/zBlbaIsdVC+YuI+JNBg7ZoRgD06ePN0qVvY2IiWqMgCIJRkluoezYN9d4lEBgYyIIFCzSvK+UNJzt//jx+fn5avX2tWrUiLS2Nv//+m1q1ammd5/z585iYmGh68AC8vLywt7cv8L0fPXpEv379+OWXX6hatWqx65yRkaHTOwiwevVq6tati4+PDwBNmjShdu3arF27loEDBxb7/PBif6R7eHiU6fn1nWvo0KE4OjoSExODpaUlixcvJiQkhGPHjuHs7EzHjh2ZPn06Q4YMoV+/fpibmzN+/HhiYmJ0An5LS8syTRYlvLqM8i/Xn376CTc3NywsLGjRogVHjx4tcN9ffvmFNm3aULlyZSpXrkxQUFCh+xfGwsQCE5kJOcoc/Tvkf0moZNxPAmQ5oDShvb8FZmZPdkvJe7Z/rloIwvP76adjDBz4JEgdPLgpy5aJIFUQBMGoSZJ6+K0hHs/MeSxKpUqV8PDw0DycnZ3L6EPRFR8fz/Xr1wkJCcHExAQTExOWL1/Oli1bMDExKXCeZNWqVUlO1s3REB4eztmzZzXnMjEx4dy5c1pJlWxtbXn48KHOsSkpKQCaIb316tXjwoULz3Vd1tbWhT6GDBlS4LFOTk7cvXtXqyz/tZOTk95jIiMj2bp1K2vWrKFVq1Y0bdqU+fPnY2lpybJlyzT7jRw5kpSUFBISErh//75mWPOz84KTkpLEaAShTBhdj+ratWsZOXIkCxcupEWLFsyePZvg4GAuXryIo6Ojzv7R0dGEhobSsmVLLCwsmDZtGh07duTs2bPUqFGjRO9dr0o9HCs5cu/xPWra1tTZrsr/P6WEUgVY34PHjgzqoz3UIyXv2b5E7y4Iz0+SJNau/ZupU09oykaMaMGsWcE6iRcEobxJkoSDg4Noi4LREm30xdWvX5+NGzeiUqk0n+PBgwexsbGhZk3dv6m8vLzIzc3lxIkTmqG/Fy9e1ASA+nh5eXH69GmtsnHjxvHo0SPmzJmDq6ur3uN8fX1JTEwkOTlZM7T19OnTHD9+nOjoaBwcHDT7JiUlERAQwIULF/Dy8sLT05O///6bu3fvag2xPXnyJBYWFpqe4t69e9OrVy82b96sM09VpVKRmppa4DzV4g791Zesxs/Pj8mTJ2vmWAPs2bMHW1tbGjRooPd8+b2fz/aMymQynXmGkiTh4uICqHugXV1dafrUeoyZmZnEx8frnQsrvFrK4vvT6LpZZs2axeDBgxkwYAANGjRg4cKFWFlZFZgyfNWqVXzyySc0adIELy8vFi9ejFKpZN++fSV+b1tzW4LqBJGcmYxCqdCzR/4cVRkKSQGWKXC1A82baKe0z79nJ9ZQFcqLTCajWrUqmtfjxrURQapgNGQyGbVq1RKJlASjJdroi/vkk0+4efMmn376KRcuXGDz5s189913jBw5Uu/n6unpSadOnfjoo484cuQIJ06cYNCgQVhaFpzYycLCgkaNGmk97O3tsbGxoVGjRpg9PbztKb6+vlStWpWDBw9qysLDw2nevDlt27bVOl/btm154403CA8PB9RzNT09PQkNDSU2NparV6+yYcMGxo0bx2effaYJHnv06EHPnj0JDQ3l+++/5/jx49y4cYOtW7cSFBSks0bp057uodb3cHR0RJIkzM3NdX6vd+zYkQYNGtCvXz9OnTrFrl27GDduHEOHDsXc3ByAo0eP4uXlxa1b6iUV/fz8qFy5Mv379+fUqVNcunSJ0aNHc+3aNbp27ao59/Tp0zl9+jRnz55l0qRJTJ06lblz52oFzIcPH8bc3Bw/P78Cr094NZTF96dR9ahmZ2dz4sQJvvrqK02ZTCYjKChIM9G9KOnp6eTk5GjdHXtaVlYWWVlZmtepqerURwqFAoVCQac6ndh/fT+Xki5hItP/8ahUkF7lEiS7w+UueXefZCgU6uA2SZJAkrADkCRN+dPXBLrZsQoql8vlqFQqveVKpVJn3oK+ckmSNHfK9JU/W8eCymUyGZK4JqO7ppycHN55x5nU1LaYmcn56qs2Ff6aXsaf06t6TUqlktu3b+vtVamo11RY3cU1VbxrUiqV3Lp1ixo1amBqalou16RSqTSP/G365iEWVF4SJT13Ue/57Lb8Xrdt27YxZswYfHx8cHBwYODAgXzzzTda++f/t0qlIiIigsGDB+Pv70/16tWZNGkSN2/e1PpcintNhX2OMpmMAQMGsGrVKs2aoytXrmTMmDF6r+edd95h1qxZTJ48GVNTU3bt2sU333xDaGgo//zzD+7u7gwfPpyRI0dqve+qVav4+eefWbJkCZMnT8bExITXXnuNfv360bFjxxJf07Pl2dnZmJqaaoLV/Pb0v//9j08++QQ/Pz8qVapE//79+fe//6051+PHj7l48SI5OTmoVCqqVKnCjh07GDduHO3atSMnJ4eGDRuyadMmGjdurDlux44dTJ48maysLHx8fNi0aROdO3fWquOvv/5K7969sbS0LJU2ZqjykjC2upfnNT39b/PZ77fClqJ67nqpyiJF03O6ffs2NWrUIDY2VuvOzJgxY9i/fz9Hjhwp8hyffPIJu3bt4uzZs3onzk+YMIF///vfOuUxMTGaDG/3pfssjV9K7I1YElKuo8zrSa0kM0OWmUvVDHtSEjqTdOAr+KchFy4k4enpwIULF8jMzGR5tWrsrFyZgZLEF5aWnD59WusXp6enJ2ZmZjrDV7y9vcnOzubixYuaMrlcjre3N6mpqVy9elVTbmFhgZeXFw8ePODmzZuachsbG+rWrUtiYqJWtjcHBwdq1apFQkICSUlJmvL8NdDi4+O11sVydXWlSpUqmmvKV6dOHWxtbcU1Gdk1nTt3jjt37miGrr0M1/Qy/pxe1WtSqVQoFAoaN27MuXPnXoprgpfv5/QqX5NKpSIpKYmqVavi4+NT5td06dIlMjIyqFWrFubm5piZmWFiYkJGRobWH37m5ubI5XKdRDX562lmZGRolecHC09/LgBWVlYoFAqtG/WSJGFpaUlubq7WepsymQwLCwtycnLIyXmSs0Mul2Nubk5WVpbW52tqaoqpqSmZmZlawb2xXVNKSgoNGzbk4MGDmuG6FemacnJyyMjI0GT9NYaf0/379/H19SUmJob69euLtvcKXFNWVhY3b96kXr16pKSkaH3vmZiY4O3tzcOHDzXD1V/USxWoTp06lR9++IHo6GgaN26sdx99Paqurq4kJSVpPlRJkriTdoeJ+ycSfvwXlJL6IzKXTLDIVBFyuSkndv/OuUfqObCJiUqqV39yd3e8JLFbkhgB9BV3rMU1lcE15eYq+fjjbXTr5kW3bl5kZ2dz9uxZGjZsiFwur5DXVFS5uKaKe00KhYKzZ8/i7e2tM2ytol5TYXUX11Txrim/jTZs2BAzM7Myv6bHjx9z48YN3N3dNTfVjaG3xNDlJfE87/n7779TpUoV2rRpU6z9jemalEolmZmZmgCkPOpe1DUdP36c+Ph4evbs+VzXZEzlJWFsdS/Pa8rMzOTatWvUqVNH812ZLyUlhapVq5ZqoGpUQ3+rVq2KXC7Xm72soMxl+WbMmMHUqVPZu3dvgUEqqO885I/Zf5pcLtcac1/DtgYd6nZg5dElZEnqOyAOciscU3No93cDTjx6kqgp/5dd/vH5ueHyBx/rm/xe0nJJkvSWFzQevKTlpVHHkpaLa3q+a8rOVtCnz+9s3HieX389w9atvQkMrK1576ffv6JcU3mXi2sq/2uSJKnAOhZ0HmO/pucpF9dkvNf09HWUxzXl/5t4+ubNszdyiioviZKe21DlJVHSc3fv3r1UzmPIa3rRNlOa1/TGG29oEmEVxtjamPj3pF9xzv10+3v2+62g77sXYVRZA8zMzHj99de1EiEplerESIVN0v7hhx+YNGkSO3fupFmzZqVeLynvf2aSHLlSQqYyobBR2Cl5z/alXhPhVZeRkUP37mvZuPE8oJ4vnZaWjSRJODk5lcoXlSCUNtE+BWMn2qhQEZiamhq6CoJQoLL4/jSqHlVQr9nUv39/mjVrRvPmzZk9ezaPHz9mwIABALz//vvUqFGDKVOmADBt2jS+/fZbfv31V9zc3DRjpfPXnipN+d3bcpUJBay0CohAVSgbaWnZ/Otfq4mKug6AhYUJmzb1JDhYvVB4UaMOBMFQZDKZaJ+CURNtVDB2kiSJQFUwai99jypAz549mTFjBt9++y1NmjQhLi6OnTt3atauSkhI4M6dO5r9FyxYQHZ2Nu+99x7Ozs6ax4wZM0q9bqq8pErZj021elSfvYGQkvdsX+o1EF5VKSmZdOy4QhOkWlubsXNnH02QqlAoiI+P15mbJQjGQLRPwdiJNioYu/wEOEaUWkYQtJTF96fR9agCDBs2jGHDhundFh0drfX6+vXrZV+hPAqlCqUSVDlPhv56eECVJ8tXkgHkp2qyL7eaCS+z+/fT6dhxBX/+qR4tYG9vwc6dfWjRQnupj6ezYgqCsRHtUzB2oo0Kxu7ZBF+C8LIzykDVWATXDebd296csDwHKqj0oBa5dleRKdU9qi4u8L//afeopuQ9mwEFL1ktCMVz584jgoJWcO7cPwBUq2bFnj398PERQ9QEQRAEQRCEl5fRDf01JjbmNtjmWmCukGGukKFKV2cAlKtMcHaFmBjw8tI+JiXv2R4QKRmEF3X+/H0uX34AgIuLDfv3h4kgVRAEQRAEQXjpiUC1BCSZeuy1TGnGtFlQp47uPil5z/blVSnhpdaunTvr1v0fHh4OxMQMoH79anr3kyQJV1dXkbFSMEqifQrGTrRRoSIwMzMzdBUEoUBl8f0pAtWS0ASqJpgWMK43Oe/ZvlwqJLwK3n7bi7NnP6FOncoF7iOTyahSpUqZZFwThBcl2qdg7EQbNZzo6GgkSSIlJaXYx0yYMIEmTZqUWZ2eFRAQwIgRI174PNnZ2Xh4eBAbG1viYyVJwsTERNxMecaXX37Jp59+auhqCLwiWX+NmqSexC5TmWLjoH+XlLxn+/Koj/DSOXnyDnPmHNYpNzPTv1B9PoVCwYULF0TGSsEoifYpGDvRRou2cOFCbGxsyM19su5BWloapqamBAQEaO2bH3zGx8cXed6WLVty584d7OzsSrW+pRVc6vPbb7/RsWNHqlSpgiRJxMXFFeu4hQsX4u7uTsuWLXW2ffTRR8jlctavX6+zLSwsjLfffpuMjAytrL/6gvzs7Gx++OEHfHx8sLKyomrVqrRq1YolS5aQk1PY4oov5q+//qJNmzZYWFjg6urKDz/8UOxjHzx4QM2aNfXesFi1apXmWpydnfnggw948OCBZvuoUaNYtmwZV69eLa1LEZ5TWXx/ikC1BFR5PaomSjOaNNW/T0res315VEh4qRw6dJN27ZYxYsQu5s49UuLjMzMzy6BWglA6RPsUjJ1oo4ULDAwkLS2N48ePa8piYmJwcnLiyJEjWp9fVFQUtWrVom7dukWe18zMDCcnpwrVU/j48WNat27NtGnTin2MSqVi3rx5DBw4UGdbeno6a9asYcyYMURERBR6jsJkZ2cTHBzM1KlT+fDDD4mNjeXo0aMMHTqUH3/8kbNnzxa7viWRmppKx44dqV27NidOnGD69OlMmDCBn3/+uVjHDxw4kMaNG+uUHzx4kPfff5+BAwdy9uxZ1q9fz9GjRxk8eLBmn6pVqxIcHMyCBQtK7XoE4yEC1UIkZyTzwPQxGSZKMkyUZFqov4QtzMwwM9d/TErec8GDNAVBV1TUNTp0WMHDh+rFjTZsOEdurkhDLwiC8CpQoV7ezhCP4q7K6enpibOzs9YygdHR0XTr1g13d3cOHz6sVR4YGAiol1SZMmUK7u7uWFpa4uPjw4YNG7T2fbYn7ZdffsHV1RUrKyu6d+/OrFmzsLe316nTihUrcHNzw87Ojl69emmWGAoLC2P//v3MmTMHSZKQJEmznOGZM2fo3Lkz1tbWVK9enX79+nH//n3NOR8/fsz777+PtbU1zs7OzJw5U+d9+/Xrx7fffktQUFAxPz04ceIE8fHxdO3aVWfb+vXradCgAV9++SV//PEHN2/eLPZ5nzZ79mz++OMP9u3bx9ChQ2nSpAl16tShd+/eHDlyhNdee+25zluUVatWkZ2dTUREBA0bNqRXr14MHz6cWbNmFXnsggULSElJYdSoUTrbDh06hJubG8OHD8fd3Z3WrVvz0UcfcfToUa39QkJCWLNmTaldj2A8RKBaiH3X9rHF+RxXKmdxxSGLBCf1F5mVlWmBx6TkPduXee2El8WOHZfp0uVXHj9WD8kJCqrDjh19MDER/zwFQRBeBZlAGwM9StKPHBgYSFRUlOZ1VFQUAQEB+Pv7a8ozMjI4cuSIJlCdMmUKy5cvZ+HChZw9e5bPP/+cvn37sn//fr3vcfDgQYYMGcJnn31GXFwcHTp0YPLkyTr7xcfHs2nTJrZu3crWrVvZv38/U6dOBWDOnDn4+fkxePBg7ty5w507d3B1dSUlJYV27drh6+vL8ePH2blzJ3fv3qVHjx6a844ePZr9+/ezefNmdu/eTXR0NCdPnizBp6RfTEwM9erVw8bGRmdbeHg4ffv2xc7Ojs6dO7N06dLneo9Vq1YRFBSEr6+vzjZTU1MqVaqk97iEhASsra0LfXz//fcFvu+hQ4do27atVrKn4OBgLl68SHJycoHHnTt3jokTJ7J8+XK98xv9/Py4efMm27dvR6VScffuXTZs2ECXLl209mvevDl///235maE8PIQ66iWgEpS33e0riQCVaF0/PbbeXr12kBOjrr3NCSkHuvW/R8WFiX7pymTyahTp45IBCIYJdE+BWMn2mjxBAYGMmLECHJzc8nIyODPP//E39+fnJwcFi5cCKiDlqysLAIDA8nKyuL7779n7969+Pn5AVCnTh0OHDjAokWL8Pf313mPH3/8kc6dO2t62OrVq0dsbCxbt27V2k+pVLJ06VJN4NevXz/27dvH5MmTsbOzw8zMDCsrK5ycnizpNm/ePHx9fbWCroiICFxdXbl06RIuLi6Eh4ezcuVK2rdvD8CyZcuoWbPmC392N27cwMXFRaf88uXLHD58mN9++w2Avn37MnLkSMaNG6czHNrcvIDhfE+d69n5wsXh4uJS5DxbB4cCkrMAiYmJuLu7a5VVr15ds61yZd1xhllZWYSGhjJ9+nRq1aqld45pq1atWLVqFT179iQzM5Pc3FxCQkL46aefdOoP6s/Yzc2t0OsQyk5ZfH+KQPU5WFsWnB48Je/ZvjwqIlRoK1f+RVjYJhQK9Q2QHj0asnJld0xNC0+cpI8kSdja2pZ2FQWhVIj2KRg7Q7dRCyDGgO9dXAEBATx+/Jhjx46RnJxMvXr1qFatGv7+/gwYMIDMzEyio6OpU6cOtWrV4uzZs6Snp9OhQwet82RnZ+vt9QO4ePEi3bt31ypr3ry5TqDq5uam1Tvp7OzMvXv3Cq3/qVOniIqKwtraWmdbfHw8GRkZZGdn06JFC025g4MDnp6ehZ63ODIyMrCw0P20IyIiCA4OpmrVqgB06dKFgQMHEhkZqQmW88nlhf99UNQc1oKYmJjg4eHxXMc+r6+++or69evTt2/fAvc5d+4cn332Gd9++y3BwcHcuXOH0aNHM2TIEMLDwzX7WVqql+JIT08v83oLBSuLeeYiUC0JSYUEmMgL7lHNH+Ag5qgKhfn55xMMGbKV/N8pYWFNWLw4BLn8+e5GKRQKzp07R4MGDYr8RSYI5U20T8HYGbqNSkABq94ZFQ8PD2rWrElUVBTJycmaHlEXFxdcXV2JjY0lKiqKdu3aAeqswADbtm2jRo0aWucqqnewKKam2n+LSZKEUll4boe0tDRCQkL0JkFydnbmypUrL1SnwlStWpXTp09rlSkUCpYtW0ZiYiImJiZa5REREZpA1dbWlhs3bpCeno6lpaUmIEhJSUEul2uG9NarV48LFy6UuG4JCQk0aNCg0H2+/vprvv76a73bnJycuHv3rlZZ/uune7SfFhkZyenTpzXzlfOD7KpVq/LNN9/w73//mylTptCqVStGjx4NQOPGjalUqRJt2rThP//5D87OzgAkJSUBUK2a/rXmhfJRFll/RaBaAipUIIFcrr9HVQk8zPtv+/KqlFDhPHyYyXffRWuC1E8+acaPP3ZBJnuxO1FiWQXBmIn2KRg70UaLJzAwkOjoaJKTkzUBBEDbtm3ZsWMHR48e5eOPPwagQYMGmJubk5CQoHeYrz6enp4cO3ZMq+zZ18VhZmam8zNt2rQpGzduxM3NTSswzFe3bl1MTU05cuQItWrVAiA5OZlLly4Vu/4F8fX1ZcGCBahUKk2guX37dh49esSff/6pdYPkzJkzDBgwgJSUFOzt7fH09GTNmjVkZWVpeg8BTp48ibu7uyZo7927N19//TV//vmnTo91Tk4O2dnZeuepvujQXz8/P7755htycnI0ddmzZw+enp56h/0CbNy4kYyMDM3rY8eO8cEHHxATE6PJFp2enq7zc8r/nJ7uPT5z5gympqY0bNiw0GsQKh4xGaMoT4+ikCi0RzUNdbAKULqrgQkvEzs7C3bv7kvlyhaMHt2SefNePEgVBEEQhPIQGBjIgQMHiIuL0wre/P39WbRoEdnZ2ZpESjY2NowaNYrPP/+cZcuWER8fz8mTJ/nxxx9ZtmyZ3vN/+umnbN++nVmzZnH58mUWLVrEjh07Sjys0M3NjSNHjnD9+nXu37+PUqlk6NChJCUlERoayrFjx4iPj2fXrl0MGDAAhUKBtbU1AwcOZPTo0URGRnLmzBnCwsJ05t4lJSURFxfHuXPnAPVw5bi4OBITEwv93NLS0rSWiAkPD6dr1674+PjQqFEjzaNHjx7Y29uzatUqAPr06YMkSQwePJgTJ05w5coVIiIimD17Nl988YXmfCNGjKBVq1a0b9+en376iVOnTnH16lXWrVvHm2++yeXLl/XWLX/ob2GPwgLV3r17Y2ZmpllGZu3atcyZM4eRI0dq9vn999/x8vLSvK5bt67WNefPca1fvz6Ojo6AOpvvb7/9xoIFC7h69SoHDx5k+PDhNG/eXGu+b0xMDG3atNEK4oWXgwhUi6B69pUEJib6h6uk5D1XAgoeHCwI4O1dndOnP2batKAKtXacIAiC8GoLDAwkIyMDDw8PTcIcUAeqjx490ixjk2/SpEmMHz+eKVOmUL9+fTp16sS2bdt0ku/ka9WqFQsXLmTWrFn4+Piwc+dOPv/8c73zOwszatQo5HI5DRo0oFq1aiQkJODi4sLBgwdRKBR07NgRb29vRowYgb29vSYYnT59Om3atCEkJISgoCBat27N66+/rnXuLVu24Ovrq1lqplevXvj6+moSSulTpUoVunfvrgk+7969y7Zt23j33Xd19pXJZHTv3l0zD9Pe3p4//viDnJwcunXrRpMmTZg7dy6zZs3io48+0hxnbm7Onj17GDNmDIsWLeLNN9/kjTfeYO7cuQwfPpxGjRqV6DMsLjs7O3bv3s21a9d4/fXX+eKLL/j222/58MMPNfs8fPiQixcvlui8YWFhzJo1i3nz5tGoUSP+7//+D09PT03iqXxr1qzRWltVeHlIquedef2SSE1Nxc7OjocPH+okUlh/dgP9V/cmR5YLgGWunHrJZmxL3EH139vqnOsUMBCoCWwq85oLFYVSqWLlyr/o08f7ueegFkWlUpGZmYmFhYUIfAWjI9qnYOzKu41mZmZy7do13N3dSxyAvYoGDx7MhQsXiIkxVMqp0vHXX3/RoUMH4uPj9SZ0KoxKpdIMGxbfo0/s2LGDL774gr/++kvvcG6hdBX23fXw4UPs7e31xlTPS/SoFuLZ6Sr5y9MU1aNqX2Y1EioahULJ4MFb6N9/Ex9++D+UyrK7L/T0+mWCYGxE+xSMnWijxmPGjBmcOnWKK1euaIYJ9+/f39DVemGNGzdm2rRpXLt27bmOFwGqrsePH7NkyRIRpL6kRKD6HOQm+n+ZpeQ925dXRQSjlpOjoG/f34mIiANg6dJTHDt2q0zeS6lUcvr06SIzHgqCIYj2KRg70UaNy9GjR+nQoQPe3t4sXLiQuXPnMmjQIENXq1SEhYXh7e39XMc+nXxIUHvvvfe0lhMSDKcsvj/F7YeSyOsMk5uKQFUoXFZWLj17bmDzZvV8DBMTGatXv0uLFi++aLggCIIgvMzWrVtn6CoIgmAERKD6HAoKVMUaqgJAenoO3buvZffueADMzeVs3NiDrl3rGbhmgiAIgiAIglAxiED1OYg5qkJBUlOzeOutX4mJSQDAysqULVt60b59HQPXTBAEQRAEQRAqDhGoloCUN/bXxFQEqoKupKQMOndexdGj6nmotrbmbN/em1atapX5e8tkMry9vXXWehMEYyDap2DsRBsVKgKxTqhgzMri+1N8Iz8HyUz/Kqkpec/25VURwaiMGLFTE6Q6OFgSGfl+uQSp+bKzs8vtvQShpET7FIydaKOCsXvFV5QUXkEiUC1EQO1AAq/Vp26SOXWTzKnxyAwTpYRkrr8jWsxRfbXNmhVMgwbVqF69Evv3h/H66y7l9t5KpZKLFy+KjJWCURLtUzB2oo0KFUFmZqahqyAIBRJZf8tZFasqVMmw5o6NOp5XyUCuBEz1f2wpec/25VE5wehUrWrF3r39SEvL5rXXqhi6OoIgCIIgCIJQYYke1RKSqyTQ06OaAzzO+2/78qyQYDCXLz/g4UPtu5vOzjYiSBUEQRCEYoqOjkaSJFJSUop9zIQJE2jSpEmZ1elZAQEBjBgx4oXP8+DBAxwdHbl+/foLn0tQe/PNN9m4caOhqyGUERGolpCJUgIzuU75w7xnGWBdrjUSDOGvv+7SuvUSunT5lbQ045jXJJfrtktBMBaifQrGTrTRwi1cuBAbGxtyc3M1ZWlpaZiamhIQEKC1b37wGR8fX+R5W7ZsyZ07d7CzsyvV+pZWcPmsnJwcxo4di7e3N5UqVcLFxYX333+f27dvF3ns5MmT6datG25ubjrbgoODkcvlHDt2TGdbQdeydOlS7O3ttcpSU1P55ptv8PLywsLCAicnJ4KCgvjtt9/KdI5rdHQ0TZs2xdzcHA8PD5YuXVrsY69cuYKNjY3OtSxduhRJkrQeFhYWWvuMGzeOL7/8Ugzbf0mJQLWETJSAme7Hlj8/1R7xob7sjh27RUDAUu7de0xs7E2+/HKvoauEXC7H29tb/KElGCXRPgVjJ9po0QIDA0lLS+P48eOaspiYGJycnDhy5IjW/MmoqChq1apF3bp1izyvmZkZTk5OSJJUJvUubenp6Zw8eZLx48dz8uRJfvvtNy5evMi//vWvIo8LDw9n4MCBOtsSEhKIjY1l2LBhRERE6D1ekiSsrKwK/ZxSUlJo2bIly5cv56uvvuLkyZP88ccf9OzZkzFjxvDw4cMCj30R165do2vXrgQGBhIXF8eIESMYNGgQu3btKvLYnJwcQkNDadOmjd7ttra23LlzR/O4ceOG1vbOnTvz6NEjduzYUSrXIjy/svj+FDFVCUgqkKtkYKr7JZGS92xfnhUSyt2BAwm0b7+c5GT1L+QWLWowaVKggWulzgSYmpoqMgIKRkm0T8HYGbyNqoAMAz2Kecmenp44OzsTHR2tKYuOjqZbt264u7tz+PBhrfLAQPXvRqVSyZQpU3B3d8fS0hIfHx82bNigte+zQ39/+eUXXF1dsbKyonv37syaNUuntw1gxYoVuLm5YWdnR69evXj06BEAYWFh7N+/nzlz5mh64vKH2545c4bOnTtjbW1N9erV6devH/fv39ec8/Hjx7z//vtYW1vj7OzMzJkztd7Tzs6OPXv20KNHDzw9PXnzzTeZN28eJ06cICEhocDPb/v27Zibm/Pmm2/qbFuyZAlvvfUWH3/8MatXryYjI0NnH5VKhUKhKLSNfv3111y/fp0jR47Qv39/GjRoQL169Rg8eDBxcXFYW5fNmL+FCxfi7u7OzJkzqV+/PsOGDeO9997jv//9b5HHjhs3Di8vL3r06KF3uyRJODk5aR7Vq1fX2i6Xy+nSpQtr1qwplWsRnl9ZfH+KQLUQ6TnppJtkkyNTqR+SSh2o6smllJL3bF+O9RPK15498XTsuIJHj9RDff39a7NnTz8qVzb8umZKpZKrV6+KoS+CURLtUzB2Bm+jmUAbAz1KkEg2MDCQqKgozeuoqCgCAgLw9/fXlGdkZHDkyBFNoDplyhSWL1/OwoULOXv2LJ9//jl9+/Zl//79et/j4MGDDBkyhM8++4y4uDg6dOjA5MmTdfaLj49n06ZNbN26la1bt7J//36mTp0KwJw5c/Dz82Pw4MGanjhXV1dSUlJo164dvr6+HD9+nJ07d3L37l2tIGn06NHs37+fzZs3s3v3bqKjozl58mShn8vDhw+RJElvMJ0vJiaG119/XadcpVKxZMkS+vbti5eXFx4eHlqB/NOysrIKPL9SqWTNmjX06dMHFxfdVQesra0xMdGfDDQmJgZra+tCH6tWrSrwvQ8dOkRQUJBWWXBwMIcOHSrwGIDIyEjWr1/PTz/9VOA+aWlp1K5dG1dXV7p168bZs2d19mnevDkxMTGFvpdQ9kTW33K248p2ttc7RY5MPR/DMleibqqVCFRfQf/730Xee2892dkKAIKD6/Lbbz2xstK/pq4gCIIgvGwCAwMZMWIEubm5ZGRk8Oeff+Lv709OTg4LFy4E1EFLVlYWgYGBZGVl8f3337N37178/PwAqFOnDgcOHGDRokX4+/vrvMePP/5I586dGTVqFAD16tUjNjaWrVu3au2nVCpZunQpNjY2APTr1499+/YxefJk7OzsMDMzw8rKCicnJ80x8+bNw9fXl++//15TFhERgaurK5cuXcLFxYXw8HBWrlxJ+/btAVi2bBk1a9Ys8DPJzMxk7NixhIaGYmtrW+B+N27c0BtA7t27l/T0dIKDgwHo27cv4eHh9OvXr8Bz6XP//n2Sk5Px8vIq0XEAzZo1Iy4urtB9nu3JfFpiYqLO9urVq5OamkpGRgaWlro39B88eEBYWBgrV64s8HPz9PQkIiKCxo0b8/DhQ2bMmEHLli05e/as1s/ExcWFmzdvolQqkclEH9zLRASqJaQe+qtb/vQcVeHlsnbtGfr2/Z3cXPWdorff9mLNmncxL2A9XUEQBEEoEQvAUB1CFkXvki8gIIDHjx9z7NgxkpOTqVevHtWqVcPf358BAwaQmZlJdHQ0derUoVatWpw9e5b09HQ6dOigdZ7s7Gx8fX31vsfFixfp3r27Vlnz5s11AlU3NzdNkArg7OzMvXv3Cq3/qVOniIqK0jsENj4+noyMDLKzs2nRooWm3MHBAU9PT73ny8nJoUePHqhUKhYsWFDoe2dkZOgkAgJ1oNyzZ09Nb2doaCijR48mPj6+WHN8873IsEtLS0s8PDye+/jnMXjwYHr37k3btm0L3MfPz09zgwPUibfq16/PokWLmDRpkqbc0tISpVJJVlaW3qBYqLjEX9olJIb+vloiI6/Ru/dvKJXqXwC9e3uzdGk3TE2NL+GGvl+AgmAsRPsUjJ1B26gEVIC/rz08PKhZsyZRUVEkJydrekRdXFxwdXUlNjaWqKgo2rVrB6iHbQJs27aNGjVqaJ3L3Nz8hepiaqrdayBJUpFDD9PS0ggJCWHatGk625ydnbly5Uqx3z8/SL1x4waRkZGF9qYCVK1aleTkZK2ypKQkfv/9d3JycrQCXYVCQUREhGbIs62tLampqTqJlFJSUjTZkqtVq4a9vT0XLlwo9jXki4mJoXPnzoXus2jRIvr06aN3m5OTE3fv3tUqu3v3Lra2tgUGjpGRkWzZsoUZM2YA6kBbqVRiYmLCzz//zAcffKBzjKmpKb6+vjo/p6SkJCpVqiSC1JeQCFRLyKSAHtWUvGf7cqyLUPZat65Fly6vsXXrJQYN8mXhwreQy41vWIlcLn+u4T6CUB5E+xSMnWijxRcYGEh0dDTJycmMHj1aU962bVt27NjB0aNH+fjjjwFo0KAB5ubmJCQk6B3mq4+np6fOEi36lmwpipmZGQqFQqusadOmbNy4ETc3N73zNevWrYupqSlHjhyhVq1aACQnJ3Pp0iWt+ucHqZcvXyYqKooqVYpeP93X15eVK1dqla1atYqaNWuyadMmrfLdu3czc+ZMJk6ciFwux9PTk927d+sEYidPnqRevXoAyGQyevXqxYoVK/juu+90hhmnpaVhYWGh97pfdOivn58f27dv1yrbs2ePVm/osw4dOqT189m8eTPTpk0jNjZW56ZGPoVCwenTp+nSpYtW+ZkzZwrsoRfKT1lk/RWBagmZKAsPVCuXZ2WEMmdmJmf9+v9jyZI/GTKkmdGmz1cqlSQnJ1O5cmUxP0MwOqJ9CsZOtNHiCwwMZOjQoeTk5GgFb/7+/gwbNozs7GxNIiUbGxtGjRrF559/jlKppHXr1jx8+JCDBw9ia2tL//79dc7/6aef0rZtW2bNmkVISAiRkZHs2LGjxL9/3dzcOHLkCNevX8fa2hoHBweGDh3KL7/8QmhoKGPGjMHBwYErV66wZs0aFi9ejLW1NQMHDmT06NFUqVIFR0dHvvnmG602kZOTw3vvvcfJkyfZunUrCoWCxMREQD1M2MzMTG99goOD+eqrrzTtDCA8PJz33nuPRo0aae3r6urKV199xc6dO+natSsff/wx8+bNY9iwYQwePBgLCwu2bdvG6tWr+d///qc5bvLkyURHR9OiRQsmT55Ms2bNMDU1JSYmhilTpnDs2DG9CZ9edOjvkCFDmDdvHmPGjOGDDz4gMjKSdevWsW3bNs0+8+bN4/fff2ffvn0A1K9fX+scx48fRyaTaX0WEydO5M0338TDw4OUlBSmT5/OjRs3GDRokNaxMTExdOzY8bnrL5SOskimJL6NS0iukouhvy8xlUrF/fvpWmUWFiZ8/PEbRhukgrreN2/eFMt/CEZJtE/B2Ik2WnyBgYFkZGTg4eGh1cvm7+/Po0ePNMvY5Js0aRLjx49nypQp1K9fn06dOrFt2zbc3d31nr9Vq1YsXLiQWbNm4ePjw86dO/n8889LPDR71KhRyOVyGjRoQLVq1UhISMDFxYWDBw+iUCjo2LEj3t7ejBgxAnt7e00wOn36dNq0aUNISAhBQUG0bt1aK1vvrVu32LJlC3///TdNmjTB2dlZ84iNjS2wPt7e3jRt2pR169YBcOLECU6dOsW7776rs6+dnR3t27cnPDwcUCeg2r9/P+fPn6dDhw60aNGCdevWsX79ejp16qQ5zsHBgcOHD9O3b1/+85//4OvrS5s2bVi9ejXTp0/XDBMube7u7mzbto09e/bg4+PDzJkzWbx4sSZBFKiTPcXHx5fovMnJyQwePJj69evTpUsXUlNTiY2NpUGDBpp9bt26RWxsLAMGDCi16xGeT1l8f0qqV/xbOTU1FTs7Ox4+fKgzv2DNXxv4YF1vray/PS7XYvHga/DMjZsuwD1gBaB9j0ioKFQqFaNH72HdurPExAygdm17Q1ep2PKHw4gF6wVjJNqnYOzKu41mZmZy7do13N3dxfztYhg8eDAXLlyo8EuQbNu2jdGjR3PmzJkS99yrVCpNBl1jvnFe3saOHUtycjI///yzoavySijsuys5ORkHBwe9MdXzEkN/S8hET4+qCtGjWtEplSqGDt3GwoUnAAgKWsFffw3B0lIsPyMIgiAI5WnGjBl06NCBSpUqsWPHDpYtW8b8+fMNXa0X1rVrVy5fvsytW7dwdXU1dHVeCo6OjowcOdLQ1RDKiAhUS0hf1t8MIDvvv8Uc1YonN1fJwIFbWL78FACSBGPHtqpwQerTafoFwdiI9ikYO9FGjcfRo0f54YcfePToEXXq1GHu3Lk68xIrqhEjRjz3sWL+tK4vvvjC0FUQypAIVEtIrtQNVFPyns0p0XJkghHIzlbQt+9vrF9/DgC5XGLZsrfp06exgWtWMnK5vETrrQlCeRLtUzB2oo0al/x5nMITkiSJYeKCUSuLaRPi1kwJmahMdLL+puQ925dzXYQXk5mZyzvvrNUEqaamMtav/78KF6SCOtNaYmJimWRcE4QXJdqnYOxEGxWMnUqlIicnRyT8EoyWyPprBPTNUU3Je7Yv57oIzy8tLZuuXX9l27bLgDqz75YtoXTvXjFTYalUKhITE8UvMMEoifYpGDvRRoWKICcnx9BVEIQClcX3pxj6W0JylVynRzU571nMT60YsrJyCQ5eSWzsTQCsrc3YujUUf383w1ZMEARBEARBEARA9KiWmL5ANSXv2b6c6yI8H3NzE/z9awNgb2/Bnj39RJAqCIIgCIIgCEZE9KiWkBj6+3KYPLkdcrnEu+82oEkTJ0NX54VJkoSDg4NYW00wSqJ9CsZOtFGhIhDrUAvGrCy+P0WgWgi/mi1pmfAa1+3jAZCrRI9qRaVQKJHLnwwgkCSJSZPaGbBGpUsmk1GrVi1DV0MQ9BLtUzB2oo0Kxk6SJMzNzQ1dDUEoUFksnySG/hbCxcYFlzR7bLPl2GbLsc6RI1eZ6IT3Yo6qcbtyJQlv7wXExNwwdFXKjFKpJCEhQWSsFIySaJ+CsRNt1HCio6ORJImUlJRiHzNhwgSaNGlSZnV6VkBAwAutf5rvwYMHODo6cv369RIfq1KpyMrKEgm/ntGrVy9mzpxp6GoIiKy/RkEM/a1Yzp37h7Ztl3D+/H26dv2VEyduG7pKZUKlUpGUlCR+gQlGSbRPwdiJNlq0hQsXYmNjQ25urqYsLS0NU1NTAgICtPbNDz7j4+OLPG/Lli25c+cOdnZ2pVrf0gou9ZkwYQJeXl5UqlSJypUrExQUxJEjR4o8bvLkyXTr1g03NzedbcHBwcjlco4dO6azLf9aFAqFVvnSpUuxt7fXKktNTeWbb77By8sLCwsLnJycCAoK4rfffivT9h0dHU3Tpk0xNzfHw8ODpUuXFvvYK1euYGNjo3MtACkpKQwdOhRnZ2fMzc2pV68e27dv12wfN24ckydP5uHDh6VwFcKLKIv2JQLVEjJR6vaopuQ925dzXYTCxcUl4u+/lDt30gCoXdueGjVsDVwrQRAEQah4AgMDSUtL4/jx45qymJgYnJycOHLkCJmZmZryqKgoatWqRd26dYs8r5mZGU5OThVqfnC9evWYN28ep0+f5sCBA7i5udGxY0f++eefAo9JT08nPDycgQMH6mxLSEggNjaWYcOGERER8dz1SklJoWXLlixfvpyvvvqKkydP8scff9CzZ0/GjBlTZsHctWvX6Nq1K4GBgcTFxTFixAgGDRrErl27ijw2JyeH0NBQ2rRpo7MtOzubDh06cP36dTZs2MDFixf55ZdfqFGjhmafRo0aUbduXVauXFmq1yQYBxGollBhc1TF0F/jcfjw3wQGLuP+/XQAXn/dmejo/jg5WRu4ZoIgCILwDJUKMjIM8yhmL4inpyfOzs5ER0dryqKjo+nWrRvu7u4cPnxYqzwwMBBQDwecMmUK7u7uWFpa4uPjw4YNG7T2fXbo7y+//IKrqytWVlZ0796dWbNm6e1tW7FiBW5ubtjZ2dGrVy8ePXoEQFhYGPv372fOnDlIkoQkSZrhtmfOnKFz585YW1tTvXp1+vXrx/379zXnfPz4Me+//z7W1tY4OzvrHVbau3dvgoKCqFOnDg0bNmTWrFmkpqby119/Ffj5bd++HXNzc958802dbUuWLOGtt97i448/ZvXq1WRkZBR4nsJ8/fXXXL9+nSNHjtC/f38aNGhAvXr1GDx4MHFxcVhbl83fQAsXLsTd3Z2ZM2dSv359hg0bxnvvvcd///vfIo8dN24cXl5e9OjRQ2dbREQESUlJbNq0iVatWuHm5oa/vz8+Pj5a+4WEhLBmzZpSux7BeIhkSiUkR7tHVQnk35+yN0B9BF3R0dcJCVlNWlo2AC1burJ9e2/s7CwMXLOyI0lShbsjLbw6RPsUjJ3B22hmJujpUSoXMTFgaVmsXQMDA4mKiuLLL78E1D2nY8aMQaFQEBUVRUBAABkZGRw5coQPPvgAgClTprBy5UoWLlzIa6+9xh9//EHfvn2pVq0a/v7+Ou9x8OBBhgwZwrRp0/jXv/7F3r17GT9+vM5+8fHxbNq0ia1bt5KcnEyPHj2YOnUqkydPZs6cOVy6dIlGjRoxceJEAKpVq0ZKSgrt2rVj0KBB/Pe//yUjI4OxY8fSo0cPIiMjARg9ejT79+9n8+bNODo68vXXX3Py5MkC58RmZ2fz888/Y2dnpxNAaX/MMbz++us65SqViiVLlvDTTz/h5eWFh4cHGzZsoF+/fjr7mpqa6pTlUyqVrFmzhj59+uDi4qKzvbAgNSYmhs6dOxe4HWDRokX06dNH77ZDhw4RFBSkVRYcHFzk0OvIyEjWr19PXFwcv/32m872LVu24Ofnx9ChQ9m8eTPVqlWjd+/ejB07VisDcvPmzZk8eTJZWVki4ZQBiay/5UyhVKCQlChR322UASYqU60e1VQg/16kGFRqeDt3XqF797VkZqrn0LRv787mzb2oVMnMwDUrWzKZDCenir/MjvByEu1TMHaijRZPYGAgI0aMIDc3l4yMDP7880/8/f3Jyclh4cKFgDpoycrKIjAwkKysLL7//nv27t2Ln58fAHXq1OHAgQMsWrRIb6D6448/0rlzZ0aNGgWoh9nGxsaydetWrf2USiVLly7FxsYGgH79+rFv3z4mT56MnZ0dZmZmWFlZaf1c582bh6+vL99//72mLCIiAldXVy5duoSLiwvh4eGsXLmS9u3bA7Bs2TJq1qypU8+tW7fSq1cv0tPTcXZ2Zs+ePVStWrXAz+7GjRt6A8i9e/eSnp5OcHAwAH379iU8PFwnUJUkqdBA9f79+yQnJ+Pl5VXgPgVp1qwZcXFxhe5TvXr1ArclJibqbK9evTqpqalkZGRgqedGyIMHDwgLC2PlypXY2ur/C/rq1atERkbSp08ftm/fzpUrV/jkk0/Iycnhu+++0+zn4uJCdnY2iYmJ1K5du9DrEMpOWWT9FYFqITZd/J3f658gR6YOeixzJeRX5PDUMlYpec82iA/T0H7//Tw9e24gJ0eddaxr19fYsKEHFhYv/09GoVBw/fp13NzcxDprgtER7VMwdgZvoxYW6p5NQ7Ao/mijgIAAHj9+zLFjx0hOTqZevXqantEBAwaQmZlJdHQ0derUoVatWpw9e5b09HQ6dOigdZ7s7Gx8fX31vsfFixfp3r27Vlnz5s11AlU3NzdNkArg7OzMvXv3Cq3/qVOniIqK0tu7GB8fT0ZGBtnZ2bRo0UJT7uDggKenp87++fMx79+/zy+//EKPHj04cuQIjo6Oet87IyMDCz2fdUREBD179sTERP23SmhoKKNHjyY+Pl5rjq9KpSIzMxNzc3O9PVcvksjG0tISDw+P5z7+eQwePJjevXvTtm3bAvdRKpU4Ojry888/I5fLef3117l16xbTp0/XClTzA+H09PQyr7dQsGeTfZWGl/8v+FIml0zgqe8HsTSN8cjKUpCbqw5S/+//GrBy5TuYmb06fxTnz80RBGMk2qdg7AzaRiWp2MNvDcnDw4OaNWsSFRVFcnKypkfUxcUFV1dXYmNjiYqKol079TrlaWnqZIbbtm3TSoADvPAQzWd7FyVJKnJ5jLS0NEJCQpg2bZrONmdnZ65cuVLs969UqRIeHh54eHjw5ptv8tprrxEeHs5XX32ld/+qVauSnJysVZaUlMTvv/9OTk4OCxYs0JQrFAoiIiKYPHkyALa2tqSmpupcX0pKiiZbcrVq1bC3t+fChQvFvoZ8Lzr018nJibt372qV3b17F1tbW729qaAe9rtlyxZmzJgBqANtpVKJiYkJP//8Mx988AHOzs6Ymppq3TyqX78+iYmJZGdnY2amHi2XlJQEqD8D4eUiAtUSMnnmI0vJe7Yv74oIOnr1akR6eg4xMQn88ksIJiYiV5ggCIIglKbAwECio6NJTk5m9OjRmvK2bduyY8cOjh49yscffwxAgwYNMDc3JyEhQe8wX308PT11lmjRt2RLUczMzHR6eJo2bcrGjRtxc3PT9GA+rW7dupiamnLkyBFq1aoFQHJyMpcuXSqy/kqlkqysrAK3+/r66mSmXbVqFTVr1mTTpk1a5bt372bmzJlMnDgRuVyOp6cnu3fv1jnnyZMnqVevHqAedtmrVy9WrFjBd999pzPMOC0tDQsLC73X/aJDf/38/LSWjAHYs2ePZri3PocOHdL6+WzevJlp06YRGxuruanRqlUrfv31V5RKpWZY6aVLl3B2dtYEqaBOkFWzZs1Ch14LFZP4S76ETCTtO3gpec/25V0RQa8PPvAlIuJfIkgVBEEQhDIQGBjIgQMHiIuL0wre/P39WbRoEdnZ2ZqMvzY2NowaNYrPP/+cZcuWER8fz8mTJ/nxxx9ZtmyZ3vN/+umnbN++nVmzZnH58mUWLVrEjh07Spyoxc3NjSNHjnD9+nXu37+PUqlk6NChJCUlERoayrFjx4iPj2fXrl0MGDAAhUKBtbU1AwcOZPTo0URGRnLmzBnCwsK05t49fvyYr7/+msOHD3Pjxg1OnDjBBx98wK1bt/i///u/AusTHBzM2bNntXpVw8PDee+992jUqJHWY+DAgdy/f5+dO3cC8PHHH3Pp0iVGjRrFX3/9xcWLF5k1axarV6/miy++0Jxv8uTJuLq60qJFC5YvX865c+e4fPkyERER+Pr6anq4n5U/9Lewx9PDrJ81ZMgQrl69ypgxY7hw4QLz589n3bp1fP7555p95s2bp5n3C+qe0aevuUaNGshkMho1akTlypU1152UlMRnn33GpUuX2LZtG99//z1Dhw7Vev+YmBg6duxYYP2Eikv8NV9Cckn0qBqL77+P4ZdfTuiUv4qZRSVJwtXV9ZW8dsH4ifYpGDvRRosvMDCQjIwMPDw8tHrZ/P39efTokWYZm3yTJk1i/PjxTJkyhfr169OpUye2bduGu7u73vO3atWKhQsXMmvWLHx8fNi5cyeff/653vmdhRk1ahRyuZwGDRpQrVo1EhIScHFx4eDBgygUCjp27Ii3tzcjRozA3t5eE4xOnz6dNm3aEBISQlBQEK1bt9bK1iuXy7lw4QLvvvsu9erVIyQkhAcPHhATE0PDhg0LrI+3tzdNmzZl3bp1AJw4cYJTp07x7rvv6uxrZ2dH+/btCQ8PB9QJqPbv38/ly5fp0KEDLVq0YN26daxfv55OnTppjnNwcODw4cP07duX//znP/j6+tKmTRtWr17N9OnTNcOES5u7uzvbtm1jz549+Pj4MHPmTBYvXqxJEAXqZE/x8fElOq+rqyu7du3i2LFjNG7cmOHDh/PZZ59psk4DZGZmsmnTJgYPHlxq1yM8n7L4/pRULzL7+iWQmpqKnZ0dDx8+1Mk6tuavDXywrrdWMqUlJ4fw7s6fNPvMAn4F3geGl1+1X2kqlYpvvolkypQDSBKsWNGdPn0aG7pagiAIglAsmZmZXLt2DXd39xIHYK+iwYMHc+HCBWIMlXCqlGzbto3Ro0dz5syZMsmQ+ipasGABv//+u96h0ULpK+y7q7CY6nmJfyUlJJeJHlVDUqlUjBixkylTDuS9hjt39A9leZUoFAouXLhQJhnXBOFFifYpGDvRRo3LjBkzOHXqFFeuXNEME+7fv7+hq/XCunbtyocffsitW7dKfKxKpSIjI+OFsvu+jExNTfnxxx8NXQ0BkfXXKMjFHFWDUSiUDBmylcWL/9SUzZvXmaFDmxuwVsYjMzPT0FUQhAKJ9ikYO9FGjcfRo0f54YcfePToEXXq1GHu3LkMGjTI0NUqFSNGjHjuY0WQqutlaReCfiJQLSG5XASqhpCToyAsbDO//noaAJlMIjz8X4SFNTFsxQRBEARBKFX58zgFQXi1iUC1hExk+gNVsY5q2cnKyqVXr41s2qReG8zERMbKld3p2bORgWsmCIIgCIIgCEJZEIFqCRUUqNqXd0VeEenpObzzzlp27VJnijMzk7Nhw/8REuJp4JoZF5lMRp06dURyBsEoifYpGDvRRoWKwNzc3NBVEIQClcX3pwhUiyCpJEyVJqCSsM62wkxRSbMtG0jP+297Q1TuFXD1ajKHDv0NgJWVKZs39yIoqI6Ba2V8JEkqtQxrglDaRPsUjJ1oo4KxkyQJuVxu6GoIQoHKYnkaceuwILdA2gdWOTZUyralUo4NtVNew+tkV/hZvT0lb1c5YG24mr7UGjVyZPv23jg7W7NrV18RpBZAoVBw+vRpkbFSMEqifQrGTrRRwdipVCrS09NFQiXBaImsv+XlLDAFpDSgHigkBUgqMk0ykCtMYRnwB6R/BTRU96aKJcLLTqtWtYiPH46lpWnRO7/CxB9YgjET7VMwdqKNCoIgGBfRo/qsW8AUIAGoCSpJCZL67pUKFTnWGVBfvd16ClS7JYb9lqbbtx/x/fcxOncMRZAqCIIgCIIgCK8OEag+axtwFagHTXNf56NjYbwf14P343rQ9VIQkiRTj/WtB/Jr0HK7CFRLy/XrKbRps4Rvvolk7Ni9YniLIAiCILzkoqOjkSSJlJSUYh8zYcIEmjRpUmZ1elZAQMALrX+a78GDBzg6OnL9+vUXPpeg9uabb7Jx40ZDV0MoIyJQfVoqsBf1WjNycFe40/5aW9oktKBNQguaJnojk/Imssshwx7e3AOOjwxX5ZfFpUsPaNt2CVevJgOwYcM5UlLE4uvFJZPJ8PT0FBkrBaMk2qdg7EQbLdrChQuxsbEhNzdXU5aWloapqSkBAQFa++YHn/Hx8UWet2XLlty5cwc7O7tSrW9pBZdFGTJkCJIkMXv27CL3nTx5Mt26dcPNzU1nW3BwMHK5nGPHjulsy78WCwsLrfKlS5dib2+vVZaamso333yDl5cXFhYWODk5ERQUxG+//VamHQDR0dE0bdoUc3NzPDw8WLp0abGPvXLlCjY2NjrXsnTpUiRJ0no8+xmMGzeOL7/8EqVSWQpXIbyIsvj+FN/IT7sE3AMcC97l6R9CqiM43IO6F8u8Zi+1M2fu0bbtEm7eTAXAy6sqMTEDqFzZ0sA1q1jMzMwMXQVBKJBon4KxE220cIGBgaSlpXH8+HFNWUxMDE5OThw5coTMzCc3l6OioqhVqxZ169Yt8rxmZmY4OTmVScbQsvb7779z+PBhXFxcitw3PT2d8PBwBg4cqLMtISGB2NhYhg0bRkRERIHnKOozSklJoWXLlixfvpyvvvqKkydP8scff9CzZ0/GjBnDw4cPi76o53Dt2jW6du1KYGAgcXFxjBgxgkGDBrFr164ij83JySE0NJQ2bdro3W5ra8udO3c0jxs3bmht79y5M48ePWLHjh2lci2CcRGB6tMygVygkOmQkvQkNXimKchywV50/D23Eydu4++/lLt3HwPQuHF19u8Po0YNsUxASSiVSk6fPi3uKApGSbRPwdgZuo2qVCoycjIM8ihuL5unpyfOzs5ER0dryqKjo+nWrRvu7u4cPnxYqzwwMBBQf7ZTpkzB3d0dS0tLfHx82LBhg9a+zw79/eWXX3B1dcXKyoru3bsza9Ysnd42gBUrVuDm5oadnR29evXi0SP1ELewsDD279/PnDlzND1x+cNtz5w5Q+fOnbG2tqZ69er069eP+/fva875+PFj3n//faytrXF2dmbmzJl6P49bt27x6aefsmrVKkxNi86jsX37dszNzXnzzTd1ti1ZsoS33nqLjz/+mNWrV5ORkaH3HAWV5/v666+5fv06R44coX///jRo0IB69eoxePBg4uLisLYumzUqFi5ciLu7OzNnzqR+/foMGzaM9957j//+979FHjtu3Di8vLzo0aOH3u2SJOHk5KR5VK9eXWu7XC6nS5curFmzplSuRXh+ZfH9KbL+Ps0C9SeSAxRwY1V6qkc1JwdkJmBpoX9foXAHDybQpcuvpKZmAdC8eQ127OiDg4PoSRUEQRBeHZm5mbRZor9HqazFDIjB0rR4v3cDAwOJioriyy+/BNQ9p2PGjEGhUBAVFUVAQAAZGRkcOXKEDz74AIApU6awcuVKFi5cyGuvvcYff/xB3759qVatGv7+/jrvcfDgQYYMGcK0adP417/+xd69exk/frzOfvHx8WzatImtW7eSnJxMjx49mDp1KpMnT2bOnDlcunSJRo0aMXHiRACqVatGSkoK7dq1Y9CgQfz3v/8lIyODsWPH0qNHDyIjIwEYPXo0+/fvZ/PmzTg6OvL1119z8uRJrTmxSqWSfv36MXr0aBo2bFi8zzkmhtdff12nXKVSsWTJEn766Se8vLzw8PBgw4YN9OvXr1jnfbpOa9asoU+fPnp7eAsLUmNiYujcuXOh51+0aBF9+vTRu+3QoUMEBQVplQUHBxc59DoyMpL169cTFxfHb7/9pneftLQ0ateujVKppGnTpnz//fc6n3nz5s2ZOnVqoe8lVEwiUH1aPdTDfu8BNfXv8vTQX/N7cNcR5J7lUbmXy759V/nXv9aQnp4DQNu2tfnf/0KxtTU3cM0EQRAEQdAnMDCQESNGkJubS0ZGBn/++Sf+/v7k5OSwcOFCQB20ZGVlERgYSFZWFt9//z179+7Fz88PgDp16nDgwAEWLVqkN1D98ccf6dy5M6NGjQKgXr16xMbGsnXrVq39lEolS5cuxcbGBoB+/fqxb98+Jk+ejJ2dHWZmZlhZWeHk5KQ5Zt68efj6+vL9999ryiIiInB1deXSpUu4uLgQHh7OypUrad++PQDLli2jZk3tPwqnTZuGiYkJw4cPL/Znd+PGDb0B5N69e0lPTyc4OBiAvn37Eh4eXuJA9f79+yQnJ+Pl5VWi4wCaNWtGXFxcofs825P5tMTERJ3t1atXJzU1lYyMDCwtdW+EPHjwgLCwMFauXImtrf5RdJ6enkRERNC4cWMePnzIjBkzaNmyJWfPntX6mbi4uHDz5k2USqWYZ/6SEYHq02yBIGAp4IzexVE1PaoKME+Bw29DR5tyqt9LQqFQ8vnnuzRBaseOdfn9955YWYklaARBEIRXj4WJBTEDYgz23sUVEBDA48ePOXbsGMnJydSrV0/TMzpgwAAyMzOJjo6mTp061KpVi7Nnz5Kenk6HDh20zpOdnY2vr6/e97h48SLdu3fXKmvevLlOoOrm5qYJUgGcnZ25d+9eofU/deoUUVFRensX4+PjycjIIDs7mxYtWmjKHRwc8PR80iNx4sQJ5syZw8mTJ0s0rzYjI0MnERCoA+WePXtiYqL+kzw0NJTRo0cTHx9frDm++V4kUZKlpSUeHh7PffzzGDx4ML1796Zt27YF7uPn56e5wQHqxFv169dn0aJFTJo0SVNuaWmJUqkkKytLb1AsVFwiUH1WV+AP4BJs8d7Mp90/QSlTj7l2fehCp5NdQaHe/rc7xHYB/aPqhYLI5TK2bu1NmzZL8PV1Yu3a9zA3F03xRchkMry9vcWdRMEoifYpGDtDt1FJkoo9/NaQPDw8qFmzJlFRUSQnJ2t6RF1cXHB1dSU2NpaoqCjatWsHqIdtAmzbto0aNWponcvc/MVGUD07L1SSpCLnyKWlpRESEsK0adN0tjk7O3PlypUi3zcmJoZ79+5Rq1YtTZlCoeCLL75g9uzZBS49U7VqVZKTk7XKkpKS+P3338nJyWHBggVa54uIiGDy5MmAOqFQamqqThCWkpKiyZZcrVo17O3tuXDhQpHXoO+aXmTor5OTE3fv3tUqu3v3Lra2tgUGjpGRkWzZsoUZM2YA6kBbqVRiYmLCzz//rBk6/jRTU1N8fX11fk5JSUlUqlRJBKkGVhbfnyI6eFYN4CtgCuTcyiGrXjYKSQGSimx5DiZp5nAeVO6w+Cv4p4ZYR/V51Kplx8GDH1C9eiVMTeVFHyAUKTs7W+/dWkEwBqJ9CsZOtNHiCQwMJDo6muTkZEaPHq0pb9u2LTt27ODo0aN8/PHHADRo0ABzc3MSEhL0DvPVx9PTU2eJFn1LthTFzMwMhUKhVda0aVM2btyIm5ubpgfzaXXr1sXU1JQjR45oAtHk5GQuXbqkqX+/fv30zsfs168fAwYMKLA+vr6+rFy5Uqts1apV1KxZk02bNmmV7969m5kzZzJx4kTkcjmenp7s3r0blUql1Yt78uRJ6tWrB6iDhF69erFixQq+++47nWHGaWlpWFhY6L3uFx366+fnx/bt27XK9uzZo9Ub+qxDhw5p/Xw2b97MtGnTiI2N1bmpkU+hUHD69Gm6dOmiVX7mzJkCe+iFik0Eqvo0BKaBaj1wG+QqOajAItcSLCQIg/QucDnv35G94WpaYWzadIHg4LpYWj65A1qzpsjsW1qUSiUXL17E29sbuVwE/oJxEe1TMHaijRZfYGAgQ4cOJScnRyv49Pf3Z9iwYWRnZ2sy/trY2DBq1Cg+//xzlEolrVu35uHDhxw8eBBbW1v69++vc/5PP/2Utm3bMmvWLEJCQoiMjGTHjh0lXr7Gzc2NI0eOcP36daytrXFwcGDo0KH88ssvhIaGMmbMGBwcHLhy5Qpr1qxh8eLFWFtbM3DgQEaPHk2VKlVwdHTkm2++0eopqlKlClWqVNF6L1NTU5ycnLSGCD8rODiYr776iuTkZCpXrgxAeHg47733Ho0aNdLa19XVla+++oqdO3fStWtXPv74Y+bNm8ewYcP46KOPsLCwYNu2baxevZr//e9/muMmT55MdHQ0LVq0YPLkyTRr1gxTU1NiYmKYMmUKx44d05s9+UWH/g4ZMoR58+YxZswYPvjgAyIjI1m3bh3btm3T7DNv3jx+//139u3bB0D9+vW1znH8+HFkMpnWZzFx4kTefPNNPDw8SElJYfr06dy4cYNBgwZpHRsTE0PHjh2fu/5C6SiLrL9iHFZBaoCqHaSbPuKxWSqPTR9xw/4ymaH3YDAk5wWploBI/1O4mTNj6d59Le+9t57sbEXRBwiCIAiCYJQCAwPJyMjAw8NDq5fN39+fR48eaZaxyTdp0iTGjx/PlClTqF+/Pp06dWLbtm24u7vrPX+rVq1YuHAhs2bNwsfHh507d/L555+XuLd71KhRyOVyGjRoQLVq1UhISMDFxYWDBw+iUCjo2LEj3t7ejBgxAnt7e00wOn36dNq0aUNISAhBQUG0bt1ab7bekvL29qZp06asW7cOUM91PXXqFO+++67OvnZ2drRv357w8HBAnYBq//79XLx4kQ4dOtCiRQvWrVvH+vXr6dSpk+Y4BwcHDh8+TN++ffnPf/6Dr68vbdq0YfXq1UyfPl0zTLi0ubu7s23bNvbs2YOPjw8zZ85k8eLFmgRRoE72FB8fX6LzJicnM3jwYOrXr0+XLl1ITU0lNjaWBg0aaPa5desWsbGxhfZmCxWXpHqR2dcvgdTUVOzs7Hj48KFO1rE1f23gg3W9yZHlAmCZK3HH9QqVPnbnDBCGOufS/549qQCo5xtMnLifCRP2a8pWrXqH3r29DVirl1P+cBjRGyAYI9E+BWNX3m00MzOTa9eu4e7uLoYbF8PgwYO5cOECMTGGSThVWrZt28bo0aM5c+ZMiefzqVQqTQbdkvYuv8zGjh1LcnIyP//8s6Gr8koo7LsrOTkZBwcHvTHV8xJDf0tInjf5PyXvtb2hKmLkVCoVY8fuZfr0WE3Zf/4TKILUMiQCAMGYifYpGDvRRo3HjBkz6NChA5UqVWLHjh0sW7aM+fPnG7paL6xr165cvnyZW7du4erqaujqvBQcHR0ZOXKkoashlBERqJaQ3MwMgPy8bZUNVxWjpVSq+PTT7cyff1xT9t//BjNixJsGrNXLTS6X4+0tbgIIxkm0T8HYiTZqXI4ePcoPP/zAo0ePqFOnDnPnztWZl1hRjRgx4rmOkyQJKyur0q3MS+CLL74wdBWEPGVxs08EqiUkelQLl5urZNCgLSxbdgoASYKFC9/iww9ffH6HUDCVSsWjR4+wsbERQ4IEoyPap2DsRBs1LvnzOIUn8pdvkclkoo0KRqksZpOKZEolIKlAZqHOWpuSV2ZvqMoYoZwcBX36/KYJUuVyieXLu4sgtRwolUquXr1aJhnXBOFFifYpGDvRRoWKICsry9BVEIQClcX3p+hRLQEJCczVH1lKXpm9oSpjhKZOPcC6dWcBMDWVsWbNe7zzTv0ijhIEQRAEQRAEQdAmelRLQFIB5urx1/lzVO0NVRkjNHKkH61b18LCwoRNm3qJIFUQBEEQBEEQhOcielRLQAIwVc8LSMkrszdMVYxSpUpmbNvWm7Nn7+HnJ7LZlTexxIFgzET7FIydaKOCsRNzU4VXjQhUSyrvE0vJe2lvoGoYgwcP0snKUuDiYqMps7U1F0GqAcjlcry8vAxdDUHQS7RPwdiJNioYO0mSsLS0NHQ1BKFAZZH1Vwz9LQFJJYE6l9IrH6gmJqYRELCM9u2Xc+/eY0NX55WnVCp58OCBSAQiGCXRPgVjJ9qoYOxUKhW5ubllkllVEEpDWXx/ikC1BCQAE1AAqXllr+I6qjdvPsTffylnztzjwoX79O+/ydBVeuWpVCpu3rwpfoEJRkm0T8HYiTb6crt+/TqSJBEXF1fgPtHR0UiSREpKSrnVq6Sys7MZMGAAb7/9tqGrUiI///wzrq6uyGQyZs+eXaJjL168iJOTE48ePSqbyr2CevXqxcyZM0v9vGJ5mnLWsFojGt2riVOaCU5pJtR6aAmm8DBvuwTYGrKCBhAfn0SbNku4dOkBALVq2fHjj50NXCtBEARBEMpaWFgYkiTpPDp16mToqr10CgquZ8+ezdKlSw1Sp+eRmprKsGHDGDt2LLdu3eLDDz8kICCAESNGFOv4r776ik8//RQbGxudbV5eXpibm5OYmKizzc3NTW9QPGHCBJo0aaJVlpiYyKeffkqdOnUwNzfH1dWVkJAQ9u3bV6w6Pq/169fj5eWFhYUF3t7ebN++vchjVq1ahY+PD1ZWVjg7O/PBBx/w4MEDrX1SUlIYOnQozs7OmJubU69ePa1zjxs3jsmTJ/Pw4cNnT290xBzVQnhV9cLrvjO5srsAuKZagsmTYb82QOmPxjZe58//Q1DQCm7fVt/V8vBwYO/eftSubW/YigmCIAjCy+CZPzhLpFIlKCghVFIS6OvtqFKlxG/TqVMnlixZolVmbm5e4vMIz8fOzq5CJVVKSEggJyeHrl274uzsXOJjt27dyo8//qiz7cCBA2RkZPDee++xbNkyxo4d+1z1u379Oq1atcLe3p7p06fj7e1NTk4Ou3btYujQoVy4cOG5zluU2NhYQkNDmTJlCm+99Ra//vorb7/9NidPnqRRo0Z6jzl48CDvv/8+//3vfwkJCeHWrVsMGTKEwYMH89tvvwHqXvcOHTrg6OjIhg0bqFGjBjdu3MDe3l5znkaNGlG3bl1WrlzJ0KFDy+T6SovoUS0BuVIGpq/m/NS4uET8/ZdqgtQGDarxxx9hIkg1IvruNgqCsRDtUzB2RtFGvb2f/7F6dcHnbdtW/zHPwdzcHCcnJ61H5cpPJkJJksTixYvp3r07VlZWvPbaa2zZskWzPTk5mT59+lCtWjUsLS157bXXtALfmzdv0qNHD+zt7XFwcKBbt25cv35dsz0sLIy3336b77//nurVq2Nvb8/EiRPJzc1l9OjRODg4ULNmTZ1gGuDChQu0bNkSCwsLGjVqxP79+wu91gMHDtCmTRssLS1xdXVl+PDhPH5cdF6Or7/+mhYtWuiU+/j4MHHiREA9n2/ixInUrFkTc3NzmjRpws6dOzX7uru7A+Dr64skSQQGBiKTyXSG/gYEBDB8+HDGjBmDg4MDTk5OTJgwQee6W7dujYWFBQ0aNGDv3r1IksSmTZuKvJbs7GyGDRuGs7MzFhYW1K5dmylTpmi2JyQk0K1bN6ytrbG1taVHjx7cvavu4Fm6dCneee2sTp06SJJEWFgY+/fvZ86cOZoe+ad/vk9bt24dPj4+1KhRQ2dbeHg4vXv3pl+/fkRERBR5HQX55JNPkCSJo0eP8u6771KvXj0aNmzIyJEjOXz48HOftyhz5syhU6dOjB49mvr16zNp0iSaNm3KvHnzCjzm0KFDuLm5MXz4cNzd3WndujUfffQRR48e1ewTERFBUlISmzZtolWrVri5ueHv74+Pj4/Wuf6/vTuPj+l6Hzj+mewRWSQhsYQQkQQRS0Qj1m9DLKVaLdIgsbTaUlpLUUsstbRFLVWqtbWlFLVUiQZFLKVFWsROUBVbEmv2nN8faeZnZI8sg+fd17xqzj333ufOHGOeOeee06lTJ1atWlVs11dUJFEtAENloNOj+rzcn3rw4D+0br2cmzcfAtCggSO7d4dQsaIe/KMugIyZ1lxcXIplxjUhnpS0T6HvpI0WrYkTJ9KtWzf+/vtvOnToQFBQELGxsQCMGzeOqKgotm7dysmTJ1mwYAH29vYApKSkEBAQgKWlJREREezbt4+yZcvSrl07kpOTtcffuXMn//77L3v27GHWrFmEhoby0ksvUa5cOQ4ePMjbb7/NgAED+Oeff3TiGjFiBMOGDePo0aP4+vrSqVOnLMMmM50/f5527drRtWtX/v77b1avXs3evXsZNGhQntcfFBTEoUOHOH/+vLbsxIkT/P3337zxxhtARqIyc+ZMZsyYwd9//01AQACdO3fm7NmzANrkY/v27Vy7do2ffvopxyWUli9fjoWFBQcPHuTTTz9l0qRJhIeHA5CWlkaXLl0oU6YMBw8eZNGiRYwZMybPa8g0d+5cNm3axI8//sjp06dZsWIFzs7OQEay/fLLLxMbG8vu3bsJDw/nwoULdO/eHYDu3buzfft27fVcu3aNOXPm4Ovry5tvvsm1a9e4du0aTk7ZrxYRERGBt7d3lvJ79+6xZs0aevbsSZs2bbhz5w4RERH5vqZMsbGxhIWFMXDgQCwsLLJsf7QX8nErVqygbNmyuT5yi+nAgQP4+/vrlAUEBHDgwIEc9/H19eXKlSts2bIFpRTXr19n7dq1dOjQQVtn06ZN+Pr6MnDgQBwcHKhbty5Tp04lLS1N51g+Pj4cOnSIpKSkHM9XUDLrbykzVM9fj+rZs7fx9/+O+PhEAHx9q7BzZzD29mVKOTLxqPT0dGJiYmTGSqGXpH0KfSdtNP82b96c5Qv51KlTdeqEhIQQGBhIzZo1mTp1Kvfv39cmXpcvX6ZBgwZ4e3vj7OyMv78/nTp1AmD16tWkp6fzzTff4OnpiYeHB0uXLuXy5cvs2rVLe3xbW1vmzp2Lm5sbffv2xc3NjYcPH/LRRx/h6urK6NGjMTExYe/evTpxDRo0iK5du+Lh4cGCBQuwtrZm8eLF2V7ntGnTCAoK4v3338fV1ZWmTZsyd+5cvv32WxITE3N9jerUqYOXlxcrV67Ulq1YsYImTZpQs2ZNAGbMmMHIkSPp0aMHbm5ufPLJJ9SvX197X2X58uUBsLOz0/Zap6SkZHu+evXqERoaiqurK71798bb21t7f2V4eDjnz5/n22+/xcvLi2bNmjFlypRc43/U5cuXcXV1pVmzZlSrVo1mzZoRGBgIwI4dOzh27BgrV66kUaNGNGnShG+//Zbdu3fzxx9/YG5ujt1/w8vLly+Po6Mj1tbWmJiYUKZMGW2PfE4JzqVLl6hUqVKW8lWrVuHq6kqdOnUwNDSkR48eOb6PuTl37hxKqUItTdW5c2ciIyNzfWSXZGeKiYnBwcFBp8zBwSHb+20z+fn5sWLFCrp3746JiYn29Zw/f762zoULF1i7di1paWls2bKFcePGMXPmTD7++GOdY1WqVInk5ORcz1dQMutvKTNUhjo9qjalGEtJqVnTlh496gDQurUzv/7aCxsbWRRd3yiliImJkRkrhV6S9in0nbTR/GvdunWWL+Rvv/22Tp169epp/2xhYYGVlRU3btwA4J133mHVqlXUr1+fDz/8kP3792vr/vXXX5w7dw5LS0ttEmxra0tiYqJO72SdOnUwMPj/r7AODg7aIaaQ0bNjZ2enPWcmX19f7Z+NjIzw9vbm5MmT2V7nX3/9xbJly3QS8oCAANLT07l48WKer1NQUJA2UVVK8cMPPxAUFARkTDD077//4ufnp7OPn59fjvEAuSaqj6pYsaL22k+fPo2TkxOOjo7a7T4+PnnGnykkJITIyEjc3NwYPHgwv/76q3bbyZMncXJy0ukRrV27NjY2NrleR34lJCRk24u8ZMkSevbsqX3es2dP1qxZU+CZgZ/k77ulpSU1a9bM9VHU695GRUUxZMgQxo8fz+HDhwkLCyM6Olrn7196ejoVKlRg0aJFNGrUiO7duzNmzBgWLlyoc6zM2B4+fFhk8RXH56dMplQAhukZQ3/j/nv+PAz91Wg0LFz4Eh4e5XnnHW/MzY1LOyQhhBDi2XTsWOH3zWbootaePdlPplSo01hoewVzYmys+11Bo9Foe1vat2/PpUuX2LJlC+Hh4bz44osMHDiQGTNmcP/+fRo1asSKFSuyHDOzhzGn4+d2zsK4f/8+AwYMYPDgwVm2Va1aNc/9AwMDGTlyJEeOHCEhIYErV65oh8QWtaK+9kc1bNiQixcvsnXrVrZv3063bt3w9/dn7dq1RXL83Njb2xMXF6dTFhUVxe+//86hQ4d0JlBKS0tj1apVvPnmmwBYWVllO6ttfHw81tbWALi6uqLRaAo1YdKKFSsYMGBArnW2bt1K8+bNs93m6OiovZc30/Xr13V+UHjctGnT8PPzY8SIEUDGDxQWFhY0b96cjz/+mIoVK1KxYkWMjY11eqk9PDyIiYkhOTkZExMTAO1Q/Ef/XukjSVRzse18GFtqneBBGUPQGHDTPpW7z8HQ3/j4RJ1eU0NDA4YO9c1lDyGEEEI8sULMwpsvtrbFc9xCKl++PMHBwQQHB9O8eXNGjBjBjBkzaNiwIatXr6ZChQpYWRX9AoC///47LVq0ACA1NZXDhw/neM9pw4YNiYqKyjMpz0mVKlVo2bIlK1asICEhQTsTK2QkUZUqVWLfvn20bNlSu8++ffu0vZ2ZCcXj9xYWlJubG1euXOH69evaoaZ//PFHgY5hZWVF9+7d6d69O6+99hrt2rUjNjYWDw8Prly5wpUrV7S9qlFRUcTHx1O7du0cj2diYpKv62rQoAFRUVE6ZYsXL6ZFixY6w10Bli5dyuLFi7WJqpubG4cPH85yzCNHjuDm5gZkDCEPCAhg/vz5DB48OMt9qvHx8Tnep9q5c+dsJ8x6VHaTQGXy9fVlx44dOsv0hIeH6/T6P+7hw4cYGemmbpkJaWZvpp+fHytXriQ9PV076uDMmTNUrFhR26YAjh8/TpUqVbT3h+srGfqbg6vAxpT7xFsbkWRqQpKpETcqV6K/CewDknk2E9UlS45Ss+Zc/vqr6Masi+Kn0WiwtbV9qqasF88PaZ9C30kbzb+kpCRiYmJ0Hrdu3cr3/uPHj2fjxo2cO3eOEydOsHnzZjw8PICM4bL29va8/PLLREREcPHiRXbt2sXgwYOzTIxUGPPnz2f9+vWcOnWKgQMHEhcXR9++fbOtO3LkSPbv38+gQYOIjIzk7NmzbNy4MV+TKWUKCgpi1apVrFmzRjvsN9OIESP45JNPWL16NadPn2bUqFFERkYyZMgQACpUqIC5uTlhYWFcv36dO3fuFGqymjZt2uDi4kJwcDB///03+/btY+zYsQD5au+zZs3ihx9+4NSpU5w5c4Y1a9bg6OiIjY0N/v7+eHp6EhQUxJEjRzh06BC9e/emZcuWud6f6ezszMGDB4mOjubWrVs59v5mTi6UmdSmpKTw3XffERgYSN26dXUe/fv35+DBg5w4cQKADz74gF9++YUpU6Zw8uRJjh8/zpgxYzhw4ID2NYaMNpGWloaPjw/r1q3j7NmznDx5krlz5+aaND7p0N8hQ4YQFhbGzJkzOXXqFBMmTODPP//UaV+jR4+md+/e2uedOnXip59+YsGCBVy4cIF9+/YxePBgfHx8tPfyvvPOO8TGxjJkyBDOnDnDL7/8wtSpU7MsQxMREUHbtm1zjK8wiuPzUxLVbJwARgK7NaA0QHoapKVilJzIAwM4RkYiG5frUZ4+8+YdpF+/Tdy+nUCbNt9x9erd0g5J5JOBgQFVq1bVuWdHCH0h7VPoO2mj+RcWFqYdYpj5aNasWb73NzExYfTo0dSrV48WLVpgaGioXSajTJky7Nmzh6pVq/Lqq6/i4eFBv379SExMLJIe1unTpzN9+nS8vLzYu3cvmzZtyrFHqV69euzevZszZ87QvHlzGjRowPjx47Od3Ccnr732Grdv3+bhw4c6S8oADB48mKFDhzJs2DA8PT0JCwtj06ZNuLq6Ahn30M6dO5evvvqKSpUq0aVLl0KtV2toaMiGDRu4f/8+jRs3pn///tpZf3OaRfhRlpaWfPrpp3h7e9O4cWOio6PZsmULBgYGaDQaNm7cSLly5WjRogX+/v7UqFGD1atX53rM4cOHY2hoSO3atSlfvjyXL1/Otl779u0xMjLSzhy8adMmbt++zSuvvJKlroeHBx4eHtpJlZo2bcrWrVvZunUrfn5+tGrViv3797Njxw6ddUpr1KjBkSNHaN26NcOGDaNu3bq0adOGHTt2sGDBgjxfn8Jq2rQpK1euZNGiRXh5ebF27Vo2bNigE9u1a9d0XpuQkBBmzZrFF198Qd26dXn99ddxc3PTrqEK4OTkxLZt2/jjjz+oV68egwcPZsiQIYwaNUpbJzExkQ0bNmh7n4tKcXx+atRzPnPA3bt3sba25s6dO1hZWXGVjCT1MmB0fC17Nr1Fuibjl54y5s4EvR/JVjKS1JbAV0DOHftPj+nT9zJ69A7t8w8+eIGZM9vKr8tPifT0dP755x+qVKkiX7SE3pH2KfRdSbfRxMRELl68SPXq1fOVLAihlNLeY/ik38327dtHs2bNOHfuHC4uLkUUYfGYP38+mzZtYtu2baUdyjNjwYIFrF+/XmdirPzK7bMrPj6ecuXKaXOqoiDfGB7zC3ABqEXOL04yYArEAFtKKK7iopRi7NidOknquHEtJEl9yiiliI2NlRkrhV6S9in0nbRR8TQo7P2q69evJzw8nOjoaLZv385bb72Fn5+f3iepAAMGDKBFixYFntFX5MzY2Jh58+YV+XGL4/NTEtVH3AW2kzGbb3Z3AWgUpJHx0AD2QDjwtP7VUUoxdOg2pkz5/wWJp09/kUmTWkuSKoQQQgiRjYiIiCxryT760Df37t1j4MCBuLu7ExISQuPGjdm4cSMAU6dOzfE62rdvX8qRZwyBHjNmDJaWlqUdyjOjf//+2gml9J3M+vuIM8ANoHoudZL/+78B4AhEA6eBnG8Z10/p6Yp33tnMokVHtGXz5rVn0KD8r60lhBBCCPG88fb2JjIysrTDyLfevXvrTMrzqLfffptu3bplu62o1wEVoqAkUX1EIpAK5LxSqIak//5k8t8j9b/9niZKKfr02ci33/4FgEYD33zTmb59G5RyZKKwNBoNjo6O0hMu9JK0T6HvpI2KgjA3Ny/0sjVP4vH1UouCra0ttnq2fJF4Osmsv8XMjIzMPSWXOpmJqul/9Yz+2+9potFo8PHJmLXO0FDDypVdJUl9yhkYGODo6CgT1Qi9JO1T6Dtpo0LfaTQajI2N5ccUobeK4/NTelQfUQuoQMbw3yrZbNeg0Q79NfmvXgXg6RjlrWvgQB8SE1OpWdOWl192L+1wxBNKS0sjOjoaZ2fnQq2zJkRxkvYp9J20UaHvlFIkJSVhamoqyarQS4Wd7Cs3kqg+wgrwB5YBFXOok5moGgPxQBfgabi9Oz1dYWCg+8E2bFjTUopGFAeZEU/oM2mfQt9JGxX6Lj09vbRDEKJEyRiXx3QEapAxsVLGx4EClQbpaaSlPeRB0l0UGTMEVwc6lFqk+Rcfn0jLlstYty6qtEMRQgghhBBCiDxJovqYysBowP7uVU5cDCct7SEqNQGVlkBS4lWOb+rPvcOLsLl7ldH/1ddnN28+oHXr5ezde5nAwHVs3Xq2tEMSQgghhBBCiFxJopqdGydg+0iI3gVKgYFRxsPYHJX8ACKXY7x9ZEY9Pfbvv/do1Wo5kZExAJQrZ07lylalHJUoDhqNBicnJ7lvReglaZ9C30kbfbZFR0ej0WhyXVJm165daDQa4uPjSyyugjIxMaFPnz506dKlxM6Zn9euKOX3fdixYwceHh7Fcl/k8+qFF15g3bp1hd5fZv0tAVfvXmXa3mncunOZOmWrYJiWhiYtBU1aCmYPEqhsVQVLew8S7lxm2t5pXL17tbRDztalS/G0aLGUqKibAFSubMnu3SHUq+dQypGJ4mBgYICdnZ3MWCn0krRPoe+kjeZPSEgIGo0my6Ndu3alHdoz5/EEUaPRYGRkxJw5c1i2bFmpxqYPPvzwQ8aOHZtl8rOEhARsbW2xt7cnKSkpy34ajYYNGzZkKQ8JCcnyA8C5c+fo06cPVapUwdTUlOrVqxMYGMiff/5ZlJeSxfz583F2dsbMzIwmTZpw6NChPPeZPXs2bm5umJub4+TkxAcffEBiou4CmlevXqVnz57Y2dlhbm6Op6enzrWMHTuWUaNGFfpe6OL4/JRP5Mf8cvYXLsRdoJZtLWzMy2GdaI5ZssIsWWH/wIxUQGNgSA3bWlyMu8iWc1tKO+Qszp69TfPmSzl/Pg6A6tVtiIjog7u7fSlHJopLWloap06dkl8WhV6S9in0nb600dsPbxf6kZia86rusQmx2e5TGO3atePatWs6jx9++KGwlyzySSlFQkICVlZW2NjYlHY4Tyw5OTnvSjnYu3cv58+fp2vXrlm2rVu3jjp16uDu7p5tQppff/75J40aNeLMmTN89dVXREVFsX79etzd3Rk2bFihj5uX1atXM3ToUEJDQzly5AheXl4EBARw48aNHPdZuXIlo0aNIjQ0lJMnT7J48WJWr17NRx99pK0TFxeHn58fxsbGbN26laioKGbOnEm5cuW0ddq3b8+9e/fYunVroWIvjs9PSVQfcTfpLtsvbKecWTkMDQyxM7fDLqEsZVIMKZNiiEOCjXYdVXMDQ2zMbAg/H869JP2ZKfDEiRu0aLGMK1fuAuDmZseePX2oXr1cHnuKp93jv5wJoU+kfQp9pw9t1HOBZ6EfPxzLOVlssbRFtvsUhqmpKY6OjjqPR7/sajQavvnmG1555RXKlCmDq6srmzZt0m6Pi4sjKCiI8uXLY25ujqurK0uXLtVuv3LlCt26dcPGxgZbW1tefvlloqOjtdsze76mTp2Kg4MDNjY2TJo0idTUVEaMGIGtrS1VqlTROWamU6dO0bRpU8zMzKhbty67d+/O9Vr37t1L8+bNtb1UgwcP5sGDB3m+Rh999BFNmjTJUu7l5cWkSZOAjBl8J02apO2tq1+/PmFhYdq61atXB6BBgwZoNBpat26NUirL0N9WrVoxePBgPvzwQ2xtbXF0dGTChAlZrrtZs2aYmZlRu3Zttm/fnmPPYk4uXLhA69atKVOmDF5eXhw4cEC77fbt2wQGBlK5cmXKlCmDp6dnlh8vWrVqxaBBg3j//fext7cnICAAgC1btlCrVi3Mzc1p3bq1znudk1WrVtGmTRvMzMyybFu8eDE9e/akZ8+eLF68ON/X9yilFCEhIbi6uhIREUHHjh1xcXGhfv36hIaGsnHjxkIdNz9mzZrFm2++SZ8+fahduzYLFy6kTJkyLFmyJMd99u/fj5+fH2+88QbOzs60bduWwMBAnZ7YTz75BCcnJ5YuXYqPjw/Vq1enbdu2uLi4aOsYGhrSoUMHVq1aVWzXV1CSqD7izO0z3HhwgwoWFbRl8WYPH6mhu45qBYsK3Hhwg9O3T5dkmDk6cuQaLVsuIybmPgCenhXYvTuEKlXkvlQhhBBClIyJEyfSrVs3/v77bzp06EBQUBCxsbEAjBs3jqioKLZu3crJkydZsGAB9vYZI75SUlIICAjA0tKSiIgI9u3bR9myZWnXrp1OD9zOnTv5999/2bNnD7NmzSI0NJSXXnqJcuXKcfDgQd5++20GDBjAP//8oxPXiBEjGDZsGEePHsXX15dOnTpx+3b2Pcvnz5+nXbt2dO3alb///pvVq1ezd+9eBg0alOf1BwUFcejQIc6fP68tO3HiBH///TdvvPEGAHPmzGHmzJnMmDGDv//+m4CAADp37szZsxmTXmYmGdu3b+fatWu53ju4fPlyLCwsOHjwIJ9++imTJk0iPDwcyOjl6tKlC2XKlOHgwYMsWrSIMWPG5HkNjxszZgzDhw8nMjKSWrVqERgYSGpqKpDxI0+jRo345ZdfOH78OG+99Ra9evXKMmR1+fLlmJiYsG/fPhYuXMiVK1d49dVX6dSpE5GRkfTv359Ro0blGUtERATe3t5Zys+fP8+BAwfo1q0b3bp1IyIigkuXLhX4WiMjIzlx4gTDhg3Ldjhrbj3aU6dOpWzZsrk+Ll++nO2+ycnJHD58GH9/f22ZgYEB/v7+Oj8MPK5p06YcPnxY+3pfuHCBLVu20KHD/69NsmnTJry9vXn99depUKECDRo04Ouvv85yLB8fHyIiInI8V0mTRPXkemmoAAA8vklEQVQRiamJpKanYmxgrC1LNkjV/lmDAeq/P5sAxgbGpKan5jrcpiTFxydy/37GB3njxpXYtSsEB4eypRyVEEIIIZ4VmzdvzvLFe+rUqTp1QkJCCAwMpGbNmkydOpX79+9rv0RfvnyZBg0a4O3tjbOzM/7+/nTq1AnIGPaYnp7ON998g6enJx4eHixdupTLly+za9cu7fFtbW2ZO3cubm5u9O3bFzc3Nx4+fMhHH32Eq6sro0ePxsTEhL179+rENWjQILp27YqHhwcLFizA2to6x163adOmERQUxPvvv4+rqytNmzZl7ty5fPvtt3n2vtepUwcvLy9WrlypLVuxYgVNmjShZs2aAMyYMYORI0fSo0cP3Nzc+OSTT6hfvz6zZ88GoHz58gDY2dnh6OiIra1tjuerV68eoaGhuLq60rt3b7y9vdmxYwcA4eHhnD9/nm+//RYvLy+aNWvGlClTco0/O8OHD6djx47UqlWLiRMncunSJc6dOwdA5cqVGT58OPXr16dGjRq89957tGvXjh9//FHnGK6urnz66ae4ubnh5ubGggULcHFxYebMmbi5uREUFERISEiesVy6dIlKlSplKV+yZAnt27enXLly2NraEhAQkG3Pel4yfyxwd3cv8L5vv/02kZGRuT6yix3g1q1bpKWl4eCgO5+Mg4MDMTExOZ7zjTfeYNKkSTRr1gxjY2NcXFxo1aqVztDfCxcusGDBAlxdXdm2bRvvvPMOgwcPZvny5TrHqlSpEleuXNGbNXuNSjsAfWJmZIaRgREp6SmYGJpkraDJyOuNAEMgOT0FIwMjzIyyDj0oDf/7X3XWrevGrFm/s359d6ysTEs7JFFCDAwMqFGjhkwEIvSStE+h76SN5l/r1q1ZsGCBTtnjSVS9evW0f7awsMDKykp7j90777xD165dOXLkCG3btqVLly40bdoUgL/++otz585haWmpc7zExESd3sk6derovFcODg7UrVtX+9zQ0BA7O7ss9/X5+vpq/2xkZIS3tzcnT57M9jr/+usv/v77b1asWKEtU0qRnp7OxYsX8fDwyHa/TEFBQSxZsoRx48ahlOKHH35g6NChANy9e5d///0XPz8/nX38/Pz466+/cjymqWn23+sefb0BKlasqL3206dP4+TkhKOjo3a7j49PrrHndY6KFSsCcOPGDdzd3UlLS2Pq1Kn8+OOPXL16leTkZJKSkihTpozOMRo1aqTz/OTJk1mGSD/6HuUkISEhy7DftLQ0li9fzpw5c7RlPXv2ZPjw4YwfP75Af7eVUnlXyoGtrW2uPyoUh127djF16lS+/PJLmjRpwrlz5xgyZAiTJ09m3LhxQMZQc29vb+2PSg0aNOD48eMsXLiQ4OBg7bHMzc1JT08nKSkJc3PzAsVRHJ+fkqg+opZdLe1w3ipWVbJsV/8lqpkpbOYwYTc7txKMMncdO9aiQwdXmWL/OaPRaLCykiHeQj9J+xT6Tl/a6LF3jhV6XwsTixy37emz54m+fOucx8JC2yuYE2NjY53nGo1G20PTvn17Ll26xJYtWwgPD+fFF19k4MCBzJgxg/v379OoUSOd5DBTZg9jTsfP7ZyFcf/+fQYMGMDgwYOzbKtatWqe+wcGBjJy5EiOHDlCQkICV65coXv37oWOR6PRZJnhNlNRX3te58j8jpl5js8++4w5c+Ywe/ZsPD09sbCw4P33388yYZKFRc5ttCDs7e2Ji4vTKdu2bRtXr17N8hqnpaWxY8cO2rRpA4ClpSV37tzJcsz4+Hisra0BqFWrFpBxb2+DBg0KFNvUqVOzjDB4XFRUVLZtyN7eHkNDQ65fv65Tfv36dZ0fGh43btw4evXqRf/+/QHw9PTkwYMHvPXWW4wZMwYDAwMqVqxI7dq1dfbz8PDIMqQ8NjYWCwuLAiepIMvTFDsrUyv8a/gTlxhHWno2M1f99waYAmnpacQnxtPGpQ2WppZZ65aAtWujmDw560QAkqQ+f9LS0jh27Fipz1gpRHakfQp9py9t1K6MXaEfuY3usjW3zXaf0lK+fHmCg4P5/vvvmT17NosWLQKgYcOGnD17lgoVKlCzZk2dR2YS8SR+//137Z9TU1M5fPhwjj2jDRs2JCoqKkscNWvWxMQkm1F3j6lSpQotW7ZkxYoVrFixgjZt2lChQsYcKFZWVlSqVIl9+/bp7LNv3z5tMpF5jsw2qZTi4cOHFJSbmxtXrlzRSX7++OOPAh8nN/v27ePll1+mZ8+eeHl5UaNGDc6cOZPnfh4eHlnuY330PcpJgwYNiIqK0ilbvHgxPXr0yDLMtkePHjrDu93c3Dh8+LDOvmlpafz111/aBLV+/frUrl2bmTNnZpvw57bG65MM/TUxMaFRo0baYduQ8WPAjh07cu1pfvjwYZbezMwfNTJ/oPLz8+P0ad05dc6cOUO1atV0yo4fP17g5DxTcXx+So/qYzq6dmTPpT2ciT1DGaOyPDBJQvPfm3zJIGN8uHF6Gmdiz1C9XHU61OyQ2+GKzbff/kWfPhtJT1eYmRkxYoRf3juJZ1ppf8ESIjfSPoW+kzaaP0lJSVnulzMyMtJOiJSX8ePH06hRI+rUqUNSUhKbN2/WJotBQUF89tlnvPzyy9oZcS9dusRPP/3Ehx9+SJUqWUe7FcT8+fNxdXXFw8ODzz//nLi4OPr27Ztt3ZEjR/LCCy8waNAg+vfvj4WFBVFRUYSHh/PFF1/k63xBQUGEhoaSnJzM559/rrNtxIgRhIaGameTXbp0KZGRkdre5AoVKmBubk5YWJh2ZuD8JMiPa9OmDS4uLgQHB/Ppp59y7949xo4dCxRdx4arqytr165l//79lCtXjlmzZnH9+vUsPXiPe/vtt5k5cyYjRoygf//+HD58OF9rxAYEBOjcW3nz5k1+/vlnNm3apDMEHKB379688sorxMbGYmtry9ChQ+nXrx/u7u60adOGBw8eMG/ePOLi4rQ9khqNhqVLl+Lv70/z5s0ZM2YM7u7u3L9/n59//plff/01xxmjn3To79ChQwkODsbb2xsfHx9mz57NgwcP6NOnj841Va5cmWnTpgHQqVMnZs2aRYMGDbRDf8eNG0enTp20CesHH3xA06ZNmTp1Kt26dePQoUMsWrRI+yNRpoiICNq2bVvo+Iua9Kg+prJVZUY3G01V66pciD9PmkE6qQaKVAPFQ6NEku/+w91bJ6lqXZXRzUZT2apyice4cOGfBAdvID09I4E+efJWkQ3pEUIIIYTISVhYGBUrVtR5NGvWLN/7m5iYMHr0aOrVq0eLFi0wNDTULodRpkwZ9uzZQ9WqVXn11Vfx8PCgX79+JCYmFsnQ7OnTpzN9+nS8vLzYu3cvmzZtyjHBrlevHrt37+bMmTM0b96cBg0aMH78+Bx7w7Lz2muvcfv2bR4+fKizpAzA4MGDGTp0KMOGDcPT05OwsDA2bdqEq6srkJH8z507l6+++opKlSpl2T+/DA0N2bBhA/fv36dx48b0799fO+tvdsu7FMbYsWNp2LAhAQEBtGrVCkdHx3zFW7VqVdatW8eGDRvw8vJi4cKFeQ6bhYwfAE6cOKHtIfz222+xsLDgxRdfzFL3xRdfxNzcnO+//x7IGJL9zTffsGTJEho1akS7du2IiYlhz549OpMY+fj48Oeff1KzZk3efPNNPDw86Ny5MydOnNBOeFUcunfvzowZMxg/fjz169cnMjKSsLAwndguX77MtWvXtM/Hjh3LsGHDGDt2LLVr16Zfv34EBATw1Vdfaes0btyY9evX88MPP1C3bl0mT57M7NmzCQoK0ta5evUq+/fv10mKS5tGPecZzt27d7G2tubOnTs6H4JX715l4q7JfHPk/99k0zQzzOp1oo1LGz6v2aFUktRZsw4wbNiv2ucDBzZm7tz2GBjIcN/nWeawNU9PzxzvYRGitEj7FPqupNtoYmIiFy9epHr16kWWLIhnm1KKhIQEzM3Nn7gndN++fTRr1oxz587prKP5NBkxYgR3797VScbEkxk5ciRxcXFZelkfldtnV1xcHLa2tllyqichPao5qGxVmf85+2OgDDBIB4N0sEu1x7nzYto3fLPEk1SlFJMn79ZJUj/8sCnz5kmSKjJmWnNzc5MZK4VekvYp9J20UfE0KOyPGuvXryc8PJzo6Gi2b9/OW2+9hZ+f31ObpELGuq7VqlXTm2VUngUVKlRg8uTJhd6/OD4/5RM5Lwo0//1nqswxNLWkXEmHoBSjR+9g/Phd2rJJk1oxfbq/TJwktApz74oQJUXap9B30kZFfkVERGRZS/bRR3Ep7He+e/fuMXDgQNzd3QkJCaFx48Zs3LgRyJilNqfraN++fVGGX6RsbGz46KOP5MelIjRs2LAsa7iWNplMqQDUf38ZbErwnOnpiiFDtvLFF/8/Q9vMmW0ZOjTvdabE8yM9PV2GVgq9Je1T6Dtpo6IgvL29iYyMLPHzZg79LajevXvTu3fvbLe9/fbbdOvWLdtthTmXeH4VR++2JKoFkP7fEFubEjznjRsP+OmnU9rnCxZ05O23vUswAiGEEEIIkcnc3DzPtWSfFk86S60QxUn6ywtAaUq+R9XRsSzbt/fC0bEsy5d3kSRVCCGEEEII8cyTHtUCUP/1qJb0PaoeHuU5e/Y9ypaV+2eEEEIIIYQQzz7pUS0AZWCAAWBZjOd4+DCFqVMjSE3VHectSarIjYGBAZ6enjKpgNBL0j6FvpM2Kp4Gcs+o0Gcy628pUxoNVhTfi3b3bhLt2n3PmDE7CQnZQFqaTLkt8i85Obm0QxAiR9I+hb6TNir0nVKqtEMQokRJoloASmNQbPenxsYm4O//LRERlwH4+ecznD8fV0xnE8+a9PR0Tp8+LeuJCb0k7VPoO2mj4mmQmJhY2iEIkaPi+PyURLUAlMagWO5PvX79Pq1aLeOPP/4FwM7OnN9+C6ZWLbtiOJsQQgghRMmLjo5Go9EUaGmXZcuWYWNjU+pxlJRWrVrx/vvvl3YYuTp9+jSOjo7cu3evtEN5ZvTo0YOZM2eWdhh6RxLVAlAGmiLvUf3nn7u0bLmMY8duABmz/O7aFULDhhWL+ExCCCGEEE/mypUr9O3bl0qVKmFiYkK1atUYMmQIt2/fznNfJycnrl27Rt26dfN9vu7du3PmzJknCblQWrVqhUajYdWqVTrls2fPxtnZWft82bJlaDQa2rVrp1MvPj4ejUbDrl27ijXOXbt2odFoiI+PL/C+U6ZMoWnTppQpU6ZAPwaMHj2a9957D0vLrLO2uLu7Y2pqSkxMTJZtzs7OzJ49O0v5hAkTqF+/vk5ZTEwM7733HjVq1MDU1BQnJyc6derEjh078h1nYaxZswZ3d3fMzMzw9PRky5Ytee6TlJTEmDFjqFatGqampjg7O7NkyRLt9hMnTtC1a1ecnZ3RaDTZvgZjx45lypQp3Llzpygv56kniWoBFPXQ34sX42jRYimnT2d8uDs5WbFnTwh161YowrOI54UsUi/0mbRPoe+kjebtwoULeHt7c/bsWX744QfOnTvHwoUL2bFjB76+vsTGxua4b3JyMoaGhjg6OmJklP9FJ8zNzalQoXS+F5mZmTF27FhSUlJyrWdkZMT27dv57bffSiiyopGcnMzrr7/OO++8k+99Ll++zObNmwkJCcmybe/evSQkJPDaa6+xfPnyQscVHR1No0aN2LlzJ5999hnHjh0jLCyM1q1bM3DgwEIfNy/79+8nMDCQfv36cfToUbp06UKXLl04fvx4rvt169aNHTt2sHjxYk6fPs0PP/yAm5ubdvvDhw+pUaMG06dPx9HRMdtj1K1bFxcXF77//vsivaannSSquahqXRXLZDNsEg2xSTSkfBmfIktUT5++RfPmS7l4MR4AF5dyRET0wdVVhvuKgjM0NMTT01O+aAm9JO1T6LvSbqN37sDevaX3yG8nzsCBAzExMeHXX3+lZcuWVK1alfbt27N9+3auXr3KmDFjtHWdnZ2ZPHkyvXv3xsrKirfeeivbIbebNm3C1dUVMzMzWrduzfLly3V6CB8f+pvZ+/bdd9/h7OyMtbU1PXr00BmGGhYWRrNmzbCxscHOzo6XXnqJ8+fPF/h9CQwMJD4+nq+//jrXehYWFvTt25dRo0YV6PgPHjygd+/elC1blooVK2Y79PO7777D29sbKysratSoQVBQEDduZIzCi46OpnXr1gCUK1cOjUajTSDz8xpMnDiRDz74AE9Pz3zH/OOPP+Ll5UXlypWzbFu8eDFvvPEGvXr10ulRLKh3330XjUbDoUOH6Nq1K7Vq1aJOnToMHTqU33//vdDHzcucOXNo164dI0aMwMPDg8mTJ9OwYUO++OKLHPcJCwtj9+7dbNmyBX9/f5ydnfH19cXPz09bp3Hjxnz22Wf06NEDU1PTHI/VqVOnLD34T5Pi+PyUdVRz0biSDw4PrCiTchcAJ6++RXaP6ogR4Vy9mvGh6uFhz/btvalUqTgXvhHPMqUU9+7dw9LSEo1GU9rhCKFD2qfQd6XdRo8dg+bNS/y0WhER0KxZ7nViY2PZtm0bU6ZMybJMiqOjI0FBQaxevZovv/xS+xrOmDGD8ePHExoamu0xL168yGuvvcaQIUPo378/R48eZfjw4XnGe/78eTZs2MDmzZuJi4ujW7duTJ8+nSlTpgAZCeDQoUOpV68e9+/fZ/z48bzyyitERkYWaAkNKysrxowZw6RJkwgODsbCwiLHuhMmTKBmzZqsXbuW1157LV/HHzFiBLt372bjxo1UqFCBjz76iCNHjugMg01JSWHy5MnUqlWLmJgYRowYQUhICFu2bMHJyYl169bRtWtXTp8+jZWVlfa9KarX4HERERF4e3tnKb937x5r1qzh4MGDuLu7c+fOHSIiImhewIYdGxtLWFgYU6ZMyfb1zm2I8ooVKxgwYECux9+6dWuOMR04cIChQ4fqlAUEBLBhw4Ycj7dp0ya8vb359NNP+e6777CwsKBz585Mnjy5wMsJ+fj4MGXKFJKSknJNaPVVccxKLYlqAaSYmhRZj+qyZV1o3Xo5BgYafv21J+XL5/zhJ0Re0tPTuXDhgvRaCb0k7VPoO2mjeTt79ixKKTw8PLLd7uHhQVxcHDdv3tQO1f3f//7HsGHDtHWio6N19vnqq69wc3Pjs88+A8DNzY3jx49rE86cpKens2zZMu09kr169WLHjh3a/bp27apTf8mSJZQvX56oqKgC3R8LGb17c+bMYdasWYwbNy7HepUqVWLIkCGMGTOGLl265Hnc+/fvs3jxYr7//ntefPFFAJYvX06VKlV06vXt2xfISAIqVqzInDlz8PHx4f79+5QtWxZbW1sAKlSooJPEFeVr8KhLly5lm6iuWrUKV1dX6tSpA2RMDrR48eICJ6rnzp1DKYW7u3uBY+vcuTNNmjTJtU52PcGZYmJicHBw0ClzcHDI9n7bTBcuXGDv3r2YmZmxfv16bt26xbvvvsvt27dZunRpgeKvVKkSycnJxMTEUK1atQLtqw9k1t9SlmZiWmSJqq2tOeHhvdi5s7ckqUIIIYR4KhSk1yS7hOZRp0+fpnHjxjplPj4+eR7X2dlZZyKfihUraofDQkZSHRgYSI0aNbCystJOfnT58uV8x57J1NSUSZMmMWPGDG7dupVr3ZEjR3Lz5s18DXs9f/48ycnJOomVra2tzr2NAIcPH6ZTp05Uq1YNBwcHWrVqla9rKcrX4FEJCQmYmZllKV+yZAk9e/bUPu/Zsydr1qwp8MzAT9IrZ2lpSc2aNXN9FLSXMy/p6eloNBpWrFiBj48PHTp0YNasWSxfvpyEhIQCHSsztocPHxZpjE8z6VHNyyN/X5LMCt+jumfPJerWrYCt7f//BalQQRJUIYQQ4nnn6Zkx/LY0z5+XmjVrotFoOHnyJK+88kqW7SdPnqRcuXKUL19eW5bbUNknYWxsrPNco9Ho9OZkJnZff/01lSpVIj09nbp165KcnFyo8/Xs2ZMZM2bw8ccf68z4+zgbGxtGjx7NxIkTeemllwp1rkc9ePCAgIAAAgIC+P7777G0tOTGjRu0a9cuz2sp6tcgk729PXFxcTplUVFR/P777xw6dIiRI0dqy9PS0li1ahVvvvkmkDGUOrtZbePj47G2tgbA1dUVjUbDqVOnChzbkw79dXR05Pr16zpl169fz3ECJMj4kaRy5cra+CFjdIFSin/++QdXV9d8x585Gdmjf4eed5Ko5kHzSKaaYlq4HtVNm07z+utr8PJyYPv23lhZPX3jzoX+y+4XTiH0hbRPoe9Ks41aW+d9j2hps7Ozo02bNnz55Zd88MEHOj1TMTExrFixgt69exfoHl83N7csy3/88ccfTxTn7du3OX36NF9//bU2Idm7d+8THdPAwIBp06bx6quv5jlD7nvvvcfcuXOZM2dOrvVcXFwwNjbm4MGDVK1aFYC4uDjOnDlDy5YtATh16hS3b99m+vTpVKlShcTExCwz0JqYmAAZSWGm4ngNMjVo0ICoqCidssWLF9OiRQvmz5+vU7506VIWL16sTVTd3Nw4fPhwlmMeOXJE25Nsa2tLQEAA8+fPZ/DgwVl+7IiPj8/xPtUnHfrr6+vLjh07dNaxDQ8Px9fXN8d9/Pz8WLNmjXYoNsCZM2cwMDDIMow7L8ePH6dKlSrY29sXaL9nmQz9zdMjiaqZeYET1VWrjvPqq6tJTk7jjz/+5fPPDxRpdEJAxkxr7u7ucm+V0EvSPoW+kzaaP1988QVJSUkEBASwZ88erly5QlhYGG3atKFy5cp53lv6uAEDBnDq1ClGjhzJmTNn+PHHH1m2bBlAoSe1KleuHHZ2dixatIhz586xc+fOLBPkFEbHjh1p0qQJX331Va71zMzMmDhxInPnzs21XtmyZenXrx8jRoxg586dHD9+nJCQEJ2JjqpWrYqJiQnz5s3j4sWLhIeH8/HHH+scp1q1amg0GjZv3szNmze5f/9+vl+Dy5cvExkZyeXLl0lLSyMyMpLIyEju37+fY9wBAQEcOHBAmxinpKTw3XffERgYSN26dXUe/fv35+DBg5w4cQKADz74gF9++YUpU6Zw8uRJjh8/zpgxYzhw4ABDhgzRnmP+/PmkpaXh4+PDunXrOHv2LCdPnmTu3Lm5Jo1POvR3yJAhhIWFMXPmTE6dOsWECRP4888/GTRokLbO6NGj6d27t/b5G2+8gZ2dHX369CEqKoo9e/YwYsQI+vbtqz1XcnKy9rVNTk7m6tWrREZGcu7cOZ3zR0RE0LZt2xzj03fF8vmpnnN37txRgLpz506WbbvO71VWo8yU7YeGyvZDQ+W4crRKL8CxFy8+ojSaCQoyHj17/qRSUtKKLngh/pOWlqZu3bql0tKkfQn9I+1T6LuSbqMJCQkqKipKJSQklMj5ilJ0dLQKDg5WDg4OytjYWDk5Oan33ntP3bp1S6detWrV1Oeff65TdvHiRQWoo0ePass2btyoatasqUxNTVWrVq3UggULFKB9bZYuXaqsra219UNDQ5WXl5fOcT///HNVrVo17fPw8HDl4eGhTE1NVb169dSuXbsUoNavX59jHI9r2bKlGjJkiE7Z/v37FaBzrsfjU0qp1NRUVbt2bQWo3377Lcdz3Lt3T/Xs2VOVKVNGOTg4qE8//TTLeVeuXKmcnZ2VqampeuGFF9TGjRuzxD5p0iTl6OioNBqNCg4OztdroJRSwcHBioweGZ1HbjGnpKSoSpUqqbCwMKWUUmvXrlUGBgYqJiYm2/oeHh7qgw8+0D7ftm2b8vPzU+XKlVN2dnaqVatWavfu3Vn2+/fff9XAgQNVtWrVlImJiapcubLq3LlzrrEVhR9//FHVqlVLmZiYqDp16qhffvlFZ3twcLBq2bKlTtnJkyeVv7+/Mjc3V1WqVFFDhw5VDx8+1G7PbG+PPx49TkJCgrK2tlYHDhwozst7Yrl9dsXFxeWYUxWWRqlimEv4KXL37l2sra25c+cOVlZWOttW/b2WXmu7k9mrau7oz913f83Xcb/44hDvvbdV+/yttxqyYMFLGBjI0gyi6KWlpXHs2DGZsVLoJWmfQt+VdBtNTEzk4sWLVK9eXYbFP2bKlCksXLiQK1eulHYoekUpRUJCAubm5qW+zNf8+fPZtGkT27ZtK9U4niULFixg/fr1/Ppr/vKM0pLbZ1dcXBy2trbZ5lSFJfeoFoAB+ftg+PTTfYwcuV37/P33mzBrVkCpf7AIIYQQQuiTL7/8ksaNG2NnZ8e+ffv47LPPdIZaCv0zYMAA4uPjtWsPiydnbGzMvHnzSjsMvSOJah40KIzSFSgoe+8O3L0LOfxKoJQiNHQXkyfv0ZaNGdOcyZNbS5IqhBBCCPGYs2fP8vHHHxMbG0vVqlUZNmwYo0ePLu2wRC6MjIwYM2ZMaYfxTOnfv39ph6CXJFHNydWraHaEY5mkMPhvcHTVS2egf3/w94eOHeGxmcNWrTquk6ROnfo/Ro8u2ELHQhSW/Kop9Jm0T6HvpI2Wjs8//5zPP/+8tMN4Kjw60ZIQzwNp8dk5cQJGjkSzexcaIE0DaQaQbGoODx7A8uUwcmRGvUe8/nodXn3VA4A5c9pJkipKjKGhIS4uLnL/n9BL0j6FvpM2KvSdRqPBzMxMRugJvVUcn5+SqD7u6lWYNg0uX4YqVUjXwP/fmqqBKlXAwyNj+7RpGfX/Y2RkwA8/dGXLljcYPDj3dZyEKErp6enExMToLHguhL6Q9in0XWm10ed8PktRAEopUlJSpM2IUpVb+yuOz09JVB/3yy9w4QLUqgWPDbHQZL43hoZQqxbp5y9w67t1OnVMTAxp3961hIIVIoNSipiYGPkHTOglaZ9C35V0G83seUhOTi6R84lnQ0pKSmmHIJ5zDx8+BDImf3pccXx+yj2qj7p7F7Zvh3LlMpLRxzw62CJVaThyPoGYiUuo2/5lanhVK7k4hRBCCPHUMjIyokyZMty8eRNjY2O591DkSSlFUlISGo1Ghv+KEqeU4uHDh9y4cQMbG5sSu01CEtVHnTkDN25A9eraojsGkG4MaOAP46u8GLOcsDI9Cdt2nps3oQbxfPjyfFadm46RkfxDI4QQQojcaTQaKlasyMWLF7l06VJphyOeAplDf42NjSVRFaXGxsYGR0fHEjufJKqPSkyE1FQwNsbefBG3rdHtRjWEne5JmKjF2L0OU+Y0xMQAxgxrLEmqKFUajQZbW1v5x0voJWmfQt+VRhs1MTHB1dVVhv+KfMm8j9rR0VF64EWpMDY2zrUntTg+PyVRfZSZGRgZYVjha9Jze2U0cNsG3h1zhNgtL2DtWz2XykIUPwMDA6pWrVraYQiRLWmfQt+VVhs1MDDAzMysxM8rnk41atQo7RCEyFFx/ICilz/JzJ8/H2dnZ8zMzGjSpAmHDh3Ktf6aNWtwd3fHzMwMT09PtmzZUrgT16qFff3duSepj0g3ApcWv4ObW+HOJ0QRSU9P5/LlyzKrqtBL0j6FvpM2KvSdtFGh756LWX9Xr17N0KFDCQ0N5ciRI3h5eREQEMCNGzeyrb9//34CAwPp168fR48epUuXLnTp0oXjx48X/ORWVhnDfQvgtjUgi4SLUqaUIjY2VmZVFXpJ2qfQd9JGhb6TNir0XXG0Tb1LVGfNmsWbb75Jnz59qF27NgsXLqRMmTIsWbIk2/pz5syhXbt2jBgxAg8PDyZPnkzDhg354osvCnzuFn0q696Tmh8aeDHEucDnEkIIIYQQQgiRPb26RzU5OZnDhw8zevRobZmBgQH+/v4cOHAg230OHDjA0KFDdcoCAgLYsGFDtvWTkpJISkrSPr9z5w4AcXFxRFT5t1Bx73S6xN27d0lLS9MpNzAwQKPRZFsOWbvIcyo3NDREKZVteXp6epZfMLIr12g0GBgY5Fj+eIw5lcs16ec1JScnc+/ePeLi4jA0NHwmrulZfJ+e12tKS0vj3r173LlzJ8tkC0/rNeUWu1zT03dNmW00Li4OExOTZ+KaHo9RrunpvqaUlBSdf+efhWt6Ft+n5/maMnOqouxZ1atE9datW6SlpeHg4KBT7uDgwKlTp7LdJyYmJtv6MTEx2dafNm0aEydOzFLu7OwMYwsXN4C1dQHHDAshhBBCCCHEM+T27dtFlhfpVaJaEkaPHq3TA5uenk5sbCx2dnY5Tqt89+5dnJycuHLlClZWVtkfeERxRCtE/uSrjQpRSqR9Cn0nbVToO2mjQt/duXOHqlWrYmtrW2TH1KtE1d7eHkNDQ65fv65Tfv369RwXl3V0dCxQfVNTU0xNTXXKbGxs8hWflZWVfDgIvSZtVOgzaZ9C30kbFfpO2qjQd0W5TI1eTaZkYmJCo0aN2LFjh7YsPT2dHTt24Ovrm+0+vr6+OvUBwsPDc6wvhBBCCCGEEEK/6VWPKsDQoUMJDg7G29sbHx8fZs+ezYMHD+jTpw8AvXv3pnLlykybNg2AIUOG0LJlS2bOnEnHjh1ZtWoVf/75J4sWLSrNyxBCCCGEEEIIUUh6l6h2796dmzdvMn78eGJiYqhfvz5hYWHaCZMuX76s06XctGlTVq5cydixY/noo49wdXVlw4YN1K1bt8hiMjU1JTQ0NMuQYSH0hbRRoc+kfQp9J21U6Dtpo0LfFUcb1ShZOVgIIYQQQgghhB7Rq3tUhRBCCCGEEEIISVSFEEIIIYQQQugVSVSFEEIIIYQQQugVSVSFEEIIIYQQQugVSVT/M3/+fJydnTEzM6NJkyYcOnQo1/pr1qzB3d0dMzMzPD092bJlSwlFKp5HBWmfX3/9Nc2bN6dcuXKUK1cOf3//PNuzEE+qoJ+hmVatWoVGo6FLly7FG6B47hW0jcbHxzNw4EAqVqyIqakptWrVkn/rRbEqaBudPXs2bm5umJub4+TkxAcffEBiYmIJRSueJ3v27KFTp05UqlQJjUbDhg0b8txn165dNGzYEFNTU2rWrMmyZcsKfF5JVIHVq1czdOhQQkNDOXLkCF5eXgQEBHDjxo1s6+/fv5/AwED69evH0aNH6dKlC126dOH48eMlHLl4HhS0fe7atYvAwEB+++03Dhw4gJOTE23btuXq1aslHLl4XhS0jWaKjo5m+PDhNG/evIQiFc+rgrbR5ORk2rRpQ3R0NGvXruX06dN8/fXXVK5cuYQjF8+LgrbRlStXMmrUKEJDQzl58iSLFy9m9erVfPTRRyUcuXgePHjwAC8vL+bPn5+v+hcvXqRjx460bt2ayMhI3n//ffr378+2bdsKdmIllI+Pjxo4cKD2eVpamqpUqZKaNm1atvW7deumOnbsqFPWpEkTNWDAgGKNUzyfCto+H5eamqosLS3V8uXLiytE8ZwrTBtNTU1VTZs2Vd98840KDg5WL7/8cglEKp5XBW2jCxYsUDVq1FDJycklFaJ4zhW0jQ4cOFD973//0ykbOnSo8vPzK9Y4hQDU+vXrc63z4Ycfqjp16uiUde/eXQUEBBToXM99j2pycjKHDx/G399fW2ZgYIC/vz8HDhzIdp8DBw7o1AcICAjIsb4QhVWY9vm4hw8fkpKSgq2tbXGFKZ5jhW2jkyZNokKFCvTr168kwhTPscK00U2bNuHr68vAgQNxcHCgbt26TJ06lbS0tJIKWzxHCtNGmzZtyuHDh7XDgy9cuMCWLVvo0KFDicQsRG6KKlcyKsqgnka3bt0iLS0NBwcHnXIHBwdOnTqV7T4xMTHZ1o+JiSm2OMXzqTDt83EjR46kUqVKWT4whCgKhWmje/fuZfHixURGRpZAhOJ5V5g2euHCBXbu3ElQUBBbtmzh3LlzvPvuu6SkpBAaGloSYYvnSGHa6BtvvMGtW7do1qwZSilSU1N5++23Zeiv0As55Up3794lISEBc3PzfB3nue9RFeJZNn36dFatWsX69esxMzMr7XCE4N69e/Tq1Yuvv/4ae3v70g5HiGylp6dToUIFFi1aRKNGjejevTtjxoxh4cKFpR2aEEDGfBRTp07lyy+/5MiRI/z000/88ssvTJ48ubRDE6LIPPc9qvb29hgaGnL9+nWd8uvXr+Po6JjtPo6OjgWqL0RhFaZ9ZpoxYwbTp09n+/bt1KtXrzjDFM+xgrbR8+fPEx0dTadOnbRl6enpABgZGXH69GlcXFyKN2jxXCnM52jFihUxNjbG0NBQW+bh4UFMTAzJycmYmJgUa8zi+VKYNjpu3Dh69epF//79AfD09OTBgwe89dZbjBkzBgMD6YsSpSenXMnKyirfvakgPaqYmJjQqFEjduzYoS1LT09nx44d+Pr6ZruPr6+vTn2A8PDwHOsLUViFaZ8An376KZMnTyYsLAxvb++SCFU8pwraRt3d3Tl27BiRkZHaR+fOnbUzAzo5OZVk+OI5UJjPUT8/P86dO6f9EQXgzJkzVKxYUZJUUeQK00YfPnyYJRnN/GElY74bIUpPkeVKBZvn6dm0atUqZWpqqpYtW6aioqLUW2+9pWxsbFRMTIxSSqlevXqpUaNGaevv27dPGRkZqRkzZqiTJ0+q0NBQZWxsrI4dO1ZalyCeYQVtn9OnT1cmJiZq7dq16tq1a9rHvXv3SusSxDOuoG30cTLrryhuBW2jly9fVpaWlmrQoEHq9OnTavPmzapChQrq448/Lq1LEM+4grbR0NBQZWlpqX744Qd14cIF9euvvyoXFxfVrVu30roE8Qy7d++eOnr0qDp69KgC1KxZs9TRo0fVpUuXlFJKjRo1SvXq1Utb/8KFC6pMmTJqxIgR6uTJk2r+/PnK0NBQhYWFFei8kqj+Z968eapq1arKxMRE+fj4qN9//127rWXLlio4OFin/o8//qhq1aqlTExMVJ06ddQvv/xSwhGL50lB2me1atUUkOURGhpa8oGL50ZBP0MfJYmqKAkFbaP79+9XTZo0UaampqpGjRpqypQpKjU1tYSjFs+TgrTRlJQUNWHCBOXi4qLMzMyUk5OTevfdd1VcXFzJBy6eeb/99lu23y0z22RwcLBq2bJlln3q16+vTExMVI0aNdTSpUsLfF6NUjI+QAghhBBCCCGE/nju71EVQgghhBBCCKFfJFEVQgghhBBCCKFXJFEVQgghhBBCCKFXJFEVQgghhBBCCKFXJFEVQgghhBBCCKFXJFEVQgghhBBCCKFXJFEVQgghhBBCCKFXJFEVQgghhBBCCKFXJFEVQghRbHbt2oVGo2HXrl2lHUqx0mg0TJgwIV91nZ2dCQkJKdZ4nhXvvvsubdq0Ke0wAEhJScHJyYkvv/yytEMRQojngiSqQgghsli2bBkajSbbx6hRo0o7vFw9HruZmRm1atVi0KBBXL9+vURi2L9/PxMmTCA+Pr5Ezpcfzs7OOq+LhYUFPj4+fPvtt4U+5pYtW/KdoBfUxYsX+eabb/joo4+0ZdHR0Tm2yxdeeEFbLyQkRGeblZUVXl5ezJw5k6SkJG29CRMm6NQzNjbG2dmZwYMHZ3nvjI2NGTp0KFOmTCExMbFYrlkIIcT/MyrtAIQQQuivSZMmUb16dZ2yunXrllI0BZMZe2JiInv37mXBggVs2bKF48ePU6ZMmSI9V0JCAkZG//9P6v79+5k4cSIhISHY2Njo1D19+jQGBqXzO3H9+vUZNmwYANeuXeObb74hODiYpKQk3nzzzQIfb8uWLcyfP79YktU5c+ZQvXp1WrdunWVbYGAgHTp00CkrX768znNTU1O++eYbAOLj41m3bh3Dhw/njz/+YNWqVTp1FyxYQNmyZXnw4AE7duxg3rx5HDlyhL179+rU69OnD6NGjWLlypX07du3KC5TCCFEDiRRFUIIkaP27dvj7e1d2mEUyqOx9+/fHzs7O2bNmsXGjRsJDAws0nOZmZnlu66pqWmRnrsgKleuTM+ePbXPQ0JCqFGjBp9//nmhEtXikpKSwooVK3j77bez3d6wYUOd68iOkZGRTp13332XJk2asHr1ambNmkWlSpW021577TXs7e0BGDBgAD169GD16tUcOnQIHx8fbT0bGxvatm3LsmXLJFEVQohiJkN/hRBCFNilS5d49913cXNzw9zcHDs7O15//XWio6Pz3Pfs2bN07doVR0dHzMzMqFKlCj169ODOnTs69b7//nsaNWqEubk5tra29OjRgytXrhQ65v/9739AxpBSgNTUVCZPnoyLiwumpqY4Ozvz0Ucf6QwNBfjzzz8JCAjA3t4ec3NzqlevniVJefQe1QkTJjBixAgAqlevrh1WmvnaPHqP6p9//olGo2H58uVZ4t22bRsajYbNmzdry65evUrfvn1xcHDA1NSUOnXqsGTJkkK/JuXLl8fd3Z3z58/rlEdERPD6669TtWpVTE1NcXJy4oMPPiAhIUFbJyQkhPnz52uvP/ORKT09ndmzZ1OnTh3MzMxwcHBgwIABxMXF5RnX3r17uXXrFv7+/oW+tscZGBjQqlUrgDzbafPmzQGyvC4Abdq0Ye/evcTGxhZZbEIIIbKSHlUhhBA5unPnDrdu3dIps7e3548//mD//v306NGDKlWqEB0dzYIFC2jVqhVRUVE5Dq1NTk4mICCApKQk3nvvPRwdHbl69SqbN28mPj4ea2trAKZMmcK4cePo1q0b/fv35+bNm8ybN48WLVpw9OjRLMNp8yMz6bCzswMyelmXL1/Oa6+9xrBhwzh48CDTpk3j5MmTrF+/HoAbN27Qtm1bypcvz6hRo7CxsSE6Opqffvopx/O8+uqrnDlzhh9++IHPP/9c21P3+NBUAG9vb2rUqMGPP/5IcHCwzrbVq1dTrlw5AgICALh+/TovvPACGo2GQYMGUb58ebZu3Uq/fv24e/cu77//foFfk9TUVP755x/KlSunU75mzRoePnzIO++8g52dHYcOHWLevHn8888/rFmzBsjoefz3338JDw/nu+++y3LsAQMGsGzZMvr06cPgwYO5ePEiX3zxBUePHmXfvn0YGxvnGNf+/fvRaDQ0aNAg2+0PHz7M0i6tra1zPSZkbQM5yUxkH39dABo1aoRSiv379/PSSy/lehwhhBBPQAkhhBCPWbp0qQKyfSil1MOHD7Psc+DAAQWob7/9Vlv222+/KUD99ttvSimljh49qgC1Zs2aHM8dHR2tDA0N1ZQpU3TKjx07poyMjLKU5xT79u3b1c2bN9WVK1fUqlWrlJ2dnTI3N1f//POPioyMVIDq37+/zr7Dhw9XgNq5c6dSSqn169crQP3xxx+5nhNQoaGh2uefffaZAtTFixez1K1WrZoKDg7WPh89erQyNjZWsbGx2rKkpCRlY2Oj+vbtqy3r16+fqlixorp165bO8Xr06KGsra2zfU8eP2/btm3VzZs31c2bN9WxY8dUr169FKAGDhyoUze7Y02bNk1pNBp16dIlbdnAgQNVdl8lIiIiFKBWrFihUx4WFpZt+eN69uyp7OzsspRfvHgxx3aZ2caUUio4OFhZWFhor/XcuXNq6tSpSqPRqHr16mnrhYaGKkCdPn1a3bx5U0VHR6slS5Yoc3NzVb58efXgwYMsMfz7778KUJ988kmu1yCEEOLJSI+qEEKIHM2fP59atWplKTc3N9f+OSUlhbt371KzZk1sbGw4cuQIvXr1yvZ4mT2m27Zto0OHDtn2vP7000+kp6fTrVs3nV4zR0dHXF1d+e2333Rmgs3J48NGq1WrxooVK6hcubJ2ptuhQ4fq1Bk2bBgzZszgl19+oXXr1tqe282bN+Pl5ZVnj11hdO/enWnTpvHTTz/Rr18/AH799Vfi4+Pp3r07AEop1q1bR7du3VBK6bwuAQEBrFq1iiNHjuDn55fruX799dcsPbt9+vThs88+0yl79P198OABCQkJNG3aFKUUR48epWrVqrmeZ82aNVhbW9OmTRudWBs1akTZsmX57bffeOONN3Lc//bt29n2ZmZ66623eP3113XKvLy8dJ4/ePAgy7U2bdo0295fNzc3neeenp4sXbo02/aZGdfjPbpCCCGKliSqQgghcuTj45PtZEoJCQlMmzaNpUuXcvXqVZRS2m2P32v6qOrVqzN06FBmzZrFihUraN68OZ07d6Znz57aJPbs2bMopXB1dc32GPlNFjOTbCMjIxwcHHBzc9POtnvp0iUMDAyoWbOmzj6Ojo7Y2Nhw6dIlAFq2bEnXrl2ZOHEin3/+Oa1ataJLly688cYbRTYpkpeXF+7u7qxevVqbqK5evRp7e3vtfbU3b94kPj6eRYsWsWjRomyPc+PGjTzP1aRJEz7++GPS0tI4fvw4H3/8MXFxcZiYmOjUu3z5MuPHj2fTpk1Z7inN7f3NdPbsWe7cuUOFChUKHeujbepxrq6ued6/amZmxs8//wxkTGBVvXp1qlSpkm3ddevWYWVlxc2bN5k7dy4XL17USdazi+vR+3GFEEIUPUlUhRBCFNh7773H0qVLef/99/H19cXa2hqNRkOPHj1IT0/Pdd+ZM2cSEhLCxo0b+fXXXxk8eDDTpk3j999/p0qVKqSnp6PRaNi6dSuGhoZZ9i9btmy+YswpyX5UXsmGRqNh7dq1/P777/z8889s27aNvn37MnPmTH7//fd8x5KX7t27M2XKFG7duoWlpSWbNm0iMDBQu+RN5mvas2fPLPeyZqpXr16e57G3t9cmeAEBAbi7u/PSSy8xZ84cbe9yWloabdq0ITY2lpEjR+Lu7o6FhQVXr14lJCQkz/c3M94KFSqwYsWKbLdnd7/uo+zs7PI16VJuDA0N8z0ZU4sWLbT3Enfq1AlPT0+CgoI4fPhwlqWEMuPKrC+EEKJ4SKIqhBCiwNauXUtwcDAzZ87UliUmJhIfH5+v/T09PfH09GTs2LHs378fPz8/Fi5cyMcff4yLiwtKKapXr57tsOOiUK1aNdLT0zl79iweHh7a8uvXrxMfH0+1atV06r/wwgu88MILTJkyhZUrVxIUFMSqVavo379/tscvaG9b9+7dmThxIuvWrcPBwYG7d+/So0cP7fby5ctjaWlJWlpakc6E27FjR1q2bMnUqVMZMGAAFhYWHDt2jDNnzrB8+XJ69+6trRseHp5l/5yu08XFhe3bt+Pn55djz2Ru3N3dWbFiBXfu3NH2tJeUsmXLEhoaSp8+ffjxxx913gf4/1mjH203Qgghip4sTyOEEKLADA0NswzNnDdvHmlpabnud/fuXVJTU3XKPD09MTAw0C4L8+qrr2JoaMjEiROznEMpxe3bt584/g4dOgAwe/ZsnfJZs2YBGQkcZPSePR5D/fr1AbIsY/MoCwsLgHwn7h4eHnh6erJ69WpWr15NxYoVadGihXa7oaEhXbt2Zd26dRw/fjzL/jdv3szXebIzcuRIbt++zddff609F+gOvVVKMWfOnCz75nSd3bp1Iy0tjcmTJ2fZJzU1Nc/XxdfXF6UUhw8fLsilFJmgoCCqVKnCJ598kmXb4cOH0Wg0+Pr6lkJkQgjx/JAeVSGEEAX20ksv8d1332FtbU3t2rU5cOAA27dvz3PZj507dzJo0CBef/11atWqRWpqKt999502EYOM3riPP/6Y0aNHEx0dTZcuXbC0tOTixYusX7+et956i+HDhz9R/F5eXgQHB7No0SLi4+Np2bIlhw4dYvny5XTp0oXWrVsDsHz5cr788kteeeUVXFxcuHfvHl9//TVWVlbaZDc7jRo1AmDMmDH06NEDY2NjOnXqpE3sstO9e3fGjx+PmZkZ/fr1yzLkdPr06fz22280adKEN998k9q1axMbG8uRI0fYvn17odf1bN++PXXr1mXWrFkMHDgQd3d3XFxcGD58OFevXsXKyop169ZlOxQ38zoHDx5MQEAAhoaG9OjRg5YtWzJgwACmTZtGZGQkbdu2xdjYmLNnz7JmzRrmzJnDa6+9lmNMzZo1w87Oju3bt2vv0y1JxsbGDBkyhBEjRhAWFka7du2028LDw/Hz88uzrQshhHhCpTDTsBBCCD2XucRLTsuyxMXFqT59+ih7e3tVtmxZFRAQoE6dOpVl6ZXHl6e5cOGC6tu3r3JxcVFmZmbK1tZWtW7dWm3fvj3LOdatW6eaNWumLCwslIWFhXJ3d1cDBw5Up0+ffqLYM6WkpKiJEyeq6tWrK2NjY+Xk5KRGjx6tEhMTtXWOHDmiAgMDVdWqVZWpqamqUKGCeumll9Sff/6pcyweW55GKaUmT56sKleurAwMDHSWqnn8Ncp09uxZ7VIre/fuzTbm69evq4EDByonJydlbGysHB0d1YsvvqgWLVqU67Vmnrdjx47Zblu2bJkC1NKlS5VSSkVFRSl/f39VtmxZZW9vr9588031119/6dRRSqnU1FT13nvvqfLlyyuNRpNlqZpFixapRo0aKXNzc2Vpaak8PT3Vhx9+qP7999884x08eLCqWbOmTlnm8jSfffZZrvtmLk+Tl8zlaW7evJll2507d5S1tbVq2bKltiw+Pl6ZmJiob775Js9jCyGEeDIapXKZVk8IIYQQohRcuHABd3d3tm7dyosvvlja4QAZQ8U//fRTzp8/X6h7b4UQQuSfJKpCCCGE0EvvvPMO586dy3Yip5KWkpKCi4sLo0aN4t133y3tcIQQ4pkniaoQQgghhBBCCL0is/4KIYQQQgghhNArkqgKIYQQQgghhNArkqgKIYQQQgghhNArkqgKIYQQQgghhNArkqgKIYQQQgghhNArkqgKIYQQQgghhNArkqgKIYQQQgghhNArkqgKIYQQQgghhNArkqgKIYQQQgghhNArkqgKIYQQQgghhNAr/wdznxfSUNL/jAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "results_lists.append(ensemble_results_soft)\n",
    "results_lists.append(ensemble_results_hard)\n",
    "\n",
    "\n",
    "# --- Plot the final comparison ---\n",
    "print(\"\\n--- Plotting all ROC curves for comparison ---\")\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\", \"Ensemble_voting_soft\", \"Ensemble_voting_hard\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54a198",
   "metadata": {},
   "source": [
    "## Check performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ba0e7",
   "metadata": {},
   "source": [
    "## Check performance on test1 and test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f504bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_performance_tester(classifier_list, test_loader):\n",
    "\n",
    "    list_weighted_clfs = []  # Reset the list for final testing\n",
    "    for i, model_info in enumerate(classifier_list):\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "\n",
    "        model = model_info[\"model\"]\n",
    "        raw_threshold = model_info[\"threshold\"]\n",
    "\n",
    "\n",
    "        # CORRECTED: Use isinstance() to check if model is a string\n",
    "        if isinstance(model, str):\n",
    "            print(f\"Skipping model {i+1} as it is a string placeholder: '{model}'\")\n",
    "            continue\n",
    "\n",
    "        # Check if the stored threshold is a NumPy number or a PyTorch Tensor\n",
    "        if isinstance(raw_threshold, (np.number, torch.Tensor)):\n",
    "            # If it is, we can safely call .item() to extract the Python float\n",
    "            threshold = raw_threshold.item()\n",
    "        else:\n",
    "            # Otherwise, it's already a float or something that can be cast to one\n",
    "            threshold = float(raw_threshold)\n",
    "        model.current_test_threshold = threshold  # Set the threshold for this model\n",
    "\n",
    "        # This code will now only run if 'model' is a PyTorch Lightning module\n",
    "        # and not a string.\n",
    "        print(f\"--- Testing model {i+1} ---\")\n",
    "\n",
    "        trainer.test(model, dataloaders=test_loader, ckpt_path=None)\n",
    "        \n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "\n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not list_weighted_clfs or list_weighted_clfs[0]['fpr'] > 0.0:\n",
    "        list_weighted_clfs.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if list_weighted_clfs[-1]['fpr'] < 1.0 or list_weighted_clfs[-1]['tpr'] < 1.0:\n",
    "        list_weighted_clfs.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return list_weighted_clfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLlabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
