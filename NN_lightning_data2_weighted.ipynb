{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33420fde",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d11cd5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d840881",
   "metadata": {},
   "source": [
    "## Display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c24af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for displaying ROC curves of multiple classifiers\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_connected_points(results_list, results_original_roc, name=\"All Classifiers\"):\n",
    "    \"\"\"\n",
    "    Creates a plot showing the performance of all classifiers as points,\n",
    "    and connects them with a line, sorted by FPR.\n",
    "\n",
    "    Args:\n",
    "        results_list: A list of dictionaries, where each dict contains 'fpr', 'tpr'.\n",
    "    \"\"\"\n",
    "    if not results_list:\n",
    "        print(\"No results to plot.\")\n",
    "        return\n",
    "\n",
    "    # Convert results to a pandas DataFrame for easy sorting\n",
    "    df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Sort the models by their False Positive Rate to create a left-to-right line\n",
    "    df_sorted = df.sort_values(by='fpr').reset_index(drop=True)\n",
    "    \n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot all the individual model points as a scatter plot\n",
    "    # This helps see the actual performance of each model\n",
    "    plt.scatter(df_sorted['fpr'], df_sorted['tpr'], c='black', marker='o', \n",
    "                alpha=0.6, s=100, zorder=3) # zorder=3 puts dots on top\n",
    "\n",
    "    # Plot the line connecting the points\n",
    "    plt.plot(df_sorted['fpr'], df_sorted['tpr'], color='red', lw=1.5,\n",
    "             alpha=0.8, label=f'{name} (AUC = {auc(df_sorted[\"fpr\"], df_sorted[\"tpr\"]):.2f})')\n",
    "    \n",
    "    #plot the original ROC curve\n",
    "    plt.plot(results_original_roc[\"fpr\"], results_original_roc[\"tpr\"], color='blue', \n",
    "             label=f'{results_original_roc[\"name\"]} (AUC = {results_original_roc[\"auc\"]:.2f})')\n",
    "\n",
    "    # Plot the \"no-skill\" line for reference\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Performance Path of All Trained Classifiers')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23b1ea",
   "metadata": {},
   "source": [
    "## Best ROC envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e350c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def get_best_roc_envelope(results_list, results_original_roc=None):\n",
    "    \"\"\"\n",
    "    Constructs the upper envelope of multiple ROC curves to find the best\n",
    "    possible operating points from a collection of classifiers.\n",
    "\n",
    "    This function is guaranteed to produce a list of points that starts at\n",
    "    (FPR=0, TPR=0) and ends at (FPR=1, TPR=1), making it suitable for direct\n",
    "    plotting and AUC calculation.\n",
    "\n",
    "    Args:\n",
    "        results_list (list): A list of dictionaries. Each dictionary must\n",
    "                             contain a 'model' name and the full ROC results\n",
    "                             under the 'full_roc' key.\n",
    "        results_original_roc (dict, optional): A dictionary containing the\n",
    "                                               ROC results of a baseline model,\n",
    "                                               which will also be included in\n",
    "                                               the comparison. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of dictionaries representing the optimal ROC\n",
    "              envelope. Each dictionary includes 'model', 'fpr', 'tpr',\n",
    "              and 'threshold'.\n",
    "    \"\"\"\n",
    "    all_points = []\n",
    "\n",
    "    # Step 1: Gather all ROC points from all provided models\n",
    "    all_results = results_list[:]\n",
    "    if results_original_roc:\n",
    "        all_results.append({\n",
    "            'model': 'original_baseline',\n",
    "            'full_roc': results_original_roc\n",
    "        })\n",
    "\n",
    "    for result in all_results:\n",
    "        model_name = result.get('model', 'Unknown Model')\n",
    "        roc = result.get('full_roc')\n",
    "        if not roc: continue\n",
    "\n",
    "        fprs = roc.get('fpr', [])\n",
    "        tprs = roc.get('tpr', [])\n",
    "        thresholds = roc.get('thresholds', [])\n",
    "\n",
    "        for i in range(len(fprs)):\n",
    "            threshold = thresholds[i] if i < len(thresholds) else thresholds[-1]\n",
    "            all_points.append({\n",
    "                'model': model_name, 'fpr': fprs[i],\n",
    "                'tpr': tprs[i], 'threshold': threshold\n",
    "            })\n",
    "\n",
    "    # Handle case with no data by returning a default diagonal line\n",
    "    if not all_points:\n",
    "        return [\n",
    "            {'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf},\n",
    "            {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}\n",
    "        ]\n",
    "\n",
    "    # Step 2: Sort all points by FPR (asc), then by TPR (desc)\n",
    "    all_points.sort(key=lambda p: (p['fpr'], -p['tpr']))\n",
    "\n",
    "    # Step 3: Build the core ROC envelope\n",
    "    best_roc_envelope = []\n",
    "    max_tpr_so_far = -1.0\n",
    "    for point in all_points:\n",
    "        # Add a point only if it has a strictly higher TPR\n",
    "        if point['tpr'] > max_tpr_so_far:\n",
    "            # To prevent adding multiple points at the same FPR, check if the last point\n",
    "            # has the same FPR and replace it if so (since this one has a higher TPR)\n",
    "            if best_roc_envelope and best_roc_envelope[-1]['fpr'] == point['fpr']:\n",
    "                best_roc_envelope[-1] = point\n",
    "            else:\n",
    "                best_roc_envelope.append(point)\n",
    "            max_tpr_so_far = point['tpr']\n",
    "    \n",
    "    # Step 4: Manually add extremities if they are missing\n",
    "    \n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not best_roc_envelope or best_roc_envelope[0]['fpr'] > 0.0:\n",
    "        best_roc_envelope.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if best_roc_envelope[-1]['fpr'] < 1.0 or best_roc_envelope[-1]['tpr'] < 1.0:\n",
    "        best_roc_envelope.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return best_roc_envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b781e9",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c3deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_data(dataset):\n",
    "    if dataset == \"data1\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [0, 2], [2, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "    elif dataset == \"data2\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [1, 2], [1, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "    elif dataset == \"pneumoniaMNIST\":\n",
    "        import medmnist\n",
    "        print(medmnist.__version__)\n",
    "        # read in the PneumoniaMNIST dataset\n",
    "        from medmnist import PneumoniaMNIST\n",
    "        train_data = PneumoniaMNIST(split='train', download=True, size=224)\n",
    "        test_data = PneumoniaMNIST(split='test', download=True, size=224)\n",
    "        val_data = PneumoniaMNIST(split='val', download=True, size=224)\n",
    "        # print the dataset info\n",
    "        print(f\"Number of training samples: {len(train_data)}\")\n",
    "        print(f\"Number of test samples: {len(test_data)}\")\n",
    "        print(f\"Number of validation samples: {len(val_data)}\")\n",
    "\n",
    "    return train_data, test_data, val_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59034e",
   "metadata": {},
   "source": [
    "## Data1: NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74133e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a060ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 1\n",
    "NUM_CHANNELS = 1\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 4\n",
    "K_FOLDS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a702675",
   "metadata": {},
   "source": [
    "### Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3760e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "\n",
    "# A simple classifier head\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_features=2, hidden_units=32, num_classes=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_features (int): Number of input features (2 for your data)\n",
    "            hidden_units (int): Number of neurons in the hidden layer\n",
    "            num_classes (int): Number of output classes (1 for binary)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            # --- Hidden Layer 1 ---\n",
    "            # Takes 2 features in, outputs a hidden representation of size 32\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.ReLU(),  # <-- The crucial non-linear activation function\n",
    "\n",
    "            # --- Output Layer ---\n",
    "            # Takes the 16-unit hidden representation, outputs 1 logit\n",
    "            nn.Linear(in_features=hidden_units, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "# A new LightningModule just for training the classifier\n",
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_features=512, hidden_units=32, num_classes=1, learning_rate=1e-4, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = SimpleClassifier(\n",
    "            input_features=self.hparams.input_features,\n",
    "            hidden_units=self.hparams.hidden_units,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "        self.current_test_threshold = 0.5  # Default threshold for binary classification\n",
    "        self.strict_loading = False \n",
    "\n",
    "        # This ensures the model's structure is correct upon initialization\n",
    "        if self.hparams.pos_weight is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(self.hparams.pos_weight))\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        \n",
    "        \n",
    "        # --- METRICS ---\n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_auc = torchmetrics.AUROC(task=\"binary\")\n",
    "        \n",
    "        # This list will store outputs from each test step\n",
    "        self.test_step_outputs = []\n",
    "        # This dictionary will hold the final results\n",
    "        self.last_test_results = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self(features)\n",
    "        \n",
    "        # For the loss function, labels need to be reshaped to match outputs\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "        \n",
    "        # For metrics, squeeze predictions to match labels' shape\n",
    "        self.train_accuracy(outputs.squeeze(), labels.int())\n",
    "        \n",
    "        self.log('classifier_train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('classifier_train_acc', self.train_accuracy, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self.model(features)\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "\n",
    "        # Append predictions and labels to our list for aggregation\n",
    "        self.test_step_outputs.append({\"preds\": outputs.detach(), \"labels\": labels.detach()})\n",
    "        \n",
    "        self.log('test_loss', loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        if not self.test_step_outputs:\n",
    "            return # Avoid errors if test loop was empty\n",
    "\n",
    "        # Concatenate all predictions and labels\n",
    "        all_preds = torch.cat([x['preds'] for x in self.test_step_outputs])\n",
    "        all_labels = torch.cat([x['labels'] for x in self.test_step_outputs])\n",
    "\n",
    "        # --- FIX: Squeeze BOTH predictions and labels to ensure they match ---\n",
    "        squeezed_preds = all_preds.squeeze()\n",
    "        all_probs = torch.sigmoid(squeezed_preds)\n",
    "        # The labels tensor might also be [N, 1], so we squeeze it as well.\n",
    "        int_labels = all_labels.squeeze().int()\n",
    "\n",
    "        # Calculate final scalar metrics\n",
    "        test_acc = self.test_accuracy(squeezed_preds, int_labels)\n",
    "        test_auc_val = self.test_auc(squeezed_preds, int_labels)\n",
    "\n",
    "\n",
    "        # Get the confusion matrix stats at the default 0.0 logit threshold\n",
    "        tp, fp, tn, fn, _ = torchmetrics.functional.stat_scores(\n",
    "            all_probs, int_labels, task=\"binary\", threshold=self.current_test_threshold\n",
    "        ) \n",
    "        \n",
    "        # Calculate TPR and FPR from these raw scores\n",
    "        epsilon = 1e-6\n",
    "        tpr_at_0 = tp / (tp + fn + epsilon)\n",
    "        fpr_at_0 = fp / (fp + tn + epsilon)\n",
    "\n",
    "        # Calculate data for the full ROC Curve\n",
    "        fpr_full, tpr_full, thresholds_full = torchmetrics.functional.roc(\n",
    "            torch.sigmoid(squeezed_preds),\n",
    "            int_labels,\n",
    "            task=\"binary\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"\\n--- Final Classifier Test Metrics ---\")\n",
    "        print(f\"Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"AUC: {test_auc_val:.4f}\")\n",
    "        print(\"-------------------------------------\\n\")\n",
    "        \n",
    "        self.last_test_results = {\n",
    "            \"w\": self.hparams.get('w'),\n",
    "            \"fpr\": fpr_at_0.cpu().numpy(),\n",
    "            \"tpr\": tpr_at_0.cpu().numpy(),\n",
    "            \"threshold\": self.current_test_threshold,\n",
    "            \"auc\": test_auc_val.cpu().numpy(),\n",
    "            \"accuracy\": test_acc.cpu().numpy(),\n",
    "            \"full_roc\": {\n",
    "                \"fpr\": fpr_full.cpu().numpy(),\n",
    "                \"tpr\": tpr_full.cpu().numpy(),\n",
    "                \"thresholds\": thresholds_full.cpu().numpy()\n",
    "            }\n",
    "        }\n",
    "        self.test_step_outputs.clear()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ea652",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f28dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1000, 2), (1000,)\n",
      "Test data shape: (600, 2), (600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train_data, test_data, val_data = generate_data(\"data2\")\n",
    "\n",
    "\n",
    "train_data_tensor = data.TensorDataset(torch.tensor(train_data[:, :-1], dtype=torch.float32),\n",
    "                                        torch.tensor(train_data[:, -1], dtype=torch.float32))\n",
    "train_loader = data.DataLoader(train_data_tensor, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS) #over-write later for k-fold cross-validation\n",
    "test_data_tensor = data.TensorDataset(torch.tensor(test_data[:, :-1], dtype=torch.float32),\n",
    "                                       torch.tensor(test_data[:, -1], dtype=torch.float32))\n",
    "test_loader = data.DataLoader(test_data_tensor, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# initialize fold\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8065beae",
   "metadata": {},
   "source": [
    "### Regular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261a6f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training for 1 epochs on train_loader ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c965bb0694614241a643d2c6127a9f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v18.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v18.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model from Phase 1 saved to: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v18.ckpt\n",
      "\n",
      "--- Testing model from Phase 1 checkpoint: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v18.ckpt ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b641647bb534099866232951c032b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5700\n",
      "AUC: 0.6139\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6873143315315247\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Manually Calculating Metrics on Test Set ---\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[176 124]\n",
      " [135 165]]\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.57      0.59      0.58       300\n",
      "     Class 1       0.57      0.55      0.56       300\n",
      "\n",
      "    accuracy                           0.57       600\n",
      "   macro avg       0.57      0.57      0.57       600\n",
      "weighted avg       0.57      0.57      0.57       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Instantiate the LightningModule\n",
    "model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    "\n",
    "checkpoint_callback_full_model = ModelCheckpoint(\n",
    "    monitor='classifier_train_acc',  # Monitor training accuracy\n",
    "    every_n_epochs=1,                # Save model every epoch\n",
    "    dirpath='checkpoints/',\n",
    "    filename='simple-clf-{epoch:02d}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "train_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',                 # Use GPUs\n",
    "    devices=1,                         # Number of GPUs to use\n",
    "    #strategy='ddp_notebook',                    # DistributedDataParallel strategy (best for multi-GPU)\n",
    "    max_epochs=NUM_EPOCHS,              # Total number of epochs\n",
    "    callbacks=[checkpoint_callback_full_model, progress_bar],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-train\"),\n",
    ")\n",
    "\n",
    "test_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=1,  # Use only one GPU\n",
    "    logger = pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-test\"),\n",
    "    # Add the callback here so the Trainer can find the 'best' path\n",
    "    callbacks=[checkpoint_callback_full_model],\n",
    "    precision='16-mixed'  # Use mixed precision for testing\n",
    ")\n",
    "\n",
    "# --- Phase 1 Training ---\n",
    "print(f\"--- Starting Training for {NUM_EPOCHS} epochs on train_loader ---\")\n",
    "train_trainer_1.fit(model, train_dataloaders=train_loader)\n",
    "\n",
    "# CRITICAL: Save the path to the best model from this phase\n",
    "path_after_phase1 = checkpoint_callback_full_model.best_model_path\n",
    "print(f\"Best model from Phase 1 saved to: {path_after_phase1}\")\n",
    "\n",
    "# --- Test 1: Evaluate the model from after Phase 1 ---\n",
    "print(f\"\\n--- Testing model from Phase 1 checkpoint: {path_after_phase1} ---\")\n",
    "model.current_test_title = \"ROC Curve after training on DataLoader 1\"\n",
    "model = LitClassifier.load_from_checkpoint(path_after_phase1)  # Load the model from Phase 1\n",
    "model.eval().to('cuda:0')  # Ensure the model is in evaluation mode and on GPU\n",
    "test_trainer_1.test(model, dataloaders=test_loader, ckpt_path=path_after_phase1)\n",
    "results_phase1 = model.last_test_results.copy()\n",
    "results_original_roc = {\"fpr\": results_phase1[\"full_roc\"][\"fpr\"], \"tpr\": results_phase1[\"full_roc\"][\"tpr\"], \"thresholds\": results_phase1[\"full_roc\"][\"thresholds\"], \"name\": \"Original NN data1\", \"auc\": results_phase1[\"auc\"], \"model\": model}\n",
    "\n",
    "# Metrics\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval() # Set to evaluation mode\n",
    "\n",
    "final_predictions = [] # This will store binary predictions (0s or 1s)\n",
    "true_labels = []\n",
    "\n",
    "print(\"\\n--- Manually Calculating Metrics on Test Set ---\")\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Move input data to the same device as the model\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # 1. Get the raw model output (logits) and convert to probabilities\n",
    "        outputs = torch.sigmoid(model(inputs))\n",
    "\n",
    "        # 2. Convert probabilities to binary class predictions (0 or 1) using a 0.5 threshold\n",
    "        preds = (outputs > 0.5).int()\n",
    "\n",
    "        final_predictions.extend(preds.cpu().numpy().flatten())\n",
    "        true_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "# Ensure they are numpy arrays for sklearn\n",
    "true_labels = np.array(true_labels)\n",
    "final_predictions = np.array(final_predictions)\n",
    "\n",
    "# Now, calculate metrics using the correct binary predictions\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(true_labels, final_predictions)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "report = classification_report(true_labels, final_predictions, target_names=['Class 0', 'Class 1'], zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c2d0a",
   "metadata": {},
   "source": [
    "### Weighted ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "226e70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSIFIERS = 50\n",
    "w = np.linspace(0.001, 0.999, NUM_CLASSIFIERS, endpoint=True)\n",
    "pos_weights = w/(1-w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19d1bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 1/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd5644e66c5423b9d14b71f665ac12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['criterion.pos_weight']\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v19.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v19.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v19.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v19.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78532d11cdaa4f1bb8d2c8409ccc3c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2655\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7676541209220886\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394bfc68d74e4bbe9aee9137cf95ac47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d84b8e924cc433088ce7b5091efa41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2630\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8202788233757019\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee7e95a9ed64491bbc8e611e7dabece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36dd3c4969d5400190cf12eac2480918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2699\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8832796812057495\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811a796d9e01476da5d918b1bbadcb5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892f5b1318804f5ca501e0cfcfdcfce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2787\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.95215904712677\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482623e5d3794a0aa3d3950e0066927c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa634dedf39e4a4ca36da2fac2ab5a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2981\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0078723430633545\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da516e8dc2441649c6da251ff0c2df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4a2348166c415e932333e3a4fa5268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3113\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0434263944625854\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056389ab57c041f4b008b5d0722cb551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87efcd092aff42b4a2d706d969903af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3248\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.043900728225708\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca7772fa04f4d68acd4b4bcb82e266e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c379d536e54c04a6699d65c16fb8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3416\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9954567551612854\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ea5d5dfcbb4ab2862b1183304ede80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed24a267a2934774b44eafff81ed8711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5120\n",
      "AUC: 0.3591\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9322989583015442\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25781aaed20a4818ae6bd029905294a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560d336a9cae421790314974b71e9db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4292\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8756572008132935\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23273a650b434dc283b286065bb602c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dc71f5759846c0ab9dc07d4d44fb85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.5569\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8254168629646301\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94ad61e00814d85a660436c5c1d6a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba5d9e59a784f4ebfa3203abd11edb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.6213\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7717716097831726\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc3a91dce954832942b44bc980a6041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f398f46d31314576bbd00215e0515e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.6597\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7272616028785706\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72347e0767f4d479df053d9482f4b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b39b70154b4a23910482789d988b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5440\n",
      "AUC: 0.6969\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.688191294670105\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ec5c02141d491ca5a862fddf7908ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8dcf43249f4a478eb970cadaf043d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6240\n",
      "AUC: 0.7201\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6613358855247498\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5fb8ecd758476a8f624db83d09a2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eac7ac9b26e4599944471e46d8e3925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.7568\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6261679530143738\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6711dc4d5f849d0ba6d1be5b963d646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32db018724c42758c1eda81de98f5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.7785\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6027655005455017\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559a1e05145d46d28bc182cc51299191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca16aedaa993446abe165ecf88be732d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7600\n",
      "AUC: 0.7939\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.582801878452301\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c411ee7bcc44dc9dd5fa5bae8683f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645909c6105348d8aedfaf12128940d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8013\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5651361346244812\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55379234254419bbf0926baddafac5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08edc93988724213af7fc64fc79279be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8190\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5444086194038391\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190732c6b8724727b70eeba6754e7b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78498661d9734501b3c08b4dea1ffde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8234\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5318567156791687\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768d255670174ebd9979a8fa4634edf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2de87311c04fe3a207021c3a6db03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8329\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5200207233428955\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03c1feaa27742f3b7f3287682553e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731f8230169448589e15cb141ab8dfcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8371\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5105209350585938\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab24e9bc6f94bd3b38498a08c4b420d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6cf85ca158485cb62be5c20858a9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8391\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5027037858963013\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb9a02091be42c2ac8438db353e10d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38ae809f49047978d22a657d4d3d0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8444\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.49636974930763245\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a052d900e6f64439a330465f180bbc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b1d0dd01894c56873146cdd46b08f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8475\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4918159246444702\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40625b332ea3470aa32135a60fe8e541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2d91386b8f404492311541a8f18bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8502\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4886922240257263\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b26afd03074c6d9ff200088f4913b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04c57d288244c5abec307473a4c3b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8520\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.48591023683547974\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e8b8b1d0924322b2ff8b060cd39ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bbaecd820e4fab9126b100fef283f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8538\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4846198856830597\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c2975fbb9e41a4a983643ec97c039a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889c8c45e03541ed9fee236763266a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8552\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.485297292470932\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fee7743639047729fb895f3befab891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec45895cf72462796201b727697950b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8556\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4809860289096832\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89082d26098f48fc9ec119c2d299c109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964fb318c8c744b1b46a0b9fd0a4ec4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8565\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4855644106864929\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1213fb065d947d7b9d9c292a2395dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db15fc53e354448aa8e499f857f80c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8570\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.49177685379981995\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540c4b0aca2145d28924dfead100c2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846adff8b38b433982951a2f0c2f100e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8575\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4954129159450531\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c285fd495864ff6a2e318bc91ed58e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5939d78226874366968ae23c992e67b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8579\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5056837201118469\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737e1aa001624cdba52e18d5d23c1f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbddc31f69274f5fb0ec131371e49365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8599\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.516907274723053\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7eb9b44c9144f8885cfb3da5fab6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9865079101514cffa6c338d32d05d0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8607\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5264061689376831\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81adbb5be49a444186a49e7962363ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa880765532a46f6b43e058809dda641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8606\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5391298532485962\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3cb3236e7e4ce98c54242df08d3852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d64684b0b5a48c798b384f2de30f858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8610\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5573033690452576\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421c89d3164e4b41b683ad6db27066d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d526130265f040ef97d344f785580886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8616\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5762844085693359\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e5f357ac944f66b50ccc67e366556d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38376c11228a4fed880c64284fb5f776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8614\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5903940200805664\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed784e87d1be432d944197fc4f2933d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4c865c168f42bdad41b91730bf828f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8625\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6163721680641174\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23acae5d93e04ba0aec5e069dbd475cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4a3761d40b4f0ca1499517e57f68ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.8629\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.641635000705719\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc98e7dd15a41d196a2f7577276ccfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9c07193b7b4c158f09886851f8d0e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.8626\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6648041009902954\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c171ac3bd4a74897be1b51d8cebd2039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbcca65fd8940948a2e13c895188396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6960\n",
      "AUC: 0.8625\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6928171515464783\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ef1eff5b724f46b48c0d82a9716fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec83d1fa087b44e0b92d5be5b4da487e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.8619\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7430084943771362\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ab6295ace8412f82b2acc1c663df25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d94c6775d01464b9069262ac5c880b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6960\n",
      "AUC: 0.8615\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8000817894935608\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3096a132a37a434897365d8bd169f6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6432b73c465846f2ad0a2c73dcbf3b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.8613\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8653768301010132\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea190985ff44e6bb40002c8f9529b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8591db3f024cec92bec94da6af4f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.8603\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.931489884853363\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6cae79ab4b44cceb22dfcececba37bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0adfc776565940f3ac1b2683cf8abd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6760\n",
      "AUC: 0.8594\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9756916165351868\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 2/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f8fc1985c44722b45a6140185f3908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe13b2aa8c343288a7867c63f5ba82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2892\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7375627756118774\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0515f1f48f47bdbe20c56c63cbd7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900ff22f955148988f1712c17914f7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2347\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7787456512451172\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2e80baf8de44ec92d16ea8a636f5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ad3e925c2f4906ba4cdd8adb49d63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2118\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8218240737915039\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bef5608577444cab63cfd4a8bc7772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2234a5bf0eeb4bf2a0a77791a8d427c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2010\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8677312135696411\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab3e91e61f64799904be262daa9d11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a141c9a87bce47f5b1d8db5a0538705d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1945\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9167004227638245\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0a0ccfd3f04a669f4388ae75b8748b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d232c330b53e4203bfe7a7521a357c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1969\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9625637531280518\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cd6e073f4747ecb4399b0ba1035f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669c1d6cd8594c27a6257dbbb937dd8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2130\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9677337408065796\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7dff488c7a415988fb86a58a496f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce238e18b23e46e684d4ec91943bfa04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2627\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9560354351997375\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64253dc804364a139b9887e7a7c49974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7ccbe4f61544509428ea8a9aef9ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.3520\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.929405152797699\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73961f5ea0d4e8fb34c755a283ddf7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc157c8819934653b8d691151bbc854a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5122\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8830832242965698\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2014b729a3c40df8dbc47d6b4d73871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aec14d636d34794823aaaac1aa9db00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.6499\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8379887342453003\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95c89815fdc43008f9eeacc61cdff96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8e2f59a0df4c4f94da7d43bf77f394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.6828\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7963687777519226\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fabe18f40b46f983418692d24a3398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9434710cd4494fb153cb34f86855be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.7202\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7508836388587952\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2961eb2f5c134ac699d337b3e302dc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3618f42d99048d897969f3cd9cc61c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5280\n",
      "AUC: 0.7483\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.71025550365448\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe8a7079eab46fb9742430ccbeb2422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9098d25e40314d5cbf4f07a4b13912b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6280\n",
      "AUC: 0.7690\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6741873621940613\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebe89c49c7b4328bf6e9b771fde79c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f46c5e6368440c970be55b83052bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6680\n",
      "AUC: 0.7864\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6397095918655396\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2714ab723743d5a8dee3f2e14daabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377f5b9c47f748328e2fa2dd45e44140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.7976\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6118695139884949\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d9c8646fac4bfd9cef364f5a86356b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f592124897e1403a94db8d3ecdea6cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.8140\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5819606781005859\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f6f1da70fe4e6d8e54b0a8e2a205a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4b54f7aeaa4ce89bdeb1d210e7303b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8245\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5566886067390442\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948745032ff34f71a43a3b3a0e53cc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333a4163292b4e38b595e2b795e388de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8286\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5433878302574158\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece283ada24a44f7b0dfccb9d7f6dc61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ed2f9868574f4f9c16aa303a874e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8342\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5245846509933472\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54d2a735765420fb0480a23408e9c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4357ca730f464d8f90df05912ad428c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8379\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5126435160636902\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb36ce290ae646dcbb9553988fadbd43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff79af4f6cb4fd6b31aeb4db6328e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8412\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4998283088207245\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a9093991cc46959043e5e807bf3dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702ae0e6508b4d10a6f27fcab7c58b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7080\n",
      "AUC: 0.8431\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.48952335119247437\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51841a35bd247f2b6e4db7c5cb15652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf785bd5e34740e387647e664847ad20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8466\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.47830161452293396\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d40ea53a0b2478f9cb0d11a2718ba4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c78b40758d44bfbc7bc7506c15a906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8483\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4712155759334564\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d14d865bc24291b6dec688f01e6805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82233c4d1a6e40098ad280ba25c756f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8502\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4650372862815857\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5467df9d2fcf47838ba1c0c6eb3a324e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d103a2de98449e8ad6ca464967735a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8524\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46011611819267273\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c107e885eeb44af78d49f88e20c2104a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34d67ffb8db4145b83044d22027562c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8534\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45679929852485657\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379ed631b987432d9f720b305c13122d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f9506d10424bf089359daf60ac6574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7560\n",
      "AUC: 0.8557\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45379379391670227\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5798bbd456a45e39b83be0b338834b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7488dd0ac7493cbf39c8a9a22e9411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7520\n",
      "AUC: 0.8567\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4527013897895813\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f5f7514c0a404db440773767902f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9dfc2d839884ad58a68d0c73d8775b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8581\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4535573422908783\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b273ef0c0d9d4539884b7286c953b934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a918c3a3c484daeb70948d5edce86c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8577\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4565396010875702\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4fc17a9d644a34b3f8bb5e72a870fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b48e247e55492094517c90b86b859f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8577\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4596022367477417\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d3a81057b340228423054193c975c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27d0517506d4c2cbed35ccf9803c27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8580\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46450427174568176\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1705b2fadb40ffa635f1c8d568e5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f408a2795a046598338f5d41b8fa15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8572\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4705519378185272\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5092b7dc26ad40a9be6363f320a5091b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7773ff2417d43d096cfc60da8d819b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8571\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.47759875655174255\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77a9841603e4bef947a8909e856762d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f23c4ea04c44d081ae72c9752a021a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8571\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4809812903404236\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc1050e4ede49c5af8061f4576a3584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a28b41fa50b4df7923ff0f3b5965fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8569\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4932645857334137\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d695619bd44c44dfb73f1db73d449703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fb1b4c763b4468b4ad16a9ed673911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8557\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5059277415275574\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40142957af0946238398c8724762a9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a08d6f55d6c4143a72da8178a9c11b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8559\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.526340126991272\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ef3ceab94148938a5d297b0ae48c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb3d5212f1240c39e8afce4ca7d5331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8557\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5434646010398865\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3250d962d53f4eaaa9cdcb36a53831c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8add79f967934ab7b8b31aa89bce3044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8553\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5679275989532471\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7285d73281b4f569b1b001a29053d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1257a5e32231444f9a7c941055460a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8549\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5950807929039001\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15625c866c86406bb25cc1e24a59a8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a136da3bad084b2687e883d41a9510d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8541\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6247408390045166\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095aefe457d942658831b4ff2426335d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76376b46292a42909c4d6d9e0ea54b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8539\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6604481339454651\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8922bb037c4ca0bd42771639fc299b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac4d8bcbc46496ebe03aacbbfce6184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8539\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7071707844734192\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f08ca824494aa6b294578d01148c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a08d9adfa1c48c5aa110d00a5cc1014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8538\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7436138987541199\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0acc7b93c4a47969e1f8e159f373986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b32017f26c946eea001a5e1832f15b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8538\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7938992977142334\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbb62da2bea4a76a45333a9589bf2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ed888e774841719977cca9c207b7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8541\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8308938145637512\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 3/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5b1f39bcb0418eb3cfaff5ce732d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd5e08ddc304ac4830526beaf3848d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1383\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8005256056785583\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15521faf56d74245a5e2e1fac1c2849f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc961c44a2a0408b90243916d8b67f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1434\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.843948245048523\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3d355be1324b0f895b1bea20cce649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169e707993da407da0ab2e897fce69f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1554\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8926207423210144\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761500ebbf404c1ea688a7556a4c5c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3cde52e8d446c9b3edd4e3fe11c7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1760\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.944499135017395\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fbd9e7fd224cfd8200c054d9a75009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168ccf654eb4446689a98a99448606cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2032\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss             0.9883993268013\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f23ecd3c3914217b032ab2901e35375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350e0d3345564e8da42d530d87fc163e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2415\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0235844850540161\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a331bff247474061aae189ecff39b648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015e90071e4e4eb9945b179efb61198a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2863\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0457496643066406\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4f8a91649c42809cd6cd0045796dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea1bee72fe542debd58660eaaff1eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3234\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0318751335144043\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ebfa97ceac405aadd28e85370edb71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff90f9ca0ec4eabb2dfc55d6cb00150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3523\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9877092242240906\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bee6596fb494af8bc9200e81a7d2902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754eac2d75284ebf8c2331f82d2f6bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4230\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9395592212677002\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe51554fbac43409f87082c29adaafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b937288a76464f70a840e7de63b34c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.5488\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8857266902923584\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd4eff6188549748375d1cd45680c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb6af9fa4f04e7fabbe85807d8da761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.6663\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8359194397926331\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c174e15b974b488eb3ec063aeecfae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b710a9205c473ba8f8e503fdeeec86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.7341\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7889459133148193\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8787cc1b14c4632a25c1e2c7e1672a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678886cddf0040fe9428b649cc43a2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.7714\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7429880499839783\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440bf4659e38491eaf58ae2cb8d54134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d2549df41f4ca6852b27a0c3dc6f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.7928\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7057761549949646\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffb4b4acdb04c3f8415b539c062b138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d4f6ec634441c3a90ab2f24e5bd899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4840\n",
      "AUC: 0.8078\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6699056625366211\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a921ac76795d46ec886ebe5102ed597a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823015822f97471fb098fe891c39897d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6480\n",
      "AUC: 0.8180\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6349582672119141\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e00dcc189fb4d5a9ee41c96950d4186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3db806e650d495cb1449fe0ff138ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8258\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6063206791877747\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e71543383f4ef9a9619ec265382efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175077d455f449ebbc4a89da4aaf1f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7680\n",
      "AUC: 0.8359\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5769469141960144\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdea0da1e7284660b952002112fa4ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc95e1de1154e5ca19c0f6601f5e908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7640\n",
      "AUC: 0.8412\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5551362633705139\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb3b3b4269b4a42bc5c7f625849d3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b8ca6fdf5f41eb93908b4cd0f64e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7680\n",
      "AUC: 0.8476\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5325221419334412\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1594c6a70046ac870bffebb2262bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdc82c5ef13458cbce3f17f2f46d0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7600\n",
      "AUC: 0.8494\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5157297253608704\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de3c1ad5335477189a14acbd29aaa4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73bfe608172459cb77ac6aae078b11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8521\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5016684532165527\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd10bf9e16ec4ba1bf2ccf396472c84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338e800423e848f693f02a627afc5f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7520\n",
      "AUC: 0.8537\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4894965589046478\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95de7395bbc743efac9a09d60e5922ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d566b66ba3d4414ea5c85cab1a01eb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8555\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.48001396656036377\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c131e9a12620478f92dfdf52332e717c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23d685a02604f73996fad7694333ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8575\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4732374846935272\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98873aeb1d47442398739da024ffad6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2ba4830582411f9886a2db90443d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8585\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46769091486930847\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97123484a6841b1b360c9ae98ea866f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197a22ebad5846b3a6a8a8875948988b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8602\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46273326873779297\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754f6eebfbd948658bd35837ff73c216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18bd71bc9fc44ffbde90f95985ede9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8609\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4597620666027069\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d0e87658674b2da494b90648488bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa39a15e260400abf5371d5b2aa7fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8615\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45950156450271606\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5d765fc973416390b10e5b05f128bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee4034e7419413dba6e2be71e046739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8624\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45758646726608276\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299766d45c30426bbbf0122d79be4e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e4514a402f44de8c2a1ffc2d03f149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8631\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4556320309638977\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43623e5d829e4612a1def87de992281b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86081e58d5d440b9d48e86f2b834973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8638\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46203815937042236\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b424cf02804c00b4a2ea6b36b608b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b938993adb0b4a7f8e9ada5316b3decc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8645\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4676938056945801\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e79d14705854425b19f6321d6c53b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075806ab505645b5bce0d5ad1c968cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8652\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4736079275608063\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88f7012d2634a28adc0b1465ae9e5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2458f11f03804a9b98028d0979611413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8654\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4788254499435425\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b820268da6343e19b182909eb6bbede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b621dfde084b4d99b2b98107effbfe84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8655\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4825604259967804\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59752bba274446a5a0792da2a048568b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b569252dbc95488ebcb99162dd5249e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8659\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4893953800201416\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42e1c066a1d44dc8142c1bc131b1be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d208d1a0bd84eaeaf94adc9505f9d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8663\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.49854129552841187\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23225ee0f2da47ceaae5191395cd29b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70f3ba544a747d296b95ca32c98566b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8671\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5098155736923218\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c94f1258ab34a8f86cc6b97d6a3cadb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af50b2069c14dd9b26f22d0856aeb91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8663\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5328621864318848\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980f73d1bd6b411eb50ab6a047721686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1974534c69848c09596d9c0dd9b63e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8661\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5516429543495178\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cb73553f2d4c98afd0c3eeb1c8b343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8527a07cf0b14a6698e420f68fad51e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8657\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5789104104042053\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b9abb09b2c451cbf814ff1016b15c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a527e3559bb64e73bbbd22631c61d285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8649\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6100141406059265\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434b9d3056324d3393aa5155de0c6aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cb438e744b4cc1b317a094f5e64ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8640\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6466864943504333\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458f92a7db6d41bea3c31d926e2ca7fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc14dae1d9ca43ff95bca7ca4c7962a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8637\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.689750075340271\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ff7d1cdee14477a18009279382fcf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d99787ca08459eba002c107c3631ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8632\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7408185005187988\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8081b010204694b6893e9a55428039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfc0ffd216740cc9d2a573b14deb3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8623\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7909818291664124\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9658c2afdf4f2b870c7376a94d8bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d2abf205bb46f18eb39559f8cc963a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8611\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8567193150520325\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a88cbb8105b414895c55858fa48d0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ac15a7ee1d44d6855daf200288c4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8605\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9020094275474548\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "--- Starting Fold 4/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a904d874a643a1a33cf978f1d9fc99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c02c133f5543b89ddddb1a8a2e1a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3422\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8193480968475342\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d7f2ea3dc149028a93312eb2d957dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6bc4a675bf4cc2bd35f35725f60ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3370\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8800300359725952\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca3e148fb2f4d77a5ec2e1cbef639ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a27fbc016149ef973b296003613eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3343\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9472030997276306\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f82c2dee1ff445192778db5879c9995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1c2572911e4b2dbc778496e9d96738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3367\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0091711282730103\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b7209af2234a37bb92b438b3307678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac91707f1584aa3acbe69a6e2e8e5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3445\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.030240535736084\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a630bf680ef4701be082ede3a47ec55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5432027bfc424dc5ad1d7abc40f6392c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3593\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.002152681350708\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb68e59050ec4dcfafa0c9eb0015b456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883d1fa26d474d6eb8bbc5c316e8961e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3891\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9554938673973083\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8acc1dd63d4f87b61a60c9f7901395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6b428bb8fc428fbc0521b90eda4c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4683\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.900529146194458\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5176278edb7a47f4966dcca328ef0f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6711b0640644ca8ea379cd1373155a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.5515\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8475346565246582\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217929a6f985463985ba2672158a94df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b30815193384b70ae273f8008f2ef73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.5832\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8003154397010803\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8139c99b054ab69d93732cf07441f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506bb4a9254e4c439a3dcad59f966f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.6089\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.749652624130249\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3030da4878be445f884024f9e3bfd43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e2ae422c2d44a5932765924987a484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5600\n",
      "AUC: 0.6551\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7037526965141296\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b9ab3115cd481faae2876930d60e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826b014965c6489d9fc8fb9fba9663ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6320\n",
      "AUC: 0.7102\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6628682613372803\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3765141fc741b5a84d5886c42e18e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ad62f9425e4935acaaa16745e4c0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.7491\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6346430778503418\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e02b2a613574cefa21e759e489f8d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa1ac000dad4fa2b5f1d4cd411840e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.7772\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6092191934585571\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a66573298848efbc7e7ee5ee9bd6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2967ec206843bd8ce83c76d8bbe295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8095\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5760064721107483\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffaee690b42432f8730c940a5727a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce9f9974d9d4777ac3067060f511a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8254\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5556005835533142\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2c3c26999b4357b9e7b4f041000fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4db2663083f4f8887f7b5fda59c1ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7520\n",
      "AUC: 0.8408\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5302383303642273\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32832957a3a947e5a944723e81e0934c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50c4a4b872840cf88d43df23aba9f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7640\n",
      "AUC: 0.8506\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.511646032333374\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b543e8f6574b8095e2a53e74bd7bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbc0171fdec4cb6bd39f340cbf5f2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7720\n",
      "AUC: 0.8538\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5010159015655518\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f986e805219d41ee8988422fa82763f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce41fcea8994831907d39761c1e2d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7760\n",
      "AUC: 0.8559\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4909391403198242\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c723afe7f924377a09af10031922e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e0d90d059c4258a9e253dcfecd64b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7560\n",
      "AUC: 0.8613\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.476236492395401\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c71249c5e94e7b99f5deae63fb25b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4962e95528b44b659d90a3d4a02ef58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8633\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4675005376338959\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a866076fbb194774a6f16eee43ae95a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b77f08d6d845779300441b2d55aefb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8654\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46079835295677185\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0836a6578b4cc594804ef4967b684f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87eabc1d3d943aa9d520f5b5aef1009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8658\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4557495713233948\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f407b1bd0c409f827e7ee0495e5013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d7f9e6698742328cd42fbeb27c4c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8662\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.451321542263031\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07c96e325944316961a5d629e5b4d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e494ca11fb448ca8c6be2b7ddb0b1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8679\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4482128918170929\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808939d9ba304e18ab5f9d759a1101e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022b10a1ef044f07afcbed49d83e715f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8681\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4461037516593933\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a872d5a41904dd09ea1054b19d87059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4d46cd1b5544f486ee264abcf6a89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8695\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4470636248588562\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4c2210d3794ac590dfa73569b000e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb529f0e6a04cf48ee72031559b7ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7560\n",
      "AUC: 0.8707\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4469273090362549\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3efa3c1fcc84e66b87e5f342a2e6970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97d5e8d8db3464f958a0daa75674efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7560\n",
      "AUC: 0.8715\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.44890812039375305\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5996c59a97de4150adc88e302452ca38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0754f3fd9d42a6ac873eb75a535754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.8719\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4505960941314697\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6e9f1b435f42eda093940c117cfddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbef50767a334786984b46cead765b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.8736\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45740604400634766\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fef92a7dd34c62bb1590ad5151b89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e138ecef920b42e2b8c8e7138670e40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8742\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4692266583442688\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2e546073e941de9b2b1e54af25b96e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade21ff67d3e454f8ce437670452fa79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8744\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4752771556377411\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0317749f29a415fb50d36a7486a2864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdbe5e5e33841c0901b048561862009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8750\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4810393750667572\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a7b5e9be2e4678b2d6c35a36accbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7a3ff63492407db80bfed6feaa8d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8758\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.49301934242248535\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b893fb75f1734ad9964aa1f2c7b647e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10cce75d9bbb4fe1bd4b215e0abafcad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8759\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4989764392375946\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d324e115a8264612a338730b26c3f1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176b12552de144bd8c45b2fc02cce18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8761\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5211317539215088\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf9f2a43fc9421296362913d790bbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb4b94c077c462dad80bac199baa1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8764\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5289367437362671\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fa266a965041109f1ad4a1823307e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3100861c8e8447a891fd71a3b700bca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8772\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5541742444038391\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f667e051e2994469a84f4278853dcf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f018f2a0ac4a4ba84fce784d657fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.8769\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5821071267127991\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2a92f38caa43ccb88b4a9602f0958d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49b866146aa42ed80dc88f6ed4fa2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8771\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6040052175521851\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a770f7d000489da36c43d55b0a83a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52e1b6417434d8084029a53b27da1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8780\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.637010931968689\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af5705e04b54cd8a6221c840775820b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe351d8d2cce46ab9e489f7cebd0e3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8790\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6773172616958618\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976b3af38c604b02baabcbe2ce0edada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563b741f82ab4f9fb9113e37a547bd04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8791\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7290652990341187\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98e2df308a44219a6f92fde1a581212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1c020227d24d2286687b828aae1d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.8783\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7949115037918091\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5b9376d1ce450c8c43f566c02bfa53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e63ab66f38f49b1af7486cf542c6149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.8761\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8667290806770325\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8246e47ad454106be5f7591b44ecd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7aa094d2e064cb1be112ac24a7cc40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6960\n",
      "AUC: 0.8741\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9460022449493408\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc9c37adb3c43efb71ebf3673da4347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08cf61266bbe4622ae4033162bf23caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.8728\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9966281652450562\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "#store the weighted classifiers of all the folds\n",
    "list_folds_weighted_clfs = []  # List to store classifiers from all folds\n",
    "#store the best classfiers of all the folds\n",
    "list_folds_best_models = []  # List to store best models from all folds\n",
    "\n",
    "# Dictionary to store the history of each fold\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "# 3. K-fold cross-validation loop\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data_tensor)):\n",
    "    list_weighted_clfs = [] # List to store the models trained at each stage\n",
    "    best_clfs = [] # List to store the best models from each stage\n",
    "    best_model_paths = [] # List to store the path of the best model from each stage\n",
    "    # 1. Instantiate the LightningModule\n",
    "    model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    "    print(f\"--- Starting Fold {fold + 1}/{K_FOLDS} ---\")\n",
    "\n",
    "    # 4. Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "    train_loader = data.DataLoader(\n",
    "                      train_data_tensor,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      sampler=train_subsampler,\n",
    "                      num_workers=NUM_WORKERS)\n",
    "    fold_loader = data.DataLoader(\n",
    "                    train_data_tensor,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    sampler=val_subsampler,\n",
    "                    num_workers=NUM_WORKERS)\n",
    "\n",
    "\n",
    "    for i, pos_weight in enumerate(pos_weights):\n",
    "        \n",
    "        model.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))  # Set the pos_weight for this stage\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            every_n_epochs=1,                # Save model every epoch\n",
    "            dirpath=f'checkpoints/stage_{i+1}/fold_{fold+1}/',\n",
    "            filename=f'best-model-fold{fold+1}-{{epoch:02d}}',\n",
    "            save_top_k=1,\n",
    "            mode='max',\n",
    "        )\n",
    "        \n",
    "        # 3. Instantiate a NEW Trainer for this specific stage\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}_fold_{fold+1}_ratio_{pos_weight}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "        \n",
    "        # 4. Train the model. It will start with weights from the previous stage.\n",
    "        trainer.fit(model, train_dataloaders=train_loader)\n",
    "        \n",
    "        # 5. Get the path to the best model from THIS stage and store it\n",
    "        if checkpoint_callback.best_model_path:\n",
    "            best_path_this_stage = checkpoint_callback.best_model_path\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. Best model path: {best_path_this_stage} ---\")\n",
    "            best_model_paths.append(best_path_this_stage)\n",
    "            \n",
    "            # 6. CRITICAL: Load the best weights back into the model object\n",
    "            # This ensures we carry forward the BEST model to the next stage, not the last.\n",
    "            print(f\"Loading best weights from {best_path_this_stage} to continue...\")\n",
    "            model = LitClassifier.load_from_checkpoint(best_path_this_stage, strict=False)  # Use strict=False to ignore missing keys if any\n",
    "        else:\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. No checkpoint was saved. ---\")\n",
    "            # If no checkpoint was saved, the model object will just have the weights from the last epoch.\n",
    "\n",
    "        # 7. Test the model after each stage\n",
    "        print(f\"\\n--- Testing model after Fold {fold+1} Stage {i+1} ---\")\n",
    "        trainer.test(model, dataloaders=fold_loader, ckpt_path=best_path_this_stage)\n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "        best_clfs = get_best_roc_envelope(list_weighted_clfs, results_original_roc)\n",
    "    list_folds_weighted_clfs.append(list_weighted_clfs)\n",
    "    list_folds_best_models.append(best_clfs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6b93abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to pickle/NN_data2_weighted.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_models': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.5081967),\n",
       "    'threshold': np.float16(0.504)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0234375),\n",
       "    'tpr': np.float32(0.5163934),\n",
       "    'threshold': np.float16(0.3767)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.03125),\n",
       "    'tpr': np.float32(0.52459013),\n",
       "    'threshold': np.float16(0.669)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0390625),\n",
       "    'tpr': np.float32(0.5327869),\n",
       "    'threshold': np.float16(0.625)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0546875),\n",
       "    'tpr': np.float32(0.5409836),\n",
       "    'threshold': np.float16(0.412)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0625),\n",
       "    'tpr': np.float32(0.5491803),\n",
       "    'threshold': np.float16(0.6436)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.078125),\n",
       "    'tpr': np.float32(0.55737704),\n",
       "    'threshold': np.float16(0.562)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09375),\n",
       "    'tpr': np.float32(0.56557375),\n",
       "    'threshold': np.float16(0.675)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.109375),\n",
       "    'tpr': np.float32(0.57377046),\n",
       "    'threshold': np.float16(0.3923)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.125),\n",
       "    'tpr': np.float32(0.58196723),\n",
       "    'threshold': np.float16(0.879)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1328125),\n",
       "    'tpr': np.float32(0.59016395),\n",
       "    'threshold': np.float16(0.8936)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.140625),\n",
       "    'tpr': np.float32(0.59836066),\n",
       "    'threshold': np.float16(0.905)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1484375),\n",
       "    'tpr': np.float32(0.60655737),\n",
       "    'threshold': np.float16(0.4072)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.171875),\n",
       "    'tpr': np.float32(0.6639344),\n",
       "    'threshold': np.float16(0.7993)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1796875),\n",
       "    'tpr': np.float32(0.6721311),\n",
       "    'threshold': np.float16(0.7783)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1953125),\n",
       "    'tpr': np.float32(0.704918),\n",
       "    'threshold': np.float16(0.9375)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.203125),\n",
       "    'tpr': np.float32(0.71311474),\n",
       "    'threshold': np.float16(0.96)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.21875),\n",
       "    'tpr': np.float32(0.74590164),\n",
       "    'threshold': np.float16(0.8726)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2265625),\n",
       "    'tpr': np.float32(0.75409836),\n",
       "    'threshold': np.float16(0.8027)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.234375),\n",
       "    'tpr': np.float32(0.7704918),\n",
       "    'threshold': np.float16(0.834)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2421875),\n",
       "    'tpr': np.float32(0.77868855),\n",
       "    'threshold': np.float16(0.85)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.25),\n",
       "    'tpr': np.float32(0.78688526),\n",
       "    'threshold': np.float16(0.806)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.265625),\n",
       "    'tpr': np.float32(0.795082),\n",
       "    'threshold': np.float16(0.824)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2734375),\n",
       "    'tpr': np.float32(0.8032787),\n",
       "    'threshold': np.float16(0.8584)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.28125),\n",
       "    'tpr': np.float32(0.8196721),\n",
       "    'threshold': np.float16(0.8955)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.296875),\n",
       "    'tpr': np.float32(0.8278689),\n",
       "    'threshold': np.float16(0.932)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3125),\n",
       "    'tpr': np.float32(0.8360656),\n",
       "    'threshold': np.float16(0.8496)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.328125),\n",
       "    'tpr': np.float32(0.8442623),\n",
       "    'threshold': np.float16(0.8633)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3359375),\n",
       "    'tpr': np.float32(0.86885244),\n",
       "    'threshold': np.float16(0.8975)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3671875),\n",
       "    'tpr': np.float32(0.8852459),\n",
       "    'threshold': np.float16(0.6895)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.375),\n",
       "    'tpr': np.float32(0.90163934),\n",
       "    'threshold': np.float16(0.712)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.40625),\n",
       "    'tpr': np.float32(0.90983605),\n",
       "    'threshold': np.float16(0.5156)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.421875),\n",
       "    'tpr': np.float32(0.92622954),\n",
       "    'threshold': np.float16(0.4807)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4375),\n",
       "    'tpr': np.float32(0.93442625),\n",
       "    'threshold': np.float16(0.878)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4453125),\n",
       "    'tpr': np.float32(0.94262296),\n",
       "    'threshold': np.float16(0.716)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.453125),\n",
       "    'tpr': np.float32(0.9672131),\n",
       "    'threshold': np.float16(0.855)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4609375),\n",
       "    'tpr': np.float32(0.9836066),\n",
       "    'threshold': np.float16(0.849)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4921875),\n",
       "    'tpr': np.float32(0.9918033),\n",
       "    'threshold': np.float16(0.6035)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5859375),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.4111)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.43939394),\n",
       "    'threshold': np.float16(0.8096)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.008474576),\n",
       "    'tpr': np.float32(0.46969697),\n",
       "    'threshold': np.float16(0.5005)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.016949153),\n",
       "    'tpr': np.float32(0.47727272),\n",
       "    'threshold': np.float16(0.36)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025423728),\n",
       "    'tpr': np.float32(0.5151515),\n",
       "    'threshold': np.float16(0.4856)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.042372882),\n",
       "    'tpr': np.float32(0.52272725),\n",
       "    'threshold': np.float16(0.52)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.050847456),\n",
       "    'tpr': np.float32(0.5378788),\n",
       "    'threshold': np.float16(0.5605)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06779661),\n",
       "    'tpr': np.float32(0.5530303),\n",
       "    'threshold': np.float16(0.6377)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.084745765),\n",
       "    'tpr': np.float32(0.56060606),\n",
       "    'threshold': np.float16(0.5815)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09322034),\n",
       "    'tpr': np.float32(0.5681818),\n",
       "    'threshold': np.float16(0.5776)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.11016949),\n",
       "    'tpr': np.float32(0.57575756),\n",
       "    'threshold': np.float16(0.7104)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.12711865),\n",
       "    'tpr': np.float32(0.6136364),\n",
       "    'threshold': np.float16(0.747)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1440678),\n",
       "    'tpr': np.float32(0.6212121),\n",
       "    'threshold': np.float16(0.4407)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15254237),\n",
       "    'tpr': np.float32(0.6287879),\n",
       "    'threshold': np.float16(0.4514)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.16949153),\n",
       "    'tpr': np.float32(0.6439394),\n",
       "    'threshold': np.float16(0.5347)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1779661),\n",
       "    'tpr': np.float32(0.65909094),\n",
       "    'threshold': np.float16(0.4976)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.18644068),\n",
       "    'tpr': np.float32(0.67424244),\n",
       "    'threshold': np.float16(0.4744)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.19491525),\n",
       "    'tpr': np.float32(0.6818182),\n",
       "    'threshold': np.float16(0.5977)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.20338982),\n",
       "    'tpr': np.float32(0.6969697),\n",
       "    'threshold': np.float16(0.4626)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.22033899),\n",
       "    'tpr': np.float32(0.7121212),\n",
       "    'threshold': np.float16(0.4434)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2542373),\n",
       "    'tpr': np.float32(0.75),\n",
       "    'threshold': np.float16(0.6113)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.26271185),\n",
       "    'tpr': np.float32(0.780303),\n",
       "    'threshold': np.float16(0.5527)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.27118644),\n",
       "    'tpr': np.float32(0.7878788),\n",
       "    'threshold': np.float16(0.4998)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.27966103),\n",
       "    'tpr': np.float32(0.81060606),\n",
       "    'threshold': np.float16(0.623)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2881356),\n",
       "    'tpr': np.float32(0.8181818),\n",
       "    'threshold': np.float16(0.6675)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29661018),\n",
       "    'tpr': np.float32(0.82575756),\n",
       "    'threshold': np.float16(0.537)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.30508474),\n",
       "    'tpr': np.float32(0.8333333),\n",
       "    'threshold': np.float16(0.566)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.31355932),\n",
       "    'tpr': np.float32(0.8484849),\n",
       "    'threshold': np.float16(0.822)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3220339),\n",
       "    'tpr': np.float32(0.8712121),\n",
       "    'threshold': np.float16(0.881)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.33050847),\n",
       "    'tpr': np.float32(0.8787879),\n",
       "    'threshold': np.float16(0.641)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3983051),\n",
       "    'tpr': np.float32(0.8939394),\n",
       "    'threshold': np.float16(0.806)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41525424),\n",
       "    'tpr': np.float32(0.9015151),\n",
       "    'threshold': np.float16(0.448)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.42372882),\n",
       "    'tpr': np.float32(0.9166667),\n",
       "    'threshold': np.float16(0.6514)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.43220338),\n",
       "    'tpr': np.float32(0.92424244),\n",
       "    'threshold': np.float16(0.48)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.44915253),\n",
       "    'tpr': np.float32(0.93939394),\n",
       "    'threshold': np.float16(0.4712)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4661017),\n",
       "    'tpr': np.float32(0.9469697),\n",
       "    'threshold': np.float16(0.4656)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.47457626),\n",
       "    'tpr': np.float32(0.95454544),\n",
       "    'threshold': np.float16(0.445)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4915254),\n",
       "    'tpr': np.float32(0.9621212),\n",
       "    'threshold': np.float16(0.4956)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5084746),\n",
       "    'tpr': np.float32(0.969697),\n",
       "    'threshold': np.float16(0.5435)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5338983),\n",
       "    'tpr': np.float32(0.97727275),\n",
       "    'threshold': np.float16(0.604)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5423729),\n",
       "    'tpr': np.float32(0.9848485),\n",
       "    'threshold': np.float16(0.4773)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.59322035),\n",
       "    'tpr': np.float32(0.99242425),\n",
       "    'threshold': np.float16(0.338)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.6101695),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.3115)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.5153846),\n",
       "    'threshold': np.float16(0.425)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.008333334),\n",
       "    'tpr': np.float32(0.56153846),\n",
       "    'threshold': np.float16(0.5303)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.016666668),\n",
       "    'tpr': np.float32(0.5769231),\n",
       "    'threshold': np.float16(0.4202)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025),\n",
       "    'tpr': np.float32(0.5846154),\n",
       "    'threshold': np.float16(0.4377)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.041666668),\n",
       "    'tpr': np.float32(0.5923077),\n",
       "    'threshold': np.float16(0.508)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.05),\n",
       "    'tpr': np.float32(0.6076923),\n",
       "    'threshold': np.float16(0.626)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06666667),\n",
       "    'tpr': np.float32(0.61538464),\n",
       "    'threshold': np.float16(0.5586)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.083333336),\n",
       "    'tpr': np.float32(0.63846153),\n",
       "    'threshold': np.float16(0.578)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.11666667),\n",
       "    'tpr': np.float32(0.64615387),\n",
       "    'threshold': np.float16(0.5947)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.125),\n",
       "    'tpr': np.float32(0.65384614),\n",
       "    'threshold': np.float16(0.67)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.13333334),\n",
       "    'tpr': np.float32(0.66923076),\n",
       "    'threshold': np.float16(0.4548)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.14166667),\n",
       "    'tpr': np.float32(0.6923077),\n",
       "    'threshold': np.float16(0.6016)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.16666667),\n",
       "    'tpr': np.float32(0.7),\n",
       "    'threshold': np.float16(0.664)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.19166666),\n",
       "    'tpr': np.float32(0.7153846),\n",
       "    'threshold': np.float16(0.4585)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2),\n",
       "    'tpr': np.float32(0.7307692),\n",
       "    'threshold': np.float16(0.4312)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.225),\n",
       "    'tpr': np.float32(0.74615383),\n",
       "    'threshold': np.float16(0.495)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.23333333),\n",
       "    'tpr': np.float32(0.75384617),\n",
       "    'threshold': np.float16(0.4712)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.24166666),\n",
       "    'tpr': np.float32(0.76153845),\n",
       "    'threshold': np.float16(0.5337)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.25833333),\n",
       "    'tpr': np.float32(0.77692306),\n",
       "    'threshold': np.float16(0.6035)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.26666668),\n",
       "    'tpr': np.float32(0.7846154),\n",
       "    'threshold': np.float16(0.5713)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.275),\n",
       "    'tpr': np.float32(0.7923077),\n",
       "    'threshold': np.float16(0.674)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3),\n",
       "    'tpr': np.float32(0.8076923),\n",
       "    'threshold': np.float16(0.9546)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.30833334),\n",
       "    'tpr': np.float32(0.8153846),\n",
       "    'threshold': np.float16(0.946)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.325),\n",
       "    'tpr': np.float32(0.83076924),\n",
       "    'threshold': np.float16(0.4607)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.34166667),\n",
       "    'tpr': np.float32(0.8384615),\n",
       "    'threshold': np.float16(0.4553)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.35),\n",
       "    'tpr': np.float32(0.84615386),\n",
       "    'threshold': np.float16(0.9023)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.375),\n",
       "    'tpr': np.float32(0.86153847),\n",
       "    'threshold': np.float16(0.8154)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.38333333),\n",
       "    'tpr': np.float32(0.88461536),\n",
       "    'threshold': np.float16(0.7793)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4),\n",
       "    'tpr': np.float32(0.8923077),\n",
       "    'threshold': np.float16(0.8755)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41666666),\n",
       "    'tpr': np.float32(0.95384616),\n",
       "    'threshold': np.float16(0.8877)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.43333334),\n",
       "    'tpr': np.float32(0.96153843),\n",
       "    'threshold': np.float16(0.856)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.45833334),\n",
       "    'tpr': np.float32(0.97692305),\n",
       "    'threshold': np.float16(0.844)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.475),\n",
       "    'tpr': np.float32(0.9846154),\n",
       "    'threshold': np.float16(0.6187)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5083333),\n",
       "    'tpr': np.float32(0.99230766),\n",
       "    'threshold': np.float16(0.7373)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.56666666),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.585)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.47413793),\n",
       "    'threshold': np.float16(0.3843)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0074626864),\n",
       "    'tpr': np.float32(0.4827586),\n",
       "    'threshold': np.float16(0.4014)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.014925373),\n",
       "    'tpr': np.float32(0.5),\n",
       "    'threshold': np.float16(0.402)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.02238806),\n",
       "    'tpr': np.float32(0.5086207),\n",
       "    'threshold': np.float16(0.4626)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.029850746),\n",
       "    'tpr': np.float32(0.54310346),\n",
       "    'threshold': np.float16(0.518)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.03731343),\n",
       "    'tpr': np.float32(0.5603448),\n",
       "    'threshold': np.float16(0.707)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.052238807),\n",
       "    'tpr': np.float32(0.5948276),\n",
       "    'threshold': np.float16(0.5454)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.05970149),\n",
       "    'tpr': np.float32(0.6034483),\n",
       "    'threshold': np.float16(0.5312)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06716418),\n",
       "    'tpr': np.float32(0.61206895),\n",
       "    'threshold': np.float16(0.4727)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.08955224),\n",
       "    'tpr': np.float32(0.62068963),\n",
       "    'threshold': np.float16(0.642)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.104477614),\n",
       "    'tpr': np.float32(0.62931037),\n",
       "    'threshold': np.float16(0.4487)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.11940298),\n",
       "    'tpr': np.float32(0.63793105),\n",
       "    'threshold': np.float16(0.786)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.13432837),\n",
       "    'tpr': np.float32(0.6465517),\n",
       "    'threshold': np.float16(0.5054)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.14179105),\n",
       "    'tpr': np.float32(0.6551724),\n",
       "    'threshold': np.float16(0.77)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.14925373),\n",
       "    'tpr': np.float32(0.67241377),\n",
       "    'threshold': np.float16(0.9785)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1641791),\n",
       "    'tpr': np.float32(0.6896552),\n",
       "    'threshold': np.float16(0.91)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.17910448),\n",
       "    'tpr': np.float32(0.73275864),\n",
       "    'threshold': np.float16(0.923)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.19402985),\n",
       "    'tpr': np.float32(0.7413793),\n",
       "    'threshold': np.float16(0.9365)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2238806),\n",
       "    'tpr': np.float32(0.75),\n",
       "    'threshold': np.float16(0.935)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.23134328),\n",
       "    'tpr': np.float32(0.76724136),\n",
       "    'threshold': np.float16(0.948)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.24626866),\n",
       "    'tpr': np.float32(0.7758621),\n",
       "    'threshold': np.float16(0.8857)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.25373134),\n",
       "    'tpr': np.float32(0.7844828),\n",
       "    'threshold': np.float16(0.9634)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29104477),\n",
       "    'tpr': np.float32(0.80172414),\n",
       "    'threshold': np.float16(0.677)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29850745),\n",
       "    'tpr': np.float32(0.8189655),\n",
       "    'threshold': np.float16(0.842)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.30597016),\n",
       "    'tpr': np.float32(0.8534483),\n",
       "    'threshold': np.float16(0.7935)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.31343284),\n",
       "    'tpr': np.float32(0.87068963),\n",
       "    'threshold': np.float16(0.925)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.32089552),\n",
       "    'tpr': np.float32(0.9051724),\n",
       "    'threshold': np.float16(0.8286)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3432836),\n",
       "    'tpr': np.float32(0.9137931),\n",
       "    'threshold': np.float16(0.6675)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.35074627),\n",
       "    'tpr': np.float32(0.92241377),\n",
       "    'threshold': np.float16(0.654)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.38059703),\n",
       "    'tpr': np.float32(0.9310345),\n",
       "    'threshold': np.float16(0.4656)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3955224),\n",
       "    'tpr': np.float32(0.9396552),\n",
       "    'threshold': np.float16(0.9165)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41044775),\n",
       "    'tpr': np.float32(0.94827586),\n",
       "    'threshold': np.float16(0.7666)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41791046),\n",
       "    'tpr': np.float32(0.9741379),\n",
       "    'threshold': np.float16(0.8413)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4477612),\n",
       "    'tpr': np.float32(0.98275864),\n",
       "    'threshold': np.float16(0.7373)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4552239),\n",
       "    'tpr': np.float32(0.9913793),\n",
       "    'threshold': np.float16(0.879)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.655)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}]],\n",
       " 'weighted_clfs': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0703125, 0.078125 , 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.15625  , 0.1796875, 0.203125 , 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.25     , 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.609375 , 0.6171875, 0.6171875, 0.6171875,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.625    , 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.7265625, 0.734375 , 0.734375 , 0.734375 , 0.734375 ,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.75     , 0.75     , 0.75     ,\n",
       "            0.75     , 0.7578125, 0.7578125, 0.7578125, 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8046875, 0.8125   , 0.8125   ,\n",
       "            0.8125   , 0.8203125, 0.8203125, 0.828125 , 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.875    , 0.875    , 0.875    ,\n",
       "            0.875    , 0.8828125, 0.8828125, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.02459016, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13114753, 0.13114753, 0.13934426, 0.14754099, 0.14754099,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.21311475, 0.21311475,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.22950819, 0.23770492,\n",
       "            0.23770492, 0.24590164, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.27868852, 0.29508197, 0.30327868, 0.3114754 , 0.3114754 ,\n",
       "            0.31967214, 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40163934, 0.40163934,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.4262295 , 0.4262295 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.4918033 , 0.5       ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6229508 , 0.6393443 , 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6721311 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.71311474, 0.71311474, 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.73770493, 0.74590164,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.86885244, 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4766, 0.4739, 0.4731, 0.4724, 0.472 , 0.4712, 0.471 ,\n",
       "            0.4692, 0.469 , 0.468 , 0.4675, 0.4666, 0.4663, 0.466 , 0.4658,\n",
       "            0.4656, 0.4653, 0.465 , 0.4646, 0.464 , 0.4639, 0.463 , 0.4626,\n",
       "            0.4624, 0.4622, 0.4612, 0.4607, 0.4595, 0.4565, 0.4558, 0.4548,\n",
       "            0.4546, 0.454 , 0.4487, 0.446 , 0.4443, 0.443 , 0.4424, 0.442 ,\n",
       "            0.4414, 0.4404, 0.4375, 0.4348, 0.4326, 0.4304, 0.4302, 0.43  ,\n",
       "            0.4287, 0.427 , 0.426 , 0.4224, 0.4211, 0.4185, 0.4182, 0.4175,\n",
       "            0.4155, 0.415 , 0.4136, 0.4124, 0.4119, 0.411 , 0.41  , 0.4094,\n",
       "            0.4087, 0.4053, 0.4045, 0.4043, 0.4026, 0.402 , 0.4006, 0.3997,\n",
       "            0.3994, 0.3975, 0.3972, 0.397 , 0.3962, 0.3945, 0.394 , 0.3936,\n",
       "            0.3923, 0.3918, 0.3909, 0.3906, 0.39  , 0.3896, 0.3894, 0.3884,\n",
       "            0.388 , 0.3875, 0.3867, 0.386 , 0.3857, 0.3855, 0.385 , 0.3843,\n",
       "            0.3838, 0.3828, 0.3818, 0.381 , 0.3801, 0.3792, 0.3782, 0.3762,\n",
       "            0.376 , 0.3757, 0.3755, 0.3748, 0.374 , 0.373 , 0.3726, 0.3723,\n",
       "            0.3718, 0.3713, 0.3708, 0.3706, 0.3704, 0.37  , 0.3699, 0.3687,\n",
       "            0.3684, 0.3674, 0.3672, 0.3667, 0.3657, 0.3652, 0.3647, 0.3645,\n",
       "            0.3638, 0.3633, 0.3628, 0.3623, 0.362 , 0.3613, 0.3608, 0.3596,\n",
       "            0.3584, 0.3577, 0.3572, 0.357 , 0.3564, 0.3562, 0.356 , 0.3557,\n",
       "            0.3552, 0.354 , 0.3525, 0.3523, 0.3513, 0.35  , 0.3489, 0.3484,\n",
       "            0.348 , 0.3477, 0.3472, 0.3452, 0.344 , 0.3433, 0.3428, 0.3423,\n",
       "            0.342 , 0.3413, 0.341 , 0.3408, 0.3406, 0.3396, 0.339 , 0.3384,\n",
       "            0.3372, 0.3362, 0.336 , 0.3354, 0.331 , 0.3303, 0.33  , 0.3293,\n",
       "            0.3286, 0.327 , 0.3262, 0.326 , 0.3254, 0.3245, 0.323 , 0.3223,\n",
       "            0.3196, 0.3188, 0.3184, 0.3179, 0.317 , 0.3142, 0.3135, 0.3123,\n",
       "            0.3088, 0.3083, 0.306 , 0.305 , 0.3042, 0.3035, 0.302 , 0.2974,\n",
       "            0.297 , 0.2932, 0.2883, 0.2805, 0.2666, 0.262 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.0859375, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1640625, 0.171875 ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.2421875,\n",
       "            0.25     , 0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.6015625,\n",
       "            0.6015625, 0.6171875, 0.625    , 0.625    , 0.625    , 0.625    ,\n",
       "            0.625    , 0.625    , 0.625    , 0.625    , 0.625    , 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6796875,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6953125, 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.75     , 0.7578125, 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8046875, 0.8046875, 0.8125   , 0.8125   , 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.828125 , 0.828125 , 0.8359375, 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.8515625, 0.8515625, 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.8671875, 0.8671875, 0.875    , 0.875    , 0.8828125,\n",
       "            0.8828125, 0.8828125, 0.8828125, 0.890625 , 0.890625 , 0.8984375,\n",
       "            0.8984375, 0.90625  , 0.90625  , 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9296875, 0.9375   , 0.9453125, 0.9453125, 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.9609375, 0.9609375, 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.01639344, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.13934426, 0.13934426,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.19672132, 0.20491803, 0.21311475, 0.21311475,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.24590164, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.32786885, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.352459  , 0.36065573, 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.37704918, 0.39344263, 0.39344263,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.43442622, 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5081967 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.6393443 , 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.71311474, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.74590164, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4568, 0.455 , 0.4546, 0.451 , 0.4507, 0.4504, 0.4495,\n",
       "            0.4478, 0.4475, 0.4473, 0.4465, 0.4463, 0.4458, 0.4456, 0.4448,\n",
       "            0.4446, 0.4438, 0.4434, 0.4429, 0.4421, 0.4417, 0.4414, 0.4412,\n",
       "            0.44  , 0.439 , 0.4368, 0.4365, 0.4363, 0.4358, 0.435 , 0.4343,\n",
       "            0.433 , 0.431 , 0.428 , 0.4265, 0.4248, 0.4238, 0.423 , 0.4204,\n",
       "            0.413 , 0.4116, 0.4094, 0.4092, 0.4075, 0.407 , 0.4014, 0.4006,\n",
       "            0.3965, 0.3962, 0.393 , 0.3926, 0.3896, 0.3872, 0.3857, 0.384 ,\n",
       "            0.379 , 0.3733, 0.371 , 0.37  , 0.3699, 0.3667, 0.3655, 0.3647,\n",
       "            0.3645, 0.364 , 0.3635, 0.3633, 0.3608, 0.3606, 0.3591, 0.359 ,\n",
       "            0.358 , 0.3555, 0.3545, 0.3525, 0.3481, 0.3477, 0.3472, 0.346 ,\n",
       "            0.3452, 0.3438, 0.343 , 0.3403, 0.3394, 0.3374, 0.3372, 0.3367,\n",
       "            0.3362, 0.335 , 0.3345, 0.3337, 0.3335, 0.3333, 0.3325, 0.3313,\n",
       "            0.3308, 0.33  , 0.3298, 0.3296, 0.3293, 0.3284, 0.328 , 0.3257,\n",
       "            0.3254, 0.323 , 0.3228, 0.321 , 0.3203, 0.3198, 0.3186, 0.3167,\n",
       "            0.3162, 0.3154, 0.315 , 0.3142, 0.313 , 0.3123, 0.3115, 0.3108,\n",
       "            0.3103, 0.31  , 0.3098, 0.3088, 0.3086, 0.308 , 0.3079, 0.3076,\n",
       "            0.3066, 0.306 , 0.3057, 0.3047, 0.3044, 0.304 , 0.3035, 0.3032,\n",
       "            0.3027, 0.3022, 0.302 , 0.3018, 0.3013, 0.301 , 0.3003, 0.2998,\n",
       "            0.2969, 0.2966, 0.295 , 0.294 , 0.2932, 0.2927, 0.2922, 0.2915,\n",
       "            0.2903, 0.29  , 0.2898, 0.287 , 0.2852, 0.2847, 0.2844, 0.2842,\n",
       "            0.2825, 0.2817, 0.2815, 0.2812, 0.2803, 0.2795, 0.279 , 0.2786,\n",
       "            0.278 , 0.276 , 0.2756, 0.2737, 0.2734, 0.2732, 0.2727, 0.2725,\n",
       "            0.2722, 0.2705, 0.2695, 0.2693, 0.2676, 0.2646, 0.2637, 0.263 ,\n",
       "            0.2605, 0.2603, 0.2573, 0.2566, 0.2559, 0.2551, 0.2542, 0.2532,\n",
       "            0.253 , 0.2502, 0.2487, 0.2473, 0.2462, 0.2451, 0.2444, 0.244 ,\n",
       "            0.2413, 0.2394, 0.239 , 0.2383, 0.2352, 0.234 , 0.2289, 0.2277,\n",
       "            0.2229, 0.2135, 0.2076, 0.1984], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.125    , 0.1328125, 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.5      , 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.59375  , 0.59375  , 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.6953125, 0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.75     , 0.75     , 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.78125  , 0.7890625, 0.7890625, 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8046875, 0.8046875, 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.828125 , 0.8359375, 0.8359375, 0.84375  , 0.84375  ,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.875    ,\n",
       "            0.875    , 0.8828125, 0.8828125, 0.890625 , 0.890625 , 0.8984375,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9296875,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.9921875, 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.04098361, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.19672132, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.23770492, 0.24590164, 0.24590164, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.30327868, 0.3114754 ,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.32786885, 0.32786885,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.36885247, 0.37704918, 0.37704918,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.5       , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.74590164, 0.74590164, 0.75409836, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4365, 0.4358, 0.4312, 0.43  , 0.4297, 0.4294, 0.4292,\n",
       "            0.4285, 0.4282, 0.4258, 0.4253, 0.425 , 0.4243, 0.4229, 0.4226,\n",
       "            0.422 , 0.4211, 0.4207, 0.4202, 0.4192, 0.4185, 0.418 , 0.4175,\n",
       "            0.4172, 0.4155, 0.4143, 0.4136, 0.4133, 0.4102, 0.41  , 0.4097,\n",
       "            0.4084, 0.4067, 0.4055, 0.4053, 0.4019, 0.3997, 0.396 , 0.3955,\n",
       "            0.3945, 0.393 , 0.392 , 0.3914, 0.3809, 0.3796, 0.3794, 0.3752,\n",
       "            0.3723, 0.3713, 0.366 , 0.3655, 0.3652, 0.3635, 0.3625, 0.3538,\n",
       "            0.353 , 0.348 , 0.344 , 0.3428, 0.3396, 0.3374, 0.334 , 0.3281,\n",
       "            0.327 , 0.3257, 0.3252, 0.3232, 0.3218, 0.3193, 0.3186, 0.3179,\n",
       "            0.3171, 0.317 , 0.3154, 0.3145, 0.3137, 0.3127, 0.3057, 0.3052,\n",
       "            0.303 , 0.3005, 0.298 , 0.2974, 0.297 , 0.293 , 0.292 , 0.2905,\n",
       "            0.2903, 0.2898, 0.288 , 0.2864, 0.2861, 0.285 , 0.2847, 0.2844,\n",
       "            0.2834, 0.2825, 0.2822, 0.282 , 0.2815, 0.281 , 0.2805, 0.2795,\n",
       "            0.2793, 0.279 , 0.2786, 0.2773, 0.276 , 0.2744, 0.2742, 0.2722,\n",
       "            0.2708, 0.2703, 0.27  , 0.2678, 0.2664, 0.2642, 0.263 , 0.2625,\n",
       "            0.2622, 0.2617, 0.2615, 0.2612, 0.2605, 0.2588, 0.2585, 0.2576,\n",
       "            0.2568, 0.2563, 0.2554, 0.255 , 0.2546, 0.2542, 0.2537, 0.2534,\n",
       "            0.2527, 0.252 , 0.2512, 0.2507, 0.2505, 0.25  , 0.249 , 0.2489,\n",
       "            0.2487, 0.2478, 0.2477, 0.247 , 0.2449, 0.2448, 0.2441, 0.244 ,\n",
       "            0.2438, 0.2428, 0.2422, 0.2417, 0.241 , 0.2394, 0.2388, 0.2384,\n",
       "            0.2382, 0.2375, 0.2367, 0.2363, 0.2355, 0.2347, 0.2335, 0.2332,\n",
       "            0.2323, 0.231 , 0.2303, 0.2297, 0.2278, 0.2264, 0.2261, 0.2257,\n",
       "            0.2242, 0.2238, 0.222 , 0.2213, 0.2207, 0.2202, 0.2173, 0.2168,\n",
       "            0.2163, 0.2144, 0.2142, 0.213 , 0.2129, 0.2108, 0.2104, 0.2101,\n",
       "            0.2098, 0.2084, 0.2068, 0.2004, 0.1989, 0.1985, 0.197 , 0.1953,\n",
       "            0.195 , 0.1948, 0.1946, 0.1943, 0.1937, 0.1936, 0.1912, 0.1896,\n",
       "            0.1874, 0.1866, 0.1863, 0.1837, 0.1826, 0.1821, 0.1819, 0.1812,\n",
       "            0.181 , 0.1746, 0.174 , 0.1675, 0.1581, 0.1577, 0.1462],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.703125 , 0.703125 , 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.75     ,\n",
       "            0.75     , 0.75     , 0.75     , 0.75     , 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.7734375, 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.796875 , 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8125   , 0.8125   , 0.8203125, 0.828125 , 0.828125 , 0.828125 ,\n",
       "            0.828125 , 0.8359375, 0.8359375, 0.8359375, 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9296875,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.9609375, 0.9609375,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.984375 , 0.9921875, 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.01639344, 0.02459016, 0.03278688, 0.03278688,\n",
       "            0.03278688, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22950819, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.24590164, 0.25409836, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.29508197, 0.29508197, 0.30327868, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.352459  , 0.36065573,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6557377 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.416 , 0.4158, 0.412 , 0.4116, 0.4102, 0.4087, 0.4082,\n",
       "            0.408 , 0.4062, 0.4048, 0.403 , 0.4028, 0.4023, 0.4006, 0.4004,\n",
       "            0.3987, 0.3984, 0.398 , 0.3977, 0.3972, 0.3967, 0.3958, 0.3936,\n",
       "            0.393 , 0.3928, 0.3926, 0.3906, 0.3892, 0.3884, 0.3835, 0.383 ,\n",
       "            0.3826, 0.381 , 0.3809, 0.3792, 0.3784, 0.3772, 0.373 , 0.3728,\n",
       "            0.3672, 0.3652, 0.3645, 0.3633, 0.3628, 0.3618, 0.3523, 0.3513,\n",
       "            0.3474, 0.3425, 0.339 , 0.3372, 0.337 , 0.3367, 0.3354, 0.3308,\n",
       "            0.328 , 0.3218, 0.3174, 0.3108, 0.3076, 0.3044, 0.3037, 0.3   ,\n",
       "            0.2986, 0.2893, 0.289 , 0.2869, 0.2866, 0.2864, 0.2856, 0.2852,\n",
       "            0.28  , 0.2795, 0.2793, 0.2783, 0.2769, 0.2766, 0.276 , 0.2727,\n",
       "            0.2703, 0.2656, 0.2651, 0.2642, 0.2607, 0.2593, 0.258 , 0.2568,\n",
       "            0.2534, 0.2517, 0.2515, 0.2502, 0.2487, 0.247 , 0.2445, 0.2444,\n",
       "            0.244 , 0.2433, 0.2429, 0.2422, 0.2415, 0.2413, 0.2399, 0.2384,\n",
       "            0.2383, 0.2382, 0.2372, 0.2351, 0.2347, 0.234 , 0.2334, 0.2323,\n",
       "            0.2318, 0.231 , 0.2306, 0.2303, 0.2286, 0.228 , 0.2264, 0.2261,\n",
       "            0.2239, 0.2213, 0.2211, 0.2207, 0.2202, 0.2181, 0.2179, 0.217 ,\n",
       "            0.2148, 0.2147, 0.2145, 0.2144, 0.2142, 0.2115, 0.211 , 0.2104,\n",
       "            0.2095, 0.2094, 0.2089, 0.2086, 0.2079, 0.2075, 0.2074, 0.207 ,\n",
       "            0.2068, 0.2059, 0.2058, 0.2053, 0.2034, 0.2031, 0.2026, 0.2018,\n",
       "            0.2015, 0.2   , 0.1996, 0.1987, 0.1978, 0.1974, 0.1973, 0.1971,\n",
       "            0.1965, 0.1964, 0.1954, 0.1953, 0.1947, 0.1946, 0.1942, 0.194 ,\n",
       "            0.1931, 0.1904, 0.1897, 0.1893, 0.1892, 0.1886, 0.1879, 0.187 ,\n",
       "            0.1863, 0.1859, 0.185 , 0.1843, 0.1842, 0.1833, 0.1815, 0.1805,\n",
       "            0.18  , 0.179 , 0.1781, 0.178 , 0.177 , 0.1768, 0.1766, 0.1754,\n",
       "            0.1743, 0.1715, 0.1714, 0.1698, 0.1686, 0.1685, 0.1677, 0.1671,\n",
       "            0.1647, 0.1644, 0.1626, 0.162 , 0.1604, 0.1602, 0.1588, 0.1542,\n",
       "            0.1525, 0.1519, 0.1512, 0.1509, 0.1506, 0.15  , 0.1475, 0.1471,\n",
       "            0.1469, 0.1454, 0.1442, 0.1436, 0.1434, 0.1406, 0.1395, 0.1392,\n",
       "            0.1385, 0.1365, 0.1349, 0.1337, 0.1328, 0.1302, 0.1242, 0.1184,\n",
       "            0.115 , 0.1058], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.65625  , 0.65625  , 0.6640625, 0.6640625, 0.6640625,\n",
       "            0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6796875, 0.6796875,\n",
       "            0.6796875, 0.6953125, 0.6953125, 0.6953125, 0.6953125, 0.6953125,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.71875  , 0.71875  , 0.71875  , 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.75     , 0.75     , 0.75     ,\n",
       "            0.75     , 0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8046875, 0.8125   , 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.8359375, 0.8359375, 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.9140625, 0.921875 , 0.9296875, 0.9296875, 0.9296875,\n",
       "            0.9296875, 0.9375   , 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.9921875, 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.24590164, 0.25409836,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.36885247, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.40983605, 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.5327869 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.59836066, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.72131145, 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.392  , 0.3916 , 0.391  , 0.3894 , 0.3877 , 0.3848 ,\n",
       "            0.384  , 0.3838 , 0.382  , 0.3809 , 0.3792 , 0.379  , 0.3782 ,\n",
       "            0.3765 , 0.3752 , 0.3743 , 0.3735 , 0.3733 , 0.3728 , 0.3716 ,\n",
       "            0.3713 , 0.369  , 0.3684 , 0.3657 , 0.3652 , 0.3645 , 0.3638 ,\n",
       "            0.3635 , 0.363  , 0.3572 , 0.3555 , 0.3547 , 0.3538 , 0.3528 ,\n",
       "            0.3523 , 0.352  , 0.3518 , 0.3506 , 0.3474 , 0.3438 , 0.3394 ,\n",
       "            0.3372 , 0.3345 , 0.3337 , 0.333  , 0.328  , 0.3271 , 0.3254 ,\n",
       "            0.3174 , 0.3118 , 0.3115 , 0.3079 , 0.3062 , 0.3003 , 0.2998 ,\n",
       "            0.2993 , 0.2969 , 0.29   , 0.2869 , 0.282  , 0.2805 , 0.2778 ,\n",
       "            0.2761 , 0.2722 , 0.265  , 0.2615 , 0.261  , 0.2573 , 0.2544 ,\n",
       "            0.2542 , 0.2524 , 0.252  , 0.251  , 0.249  , 0.2485 , 0.2434 ,\n",
       "            0.243  , 0.2407 , 0.2405 , 0.2394 , 0.237  , 0.2362 , 0.2335 ,\n",
       "            0.2334 , 0.2313 , 0.2307 , 0.2301 , 0.2278 , 0.2238 , 0.2222 ,\n",
       "            0.2218 , 0.2207 , 0.2203 , 0.2185 , 0.2167 , 0.2147 , 0.2113 ,\n",
       "            0.2103 , 0.2089 , 0.2081 , 0.2075 , 0.2068 , 0.2056 , 0.2045 ,\n",
       "            0.2043 , 0.2042 , 0.2035 , 0.2031 , 0.2013 , 0.2007 , 0.1996 ,\n",
       "            0.1987 , 0.1982 , 0.1978 , 0.1971 , 0.1968 , 0.1959 , 0.1958 ,\n",
       "            0.1943 , 0.194  , 0.1925 , 0.1921 , 0.1918 , 0.1909 , 0.1892 ,\n",
       "            0.188  , 0.1857 , 0.1849 , 0.1843 , 0.1842 , 0.1841 , 0.1835 ,\n",
       "            0.1829 , 0.1819 , 0.181  , 0.1796 , 0.1787 , 0.1781 , 0.1776 ,\n",
       "            0.177  , 0.1755 , 0.1743 , 0.174  , 0.1731 , 0.1727 , 0.1724 ,\n",
       "            0.1719 , 0.1718 , 0.1707 , 0.1703 , 0.1698 , 0.1692 , 0.1688 ,\n",
       "            0.1686 , 0.1672 , 0.1669 , 0.1666 , 0.166  , 0.1658 , 0.1654 ,\n",
       "            0.1638 , 0.1633 , 0.1632 , 0.163  , 0.1625 , 0.162  , 0.1616 ,\n",
       "            0.1614 , 0.1611 , 0.1602 , 0.159  , 0.1588 , 0.1587 , 0.1584 ,\n",
       "            0.1575 , 0.157  , 0.1559 , 0.1556 , 0.1525 , 0.1519 , 0.1511 ,\n",
       "            0.1508 , 0.1506 , 0.1504 , 0.15   , 0.1493 , 0.1483 , 0.1482 ,\n",
       "            0.147  , 0.1451 , 0.1442 , 0.1432 , 0.1415 , 0.1412 , 0.141  ,\n",
       "            0.1401 , 0.1392 , 0.139  , 0.1365 , 0.1348 , 0.1328 , 0.1327 ,\n",
       "            0.1326 , 0.1299 , 0.1298 , 0.129  , 0.1274 , 0.127  , 0.1263 ,\n",
       "            0.1252 , 0.121  , 0.1194 , 0.1188 , 0.1174 , 0.11615, 0.11597,\n",
       "            0.11395, 0.1138 , 0.1128 , 0.112  , 0.1101 , 0.1097 , 0.1084 ,\n",
       "            0.1069 , 0.1067 , 0.1063 , 0.10284, 0.10266, 0.1019 , 0.09845,\n",
       "            0.0932 , 0.0877 , 0.0854 , 0.0771 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.625    , 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6796875, 0.6796875, 0.6796875,\n",
       "            0.6875   , 0.6875   , 0.6953125, 0.6953125, 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.7109375, 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.71875  , 0.71875  , 0.71875  , 0.71875  , 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.734375 , 0.75     , 0.75     , 0.75     , 0.75     ,\n",
       "            0.75     , 0.75     , 0.75     , 0.75     , 0.75     , 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8046875, 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.8359375, 0.8359375,\n",
       "            0.84375  , 0.84375  , 0.84375  , 0.84375  , 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.875    , 0.875    , 0.8828125, 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.953125 , 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 ,\n",
       "            0.9921875, 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.1147541 ,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.27868852, 0.28688523, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.31967214, 0.32786885, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.37704918, 0.3852459 ,\n",
       "            0.3852459 , 0.39344263, 0.39344263, 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40163934, 0.40983605, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.74590164,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.367  , 0.3665 , 0.366  , 0.3655 , 0.3652 , 0.3638 ,\n",
       "            0.3613 , 0.3604 , 0.3586 , 0.3584 , 0.3572 , 0.356  , 0.3557 ,\n",
       "            0.3555 , 0.355  , 0.3533 , 0.351  , 0.35   , 0.3499 , 0.3494 ,\n",
       "            0.3481 , 0.3477 , 0.3462 , 0.346  , 0.3452 , 0.342  , 0.3408 ,\n",
       "            0.3406 , 0.3403 , 0.34   , 0.3386 , 0.3372 , 0.3345 , 0.3318 ,\n",
       "            0.3306 , 0.33   , 0.3286 , 0.3281 , 0.3264 , 0.3252 , 0.3235 ,\n",
       "            0.3186 , 0.3154 , 0.3127 , 0.31   , 0.3093 , 0.3062 , 0.3054 ,\n",
       "            0.3025 , 0.2993 , 0.2935 , 0.2913 , 0.29   , 0.287  , 0.2837 ,\n",
       "            0.2803 , 0.278  , 0.2778 , 0.2764 , 0.2717 , 0.2708 , 0.265  ,\n",
       "            0.2646 , 0.2634 , 0.2595 , 0.2534 , 0.2502 , 0.2467 , 0.2445 ,\n",
       "            0.2444 , 0.2433 , 0.241  , 0.2406 , 0.2391 , 0.2382 , 0.2328 ,\n",
       "            0.2306 , 0.2251 , 0.2242 , 0.2235 , 0.2233 , 0.2225 , 0.2212 ,\n",
       "            0.2207 , 0.2195 , 0.2194 , 0.2191 , 0.2189 , 0.218  , 0.2152 ,\n",
       "            0.2144 , 0.2134 , 0.213  , 0.2106 , 0.2098 , 0.2069 , 0.2058 ,\n",
       "            0.2    , 0.1998 , 0.1991 , 0.1965 , 0.195  , 0.1947 , 0.1898 ,\n",
       "            0.1879 , 0.1877 , 0.1871 , 0.187  , 0.1849 , 0.1816 , 0.1805 ,\n",
       "            0.1799 , 0.1797 , 0.1792 , 0.1781 , 0.1775 , 0.1774 , 0.1758 ,\n",
       "            0.1747 , 0.1738 , 0.1726 , 0.1724 , 0.1719 , 0.171  , 0.1709 ,\n",
       "            0.1708 , 0.1705 , 0.1687 , 0.1685 , 0.167  , 0.1669 , 0.1663 ,\n",
       "            0.1658 , 0.1643 , 0.163  , 0.1622 , 0.1608 , 0.1603 , 0.1597 ,\n",
       "            0.1594 , 0.1581 , 0.158  , 0.157  , 0.1567 , 0.1565 , 0.1558 ,\n",
       "            0.154  , 0.1539 , 0.1532 , 0.1526 , 0.1519 , 0.1505 , 0.1501 ,\n",
       "            0.1492 , 0.1488 , 0.1483 , 0.1482 , 0.148  , 0.1472 , 0.1466 ,\n",
       "            0.1462 , 0.146  , 0.1451 , 0.1439 , 0.1432 , 0.1422 , 0.1412 ,\n",
       "            0.141  , 0.1406 , 0.1403 , 0.1401 , 0.1399 , 0.139  , 0.1387 ,\n",
       "            0.1377 , 0.1373 , 0.1367 , 0.1353 , 0.1334 , 0.1327 , 0.1311 ,\n",
       "            0.1306 , 0.13   , 0.1294 , 0.1289 , 0.1287 , 0.1283 , 0.1282 ,\n",
       "            0.1256 , 0.1255 , 0.12494, 0.12305, 0.12177, 0.1217 , 0.1213 ,\n",
       "            0.1204 , 0.1198 , 0.1197 , 0.1192 , 0.118  , 0.1172 , 0.11554,\n",
       "            0.11395, 0.1134 , 0.1122 , 0.111  , 0.11084, 0.11066, 0.10913,\n",
       "            0.10895, 0.1074 , 0.10724, 0.10614, 0.1007 , 0.1    , 0.09845,\n",
       "            0.0972 , 0.09686, 0.0967 , 0.096  , 0.0959 , 0.0957 , 0.09283,\n",
       "            0.09125, 0.09106, 0.0901 , 0.0887 , 0.0882 , 0.0871 , 0.0865 ,\n",
       "            0.0856 , 0.08136, 0.07697, 0.07135, 0.0703 , 0.06256],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.359375 , 0.3671875, 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.703125 , 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.75     , 0.75     , 0.75     , 0.75     , 0.75     , 0.75     ,\n",
       "            0.75     , 0.75     , 0.7578125, 0.765625 , 0.765625 , 0.765625 ,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.796875 ,\n",
       "            0.8046875, 0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.8359375, 0.84375  , 0.84375  , 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.8828125, 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.09016393, 0.09836066, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.32786885,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.44262296, 0.45081967, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59016395, 0.59016395,\n",
       "            0.59016395, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6147541 , 0.6229508 , 0.6229508 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6639344 , 0.6639344 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3447 , 0.3442 , 0.344  , 0.3438 , 0.343  , 0.3423 ,\n",
       "            0.342  , 0.3408 , 0.3389 , 0.3386 , 0.3384 , 0.338  , 0.3364 ,\n",
       "            0.3345 , 0.3337 , 0.3335 , 0.3325 , 0.3323 , 0.3315 , 0.3303 ,\n",
       "            0.33   , 0.327  , 0.3267 , 0.3264 , 0.326  , 0.3213 , 0.3208 ,\n",
       "            0.32   , 0.3198 , 0.3179 , 0.317  , 0.3164 , 0.3162 , 0.316  ,\n",
       "            0.3132 , 0.312  , 0.311  , 0.3052 , 0.305  , 0.298  , 0.2961 ,\n",
       "            0.2925 , 0.2898 , 0.2883 , 0.2825 , 0.2815 , 0.2808 , 0.278  ,\n",
       "            0.276  , 0.2744 , 0.2727 , 0.2664 , 0.266  , 0.262  , 0.2605 ,\n",
       "            0.2573 , 0.257  , 0.2568 , 0.2473 , 0.2448 , 0.2434 , 0.2433 ,\n",
       "            0.243  , 0.2429 , 0.2424 , 0.2395 , 0.2334 , 0.2316 , 0.2301 ,\n",
       "            0.2255 , 0.2252 , 0.2246 , 0.2217 , 0.2207 , 0.218  , 0.2172 ,\n",
       "            0.2168 , 0.2152 , 0.2148 , 0.2134 , 0.2123 , 0.2114 , 0.2091 ,\n",
       "            0.2089 , 0.2059 , 0.2047 , 0.2007 , 0.1996 , 0.1985 , 0.1979 ,\n",
       "            0.1959 , 0.1947 , 0.1927 , 0.1923 , 0.1915 , 0.1898 , 0.1886 ,\n",
       "            0.1884 , 0.1866 , 0.1857 , 0.1855 , 0.1842 , 0.182  , 0.1785 ,\n",
       "            0.1764 , 0.174  , 0.1738 , 0.1733 , 0.173  , 0.1727 , 0.1724 ,\n",
       "            0.1708 , 0.1707 , 0.1693 , 0.169  , 0.1677 , 0.1666 , 0.1661 ,\n",
       "            0.1653 , 0.1648 , 0.1646 , 0.1644 , 0.1641 , 0.1635 , 0.1633 ,\n",
       "            0.1632 , 0.1616 , 0.1608 , 0.1605 , 0.1604 , 0.1594 , 0.1593 ,\n",
       "            0.1581 , 0.1571 , 0.1567 , 0.156  , 0.1549 , 0.1543 , 0.1542 ,\n",
       "            0.153  , 0.1504 , 0.1501 , 0.1498 , 0.1497 , 0.1495 , 0.1487 ,\n",
       "            0.1478 , 0.1476 , 0.1451 , 0.1449 , 0.1445 , 0.1442 , 0.1434 ,\n",
       "            0.1433 , 0.1431 , 0.1416 , 0.1414 , 0.1411 , 0.1384 , 0.1372 ,\n",
       "            0.137  , 0.1368 , 0.1367 , 0.1362 , 0.1361 , 0.1349 , 0.1348 ,\n",
       "            0.1334 , 0.1322 , 0.1316 , 0.1315 , 0.1312 , 0.1305 , 0.13   ,\n",
       "            0.1259 , 0.1256 , 0.1255 , 0.1251 , 0.12476, 0.1241 , 0.12335,\n",
       "            0.12317, 0.12274, 0.1188 , 0.1184 , 0.1174 , 0.11633, 0.11615,\n",
       "            0.11554, 0.115  , 0.11456, 0.11316, 0.1122 , 0.112  , 0.11127,\n",
       "            0.1103 , 0.1097 , 0.108  , 0.1058 , 0.1052 , 0.10504, 0.1032 ,\n",
       "            0.10144, 0.10016, 0.09827, 0.0957 , 0.0937 , 0.09283, 0.09235,\n",
       "            0.0922 , 0.09186, 0.0909 , 0.09076, 0.0906 , 0.0903 , 0.0898 ,\n",
       "            0.089  , 0.0862 , 0.08435, 0.08417, 0.08374, 0.08344, 0.0827 ,\n",
       "            0.08093, 0.0808 , 0.07574, 0.0716 , 0.0656 , 0.06476, 0.0577 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0546875,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.109375 , 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1796875, 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.5      , 0.5      , 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.75     , 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.765625 , 0.765625 , 0.7734375,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.796875 , 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.8671875, 0.875    , 0.875    , 0.875    , 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.953125 ,\n",
       "            0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.9609375,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.03278688, 0.04098361, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.31967214, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.60655737, 0.6147541 , 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.647541  , 0.6639344 ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.33   , 0.3298 , 0.3296 , 0.3284 , 0.3271 , 0.327  ,\n",
       "            0.326  , 0.3257 , 0.3254 , 0.3252 , 0.3242 , 0.3235 , 0.3232 ,\n",
       "            0.323  , 0.3228 , 0.3225 , 0.322  , 0.3218 , 0.3215 , 0.3203 ,\n",
       "            0.32   , 0.3193 , 0.3174 , 0.3154 , 0.315  , 0.3132 , 0.3123 ,\n",
       "            0.3115 , 0.3096 , 0.309  , 0.3086 , 0.3076 , 0.307  , 0.3064 ,\n",
       "            0.3027 , 0.2988 , 0.2986 , 0.2966 , 0.2954 , 0.2874 , 0.2856 ,\n",
       "            0.2854 , 0.2842 , 0.2832 , 0.28   , 0.279  , 0.2788 , 0.2786 ,\n",
       "            0.2773 , 0.276  , 0.2756 , 0.2734 , 0.2727 , 0.2715 , 0.2673 ,\n",
       "            0.266  , 0.2659 , 0.2644 , 0.2617 , 0.2612 , 0.261  , 0.2595 ,\n",
       "            0.2573 , 0.257  , 0.2527 , 0.2494 , 0.249  , 0.248  , 0.2471 ,\n",
       "            0.2462 , 0.2458 , 0.2456 , 0.2448 , 0.2426 , 0.2417 , 0.2401 ,\n",
       "            0.239  , 0.2386 , 0.235  , 0.2346 , 0.2339 , 0.2311 , 0.2292 ,\n",
       "            0.2269 , 0.2224 , 0.2216 , 0.2207 , 0.22   , 0.2179 , 0.2175 ,\n",
       "            0.2139 , 0.2128 , 0.2101 , 0.21   , 0.2094 , 0.209  , 0.2081 ,\n",
       "            0.208  , 0.2068 , 0.2053 , 0.205  , 0.2039 , 0.2031 , 0.2029 ,\n",
       "            0.2026 , 0.2012 , 0.1989 , 0.1967 , 0.196  , 0.1959 , 0.1947 ,\n",
       "            0.194  , 0.1912 , 0.1901 , 0.19   , 0.1893 , 0.1864 , 0.1848 ,\n",
       "            0.1835 , 0.1833 , 0.1831 , 0.1823 , 0.1814 , 0.1807 , 0.1803 ,\n",
       "            0.1788 , 0.1772 , 0.1764 , 0.1761 , 0.1758 , 0.1755 , 0.1753 ,\n",
       "            0.1752 , 0.1744 , 0.1743 , 0.1721 , 0.1714 , 0.1711 , 0.17   ,\n",
       "            0.1694 , 0.1687 , 0.1681 , 0.166  , 0.1656 , 0.1646 , 0.164  ,\n",
       "            0.1633 , 0.1627 , 0.1626 , 0.1616 , 0.1608 , 0.1584 , 0.1572 ,\n",
       "            0.157  , 0.1569 , 0.1561 , 0.1536 , 0.1531 , 0.152  , 0.1516 ,\n",
       "            0.1506 , 0.149  , 0.1488 , 0.1484 , 0.148  , 0.1444 , 0.1438 ,\n",
       "            0.1423 , 0.1418 , 0.1412 , 0.1407 , 0.1406 , 0.1405 , 0.1404 ,\n",
       "            0.1398 , 0.1349 , 0.1346 , 0.1342 , 0.1338 , 0.1323 , 0.1298 ,\n",
       "            0.1292 , 0.1273 , 0.1271 , 0.1255 , 0.12494, 0.1238 , 0.1232 ,\n",
       "            0.12305, 0.1226 , 0.1222 , 0.1214 , 0.121  , 0.1204 , 0.1195 ,\n",
       "            0.119  , 0.1188 , 0.11755, 0.11676, 0.1166 , 0.115  , 0.1134 ,\n",
       "            0.1095 , 0.10913, 0.1086 , 0.10706, 0.10614, 0.1058 , 0.1043 ,\n",
       "            0.10156, 0.10126, 0.1005 , 0.10034, 0.09894, 0.0979 , 0.0977 ,\n",
       "            0.0972 , 0.0967 , 0.0955 , 0.09186, 0.09106, 0.09076, 0.0901 ,\n",
       "            0.0873 , 0.08374, 0.0799 , 0.0741 , 0.07007, 0.0644 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0703125, 0.09375  , 0.109375 , 0.125    , 0.140625 , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.4765625, 0.4765625, 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.6015625, 0.609375 , 0.609375 , 0.6171875, 0.625    , 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.65625  , 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.703125 ,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.7109375, 0.71875  , 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  , 0.78125  ,\n",
       "            0.78125  , 0.78125  , 0.78125  , 0.78125  , 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.8671875, 0.8671875, 0.875    , 0.875    , 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.9453125, 0.953125 , 0.9609375, 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625,\n",
       "            0.9765625, 0.984375 , 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.03278688, 0.03278688, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09016393, 0.09016393, 0.09016393,\n",
       "            0.09016393, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.16393442, 0.18032786, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.3114754 ,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40163934, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.59016395, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.59836066, 0.60655737, 0.60655737,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.6393443 , 0.6393443 , 0.6393443 ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3223 , 0.322  , 0.3208 , 0.3196 , 0.3193 , 0.3188 ,\n",
       "            0.3186 , 0.3184 , 0.318  , 0.3179 , 0.3176 , 0.3171 , 0.317  ,\n",
       "            0.3164 , 0.3162 , 0.3154 , 0.3147 , 0.3137 , 0.3127 , 0.3123 ,\n",
       "            0.3118 , 0.3115 , 0.3098 , 0.309  , 0.3088 , 0.3086 , 0.3074 ,\n",
       "            0.3071 , 0.3064 , 0.3052 , 0.3042 , 0.3037 , 0.3032 , 0.303  ,\n",
       "            0.3025 , 0.3022 , 0.301  , 0.3008 , 0.3003 , 0.2976 , 0.297  ,\n",
       "            0.2954 , 0.2952 , 0.2944 , 0.293  , 0.2927 , 0.2925 , 0.2922 ,\n",
       "            0.2915 , 0.2905 , 0.288  , 0.2878 , 0.2861 , 0.2856 , 0.2854 ,\n",
       "            0.2847 , 0.2832 , 0.282  , 0.2812 , 0.281  , 0.2786 , 0.2776 ,\n",
       "            0.277  , 0.2747 , 0.2742 , 0.2725 , 0.271  , 0.2705 , 0.27   ,\n",
       "            0.2695 , 0.269  , 0.2664 , 0.2654 , 0.263  , 0.2615 , 0.2605 ,\n",
       "            0.259  , 0.256  , 0.2546 , 0.2542 , 0.2522 , 0.2517 , 0.251  ,\n",
       "            0.2478 , 0.247  , 0.2438 , 0.2433 , 0.2424 , 0.241  , 0.2401 ,\n",
       "            0.2382 , 0.2375 , 0.2372 , 0.2367 , 0.2303 , 0.2297 , 0.2295 ,\n",
       "            0.2292 , 0.2277 , 0.2274 , 0.2272 , 0.2257 , 0.2247 , 0.2242 ,\n",
       "            0.2217 , 0.2191 , 0.218  , 0.2179 , 0.2158 , 0.2157 , 0.2148 ,\n",
       "            0.214  , 0.2139 , 0.2133 , 0.2098 , 0.2094 , 0.2091 , 0.2085 ,\n",
       "            0.2059 , 0.2051 , 0.2047 , 0.2017 , 0.201  , 0.2009 , 0.2007 ,\n",
       "            0.2002 , 0.1998 , 0.199  , 0.1978 , 0.1974 , 0.1973 , 0.1925 ,\n",
       "            0.1924 , 0.1918 , 0.1904 , 0.1893 , 0.1892 , 0.1891 , 0.189  ,\n",
       "            0.1885 , 0.1876 , 0.1873 , 0.1864 , 0.1859 , 0.1858 , 0.1821 ,\n",
       "            0.1815 , 0.1813 , 0.1797 , 0.1788 , 0.1783 , 0.1763 , 0.1755 ,\n",
       "            0.1744 , 0.173  , 0.1708 , 0.1699 , 0.1696 , 0.169  , 0.1685 ,\n",
       "            0.1674 , 0.167  , 0.1649 , 0.1646 , 0.1627 , 0.1621 , 0.1617 ,\n",
       "            0.1606 , 0.1587 , 0.1572 , 0.1569 , 0.1559 , 0.1555 , 0.1545 ,\n",
       "            0.1517 , 0.151  , 0.1495 , 0.149  , 0.1487 , 0.1477 , 0.1466 ,\n",
       "            0.1462 , 0.1423 , 0.1421 , 0.1418 , 0.1414 , 0.1412 , 0.1411 ,\n",
       "            0.1405 , 0.1401 , 0.1389 , 0.1383 , 0.1376 , 0.1373 , 0.1362 ,\n",
       "            0.1335 , 0.1322 , 0.1318 , 0.1292 , 0.1278 , 0.1277 , 0.1274 ,\n",
       "            0.1272 , 0.1268 , 0.12305, 0.12286, 0.1223 , 0.1213 , 0.12085,\n",
       "            0.12067, 0.1204 , 0.1186 , 0.11816, 0.1174 , 0.1142 , 0.11163,\n",
       "            0.11066, 0.1093 , 0.10876, 0.1058 , 0.10266, 0.1011 , 0.09753,\n",
       "            0.09186, 0.0833 , 0.07965], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.078125 , 0.078125 , 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.109375 , 0.125    , 0.1328125, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.203125 , 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.234375 , 0.2421875, 0.265625 , 0.28125  ,\n",
       "            0.2890625, 0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.3203125,\n",
       "            0.328125 , 0.328125 , 0.34375  , 0.34375  , 0.34375  , 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.4765625, 0.4765625, 0.4765625, 0.4765625, 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.625    , 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.671875 ,\n",
       "            0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.6953125, 0.703125 , 0.703125 , 0.703125 , 0.703125 , 0.7109375,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.765625 , 0.765625 , 0.7734375,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.828125 , 0.828125 , 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.8828125, 0.8828125, 0.8828125, 0.8828125,\n",
       "            0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.9453125, 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.01639344, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.06557377, 0.06557377, 0.07377049,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.09836066,\n",
       "            0.09836066, 0.09836066, 0.09836066, 0.09836066, 0.10655738,\n",
       "            0.10655738, 0.10655738, 0.1147541 , 0.1147541 , 0.1147541 ,\n",
       "            0.1147541 , 0.1147541 , 0.12295082, 0.12295082, 0.12295082,\n",
       "            0.13114753, 0.13114753, 0.13114753, 0.13934426, 0.13934426,\n",
       "            0.13934426, 0.14754099, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.21311475, 0.21311475, 0.21311475,\n",
       "            0.21311475, 0.21311475, 0.21311475, 0.21311475, 0.22131148,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.24590164,\n",
       "            0.24590164, 0.24590164, 0.2704918 , 0.27868852, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.3442623 , 0.3442623 , 0.352459  ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59016395, 0.59836066, 0.59836066, 0.60655737,\n",
       "            0.60655737, 0.6147541 , 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3293 , 0.328  , 0.3242 , 0.3232 , 0.3228 , 0.322  ,\n",
       "            0.3218 , 0.3213 , 0.3203 , 0.32   , 0.319  , 0.3186 , 0.3184 ,\n",
       "            0.3176 , 0.3174 , 0.3162 , 0.316  , 0.3154 , 0.3152 , 0.315  ,\n",
       "            0.3147 , 0.3145 , 0.3142 , 0.314  , 0.3137 , 0.3135 , 0.3132 ,\n",
       "            0.313  , 0.3127 , 0.3125 , 0.3123 , 0.312  , 0.3115 , 0.311  ,\n",
       "            0.3108 , 0.3105 , 0.3088 , 0.308  , 0.3066 , 0.3062 , 0.3047 ,\n",
       "            0.3044 , 0.304  , 0.3037 , 0.3035 , 0.303  , 0.3022 , 0.2998 ,\n",
       "            0.2993 , 0.2988 , 0.298  , 0.2979 , 0.2976 , 0.2964 , 0.2961 ,\n",
       "            0.296  , 0.2954 , 0.295  , 0.2937 , 0.2917 , 0.2913 , 0.291  ,\n",
       "            0.2908 , 0.289  , 0.2876 , 0.2869 , 0.2866 , 0.286  , 0.2847 ,\n",
       "            0.2844 , 0.2827 , 0.2817 , 0.2815 , 0.2805 , 0.2786 , 0.2776 ,\n",
       "            0.277  , 0.2747 , 0.274  , 0.2737 , 0.2695 , 0.2673 , 0.2668 ,\n",
       "            0.2644 , 0.2634 , 0.263  , 0.2622 , 0.262  , 0.2607 , 0.2603 ,\n",
       "            0.26   , 0.2588 , 0.2585 , 0.258  , 0.2573 , 0.257  , 0.2556 ,\n",
       "            0.255  , 0.2534 , 0.2527 , 0.2522 , 0.252  , 0.246  , 0.2391 ,\n",
       "            0.2375 , 0.2355 , 0.2351 , 0.2344 , 0.2322 , 0.2318 , 0.2313 ,\n",
       "            0.2283 , 0.2272 , 0.2251 , 0.2234 , 0.2216 , 0.2207 , 0.2203 ,\n",
       "            0.2195 , 0.2194 , 0.2189 , 0.2186 , 0.2184 , 0.2177 , 0.2167 ,\n",
       "            0.2161 , 0.2145 , 0.2125 , 0.2114 , 0.2081 , 0.208  , 0.2068 ,\n",
       "            0.2065 , 0.2063 , 0.2056 , 0.2054 , 0.2047 , 0.2032 , 0.201  ,\n",
       "            0.2001 , 0.1981 , 0.1971 , 0.1946 , 0.1923 , 0.1904 , 0.1903 ,\n",
       "            0.1901 , 0.19   , 0.1896 , 0.1885 , 0.1824 , 0.1819 , 0.1788 ,\n",
       "            0.178  , 0.1768 , 0.1765 , 0.1763 , 0.1761 , 0.1743 , 0.1738 ,\n",
       "            0.1733 , 0.173  , 0.1725 , 0.1721 , 0.172  , 0.1714 , 0.1709 ,\n",
       "            0.1659 , 0.1647 , 0.1637 , 0.1636 , 0.1627 , 0.1622 , 0.161  ,\n",
       "            0.1608 , 0.1606 , 0.1598 , 0.158  , 0.1572 , 0.1567 , 0.1544 ,\n",
       "            0.1525 , 0.1514 , 0.151  , 0.15   , 0.1495 , 0.1492 , 0.1478 ,\n",
       "            0.1465 , 0.1443 , 0.144  , 0.1438 , 0.1436 , 0.1423 , 0.1409 ,\n",
       "            0.1383 , 0.1377 , 0.1345 , 0.1342 , 0.1305 , 0.1296 , 0.1289 ,\n",
       "            0.1266 , 0.126  , 0.1242 , 0.1196 , 0.11755, 0.11615, 0.1144 ,\n",
       "            0.10895, 0.09515, 0.0942 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.046875 ,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1484375, 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.2578125, 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.3203125,\n",
       "            0.3203125, 0.328125 , 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.3671875, 0.375    , 0.375    , 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.6953125, 0.703125 , 0.703125 , 0.703125 , 0.7109375,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.734375 , 0.7421875,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.7890625, 0.7890625, 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.8359375, 0.8359375,\n",
       "            0.84375  , 0.84375  , 0.84375  , 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.90625  , 0.9140625, 0.9140625, 0.9140625, 0.921875 ,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.1557377 , 0.16393442, 0.17213115, 0.19672132,\n",
       "            0.21311475, 0.21311475, 0.22131148, 0.22131148, 0.22950819,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.24590164, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.29508197,\n",
       "            0.29508197, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.31967214, 0.32786885, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.3442623 , 0.3442623 , 0.3442623 , 0.3442623 ,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.36885247, 0.36885247, 0.36885247, 0.36885247, 0.3852459 ,\n",
       "            0.3852459 , 0.3852459 , 0.3852459 , 0.3852459 , 0.3852459 ,\n",
       "            0.3852459 , 0.39344263, 0.39344263, 0.40163934, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.4262295 , 0.4262295 ,\n",
       "            0.4262295 , 0.4262295 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.46721312, 0.46721312,\n",
       "            0.46721312, 0.48360655, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59016395, 0.59016395, 0.59016395, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.7295082 , 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.76229507, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.358  , 0.3574 , 0.354  , 0.3538 , 0.3535 , 0.3525 ,\n",
       "            0.3516 , 0.3513 , 0.3508 , 0.3503 , 0.346  , 0.345  , 0.3445 ,\n",
       "            0.3442 , 0.344  , 0.3438 , 0.3413 , 0.3396 , 0.3394 , 0.339  ,\n",
       "            0.338  , 0.3376 , 0.3372 , 0.3364 , 0.3354 , 0.3333 , 0.3328 ,\n",
       "            0.3315 , 0.3306 , 0.328  , 0.327  , 0.3237 , 0.323  , 0.3228 ,\n",
       "            0.3223 , 0.3208 , 0.3206 , 0.3176 , 0.3174 , 0.3171 , 0.317  ,\n",
       "            0.3167 , 0.3162 , 0.3157 , 0.3154 , 0.3152 , 0.3147 , 0.3145 ,\n",
       "            0.314  , 0.3135 , 0.3125 , 0.3123 , 0.3118 , 0.311  , 0.3105 ,\n",
       "            0.3103 , 0.3098 , 0.3096 , 0.3093 , 0.309  , 0.3086 , 0.3079 ,\n",
       "            0.3076 , 0.3066 , 0.3062 , 0.3052 , 0.3044 , 0.304  , 0.3037 ,\n",
       "            0.3032 , 0.303  , 0.3025 , 0.302  , 0.301  , 0.3008 , 0.3005 ,\n",
       "            0.2996 , 0.298  , 0.2979 , 0.2976 , 0.2974 , 0.2961 , 0.2947 ,\n",
       "            0.2925 , 0.291  , 0.29   , 0.2896 , 0.289  , 0.2878 , 0.287  ,\n",
       "            0.2864 , 0.286  , 0.285  , 0.2847 , 0.283  , 0.2805 , 0.28   ,\n",
       "            0.279  , 0.2761 , 0.2747 , 0.2742 , 0.2734 , 0.2705 , 0.2695 ,\n",
       "            0.2693 , 0.269  , 0.2673 , 0.2668 , 0.2664 , 0.2642 , 0.2563 ,\n",
       "            0.2556 , 0.2544 , 0.2522 , 0.2489 , 0.2483 , 0.248  , 0.2467 ,\n",
       "            0.2452 , 0.244  , 0.2437 , 0.243  , 0.2426 , 0.2406 , 0.2402 ,\n",
       "            0.2394 , 0.2386 , 0.2362 , 0.2351 , 0.2335 , 0.233  , 0.2325 ,\n",
       "            0.2319 , 0.2318 , 0.2301 , 0.2297 , 0.2295 , 0.228  , 0.2269 ,\n",
       "            0.2268 , 0.2247 , 0.224  , 0.2227 , 0.2224 , 0.2217 , 0.2212 ,\n",
       "            0.2195 , 0.2162 , 0.2156 , 0.2153 , 0.2133 , 0.2119 , 0.2106 ,\n",
       "            0.2089 , 0.2073 , 0.2053 , 0.2047 , 0.2018 , 0.2017 , 0.2013 ,\n",
       "            0.1998 , 0.1982 , 0.1979 , 0.1971 , 0.197  , 0.1962 , 0.1958 ,\n",
       "            0.194  , 0.1936 , 0.1919 , 0.191  , 0.1901 , 0.1863 , 0.1859 ,\n",
       "            0.1858 , 0.1836 , 0.183  , 0.1824 , 0.1813 , 0.1796 , 0.1783 ,\n",
       "            0.1774 , 0.1765 , 0.1755 , 0.1744 , 0.1743 , 0.174  , 0.1737 ,\n",
       "            0.1725 , 0.1711 , 0.1707 , 0.1681 , 0.1666 , 0.1659 , 0.1656 ,\n",
       "            0.1615 , 0.1608 , 0.1606 , 0.1597 , 0.1567 , 0.1536 , 0.1519 ,\n",
       "            0.1514 , 0.1511 , 0.1501 , 0.1462 , 0.1451 , 0.1443 , 0.1398 ,\n",
       "            0.1396 , 0.138  , 0.1344 , 0.1333 , 0.1318 , 0.1298 , 0.1273 ,\n",
       "            0.1093 , 0.10706], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.109375 , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.359375 , 0.3671875, 0.375    , 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.625    , 0.625    , 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.71875  , 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.7421875, 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8046875,\n",
       "            0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.8203125, 0.828125 ,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.84375  , 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.875    , 0.875    ,\n",
       "            0.8828125, 0.8828125, 0.8828125, 0.8828125, 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.984375 , 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.1557377 , 0.16393442, 0.17213115, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.352459  , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.46721312,\n",
       "            0.46721312, 0.46721312, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.48360655, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5081967 , 0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.58196723, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.72131145, 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.74590164, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4187, 0.411 , 0.4016, 0.4   , 0.3992, 0.399 , 0.3972,\n",
       "            0.3965, 0.395 , 0.3923, 0.3909, 0.3892, 0.3867, 0.3865, 0.386 ,\n",
       "            0.385 , 0.383 , 0.3828, 0.382 , 0.38  , 0.3796, 0.3787, 0.3784,\n",
       "            0.3743, 0.3735, 0.3726, 0.372 , 0.3718, 0.3716, 0.3713, 0.3706,\n",
       "            0.3704, 0.3699, 0.3691, 0.3684, 0.3682, 0.367 , 0.3625, 0.3623,\n",
       "            0.3586, 0.3584, 0.358 , 0.3557, 0.3538, 0.3525, 0.3506, 0.349 ,\n",
       "            0.3477, 0.3472, 0.3464, 0.3438, 0.3428, 0.3418, 0.3416, 0.3408,\n",
       "            0.34  , 0.338 , 0.3357, 0.3342, 0.3335, 0.333 , 0.327 , 0.3267,\n",
       "            0.3245, 0.324 , 0.3237, 0.323 , 0.3228, 0.3223, 0.3198, 0.3193,\n",
       "            0.319 , 0.3186, 0.318 , 0.3176, 0.317 , 0.3162, 0.3152, 0.3132,\n",
       "            0.3123, 0.3118, 0.3115, 0.3098, 0.3088, 0.3076, 0.3074, 0.307 ,\n",
       "            0.3057, 0.3054, 0.305 , 0.3044, 0.3042, 0.3032, 0.3027, 0.3025,\n",
       "            0.3022, 0.3018, 0.3015, 0.301 , 0.2998, 0.2969, 0.2964, 0.2961,\n",
       "            0.2944, 0.2942, 0.2937, 0.2925, 0.2917, 0.2915, 0.2898, 0.288 ,\n",
       "            0.2876, 0.2869, 0.2864, 0.2834, 0.283 , 0.2825, 0.2815, 0.2808,\n",
       "            0.2803, 0.28  , 0.2778, 0.2756, 0.2737, 0.2725, 0.2712, 0.2695,\n",
       "            0.269 , 0.268 , 0.2676, 0.2668, 0.2644, 0.2625, 0.2617, 0.2612,\n",
       "            0.2605, 0.26  , 0.2593, 0.2588, 0.2583, 0.2554, 0.255 , 0.2546,\n",
       "            0.2502, 0.2498, 0.2494, 0.249 , 0.2466, 0.2452, 0.2433, 0.2415,\n",
       "            0.2397, 0.2378, 0.2367, 0.2355, 0.2346, 0.2338, 0.2335, 0.2334,\n",
       "            0.2332, 0.2316, 0.2302, 0.2297, 0.228 , 0.2278, 0.2272, 0.2266,\n",
       "            0.2252, 0.2251, 0.2249, 0.2246, 0.222 , 0.2186, 0.2179, 0.2177,\n",
       "            0.2172, 0.215 , 0.2144, 0.2125, 0.212 , 0.2104, 0.2086, 0.2081,\n",
       "            0.2069, 0.2068, 0.2063, 0.2058, 0.2043, 0.2029, 0.2015, 0.1993,\n",
       "            0.1991, 0.1974, 0.1967, 0.196 , 0.1958, 0.193 , 0.1925, 0.1923,\n",
       "            0.1918, 0.1865, 0.1863, 0.1859, 0.1842, 0.1816, 0.1783, 0.1781,\n",
       "            0.1772, 0.1748, 0.1709, 0.1688, 0.1677, 0.1637, 0.1621, 0.162 ,\n",
       "            0.1603, 0.1586, 0.155 , 0.1543, 0.1511, 0.1334, 0.1265],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.0625   , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1953125, 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.234375 , 0.2421875, 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.3515625, 0.359375 , 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.4140625, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.578125 , 0.578125 , 0.578125 , 0.59375  , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.640625 , 0.6484375, 0.6640625, 0.671875 ,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.7265625, 0.734375 , 0.734375 , 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.75     , 0.75     , 0.765625 , 0.7734375,\n",
       "            0.7734375, 0.7890625, 0.796875 , 0.796875 , 0.796875 , 0.8046875,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.8515625, 0.859375 , 0.859375 , 0.8671875, 0.875    , 0.875    ,\n",
       "            0.875    , 0.875    , 0.875    , 0.875    , 0.875    , 0.875    ,\n",
       "            0.875    , 0.875    , 0.8828125, 0.890625 , 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.921875 , 0.921875 , 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4262295 , 0.44262296,\n",
       "            0.45081967, 0.45081967, 0.45081967, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.4918033 , 0.4918033 , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.59836066, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.59836066, 0.59836066, 0.59836066,\n",
       "            0.60655737, 0.60655737, 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.6229508 , 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6639344 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6967213 , 0.6967213 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4783, 0.478 , 0.4602, 0.459 , 0.4573, 0.4556, 0.449 ,\n",
       "            0.4485, 0.4443, 0.4424, 0.44  , 0.4377, 0.4375, 0.4368, 0.4324,\n",
       "            0.4316, 0.43  , 0.4292, 0.429 , 0.4253, 0.4248, 0.424 , 0.4207,\n",
       "            0.4202, 0.4187, 0.4182, 0.4175, 0.4163, 0.414 , 0.4138, 0.4136,\n",
       "            0.4119, 0.4114, 0.411 , 0.4019, 0.401 , 0.4004, 0.4   , 0.398 ,\n",
       "            0.3977, 0.3975, 0.396 , 0.3953, 0.395 , 0.394 , 0.3894, 0.385 ,\n",
       "            0.3833, 0.3818, 0.3813, 0.379 , 0.3782, 0.3735, 0.356 , 0.353 ,\n",
       "            0.3513, 0.351 , 0.3508, 0.3506, 0.3472, 0.3464, 0.3433, 0.3428,\n",
       "            0.3425, 0.3403, 0.339 , 0.3386, 0.3364, 0.333 , 0.3328, 0.3315,\n",
       "            0.328 , 0.3271, 0.327 , 0.3264, 0.324 , 0.3235, 0.3225, 0.3223,\n",
       "            0.3218, 0.32  , 0.3196, 0.3193, 0.3176, 0.3171, 0.3167, 0.3164,\n",
       "            0.3147, 0.314 , 0.3135, 0.3132, 0.313 , 0.3123, 0.3108, 0.31  ,\n",
       "            0.3079, 0.3066, 0.3057, 0.305 , 0.3037, 0.3035, 0.303 , 0.3015,\n",
       "            0.3013, 0.3008, 0.2993, 0.298 , 0.2979, 0.2976, 0.2964, 0.2961,\n",
       "            0.295 , 0.2947, 0.2932, 0.293 , 0.2925, 0.2917, 0.2915, 0.2896,\n",
       "            0.2893, 0.289 , 0.2888, 0.2883, 0.2878, 0.2869, 0.2866, 0.2864,\n",
       "            0.286 , 0.2852, 0.2847, 0.2834, 0.2832, 0.2827, 0.2805, 0.2795,\n",
       "            0.2786, 0.277 , 0.2769, 0.2734, 0.2727, 0.2722, 0.267 , 0.2656,\n",
       "            0.2632, 0.2627, 0.2615, 0.2588, 0.2573, 0.2559, 0.2556, 0.255 ,\n",
       "            0.2542, 0.254 , 0.2534, 0.2532, 0.252 , 0.2517, 0.2512, 0.251 ,\n",
       "            0.2498, 0.2493, 0.2477, 0.2466, 0.2463, 0.2451, 0.2449, 0.243 ,\n",
       "            0.2418, 0.2415, 0.2401, 0.2399, 0.2391, 0.2388, 0.2375, 0.2374,\n",
       "            0.237 , 0.2318, 0.2314, 0.2307, 0.2278, 0.2273, 0.2269, 0.2251,\n",
       "            0.2244, 0.2218, 0.2205, 0.2195, 0.2185, 0.2179, 0.2167, 0.2163,\n",
       "            0.2142, 0.2124, 0.211 , 0.2109, 0.21  , 0.2096, 0.2089, 0.2048,\n",
       "            0.2024, 0.2009, 0.1985, 0.1973, 0.1959, 0.1941, 0.1907, 0.1858,\n",
       "            0.1849, 0.1843, 0.1824, 0.182 , 0.181 , 0.1749, 0.1748, 0.1707,\n",
       "            0.1682, 0.1565, 0.1445], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.06557377, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.2421875, 0.25     , 0.2578125,\n",
       "            0.2578125, 0.2734375, 0.28125  , 0.296875 , 0.3046875, 0.3203125,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5546875, 0.5703125, 0.5859375,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.75     , 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8046875, 0.8125   , 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.8359375,\n",
       "            0.8359375, 0.8359375, 0.8359375, 0.84375  , 0.84375  , 0.8515625,\n",
       "            0.8515625, 0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.984375 , 0.984375 , 0.984375 , 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59016395, 0.59016395, 0.59016395, 0.59016395,\n",
       "            0.59016395, 0.59016395, 0.59836066, 0.59836066, 0.59836066,\n",
       "            0.60655737, 0.60655737, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.63114756, 0.6393443 , 0.6393443 ,\n",
       "            0.6393443 , 0.6393443 , 0.6393443 , 0.6393443 , 0.6393443 ,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.73770493, 0.73770493,\n",
       "            0.73770493, 0.74590164, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.549 , 0.54  , 0.5317, 0.5273, 0.5244, 0.5225, 0.5186,\n",
       "            0.5044, 0.4922, 0.491 , 0.4897, 0.489 , 0.4888, 0.4883, 0.487 ,\n",
       "            0.4827, 0.4822, 0.4783, 0.477 , 0.474 , 0.472 , 0.4697, 0.469 ,\n",
       "            0.4688, 0.4683, 0.4678, 0.4656, 0.4617, 0.461 , 0.459 , 0.4587,\n",
       "            0.4573, 0.4553, 0.4521, 0.4512, 0.451 , 0.4502, 0.4485, 0.4478,\n",
       "            0.4475, 0.4465, 0.4434, 0.438 , 0.437 , 0.434 , 0.4326, 0.431 ,\n",
       "            0.4297, 0.429 , 0.428 , 0.4258, 0.425 , 0.4248, 0.4194, 0.4094,\n",
       "            0.4048, 0.403 , 0.4023, 0.3997, 0.3945, 0.3904, 0.3867, 0.386 ,\n",
       "            0.3772, 0.3767, 0.3748, 0.3699, 0.363 , 0.3625, 0.3618, 0.3606,\n",
       "            0.3574, 0.3555, 0.3552, 0.3538, 0.3535, 0.3518, 0.35  , 0.3489,\n",
       "            0.3484, 0.3457, 0.3445, 0.344 , 0.343 , 0.3403, 0.3396, 0.3374,\n",
       "            0.3367, 0.3364, 0.3362, 0.336 , 0.3345, 0.3342, 0.3313, 0.3286,\n",
       "            0.3284, 0.3271, 0.3264, 0.3254, 0.325 , 0.3218, 0.3213, 0.32  ,\n",
       "            0.3196, 0.3193, 0.3188, 0.3184, 0.318 , 0.3174, 0.3164, 0.3154,\n",
       "            0.3147, 0.3137, 0.3135, 0.3132, 0.3127, 0.3115, 0.3113, 0.3103,\n",
       "            0.3098, 0.3088, 0.3074, 0.306 , 0.3052, 0.3044, 0.3032, 0.303 ,\n",
       "            0.3022, 0.3005, 0.2998, 0.2996, 0.2993, 0.2969, 0.2966, 0.2952,\n",
       "            0.295 , 0.2942, 0.2935, 0.293 , 0.2922, 0.2915, 0.2913, 0.2903,\n",
       "            0.29  , 0.289 , 0.2869, 0.2864, 0.286 , 0.2852, 0.282 , 0.2815,\n",
       "            0.2812, 0.28  , 0.2795, 0.2793, 0.279 , 0.2783, 0.278 , 0.2769,\n",
       "            0.2766, 0.2761, 0.276 , 0.2742, 0.2737, 0.2717, 0.2712, 0.2708,\n",
       "            0.27  , 0.2683, 0.2673, 0.2666, 0.2656, 0.2654, 0.2646, 0.2637,\n",
       "            0.2632, 0.2605, 0.2568, 0.2551, 0.2546, 0.2537, 0.252 , 0.2483,\n",
       "            0.2482, 0.2478, 0.2467, 0.2451, 0.244 , 0.2438, 0.243 , 0.2422,\n",
       "            0.2406, 0.2402, 0.2386, 0.2379, 0.2375, 0.2374, 0.2352, 0.2344,\n",
       "            0.2339, 0.2325, 0.2313, 0.2307, 0.2299, 0.228 , 0.2256, 0.2251,\n",
       "            0.2244, 0.224 , 0.2235, 0.2211, 0.2197, 0.2181, 0.2179, 0.2119,\n",
       "            0.2109, 0.2089, 0.2086, 0.2081, 0.2075, 0.2068, 0.2064, 0.2   ,\n",
       "            0.1925, 0.1924, 0.1884, 0.1859, 0.1805, 0.1785, 0.1609],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.22950819, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.1640625, 0.1640625, 0.1640625, 0.1796875,\n",
       "            0.1875   , 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.359375 , 0.359375 , 0.3671875, 0.3671875,\n",
       "            0.3671875, 0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.65625  , 0.6640625, 0.6640625, 0.6796875, 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.796875 ,\n",
       "            0.8046875, 0.8046875, 0.8046875, 0.8046875, 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.828125 , 0.828125 , 0.828125 ,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.9140625, 0.9140625, 0.921875 , 0.921875 , 0.921875 , 0.9296875,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.984375 , 0.9921875, 0.9921875,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.24590164, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59016395, 0.59016395,\n",
       "            0.59016395, 0.59016395, 0.59016395, 0.59016395, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.647541  , 0.647541  ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.795082  , 0.795082  ,\n",
       "            0.795082  , 0.795082  , 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6157, 0.6006, 0.5977, 0.594 , 0.584 , 0.5825, 0.5566,\n",
       "            0.5454, 0.5435, 0.5415, 0.54  , 0.538 , 0.5356, 0.532 , 0.527 ,\n",
       "            0.5234, 0.523 , 0.52  , 0.5195, 0.519 , 0.5176, 0.5137, 0.5103,\n",
       "            0.5083, 0.505 , 0.5   , 0.4993, 0.4978, 0.4973, 0.4946, 0.4932,\n",
       "            0.4917, 0.4912, 0.49  , 0.4858, 0.4807, 0.478 , 0.4744, 0.47  ,\n",
       "            0.4695, 0.4656, 0.4644, 0.4626, 0.4607, 0.4595, 0.4573, 0.4553,\n",
       "            0.4507, 0.4497, 0.43  , 0.4285, 0.4253, 0.4175, 0.4172, 0.4158,\n",
       "            0.4119, 0.403 , 0.3972, 0.3962, 0.3882, 0.3826, 0.3809, 0.3792,\n",
       "            0.3782, 0.374 , 0.3738, 0.3723, 0.3706, 0.367 , 0.3665, 0.3647,\n",
       "            0.3635, 0.3628, 0.3564, 0.356 , 0.3542, 0.3538, 0.3494, 0.3462,\n",
       "            0.346 , 0.3457, 0.3442, 0.344 , 0.3438, 0.343 , 0.341 , 0.3396,\n",
       "            0.3386, 0.336 , 0.3342, 0.3337, 0.3335, 0.3315, 0.3308, 0.3306,\n",
       "            0.3303, 0.3296, 0.3289, 0.3274, 0.3271, 0.3262, 0.326 , 0.3257,\n",
       "            0.3235, 0.323 , 0.3225, 0.3215, 0.3184, 0.318 , 0.317 , 0.3157,\n",
       "            0.315 , 0.3147, 0.3145, 0.3142, 0.3127, 0.3125, 0.3103, 0.31  ,\n",
       "            0.3083, 0.308 , 0.3074, 0.3066, 0.306 , 0.3057, 0.3037, 0.303 ,\n",
       "            0.3005, 0.2988, 0.298 , 0.2976, 0.297 , 0.2944, 0.2932, 0.2922,\n",
       "            0.292 , 0.2917, 0.2903, 0.29  , 0.2898, 0.2896, 0.289 , 0.2874,\n",
       "            0.2869, 0.2866, 0.286 , 0.2854, 0.285 , 0.2825, 0.2815, 0.281 ,\n",
       "            0.2805, 0.2778, 0.2776, 0.2727, 0.2717, 0.2708, 0.27  , 0.2695,\n",
       "            0.2693, 0.269 , 0.268 , 0.2676, 0.2673, 0.2654, 0.2642, 0.2632,\n",
       "            0.2622, 0.2595, 0.258 , 0.2563, 0.2559, 0.2542, 0.252 , 0.2512,\n",
       "            0.248 , 0.2478, 0.2477, 0.2458, 0.2452, 0.2451, 0.2437, 0.2434,\n",
       "            0.2411, 0.2407, 0.239 , 0.2384, 0.2382, 0.2368, 0.2347, 0.2338,\n",
       "            0.2322, 0.2297, 0.229 , 0.2278, 0.2252, 0.2246, 0.2239, 0.2202,\n",
       "            0.2189, 0.2175, 0.2172, 0.2166, 0.2134, 0.2096, 0.2095, 0.208 ,\n",
       "            0.2075, 0.205 , 0.2037, 0.2004, 0.1978, 0.1934, 0.1871, 0.1863,\n",
       "            0.182 , 0.1652], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.39344263, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0546875, 0.0546875,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.25     , 0.2578125,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.3203125, 0.3203125, 0.3203125, 0.3359375,\n",
       "            0.3359375, 0.34375  , 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4296875, 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6875   , 0.6875   , 0.6875   , 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.71875  , 0.7265625, 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.75     , 0.75     , 0.75     ,\n",
       "            0.765625 , 0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.8671875, 0.8828125, 0.890625 ,\n",
       "            0.890625 , 0.890625 , 0.8984375, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.4918033 , 0.5       , 0.5081967 , 0.5081967 ,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6147541 , 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.63114756, 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 ,\n",
       "            0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 ,\n",
       "            0.6967213 , 0.71311474, 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.682 , 0.6733, 0.665 , 0.6577, 0.6514, 0.6465, 0.6445,\n",
       "            0.613 , 0.609 , 0.608 , 0.5986, 0.595 , 0.5913, 0.5845, 0.5806,\n",
       "            0.58  , 0.576 , 0.575 , 0.574 , 0.5737, 0.5723, 0.5693, 0.5674,\n",
       "            0.5664, 0.5635, 0.561 , 0.5576, 0.556 , 0.553 , 0.552 , 0.55  ,\n",
       "            0.5493, 0.547 , 0.5435, 0.54  , 0.539 , 0.5356, 0.5312, 0.5303,\n",
       "            0.528 , 0.523 , 0.522 , 0.5186, 0.516 , 0.515 , 0.5117, 0.51  ,\n",
       "            0.4995, 0.4958, 0.4949, 0.4934, 0.4924, 0.492 , 0.4805, 0.4785,\n",
       "            0.4656, 0.4612, 0.458 , 0.4578, 0.457 , 0.452 , 0.451 , 0.4448,\n",
       "            0.4412, 0.433 , 0.4294, 0.4275, 0.4236, 0.4224, 0.4143, 0.4136,\n",
       "            0.412 , 0.4114, 0.406 , 0.4043, 0.4011, 0.4001, 0.3972, 0.3967,\n",
       "            0.3965, 0.3936, 0.3933, 0.3923, 0.386 , 0.3835, 0.382 , 0.3818,\n",
       "            0.3782, 0.3765, 0.3733, 0.3718, 0.3682, 0.3677, 0.367 , 0.3645,\n",
       "            0.363 , 0.3628, 0.362 , 0.3604, 0.36  , 0.3584, 0.3577, 0.3572,\n",
       "            0.357 , 0.356 , 0.3557, 0.3552, 0.3542, 0.3538, 0.3533, 0.3496,\n",
       "            0.3494, 0.3464, 0.3462, 0.3452, 0.345 , 0.343 , 0.3418, 0.3408,\n",
       "            0.3406, 0.339 , 0.3345, 0.3335, 0.3325, 0.3318, 0.3306, 0.3303,\n",
       "            0.33  , 0.3296, 0.329 , 0.3289, 0.3262, 0.326 , 0.3245, 0.3228,\n",
       "            0.3225, 0.3218, 0.321 , 0.32  , 0.3193, 0.3186, 0.3176, 0.3164,\n",
       "            0.3162, 0.3154, 0.3137, 0.3125, 0.3096, 0.309 , 0.308 , 0.3071,\n",
       "            0.306 , 0.3044, 0.3027, 0.299 , 0.2983, 0.2961, 0.2947, 0.2944,\n",
       "            0.2937, 0.2922, 0.2915, 0.29  , 0.2898, 0.2896, 0.288 , 0.2874,\n",
       "            0.2861, 0.2847, 0.2832, 0.2825, 0.2822, 0.2798, 0.2769, 0.2761,\n",
       "            0.275 , 0.2747, 0.2742, 0.274 , 0.2712, 0.2703, 0.268 , 0.2673,\n",
       "            0.2656, 0.2654, 0.265 , 0.2646, 0.2644, 0.2642, 0.2634, 0.2627,\n",
       "            0.2625, 0.2622, 0.2615, 0.261 , 0.2607, 0.2603, 0.2593, 0.258 ,\n",
       "            0.257 , 0.2568, 0.2554, 0.255 , 0.2524, 0.2515, 0.2494, 0.2493,\n",
       "            0.2482, 0.2466, 0.244 , 0.2407, 0.2402, 0.2292, 0.2283, 0.2268,\n",
       "            0.223 , 0.2218, 0.2175, 0.2163, 0.2135, 0.2103, 0.2039, 0.202 ,\n",
       "            0.1995, 0.1959, 0.1958, 0.1948, 0.1934, 0.1882], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.45901638, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1953125, 0.203125 ,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.25     , 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.3203125, 0.328125 ,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.3984375,\n",
       "            0.40625  , 0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.59375  , 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6875   , 0.6953125, 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.859375 , 0.875    , 0.8828125, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.921875 , 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.9453125, 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5081967 , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.6229508 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.72131145, 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7354, 0.73  , 0.7207, 0.707 , 0.7056, 0.697 , 0.6943,\n",
       "            0.66  , 0.6597, 0.659 , 0.6465, 0.6396, 0.6367, 0.63  , 0.6265,\n",
       "            0.6235, 0.6206, 0.6196, 0.6167, 0.6157, 0.615 , 0.6113, 0.61  ,\n",
       "            0.6084, 0.607 , 0.6064, 0.6025, 0.5986, 0.598 , 0.5967, 0.595 ,\n",
       "            0.591 , 0.5894, 0.582 , 0.5806, 0.576 , 0.5713, 0.5654, 0.565 ,\n",
       "            0.563 , 0.56  , 0.5547, 0.5513, 0.551 , 0.548 , 0.542 , 0.5303,\n",
       "            0.527 , 0.5254, 0.525 , 0.5225, 0.5205, 0.5176, 0.5063, 0.4946,\n",
       "            0.4937, 0.4885, 0.4834, 0.4802, 0.479 , 0.4753, 0.475 , 0.4604,\n",
       "            0.459 , 0.454 , 0.4531, 0.4504, 0.4426, 0.4395, 0.439 , 0.434 ,\n",
       "            0.4338, 0.4333, 0.4287, 0.4277, 0.4255, 0.4214, 0.42  , 0.4197,\n",
       "            0.4172, 0.413 , 0.4124, 0.406 , 0.405 , 0.3955, 0.3928, 0.392 ,\n",
       "            0.3916, 0.3901, 0.3892, 0.3884, 0.3882, 0.3865, 0.3828, 0.3823,\n",
       "            0.382 , 0.3809, 0.3801, 0.3757, 0.3748, 0.3743, 0.374 , 0.371 ,\n",
       "            0.3699, 0.3687, 0.3667, 0.3662, 0.365 , 0.3647, 0.3596, 0.3594,\n",
       "            0.359 , 0.3574, 0.3572, 0.3564, 0.3557, 0.3552, 0.355 , 0.3547,\n",
       "            0.3538, 0.3528, 0.3506, 0.3496, 0.3486, 0.3481, 0.348 , 0.3462,\n",
       "            0.3445, 0.3442, 0.3418, 0.3403, 0.34  , 0.339 , 0.3364, 0.3357,\n",
       "            0.334 , 0.3333, 0.3325, 0.3318, 0.3306, 0.3293, 0.328 , 0.3247,\n",
       "            0.32  , 0.3198, 0.316 , 0.3152, 0.315 , 0.3142, 0.3135, 0.3132,\n",
       "            0.313 , 0.3108, 0.3088, 0.3083, 0.3079, 0.3074, 0.3057, 0.3047,\n",
       "            0.303 , 0.301 , 0.2998, 0.297 , 0.2966, 0.2947, 0.294 , 0.2922,\n",
       "            0.2915, 0.2898, 0.2896, 0.2893, 0.284 , 0.2837, 0.282 , 0.2808,\n",
       "            0.2798, 0.2788, 0.2783, 0.2776, 0.2766, 0.2761, 0.2756, 0.2742,\n",
       "            0.274 , 0.273 , 0.2712, 0.271 , 0.27  , 0.2695, 0.269 , 0.2686,\n",
       "            0.268 , 0.2678, 0.2673, 0.2668, 0.266 , 0.2656, 0.2654, 0.2632,\n",
       "            0.2625, 0.262 , 0.2578, 0.2566, 0.2563, 0.2556, 0.255 , 0.2537,\n",
       "            0.251 , 0.25  , 0.249 , 0.2471, 0.2462, 0.2413, 0.239 , 0.2382,\n",
       "            0.2362, 0.2344, 0.2339, 0.2294, 0.2166, 0.2161, 0.2147, 0.2144,\n",
       "            0.2076, 0.2063, 0.2037, 0.1993, 0.1904, 0.1869, 0.1821, 0.1812,\n",
       "            0.1792], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.5081967, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.140625 , 0.1484375, 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.171875 , 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.2421875, 0.25     , 0.2578125, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3125   , 0.3125   , 0.3125   ,\n",
       "            0.3125   , 0.3203125, 0.3203125, 0.328125 , 0.3359375, 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.3828125, 0.3828125,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.8359375,\n",
       "            0.84375  , 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.921875 , 0.9296875, 0.9296875, 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5081967 ,\n",
       "            0.5081967 , 0.5081967 , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.60655737, 0.60655737, 0.6147541 , 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.6229508 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.7295082 , 0.7295082 , 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7812, 0.7783, 0.769 , 0.753 , 0.751 , 0.741 , 0.739 ,\n",
       "            0.7065, 0.7056, 0.701 , 0.69  , 0.6807, 0.678 , 0.6743, 0.6665,\n",
       "            0.6646, 0.6606, 0.658 , 0.655 , 0.6543, 0.654 , 0.652 , 0.647 ,\n",
       "            0.6455, 0.6445, 0.643 , 0.6396, 0.637 , 0.6333, 0.6313, 0.6265,\n",
       "            0.624 , 0.6216, 0.615 , 0.61  , 0.6045, 0.6035, 0.5967, 0.5957,\n",
       "            0.595 , 0.5913, 0.587 , 0.581 , 0.5776, 0.5723, 0.5586, 0.5566,\n",
       "            0.5547, 0.552 , 0.55  , 0.547 , 0.5303, 0.527 , 0.5195, 0.5176,\n",
       "            0.508 , 0.5073, 0.504 , 0.499 , 0.496 , 0.4866, 0.483 , 0.4827,\n",
       "            0.482 , 0.4773, 0.4712, 0.4695, 0.4683, 0.4639, 0.463 , 0.462 ,\n",
       "            0.4587, 0.4548, 0.4526, 0.4492, 0.4473, 0.4456, 0.4395, 0.436 ,\n",
       "            0.433 , 0.4314, 0.428 , 0.4265, 0.421 , 0.4177, 0.4133, 0.4102,\n",
       "            0.4077, 0.4072, 0.407 , 0.4067, 0.4062, 0.406 , 0.4006, 0.4004,\n",
       "            0.3994, 0.3982, 0.3943, 0.3909, 0.3906, 0.39  , 0.3894, 0.3884,\n",
       "            0.386 , 0.3845, 0.3838, 0.381 , 0.3787, 0.3784, 0.378 , 0.3743,\n",
       "            0.373 , 0.372 , 0.371 , 0.3699, 0.3684, 0.368 , 0.3672, 0.366 ,\n",
       "            0.365 , 0.3645, 0.3638, 0.3635, 0.3633, 0.3623, 0.3594, 0.3582,\n",
       "            0.3574, 0.3567, 0.3564, 0.3552, 0.351 , 0.3499, 0.3494, 0.349 ,\n",
       "            0.3489, 0.347 , 0.3467, 0.3435, 0.343 , 0.338 , 0.336 , 0.3333,\n",
       "            0.33  , 0.3298, 0.3281, 0.327 , 0.3267, 0.3254, 0.3228, 0.322 ,\n",
       "            0.3174, 0.3162, 0.3142, 0.3113, 0.3103, 0.31  , 0.3086, 0.3079,\n",
       "            0.3064, 0.304 , 0.3032, 0.3027, 0.3022, 0.3013, 0.3008, 0.2998,\n",
       "            0.2966, 0.2954, 0.295 , 0.2942, 0.2932, 0.292 , 0.2915, 0.2898,\n",
       "            0.2886, 0.287 , 0.2852, 0.2832, 0.2822, 0.281 , 0.2808, 0.2803,\n",
       "            0.2795, 0.2788, 0.2766, 0.2761, 0.2747, 0.2742, 0.2737, 0.2727,\n",
       "            0.2717, 0.2705, 0.27  , 0.2695, 0.269 , 0.2678, 0.2651, 0.2644,\n",
       "            0.2622, 0.2612, 0.2605, 0.258 , 0.2563, 0.2559, 0.253 , 0.252 ,\n",
       "            0.2507, 0.25  , 0.2493, 0.2478, 0.2452, 0.2445, 0.2429, 0.2426,\n",
       "            0.2422, 0.2401, 0.2391, 0.236 , 0.2358, 0.2281, 0.2277, 0.2217,\n",
       "            0.214 , 0.2124, 0.212 , 0.2094, 0.207 , 0.2018, 0.1907, 0.1776,\n",
       "            0.1771, 0.1678, 0.1675, 0.1653], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.0390625, dtype=float32),\n",
       "    'tpr': array(0.5163934, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.015625 , 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1015625, 0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.140625 , 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.2421875,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.2890625, 0.296875 , 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3125   , 0.3203125, 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.3671875, 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.625    , 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5081967 , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.647541  , 0.647541  , 0.6557377 , 0.6639344 , 0.6639344 ,\n",
       "            0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.7295082 , 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.852459  , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8237, 0.823 , 0.814 , 0.798 , 0.7935, 0.7847, 0.782 ,\n",
       "            0.7524, 0.751 , 0.7437, 0.7334, 0.723 , 0.7217, 0.719 , 0.711 ,\n",
       "            0.7056, 0.703 , 0.6987, 0.6978, 0.6963, 0.696 , 0.695 , 0.694 ,\n",
       "            0.689 , 0.688 , 0.6836, 0.682 , 0.68  , 0.6777, 0.6733, 0.673 ,\n",
       "            0.6655, 0.663 , 0.6626, 0.653 , 0.646 , 0.645 , 0.6406, 0.6333,\n",
       "            0.633 , 0.6323, 0.6313, 0.63  , 0.625 , 0.615 , 0.6104, 0.6055,\n",
       "            0.5923, 0.592 , 0.5903, 0.59  , 0.582 , 0.5815, 0.5767, 0.56  ,\n",
       "            0.558 , 0.5483, 0.537 , 0.5337, 0.5317, 0.5225, 0.522 , 0.5137,\n",
       "            0.5103, 0.51  , 0.509 , 0.4995, 0.4976, 0.4956, 0.494 , 0.4922,\n",
       "            0.4883, 0.4863, 0.4832, 0.4763, 0.476 , 0.4722, 0.4714, 0.4695,\n",
       "            0.4636, 0.4568, 0.455 , 0.4495, 0.4485, 0.446 , 0.4429, 0.4424,\n",
       "            0.433 , 0.4287, 0.4265, 0.4248, 0.4243, 0.4238, 0.4233, 0.4224,\n",
       "            0.4172, 0.417 , 0.4119, 0.4114, 0.4082, 0.4077, 0.4062, 0.4058,\n",
       "            0.405 , 0.4038, 0.4004, 0.3994, 0.3992, 0.3982, 0.3967, 0.3958,\n",
       "            0.3936, 0.3909, 0.3906, 0.3884, 0.387 , 0.3862, 0.3838, 0.383 ,\n",
       "            0.3816, 0.3804, 0.38  , 0.378 , 0.377 , 0.3743, 0.3738, 0.373 ,\n",
       "            0.3706, 0.3694, 0.369 , 0.3682, 0.3677, 0.3665, 0.366 , 0.3638,\n",
       "            0.3625, 0.362 , 0.3604, 0.359 , 0.3582, 0.3508, 0.3503, 0.35  ,\n",
       "            0.3489, 0.3486, 0.3467, 0.3447, 0.3394, 0.3374, 0.3364, 0.3354,\n",
       "            0.3345, 0.334 , 0.3323, 0.329 , 0.3213, 0.3206, 0.3203, 0.3176,\n",
       "            0.3171, 0.3145, 0.3137, 0.3125, 0.3108, 0.3096, 0.308 , 0.307 ,\n",
       "            0.3064, 0.3062, 0.306 , 0.3032, 0.3018, 0.301 , 0.3005, 0.2969,\n",
       "            0.2966, 0.296 , 0.2937, 0.2932, 0.2925, 0.2903, 0.2898, 0.288 ,\n",
       "            0.2869, 0.2864, 0.2847, 0.283 , 0.2825, 0.2815, 0.281 , 0.2798,\n",
       "            0.2783, 0.2778, 0.277 , 0.2742, 0.2715, 0.271 , 0.2688, 0.2668,\n",
       "            0.2646, 0.263 , 0.2622, 0.2612, 0.26  , 0.2568, 0.2556, 0.2554,\n",
       "            0.2534, 0.2532, 0.2527, 0.2505, 0.2489, 0.2483, 0.2482, 0.2471,\n",
       "            0.2458, 0.2445, 0.2433, 0.2415, 0.2374, 0.2356, 0.2339, 0.2306,\n",
       "            0.2269, 0.2264, 0.2249, 0.2198, 0.2175, 0.2168, 0.2157, 0.215 ,\n",
       "            0.213 , 0.2002, 0.1909, 0.1794, 0.169 , 0.1654, 0.156 , 0.1558,\n",
       "            0.1536], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1171875, dtype=float32),\n",
       "    'tpr': array(0.55737704, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.125    , 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.1640625,\n",
       "            0.1640625, 0.1640625, 0.1796875, 0.1796875, 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.2421875, 0.2421875,\n",
       "            0.25     , 0.25     , 0.2578125, 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.2890625, 0.2890625, 0.3046875, 0.3125   ,\n",
       "            0.3125   , 0.3125   , 0.3125   , 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3671875, 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.78125  , 0.7890625, 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.6229508 , 0.63114756, 0.63114756, 0.6393443 , 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.647541  , 0.647541  ,\n",
       "            0.647541  , 0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8623, 0.86  , 0.853 , 0.8384, 0.8306, 0.823 , 0.821 ,\n",
       "            0.7954, 0.7935, 0.782 , 0.775 , 0.7637, 0.762 , 0.7607, 0.7544,\n",
       "            0.7456, 0.7446, 0.743 , 0.736 , 0.7354, 0.735 , 0.7344, 0.734 ,\n",
       "            0.7295, 0.7266, 0.7256, 0.72  , 0.719 , 0.7183, 0.718 , 0.711 ,\n",
       "            0.7065, 0.705 , 0.699 , 0.6904, 0.69  , 0.6816, 0.676 , 0.674 ,\n",
       "            0.673 , 0.668 , 0.6675, 0.667 , 0.649 , 0.643 , 0.6406, 0.6396,\n",
       "            0.6284, 0.6255, 0.623 , 0.6143, 0.6123, 0.6084, 0.605 , 0.587 ,\n",
       "            0.582 , 0.575 , 0.5737, 0.5645, 0.5547, 0.554 , 0.553 , 0.548 ,\n",
       "            0.547 , 0.5454, 0.545 , 0.538 , 0.5273, 0.5244, 0.524 , 0.523 ,\n",
       "            0.52  , 0.5166, 0.5137, 0.511 , 0.5107, 0.509 , 0.508 , 0.5044,\n",
       "            0.499 , 0.495 , 0.4893, 0.486 , 0.4749, 0.4731, 0.4702, 0.4695,\n",
       "            0.4663, 0.4656, 0.462 , 0.4612, 0.459 , 0.4546, 0.4543, 0.4526,\n",
       "            0.451 , 0.4495, 0.4465, 0.4438, 0.439 , 0.4375, 0.436 , 0.4358,\n",
       "            0.435 , 0.433 , 0.4307, 0.4302, 0.428 , 0.4233, 0.423 , 0.4229,\n",
       "            0.4224, 0.4219, 0.4202, 0.4192, 0.414 , 0.4136, 0.4119, 0.4111,\n",
       "            0.409 , 0.407 , 0.4062, 0.405 , 0.4045, 0.3992, 0.3982, 0.398 ,\n",
       "            0.3975, 0.397 , 0.3955, 0.3926, 0.3904, 0.39  , 0.3882, 0.3806,\n",
       "            0.3794, 0.3777, 0.3738, 0.3726, 0.37  , 0.3691, 0.3667, 0.3655,\n",
       "            0.365 , 0.3584, 0.357 , 0.3552, 0.355 , 0.3547, 0.3525, 0.3477,\n",
       "            0.3455, 0.3447, 0.3433, 0.3425, 0.342 , 0.3416, 0.3403, 0.3352,\n",
       "            0.3345, 0.3337, 0.3325, 0.3306, 0.329 , 0.3271, 0.3242, 0.3237,\n",
       "            0.3235, 0.3174, 0.315 , 0.3145, 0.3142, 0.3137, 0.313 , 0.3123,\n",
       "            0.3105, 0.31  , 0.3098, 0.3093, 0.3086, 0.3057, 0.3052, 0.3044,\n",
       "            0.303 , 0.2986, 0.2983, 0.2976, 0.2974, 0.2927, 0.2908, 0.2886,\n",
       "            0.288 , 0.2837, 0.2808, 0.2795, 0.2776, 0.274 , 0.273 , 0.2712,\n",
       "            0.2708, 0.268 , 0.2673, 0.2656, 0.261 , 0.2605, 0.2578, 0.2559,\n",
       "            0.2556, 0.2502, 0.2494, 0.2473, 0.2463, 0.2448, 0.2434, 0.2415,\n",
       "            0.2411, 0.2395, 0.2382, 0.2375, 0.2358, 0.2292, 0.2273, 0.2272,\n",
       "            0.2251, 0.2222, 0.2185, 0.218 , 0.211 , 0.2098, 0.1915, 0.1805,\n",
       "            0.1709, 0.1665, 0.1561, 0.1461, 0.1449, 0.1428], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1328125, dtype=float32),\n",
       "    'tpr': array(0.57377046, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.046875 , 0.0546875, 0.0546875, 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2421875, 0.25     , 0.25     , 0.25     , 0.2578125,\n",
       "            0.2578125, 0.2578125, 0.2578125, 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3125   , 0.328125 , 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.3515625, 0.359375 ,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.4140625, 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.421875 , 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.4921875, 0.4921875, 0.4921875, 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.796875 , 0.8046875, 0.8046875, 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.33606556, 0.3442623 ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.5       , 0.5081967 , 0.5081967 , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59836066, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.647541  , 0.647541  ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.74590164, 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8906, 0.8877, 0.883 , 0.869 , 0.86  , 0.8535, 0.8516,\n",
       "            0.8286, 0.8257, 0.8135, 0.808 , 0.799 , 0.795 , 0.7935, 0.789 ,\n",
       "            0.7812, 0.7783, 0.7754, 0.7695, 0.769 , 0.7686, 0.7676, 0.7666,\n",
       "            0.7627, 0.7617, 0.7603, 0.7524, 0.752 , 0.7515, 0.743 , 0.741 ,\n",
       "            0.7373, 0.731 , 0.725 , 0.7217, 0.7124, 0.707 , 0.7065, 0.701 ,\n",
       "            0.698 , 0.6978, 0.6787, 0.674 , 0.672 , 0.67  , 0.658 , 0.6543,\n",
       "            0.6523, 0.6416, 0.64  , 0.636 , 0.6353, 0.6157, 0.6123, 0.6084,\n",
       "            0.603 , 0.589 , 0.584 , 0.5806, 0.58  , 0.5747, 0.5703, 0.5693,\n",
       "            0.5635, 0.5513, 0.548 , 0.5464, 0.5454, 0.5405, 0.539 , 0.538 ,\n",
       "            0.5356, 0.533 , 0.5327, 0.5303, 0.5293, 0.5264, 0.5225, 0.511 ,\n",
       "            0.505 , 0.4968, 0.4941, 0.4917, 0.4856, 0.484 , 0.4812, 0.4807,\n",
       "            0.4792, 0.4763, 0.473 , 0.4707, 0.4705, 0.47  , 0.469 , 0.4683,\n",
       "            0.465 , 0.4548, 0.4546, 0.4521, 0.4504, 0.4497, 0.4492, 0.446 ,\n",
       "            0.4458, 0.4443, 0.4426, 0.4417, 0.441 , 0.4402, 0.4397, 0.434 ,\n",
       "            0.433 , 0.4329, 0.4324, 0.4272, 0.4263, 0.4258, 0.4246, 0.4236,\n",
       "            0.4224, 0.4202, 0.419 , 0.4177, 0.4126, 0.4124, 0.4094, 0.4092,\n",
       "            0.4082, 0.4067, 0.4062, 0.406 , 0.4043, 0.403 , 0.3848, 0.3835,\n",
       "            0.383 , 0.3823, 0.382 , 0.3813, 0.3801, 0.3782, 0.3772, 0.376 ,\n",
       "            0.3733, 0.373 , 0.367 , 0.3667, 0.3599, 0.3591, 0.358 , 0.3572,\n",
       "            0.3557, 0.3547, 0.3525, 0.3516, 0.347 , 0.3467, 0.343 , 0.337 ,\n",
       "            0.3367, 0.3352, 0.3345, 0.333 , 0.3315, 0.3252, 0.3242, 0.3237,\n",
       "            0.3223, 0.3218, 0.321 , 0.3176, 0.3171, 0.3157, 0.3115, 0.3064,\n",
       "            0.3057, 0.3025, 0.302 , 0.3018, 0.3005, 0.3003, 0.2961, 0.294 ,\n",
       "            0.2932, 0.293 , 0.2888, 0.2834, 0.2832, 0.2805, 0.2776, 0.2761,\n",
       "            0.2722, 0.2705, 0.2668, 0.2664, 0.262 , 0.2585, 0.256 , 0.2544,\n",
       "            0.2542, 0.254 , 0.2532, 0.251 , 0.2502, 0.2493, 0.2426, 0.2421,\n",
       "            0.2418, 0.2394, 0.2384, 0.2351, 0.2332, 0.2327, 0.2322, 0.2289,\n",
       "            0.2239, 0.2203, 0.2189, 0.2179, 0.213 , 0.2089, 0.2085, 0.2017,\n",
       "            0.2002, 0.1831, 0.1699, 0.1604, 0.1577, 0.1455, 0.1355, 0.134 ,\n",
       "            0.132 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1640625, dtype=float32),\n",
       "    'tpr': array(0.59836066, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0546875, 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.078125 , 0.078125 ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.25     , 0.25     , 0.25     , 0.25     ,\n",
       "            0.25     , 0.25     , 0.25     , 0.2578125, 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.296875 , 0.3046875, 0.3125   , 0.3125   , 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.375    , 0.375    , 0.3828125, 0.390625 , 0.390625 ,\n",
       "            0.390625 , 0.390625 , 0.390625 , 0.3984375, 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5      , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.75     , 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.20491803, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.4918033 , 0.5       , 0.5       , 0.5081967 , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.6229508 , 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.73770493, 0.73770493,\n",
       "            0.73770493, 0.74590164, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9116, 0.9077, 0.9043, 0.8916, 0.8813, 0.876 , 0.874 ,\n",
       "            0.854 , 0.8506, 0.837 , 0.833 , 0.8267, 0.8193, 0.8174, 0.8164,\n",
       "            0.811 , 0.805 , 0.8   , 0.799 , 0.7954, 0.792 , 0.7915, 0.79  ,\n",
       "            0.7896, 0.781 , 0.7783, 0.7764, 0.776 , 0.7695, 0.768 , 0.7637,\n",
       "            0.7544, 0.7456, 0.7363, 0.735 , 0.7334, 0.73  , 0.7295, 0.7227,\n",
       "            0.721 , 0.7207, 0.7056, 0.7007, 0.694 , 0.6934, 0.684 , 0.678 ,\n",
       "            0.673 , 0.666 , 0.6626, 0.66  , 0.6567, 0.641 , 0.6313, 0.631 ,\n",
       "            0.6284, 0.6187, 0.6094, 0.6084, 0.6074, 0.607 , 0.594 , 0.5903,\n",
       "            0.5854, 0.576 , 0.5737, 0.5684, 0.5664, 0.566 , 0.565 , 0.562 ,\n",
       "            0.561 , 0.56  , 0.5576, 0.556 , 0.553 , 0.55  , 0.536 , 0.525 ,\n",
       "            0.524 , 0.5205, 0.519 , 0.512 , 0.51  , 0.5044, 0.502 , 0.4998,\n",
       "            0.4983, 0.4976, 0.4966, 0.4956, 0.4954, 0.495 , 0.4941, 0.4922,\n",
       "            0.4897, 0.479 , 0.477 , 0.4753, 0.471 , 0.47  , 0.469 , 0.4685,\n",
       "            0.467 , 0.4663, 0.466 , 0.4658, 0.463 , 0.4565, 0.4556, 0.454 ,\n",
       "            0.452 , 0.4504, 0.447 , 0.4456, 0.444 , 0.4434, 0.4421, 0.438 ,\n",
       "            0.4363, 0.4358, 0.4353, 0.4346, 0.434 , 0.4338, 0.4275, 0.4272,\n",
       "            0.426 , 0.424 , 0.4233, 0.4219, 0.4158, 0.4045, 0.404 , 0.403 ,\n",
       "            0.3994, 0.3982, 0.3977, 0.394 , 0.3923, 0.3894, 0.3884, 0.3862,\n",
       "            0.385 , 0.383 , 0.382 , 0.3813, 0.3801, 0.3784, 0.375 , 0.3733,\n",
       "            0.3687, 0.3674, 0.3643, 0.3582, 0.3577, 0.356 , 0.352 , 0.3516,\n",
       "            0.3496, 0.3486, 0.3481, 0.347 , 0.3464, 0.346 , 0.3394, 0.339 ,\n",
       "            0.3367, 0.3352, 0.3347, 0.3328, 0.332 , 0.3315, 0.3298, 0.3267,\n",
       "            0.3232, 0.3208, 0.3196, 0.314 , 0.3137, 0.3096, 0.3093, 0.3062,\n",
       "            0.306 , 0.3005, 0.2993, 0.2966, 0.296 , 0.2908, 0.29  , 0.2893,\n",
       "            0.2854, 0.2808, 0.2769, 0.2766, 0.2751, 0.2737, 0.272 , 0.2644,\n",
       "            0.2632, 0.258 , 0.2563, 0.2551, 0.252 , 0.2489, 0.2487, 0.2456,\n",
       "            0.2452, 0.2438, 0.2426, 0.2355, 0.2347, 0.2319, 0.2301, 0.2268,\n",
       "            0.2247, 0.2225, 0.222 , 0.2189, 0.2091, 0.2085, 0.2068, 0.202 ,\n",
       "            0.1979, 0.1974, 0.1934, 0.1876, 0.1711, 0.1586, 0.1527, 0.1511,\n",
       "            0.1359, 0.1259, 0.1232, 0.1213], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.2109375, dtype=float32),\n",
       "    'tpr': array(0.6393443, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.1640625,\n",
       "            0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.2421875,\n",
       "            0.25     , 0.25     , 0.25     , 0.25     , 0.25     , 0.2578125,\n",
       "            0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.2890625, 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.3984375,\n",
       "            0.3984375, 0.3984375, 0.3984375, 0.40625  , 0.40625  , 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.5234375, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18852459, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.60655737, 0.6147541 , 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.6393443 , 0.6393443 ,\n",
       "            0.6393443 , 0.647541  , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9287 , 0.9243 , 0.922  , 0.9106 , 0.9    , 0.8955 ,\n",
       "            0.8936 , 0.876  , 0.8726 , 0.8584 , 0.8555 , 0.8506 , 0.842  ,\n",
       "            0.841  , 0.839  , 0.837  , 0.829  , 0.824  , 0.822  , 0.8193 ,\n",
       "            0.819  , 0.8154 , 0.8145 , 0.814  , 0.8115 , 0.8066 , 0.8027 ,\n",
       "            0.799  , 0.7954 , 0.791  , 0.7876 , 0.7817 , 0.777  , 0.7686 ,\n",
       "            0.761  , 0.759  , 0.7583 , 0.756  , 0.752  , 0.7456 , 0.743  ,\n",
       "            0.742  , 0.7344 , 0.722  , 0.716  , 0.7153 , 0.708  , 0.701  ,\n",
       "            0.6934 , 0.693  , 0.683  , 0.6797 , 0.6772 , 0.6655 , 0.657  ,\n",
       "            0.6523 , 0.652  , 0.6494 , 0.648  , 0.637  , 0.6333 , 0.6323 ,\n",
       "            0.6313 , 0.6294 , 0.617  , 0.6147 , 0.6016 , 0.601  , 0.598  ,\n",
       "            0.5967 , 0.589  , 0.5884 , 0.587  , 0.586  , 0.5854 , 0.585  ,\n",
       "            0.5796 , 0.5693 , 0.567  , 0.558  , 0.5493 , 0.543  , 0.542  ,\n",
       "            0.541  , 0.537  , 0.531  , 0.5254 , 0.525  , 0.522  , 0.519  ,\n",
       "            0.5186 , 0.517  , 0.5166 , 0.516  , 0.5107 , 0.507  , 0.5063 ,\n",
       "            0.5005 , 0.4958 , 0.4924 , 0.4922 , 0.4907 , 0.4868 , 0.4866 ,\n",
       "            0.486  , 0.4841 , 0.484  , 0.4836 , 0.4783 , 0.478  , 0.468  ,\n",
       "            0.4673 , 0.4646 , 0.464  , 0.4639 , 0.4617 , 0.4597 , 0.4595 ,\n",
       "            0.4583 , 0.4563 , 0.4558 , 0.4531 , 0.451  , 0.4468 , 0.4438 ,\n",
       "            0.4436 , 0.4424 , 0.4417 , 0.4404 , 0.4387 , 0.4363 , 0.4343 ,\n",
       "            0.4316 , 0.4292 , 0.4287 , 0.4246 , 0.4216 , 0.4192 , 0.4177 ,\n",
       "            0.4128 , 0.4114 , 0.4087 , 0.408  , 0.4055 , 0.405  , 0.4011 ,\n",
       "            0.3992 , 0.3945 , 0.394  , 0.3923 , 0.392  , 0.387  , 0.3855 ,\n",
       "            0.3835 , 0.3828 , 0.3792 , 0.375  , 0.37   , 0.3687 , 0.3645 ,\n",
       "            0.3633 , 0.3625 , 0.3618 , 0.3608 , 0.3586 , 0.3574 , 0.357  ,\n",
       "            0.3523 , 0.3489 , 0.348  , 0.3477 , 0.3474 , 0.3442 , 0.342  ,\n",
       "            0.3362 , 0.3354 , 0.3352 , 0.3298 , 0.329  , 0.3262 , 0.3257 ,\n",
       "            0.3218 , 0.3154 , 0.3127 , 0.3032 , 0.301  , 0.2998 , 0.2974 ,\n",
       "            0.297  , 0.2932 , 0.2927 , 0.2908 , 0.289  , 0.2874 , 0.2844 ,\n",
       "            0.284  , 0.2766 , 0.2742 , 0.2727 , 0.2722 , 0.269  , 0.2664 ,\n",
       "            0.2642 , 0.2605 , 0.2588 , 0.2563 , 0.2473 , 0.2463 , 0.2417 ,\n",
       "            0.239  , 0.2384 , 0.2368 , 0.2355 , 0.2325 , 0.2319 , 0.2299 ,\n",
       "            0.2263 , 0.2216 , 0.2195 , 0.214  , 0.2118 , 0.2113 , 0.2085 ,\n",
       "            0.1982 , 0.1979 , 0.1948 , 0.1907 , 0.1865 , 0.1863 , 0.1836 ,\n",
       "            0.1753 , 0.1598 , 0.1475 , 0.1458 , 0.1411 , 0.1257 , 0.11597,\n",
       "            0.1126 , 0.11066], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.25, dtype=float32),\n",
       "    'tpr': array(0.6885246, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1015625, 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.25     , 0.25     , 0.25     , 0.25     , 0.25     , 0.2578125,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.265625 , 0.265625 , 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.375    ,\n",
       "            0.375    , 0.375    , 0.3828125, 0.390625 , 0.390625 , 0.3984375,\n",
       "            0.3984375, 0.3984375, 0.3984375, 0.3984375, 0.40625  , 0.40625  ,\n",
       "            0.40625  , 0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4609375, 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.4765625, 0.484375 , 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.71875  , 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18852459, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.63114756, 0.6393443 ,\n",
       "            0.6393443 , 0.6393443 , 0.6393443 , 0.647541  , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.945  , 0.9404 , 0.939  , 0.929  , 0.919  , 0.915  ,\n",
       "            0.913  , 0.898  , 0.895  , 0.881  , 0.879  , 0.875  , 0.866  ,\n",
       "            0.865  , 0.8633 , 0.863  , 0.855  , 0.8516 , 0.846  , 0.8457 ,\n",
       "            0.8447 , 0.843  , 0.84   , 0.8394 , 0.836  , 0.8345 , 0.8296 ,\n",
       "            0.824  , 0.8237 , 0.817  , 0.8145 , 0.8105 , 0.8027 , 0.795  ,\n",
       "            0.7905 , 0.7866 , 0.785  , 0.7847 , 0.778  , 0.772  , 0.769  ,\n",
       "            0.768  , 0.766  , 0.7476 , 0.7427 , 0.741  , 0.736  , 0.728  ,\n",
       "            0.7246 , 0.7183 , 0.708  , 0.7046 , 0.702  , 0.6943 , 0.6875 ,\n",
       "            0.6807 , 0.6787 , 0.673  , 0.6694 , 0.6626 , 0.662  , 0.661  ,\n",
       "            0.6543 , 0.645  , 0.6426 , 0.625  , 0.624  , 0.6226 , 0.6196 ,\n",
       "            0.616  , 0.6157 , 0.615  , 0.6143 , 0.6133 , 0.61   , 0.6055 ,\n",
       "            0.5938 , 0.586  , 0.584  , 0.577  , 0.57   , 0.569  , 0.5645 ,\n",
       "            0.5625 , 0.556  , 0.5527 , 0.5503 , 0.5454 , 0.543  , 0.54   ,\n",
       "            0.5327 , 0.528  , 0.5244 , 0.5234 , 0.523  , 0.518  , 0.5166 ,\n",
       "            0.513  , 0.51   , 0.5083 , 0.505  , 0.503  , 0.502  , 0.4966 ,\n",
       "            0.4863 , 0.4841 , 0.484  , 0.4836 , 0.483  , 0.4822 , 0.4814 ,\n",
       "            0.4783 , 0.476  , 0.4739 , 0.4724 , 0.4705 , 0.4702 , 0.4631 ,\n",
       "            0.4626 , 0.4585 , 0.4565 , 0.4563 , 0.4524 , 0.452  , 0.4517 ,\n",
       "            0.4492 , 0.4485 , 0.4417 , 0.4404 , 0.4397 , 0.4395 , 0.4375 ,\n",
       "            0.437  , 0.4363 , 0.43   , 0.4292 , 0.4258 , 0.4255 , 0.423  ,\n",
       "            0.4216 , 0.4177 , 0.4163 , 0.4138 , 0.4124 , 0.411  , 0.4094 ,\n",
       "            0.4019 , 0.3982 , 0.3923 , 0.392  , 0.3914 , 0.389  , 0.3867 ,\n",
       "            0.384  , 0.381  , 0.3792 , 0.3767 , 0.3735 , 0.3684 , 0.3674 ,\n",
       "            0.3643 , 0.3599 , 0.3594 , 0.3591 , 0.3555 , 0.3525 , 0.35   ,\n",
       "            0.3489 , 0.347  , 0.3464 , 0.3438 , 0.3394 , 0.3352 , 0.3296 ,\n",
       "            0.3286 , 0.327  , 0.3242 , 0.319  , 0.3137 , 0.3096 , 0.3064 ,\n",
       "            0.3044 , 0.2998 , 0.2966 , 0.295  , 0.289  , 0.2876 , 0.2852 ,\n",
       "            0.2808 , 0.2803 , 0.279  , 0.2776 , 0.2754 , 0.274  , 0.267  ,\n",
       "            0.2666 , 0.264  , 0.2588 , 0.2573 , 0.2505 , 0.2411 , 0.2388 ,\n",
       "            0.2358 , 0.2335 , 0.233  , 0.2306 , 0.2302 , 0.229  , 0.2247 ,\n",
       "            0.2238 , 0.2195 , 0.213  , 0.2051 , 0.2029 , 0.2024 , 0.2    ,\n",
       "            0.1893 , 0.1886 , 0.1848 , 0.1813 , 0.177  , 0.1766 , 0.1748 ,\n",
       "            0.1649 , 0.15   , 0.1378 , 0.1318 , 0.11633, 0.1067 , 0.1032 ,\n",
       "            0.10126], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.265625, dtype=float32),\n",
       "    'tpr': array(0.73770493, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.25     , 0.25     , 0.25     , 0.25     , 0.25     ,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.2734375, 0.28125  , 0.28125  , 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.3828125, 0.390625 , 0.390625 ,\n",
       "            0.390625 , 0.390625 , 0.3984375, 0.3984375, 0.40625  , 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.17213115, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.47540984, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.72131145, 0.7295082 , 0.7295082 ,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.795082  , 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9556 , 0.951  , 0.95   , 0.942  , 0.931  , 0.928  ,\n",
       "            0.927  , 0.9136 , 0.9106 , 0.8965 , 0.895  , 0.8926 , 0.884  ,\n",
       "            0.883  , 0.882  , 0.8784 , 0.873  , 0.8716 , 0.8643 , 0.8633 ,\n",
       "            0.863  , 0.859  , 0.858  , 0.857  , 0.855  , 0.852  , 0.8486 ,\n",
       "            0.844  , 0.843  , 0.8423 , 0.836  , 0.8345 , 0.833  , 0.8203 ,\n",
       "            0.814  , 0.8125 , 0.8076 , 0.807  , 0.8037 , 0.7954 , 0.7915 ,\n",
       "            0.7866 , 0.786  , 0.7656 , 0.762  , 0.76   , 0.758  , 0.751  ,\n",
       "            0.749  , 0.735  , 0.7266 , 0.721  , 0.7207 , 0.7173 , 0.7134 ,\n",
       "            0.7124 , 0.704  , 0.701  , 0.699  , 0.69   , 0.6895 , 0.689  ,\n",
       "            0.6885 , 0.6733 , 0.669  , 0.6685 , 0.6533 , 0.65   , 0.6465 ,\n",
       "            0.6436 , 0.642  , 0.6416 , 0.64   , 0.639  , 0.637  , 0.6357 ,\n",
       "            0.6304 , 0.63   , 0.615  , 0.61   , 0.6074 , 0.5986 , 0.598  ,\n",
       "            0.597  , 0.596  , 0.586  , 0.5825 , 0.582  , 0.5776 , 0.576  ,\n",
       "            0.571  , 0.5703 , 0.568  , 0.567  , 0.564  , 0.557  , 0.554  ,\n",
       "            0.549  , 0.548  , 0.544  , 0.5405 , 0.539  , 0.5386 , 0.538  ,\n",
       "            0.536  , 0.5356 , 0.5337 , 0.5293 , 0.524  , 0.5176 , 0.5166 ,\n",
       "            0.51   , 0.5083 , 0.508  , 0.5073 , 0.502  , 0.4998 , 0.4978 ,\n",
       "            0.497  , 0.4949 , 0.4946 , 0.4888 , 0.487  , 0.4822 , 0.48   ,\n",
       "            0.4795 , 0.4727 , 0.471  , 0.4695 , 0.4675 , 0.4663 , 0.4658 ,\n",
       "            0.4656 , 0.4639 , 0.4604 , 0.4568 , 0.4534 , 0.4526 , 0.4524 ,\n",
       "            0.452  , 0.4514 , 0.4502 , 0.4478 , 0.447  , 0.446  , 0.4453 ,\n",
       "            0.445  , 0.4434 , 0.437  , 0.4368 , 0.429  , 0.4268 , 0.4243 ,\n",
       "            0.4194 , 0.4119 , 0.4102 , 0.408  , 0.407  , 0.4045 , 0.403  ,\n",
       "            0.3977 , 0.395  , 0.3948 , 0.3867 , 0.3857 , 0.3853 , 0.3845 ,\n",
       "            0.3823 , 0.3809 , 0.38   , 0.3765 , 0.376  , 0.3718 , 0.3708 ,\n",
       "            0.369  , 0.3667 , 0.3628 , 0.3613 , 0.3477 , 0.3457 , 0.3389 ,\n",
       "            0.3345 , 0.3335 , 0.3315 , 0.33   , 0.3296 , 0.3293 , 0.3208 ,\n",
       "            0.3186 , 0.3132 , 0.2974 , 0.297  , 0.2961 , 0.2935 , 0.293  ,\n",
       "            0.2917 , 0.2852 , 0.285  , 0.2847 , 0.284  , 0.283  , 0.2788 ,\n",
       "            0.2786 , 0.2783 , 0.2664 , 0.2583 , 0.2563 , 0.2473 , 0.2433 ,\n",
       "            0.243  , 0.2358 , 0.2328 , 0.2319 , 0.2294 , 0.2244 , 0.2234 ,\n",
       "            0.2233 , 0.2213 , 0.214  , 0.2135 , 0.2101 , 0.204  , 0.1958 ,\n",
       "            0.1934 , 0.1929 , 0.1917 , 0.1815 , 0.1783 , 0.1726 , 0.1715 ,\n",
       "            0.1686 , 0.1675 , 0.1672 , 0.1532 , 0.1381 , 0.1354 , 0.1288 ,\n",
       "            0.12494, 0.10913, 0.0995 , 0.09467, 0.093  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.296875, dtype=float32),\n",
       "    'tpr': array(0.7704918, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.15625  , 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.25     , 0.25     , 0.25     , 0.25     ,\n",
       "            0.25     , 0.2578125, 0.2578125, 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.359375 ,\n",
       "            0.359375 , 0.359375 , 0.3671875, 0.3671875, 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4296875, 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.625    , 0.625    , 0.6328125, 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.16393442,\n",
       "            0.17213115, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.44262296, 0.45081967, 0.46721312,\n",
       "            0.47540984, 0.47540984, 0.48360655, 0.4918033 , 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.965  , 0.9604 , 0.96   , 0.9526 , 0.943  , 0.94   ,\n",
       "            0.939  , 0.9277 , 0.925  , 0.911  , 0.91   , 0.908  , 0.9004 ,\n",
       "            0.9    , 0.897  , 0.894  , 0.89   , 0.8896 , 0.882  , 0.881  ,\n",
       "            0.88   , 0.877  , 0.8755 , 0.874  , 0.8735 , 0.8687 , 0.8667 ,\n",
       "            0.864  , 0.8604 , 0.8594 , 0.854  , 0.8535 , 0.853  , 0.8384 ,\n",
       "            0.833  , 0.8325 , 0.828  , 0.8276 , 0.8223 , 0.815  , 0.814  ,\n",
       "            0.8105 , 0.805  , 0.8047 , 0.784  , 0.7817 , 0.7783 , 0.775  ,\n",
       "            0.7686 , 0.753  , 0.745  , 0.741  , 0.7397 , 0.7393 , 0.738  ,\n",
       "            0.73   , 0.7266 , 0.7188 , 0.716  , 0.7153 , 0.715  , 0.7065 ,\n",
       "            0.6934 , 0.692  , 0.6904 , 0.6836 , 0.68   , 0.6743 , 0.674  ,\n",
       "            0.673  , 0.6685 , 0.6675 , 0.6655 , 0.665  , 0.6626 , 0.654  ,\n",
       "            0.653  , 0.651  , 0.649  , 0.6367 , 0.6353 , 0.634  , 0.6255 ,\n",
       "            0.625  , 0.622  , 0.6167 , 0.6123 , 0.607  , 0.6055 , 0.602  ,\n",
       "            0.6    , 0.597  , 0.5938 , 0.5933 , 0.591  , 0.586  , 0.5806 ,\n",
       "            0.5796 , 0.5757 , 0.569  , 0.567  , 0.566  , 0.565  , 0.5625 ,\n",
       "            0.561  , 0.5566 , 0.5513 , 0.549  , 0.547  , 0.5435 , 0.538  ,\n",
       "            0.5366 , 0.5337 , 0.5303 , 0.53   , 0.5283 , 0.5215 , 0.5205 ,\n",
       "            0.52   , 0.517  , 0.5156 , 0.5146 , 0.513  , 0.509  , 0.5005 ,\n",
       "            0.4995 , 0.498  , 0.4941 , 0.49   , 0.4893 , 0.4875 , 0.4849 ,\n",
       "            0.4822 , 0.4817 , 0.481  , 0.478  , 0.4749 , 0.4734 , 0.471  ,\n",
       "            0.4673 , 0.4644 , 0.464  , 0.4624 , 0.4622 , 0.4614 , 0.4597 ,\n",
       "            0.4575 , 0.4573 , 0.4568 , 0.4558 , 0.453  , 0.444  , 0.4397 ,\n",
       "            0.4355 , 0.4316 , 0.4292 , 0.429  , 0.4263 , 0.413  , 0.41   ,\n",
       "            0.4045 , 0.4019 , 0.3997 , 0.3994 , 0.3987 , 0.397  , 0.3943 ,\n",
       "            0.393  , 0.3906 , 0.3882 , 0.388  , 0.3867 , 0.362  , 0.3616 ,\n",
       "            0.3591 , 0.359  , 0.3462 , 0.3457 , 0.3447 , 0.3345 , 0.3342 ,\n",
       "            0.3289 , 0.3267 , 0.314  , 0.3125 , 0.311  , 0.31   , 0.3025 ,\n",
       "            0.2996 , 0.295  , 0.2903 , 0.2898 , 0.2869 , 0.2866 , 0.281  ,\n",
       "            0.2769 , 0.275  , 0.2747 , 0.2727 , 0.2703 , 0.252  , 0.249  ,\n",
       "            0.2483 , 0.2379 , 0.2358 , 0.2294 , 0.228  , 0.2277 , 0.2212 ,\n",
       "            0.22   , 0.2167 , 0.2158 , 0.2123 , 0.2075 , 0.205  , 0.2039 ,\n",
       "            0.1947 , 0.1863 , 0.1837 , 0.1831 , 0.1829 , 0.1731 , 0.1685 ,\n",
       "            0.1617 , 0.1614 , 0.1609 , 0.158  , 0.1577 , 0.1422 , 0.1305 ,\n",
       "            0.1279 , 0.1197 , 0.1172 , 0.10144, 0.09204, 0.0865 , 0.08496],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3203125, dtype=float32),\n",
       "    'tpr': array(0.8032787, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.25     , 0.25     , 0.25     , 0.25     ,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3046875, 0.3125   ,\n",
       "            0.3125   , 0.3203125, 0.3203125, 0.328125 , 0.3359375, 0.3359375,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3671875, 0.3671875, 0.375    , 0.3828125, 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4296875, 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.47540984, 0.47540984, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.60655737, 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.63114756, 0.647541  ,\n",
       "            0.647541  , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.72131145, 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.92622954, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.97   , 0.966  , 0.959  , 0.95   , 0.9478 , 0.9463 ,\n",
       "            0.9365 , 0.9336 , 0.9204 , 0.9194 , 0.918  , 0.9106 , 0.91   ,\n",
       "            0.907  , 0.9043 , 0.901  , 0.9004 , 0.893  , 0.8926 , 0.8906 ,\n",
       "            0.89   , 0.888  , 0.886  , 0.8853 , 0.885  , 0.8794 , 0.8784 ,\n",
       "            0.876  , 0.8716 , 0.8706 , 0.866  , 0.865  , 0.8647 , 0.8496 ,\n",
       "            0.8467 , 0.8447 , 0.8413 , 0.841  , 0.8345 , 0.83   , 0.8257 ,\n",
       "            0.8228 , 0.817  , 0.8164 , 0.796  , 0.794  , 0.792  , 0.7905 ,\n",
       "            0.79   , 0.7817 , 0.7646 , 0.7593 , 0.7573 , 0.7544 , 0.7534 ,\n",
       "            0.751  , 0.7476 , 0.741  , 0.7334 , 0.7324 , 0.732  , 0.7314 ,\n",
       "            0.718  , 0.71   , 0.705  , 0.7046 , 0.703  , 0.7    , 0.6924 ,\n",
       "            0.6895 , 0.685  , 0.684  , 0.6816 , 0.678  , 0.6685 , 0.6626 ,\n",
       "            0.6616 , 0.66   , 0.654  , 0.6504 , 0.645  , 0.6426 , 0.6387 ,\n",
       "            0.637  , 0.627  , 0.6216 , 0.6206 , 0.6157 , 0.615  , 0.6147 ,\n",
       "            0.6113 , 0.609  , 0.6064 , 0.601  , 0.599  , 0.596  , 0.5947 ,\n",
       "            0.5845 , 0.5835 , 0.583  , 0.5825 , 0.582  , 0.578  , 0.572  ,\n",
       "            0.5693 , 0.567  , 0.56   , 0.5596 , 0.5576 , 0.557  , 0.551  ,\n",
       "            0.5474 , 0.5464 , 0.546  , 0.543  , 0.5376 , 0.5337 , 0.533  ,\n",
       "            0.5293 , 0.527  , 0.525  , 0.518  , 0.517  , 0.515  , 0.512  ,\n",
       "            0.5083 , 0.5073 , 0.507  , 0.4998 , 0.499  , 0.4978 , 0.4944 ,\n",
       "            0.4922 , 0.4902 , 0.4895 , 0.489  , 0.4863 , 0.4817 , 0.481  ,\n",
       "            0.4795 , 0.478  , 0.4758 , 0.4736 , 0.4722 , 0.4692 , 0.4644 ,\n",
       "            0.4617 , 0.457  , 0.4568 , 0.4565 , 0.452  , 0.4492 , 0.446  ,\n",
       "            0.4453 , 0.4434 , 0.4285 , 0.4202 , 0.4194 , 0.418  , 0.4155 ,\n",
       "            0.4146 , 0.4128 , 0.412  , 0.4111 , 0.411  , 0.408  , 0.4043 ,\n",
       "            0.4038 , 0.402  , 0.3843 , 0.381  , 0.3706 , 0.3613 , 0.361  ,\n",
       "            0.3584 , 0.355  , 0.3467 , 0.3423 , 0.3367 , 0.3274 , 0.327  ,\n",
       "            0.326  , 0.3252 , 0.3208 , 0.3135 , 0.3086 , 0.3083 , 0.3074 ,\n",
       "            0.296  , 0.294  , 0.281  , 0.2798 , 0.277  , 0.275  , 0.2715 ,\n",
       "            0.2712 , 0.2703 , 0.2659 , 0.2573 , 0.2455 , 0.2375 , 0.2285 ,\n",
       "            0.2281 , 0.2252 , 0.2238 , 0.2235 , 0.2194 , 0.2108 , 0.2086 ,\n",
       "            0.2032 , 0.202  , 0.2012 , 0.1942 , 0.1863 , 0.1774 , 0.1752 ,\n",
       "            0.1747 , 0.1743 , 0.1658 , 0.1592 , 0.1548 , 0.1528 , 0.1504 ,\n",
       "            0.1497 , 0.149  , 0.1318 , 0.1276 , 0.1174 , 0.1118 , 0.11084,\n",
       "            0.09515, 0.0859 , 0.07947, 0.07825], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.359375, dtype=float32),\n",
       "    'tpr': array(0.8360656, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.2421875, 0.2421875, 0.25     , 0.25     ,\n",
       "            0.25     , 0.25     , 0.25     , 0.2578125, 0.2578125, 0.265625 ,\n",
       "            0.265625 , 0.2734375, 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.296875 , 0.296875 , 0.3046875, 0.3046875, 0.3125   , 0.3125   ,\n",
       "            0.3125   , 0.3203125, 0.3203125, 0.328125 , 0.3359375, 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.3671875,\n",
       "            0.3671875, 0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.47540984, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.74590164, 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9756 , 0.9717 , 0.966  , 0.9575 , 0.9556 , 0.954  ,\n",
       "            0.9453 , 0.9424 , 0.93   , 0.9297 , 0.928  , 0.9214 , 0.921  ,\n",
       "            0.918  , 0.915  , 0.912  , 0.9116 , 0.9053 , 0.905  , 0.9043 ,\n",
       "            0.903  , 0.9014 , 0.9004 , 0.8984 , 0.8975 , 0.897  , 0.891  ,\n",
       "            0.8887 , 0.8843 , 0.8833 , 0.8794 , 0.8784 , 0.878  , 0.863  ,\n",
       "            0.8604 , 0.858  , 0.8555 , 0.8545 , 0.848  , 0.8447 , 0.8394 ,\n",
       "            0.8364 , 0.8306 , 0.83   , 0.8096 , 0.808  , 0.806  , 0.804  ,\n",
       "            0.7964 , 0.7783 , 0.775  , 0.771  , 0.7695 , 0.769  , 0.7646 ,\n",
       "            0.764  , 0.763  , 0.7563 , 0.7505 , 0.7495 , 0.7476 , 0.746  ,\n",
       "            0.7305 , 0.7266 , 0.72   , 0.7183 , 0.717  , 0.7075 , 0.706  ,\n",
       "            0.704  , 0.6987 , 0.698  , 0.6963 , 0.6953 , 0.694  , 0.683  ,\n",
       "            0.675  , 0.6743 , 0.6714 , 0.669  , 0.665  , 0.664  , 0.6616 ,\n",
       "            0.6577 , 0.654  , 0.6523 , 0.6436 , 0.635  , 0.631  , 0.63   ,\n",
       "            0.629  , 0.628  , 0.6265 , 0.622  , 0.62   , 0.6143 , 0.6123 ,\n",
       "            0.609  , 0.6    , 0.5996 , 0.5977 , 0.5967 , 0.596  , 0.594  ,\n",
       "            0.5923 , 0.587  , 0.585  , 0.5796 , 0.5757 , 0.5693 , 0.569  ,\n",
       "            0.566  , 0.5654 , 0.564  , 0.5625 , 0.5605 , 0.558  , 0.555  ,\n",
       "            0.551  , 0.546  , 0.545  , 0.5405 , 0.538  , 0.5376 , 0.536  ,\n",
       "            0.534  , 0.5312 , 0.529  , 0.524  , 0.5234 , 0.5225 , 0.522  ,\n",
       "            0.5215 , 0.515  , 0.5117 , 0.5103 , 0.5024 , 0.5015 , 0.501  ,\n",
       "            0.5005 , 0.4973 , 0.4954 , 0.4917 , 0.4915 , 0.4863 , 0.4814 ,\n",
       "            0.4792 , 0.479  , 0.475  , 0.4724 , 0.4668 , 0.4658 , 0.4592 ,\n",
       "            0.4585 , 0.4583 , 0.457  , 0.4565 , 0.454  , 0.439  , 0.4333 ,\n",
       "            0.4312 , 0.4294 , 0.4292 , 0.4263 , 0.4258 , 0.422  , 0.4197 ,\n",
       "            0.4194 , 0.418  , 0.4155 , 0.415  , 0.412  , 0.4053 , 0.4038 ,\n",
       "            0.3967 , 0.382  , 0.3784 , 0.3708 , 0.3618 , 0.36   , 0.355  ,\n",
       "            0.3547 , 0.3389 , 0.3374 , 0.3357 , 0.3354 , 0.3247 , 0.3223 ,\n",
       "            0.3174 , 0.3147 , 0.3105 , 0.305  , 0.301  , 0.2986 , 0.2983 ,\n",
       "            0.2915 , 0.2766 , 0.2747 , 0.272  , 0.2717 , 0.2668 , 0.2664 ,\n",
       "            0.2632 , 0.2612 , 0.2585 , 0.2384 , 0.2268 , 0.2211 , 0.2194 ,\n",
       "            0.2181 , 0.218  , 0.2167 , 0.2158 , 0.2039 , 0.2012 , 0.2002 ,\n",
       "            0.1962 , 0.1954 , 0.194  , 0.1842 , 0.1771 , 0.1681 , 0.1665 ,\n",
       "            0.1653 , 0.1648 , 0.1577 , 0.1495 , 0.148  , 0.1433 , 0.1409 ,\n",
       "            0.1404 , 0.1393 , 0.1232 , 0.12146, 0.10724, 0.10394, 0.10376,\n",
       "            0.0883 , 0.07935, 0.0724 , 0.07135], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.390625, dtype=float32),\n",
       "    'tpr': array(0.8606557, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.234375 , 0.2421875, 0.2421875, 0.2421875,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.2578125, 0.265625 , 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.3515625, 0.3515625,\n",
       "            0.3515625, 0.359375 , 0.359375 , 0.3671875, 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.390625 , 0.390625 , 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7578125, 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.28688523, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.48360655, 0.4918033 , 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.60655737, 0.60655737, 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.7295082 , 0.73770493,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9805 , 0.977  , 0.972  , 0.9644 , 0.963  , 0.962  ,\n",
       "            0.954  , 0.9517 , 0.94   , 0.9395 , 0.939  , 0.9326 , 0.932  ,\n",
       "            0.9287 , 0.9253 , 0.9243 , 0.9233 , 0.9185 , 0.9175 , 0.917  ,\n",
       "            0.9146 , 0.913  , 0.911  , 0.9106 , 0.9087 , 0.9043 , 0.903  ,\n",
       "            0.897  , 0.896  , 0.8945 , 0.8916 , 0.876  , 0.872  , 0.8716 ,\n",
       "            0.87   , 0.863  , 0.8623 , 0.853  , 0.8516 , 0.8447 , 0.844  ,\n",
       "            0.8257 , 0.824  , 0.823  , 0.819  , 0.8125 , 0.7974 , 0.7925 ,\n",
       "            0.79   , 0.788  , 0.7866 , 0.786  , 0.7803 , 0.7783 , 0.7754 ,\n",
       "            0.7725 , 0.7715 , 0.7695 , 0.763  , 0.749  , 0.7456 , 0.7446 ,\n",
       "            0.742  , 0.7397 , 0.7344 , 0.7305 , 0.728  , 0.726  , 0.72   ,\n",
       "            0.7197 , 0.717  , 0.7163 , 0.715  , 0.703  , 0.693  , 0.692  ,\n",
       "            0.6875 , 0.687  , 0.6846 , 0.684  , 0.6826 , 0.6807 , 0.68   ,\n",
       "            0.674  , 0.6685 , 0.655  , 0.653  , 0.6494 , 0.649  , 0.6455 ,\n",
       "            0.6426 , 0.642  , 0.6406 , 0.638  , 0.637  , 0.635  , 0.6284 ,\n",
       "            0.6265 , 0.623  , 0.621  , 0.6187 , 0.617  , 0.615  , 0.6147 ,\n",
       "            0.6123 , 0.605  , 0.602  , 0.599  , 0.5967 , 0.588  , 0.5874 ,\n",
       "            0.5854 , 0.582  , 0.581  , 0.578  , 0.5767 , 0.574  , 0.5723 ,\n",
       "            0.5664 , 0.5654 , 0.5625 , 0.559  , 0.5576 , 0.556  , 0.5513 ,\n",
       "            0.548  , 0.545  , 0.544  , 0.5415 , 0.539  , 0.536  , 0.533  ,\n",
       "            0.5327 , 0.5264 , 0.5254 , 0.5244 , 0.521  , 0.52   , 0.516  ,\n",
       "            0.5146 , 0.5103 , 0.51   , 0.5083 , 0.5044 , 0.503  , 0.4988 ,\n",
       "            0.4937 , 0.4922 , 0.4844 , 0.483  , 0.4795 , 0.4792 , 0.472  ,\n",
       "            0.4717 , 0.4692 , 0.4592 , 0.4578 , 0.4575 , 0.4565 , 0.4543 ,\n",
       "            0.4512 , 0.4504 , 0.4492 , 0.4458 , 0.4397 , 0.4358 , 0.4355 ,\n",
       "            0.4343 , 0.434  , 0.429  , 0.424  , 0.4197 , 0.4084 , 0.4077 ,\n",
       "            0.3926 , 0.389  , 0.3796 , 0.374  , 0.3699 , 0.3596 , 0.3538 ,\n",
       "            0.3528 , 0.3513 , 0.34   , 0.3389 , 0.3357 , 0.3232 , 0.3167 ,\n",
       "            0.3074 , 0.3071 , 0.305  , 0.304  , 0.3018 , 0.2932 , 0.2898 ,\n",
       "            0.2812 , 0.2693 , 0.2678 , 0.267  , 0.263  , 0.2622 , 0.262  ,\n",
       "            0.2554 , 0.2505 , 0.231  , 0.2173 , 0.2152 , 0.2133 , 0.2098 ,\n",
       "            0.207  , 0.1968 , 0.1915 , 0.191  , 0.1887 , 0.1838 , 0.1738 ,\n",
       "            0.1676 , 0.1584 , 0.158  , 0.1555 , 0.1549 , 0.1494 , 0.141  ,\n",
       "            0.1395 , 0.1338 , 0.1322 , 0.1313 , 0.1279 , 0.1196 , 0.11084,\n",
       "            0.0974 , 0.09686, 0.0957 , 0.0818 , 0.0732 , 0.0656 , 0.0649 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3984375, dtype=float32),\n",
       "    'tpr': array(0.89344263, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.234375 , 0.2421875, 0.2421875,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.265625 , 0.265625 ,\n",
       "            0.265625 , 0.265625 , 0.2734375, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.2890625, 0.2890625, 0.296875 , 0.296875 , 0.3203125, 0.3203125,\n",
       "            0.3203125, 0.328125 , 0.328125 , 0.3359375, 0.34375  , 0.34375  ,\n",
       "            0.34375  , 0.34375  , 0.3515625, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.375    , 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.3984375, 0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.421875 ,\n",
       "            0.421875 , 0.421875 , 0.421875 , 0.4296875, 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5      , 0.5078125, 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.6229508 , 0.63114756, 0.63114756, 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.72131145, 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.984  , 0.981  , 0.9805 , 0.9766 , 0.969  , 0.9683 ,\n",
       "            0.9673 , 0.9604 , 0.9585 , 0.9473 , 0.947  , 0.942  , 0.9404 ,\n",
       "            0.9365 , 0.9336 , 0.932  , 0.928  , 0.9272 , 0.9263 , 0.924  ,\n",
       "            0.9224 , 0.9214 , 0.921  , 0.92   , 0.918  , 0.914  , 0.9136 ,\n",
       "            0.9106 , 0.907  , 0.9062 , 0.906  , 0.902  , 0.8887 , 0.8857 ,\n",
       "            0.8843 , 0.8833 , 0.8823 , 0.878  , 0.8735 , 0.8633 , 0.863  ,\n",
       "            0.8545 , 0.843  , 0.837  , 0.836  , 0.8345 , 0.8296 , 0.826  ,\n",
       "            0.8184 , 0.808  , 0.8076 , 0.804  , 0.802  , 0.798  , 0.7925 ,\n",
       "            0.792  , 0.7915 , 0.789  , 0.788  , 0.7773 , 0.7705 , 0.7695 ,\n",
       "            0.7676 , 0.7573 , 0.755  , 0.7534 , 0.7485 , 0.748  , 0.747  ,\n",
       "            0.741  , 0.74   , 0.737  , 0.7344 , 0.7236 , 0.7173 , 0.7134 ,\n",
       "            0.708  , 0.7075 , 0.7056 , 0.7046 , 0.702  , 0.6973 , 0.696  ,\n",
       "            0.6895 , 0.6777 , 0.6763 , 0.673  , 0.6714 , 0.6646 , 0.6636 ,\n",
       "            0.663  , 0.6553 , 0.655  , 0.651  , 0.65   , 0.6494 , 0.647  ,\n",
       "            0.6465 , 0.643  , 0.6396 , 0.632  , 0.626  , 0.621  , 0.6094 ,\n",
       "            0.6084 , 0.608  , 0.6064 , 0.601  , 0.6    , 0.5996 , 0.596  ,\n",
       "            0.595  , 0.594  , 0.59   , 0.588  , 0.5864 , 0.5835 , 0.582  ,\n",
       "            0.581  , 0.579  , 0.5776 , 0.5767 , 0.5723 , 0.571  , 0.567  ,\n",
       "            0.5635 , 0.562  , 0.558  , 0.5576 , 0.5527 , 0.5522 , 0.549  ,\n",
       "            0.5454 , 0.545  , 0.542  , 0.539  , 0.534  , 0.5337 , 0.532  ,\n",
       "            0.5303 , 0.5225 , 0.521  , 0.5117 , 0.5083 , 0.506  , 0.495  ,\n",
       "            0.4934 , 0.4878 , 0.485  , 0.4844 , 0.4824 , 0.4807 , 0.4785 ,\n",
       "            0.4746 , 0.4744 , 0.4702 , 0.4624 , 0.4607 , 0.4583 , 0.4578 ,\n",
       "            0.4534 , 0.4531 , 0.4521 , 0.4507 , 0.425  , 0.4126 , 0.4124 ,\n",
       "            0.4114 , 0.3906 , 0.3896 , 0.3782 , 0.3765 , 0.3752 , 0.3613 ,\n",
       "            0.3599 , 0.3474 , 0.3464 , 0.3328 , 0.3262 , 0.3237 , 0.3152 ,\n",
       "            0.313  , 0.3    , 0.298  , 0.2944 , 0.291  , 0.2898 , 0.285  ,\n",
       "            0.2815 , 0.2637 , 0.2617 , 0.2605 , 0.259  , 0.2517 , 0.248  ,\n",
       "            0.2428 , 0.2242 , 0.2162 , 0.2135 , 0.2103 , 0.2042 , 0.2015 ,\n",
       "            0.201  , 0.1956 , 0.1913 , 0.1891 , 0.1838 , 0.1813 , 0.1747 ,\n",
       "            0.1637 , 0.1592 , 0.1503 , 0.1497 , 0.1466 , 0.1461 , 0.1426 ,\n",
       "            0.1359 , 0.1304 , 0.1251 , 0.12445, 0.1236 , 0.11816, 0.1172 ,\n",
       "            0.10126, 0.0922 , 0.0888 , 0.0869 , 0.07666, 0.0683 , 0.05988,\n",
       "            0.05942], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3984375, dtype=float32),\n",
       "    'tpr': array(0.89344263, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.2421875, 0.25     , 0.25     , 0.2578125,\n",
       "            0.265625 , 0.265625 , 0.265625 , 0.265625 , 0.265625 , 0.2734375,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.34375  , 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.375    ,\n",
       "            0.375    , 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.4140625, 0.421875 , 0.421875 , 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4453125, 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.7295082 , 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9854 , 0.983  , 0.9824 , 0.9785 , 0.972  , 0.9707 ,\n",
       "            0.9697 , 0.963  , 0.961  , 0.9507 , 0.95   , 0.9497 , 0.9443 ,\n",
       "            0.9434 , 0.9404 , 0.9375 , 0.9365 , 0.9355 , 0.931  , 0.93   ,\n",
       "            0.9297 , 0.9277 , 0.926  , 0.9253 , 0.9243 , 0.924  , 0.922  ,\n",
       "            0.918  , 0.9165 , 0.916  , 0.911  , 0.9097 , 0.909  , 0.906  ,\n",
       "            0.8916 , 0.89   , 0.887  , 0.8853 , 0.8794 , 0.878  , 0.8677 ,\n",
       "            0.867  , 0.859  , 0.8438 , 0.84   , 0.8394 , 0.839  , 0.8335 ,\n",
       "            0.829  , 0.816  , 0.8086 , 0.8066 , 0.805  , 0.8047 , 0.801  ,\n",
       "            0.7954 , 0.7925 , 0.791  , 0.79   , 0.7886 , 0.7793 , 0.7676 ,\n",
       "            0.7666 , 0.7637 , 0.758  , 0.757  , 0.7495 , 0.7485 , 0.747  ,\n",
       "            0.744  , 0.7373 , 0.737  , 0.7334 , 0.7324 , 0.7207 , 0.7124 ,\n",
       "            0.71   , 0.7065 , 0.704  , 0.701  , 0.7    , 0.6978 , 0.693  ,\n",
       "            0.692  , 0.691  , 0.6733 , 0.6714 , 0.669  , 0.666  , 0.661  ,\n",
       "            0.6597 , 0.6587 , 0.658  , 0.652  , 0.6504 , 0.65   , 0.6455 ,\n",
       "            0.644  , 0.6426 , 0.6387 , 0.6353 , 0.63   , 0.629  , 0.627  ,\n",
       "            0.621  , 0.616  , 0.6055 , 0.6045 , 0.6035 , 0.602  , 0.598  ,\n",
       "            0.597  , 0.595  , 0.5923 , 0.591  , 0.5903 , 0.586  , 0.5854 ,\n",
       "            0.582  , 0.5815 , 0.5776 , 0.5767 , 0.5757 , 0.5747 , 0.5723 ,\n",
       "            0.57   , 0.569  , 0.5674 , 0.566  , 0.565  , 0.5586 , 0.557  ,\n",
       "            0.5537 , 0.55   , 0.549  , 0.546  , 0.541  , 0.5405 , 0.5386 ,\n",
       "            0.536  , 0.532  , 0.529  , 0.5283 , 0.528  , 0.5205 , 0.518  ,\n",
       "            0.516  , 0.51   , 0.503  , 0.4897 , 0.4893 , 0.486  , 0.4836 ,\n",
       "            0.4812 , 0.479  , 0.4773 , 0.4717 , 0.4714 , 0.4712 , 0.4673 ,\n",
       "            0.459  , 0.458  , 0.4573 , 0.455  , 0.4512 , 0.4495 , 0.4492 ,\n",
       "            0.447  , 0.4177 , 0.4104 , 0.4082 , 0.4053 , 0.405  , 0.3872 ,\n",
       "            0.377  , 0.3735 , 0.367  , 0.3596 , 0.3508 , 0.3396 , 0.3374 ,\n",
       "            0.3232 , 0.3225 , 0.3152 , 0.3123 , 0.3093 , 0.2915 , 0.288  ,\n",
       "            0.2864 , 0.2856 , 0.2832 , 0.2803 , 0.2756 , 0.2546 , 0.252  ,\n",
       "            0.2502 , 0.2411 , 0.2383 , 0.2332 , 0.2148 , 0.209  , 0.207  ,\n",
       "            0.2026 , 0.1956 , 0.1924 , 0.1907 , 0.1849 , 0.183  , 0.182  ,\n",
       "            0.1758 , 0.1744 , 0.1711 , 0.1648 , 0.1538 , 0.1501 , 0.1415 ,\n",
       "            0.1405 , 0.1373 , 0.1368 , 0.1342 , 0.1285 , 0.12146, 0.1166 ,\n",
       "            0.11615, 0.11536, 0.11316, 0.1082 , 0.093  , 0.0859 , 0.082  ,\n",
       "            0.0799 , 0.0709 , 0.0629 , 0.0545 , 0.0542 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.421875, dtype=float32),\n",
       "    'tpr': array(0.92622954, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.25     , 0.25     , 0.2578125,\n",
       "            0.265625 , 0.265625 , 0.265625 , 0.265625 , 0.265625 , 0.265625 ,\n",
       "            0.2734375, 0.2890625, 0.296875 , 0.296875 , 0.296875 , 0.296875 ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.34375  ,\n",
       "            0.34375  , 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.3671875,\n",
       "            0.3671875, 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.3984375, 0.3984375, 0.3984375, 0.40625  , 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.48360655, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.7295082 , 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.989  , 0.987  , 0.9863 , 0.983  , 0.9775 , 0.9766 ,\n",
       "            0.9756 , 0.97   , 0.9683 , 0.959  , 0.9585 , 0.954  , 0.953  ,\n",
       "            0.9497 , 0.9473 , 0.946  , 0.9424 , 0.9414 , 0.9404 , 0.9385 ,\n",
       "            0.9375 , 0.9365 , 0.936  , 0.935  , 0.9336 , 0.93   , 0.9297 ,\n",
       "            0.9277 , 0.924  , 0.9233 , 0.9224 , 0.9194 , 0.907  , 0.9043 ,\n",
       "            0.9033 , 0.902  , 0.9014 , 0.897  , 0.893  , 0.8833 , 0.883  ,\n",
       "            0.875  , 0.8643 , 0.8584 , 0.857  , 0.8555 , 0.8506 , 0.8477 ,\n",
       "            0.8403 , 0.831  , 0.829  , 0.8267 , 0.824  , 0.8193 , 0.815  ,\n",
       "            0.814  , 0.812  , 0.8105 , 0.8003 , 0.794  , 0.7925 , 0.791  ,\n",
       "            0.781  , 0.777  , 0.776  , 0.7725 , 0.77   , 0.7695 , 0.763  ,\n",
       "            0.7617 , 0.7593 , 0.7583 , 0.7466 , 0.74   , 0.7393 , 0.7344 ,\n",
       "            0.7295 , 0.728  , 0.7266 , 0.7256 , 0.7217 , 0.718  , 0.7173 ,\n",
       "            0.7104 , 0.701  , 0.6978 , 0.697  , 0.6924 , 0.6914 , 0.6885 ,\n",
       "            0.686  , 0.6855 , 0.684  , 0.683  , 0.6772 , 0.676  , 0.675  ,\n",
       "            0.672  , 0.669  , 0.667  , 0.6665 , 0.664  , 0.6626 , 0.6616 ,\n",
       "            0.653  , 0.647  , 0.6426 , 0.635  , 0.6333 , 0.6304 , 0.63   ,\n",
       "            0.623  , 0.622  , 0.6206 , 0.6187 , 0.616  , 0.6157 , 0.613  ,\n",
       "            0.612  , 0.61   , 0.6035 , 0.6006 , 0.6    , 0.599  , 0.598  ,\n",
       "            0.5977 , 0.5923 , 0.582  , 0.5815 , 0.581  , 0.579  , 0.578  ,\n",
       "            0.5693 , 0.5684 , 0.5654 , 0.565  , 0.563  , 0.554  , 0.5537 ,\n",
       "            0.5522 , 0.543  , 0.5415 , 0.5356 , 0.532  , 0.524  , 0.519  ,\n",
       "            0.5176 , 0.5156 , 0.514  , 0.5073 , 0.504  , 0.5005 , 0.5    ,\n",
       "            0.499  , 0.495  , 0.4941 , 0.4863 , 0.4858 , 0.4849 , 0.4812 ,\n",
       "            0.4795 , 0.473  , 0.4724 , 0.4717 , 0.4602 , 0.4546 , 0.437  ,\n",
       "            0.431  , 0.4294 , 0.4165 , 0.4155 , 0.41   , 0.408  , 0.4045 ,\n",
       "            0.3992 , 0.3853 , 0.3726 , 0.357  , 0.3496 , 0.341  , 0.3352 ,\n",
       "            0.327  , 0.3252 , 0.32   , 0.295  , 0.294  , 0.287  , 0.286  ,\n",
       "            0.2837 , 0.275  , 0.255  , 0.253  , 0.251  , 0.2375 , 0.2363 ,\n",
       "            0.2311 , 0.2128 , 0.2096 , 0.2084 , 0.2018 , 0.1934 , 0.1866 ,\n",
       "            0.1863 , 0.1812 , 0.1804 , 0.1792 , 0.1733 , 0.1704 , 0.1659 ,\n",
       "            0.1597 , 0.1482 , 0.1453 , 0.1368 , 0.1351 , 0.1318 , 0.1313 ,\n",
       "            0.1298 , 0.12476, 0.1158 , 0.1118 , 0.111  , 0.1101 , 0.10144,\n",
       "            0.0866 , 0.0818 , 0.0771 , 0.07385, 0.06696, 0.059  , 0.05032,\n",
       "            0.05014], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.4609375, dtype=float32),\n",
       "    'tpr': array(0.94262296, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.2421875,\n",
       "            0.25     , 0.25     , 0.25     , 0.2578125, 0.2734375, 0.2734375,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.2734375, 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.34375  ,\n",
       "            0.34375  , 0.3515625, 0.3515625, 0.359375 , 0.359375 , 0.359375 ,\n",
       "            0.3671875, 0.3671875, 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.390625 , 0.3984375, 0.3984375, 0.40625  , 0.40625  , 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6639344 , 0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8032787 , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.991  , 0.9893 , 0.989  , 0.9863 , 0.9814 , 0.9805 ,\n",
       "            0.98   , 0.975  , 0.9736 , 0.9653 , 0.965  , 0.9614 , 0.96   ,\n",
       "            0.957  , 0.955  , 0.9536 , 0.953  , 0.9507 , 0.9497 , 0.9487 ,\n",
       "            0.947  , 0.946  , 0.9453 , 0.944  , 0.9434 , 0.942  , 0.9395 ,\n",
       "            0.9355 , 0.934  , 0.933  , 0.931  , 0.929  , 0.9287 , 0.919  ,\n",
       "            0.915  , 0.914  , 0.913  , 0.9097 , 0.9043 , 0.8955 , 0.8936 ,\n",
       "            0.886  , 0.88   , 0.873  , 0.8706 , 0.8677 , 0.8633 , 0.8623 ,\n",
       "            0.861  , 0.85   , 0.8496 , 0.8438 , 0.8364 , 0.835  , 0.834  ,\n",
       "            0.833  , 0.8325 , 0.831  , 0.8276 , 0.823  , 0.8174 , 0.8164 ,\n",
       "            0.815  , 0.8135 , 0.8003 , 0.799  , 0.7935 , 0.7915 , 0.7905 ,\n",
       "            0.7866 , 0.785  , 0.783  , 0.7817 , 0.7803 , 0.78   , 0.7686 ,\n",
       "            0.7656 , 0.765  , 0.7617 , 0.753  , 0.7495 , 0.749  , 0.7485 ,\n",
       "            0.747  , 0.741  , 0.7314 , 0.727  , 0.7227 , 0.721  , 0.719  ,\n",
       "            0.717  , 0.716  , 0.7124 , 0.7104 , 0.709  , 0.7075 , 0.7026 ,\n",
       "            0.701  , 0.6997 , 0.6987 , 0.696  , 0.694  , 0.692  , 0.691  ,\n",
       "            0.6875 , 0.6826 , 0.676  , 0.671  , 0.67   , 0.6675 , 0.66   ,\n",
       "            0.6567 , 0.6533 , 0.653  , 0.651  , 0.65   , 0.649  , 0.6475 ,\n",
       "            0.647  , 0.646  , 0.6396 , 0.639  , 0.6313 , 0.63   , 0.6284 ,\n",
       "            0.627  , 0.6265 , 0.624  , 0.621  , 0.6177 , 0.6157 , 0.6123 ,\n",
       "            0.61   , 0.6094 , 0.609  , 0.606  , 0.603  , 0.6016 , 0.6    ,\n",
       "            0.5996 , 0.598  , 0.597  , 0.595  , 0.5894 , 0.588  , 0.579  ,\n",
       "            0.575  , 0.5737 , 0.5664 , 0.5615 , 0.5537 , 0.553  , 0.5522 ,\n",
       "            0.5513 , 0.5444 , 0.539  , 0.5327 , 0.5312 , 0.5293 , 0.5273 ,\n",
       "            0.5244 , 0.5234 , 0.5215 , 0.516  , 0.5117 , 0.5083 , 0.4983 ,\n",
       "            0.4976 , 0.497  , 0.496  , 0.482  , 0.4653 , 0.4644 , 0.4573 ,\n",
       "            0.4553 , 0.4407 , 0.4348 , 0.4343 , 0.4302 , 0.4272 , 0.427  ,\n",
       "            0.4253 , 0.4133 , 0.3752 , 0.3623 , 0.3608 , 0.3496 , 0.3423 ,\n",
       "            0.3403 , 0.3333 , 0.329  , 0.3252 , 0.3123 , 0.3074 , 0.2969 ,\n",
       "            0.2922 , 0.2805 , 0.2766 , 0.2715 , 0.2556 , 0.2546 , 0.2524 ,\n",
       "            0.2494 , 0.2334 , 0.2318 , 0.2278 , 0.2118 , 0.2103 , 0.2024 ,\n",
       "            0.1915 , 0.1819 , 0.1814 , 0.1783 , 0.1782 , 0.1724 , 0.1719 ,\n",
       "            0.1664 , 0.1602 , 0.154  , 0.142  , 0.1406 , 0.1324 , 0.1299 ,\n",
       "            0.1265 , 0.126  , 0.12213, 0.1126 , 0.1101 , 0.1063 , 0.10596,\n",
       "            0.1054 , 0.09436, 0.0804 , 0.0788 , 0.07275, 0.06744, 0.06384,\n",
       "            0.05603, 0.0469 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.4765625, dtype=float32),\n",
       "    'tpr': array(0.9590164, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.2421875,\n",
       "            0.25     , 0.2578125, 0.2578125, 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.2734375, 0.2734375, 0.28125  , 0.28125  , 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.328125 , 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.390625 , 0.3984375, 0.3984375,\n",
       "            0.40625  , 0.40625  , 0.421875 , 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45081967, 0.46721312, 0.47540984,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6639344 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.73770493, 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9927 , 0.991  , 0.989  , 0.985  , 0.984  , 0.9834 ,\n",
       "            0.979  , 0.978  , 0.9707 , 0.97   , 0.967  , 0.966  , 0.963  ,\n",
       "            0.9614 , 0.961  , 0.9595 , 0.9575 , 0.9565 , 0.9556 , 0.9536 ,\n",
       "            0.9526 , 0.951  , 0.9507 , 0.949  , 0.9473 , 0.9443 , 0.942  ,\n",
       "            0.9414 , 0.9395 , 0.9375 , 0.928  , 0.925  , 0.924  , 0.923  ,\n",
       "            0.9224 , 0.919  , 0.9146 , 0.9062 , 0.905  , 0.8975 , 0.8906 ,\n",
       "            0.885  , 0.8823 , 0.88   , 0.8755 , 0.8745 , 0.872  , 0.862  ,\n",
       "            0.8613 , 0.857  , 0.8496 , 0.8477 , 0.846  , 0.8457 , 0.8438 ,\n",
       "            0.841  , 0.8374 , 0.8296 , 0.827  , 0.8267 , 0.815  , 0.811  ,\n",
       "            0.8066 , 0.805  , 0.8047 , 0.8003 , 0.7974 , 0.796  , 0.795  ,\n",
       "            0.794  , 0.7925 , 0.7827 , 0.7793 , 0.7783 , 0.7754 , 0.766  ,\n",
       "            0.763  , 0.7617 , 0.7544 , 0.7456 , 0.74   , 0.738  , 0.736  ,\n",
       "            0.734  , 0.7295 , 0.727  , 0.724  , 0.7236 , 0.7227 , 0.72   ,\n",
       "            0.7183 , 0.717  , 0.7134 , 0.7114 , 0.7085 , 0.707  , 0.704  ,\n",
       "            0.7007 , 0.697  , 0.6875 , 0.687  , 0.6836 , 0.68   , 0.674  ,\n",
       "            0.6704 , 0.6675 , 0.6665 , 0.6655 , 0.665  , 0.664  , 0.661  ,\n",
       "            0.66   , 0.658  , 0.6523 , 0.6475 , 0.6436 , 0.643  , 0.6426 ,\n",
       "            0.6406 , 0.639  , 0.636  , 0.6333 , 0.6313 , 0.6284 , 0.6274 ,\n",
       "            0.6255 , 0.624  , 0.623  , 0.618  , 0.6157 , 0.6147 , 0.6143 ,\n",
       "            0.614  , 0.609  , 0.6045 , 0.601  , 0.592  , 0.59   , 0.588  ,\n",
       "            0.5786 , 0.5767 , 0.57   , 0.569  , 0.565  , 0.5557 , 0.552  ,\n",
       "            0.545  , 0.544  , 0.5415 , 0.5376 , 0.534  , 0.533  , 0.531  ,\n",
       "            0.525  , 0.5215 , 0.5103 , 0.509  , 0.5083 , 0.507  , 0.49   ,\n",
       "            0.4795 , 0.4707 , 0.4668 , 0.4636 , 0.4497 , 0.4475 , 0.4465 ,\n",
       "            0.4421 , 0.441  , 0.4333 , 0.4312 , 0.4272 , 0.3782 , 0.3667 ,\n",
       "            0.3645 , 0.3572 , 0.3481 , 0.3435 , 0.3398 , 0.3298 , 0.327  ,\n",
       "            0.3218 , 0.3135 , 0.2969 , 0.2937 , 0.278  , 0.2744 , 0.2698 ,\n",
       "            0.2542 , 0.2534 , 0.251  , 0.2473 , 0.2302 , 0.228  , 0.2246 ,\n",
       "            0.2118 , 0.2109 , 0.2073 , 0.2006 , 0.1882 , 0.18   , 0.1765 ,\n",
       "            0.1738 , 0.1735 , 0.1683 , 0.1669 , 0.1616 , 0.1545 , 0.1487 ,\n",
       "            0.1362 , 0.1354 , 0.1274 , 0.1245 , 0.12115, 0.121  , 0.12054,\n",
       "            0.11816, 0.11066, 0.1047 , 0.10126, 0.1007 , 0.10016, 0.0887 ,\n",
       "            0.075  , 0.0749 , 0.0683 , 0.0627 , 0.0601 , 0.05252, 0.04337],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.484375, dtype=float32),\n",
       "    'tpr': array(0.9590164, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.2421875, 0.2421875,\n",
       "            0.2421875, 0.25     , 0.265625 , 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.296875 , 0.3203125, 0.3203125, 0.3203125, 0.328125 , 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.34375  , 0.3515625, 0.359375 , 0.359375 ,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.375    , 0.375    ,\n",
       "            0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.40983605, 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.46721312, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.59016395, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6721311 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.74590164, 0.74590164,\n",
       "            0.74590164, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9946 , 0.993  , 0.991  , 0.988  , 0.987  , 0.9863 ,\n",
       "            0.983  , 0.982  , 0.9756 , 0.975  , 0.972  , 0.9717 , 0.9688 ,\n",
       "            0.968  , 0.9663 , 0.966  , 0.964  , 0.9634 , 0.9624 , 0.9604 ,\n",
       "            0.96   , 0.9595 , 0.958  , 0.9565 , 0.955  , 0.9546 , 0.9517 ,\n",
       "            0.951  , 0.9497 , 0.9478 , 0.9463 , 0.9385 , 0.935  , 0.9336 ,\n",
       "            0.933  , 0.9326 , 0.93   , 0.9253 , 0.9175 , 0.916  , 0.909  ,\n",
       "            0.9043 , 0.898  , 0.8955 , 0.892  , 0.89   , 0.888  , 0.8804 ,\n",
       "            0.8774 , 0.8726 , 0.865  , 0.8643 , 0.863  , 0.8613 , 0.8604 ,\n",
       "            0.8555 , 0.852  , 0.851  , 0.8496 , 0.8457 , 0.8335 , 0.833  ,\n",
       "            0.826  , 0.825  , 0.82   , 0.8174 , 0.817  , 0.816  , 0.814  ,\n",
       "            0.8057 , 0.8037 , 0.803  , 0.8027 , 0.7915 , 0.79   , 0.7847 ,\n",
       "            0.782  , 0.7783 , 0.767  , 0.7627 , 0.762  , 0.7617 , 0.7583 ,\n",
       "            0.7573 , 0.757  , 0.756  , 0.7554 , 0.7524 , 0.752  , 0.7495 ,\n",
       "            0.7456 , 0.744  , 0.742  , 0.7383 , 0.737  , 0.735  , 0.734  ,\n",
       "            0.7324 , 0.7275 , 0.7217 , 0.7124 , 0.7114 , 0.7095 , 0.707  ,\n",
       "            0.705  , 0.7026 , 0.7    , 0.699  , 0.691  , 0.69   , 0.6875 ,\n",
       "            0.6836 , 0.681  , 0.68   , 0.678  , 0.6733 , 0.672  , 0.664  ,\n",
       "            0.662  , 0.6616 , 0.659  , 0.658  , 0.655  , 0.653  , 0.6494 ,\n",
       "            0.6484 , 0.648  , 0.6465 , 0.646  , 0.6445 , 0.6396 , 0.6387 ,\n",
       "            0.6377 , 0.6367 , 0.626  , 0.623  , 0.62   , 0.613  , 0.6074 ,\n",
       "            0.605  , 0.6045 , 0.604  , 0.5894 , 0.5854 , 0.579  , 0.578  ,\n",
       "            0.574  , 0.5737 , 0.5713 , 0.568  , 0.5615 , 0.556  , 0.553  ,\n",
       "            0.55   , 0.538  , 0.534  , 0.533  , 0.522  , 0.5093 , 0.494  ,\n",
       "            0.4917 , 0.4805 , 0.4768 , 0.4722 , 0.47   , 0.4675 , 0.4656 ,\n",
       "            0.461  , 0.456  , 0.4463 , 0.443  , 0.382  , 0.3796 , 0.372  ,\n",
       "            0.3716 , 0.3635 , 0.3533 , 0.346  , 0.3386 , 0.334  , 0.333  ,\n",
       "            0.326  , 0.3    , 0.2996 , 0.273  , 0.2676 , 0.2656 , 0.2556 ,\n",
       "            0.2551 , 0.2527 , 0.2458 , 0.2274 , 0.2227 , 0.2216 , 0.215  ,\n",
       "            0.2129 , 0.2047 , 0.2012 , 0.1864 , 0.1804 , 0.1718 , 0.1708 ,\n",
       "            0.1659 , 0.1653 , 0.1602 , 0.1575 , 0.1488 , 0.1432 , 0.1306 ,\n",
       "            0.1301 , 0.1229 , 0.1195 , 0.1172 , 0.11554, 0.11536, 0.1152 ,\n",
       "            0.1105 , 0.0991 , 0.09656, 0.0957 , 0.09534, 0.0823 , 0.0717 ,\n",
       "            0.0689 , 0.06396, 0.05698, 0.05685, 0.0494 , 0.0401 , 0.04   ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.97540987, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.1640625,\n",
       "            0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.2421875, 0.2421875, 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.2734375, 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3125   , 0.3203125, 0.3203125,\n",
       "            0.3359375, 0.34375  , 0.34375  , 0.34375  , 0.3515625, 0.3515625,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.375    , 0.375    ,\n",
       "            0.3828125, 0.3828125, 0.3828125, 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.40983605, 0.4262295 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59836066, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6967213 , 0.71311474, 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.74590164, 0.74590164, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9956 , 0.9946 , 0.9927 , 0.9897 , 0.9893 , 0.989  ,\n",
       "            0.986  , 0.985  , 0.979  , 0.976  , 0.9756 , 0.9736 , 0.972  ,\n",
       "            0.9717 , 0.9707 , 0.969  , 0.9683 , 0.9673 , 0.966  , 0.9653 ,\n",
       "            0.964  , 0.9634 , 0.9624 , 0.961  , 0.958  , 0.9575 , 0.956  ,\n",
       "            0.9546 , 0.953  , 0.946  , 0.9434 , 0.9414 , 0.941  , 0.9385 ,\n",
       "            0.9336 , 0.927  , 0.9253 , 0.919  , 0.9146 , 0.9087 , 0.906  ,\n",
       "            0.9033 , 0.903  , 0.8994 , 0.894  , 0.8896 , 0.8853 , 0.879  ,\n",
       "            0.878  , 0.8765 , 0.875  , 0.8745 , 0.8726 , 0.868  , 0.866  ,\n",
       "            0.864  , 0.8604 , 0.8594 , 0.8496 , 0.8486 , 0.842  , 0.841  ,\n",
       "            0.8364 , 0.834  , 0.832  , 0.8315 , 0.8306 , 0.8296 , 0.825  ,\n",
       "            0.823  , 0.8228 , 0.82   , 0.811  , 0.8105 , 0.8022 , 0.8    ,\n",
       "            0.799  , 0.7974 , 0.788  , 0.786  , 0.7837 , 0.7812 , 0.7803 ,\n",
       "            0.78   , 0.7783 , 0.777  , 0.7754 , 0.7705 , 0.769  , 0.7656 ,\n",
       "            0.7637 , 0.763  , 0.758  , 0.757  , 0.7554 , 0.755  , 0.751  ,\n",
       "            0.7495 , 0.7383 , 0.731  , 0.7295 , 0.7285 , 0.728  , 0.727  ,\n",
       "            0.7266 , 0.7236 , 0.715  , 0.712  , 0.711  , 0.7104 , 0.71   ,\n",
       "            0.7056 , 0.705  , 0.7007 , 0.7    , 0.698  , 0.697  , 0.688  ,\n",
       "            0.6875 , 0.686  , 0.684  , 0.6836 , 0.6826 , 0.681  , 0.6797 ,\n",
       "            0.6787 , 0.6777 , 0.675  , 0.6704 , 0.6675 , 0.6636 , 0.6626 ,\n",
       "            0.662  , 0.657  , 0.654  , 0.6484 , 0.645  , 0.6387 , 0.638  ,\n",
       "            0.6377 , 0.6367 , 0.635  , 0.6284 , 0.6274 , 0.6055 , 0.6045 ,\n",
       "            0.604  , 0.6016 , 0.6    , 0.597  , 0.592  , 0.5815 , 0.579  ,\n",
       "            0.578  , 0.5723 , 0.5654 , 0.5586 , 0.5576 , 0.54   , 0.5366 ,\n",
       "            0.518  , 0.5137 , 0.502  , 0.5015 , 0.5    , 0.4917 , 0.488  ,\n",
       "            0.485  , 0.4758 , 0.4749 , 0.4604 , 0.4565 , 0.395  , 0.3906 ,\n",
       "            0.3882 , 0.3838 , 0.3804 , 0.3708 , 0.362  , 0.3503 , 0.3435 ,\n",
       "            0.343  , 0.3384 , 0.3083 , 0.3062 , 0.2715 , 0.2654 , 0.2644 ,\n",
       "            0.2603 , 0.2588 , 0.2568 , 0.2467 , 0.2272 , 0.2216 , 0.2208 ,\n",
       "            0.2205 , 0.2179 , 0.2051 , 0.2043 , 0.1869 , 0.1836 , 0.17   ,\n",
       "            0.169  , 0.166  , 0.1605 , 0.1558 , 0.145  , 0.1396 , 0.1277 ,\n",
       "            0.1259 , 0.12036, 0.11633, 0.115  , 0.1144 , 0.1126 , 0.1118 ,\n",
       "            0.11145, 0.09503, 0.0935 , 0.0922 , 0.0775 , 0.0698 , 0.0645 ,\n",
       "            0.0611 , 0.0548 , 0.05292, 0.04733, 0.0378 , 0.0376 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5078125, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.1484375, 0.15625  , 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.25     , 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.3203125, 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.34375  , 0.34375  , 0.34375  , 0.3515625, 0.3515625, 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.3671875, 0.375    , 0.3828125, 0.3828125,\n",
       "            0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09836066, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18852459,\n",
       "            0.19672132, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9966 , 0.9956 , 0.994  , 0.9917 , 0.991  , 0.9907 ,\n",
       "            0.9883 , 0.9873 , 0.9824 , 0.982  , 0.9795 , 0.977  , 0.976  ,\n",
       "            0.975  , 0.9746 , 0.973  , 0.9727 , 0.9717 , 0.97   , 0.9697 ,\n",
       "            0.9683 , 0.967  , 0.9663 , 0.966  , 0.963  , 0.9624 , 0.9614 ,\n",
       "            0.96   , 0.959  , 0.9585 , 0.9526 , 0.9497 , 0.9478 , 0.9473 ,\n",
       "            0.947  , 0.946  , 0.9404 , 0.9336 , 0.932  , 0.9263 , 0.924  ,\n",
       "            0.9175 , 0.9146 , 0.911  , 0.908  , 0.9062 , 0.9004 , 0.896  ,\n",
       "            0.891  , 0.89   , 0.887  , 0.8867 , 0.8833 , 0.8823 , 0.882  ,\n",
       "            0.881  , 0.8774 , 0.8735 , 0.873  , 0.8696 , 0.8643 , 0.861  ,\n",
       "            0.8555 , 0.855  , 0.8506 , 0.8486 , 0.8467 , 0.8457 , 0.844  ,\n",
       "            0.843  , 0.8423 , 0.841  , 0.839  , 0.8345 , 0.829  , 0.827  ,\n",
       "            0.8174 , 0.814  , 0.8135 , 0.812  , 0.8057 , 0.8047 , 0.8027 ,\n",
       "            0.802  , 0.8013 , 0.801  , 0.798  , 0.795  , 0.792  , 0.788  ,\n",
       "            0.7876 , 0.787  , 0.7847 , 0.784  , 0.782  , 0.7783 , 0.776  ,\n",
       "            0.7744 , 0.7734 , 0.7725 , 0.7715 , 0.767  , 0.764  , 0.7534 ,\n",
       "            0.753  , 0.7495 , 0.748  , 0.7466 , 0.7456 , 0.7427 , 0.7383 ,\n",
       "            0.734  , 0.7334 , 0.7295 , 0.729  , 0.728  , 0.7246 , 0.722  ,\n",
       "            0.7217 , 0.719  , 0.7183 , 0.716  , 0.7104 , 0.706  , 0.7046 ,\n",
       "            0.703  , 0.7026 , 0.701  , 0.7007 , 0.699  , 0.6987 , 0.697  ,\n",
       "            0.695  , 0.693  , 0.6855 , 0.6836 , 0.679  , 0.6777 , 0.674  ,\n",
       "            0.6724 , 0.6655 , 0.665  , 0.6646 , 0.663  , 0.659  , 0.657  ,\n",
       "            0.6514 , 0.647  , 0.6265 , 0.624  , 0.6226 , 0.622  , 0.6196 ,\n",
       "            0.6187 , 0.6147 , 0.602  , 0.5996 , 0.5947 , 0.5854 , 0.5845 ,\n",
       "            0.5767 , 0.5757 , 0.5635 , 0.5454 , 0.539  , 0.5366 , 0.525  ,\n",
       "            0.5205 , 0.5117 , 0.509  , 0.5015 , 0.4863 , 0.483  , 0.4744 ,\n",
       "            0.467  , 0.4622 , 0.402  , 0.4    , 0.393  , 0.3875 , 0.3813 ,\n",
       "            0.3782 , 0.376  , 0.3499 , 0.3484 , 0.345  , 0.3367 , 0.309  ,\n",
       "            0.3054 , 0.2634 , 0.258  , 0.2573 , 0.256  , 0.2544 , 0.2421 ,\n",
       "            0.2216 , 0.2213 , 0.2162 , 0.2144 , 0.2125 , 0.2015 , 0.2002 ,\n",
       "            0.1824 , 0.181  , 0.1648 , 0.1622 , 0.1614 , 0.1514 , 0.1498 ,\n",
       "            0.1477 , 0.138  , 0.1328 , 0.1217 , 0.1186 , 0.11475, 0.11084,\n",
       "            0.1103 , 0.1099 , 0.1097 , 0.1056 , 0.1052 , 0.089  , 0.088  ,\n",
       "            0.0868 , 0.0866 , 0.0709 , 0.0661 , 0.05878, 0.05664, 0.05127,\n",
       "            0.04752, 0.0441 , 0.0347 , 0.0345 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5078125, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.28125  , 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.2890625, 0.296875 , 0.296875 , 0.3046875, 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.3359375, 0.34375  ,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.3671875, 0.375    , 0.3828125, 0.3828125, 0.390625 ,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5      , 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.19672132, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6639344 , 0.6639344 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.997  , 0.9966 , 0.996  , 0.995  , 0.9927 , 0.992  ,\n",
       "            0.99   , 0.9893 , 0.985  , 0.9844 , 0.9824 , 0.982  , 0.98   ,\n",
       "            0.979  , 0.978  , 0.9766 , 0.976  , 0.975  , 0.974  , 0.9736 ,\n",
       "            0.9717 , 0.9707 , 0.97   , 0.9697 , 0.967  , 0.966  , 0.9644 ,\n",
       "            0.9634 , 0.963  , 0.958  , 0.9556 , 0.9536 , 0.9526 , 0.947  ,\n",
       "            0.9404 , 0.9385 , 0.933  , 0.932  , 0.926  , 0.9253 , 0.9224 ,\n",
       "            0.919  , 0.918  , 0.9165 , 0.9155 , 0.91   , 0.9062 , 0.903  ,\n",
       "            0.9014 , 0.898  , 0.896  , 0.8945 , 0.8916 , 0.891  , 0.8867 ,\n",
       "            0.886  , 0.882  , 0.8804 , 0.8784 , 0.873  , 0.8687 , 0.865  ,\n",
       "            0.8633 , 0.861  , 0.8604 , 0.8584 , 0.8574 , 0.8564 , 0.855  ,\n",
       "            0.8545 , 0.854  , 0.849  , 0.846  , 0.8438 , 0.8335 , 0.83   ,\n",
       "            0.8286 , 0.8257 , 0.8237 , 0.823  , 0.8223 , 0.82   , 0.819  ,\n",
       "            0.8164 , 0.8115 , 0.809  , 0.8066 , 0.8047 , 0.803  , 0.7993 ,\n",
       "            0.799  , 0.7974 , 0.7954 , 0.7944 , 0.7935 , 0.7905 , 0.7896 ,\n",
       "            0.789  , 0.785  , 0.781  , 0.7773 , 0.776  , 0.772  , 0.766  ,\n",
       "            0.7656 , 0.765  , 0.7637 , 0.7627 , 0.7563 , 0.7544 , 0.75   ,\n",
       "            0.7495 , 0.747  , 0.7456 , 0.7446 , 0.743  , 0.741  , 0.74   ,\n",
       "            0.7373 , 0.7363 , 0.734  , 0.7334 , 0.7314 , 0.7275 , 0.727  ,\n",
       "            0.7246 , 0.723  , 0.7217 , 0.7207 , 0.72   , 0.718  , 0.708  ,\n",
       "            0.705  , 0.703  , 0.698  , 0.693  , 0.6924 , 0.69   , 0.6895 ,\n",
       "            0.6875 , 0.687  , 0.686  , 0.685  , 0.683  , 0.67   , 0.667  ,\n",
       "            0.6514 , 0.646  , 0.6436 , 0.64   , 0.635  , 0.633  , 0.6255 ,\n",
       "            0.623  , 0.614  , 0.6084 , 0.6    , 0.598  , 0.596  , 0.5894 ,\n",
       "            0.567  , 0.558  , 0.557  , 0.552  , 0.5435 , 0.5386 , 0.53   ,\n",
       "            0.5044 , 0.4944 , 0.4917 , 0.4783 , 0.4775 , 0.4724 , 0.414  ,\n",
       "            0.4138 , 0.4067 , 0.3938 , 0.3914 , 0.39   , 0.3872 , 0.361  ,\n",
       "            0.3513 , 0.3396 , 0.3142 , 0.3093 , 0.2603 , 0.2595 , 0.2573 ,\n",
       "            0.256  , 0.2544 , 0.251  , 0.2415 , 0.2247 , 0.2198 , 0.2181 ,\n",
       "            0.2114 , 0.2085 , 0.2023 , 0.1991 , 0.1816 , 0.1804 , 0.1625 ,\n",
       "            0.1594 , 0.1588 , 0.147  , 0.1454 , 0.1428 , 0.1338 , 0.1289 ,\n",
       "            0.11816, 0.11395, 0.11145, 0.11084, 0.1076 , 0.1069 , 0.10156,\n",
       "            0.10144, 0.08496, 0.08466, 0.0833 , 0.083  , 0.06647, 0.0635 ,\n",
       "            0.0548 , 0.0537 , 0.04886, 0.04376, 0.04184, 0.03247, 0.03223],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.515625, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.109375 ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.2421875,\n",
       "            0.25     , 0.25     , 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.28125  , 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3125   , 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.359375 , 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.375    , 0.375    , 0.375    , 0.375    ,\n",
       "            0.375    , 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.484375 ,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09836066,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.19672132,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.3852459 ,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45081967, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9976 , 0.997  , 0.996  , 0.994  , 0.9937 , 0.9917 ,\n",
       "            0.9907 , 0.9873 , 0.987  , 0.985  , 0.983  , 0.982  , 0.9814 ,\n",
       "            0.981  , 0.98   , 0.9795 , 0.9785 , 0.9775 , 0.977  , 0.9756 ,\n",
       "            0.9746 , 0.974  , 0.9736 , 0.971  , 0.9707 , 0.9697 , 0.9688 ,\n",
       "            0.9683 , 0.968  , 0.9634 , 0.9614 , 0.9595 , 0.9585 , 0.958  ,\n",
       "            0.9526 , 0.9473 , 0.945  , 0.9404 , 0.94   , 0.9355 , 0.9336 ,\n",
       "            0.93   , 0.9287 , 0.927  , 0.9253 , 0.924  , 0.92   , 0.916  ,\n",
       "            0.9136 , 0.9126 , 0.9097 , 0.909  , 0.9087 , 0.908  , 0.901  ,\n",
       "            0.9004 , 0.8984 , 0.8965 , 0.8926 , 0.8916 , 0.8853 , 0.882  ,\n",
       "            0.88   , 0.8774 , 0.877  , 0.8765 , 0.8745 , 0.873  , 0.87   ,\n",
       "            0.866  , 0.8657 , 0.865  , 0.864  , 0.8623 , 0.85   , 0.849  ,\n",
       "            0.8486 , 0.8457 , 0.845  , 0.844  , 0.8433 , 0.84   , 0.8384 ,\n",
       "            0.8315 , 0.8296 , 0.829  , 0.826  , 0.8257 , 0.824  , 0.82   ,\n",
       "            0.818  , 0.8164 , 0.812  , 0.811  , 0.8105 , 0.81   , 0.8076 ,\n",
       "            0.806  , 0.8037 , 0.799  , 0.791  , 0.79   , 0.788  , 0.7876 ,\n",
       "            0.785  , 0.7847 , 0.78   , 0.7734 , 0.771  , 0.7705 , 0.7695 ,\n",
       "            0.7686 , 0.768  , 0.7637 , 0.763  , 0.7627 , 0.762  , 0.7607 ,\n",
       "            0.7583 , 0.7554 , 0.7544 , 0.7515 , 0.7495 , 0.748  , 0.7446 ,\n",
       "            0.744  , 0.7417 , 0.735  , 0.733  , 0.7305 , 0.7275 , 0.7266 ,\n",
       "            0.7256 , 0.725  , 0.7236 , 0.722  , 0.714  , 0.7134 , 0.712  ,\n",
       "            0.7095 , 0.703  , 0.6943 , 0.694  , 0.683  , 0.6772 , 0.6763 ,\n",
       "            0.6753 , 0.6743 , 0.673  , 0.657  , 0.6567 , 0.6562 , 0.6543 ,\n",
       "            0.639  , 0.6265 , 0.6245 , 0.6235 , 0.6216 , 0.604  , 0.588  ,\n",
       "            0.5874 , 0.5757 , 0.575  , 0.574  , 0.5586 , 0.5117 , 0.5103 ,\n",
       "            0.4993 , 0.495  , 0.4883 , 0.4832 , 0.437  , 0.4326 , 0.4287 ,\n",
       "            0.4207 , 0.4094 , 0.398  , 0.3977 , 0.3804 , 0.3625 , 0.3562 ,\n",
       "            0.3462 , 0.3245 , 0.3174 , 0.266  , 0.2622 , 0.2615 , 0.2573 ,\n",
       "            0.2527 , 0.2473 , 0.243  , 0.2323 , 0.224  , 0.22   , 0.2101 ,\n",
       "            0.2063 , 0.2056 , 0.2002 , 0.1855 , 0.1808 , 0.1626 , 0.1602 ,\n",
       "            0.1567 , 0.1456 , 0.1403 , 0.1388 , 0.1307 , 0.126  , 0.11597,\n",
       "            0.1134 , 0.1103 , 0.1095 , 0.1069 , 0.1052 , 0.1043 , 0.09894,\n",
       "            0.0986 , 0.0823 , 0.08167, 0.0808 , 0.0804 , 0.06256, 0.0621 ,\n",
       "            0.05145, 0.05127, 0.04724, 0.04037, 0.0403 , 0.03073, 0.03033],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.53125, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.078125 , 0.078125 , 0.078125 ,\n",
       "            0.09375  , 0.109375 , 0.1171875, 0.125    , 0.125    , 0.125    ,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2109375, 0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.25     , 0.2578125, 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.296875 , 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.375    , 0.375    , 0.375    , 0.375    , 0.3828125,\n",
       "            0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.09016393, 0.09836066,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.998  , 0.9976 , 0.9966 , 0.995  , 0.9946 , 0.993  ,\n",
       "            0.9927 , 0.9893 , 0.989  , 0.9873 , 0.9854 , 0.985  , 0.984  ,\n",
       "            0.983  , 0.9824 , 0.982  , 0.9805 , 0.979  , 0.9785 , 0.978  ,\n",
       "            0.9775 , 0.977  , 0.9756 , 0.974  , 0.9736 , 0.972  , 0.9717 ,\n",
       "            0.9683 , 0.9663 , 0.9644 , 0.9634 , 0.9624 , 0.958  , 0.953  ,\n",
       "            0.95   , 0.948  , 0.946  , 0.9453 , 0.9414 , 0.9395 , 0.9375 ,\n",
       "            0.933  , 0.931  , 0.9297 , 0.9253 , 0.925  , 0.924  , 0.9233 ,\n",
       "            0.9224 , 0.9204 , 0.9185 , 0.911  , 0.909  , 0.908  , 0.907  ,\n",
       "            0.9053 , 0.9014 , 0.899  , 0.897  , 0.896  , 0.895  , 0.894  ,\n",
       "            0.8936 , 0.892  , 0.8896 , 0.889  , 0.884  , 0.8794 , 0.879  ,\n",
       "            0.8774 , 0.874  , 0.8706 , 0.866  , 0.865  , 0.8647 , 0.8633 ,\n",
       "            0.8623 , 0.8584 , 0.858  , 0.8574 , 0.8535 , 0.851  , 0.8496 ,\n",
       "            0.8486 , 0.848  , 0.8467 , 0.846  , 0.8457 , 0.8438 , 0.838  ,\n",
       "            0.8374 , 0.837  , 0.831  , 0.829  , 0.8286 , 0.828  , 0.8276 ,\n",
       "            0.8267 , 0.8228 , 0.8223 , 0.812  , 0.8105 , 0.8096 , 0.808  ,\n",
       "            0.8076 , 0.8027 , 0.8022 , 0.798  , 0.7954 , 0.795  , 0.793  ,\n",
       "            0.7905 , 0.789  , 0.788  , 0.7876 , 0.785  , 0.783  , 0.7817 ,\n",
       "            0.781  , 0.7793 , 0.7754 , 0.775  , 0.7725 , 0.772  , 0.765  ,\n",
       "            0.763  , 0.7627 , 0.759  , 0.7583 , 0.7573 , 0.757  , 0.7534 ,\n",
       "            0.753  , 0.743  , 0.741  , 0.738  , 0.7314 , 0.7305 , 0.7173 ,\n",
       "            0.7153 , 0.712  , 0.7056 , 0.7036 , 0.702  , 0.6997 , 0.684  ,\n",
       "            0.682  , 0.677  , 0.6753 , 0.6665 , 0.6616 , 0.6543 , 0.652  ,\n",
       "            0.65   , 0.639  , 0.6377 , 0.619  , 0.6147 , 0.6074 , 0.6045 ,\n",
       "            0.588  , 0.5845 , 0.5254 , 0.5093 , 0.5083 , 0.5024 , 0.499  ,\n",
       "            0.4832 , 0.458  , 0.4487 , 0.4475 , 0.4443 , 0.427  , 0.4045 ,\n",
       "            0.4001 , 0.3975 , 0.3706 , 0.3577 , 0.3489 , 0.3318 , 0.322  ,\n",
       "            0.269  , 0.2637 , 0.2502 , 0.2463 , 0.2417 , 0.2382 , 0.2375 ,\n",
       "            0.2277 , 0.2158 , 0.2079 , 0.2056 , 0.199  , 0.1984 , 0.1871 ,\n",
       "            0.1785 , 0.1603 , 0.1587 , 0.152  , 0.1421 , 0.1321 , 0.1313 ,\n",
       "            0.1254 , 0.121  , 0.1152 , 0.1118 , 0.1058 , 0.10504, 0.1047 ,\n",
       "            0.1021 , 0.1    , 0.0945 , 0.09436, 0.0785 , 0.0771 , 0.07684,\n",
       "            0.0763 , 0.05988, 0.0572 , 0.0484 , 0.0469 , 0.045  , 0.03824,\n",
       "            0.03607, 0.02855, 0.02802], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5390625, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.125    , 0.125    ,\n",
       "            0.125    , 0.125    , 0.1328125, 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.2109375, 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.25     , 0.25     ,\n",
       "            0.25     , 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3046875, 0.3046875, 0.3046875,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.34375  , 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.3671875, 0.375    ,\n",
       "            0.375    , 0.375    , 0.375    , 0.375    , 0.3828125, 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.39344263, 0.40163934, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.44262296, 0.45901638, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.59836066, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.998  , 0.9976 , 0.996  , 0.9956 , 0.994  ,\n",
       "            0.9937 , 0.9907 , 0.99   , 0.9893 , 0.989  , 0.9873 , 0.987  ,\n",
       "            0.986  , 0.985  , 0.9844 , 0.984  , 0.983  , 0.9814 , 0.981  ,\n",
       "            0.9805 , 0.98   , 0.978  , 0.977  , 0.9766 , 0.9756 , 0.975  ,\n",
       "            0.9717 , 0.9697 , 0.9683 , 0.967  , 0.9663 , 0.9624 , 0.9575 ,\n",
       "            0.955  , 0.953  , 0.951  , 0.9507 , 0.95   , 0.947  , 0.9453 ,\n",
       "            0.9434 , 0.939  , 0.937  , 0.936  , 0.9316 , 0.9307 , 0.93   ,\n",
       "            0.927  , 0.925  , 0.9185 , 0.916  , 0.915  , 0.912  , 0.909  ,\n",
       "            0.9067 , 0.905  , 0.9043 , 0.904  , 0.9033 , 0.903  , 0.901  ,\n",
       "            0.899  , 0.8984 , 0.898  , 0.8945 , 0.892  , 0.8896 , 0.8877 ,\n",
       "            0.886  , 0.8843 , 0.882  , 0.879  , 0.877  , 0.876  , 0.8755 ,\n",
       "            0.874  , 0.87   , 0.867  , 0.8643 , 0.8633 , 0.8623 , 0.8604 ,\n",
       "            0.859  , 0.8584 , 0.8555 , 0.851  , 0.8496 , 0.849  , 0.847  ,\n",
       "            0.844  , 0.841  , 0.8403 , 0.8384 , 0.837  , 0.832  , 0.8267 ,\n",
       "            0.826  , 0.8237 , 0.822  , 0.8203 , 0.817  , 0.815  , 0.8105 ,\n",
       "            0.8096 , 0.809  , 0.8086 , 0.8076 , 0.806  , 0.805  , 0.8047 ,\n",
       "            0.803  , 0.8022 , 0.801  , 0.8003 , 0.7983 , 0.7974 , 0.7964 ,\n",
       "            0.796  , 0.7925 , 0.7886 , 0.7876 , 0.7847 , 0.7817 , 0.78   ,\n",
       "            0.7793 , 0.778  , 0.7773 , 0.774  , 0.7734 , 0.768  , 0.76   ,\n",
       "            0.758  , 0.755  , 0.753  , 0.7466 , 0.7446 , 0.7334 , 0.7314 ,\n",
       "            0.73   , 0.7285 , 0.725  , 0.7236 , 0.7227 , 0.718  , 0.7036 ,\n",
       "            0.7017 , 0.6924 , 0.6895 , 0.686  , 0.6772 , 0.6763 , 0.6694 ,\n",
       "            0.6675 , 0.662  , 0.653  , 0.6426 , 0.6343 , 0.632  , 0.6255 ,\n",
       "            0.6035 , 0.599  , 0.536  , 0.519  , 0.512  , 0.5073 , 0.5063 ,\n",
       "            0.4856 , 0.474  , 0.4648 , 0.4634 , 0.4587 , 0.4412 , 0.4111 ,\n",
       "            0.4102 , 0.4026 , 0.377  , 0.3591 , 0.3513 , 0.3374 , 0.326  ,\n",
       "            0.2712 , 0.2654 , 0.2651 , 0.2456 , 0.2426 , 0.2422 , 0.2406 ,\n",
       "            0.2319 , 0.2302 , 0.2124 , 0.2089 , 0.2018 , 0.1959 , 0.1942 ,\n",
       "            0.1884 , 0.1763 , 0.158  , 0.157  , 0.1482 , 0.139  , 0.127  ,\n",
       "            0.1255 , 0.121  , 0.11676, 0.11597, 0.1084 , 0.10284, 0.1025 ,\n",
       "            0.1    , 0.0991 , 0.0964 , 0.0909 , 0.0906 , 0.0752 , 0.07367,\n",
       "            0.0729 , 0.0576 , 0.0532 , 0.0457 , 0.04337, 0.04288, 0.0363 ,\n",
       "            0.0329 , 0.02666, 0.02606], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.546875, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.1015625, 0.1171875, 0.1171875,\n",
       "            0.125    , 0.125    , 0.125    , 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.234375 , 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.25     , 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.34375  , 0.3515625, 0.3671875, 0.3671875,\n",
       "            0.375    , 0.375    , 0.375    , 0.375    , 0.375    , 0.3828125,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.421875 , 0.4296875,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.03278688, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.09836066, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.19672132, 0.20491803, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.4180328 , 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.59016395, 0.59016395, 0.59836066, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.998  , 0.9966 , 0.996  , 0.995  , 0.9946 ,\n",
       "            0.992  , 0.9907 , 0.9893 , 0.989  , 0.9883 , 0.9873 , 0.987  ,\n",
       "            0.9863 , 0.986  , 0.9854 , 0.9844 , 0.984  , 0.9834 , 0.983  ,\n",
       "            0.9814 , 0.981  , 0.98   , 0.979  , 0.9785 , 0.9756 , 0.974  ,\n",
       "            0.9727 , 0.9717 , 0.971  , 0.9673 , 0.9634 , 0.9604 , 0.9595 ,\n",
       "            0.959  , 0.957  , 0.9565 , 0.954  , 0.9536 , 0.95   , 0.9463 ,\n",
       "            0.9443 , 0.942  , 0.9414 , 0.941  , 0.94   , 0.9395 , 0.9365 ,\n",
       "            0.934  , 0.9287 , 0.9272 , 0.9253 , 0.9243 , 0.922  , 0.9194 ,\n",
       "            0.9185 , 0.918  , 0.916  , 0.9155 , 0.915  , 0.9136 , 0.911  ,\n",
       "            0.91   , 0.905  , 0.903  , 0.901  , 0.8975 , 0.897  , 0.8945 ,\n",
       "            0.8936 , 0.892  , 0.891  , 0.8877 , 0.885  , 0.8843 , 0.884  ,\n",
       "            0.8813 , 0.881  , 0.878  , 0.877  , 0.876  , 0.8735 , 0.87   ,\n",
       "            0.8696 , 0.869  , 0.8667 , 0.866  , 0.8604 , 0.86   , 0.859  ,\n",
       "            0.853  , 0.85   , 0.8477 , 0.846  , 0.845  , 0.8423 , 0.8403 ,\n",
       "            0.839  , 0.835  , 0.8345 , 0.834  , 0.8325 , 0.8315 , 0.831  ,\n",
       "            0.83   , 0.829  , 0.8286 , 0.824  , 0.8237 , 0.823  , 0.8228 ,\n",
       "            0.8223 , 0.8213 , 0.819  , 0.818  , 0.8174 , 0.813  , 0.8125 ,\n",
       "            0.811  , 0.8086 , 0.8066 , 0.8022 , 0.801  , 0.8003 , 0.799  ,\n",
       "            0.7915 , 0.787  , 0.781  , 0.78   , 0.7715 , 0.7705 , 0.7666 ,\n",
       "            0.7603 , 0.759  , 0.754  , 0.753  , 0.752  , 0.751  , 0.747  ,\n",
       "            0.7446 , 0.733  , 0.7314 , 0.7163 , 0.716  , 0.712  , 0.7085 ,\n",
       "            0.7026 , 0.6973 , 0.6953 , 0.677  , 0.6753 , 0.667  , 0.6646 ,\n",
       "            0.657  , 0.633  , 0.619  , 0.5566 , 0.5386 , 0.5244 , 0.519  ,\n",
       "            0.5005 , 0.4973 , 0.4915 , 0.4907 , 0.4788 , 0.4626 , 0.432  ,\n",
       "            0.4236 , 0.4133 , 0.3909 , 0.3684 , 0.3608 , 0.3494 , 0.3372 ,\n",
       "            0.2786 , 0.2727 , 0.2717 , 0.2517 , 0.2473 , 0.2444 , 0.244  ,\n",
       "            0.2372 , 0.233  , 0.2139 , 0.2134 , 0.2026 , 0.1973 , 0.1947 ,\n",
       "            0.1929 , 0.1776 , 0.1588 , 0.1584 , 0.1477 , 0.1388 , 0.1255 ,\n",
       "            0.1238 , 0.1193 , 0.1188 , 0.11536, 0.10706, 0.10266, 0.10144,\n",
       "            0.09827, 0.0981 , 0.09467, 0.0891 , 0.0888 , 0.0734 , 0.07196,\n",
       "            0.0709 , 0.05655, 0.0511 , 0.044  , 0.04163, 0.04132, 0.035  ,\n",
       "            0.03108, 0.02533, 0.02466], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5703125, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.125    , 0.125    , 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.1640625, 0.171875 , 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.2421875, 0.2421875, 0.2578125,\n",
       "            0.265625 , 0.265625 , 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.296875 , 0.3046875, 0.3046875, 0.3046875, 0.3203125,\n",
       "            0.3203125, 0.34375  , 0.34375  , 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.375    , 0.375    , 0.375    , 0.3828125,\n",
       "            0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.03278688, 0.04098361, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.4180328 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.59836066, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.9985 , 0.9976 , 0.997  , 0.996  , 0.9956 ,\n",
       "            0.9937 , 0.9927 , 0.992  , 0.991  , 0.9907 , 0.99   , 0.9897 ,\n",
       "            0.9893 , 0.989  , 0.9883 , 0.988  , 0.987  , 0.9863 , 0.986  ,\n",
       "            0.9844 , 0.984  , 0.9834 , 0.9824 , 0.982  , 0.9795 , 0.978  ,\n",
       "            0.977  , 0.976  , 0.9756 , 0.972  , 0.9688 , 0.9663 , 0.966  ,\n",
       "            0.9653 , 0.9634 , 0.963  , 0.9614 , 0.9604 , 0.957  , 0.9536 ,\n",
       "            0.952  , 0.95   , 0.949  , 0.948  , 0.9478 , 0.9453 , 0.9424 ,\n",
       "            0.9385 , 0.9375 , 0.9346 , 0.9336 , 0.9316 , 0.9297 , 0.929  ,\n",
       "            0.927  , 0.9263 , 0.926  , 0.9253 , 0.9243 , 0.9224 , 0.922  ,\n",
       "            0.9175 , 0.917  , 0.916  , 0.913  , 0.9106 , 0.909  , 0.908  ,\n",
       "            0.907  , 0.9053 , 0.905  , 0.904  , 0.902  , 0.9014 , 0.9004 ,\n",
       "            0.8984 , 0.896  , 0.894  , 0.893  , 0.891  , 0.8906 , 0.89   ,\n",
       "            0.888  , 0.887  , 0.8857 , 0.885  , 0.884  , 0.8813 , 0.878  ,\n",
       "            0.8755 , 0.8745 , 0.874  , 0.8687 , 0.8677 , 0.8643 , 0.8623 ,\n",
       "            0.8604 , 0.859  , 0.857  , 0.8564 , 0.855  , 0.853  , 0.851  ,\n",
       "            0.8506 , 0.85   , 0.849  , 0.8486 , 0.848  , 0.845  , 0.8438 ,\n",
       "            0.842  , 0.84   , 0.8384 , 0.8374 , 0.837  , 0.836  , 0.8345 ,\n",
       "            0.8325 , 0.8315 , 0.83   , 0.825  , 0.821  , 0.8193 , 0.819  ,\n",
       "            0.8164 , 0.811  , 0.8086 , 0.801  , 0.8003 , 0.7905 , 0.7896 ,\n",
       "            0.785  , 0.7837 , 0.7793 , 0.7773 , 0.7764 , 0.7744 , 0.773  ,\n",
       "            0.767  , 0.7656 , 0.757  , 0.7554 , 0.74   , 0.7373 , 0.735  ,\n",
       "            0.7314 , 0.726  , 0.724  , 0.721  , 0.7188 , 0.705  , 0.696  ,\n",
       "            0.695  , 0.6895 , 0.6836 , 0.6577 , 0.6377 , 0.5747 , 0.556  ,\n",
       "            0.5396 , 0.5376 , 0.5327 , 0.5234 , 0.515  , 0.513  , 0.51   ,\n",
       "            0.4958 , 0.4822 , 0.45   , 0.4355 , 0.424  , 0.4028 , 0.3774 ,\n",
       "            0.3699 , 0.3599 , 0.3467 , 0.2844 , 0.278  , 0.2769 , 0.2588 ,\n",
       "            0.2482 , 0.2477 , 0.2455 , 0.2424 , 0.2339 , 0.2175 , 0.2139 ,\n",
       "            0.2026 , 0.1978 , 0.196  , 0.1943 , 0.178  , 0.1586 , 0.1584 ,\n",
       "            0.1465 , 0.1378 , 0.1232 , 0.1216 , 0.1201 , 0.1172 , 0.11316,\n",
       "            0.10504, 0.10156, 0.0995 , 0.09656, 0.0955 , 0.0927 , 0.0868 ,\n",
       "            0.0866 , 0.07135, 0.0698 , 0.06866, 0.0684 , 0.0549 , 0.04858,\n",
       "            0.04208, 0.04   , 0.0389 , 0.03354, 0.02908, 0.02377, 0.0231 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.578125, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1171875, 0.125    , 0.1328125, 0.1328125,\n",
       "            0.1328125, 0.1484375, 0.1640625, 0.171875 , 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.265625 ,\n",
       "            0.2734375, 0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.3359375, 0.34375  , 0.34375  , 0.34375  , 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.375    , 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.390625 , 0.390625 , 0.4140625, 0.421875 , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.03278688, 0.04098361, 0.05737705,\n",
       "            0.07377049, 0.09836066, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.14754099, 0.1557377 , 0.17213115, 0.19672132, 0.21311475,\n",
       "            0.22131148, 0.23770492, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59016395, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.6229508 , 0.63114756, 0.647541  , 0.6639344 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.9985 , 0.998  , 0.9976 , 0.9966 , 0.9946 ,\n",
       "            0.9937 , 0.9927 , 0.992  , 0.9917 , 0.991  , 0.9907 , 0.9897 ,\n",
       "            0.989  , 0.9883 , 0.988  , 0.9863 , 0.986  , 0.985  , 0.9844 ,\n",
       "            0.982  , 0.981  , 0.98   , 0.979  , 0.9785 , 0.9756 , 0.9727 ,\n",
       "            0.97   , 0.9673 , 0.967  , 0.965  , 0.962  , 0.959  , 0.9585 ,\n",
       "            0.958  , 0.9575 , 0.957  , 0.9556 , 0.9546 , 0.9536 , 0.9517 ,\n",
       "            0.9487 , 0.946  , 0.9453 , 0.941  , 0.94   , 0.9395 , 0.9385 ,\n",
       "            0.938  , 0.9365 , 0.935  , 0.9346 , 0.934  , 0.9336 , 0.933  ,\n",
       "            0.9326 , 0.931  , 0.9307 , 0.929  , 0.9277 , 0.925  , 0.923  ,\n",
       "            0.9224 , 0.9194 , 0.919  , 0.9175 , 0.916  , 0.914  , 0.9136 ,\n",
       "            0.913  , 0.9126 , 0.911  , 0.908  , 0.906  , 0.904  , 0.903  ,\n",
       "            0.902  , 0.9004 , 0.899  , 0.8984 , 0.898  , 0.894  , 0.8926 ,\n",
       "            0.889  , 0.887  , 0.886  , 0.8843 , 0.8794 , 0.879  , 0.877  ,\n",
       "            0.873  , 0.8726 , 0.871  , 0.8706 , 0.8696 , 0.8687 , 0.867  ,\n",
       "            0.8667 , 0.865  , 0.8643 , 0.8633 , 0.861  , 0.8584 , 0.858  ,\n",
       "            0.857  , 0.855  , 0.854  , 0.8525 , 0.8516 , 0.851  , 0.8496 ,\n",
       "            0.849  , 0.8486 , 0.846  , 0.845  , 0.841  , 0.837  , 0.8364 ,\n",
       "            0.835  , 0.8276 , 0.827  , 0.8184 , 0.817  , 0.807  , 0.804  ,\n",
       "            0.8027 , 0.8003 , 0.7974 , 0.797  , 0.7944 , 0.79   , 0.7866 ,\n",
       "            0.778  , 0.7764 , 0.7617 , 0.7583 , 0.7534 , 0.751  , 0.747  ,\n",
       "            0.742  , 0.741  , 0.739  , 0.73   , 0.7217 , 0.7114 , 0.7104 ,\n",
       "            0.707  , 0.6797 , 0.6514 , 0.588  , 0.567  , 0.5493 , 0.5415 ,\n",
       "            0.5396 , 0.5347 , 0.5327 , 0.515  , 0.5083 , 0.4976 , 0.4639 ,\n",
       "            0.4426 , 0.429  , 0.4104 , 0.381  , 0.3738 , 0.3665 , 0.352  ,\n",
       "            0.2869 , 0.28   , 0.2786 , 0.2632 , 0.2473 , 0.2452 , 0.2448 ,\n",
       "            0.2422 , 0.2297 , 0.2185 , 0.211  , 0.1996 , 0.1973 , 0.1954 ,\n",
       "            0.1904 , 0.1757 , 0.1567 , 0.1564 , 0.1431 , 0.1349 , 0.12067,\n",
       "            0.1188 , 0.11676, 0.1134 , 0.1095 , 0.10175, 0.0995 , 0.0964 ,\n",
       "            0.0939 , 0.09155, 0.0893 , 0.0836 , 0.0833 , 0.0684 , 0.06683,\n",
       "            0.06573, 0.065  , 0.05283, 0.04535, 0.0398 , 0.03812, 0.03616,\n",
       "            0.0318 , 0.02666, 0.02216, 0.02148], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5859375, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.2890625, 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.34375  , 0.34375  , 0.359375 , 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.375    , 0.375    , 0.3828125, 0.390625 , 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.4140625, 0.421875 , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.03278688, 0.04098361, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13934426, 0.14754099, 0.16393442, 0.17213115,\n",
       "            0.19672132, 0.21311475, 0.23770492, 0.25409836, 0.26229507,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.31967214, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.3852459 , 0.39344263, 0.40163934, 0.4180328 ,\n",
       "            0.4262295 , 0.44262296, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6967213 ,\n",
       "            0.6967213 , 0.6967213 , 0.6967213 , 0.704918  , 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9995 , 0.999  , 0.9985 , 0.998  , 0.9976 , 0.997  ,\n",
       "            0.9956 , 0.995  , 0.9946 , 0.994  , 0.9937 , 0.993  , 0.9927 ,\n",
       "            0.992  , 0.9917 , 0.9907 , 0.99   , 0.989  , 0.9883 , 0.9873 ,\n",
       "            0.985  , 0.984  , 0.9834 , 0.9824 , 0.9795 , 0.9766 , 0.975  ,\n",
       "            0.9746 , 0.9727 , 0.972  , 0.9717 , 0.97   , 0.9673 , 0.965  ,\n",
       "            0.964  , 0.9634 , 0.962  , 0.961  , 0.96   , 0.9585 , 0.9556 ,\n",
       "            0.953  , 0.9526 , 0.9487 , 0.948  , 0.9473 , 0.947  , 0.9463 ,\n",
       "            0.945  , 0.944  , 0.9434 , 0.9424 , 0.942  , 0.9414 , 0.9395 ,\n",
       "            0.9365 , 0.934  , 0.933  , 0.932  , 0.9297 , 0.929  , 0.928  ,\n",
       "            0.9272 , 0.9263 , 0.926  , 0.9243 , 0.924  , 0.9224 , 0.9194 ,\n",
       "            0.917  , 0.915  , 0.9146 , 0.914  , 0.9136 , 0.912  , 0.9116 ,\n",
       "            0.9106 , 0.9097 , 0.906  , 0.9014 , 0.8994 , 0.899  , 0.8984 ,\n",
       "            0.892  , 0.89   , 0.888  , 0.8867 , 0.8853 , 0.8843 , 0.884  ,\n",
       "            0.8833 , 0.883  , 0.8823 , 0.882  , 0.8804 , 0.88   , 0.8784 ,\n",
       "            0.878  , 0.877  , 0.8765 , 0.874  , 0.872  , 0.8706 , 0.869  ,\n",
       "            0.8687 , 0.8677 , 0.867  , 0.8657 , 0.865  , 0.8643 , 0.8633 ,\n",
       "            0.862  , 0.857  , 0.853  , 0.8525 , 0.8506 , 0.8457 , 0.844  ,\n",
       "            0.8433 , 0.836  , 0.8335 , 0.824  , 0.8237 , 0.82   , 0.8174 ,\n",
       "            0.817  , 0.8164 , 0.816  , 0.815  , 0.8135 , 0.807  , 0.8057 ,\n",
       "            0.798  , 0.7964 , 0.782  , 0.781  , 0.7754 , 0.772  , 0.7656 ,\n",
       "            0.7617 , 0.761  , 0.7593 , 0.7544 , 0.7466 , 0.734  , 0.73   ,\n",
       "            0.7295 , 0.7026 , 0.6714 , 0.6074 , 0.585  , 0.567  , 0.565  ,\n",
       "            0.562  , 0.5586 , 0.557  , 0.556  , 0.5356 , 0.5273 , 0.5176 ,\n",
       "            0.4824 , 0.4578 , 0.445  , 0.4248 , 0.3953 , 0.3867 , 0.3794 ,\n",
       "            0.3643 , 0.2954 , 0.2883 , 0.2864 , 0.2725 , 0.254  , 0.253  ,\n",
       "            0.252  , 0.2489 , 0.2388 , 0.2242 , 0.2148 , 0.2029 , 0.2024 ,\n",
       "            0.1985 , 0.1947 , 0.1782 , 0.1587 , 0.1582 , 0.1444 , 0.1359 ,\n",
       "            0.1229 , 0.1201 , 0.1195 , 0.1136 , 0.1097 , 0.10175, 0.0997 ,\n",
       "            0.0962 , 0.0937 , 0.0914 , 0.089  , 0.083  , 0.0827 , 0.06757,\n",
       "            0.066  , 0.06476, 0.0642 , 0.05212, 0.04477, 0.03876, 0.03732,\n",
       "            0.03528, 0.03091, 0.02615, 0.02129, 0.02065], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5859375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.1328125, 0.140625 , 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.2734375, 0.28125  , 0.28125  , 0.28125  , 0.28125  , 0.28125  ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.3359375, 0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3671875, 0.375    , 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.4140625, 0.4140625, 0.421875 , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.04098361, 0.05737705, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.1147541 , 0.12295082, 0.14754099,\n",
       "            0.1557377 , 0.17213115, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.47540984, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5081967 , 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59836066, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9995 , 0.999  , 0.9985 , 0.998  , 0.997  , 0.9966 ,\n",
       "            0.996  , 0.9956 , 0.995  , 0.9946 , 0.994  , 0.9937 , 0.993  ,\n",
       "            0.9927 , 0.992  , 0.9917 , 0.991  , 0.9907 , 0.99   , 0.9897 ,\n",
       "            0.9883 , 0.9873 , 0.987  , 0.9863 , 0.986  , 0.984  , 0.9814 ,\n",
       "            0.981  , 0.9805 , 0.98   , 0.9785 , 0.978  , 0.9775 , 0.976  ,\n",
       "            0.9736 , 0.972  , 0.9717 , 0.971  , 0.9707 , 0.97   , 0.9697 ,\n",
       "            0.9683 , 0.968  , 0.965  , 0.964  , 0.9634 , 0.9595 , 0.959  ,\n",
       "            0.958  , 0.957  , 0.956  , 0.9556 , 0.9546 , 0.9536 , 0.953  ,\n",
       "            0.9526 , 0.951  , 0.95   , 0.948  , 0.9473 , 0.946  , 0.945  ,\n",
       "            0.943  , 0.942  , 0.9414 , 0.9404 , 0.9395 , 0.939  , 0.936  ,\n",
       "            0.9355 , 0.934  , 0.931  , 0.9307 , 0.93   , 0.929  , 0.928  ,\n",
       "            0.9277 , 0.927  , 0.926  , 0.9233 , 0.9204 , 0.92   , 0.9185 ,\n",
       "            0.9175 , 0.9126 , 0.912  , 0.9106 , 0.9077 , 0.9062 , 0.906  ,\n",
       "            0.905  , 0.9043 , 0.904  , 0.9014 , 0.9004 , 0.9    , 0.8994 ,\n",
       "            0.898  , 0.897  , 0.8965 , 0.8955 , 0.895  , 0.892  , 0.8906 ,\n",
       "            0.889  , 0.8867 , 0.8857 , 0.8784 , 0.877  , 0.875  , 0.8745 ,\n",
       "            0.8735 , 0.8726 , 0.8696 , 0.8633 , 0.8623 , 0.8594 , 0.854  ,\n",
       "            0.851  , 0.8486 , 0.8477 , 0.844  , 0.8433 , 0.841  , 0.836  ,\n",
       "            0.835  , 0.8296 , 0.8286 , 0.8213 , 0.8164 , 0.815  , 0.813  ,\n",
       "            0.801  , 0.7954 , 0.794  , 0.793  , 0.792  , 0.786  , 0.7695 ,\n",
       "            0.767  , 0.7583 , 0.7397 , 0.7007 , 0.637  , 0.614  , 0.6025 ,\n",
       "            0.5947 , 0.594  , 0.5815 , 0.5796 , 0.559  , 0.5557 , 0.5547 ,\n",
       "            0.515  , 0.482  , 0.467  , 0.4495 , 0.415  , 0.4065 , 0.4026 ,\n",
       "            0.385  , 0.31   , 0.3022 , 0.2998 , 0.2896 , 0.2673 , 0.2637 ,\n",
       "            0.2578 , 0.2554 , 0.2428 , 0.2351 , 0.2205 , 0.2115 , 0.2079 ,\n",
       "            0.2043 , 0.1987 , 0.1835 , 0.1638 , 0.1625 , 0.147  , 0.1385 ,\n",
       "            0.1295 , 0.12054, 0.119  , 0.1142 , 0.1105 , 0.1025 , 0.1019 ,\n",
       "            0.09705, 0.09485, 0.09106, 0.0891 , 0.083  , 0.0827 , 0.0673 ,\n",
       "            0.06573, 0.0643 , 0.06335, 0.05225, 0.04346, 0.03802, 0.037  ,\n",
       "            0.03397, 0.0305 , 0.0248 , 0.0206 , 0.01991], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1875   , 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3203125, 0.3203125, 0.328125 , 0.328125 ,\n",
       "            0.3359375, 0.3359375, 0.3359375, 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.3671875, 0.375    , 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.4140625, 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.03278688, 0.05737705, 0.07377049, 0.10655738,\n",
       "            0.1147541 , 0.13934426, 0.1557377 , 0.17213115, 0.19672132,\n",
       "            0.21311475, 0.23770492, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.3114754 , 0.31967214, 0.33606556,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.47540984, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.52459013, 0.5327869 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59016395, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.75409836, 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.77868855, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9995 , 0.999  , 0.9985 , 0.9976 , 0.997  , 0.9966 ,\n",
       "            0.996  , 0.9956 , 0.995  , 0.9946 , 0.994  , 0.9937 , 0.993  ,\n",
       "            0.9927 , 0.992  , 0.991  , 0.9907 , 0.9897 , 0.9893 , 0.988  ,\n",
       "            0.9863 , 0.986  , 0.9854 , 0.9844 , 0.984  , 0.983  , 0.9824 ,\n",
       "            0.9814 , 0.9795 , 0.979  , 0.9785 , 0.978  , 0.9775 , 0.9766 ,\n",
       "            0.9756 , 0.9727 , 0.969  , 0.9688 , 0.967  , 0.9663 , 0.966  ,\n",
       "            0.9653 , 0.965  , 0.9644 , 0.9634 , 0.9614 , 0.961  , 0.9604 ,\n",
       "            0.9595 , 0.959  , 0.958  , 0.9575 , 0.9565 , 0.9546 , 0.954  ,\n",
       "            0.9536 , 0.953  , 0.9526 , 0.952  , 0.9517 , 0.95   , 0.9497 ,\n",
       "            0.948  , 0.9478 , 0.947  , 0.9453 , 0.945  , 0.944  , 0.9434 ,\n",
       "            0.9424 , 0.941  , 0.939  , 0.9375 , 0.9365 , 0.9346 , 0.9336 ,\n",
       "            0.9316 , 0.93   , 0.9287 , 0.9277 , 0.9263 , 0.926  , 0.9253 ,\n",
       "            0.925  , 0.924  , 0.9233 , 0.922  , 0.92   , 0.919  , 0.9185 ,\n",
       "            0.9175 , 0.9165 , 0.916  , 0.915  , 0.9146 , 0.914  , 0.9136 ,\n",
       "            0.91   , 0.9097 , 0.909  , 0.907  , 0.9062 , 0.901  , 0.8984 ,\n",
       "            0.8975 , 0.897  , 0.8965 , 0.8926 , 0.8916 , 0.8867 , 0.8833 ,\n",
       "            0.883  , 0.8804 , 0.8765 , 0.876  , 0.8745 , 0.8706 , 0.868  ,\n",
       "            0.8643 , 0.863  , 0.861  , 0.858  , 0.8574 , 0.8477 , 0.8467 ,\n",
       "            0.8447 , 0.828  , 0.8276 , 0.825  , 0.8228 , 0.8223 , 0.8213 ,\n",
       "            0.8022 , 0.8013 , 0.7876 , 0.774  , 0.733  , 0.6694 , 0.646  ,\n",
       "            0.641  , 0.633  , 0.632  , 0.626  , 0.6123 , 0.609  , 0.5933 ,\n",
       "            0.593  , 0.586  , 0.549  , 0.5107 , 0.4963 , 0.4783 , 0.4424 ,\n",
       "            0.4321 , 0.43   , 0.4102 , 0.3286 , 0.32   , 0.3171 , 0.309  ,\n",
       "            0.2842 , 0.2786 , 0.2712 , 0.268  , 0.2563 , 0.2482 , 0.2302 ,\n",
       "            0.2227 , 0.2168 , 0.2133 , 0.2076 , 0.1915 , 0.1707 , 0.1694 ,\n",
       "            0.1523 , 0.1436 , 0.1371 , 0.1243 , 0.1236 , 0.1172 , 0.11316,\n",
       "            0.1054 , 0.10504, 0.0993 , 0.09705, 0.09283, 0.09106, 0.08435,\n",
       "            0.08417, 0.0683 , 0.06647, 0.065  , 0.06396, 0.05292, 0.04346,\n",
       "            0.03796, 0.03705, 0.0336 , 0.03044, 0.02443, 0.02014, 0.01945],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.609375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   ,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.1171875, 0.125    , 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.1640625, 0.1640625, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.265625 ,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.3359375, 0.3359375, 0.3359375, 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.40625  , 0.4140625, 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.05737705, 0.07377049, 0.09836066,\n",
       "            0.1147541 , 0.14754099, 0.17213115, 0.19672132, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.28688523, 0.29508197, 0.3114754 ,\n",
       "            0.31967214, 0.33606556, 0.3442623 , 0.3442623 , 0.36065573,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40983605, 0.4180328 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.47540984, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5327869 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.7295082 , 0.7295082 ,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 1.     , 0.9995 , 0.999  , 0.9985 , 0.998  , 0.9976 ,\n",
       "            0.997  , 0.9966 , 0.996  , 0.9956 , 0.995  , 0.9946 , 0.9937 ,\n",
       "            0.993  , 0.9927 , 0.992  , 0.9907 , 0.99   , 0.9893 , 0.989  ,\n",
       "            0.9883 , 0.9873 , 0.987  , 0.9863 , 0.985  , 0.9844 , 0.984  ,\n",
       "            0.9834 , 0.983  , 0.9824 , 0.9814 , 0.9795 , 0.9775 , 0.977  ,\n",
       "            0.975  , 0.9746 , 0.974  , 0.9736 , 0.9727 , 0.972  , 0.971  ,\n",
       "            0.9707 , 0.969  , 0.9688 , 0.9683 , 0.968  , 0.9653 , 0.965  ,\n",
       "            0.9644 , 0.964  , 0.9624 , 0.962  , 0.961  , 0.96   , 0.9585 ,\n",
       "            0.9575 , 0.957  , 0.9565 , 0.956  , 0.953  , 0.9526 , 0.952  ,\n",
       "            0.9507 , 0.9487 , 0.9478 , 0.946  , 0.945  , 0.9443 , 0.9434 ,\n",
       "            0.943  , 0.9424 , 0.942  , 0.9414 , 0.941  , 0.9404 , 0.9395 ,\n",
       "            0.939  , 0.9385 , 0.937  , 0.9365 , 0.935  , 0.9336 , 0.9326 ,\n",
       "            0.932  , 0.9316 , 0.929  , 0.928  , 0.9277 , 0.9272 , 0.926  ,\n",
       "            0.9253 , 0.921  , 0.919  , 0.918  , 0.917  , 0.916  , 0.913  ,\n",
       "            0.9106 , 0.9087 , 0.905  , 0.903  , 0.9014 , 0.8994 , 0.8984 ,\n",
       "            0.8955 , 0.8916 , 0.8906 , 0.8877 , 0.886  , 0.885  , 0.8843 ,\n",
       "            0.878  , 0.877  , 0.8726 , 0.872  , 0.8604 , 0.8555 , 0.855  ,\n",
       "            0.854  , 0.852  , 0.849  , 0.8477 , 0.8345 , 0.834  , 0.8164 ,\n",
       "            0.807  , 0.7646 , 0.701  , 0.6787 , 0.6777 , 0.6704 , 0.669  ,\n",
       "            0.6577 , 0.646  , 0.642  , 0.63   , 0.6274 , 0.6206 , 0.5845 ,\n",
       "            0.5415 , 0.5293 , 0.509  , 0.4731 , 0.4604 , 0.4597 , 0.4373 ,\n",
       "            0.3484 , 0.3394 , 0.3364 , 0.3298 , 0.3025 , 0.2957 , 0.289  ,\n",
       "            0.2852 , 0.2747 , 0.2627 , 0.2424 , 0.2355 , 0.2281 , 0.2239 ,\n",
       "            0.2202 , 0.201  , 0.1787 , 0.1774 , 0.1592 , 0.1497 , 0.1456 ,\n",
       "            0.1309 , 0.1304 , 0.1217 , 0.1174 , 0.1097 , 0.1084 , 0.1025 ,\n",
       "            0.10016, 0.0959 , 0.0937 , 0.0868 , 0.0865 , 0.0698 , 0.06793,\n",
       "            0.06647, 0.06537, 0.0541 , 0.04443, 0.03824, 0.03754, 0.03384,\n",
       "            0.03067, 0.02475, 0.02002, 0.01927], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6171875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.109375 , 0.1171875, 0.140625 , 0.1484375, 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.25     , 0.2578125,\n",
       "            0.265625 , 0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.3359375, 0.3359375, 0.3359375, 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.375    ,\n",
       "            0.3828125, 0.40625  , 0.4140625, 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4296875, 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.03278688, 0.07377049, 0.09836066, 0.12295082,\n",
       "            0.16393442, 0.19672132, 0.23770492, 0.25409836, 0.27868852,\n",
       "            0.28688523, 0.30327868, 0.3114754 , 0.32786885, 0.33606556,\n",
       "            0.33606556, 0.3442623 , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.4180328 , 0.43442622,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5       , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6229508 , 0.63114756, 0.6393443 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.8032787 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 1.     , 0.9995 , 0.999  , 0.9985 , 0.998  , 0.9976 ,\n",
       "            0.997  , 0.9966 , 0.996  , 0.9956 , 0.995  , 0.9946 , 0.994  ,\n",
       "            0.9937 , 0.993  , 0.9927 , 0.9917 , 0.991  , 0.99   , 0.9897 ,\n",
       "            0.9893 , 0.989  , 0.988  , 0.9873 , 0.9863 , 0.986  , 0.985  ,\n",
       "            0.9844 , 0.983  , 0.9824 , 0.9814 , 0.981  , 0.9805 , 0.98   ,\n",
       "            0.9795 , 0.979  , 0.9785 , 0.978  , 0.976  , 0.9756 , 0.973  ,\n",
       "            0.9727 , 0.972  , 0.9717 , 0.971  , 0.9697 , 0.969  , 0.967  ,\n",
       "            0.9663 , 0.966  , 0.9634 , 0.963  , 0.9624 , 0.961  , 0.96   ,\n",
       "            0.9595 , 0.9585 , 0.9575 , 0.9565 , 0.956  , 0.955  , 0.9546 ,\n",
       "            0.954  , 0.9536 , 0.953  , 0.9526 , 0.952  , 0.951  , 0.9497 ,\n",
       "            0.948  , 0.9478 , 0.9463 , 0.9453 , 0.944  , 0.9434 , 0.942  ,\n",
       "            0.9414 , 0.941  , 0.9404 , 0.9395 , 0.936  , 0.935  , 0.933  ,\n",
       "            0.932  , 0.931  , 0.929  , 0.9253 , 0.9233 , 0.9214 , 0.9204 ,\n",
       "            0.9185 , 0.916  , 0.915  , 0.9106 , 0.909  , 0.907  , 0.9053 ,\n",
       "            0.905  , 0.9043 , 0.904  , 0.9014 , 0.9    , 0.8945 , 0.893  ,\n",
       "            0.8853 , 0.882  , 0.877  , 0.8765 , 0.875  , 0.872  , 0.869  ,\n",
       "            0.861  , 0.8594 , 0.8403 , 0.8345 , 0.7944 , 0.7334 , 0.7163 ,\n",
       "            0.7114 , 0.7104 , 0.7095 , 0.6924 , 0.681  , 0.675  , 0.6714 ,\n",
       "            0.665  , 0.656  , 0.6255 , 0.5767 , 0.5664 , 0.545  , 0.5093 ,\n",
       "            0.4958 , 0.4946 , 0.471  , 0.3757 , 0.3657 , 0.3638 , 0.3591 ,\n",
       "            0.3289 , 0.3198 , 0.3118 , 0.308  , 0.297  , 0.2847 , 0.2607 ,\n",
       "            0.2556 , 0.2452 , 0.241  , 0.2382 , 0.2167 , 0.1927 , 0.1913 ,\n",
       "            0.1715 , 0.161  , 0.1606 , 0.1415 , 0.1403 , 0.1302 , 0.1257 ,\n",
       "            0.1186 , 0.11615, 0.1099 , 0.1074 , 0.1025 , 0.10016, 0.0925 ,\n",
       "            0.09235, 0.0745 , 0.0725 , 0.0707 , 0.06964, 0.05792, 0.04724,\n",
       "            0.04053, 0.04   , 0.03574, 0.03265, 0.02606, 0.02109, 0.0203 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6328125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.203125 ,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.25     , 0.265625 , 0.2734375, 0.2734375, 0.28125  ,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.3203125, 0.3359375, 0.3359375, 0.3359375, 0.3359375,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.03278688, 0.07377049, 0.1147541 , 0.1557377 ,\n",
       "            0.19672132, 0.23770492, 0.25409836, 0.28688523, 0.30327868,\n",
       "            0.3114754 , 0.33606556, 0.33606556, 0.3442623 , 0.3442623 ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.39344263, 0.40163934,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5       , 0.5163934 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59016395, 0.59836066, 0.60655737, 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.7295082 , 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.8032787 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 1.     , 0.9995 , 0.999  , 0.9985 , 0.998  , 0.9976 ,\n",
       "            0.997  , 0.9966 , 0.996  , 0.9956 , 0.995  , 0.9946 , 0.994  ,\n",
       "            0.9937 , 0.993  , 0.9927 , 0.9917 , 0.991  , 0.9907 , 0.9897 ,\n",
       "            0.9893 , 0.989  , 0.9883 , 0.9873 , 0.987  , 0.986  , 0.9854 ,\n",
       "            0.985  , 0.9844 , 0.984  , 0.9834 , 0.983  , 0.9824 , 0.982  ,\n",
       "            0.9814 , 0.98   , 0.9795 , 0.979  , 0.9775 , 0.977  , 0.9766 ,\n",
       "            0.976  , 0.9756 , 0.9746 , 0.974  , 0.9717 , 0.971  , 0.9707 ,\n",
       "            0.9688 , 0.9683 , 0.968  , 0.9663 , 0.966  , 0.965  , 0.9644 ,\n",
       "            0.964  , 0.963  , 0.9624 , 0.962  , 0.961  , 0.9604 , 0.9595 ,\n",
       "            0.9585 , 0.9575 , 0.9565 , 0.9556 , 0.955  , 0.9536 , 0.9526 ,\n",
       "            0.951  , 0.9507 , 0.949  , 0.9487 , 0.948  , 0.947  , 0.9443 ,\n",
       "            0.944  , 0.9414 , 0.9404 , 0.9395 , 0.938  , 0.9346 , 0.933  ,\n",
       "            0.9307 , 0.9287 , 0.928  , 0.926  , 0.9253 , 0.9214 , 0.92   ,\n",
       "            0.918  , 0.9165 , 0.9146 , 0.914  , 0.912  , 0.9067 , 0.9053 ,\n",
       "            0.8994 , 0.896  , 0.89   , 0.8887 , 0.888  , 0.8853 , 0.882  ,\n",
       "            0.876  , 0.874  , 0.854  , 0.8506 , 0.813  , 0.7524 , 0.7373 ,\n",
       "            0.7314 , 0.731  , 0.7134 , 0.7026 , 0.6978 , 0.6934 , 0.686  ,\n",
       "            0.679  , 0.6475 , 0.598  , 0.59   , 0.566  , 0.5327 , 0.517  ,\n",
       "            0.516  , 0.4915 , 0.393  , 0.3826 , 0.3804 , 0.376  , 0.3442 ,\n",
       "            0.3357 , 0.3286 , 0.3242 , 0.315  , 0.2976 , 0.273  , 0.2673 ,\n",
       "            0.2566 , 0.2517 , 0.2505 , 0.2264 , 0.201  , 0.2    , 0.1796 ,\n",
       "            0.169  , 0.1683 , 0.1503 , 0.1475 , 0.1361 , 0.1312 , 0.12366,\n",
       "            0.121  , 0.11456, 0.1118 , 0.10724, 0.1043 , 0.0964 , 0.096  ,\n",
       "            0.0774 , 0.0753 , 0.07355, 0.07263, 0.0602 , 0.0494 , 0.04202,\n",
       "            0.04147, 0.0372 , 0.03378, 0.02711, 0.02174, 0.02092],\n",
       "           dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.30508474, 0.30508474,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.38135594, 0.3898305 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.58474576, 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.61864406, 0.62711865, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6864407 , 0.69491524, 0.7033898 , 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.7966102 , 0.7966102 , 0.80508476, 0.8135593 , 0.8305085 ,\n",
       "            0.83898306, 0.8559322 , 0.8559322 , 0.86440676, 0.86440676,\n",
       "            0.86440676, 0.86440676, 0.86440676, 0.87288135, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.9322034 , 0.94067794, 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.08333334, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.12878788, 0.12878788, 0.13636364,\n",
       "            0.13636364, 0.13636364, 0.13636364, 0.14393939, 0.14393939,\n",
       "            0.14393939, 0.15151516, 0.15151516, 0.15151516, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.20454545, 0.21212122, 0.23484848,\n",
       "            0.23484848, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28030303, 0.28787878, 0.29545453, 0.29545453,\n",
       "            0.3030303 , 0.3030303 , 0.31060606, 0.31060606, 0.32575756,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.3409091 , 0.3409091 ,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.36363637, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.3939394 , 0.40151516,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.70454544, 0.7121212 , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4612, 0.4602, 0.4595, 0.4587, 0.4563, 0.456 , 0.4543,\n",
       "            0.452 , 0.4512, 0.4497, 0.4492, 0.449 , 0.447 , 0.4468, 0.4465,\n",
       "            0.4463, 0.446 , 0.4458, 0.445 , 0.4446, 0.4438, 0.4436, 0.443 ,\n",
       "            0.4429, 0.4421, 0.442 , 0.4417, 0.4412, 0.441 , 0.4407, 0.4404,\n",
       "            0.4402, 0.44  , 0.4397, 0.4392, 0.4387, 0.4385, 0.438 , 0.4377,\n",
       "            0.4373, 0.4368, 0.4365, 0.4363, 0.436 , 0.4358, 0.4355, 0.4343,\n",
       "            0.4333, 0.4329, 0.4326, 0.4324, 0.4321, 0.432 , 0.4316, 0.4314,\n",
       "            0.4312, 0.431 , 0.4307, 0.4304, 0.4297, 0.4292, 0.4287, 0.4285,\n",
       "            0.4282, 0.428 , 0.4275, 0.4272, 0.4268, 0.4265, 0.4263, 0.426 ,\n",
       "            0.4258, 0.4255, 0.4253, 0.4248, 0.4246, 0.4243, 0.424 , 0.4238,\n",
       "            0.4236, 0.4233, 0.4226, 0.4224, 0.422 , 0.4216, 0.4214, 0.4211,\n",
       "            0.4207, 0.4204, 0.4202, 0.42  , 0.4194, 0.4192, 0.419 , 0.4187,\n",
       "            0.4185, 0.4182, 0.418 , 0.4177, 0.4172, 0.4165, 0.4163, 0.416 ,\n",
       "            0.4155, 0.4153, 0.4148, 0.4146, 0.414 , 0.413 , 0.4114, 0.4104,\n",
       "            0.4102, 0.41  , 0.4097, 0.4087, 0.4084, 0.4077, 0.4067, 0.4065,\n",
       "            0.406 , 0.4055, 0.405 , 0.4038, 0.4033, 0.4016, 0.4014, 0.401 ,\n",
       "            0.4004, 0.4   , 0.399 , 0.3982, 0.398 , 0.3958, 0.3928, 0.3916,\n",
       "            0.3909, 0.3901, 0.3882, 0.3877, 0.3857, 0.3853, 0.385 , 0.3843,\n",
       "            0.384 , 0.3835, 0.3823, 0.3818, 0.381 , 0.3801, 0.38  , 0.3784,\n",
       "            0.3772, 0.3757, 0.3745, 0.3738, 0.3726, 0.372 , 0.3696, 0.3691,\n",
       "            0.3672, 0.3652, 0.365 , 0.3645, 0.3594, 0.3586, 0.3574, 0.3564,\n",
       "            0.3552, 0.354 , 0.3538, 0.352 , 0.35  , 0.3345], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.47457626, 0.48305085, 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.61864406, 0.61864406, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.69491524, 0.69491524, 0.7118644 , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7711864 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.84745765, 0.86440676,\n",
       "            0.86440676, 0.86440676, 0.8898305 , 0.8898305 , 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06818182, 0.06818182,\n",
       "            0.07575758, 0.09090909, 0.09090909, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12121212, 0.12121212, 0.12878788, 0.12878788, 0.13636364,\n",
       "            0.13636364, 0.13636364, 0.14393939, 0.14393939, 0.15151516,\n",
       "            0.15151516, 0.15151516, 0.15151516, 0.15151516, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18181819, 0.18181819,\n",
       "            0.1969697 , 0.1969697 , 0.20454545, 0.21212122, 0.22727273,\n",
       "            0.22727273, 0.23484848, 0.23484848, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25      , 0.25757575, 0.28030303, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.31060606,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.34848484, 0.3560606 , 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.37121212, 0.37878788, 0.3939394 ,\n",
       "            0.40151516, 0.40151516, 0.4090909 , 0.4090909 , 0.4090909 ,\n",
       "            0.4090909 , 0.4090909 , 0.4090909 , 0.41666666, 0.41666666,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.780303  ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4478, 0.4375, 0.4358, 0.4355, 0.4321, 0.43  , 0.4294,\n",
       "            0.4282, 0.427 , 0.4265, 0.4263, 0.4248, 0.4238, 0.4219, 0.4216,\n",
       "            0.421 , 0.4204, 0.4202, 0.42  , 0.4194, 0.418 , 0.4177, 0.4175,\n",
       "            0.417 , 0.4167, 0.4165, 0.416 , 0.4158, 0.4153, 0.4143, 0.4138,\n",
       "            0.4136, 0.4133, 0.413 , 0.4111, 0.411 , 0.4106, 0.4104, 0.41  ,\n",
       "            0.4094, 0.4092, 0.4084, 0.4082, 0.4075, 0.4072, 0.4065, 0.4062,\n",
       "            0.406 , 0.4055, 0.4053, 0.405 , 0.4048, 0.4045, 0.4038, 0.4033,\n",
       "            0.4019, 0.4016, 0.401 , 0.4006, 0.4001, 0.3992, 0.399 , 0.3984,\n",
       "            0.3977, 0.397 , 0.3965, 0.3962, 0.396 , 0.3958, 0.3955, 0.3953,\n",
       "            0.395 , 0.3943, 0.3933, 0.393 , 0.3926, 0.3923, 0.392 , 0.3918,\n",
       "            0.3916, 0.3914, 0.391 , 0.3909, 0.3906, 0.3904, 0.3896, 0.3884,\n",
       "            0.388 , 0.3877, 0.3865, 0.3862, 0.386 , 0.3857, 0.3853, 0.385 ,\n",
       "            0.3845, 0.384 , 0.3838, 0.3826, 0.382 , 0.381 , 0.3796, 0.3794,\n",
       "            0.3792, 0.3784, 0.3782, 0.378 , 0.3777, 0.3774, 0.377 , 0.3767,\n",
       "            0.3765, 0.3757, 0.3755, 0.3752, 0.375 , 0.3743, 0.374 , 0.3735,\n",
       "            0.3726, 0.3718, 0.3716, 0.3713, 0.371 , 0.3708, 0.3691, 0.3682,\n",
       "            0.3677, 0.3674, 0.3665, 0.366 , 0.3645, 0.3635, 0.3633, 0.362 ,\n",
       "            0.3618, 0.361 , 0.3606, 0.3604, 0.3599, 0.359 , 0.3582, 0.358 ,\n",
       "            0.3564, 0.3555, 0.3552, 0.355 , 0.3547, 0.354 , 0.3533, 0.3525,\n",
       "            0.3496, 0.3481, 0.3462, 0.3457, 0.3452, 0.345 , 0.3418, 0.341 ,\n",
       "            0.3381, 0.3352, 0.3328, 0.3325, 0.3306, 0.3284, 0.3271, 0.327 ,\n",
       "            0.3264, 0.3254, 0.3252, 0.3213, 0.3206, 0.3198, 0.3188, 0.3186,\n",
       "            0.3171, 0.3164, 0.316 , 0.3147, 0.313 , 0.3123, 0.3108, 0.3103,\n",
       "            0.309 , 0.306 , 0.3013, 0.2993, 0.2986, 0.2979, 0.2966, 0.2944,\n",
       "            0.2915, 0.2903, 0.2878, 0.2852, 0.2837, 0.2822, 0.261 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11864407, 0.12711865, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.80508476, 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.83898306, 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.90677965, 0.90677965, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.06060606, 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06818182, 0.06818182, 0.06818182, 0.06818182, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12121212, 0.12121212, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.13636364, 0.13636364, 0.13636364, 0.13636364,\n",
       "            0.14393939, 0.14393939, 0.15151516, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.16666667, 0.17424242, 0.18181819, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28030303, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.31060606, 0.31060606, 0.31060606,\n",
       "            0.31060606, 0.31060606, 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.3560606 , 0.3560606 , 0.3560606 , 0.3560606 , 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.40151516, 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.49242425, 0.5       , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6515151 , 0.65909094, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4338, 0.4136, 0.4128, 0.4126, 0.4119, 0.4102, 0.4094,\n",
       "            0.4053, 0.4038, 0.4033, 0.4023, 0.4016, 0.4014, 0.3975, 0.3972,\n",
       "            0.3965, 0.3948, 0.3936, 0.3933, 0.3926, 0.3916, 0.3914, 0.391 ,\n",
       "            0.39  , 0.3894, 0.3892, 0.3887, 0.386 , 0.3857, 0.3855, 0.3848,\n",
       "            0.384 , 0.3838, 0.3826, 0.382 , 0.3816, 0.3804, 0.3801, 0.38  ,\n",
       "            0.3796, 0.3794, 0.3792, 0.379 , 0.3787, 0.3784, 0.3777, 0.377 ,\n",
       "            0.3767, 0.3762, 0.3755, 0.3743, 0.3735, 0.3733, 0.373 , 0.3728,\n",
       "            0.372 , 0.3718, 0.3716, 0.3713, 0.3706, 0.3704, 0.37  , 0.3696,\n",
       "            0.3694, 0.3687, 0.3684, 0.3677, 0.367 , 0.3662, 0.3655, 0.3652,\n",
       "            0.3645, 0.3643, 0.3616, 0.3606, 0.3596, 0.3594, 0.3586, 0.3582,\n",
       "            0.358 , 0.3572, 0.3564, 0.3562, 0.3555, 0.3552, 0.355 , 0.3545,\n",
       "            0.3535, 0.353 , 0.3528, 0.3525, 0.352 , 0.3513, 0.35  , 0.3499,\n",
       "            0.3496, 0.3494, 0.3489, 0.3484, 0.3477, 0.3474, 0.3467, 0.3464,\n",
       "            0.3457, 0.3455, 0.3452, 0.345 , 0.3447, 0.344 , 0.3435, 0.3433,\n",
       "            0.3428, 0.3423, 0.3408, 0.34  , 0.3376, 0.3374, 0.336 , 0.3352,\n",
       "            0.3347, 0.3345, 0.3342, 0.3333, 0.3328, 0.3325, 0.3315, 0.3308,\n",
       "            0.3306, 0.3298, 0.3296, 0.329 , 0.3286, 0.327 , 0.3262, 0.3257,\n",
       "            0.3252, 0.325 , 0.324 , 0.321 , 0.3206, 0.32  , 0.3198, 0.3193,\n",
       "            0.3186, 0.3176, 0.317 , 0.3162, 0.3157, 0.315 , 0.3142, 0.3132,\n",
       "            0.3115, 0.3113, 0.309 , 0.3086, 0.3083, 0.3079, 0.3042, 0.303 ,\n",
       "            0.3025, 0.302 , 0.3015, 0.3   , 0.2983, 0.2954, 0.2932, 0.2905,\n",
       "            0.2888, 0.2886, 0.288 , 0.2844, 0.2825, 0.282 , 0.2817, 0.281 ,\n",
       "            0.2808, 0.2805, 0.2788, 0.2778, 0.2776, 0.2742, 0.2725, 0.2717,\n",
       "            0.271 , 0.27  , 0.2698, 0.2683, 0.268 , 0.2673, 0.2664, 0.266 ,\n",
       "            0.2646, 0.2612, 0.261 , 0.2507, 0.2505, 0.2493, 0.2482, 0.2478,\n",
       "            0.247 , 0.2433, 0.2418, 0.239 , 0.2358, 0.2344, 0.2339, 0.2106],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.13559322, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.21186441, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.33898306, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.38135594, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.58474576, 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7118644 , 0.720339  , 0.720339  ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7627119 , 0.7627119 , 0.7711864 ,\n",
       "            0.7881356 , 0.7966102 , 0.7966102 , 0.7966102 , 0.7966102 ,\n",
       "            0.80508476, 0.80508476, 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8220339 , 0.8220339 , 0.8305085 , 0.83898306, 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.84745765, 0.8559322 , 0.8559322 ,\n",
       "            0.86440676, 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.89830506, 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.94067794, 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06818182, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.13636364, 0.13636364,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.16666667, 0.17424242, 0.17424242, 0.17424242, 0.18181819,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.1969697 , 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.24242425,\n",
       "            0.24242425, 0.25      , 0.2651515 , 0.27272728, 0.27272728,\n",
       "            0.28030303, 0.28030303, 0.28787878, 0.28787878, 0.28787878,\n",
       "            0.28787878, 0.29545453, 0.29545453, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.31060606, 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.3560606 , 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.49242425, 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.419 , 0.398 , 0.3965, 0.3923, 0.389 , 0.3867, 0.3835,\n",
       "            0.382 , 0.3813, 0.3796, 0.3777, 0.3748, 0.3743, 0.3726, 0.37  ,\n",
       "            0.3699, 0.3694, 0.3684, 0.3672, 0.3662, 0.365 , 0.364 , 0.3635,\n",
       "            0.3623, 0.3616, 0.3606, 0.36  , 0.3594, 0.3586, 0.358 , 0.3567,\n",
       "            0.3564, 0.355 , 0.3547, 0.3542, 0.354 , 0.353 , 0.3523, 0.3518,\n",
       "            0.3516, 0.3499, 0.349 , 0.3489, 0.3486, 0.3481, 0.348 , 0.3477,\n",
       "            0.3472, 0.347 , 0.3467, 0.3462, 0.3457, 0.345 , 0.3445, 0.3442,\n",
       "            0.343 , 0.341 , 0.3408, 0.3403, 0.3398, 0.3396, 0.3386, 0.338 ,\n",
       "            0.3376, 0.3354, 0.335 , 0.3342, 0.3337, 0.3333, 0.3313, 0.3306,\n",
       "            0.3293, 0.327 , 0.325 , 0.3237, 0.3235, 0.3228, 0.3225, 0.3223,\n",
       "            0.322 , 0.3215, 0.3203, 0.32  , 0.3198, 0.3196, 0.319 , 0.3188,\n",
       "            0.3186, 0.3184, 0.318 , 0.3176, 0.3167, 0.3162, 0.3154, 0.315 ,\n",
       "            0.3142, 0.3137, 0.3135, 0.3123, 0.312 , 0.3118, 0.3115, 0.3113,\n",
       "            0.311 , 0.3108, 0.3103, 0.3093, 0.3083, 0.308 , 0.3071, 0.307 ,\n",
       "            0.3057, 0.3054, 0.3052, 0.304 , 0.3015, 0.301 , 0.2996, 0.2983,\n",
       "            0.298 , 0.297 , 0.2966, 0.2964, 0.2947, 0.2944, 0.294 , 0.2937,\n",
       "            0.2935, 0.2917, 0.2913, 0.2908, 0.29  , 0.2893, 0.2886, 0.2878,\n",
       "            0.2876, 0.287 , 0.2869, 0.2866, 0.2856, 0.2852, 0.285 , 0.2847,\n",
       "            0.284 , 0.2834, 0.2832, 0.2825, 0.282 , 0.2815, 0.2812, 0.2798,\n",
       "            0.2764, 0.2761, 0.276 , 0.2756, 0.2747, 0.2744, 0.2737, 0.2727,\n",
       "            0.2725, 0.2715, 0.2703, 0.268 , 0.2673, 0.267 , 0.2654, 0.2646,\n",
       "            0.2625, 0.2593, 0.2588, 0.2563, 0.2559, 0.255 , 0.2542, 0.2527,\n",
       "            0.2502, 0.2496, 0.2463, 0.2451, 0.2445, 0.244 , 0.243 , 0.2428,\n",
       "            0.2422, 0.2394, 0.2388, 0.2384, 0.2378, 0.236 , 0.2347, 0.2338,\n",
       "            0.233 , 0.2316, 0.2306, 0.2301, 0.2286, 0.2281, 0.228 , 0.2273,\n",
       "            0.2242, 0.2211, 0.2115, 0.2114, 0.2109, 0.209 , 0.2086, 0.2084,\n",
       "            0.2051, 0.2037, 0.2012, 0.1976, 0.1967, 0.1964, 0.1731],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.1779661 , 0.18644068,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.62711865, 0.63559324,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.779661  , 0.7966102 ,\n",
       "            0.80508476, 0.80508476, 0.80508476, 0.80508476, 0.80508476,\n",
       "            0.8220339 , 0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.86440676,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.88135594, 0.88135594,\n",
       "            0.88135594, 0.88135594, 0.8898305 , 0.89830506, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.94067794, 0.94067794, 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06060606, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.13636364, 0.13636364,\n",
       "            0.14393939, 0.14393939, 0.15151516, 0.1590909 , 0.1590909 ,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.17424242, 0.17424242,\n",
       "            0.17424242, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.28787878, 0.29545453, 0.29545453,\n",
       "            0.29545453, 0.29545453, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.32575756, 0.3409091 , 0.3409091 ,\n",
       "            0.34848484, 0.34848484, 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.3560606 , 0.37121212, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.40151516, 0.4090909 , 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.5151515 , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.72727275, 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4023, 0.3809, 0.3801, 0.3743, 0.3638, 0.3628, 0.3623,\n",
       "            0.3594, 0.3574, 0.357 , 0.3525, 0.3523, 0.3518, 0.3508, 0.3503,\n",
       "            0.3496, 0.347 , 0.3457, 0.3455, 0.3442, 0.3438, 0.3433, 0.3413,\n",
       "            0.3394, 0.3384, 0.3381, 0.3364, 0.3357, 0.3354, 0.3347, 0.3306,\n",
       "            0.3296, 0.3293, 0.3289, 0.3286, 0.328 , 0.3271, 0.3264, 0.3262,\n",
       "            0.3237, 0.3223, 0.3218, 0.3213, 0.321 , 0.3208, 0.3206, 0.32  ,\n",
       "            0.3193, 0.3176, 0.3171, 0.3167, 0.3162, 0.3157, 0.3154, 0.3127,\n",
       "            0.3125, 0.312 , 0.3113, 0.311 , 0.31  , 0.308 , 0.3076, 0.3074,\n",
       "            0.3062, 0.3057, 0.3054, 0.305 , 0.3044, 0.3037, 0.3013, 0.3005,\n",
       "            0.2996, 0.299 , 0.2988, 0.2952, 0.2944, 0.2937, 0.2925, 0.2908,\n",
       "            0.2905, 0.2896, 0.2883, 0.288 , 0.2874, 0.287 , 0.2864, 0.286 ,\n",
       "            0.2852, 0.2837, 0.2834, 0.2832, 0.283 , 0.2822, 0.2815, 0.2812,\n",
       "            0.281 , 0.2805, 0.2803, 0.2795, 0.2788, 0.2786, 0.2778, 0.2754,\n",
       "            0.2751, 0.2747, 0.2742, 0.2732, 0.2727, 0.2722, 0.272 , 0.2712,\n",
       "            0.2708, 0.27  , 0.2686, 0.268 , 0.2673, 0.2668, 0.2664, 0.2656,\n",
       "            0.2654, 0.2646, 0.2632, 0.262 , 0.2605, 0.2603, 0.259 , 0.2585,\n",
       "            0.2583, 0.258 , 0.256 , 0.2551, 0.2544, 0.2542, 0.2527, 0.2524,\n",
       "            0.252 , 0.2507, 0.2502, 0.25  , 0.2494, 0.249 , 0.2487, 0.2478,\n",
       "            0.2474, 0.247 , 0.2438, 0.2437, 0.2429, 0.2418, 0.2417, 0.2394,\n",
       "            0.2379, 0.237 , 0.2363, 0.236 , 0.2358, 0.2356, 0.2355, 0.2347,\n",
       "            0.2338, 0.2328, 0.2316, 0.2303, 0.2281, 0.2269, 0.226 , 0.2252,\n",
       "            0.2249, 0.2244, 0.2233, 0.2207, 0.219 , 0.2185, 0.2172, 0.2148,\n",
       "            0.2144, 0.2137, 0.2134, 0.2133, 0.2115, 0.2113, 0.2104, 0.21  ,\n",
       "            0.2068, 0.206 , 0.2047, 0.2037, 0.2032, 0.2028, 0.1991, 0.1985,\n",
       "            0.1981, 0.1976, 0.1971, 0.1968, 0.1965, 0.1962, 0.1959, 0.1946,\n",
       "            0.1886, 0.1815, 0.1803, 0.1785, 0.1783, 0.1771, 0.1759, 0.1744,\n",
       "            0.1731, 0.1704, 0.1672, 0.1664, 0.1444], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.41525424, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.59322035, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.69491524, 0.69491524, 0.7033898 , 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.8135593 , 0.8135593 , 0.8135593 , 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.83898306, 0.83898306, 0.83898306, 0.8559322 ,\n",
       "            0.8559322 , 0.86440676, 0.86440676, 0.87288135, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.8898305 , 0.8898305 , 0.8898305 ,\n",
       "            0.89830506, 0.89830506, 0.90677965, 0.90677965, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9237288 , 0.9237288 , 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.01515152, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.06818182, 0.07575758, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.09848485, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.12121212, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.13636364, 0.13636364, 0.14393939, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.1590909 , 0.17424242, 0.18181819,\n",
       "            0.18181819, 0.18181819, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.1969697 , 0.20454545, 0.21969697, 0.21969697, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.2651515 , 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.29545453, 0.29545453,\n",
       "            0.3030303 , 0.3030303 , 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.34848484, 0.3560606 , 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.37878788, 0.38636363, 0.38636363,\n",
       "            0.38636363, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.4090909 , 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.4318182 , 0.4469697 , 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3845 , 0.3628 , 0.3623 , 0.3547 , 0.3418 , 0.3416 ,\n",
       "            0.3389 , 0.335  , 0.333  , 0.332  , 0.3298 , 0.3289 , 0.3281 ,\n",
       "            0.328  , 0.3247 , 0.3245 , 0.3237 , 0.3225 , 0.322  , 0.3218 ,\n",
       "            0.3215 , 0.3206 , 0.32   , 0.317  , 0.3157 , 0.3154 , 0.315  ,\n",
       "            0.3145 , 0.3118 , 0.3115 , 0.3108 , 0.3105 , 0.3103 , 0.3093 ,\n",
       "            0.3054 , 0.3047 , 0.3042 , 0.3027 , 0.302  , 0.3013 , 0.3008 ,\n",
       "            0.3005 , 0.2983 , 0.2976 , 0.297  , 0.2964 , 0.2961 , 0.296  ,\n",
       "            0.2954 , 0.294  , 0.2937 , 0.2922 , 0.292  , 0.2917 , 0.2913 ,\n",
       "            0.2908 , 0.2869 , 0.2864 , 0.2861 , 0.2854 , 0.2852 , 0.2844 ,\n",
       "            0.2834 , 0.2812 , 0.28   , 0.2788 , 0.278  , 0.2773 , 0.2764 ,\n",
       "            0.276  , 0.2756 , 0.275  , 0.2747 , 0.2737 , 0.273  , 0.272  ,\n",
       "            0.2695 , 0.2683 , 0.2676 , 0.267  , 0.2634 , 0.263  , 0.2627 ,\n",
       "            0.262  , 0.2612 , 0.2588 , 0.2583 , 0.2576 , 0.2573 , 0.2566 ,\n",
       "            0.256  , 0.2556 , 0.2551 , 0.2542 , 0.2537 , 0.253  , 0.2522 ,\n",
       "            0.251  , 0.25   , 0.2493 , 0.2487 , 0.2485 , 0.248  , 0.2477 ,\n",
       "            0.2474 , 0.2462 , 0.2438 , 0.2422 , 0.2406 , 0.2405 , 0.2395 ,\n",
       "            0.2386 , 0.2384 , 0.2383 , 0.2382 , 0.2378 , 0.2366 , 0.2362 ,\n",
       "            0.236  , 0.2356 , 0.2355 , 0.2339 , 0.2338 , 0.2335 , 0.2334 ,\n",
       "            0.2323 , 0.2318 , 0.2311 , 0.2302 , 0.2301 , 0.2292 , 0.2285 ,\n",
       "            0.2278 , 0.2273 , 0.2249 , 0.2247 , 0.2242 , 0.2238 , 0.2229 ,\n",
       "            0.2227 , 0.2224 , 0.2208 , 0.2207 , 0.22   , 0.2194 , 0.2189 ,\n",
       "            0.2179 , 0.2175 , 0.2167 , 0.2163 , 0.2162 , 0.2157 , 0.2156 ,\n",
       "            0.2152 , 0.215  , 0.2147 , 0.2144 , 0.2133 , 0.2113 , 0.2109 ,\n",
       "            0.2104 , 0.209  , 0.2085 , 0.2065 , 0.2042 , 0.2029 , 0.2028 ,\n",
       "            0.2024 , 0.202  , 0.2017 , 0.2009 , 0.1998 , 0.1996 , 0.1991 ,\n",
       "            0.1978 , 0.1971 , 0.1952 , 0.1937 , 0.1929 , 0.1925 , 0.1924 ,\n",
       "            0.1917 , 0.1907 , 0.1906 , 0.19   , 0.1898 , 0.1876 , 0.1871 ,\n",
       "            0.1866 , 0.185  , 0.183  , 0.1823 , 0.1815 , 0.1814 , 0.1807 ,\n",
       "            0.1805 , 0.1803 , 0.1799 , 0.1787 , 0.178  , 0.1755 , 0.1754 ,\n",
       "            0.1747 , 0.1741 , 0.174  , 0.173  , 0.1726 , 0.1724 , 0.1683 ,\n",
       "            0.1653 , 0.1636 , 0.16   , 0.1581 , 0.1567 , 0.1556 , 0.1548 ,\n",
       "            0.1531 , 0.153  , 0.1517 , 0.1489 , 0.1459 , 0.1455 , 0.1454 ,\n",
       "            0.12463], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.21186441, 0.23728813,\n",
       "            0.2457627 , 0.26271185, 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.34745762, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.37288135, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7033898 , 0.7033898 ,\n",
       "            0.7118644 , 0.7118644 , 0.7118644 , 0.7118644 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7288136 , 0.7288136 , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.779661  , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.7966102 , 0.7966102 , 0.7966102 ,\n",
       "            0.80508476, 0.80508476, 0.8220339 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.8305085 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.8559322 , 0.8559322 , 0.8559322 , 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.87288135, 0.88135594, 0.88135594,\n",
       "            0.8898305 , 0.8898305 , 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.91525424, 0.9237288 ,\n",
       "            0.9237288 , 0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.06818182, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.12121212, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.13636364, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.15151516, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.1969697 , 0.1969697 , 0.1969697 , 0.1969697 ,\n",
       "            0.1969697 , 0.20454545, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.34848484, 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.37878788, 0.38636363, 0.38636363,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.7651515 , 0.7651515 ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3665, 0.3452, 0.345 , 0.3367, 0.3267, 0.3245, 0.32  ,\n",
       "            0.3188, 0.3164, 0.315 , 0.3145, 0.313 , 0.31  , 0.3098, 0.3096,\n",
       "            0.3086, 0.308 , 0.3074, 0.3064, 0.3052, 0.305 , 0.3037, 0.3032,\n",
       "            0.302 , 0.2976, 0.2969, 0.2966, 0.2957, 0.2925, 0.292 , 0.2908,\n",
       "            0.2888, 0.288 , 0.2874, 0.287 , 0.2869, 0.286 , 0.2856, 0.285 ,\n",
       "            0.2837, 0.2793, 0.279 , 0.2788, 0.2786, 0.278 , 0.277 , 0.2769,\n",
       "            0.2766, 0.275 , 0.2742, 0.2727, 0.2698, 0.2695, 0.2688, 0.2686,\n",
       "            0.268 , 0.2676, 0.2651, 0.2622, 0.2612, 0.259 , 0.2583, 0.2576,\n",
       "            0.2573, 0.256 , 0.2559, 0.2556, 0.2544, 0.2542, 0.254 , 0.251 ,\n",
       "            0.2505, 0.2477, 0.2471, 0.2467, 0.2463, 0.2458, 0.2456, 0.2455,\n",
       "            0.2426, 0.2421, 0.2418, 0.2406, 0.2402, 0.2388, 0.2382, 0.2379,\n",
       "            0.2374, 0.2368, 0.2367, 0.2346, 0.2344, 0.2327, 0.2323, 0.2316,\n",
       "            0.2313, 0.2307, 0.2302, 0.2299, 0.2297, 0.2292, 0.2286, 0.2281,\n",
       "            0.2278, 0.2277, 0.2274, 0.2273, 0.2261, 0.2257, 0.2255, 0.2238,\n",
       "            0.2234, 0.2224, 0.2216, 0.2213, 0.2212, 0.2203, 0.2202, 0.2198,\n",
       "            0.2189, 0.2184, 0.218 , 0.2179, 0.2177, 0.2173, 0.2161, 0.2158,\n",
       "            0.2156, 0.215 , 0.2145, 0.2144, 0.213 , 0.2129, 0.2123, 0.2119,\n",
       "            0.2109, 0.2108, 0.2101, 0.2096, 0.2089, 0.2085, 0.2076, 0.2065,\n",
       "            0.2063, 0.206 , 0.2056, 0.2053, 0.205 , 0.2047, 0.2045, 0.2042,\n",
       "            0.2028, 0.2023, 0.202 , 0.2018, 0.2004, 0.2001, 0.2   , 0.1993,\n",
       "            0.1984, 0.1982, 0.1974, 0.1973, 0.1971, 0.1959, 0.1948, 0.1942,\n",
       "            0.1941, 0.194 , 0.1936, 0.1935, 0.1925, 0.1918, 0.1907, 0.189 ,\n",
       "            0.1887, 0.1879, 0.1873, 0.1866, 0.1865, 0.1863, 0.186 , 0.1859,\n",
       "            0.1841, 0.1827, 0.1819, 0.1814, 0.1813, 0.181 , 0.1803, 0.18  ,\n",
       "            0.1799, 0.1794, 0.1785, 0.1782, 0.1781, 0.1774, 0.1731, 0.1707,\n",
       "            0.17  , 0.1677, 0.1653, 0.1649, 0.1648, 0.1636, 0.1621, 0.1616,\n",
       "            0.161 , 0.16  , 0.1594, 0.1573, 0.1543, 0.1542, 0.1539, 0.1527,\n",
       "            0.1506, 0.1343], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.37288135, 0.38135594, 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.5       , 0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 , 0.5508475 ,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.66101694, 0.6694915 , 0.6694915 , 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7118644 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.7118644 , 0.7118644 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.720339  , 0.720339  ,\n",
       "            0.720339  , 0.720339  , 0.720339  , 0.720339  , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.80508476, 0.80508476, 0.80508476, 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8220339 , 0.8305085 , 0.8305085 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.84745765, 0.84745765,\n",
       "            0.84745765, 0.84745765, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.86440676, 0.86440676, 0.87288135, 0.88135594, 0.88135594,\n",
       "            0.8898305 , 0.8898305 , 0.8898305 , 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9237288 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.06818182, 0.07575758, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09090909, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.13636364, 0.13636364, 0.13636364, 0.13636364,\n",
       "            0.14393939, 0.14393939, 0.14393939, 0.15151516, 0.15151516,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.22727273, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.59090906, 0.6060606 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.79545456,\n",
       "            0.79545456, 0.79545456, 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3489, 0.3289, 0.3281, 0.3203, 0.314 , 0.3096, 0.309 ,\n",
       "            0.3042, 0.3032, 0.3013, 0.301 , 0.3008, 0.2996, 0.2986, 0.2969,\n",
       "            0.2954, 0.295 , 0.2947, 0.2937, 0.2905, 0.289 , 0.2883, 0.2864,\n",
       "            0.286 , 0.2854, 0.285 , 0.2837, 0.2825, 0.2805, 0.2803, 0.28  ,\n",
       "            0.2795, 0.2788, 0.2786, 0.277 , 0.2744, 0.2727, 0.2725, 0.272 ,\n",
       "            0.2717, 0.271 , 0.2698, 0.2686, 0.2678, 0.2666, 0.2664, 0.2646,\n",
       "            0.2644, 0.2637, 0.2627, 0.2615, 0.2605, 0.259 , 0.258 , 0.2573,\n",
       "            0.2556, 0.2542, 0.2527, 0.2522, 0.2512, 0.2498, 0.2494, 0.2478,\n",
       "            0.2477, 0.2473, 0.2467, 0.2458, 0.2445, 0.2438, 0.2437, 0.2428,\n",
       "            0.2422, 0.2402, 0.2395, 0.239 , 0.2388, 0.2383, 0.2375, 0.237 ,\n",
       "            0.2366, 0.2363, 0.236 , 0.235 , 0.2347, 0.2346, 0.2344, 0.2338,\n",
       "            0.2306, 0.2303, 0.2302, 0.2295, 0.2294, 0.229 , 0.2286, 0.2274,\n",
       "            0.2266, 0.2257, 0.2246, 0.2242, 0.2235, 0.223 , 0.2224, 0.2222,\n",
       "            0.222 , 0.2211, 0.2207, 0.2205, 0.2198, 0.2197, 0.2191, 0.219 ,\n",
       "            0.2189, 0.2185, 0.2177, 0.2173, 0.2168, 0.2166, 0.215 , 0.2148,\n",
       "            0.2144, 0.2137, 0.2133, 0.2129, 0.2125, 0.2123, 0.212 , 0.2118,\n",
       "            0.2114, 0.2108, 0.2104, 0.2101, 0.21  , 0.2098, 0.2096, 0.2095,\n",
       "            0.2091, 0.2085, 0.2079, 0.2076, 0.2074, 0.2073, 0.207 , 0.2065,\n",
       "            0.2063, 0.2056, 0.2054, 0.2053, 0.2039, 0.2035, 0.2032, 0.2031,\n",
       "            0.2024, 0.2021, 0.202 , 0.2009, 0.2007, 0.2004, 0.2001, 0.1998,\n",
       "            0.1996, 0.1993, 0.1991, 0.199 , 0.1989, 0.1987, 0.1985, 0.1984,\n",
       "            0.1979, 0.1976, 0.1974, 0.1967, 0.1965, 0.1958, 0.1954, 0.195 ,\n",
       "            0.1943, 0.1942, 0.1934, 0.1929, 0.1913, 0.1909, 0.1907, 0.19  ,\n",
       "            0.1892, 0.1887, 0.1885, 0.1859, 0.1858, 0.1846, 0.183 , 0.1827,\n",
       "            0.1826, 0.1823, 0.1819, 0.1816, 0.1805, 0.1791, 0.179 , 0.1788,\n",
       "            0.1776, 0.1771, 0.1766, 0.1764, 0.1759, 0.1758, 0.1757, 0.1753,\n",
       "            0.1733, 0.1707, 0.1687, 0.1664, 0.1663, 0.1578, 0.1567, 0.1562,\n",
       "            0.1449, 0.1427], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.21186441, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.43220338, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.59322035, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6694915 , 0.6694915 , 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.720339  ,\n",
       "            0.720339  , 0.720339  , 0.7288136 , 0.7288136 , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8220339 , 0.8305085 , 0.8305085 ,\n",
       "            0.83898306, 0.83898306, 0.86440676, 0.87288135, 0.89830506,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9915254 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.06818182, 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.14393939, 0.15151516, 0.15151516, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.18939394,\n",
       "            0.18939394, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.42424244, 0.42424244, 0.4318182 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.57575756, 0.5833333 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.7121212 , 0.719697  , 0.7348485 ,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.82575756, 0.8333333 , 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.334 , 0.3137, 0.3127, 0.305 , 0.3035, 0.3013, 0.2974,\n",
       "            0.297 , 0.2966, 0.2961, 0.2947, 0.2944, 0.2925, 0.2922, 0.2917,\n",
       "            0.2915, 0.2913, 0.289 , 0.2852, 0.2832, 0.282 , 0.2817, 0.2805,\n",
       "            0.279 , 0.2786, 0.2776, 0.277 , 0.2769, 0.2764, 0.2737, 0.2725,\n",
       "            0.2712, 0.271 , 0.2708, 0.2693, 0.2627, 0.2622, 0.2615, 0.2612,\n",
       "            0.26  , 0.2573, 0.257 , 0.2563, 0.256 , 0.2551, 0.255 , 0.2534,\n",
       "            0.2532, 0.2524, 0.2512, 0.251 , 0.2505, 0.25  , 0.2494, 0.2485,\n",
       "            0.2473, 0.2471, 0.2467, 0.2466, 0.2462, 0.2458, 0.2456, 0.2449,\n",
       "            0.2445, 0.2444, 0.2437, 0.2428, 0.2426, 0.2415, 0.2411, 0.241 ,\n",
       "            0.2407, 0.2406, 0.2401, 0.2394, 0.239 , 0.2386, 0.2378, 0.2372,\n",
       "            0.2363, 0.236 , 0.2358, 0.2355, 0.2346, 0.2344, 0.2338, 0.2332,\n",
       "            0.2328, 0.2325, 0.2323, 0.2318, 0.2314, 0.2313, 0.2311, 0.2306,\n",
       "            0.2302, 0.2301, 0.2295, 0.2294, 0.2292, 0.2281, 0.228 , 0.2278,\n",
       "            0.2274, 0.2273, 0.2272, 0.2266, 0.2264, 0.2263, 0.2261, 0.2244,\n",
       "            0.2239, 0.2234, 0.2233, 0.2229, 0.2225, 0.2224, 0.2218, 0.2217,\n",
       "            0.2216, 0.2211, 0.2208, 0.2202, 0.22  , 0.2179, 0.2175, 0.2173,\n",
       "            0.2172, 0.217 , 0.2168, 0.2167, 0.2161, 0.2158, 0.2152, 0.2142,\n",
       "            0.214 , 0.2135, 0.2123, 0.2119, 0.2113, 0.2109, 0.2101, 0.21  ,\n",
       "            0.2096, 0.2091, 0.2086, 0.2085, 0.2084, 0.208 , 0.2075, 0.2064,\n",
       "            0.2054, 0.2053, 0.2051, 0.2037, 0.2023, 0.2021, 0.2018, 0.2017,\n",
       "            0.2013, 0.2004, 0.2001, 0.2   , 0.1989, 0.1985, 0.1982, 0.1976,\n",
       "            0.1965, 0.1953, 0.1948, 0.1946, 0.1937, 0.1927, 0.1923, 0.1912,\n",
       "            0.1904, 0.189 , 0.1887, 0.1882, 0.1848, 0.1836, 0.1833, 0.183 ,\n",
       "            0.1819, 0.1814, 0.1804, 0.1803, 0.1796, 0.177 , 0.1763, 0.1758,\n",
       "            0.1752, 0.1719, 0.1716, 0.1692, 0.164 , 0.1587, 0.1573, 0.1486,\n",
       "            0.1342], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.2457627 , 0.2457627 ,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.2881356 , 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.2881356 , 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.37288135, 0.38135594, 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5508475 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7118644 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8135593 , 0.8135593 ,\n",
       "            0.8135593 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.8559322 , 0.87288135, 0.88135594, 0.88135594, 0.88135594,\n",
       "            0.88135594, 0.8898305 , 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.9237288 , 0.9237288 , 0.9237288 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.94067794, 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.04545455,\n",
       "            0.06060606, 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.15151516,\n",
       "            0.16666667, 0.18939394, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25757575, 0.2651515 ,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.3181818 , 0.3409091 , 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.40151516, 0.4090909 ,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6136364 , 0.6136364 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.75      , 0.75      , 0.75757575, 0.75757575,\n",
       "            0.75757575, 0.7651515 , 0.7651515 , 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3242, 0.3005, 0.3   , 0.2998, 0.2983, 0.298 , 0.2974,\n",
       "            0.295 , 0.2944, 0.2935, 0.2927, 0.2925, 0.2913, 0.2903, 0.29  ,\n",
       "            0.2874, 0.2869, 0.2864, 0.2847, 0.2844, 0.2837, 0.283 , 0.281 ,\n",
       "            0.28  , 0.2778, 0.2766, 0.2754, 0.2751, 0.2742, 0.274 , 0.2737,\n",
       "            0.2734, 0.2732, 0.2727, 0.2725, 0.2722, 0.272 , 0.2717, 0.2712,\n",
       "            0.271 , 0.2708, 0.2703, 0.27  , 0.2695, 0.2693, 0.2688, 0.2683,\n",
       "            0.268 , 0.2678, 0.2673, 0.267 , 0.2668, 0.2664, 0.266 , 0.2659,\n",
       "            0.2656, 0.2654, 0.2646, 0.2642, 0.264 , 0.2637, 0.2632, 0.263 ,\n",
       "            0.2627, 0.2625, 0.2622, 0.262 , 0.2605, 0.26  , 0.2595, 0.2588,\n",
       "            0.2573, 0.2563, 0.256 , 0.2551, 0.2544, 0.254 , 0.252 , 0.2515,\n",
       "            0.251 , 0.2507, 0.2502, 0.25  , 0.2498, 0.2496, 0.2493, 0.2489,\n",
       "            0.2487, 0.2478, 0.2474, 0.2473, 0.247 , 0.2463, 0.2462, 0.2456,\n",
       "            0.2452, 0.2433, 0.2426, 0.2417, 0.2397, 0.2394, 0.2391, 0.2386,\n",
       "            0.2383, 0.2382, 0.2379, 0.2368, 0.2355, 0.2343, 0.2339, 0.2334,\n",
       "            0.2323, 0.2322, 0.2319, 0.2311, 0.2306, 0.2302, 0.2301, 0.2297,\n",
       "            0.2281, 0.2278, 0.2277, 0.2274, 0.2272, 0.226 , 0.2257, 0.2251,\n",
       "            0.2239, 0.2234, 0.223 , 0.2229, 0.2224, 0.2222, 0.2218, 0.2208,\n",
       "            0.2205, 0.2203, 0.22  , 0.2197, 0.2191, 0.2189, 0.2177, 0.2168,\n",
       "            0.2167, 0.2161, 0.215 , 0.2148, 0.213 , 0.2129, 0.2128, 0.2125,\n",
       "            0.2124, 0.2123, 0.212 , 0.2106, 0.2101, 0.21  , 0.2098, 0.2086,\n",
       "            0.208 , 0.2076, 0.2073, 0.207 , 0.2069, 0.2068, 0.2056, 0.2047,\n",
       "            0.2043, 0.2028, 0.2012, 0.2004, 0.2001, 0.2   , 0.1995, 0.1987,\n",
       "            0.1985, 0.1968, 0.1967, 0.1962, 0.1958, 0.1953, 0.1952, 0.1948,\n",
       "            0.1943, 0.1942, 0.1934, 0.1927, 0.1912, 0.1907, 0.1904, 0.189 ,\n",
       "            0.1886, 0.1871, 0.1863, 0.1857, 0.1855, 0.1837, 0.1803, 0.173 ,\n",
       "            0.1699, 0.1698, 0.1647, 0.1608, 0.1277], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.2881356 , 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.40677965,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.4915254 , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.7033898 , 0.720339  , 0.720339  ,\n",
       "            0.720339  , 0.720339  , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.779661  , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8135593 , 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.83898306, 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.88135594, 0.8898305 , 0.8898305 ,\n",
       "            0.89830506, 0.89830506, 0.89830506, 0.89830506, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03787879, 0.04545455,\n",
       "            0.06060606, 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.11363637, 0.12121212, 0.15151516, 0.1590909 , 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.27272728,\n",
       "            0.28030303, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.4318182 , 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.47727272, 0.47727272, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.47727272, 0.47727272, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.74242425, 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3247 , 0.3245 , 0.3242 , 0.324  , 0.3237 , 0.3235 ,\n",
       "            0.3203 , 0.3196 , 0.319  , 0.3188 , 0.3179 , 0.3176 , 0.3174 ,\n",
       "            0.3171 , 0.3162 , 0.316  , 0.3157 , 0.3154 , 0.3152 , 0.315  ,\n",
       "            0.3147 , 0.3145 , 0.314  , 0.3137 , 0.3135 , 0.3108 , 0.31   ,\n",
       "            0.3086 , 0.3083 , 0.3074 , 0.306  , 0.3047 , 0.304  , 0.3037 ,\n",
       "            0.3035 , 0.3032 , 0.302  , 0.3018 , 0.3005 , 0.3003 , 0.2998 ,\n",
       "            0.2996 , 0.298  , 0.2969 , 0.2966 , 0.2957 , 0.2954 , 0.2942 ,\n",
       "            0.2922 , 0.292  , 0.2915 , 0.2913 , 0.2905 , 0.2903 , 0.2898 ,\n",
       "            0.2896 , 0.2893 , 0.288  , 0.2874 , 0.2864 , 0.2852 , 0.285  ,\n",
       "            0.2847 , 0.2837 , 0.2827 , 0.2825 , 0.2817 , 0.2815 , 0.2786 ,\n",
       "            0.2776 , 0.2751 , 0.2742 , 0.2737 , 0.2732 , 0.2727 , 0.27   ,\n",
       "            0.2698 , 0.269  , 0.2673 , 0.2646 , 0.2622 , 0.262  , 0.2595 ,\n",
       "            0.258  , 0.2576 , 0.2573 , 0.2568 , 0.256  , 0.254  , 0.2534 ,\n",
       "            0.2532 , 0.2527 , 0.2522 , 0.252  , 0.2517 , 0.25   , 0.2496 ,\n",
       "            0.2494 , 0.248  , 0.2478 , 0.2477 , 0.2474 , 0.246  , 0.2452 ,\n",
       "            0.2437 , 0.2434 , 0.243  , 0.2426 , 0.2422 , 0.2418 , 0.2415 ,\n",
       "            0.2411 , 0.2406 , 0.2402 , 0.2401 , 0.2395 , 0.2391 , 0.2382 ,\n",
       "            0.2372 , 0.2363 , 0.2362 , 0.236  , 0.2352 , 0.2344 , 0.234  ,\n",
       "            0.2334 , 0.233  , 0.2328 , 0.2325 , 0.2319 , 0.2314 , 0.231  ,\n",
       "            0.2307 , 0.2299 , 0.2285 , 0.2281 , 0.228  , 0.2278 , 0.2268 ,\n",
       "            0.2266 , 0.226  , 0.2256 , 0.2251 , 0.2249 , 0.2242 , 0.2238 ,\n",
       "            0.2234 , 0.223  , 0.2227 , 0.222  , 0.2208 , 0.2203 , 0.2198 ,\n",
       "            0.2197 , 0.2184 , 0.2177 , 0.2175 , 0.2173 , 0.2168 , 0.2166 ,\n",
       "            0.2162 , 0.2153 , 0.215  , 0.2148 , 0.2142 , 0.2133 , 0.2125 ,\n",
       "            0.2119 , 0.2118 , 0.2115 , 0.2114 , 0.211  , 0.2109 , 0.2104 ,\n",
       "            0.2091 , 0.209  , 0.2089 , 0.208  , 0.2075 , 0.2064 , 0.2051 ,\n",
       "            0.2045 , 0.2034 , 0.2032 , 0.2026 , 0.2018 , 0.2013 , 0.2004 ,\n",
       "            0.1993 , 0.199  , 0.1989 , 0.1984 , 0.1981 , 0.1978 , 0.1967 ,\n",
       "            0.1935 , 0.1901 , 0.1885 , 0.1869 , 0.1842 , 0.1821 , 0.177  ,\n",
       "            0.1735 , 0.1476 , 0.12146], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.38135594,\n",
       "            0.3983051 , 0.3983051 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5423729 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.63559324, 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6694915 , 0.6779661 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.80508476, 0.80508476, 0.8135593 ,\n",
       "            0.8135593 , 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.9237288 ,\n",
       "            0.9237288 , 0.94067794, 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.59090906, 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6060606 , 0.6060606 , 0.6212121 ,\n",
       "            0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.6818182 , 0.6818182 , 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.72727275, 0.74242425,\n",
       "            0.75      , 0.75      , 0.75      , 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3994, 0.3892, 0.3884, 0.3875, 0.387 , 0.3855, 0.385 ,\n",
       "            0.3826, 0.3813, 0.3806, 0.38  , 0.3772, 0.376 , 0.373 , 0.3713,\n",
       "            0.3704, 0.3699, 0.3696, 0.3684, 0.3667, 0.3662, 0.366 , 0.3655,\n",
       "            0.3652, 0.364 , 0.3618, 0.361 , 0.3606, 0.3596, 0.359 , 0.3577,\n",
       "            0.357 , 0.3564, 0.3562, 0.356 , 0.3535, 0.3496, 0.349 , 0.345 ,\n",
       "            0.3438, 0.3435, 0.343 , 0.3403, 0.3389, 0.3384, 0.3354, 0.3337,\n",
       "            0.333 , 0.3323, 0.3318, 0.328 , 0.327 , 0.3267, 0.3235, 0.3203,\n",
       "            0.3162, 0.3105, 0.31  , 0.3093, 0.309 , 0.308 , 0.304 , 0.3035,\n",
       "            0.301 , 0.2988, 0.2986, 0.2976, 0.2961, 0.294 , 0.2937, 0.2932,\n",
       "            0.2908, 0.2903, 0.2898, 0.2896, 0.2886, 0.2878, 0.2864, 0.285 ,\n",
       "            0.2847, 0.283 , 0.2815, 0.2808, 0.2805, 0.2795, 0.2783, 0.2769,\n",
       "            0.2756, 0.2754, 0.275 , 0.2742, 0.2737, 0.2722, 0.272 , 0.2712,\n",
       "            0.2705, 0.2693, 0.2683, 0.2673, 0.2651, 0.2646, 0.2612, 0.2607,\n",
       "            0.2603, 0.2598, 0.259 , 0.2563, 0.256 , 0.2542, 0.2537, 0.2522,\n",
       "            0.252 , 0.2517, 0.2515, 0.2512, 0.251 , 0.2494, 0.249 , 0.2485,\n",
       "            0.2482, 0.2477, 0.2473, 0.2471, 0.247 , 0.2467, 0.246 , 0.2458,\n",
       "            0.2456, 0.2452, 0.2451, 0.2438, 0.2422, 0.2418, 0.2407, 0.2397,\n",
       "            0.237 , 0.2363, 0.236 , 0.2356, 0.2351, 0.235 , 0.2347, 0.2339,\n",
       "            0.2338, 0.2335, 0.2332, 0.233 , 0.2327, 0.2325, 0.2323, 0.2318,\n",
       "            0.2316, 0.2313, 0.231 , 0.2301, 0.2299, 0.2297, 0.2294, 0.2292,\n",
       "            0.229 , 0.2289, 0.2286, 0.2285, 0.2281, 0.2277, 0.2273, 0.2268,\n",
       "            0.2264, 0.2249, 0.2244, 0.2235, 0.2233, 0.2225, 0.2218, 0.2208,\n",
       "            0.2207, 0.2198, 0.2197, 0.218 , 0.2179, 0.2177, 0.2173, 0.2168,\n",
       "            0.2166, 0.2142, 0.2133, 0.2124, 0.212 , 0.2118, 0.2115, 0.2113,\n",
       "            0.2096, 0.2095, 0.2094, 0.208 , 0.2079, 0.2063, 0.206 , 0.2045,\n",
       "            0.2042, 0.204 , 0.2039, 0.2023, 0.2021, 0.202 , 0.2018, 0.2006,\n",
       "            0.186 , 0.1826, 0.1622, 0.1371, 0.1172], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.3644068 ,\n",
       "            0.3644068 , 0.3644068 , 0.37288135, 0.38135594, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.40677965, 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6864407 ,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.88135594, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25757575, 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.4469697 , 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4822 , 0.4607 , 0.4604 , 0.4592 , 0.4568 , 0.4546 ,\n",
       "            0.4534 , 0.448  , 0.4478 , 0.4465 , 0.4458 , 0.4434 , 0.4353 ,\n",
       "            0.4294 , 0.4287 , 0.4282 , 0.426  , 0.4258 , 0.4255 , 0.4243 ,\n",
       "            0.4226 , 0.4204 , 0.42   , 0.4187 , 0.418  , 0.4163 , 0.416  ,\n",
       "            0.4124 , 0.412  , 0.4094 , 0.4077 , 0.4043 , 0.403  , 0.4028 ,\n",
       "            0.3923 , 0.3916 , 0.3914 , 0.3894 , 0.3887 , 0.3865 , 0.3813 ,\n",
       "            0.3787 , 0.3772 , 0.3767 , 0.3726 , 0.3691 , 0.3672 , 0.3665 ,\n",
       "            0.3662 , 0.3652 , 0.3564 , 0.353  , 0.347  , 0.3455 , 0.3442 ,\n",
       "            0.3257 , 0.3223 , 0.3213 , 0.3184 , 0.3176 , 0.3171 , 0.3167 ,\n",
       "            0.3115 , 0.311  , 0.3105 , 0.308  , 0.3076 , 0.3071 , 0.306  ,\n",
       "            0.3057 , 0.3027 , 0.3018 , 0.3013 , 0.3008 , 0.3    , 0.2988 ,\n",
       "            0.2983 , 0.2979 , 0.2976 , 0.2957 , 0.2952 , 0.2915 , 0.2913 ,\n",
       "            0.2903 , 0.2898 , 0.2869 , 0.286  , 0.2854 , 0.2844 , 0.2832 ,\n",
       "            0.281  , 0.2805 , 0.2798 , 0.2795 , 0.2783 , 0.2773 , 0.2769 ,\n",
       "            0.2764 , 0.2747 , 0.2744 , 0.2742 , 0.2722 , 0.2717 , 0.2715 ,\n",
       "            0.2712 , 0.2708 , 0.27   , 0.269  , 0.268  , 0.2676 , 0.2673 ,\n",
       "            0.267  , 0.2668 , 0.2666 , 0.2664 , 0.2659 , 0.2654 , 0.265  ,\n",
       "            0.2644 , 0.2637 , 0.2612 , 0.261  , 0.2605 , 0.26   , 0.2588 ,\n",
       "            0.2585 , 0.2576 , 0.2573 , 0.257  , 0.2568 , 0.256  , 0.2559 ,\n",
       "            0.2556 , 0.2554 , 0.2542 , 0.2537 , 0.2534 , 0.2532 , 0.2527 ,\n",
       "            0.252  , 0.251  , 0.2505 , 0.2496 , 0.2494 , 0.2489 , 0.2477 ,\n",
       "            0.2466 , 0.246  , 0.2451 , 0.2445 , 0.2441 , 0.244  , 0.2438 ,\n",
       "            0.2437 , 0.2433 , 0.243  , 0.2429 , 0.2428 , 0.2418 , 0.2417 ,\n",
       "            0.2415 , 0.2413 , 0.2411 , 0.2407 , 0.2402 , 0.2397 , 0.2395 ,\n",
       "            0.2384 , 0.2383 , 0.2382 , 0.2378 , 0.2375 , 0.2374 , 0.2372 ,\n",
       "            0.2367 , 0.2362 , 0.2356 , 0.2347 , 0.2339 , 0.2338 , 0.2335 ,\n",
       "            0.2332 , 0.2328 , 0.2325 , 0.2323 , 0.2322 , 0.2316 , 0.2297 ,\n",
       "            0.2292 , 0.2285 , 0.2278 , 0.2277 , 0.2272 , 0.2261 , 0.226  ,\n",
       "            0.2257 , 0.2255 , 0.2249 , 0.2244 , 0.223  , 0.2229 , 0.2225 ,\n",
       "            0.222  , 0.2217 , 0.2213 , 0.219  , 0.2186 , 0.2173 , 0.2167 ,\n",
       "            0.2161 , 0.2158 , 0.2147 , 0.2059 , 0.2047 , 0.2026 , 0.1981 ,\n",
       "            0.1954 , 0.1936 , 0.1907 , 0.1765 , 0.15   , 0.1254 , 0.11066],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.10606061, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.04237288, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3559322 , 0.37288135, 0.37288135, 0.38135594, 0.38135594,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.3983051 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.5677966 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6694915 , 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.720339  , 0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.7966102 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8220339 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.23484848, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.4848485 , 0.4848485 ,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.67424244, 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.7348485 , 0.7348485 , 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.74242425, 0.75      , 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.8030303 , 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8560606 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5684, 0.536 , 0.5347, 0.5303, 0.526 , 0.524 , 0.519 ,\n",
       "            0.5186, 0.5166, 0.5156, 0.5146, 0.51  , 0.5015, 0.4915, 0.4912,\n",
       "            0.4902, 0.488 , 0.4856, 0.4854, 0.4849, 0.4844, 0.4775, 0.4768,\n",
       "            0.475 , 0.474 , 0.4734, 0.4717, 0.467 , 0.4656, 0.462 , 0.4604,\n",
       "            0.4592, 0.455 , 0.454 , 0.453 , 0.4443, 0.4377, 0.4373, 0.4358,\n",
       "            0.435 , 0.4302, 0.43  , 0.421 , 0.416 , 0.415 , 0.4143, 0.4067,\n",
       "            0.4038, 0.4001, 0.3997, 0.3862, 0.3833, 0.3794, 0.3762, 0.3738,\n",
       "            0.3552, 0.3474, 0.3372, 0.3364, 0.3345, 0.3333, 0.333 , 0.3325,\n",
       "            0.3276, 0.324 , 0.323 , 0.3218, 0.321 , 0.317 , 0.3154, 0.3147,\n",
       "            0.3132, 0.313 , 0.3125, 0.311 , 0.31  , 0.3071, 0.306 , 0.3042,\n",
       "            0.3018, 0.2993, 0.2988, 0.298 , 0.2969, 0.295 , 0.2944, 0.2932,\n",
       "            0.292 , 0.2913, 0.2905, 0.289 , 0.2886, 0.288 , 0.2874, 0.2864,\n",
       "            0.286 , 0.2854, 0.285 , 0.2847, 0.2844, 0.2837, 0.2834, 0.2832,\n",
       "            0.2822, 0.2817, 0.2808, 0.2805, 0.2803, 0.28  , 0.278 , 0.2776,\n",
       "            0.2773, 0.277 , 0.2766, 0.2734, 0.2732, 0.2727, 0.2725, 0.2717,\n",
       "            0.2715, 0.2712, 0.271 , 0.2708, 0.27  , 0.269 , 0.2683, 0.2678,\n",
       "            0.2668, 0.2666, 0.2664, 0.2654, 0.2646, 0.2644, 0.264 , 0.2637,\n",
       "            0.2632, 0.263 , 0.2625, 0.2617, 0.2607, 0.2605, 0.2603, 0.2595,\n",
       "            0.2593, 0.259 , 0.258 , 0.257 , 0.2568, 0.2559, 0.255 , 0.2542,\n",
       "            0.2532, 0.253 , 0.2527, 0.2524, 0.252 , 0.2515, 0.251 , 0.2507,\n",
       "            0.2505, 0.2502, 0.2496, 0.2489, 0.2483, 0.248 , 0.2467, 0.2463,\n",
       "            0.2462, 0.2458, 0.2455, 0.2452, 0.2445, 0.244 , 0.2434, 0.2428,\n",
       "            0.2424, 0.2422, 0.2417, 0.2413, 0.2394, 0.2374, 0.2372, 0.2366,\n",
       "            0.2358, 0.2339, 0.2338, 0.2332, 0.2318, 0.2303, 0.2299, 0.2277,\n",
       "            0.2268, 0.2252, 0.2249, 0.2246, 0.2218, 0.219 , 0.2173, 0.2158,\n",
       "            0.2144, 0.2139, 0.2125, 0.2073, 0.2029, 0.1993, 0.1906, 0.1897,\n",
       "            0.188 , 0.178 , 0.1752, 0.1693, 0.1372, 0.1134, 0.1036],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.29545453, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.26271185, 0.26271185, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.34745762, 0.3559322 , 0.3644068 , 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.48305085, 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.60169494, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.65254235, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.779661  , 0.779661  ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.87288135, 0.88135594, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.15151516, 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.21212122,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.653  , 0.612  , 0.611  , 0.6045 , 0.5986 , 0.596  ,\n",
       "            0.5913 , 0.591  , 0.588  , 0.5864 , 0.586  , 0.579  , 0.5684 ,\n",
       "            0.556  , 0.5557 , 0.5537 , 0.5522 , 0.549  , 0.5483 , 0.5474 ,\n",
       "            0.5386 , 0.5366 , 0.5356 , 0.5337 , 0.5327 , 0.525  , 0.524  ,\n",
       "            0.5225 , 0.5176 , 0.5166 , 0.515  , 0.51   , 0.509  , 0.5063 ,\n",
       "            0.4985 , 0.4888 , 0.4883 , 0.4849 , 0.484  , 0.4812 , 0.4768 ,\n",
       "            0.4663 , 0.4614 , 0.459  , 0.4587 , 0.4575 , 0.45   , 0.4434 ,\n",
       "            0.4407 , 0.437  , 0.4214 , 0.4167 , 0.4165 , 0.4094 , 0.4058 ,\n",
       "            0.3926 , 0.3743 , 0.3643 , 0.3608 , 0.36   , 0.3574 , 0.3567 ,\n",
       "            0.3562 , 0.3503 , 0.3484 , 0.3457 , 0.345  , 0.3425 , 0.3396 ,\n",
       "            0.3315 , 0.3308 , 0.3306 , 0.3289 , 0.3264 , 0.3245 , 0.321  ,\n",
       "            0.3206 , 0.3203 , 0.318  , 0.3171 , 0.3152 , 0.3135 , 0.313  ,\n",
       "            0.3118 , 0.3083 , 0.3042 , 0.3032 , 0.3018 , 0.3015 , 0.3013 ,\n",
       "            0.3003 , 0.2998 , 0.2983 , 0.2976 , 0.2969 , 0.2966 , 0.2961 ,\n",
       "            0.2944 , 0.2935 , 0.2932 , 0.293  , 0.2925 , 0.292  , 0.2917 ,\n",
       "            0.2915 , 0.2903 , 0.2893 , 0.2888 , 0.288  , 0.2874 , 0.287  ,\n",
       "            0.2869 , 0.2856 , 0.2854 , 0.2852 , 0.2837 , 0.282  , 0.281  ,\n",
       "            0.2795 , 0.2793 , 0.2788 , 0.2786 , 0.278  , 0.2778 , 0.277  ,\n",
       "            0.2764 , 0.2751 , 0.2744 , 0.2725 , 0.2722 , 0.272  , 0.2708 ,\n",
       "            0.27   , 0.2695 , 0.269  , 0.2686 , 0.268  , 0.2676 , 0.2673 ,\n",
       "            0.2666 , 0.2664 , 0.2659 , 0.2644 , 0.2642 , 0.264  , 0.2637 ,\n",
       "            0.2625 , 0.2617 , 0.2612 , 0.2607 , 0.2605 , 0.26   , 0.2595 ,\n",
       "            0.259  , 0.2588 , 0.258  , 0.2578 , 0.2566 , 0.256  , 0.2559 ,\n",
       "            0.2556 , 0.255  , 0.2546 , 0.2542 , 0.2534 , 0.2532 , 0.2524 ,\n",
       "            0.2522 , 0.252  , 0.25   , 0.2493 , 0.2489 , 0.2485 , 0.2483 ,\n",
       "            0.2474 , 0.2471 , 0.247  , 0.2467 , 0.2466 , 0.2463 , 0.2451 ,\n",
       "            0.244  , 0.2429 , 0.2405 , 0.2395 , 0.2391 , 0.236  , 0.2328 ,\n",
       "            0.2323 , 0.2318 , 0.2313 , 0.229  , 0.2281 , 0.2218 , 0.2167 ,\n",
       "            0.2124 , 0.2109 , 0.2084 , 0.2042 , 0.202  , 0.1953 , 0.191  ,\n",
       "            0.1855 , 0.1831 , 0.1758 , 0.1646 , 0.1641 , 0.1605 , 0.1268 ,\n",
       "            0.10394, 0.0991 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.37121212, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.22881356, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.31355932, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.37288135, 0.3898305 , 0.3898305 ,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.4661017 , 0.47457626, 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.55932206, 0.5762712 , 0.5762712 , 0.59322035,\n",
       "            0.59322035, 0.59322035, 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.69491524,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.7288136 , 0.7288136 ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.5984849 , 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.8333333 , 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7246 , 0.6787 , 0.6777 , 0.67   , 0.6636 , 0.6606 ,\n",
       "            0.6567 , 0.6553 , 0.6514 , 0.651  , 0.649  , 0.6406 , 0.63   ,\n",
       "            0.6143 , 0.6113 , 0.611  , 0.6074 , 0.606  , 0.6055 , 0.6045 ,\n",
       "            0.5933 , 0.5923 , 0.5913 , 0.5903 , 0.59   , 0.5884 , 0.579  ,\n",
       "            0.5786 , 0.5757 , 0.5693 , 0.569  , 0.5664 , 0.562  , 0.5586 ,\n",
       "            0.556  , 0.551  , 0.538  , 0.5376 , 0.5312 , 0.5303 , 0.529  ,\n",
       "            0.5215 , 0.5103 , 0.5083 , 0.502  , 0.4998 , 0.497  , 0.4924 ,\n",
       "            0.4814 , 0.4775 , 0.472  , 0.4543 , 0.4536 , 0.449  , 0.4421 ,\n",
       "            0.4348 , 0.4338 , 0.3977 , 0.3928 , 0.3916 , 0.39   , 0.3884 ,\n",
       "            0.3865 , 0.3845 , 0.3801 , 0.3782 , 0.3704 , 0.37   , 0.3647 ,\n",
       "            0.3625 , 0.3567 , 0.3555 , 0.3464 , 0.3457 , 0.3455 , 0.3384 ,\n",
       "            0.338  , 0.3367 , 0.3357 , 0.3354 , 0.3345 , 0.3342 , 0.3323 ,\n",
       "            0.332  , 0.3306 , 0.3293 , 0.3289 , 0.3281 , 0.328  , 0.3247 ,\n",
       "            0.3228 , 0.3223 , 0.3215 , 0.32   , 0.319  , 0.3186 , 0.3174 ,\n",
       "            0.3171 , 0.3145 , 0.314  , 0.3125 , 0.311  , 0.3105 , 0.3098 ,\n",
       "            0.3093 , 0.307  , 0.3064 , 0.3062 , 0.3052 , 0.3047 , 0.304  ,\n",
       "            0.3022 , 0.3008 , 0.298  , 0.2976 , 0.2969 , 0.2961 , 0.296  ,\n",
       "            0.2944 , 0.2935 , 0.2927 , 0.2925 , 0.292  , 0.2917 , 0.2915 ,\n",
       "            0.2908 , 0.2903 , 0.29   , 0.2898 , 0.2896 , 0.289  , 0.2886 ,\n",
       "            0.2883 , 0.2878 , 0.287  , 0.2864 , 0.2861 , 0.285  , 0.2842 ,\n",
       "            0.284  , 0.2827 , 0.2825 , 0.2822 , 0.282  , 0.281  , 0.2805 ,\n",
       "            0.28   , 0.2795 , 0.2788 , 0.2776 , 0.2773 , 0.277  , 0.2769 ,\n",
       "            0.2766 , 0.276  , 0.2751 , 0.2744 , 0.2742 , 0.274  , 0.2737 ,\n",
       "            0.2734 , 0.2725 , 0.2722 , 0.2717 , 0.2715 , 0.2698 , 0.269  ,\n",
       "            0.268  , 0.2678 , 0.2673 , 0.2664 , 0.266  , 0.2659 , 0.2644 ,\n",
       "            0.2642 , 0.264  , 0.2632 , 0.263  , 0.2627 , 0.26   , 0.2578 ,\n",
       "            0.257  , 0.2566 , 0.256  , 0.2544 , 0.2542 , 0.2517 , 0.2515 ,\n",
       "            0.2512 , 0.249  , 0.248  , 0.2471 , 0.2466 , 0.2462 , 0.246  ,\n",
       "            0.2452 , 0.2417 , 0.2415 , 0.239  , 0.2384 , 0.2216 , 0.2133 ,\n",
       "            0.2101 , 0.2048 , 0.2039 , 0.2032 , 0.2006 , 0.1952 , 0.1948 ,\n",
       "            0.1942 , 0.1887 , 0.1794 , 0.1782 , 0.1759 , 0.1627 , 0.1572 ,\n",
       "            0.1509 , 0.1471 , 0.1158 , 0.0937 , 0.09235], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.4090909, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.19491525, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.2457627 , 0.2457627 ,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.37288135, 0.37288135,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5508475 , 0.5508475 , 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.720339  , 0.720339  , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.56060606, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 , 0.6136364 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.7878788 , 0.7878788 , 0.79545456,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7866 , 0.7397 , 0.739  , 0.7383 , 0.7305 , 0.7227 ,\n",
       "            0.7197 , 0.717  , 0.715  , 0.711  , 0.7095 , 0.7075 , 0.6987 ,\n",
       "            0.687  , 0.67   , 0.669  , 0.666  , 0.6655 , 0.662  , 0.661  ,\n",
       "            0.66   , 0.6597 , 0.647  , 0.646  , 0.6445 , 0.644  , 0.642  ,\n",
       "            0.6416 , 0.6323 , 0.6313 , 0.6274 , 0.62   , 0.6177 , 0.613  ,\n",
       "            0.6084 , 0.6055 , 0.601  , 0.586  , 0.5796 , 0.576  , 0.574  ,\n",
       "            0.566  , 0.5537 , 0.545  , 0.541  , 0.5376 , 0.534  , 0.52   ,\n",
       "            0.5156 , 0.508  , 0.491  , 0.4868 , 0.4817 , 0.475  , 0.4712 ,\n",
       "            0.4648 , 0.4214 , 0.42   , 0.4194 , 0.4192 , 0.418  , 0.4172 ,\n",
       "            0.4119 , 0.4065 , 0.4036 , 0.399  , 0.3975 , 0.386  , 0.3809 ,\n",
       "            0.377  , 0.3733 , 0.3708 , 0.3684 , 0.3635 , 0.3604 , 0.3599 ,\n",
       "            0.3591 , 0.3557 , 0.3555 , 0.355  , 0.3538 , 0.3477 , 0.3457 ,\n",
       "            0.345  , 0.343  , 0.3425 , 0.3396 , 0.3376 , 0.337  , 0.3357 ,\n",
       "            0.3345 , 0.334  , 0.3333 , 0.3328 , 0.3298 , 0.3293 , 0.3284 ,\n",
       "            0.3274 , 0.326  , 0.3254 , 0.3245 , 0.323  , 0.3228 , 0.321  ,\n",
       "            0.3186 , 0.3145 , 0.3142 , 0.3137 , 0.3125 , 0.312  , 0.3103 ,\n",
       "            0.31   , 0.3096 , 0.309  , 0.3083 , 0.3064 , 0.3047 , 0.3037 ,\n",
       "            0.3032 , 0.3022 , 0.302  , 0.3018 , 0.301  , 0.3    , 0.2998 ,\n",
       "            0.299  , 0.2986 , 0.2974 , 0.2969 , 0.2966 , 0.2957 , 0.2947 ,\n",
       "            0.2935 , 0.2932 , 0.293  , 0.2927 , 0.2925 , 0.2922 , 0.2917 ,\n",
       "            0.2905 , 0.2898 , 0.2893 , 0.2888 , 0.2886 , 0.2874 , 0.287  ,\n",
       "            0.2864 , 0.2844 , 0.2842 , 0.2832 , 0.283  , 0.282  , 0.2817 ,\n",
       "            0.2805 , 0.2803 , 0.28   , 0.2793 , 0.279  , 0.2788 , 0.2786 ,\n",
       "            0.2783 , 0.2776 , 0.277  , 0.2756 , 0.2751 , 0.275  , 0.2742 ,\n",
       "            0.274  , 0.2732 , 0.272  , 0.2715 , 0.2712 , 0.271  , 0.2708 ,\n",
       "            0.27   , 0.2688 , 0.2659 , 0.2654 , 0.2642 , 0.2637 , 0.2625 ,\n",
       "            0.2622 , 0.262  , 0.2612 , 0.259  , 0.2578 , 0.2576 , 0.2559 ,\n",
       "            0.2551 , 0.2546 , 0.2537 , 0.2534 , 0.2458 , 0.2452 , 0.2422 ,\n",
       "            0.2401 , 0.2379 , 0.2358 , 0.235  , 0.215  , 0.2051 , 0.2037 ,\n",
       "            0.1973 , 0.1967 , 0.1959 , 0.1925 , 0.1877 , 0.1865 , 0.1852 ,\n",
       "            0.1823 , 0.171  , 0.1688 , 0.1687 , 0.1511 , 0.1499 , 0.1393 ,\n",
       "            0.1354 , 0.1056 , 0.0857 , 0.08417], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.4469697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.37288135, 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.4661017 , 0.48305085, 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.59322035, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.63559324, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.720339  , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46212122, 0.46969697, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.5984849 ,\n",
       "            0.6060606 , 0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6287879 , 0.6287879 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.68939394, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.81060606, 0.8181818 , 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.84090906, 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8712121 ,\n",
       "            0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.9015151 , 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.838  , 0.792  , 0.791  , 0.7905 , 0.783  , 0.775  ,\n",
       "            0.772  , 0.7715 , 0.7686 , 0.7656 , 0.7607 , 0.76   , 0.7505 ,\n",
       "            0.7407 , 0.722  , 0.7207 , 0.718  , 0.716  , 0.715  , 0.714  ,\n",
       "            0.7104 , 0.709  , 0.7085 , 0.6987 , 0.697  , 0.6953 , 0.694  ,\n",
       "            0.6934 , 0.6904 , 0.6846 , 0.6807 , 0.677  , 0.669  , 0.668  ,\n",
       "            0.665  , 0.6626 , 0.655  , 0.653  , 0.6523 , 0.635  , 0.6294 ,\n",
       "            0.6196 , 0.6167 , 0.61   , 0.6016 , 0.598  , 0.589  , 0.5815 ,\n",
       "            0.578  , 0.5767 , 0.559  , 0.5503 , 0.5435 , 0.5317 , 0.5186 ,\n",
       "            0.5176 , 0.515  , 0.51   , 0.4932 , 0.4658 , 0.458  , 0.4553 ,\n",
       "            0.455  , 0.4524 , 0.4429 , 0.442  , 0.4414 , 0.4348 , 0.4214 ,\n",
       "            0.4165 , 0.4148 , 0.4116 , 0.406  , 0.3987 , 0.3977 , 0.396  ,\n",
       "            0.3926 , 0.391  , 0.3909 , 0.39   , 0.3877 , 0.3853 , 0.384  ,\n",
       "            0.3801 , 0.378  , 0.3718 , 0.3716 , 0.369  , 0.3657 , 0.363  ,\n",
       "            0.36   , 0.3591 , 0.3584 , 0.358  , 0.356  , 0.3538 , 0.3525 ,\n",
       "            0.35   , 0.3486 , 0.3484 , 0.3442 , 0.3428 , 0.3425 , 0.342  ,\n",
       "            0.3416 , 0.3406 , 0.34   , 0.3389 , 0.3364 , 0.335  , 0.3325 ,\n",
       "            0.3318 , 0.3315 , 0.3289 , 0.3284 , 0.3281 , 0.326  , 0.3252 ,\n",
       "            0.3247 , 0.324  , 0.3228 , 0.3218 , 0.3215 , 0.3213 , 0.3198 ,\n",
       "            0.3179 , 0.3174 , 0.3171 , 0.316  , 0.3154 , 0.315  , 0.3145 ,\n",
       "            0.3127 , 0.3125 , 0.3123 , 0.3115 , 0.3113 , 0.3108 , 0.3096 ,\n",
       "            0.3083 , 0.3062 , 0.3054 , 0.3052 , 0.305  , 0.3047 , 0.3042 ,\n",
       "            0.304  , 0.3035 , 0.3032 , 0.3022 , 0.302  , 0.3018 , 0.3005 ,\n",
       "            0.2993 , 0.299  , 0.2988 , 0.2986 , 0.2974 , 0.297  , 0.2966 ,\n",
       "            0.2964 , 0.2954 , 0.295  , 0.2925 , 0.2915 , 0.2913 , 0.291  ,\n",
       "            0.2908 , 0.2905 , 0.2903 , 0.2898 , 0.2893 , 0.289  , 0.288  ,\n",
       "            0.2876 , 0.2874 , 0.2861 , 0.286  , 0.2852 , 0.2844 , 0.283  ,\n",
       "            0.282  , 0.2803 , 0.2795 , 0.277  , 0.2769 , 0.2766 , 0.276  ,\n",
       "            0.2754 , 0.274  , 0.2725 , 0.2686 , 0.2683 , 0.267  , 0.2607 ,\n",
       "            0.256  , 0.254  , 0.2418 , 0.2402 , 0.2384 , 0.2358 , 0.234  ,\n",
       "            0.2299 , 0.2283 , 0.2074 , 0.1967 , 0.1958 , 0.1887 , 0.188  ,\n",
       "            0.1871 , 0.1833 , 0.1787 , 0.1766 , 0.1754 , 0.1736 , 0.1616 ,\n",
       "            0.1593 , 0.1581 , 0.1403 , 0.1393 , 0.1277 , 0.1236 , 0.0945 ,\n",
       "            0.0772 , 0.07385], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.46969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.58474576, 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.6101695 , 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7118644 , 0.720339  ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.7121212 , 0.7121212 , 0.7121212 ,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8794 , 0.838  , 0.837  , 0.836  , 0.829  , 0.822  ,\n",
       "            0.8193 , 0.819  , 0.816  , 0.8135 , 0.807  , 0.7974 , 0.7886 ,\n",
       "            0.7705 , 0.768  , 0.766  , 0.763  , 0.7627 , 0.7617 , 0.757  ,\n",
       "            0.756  , 0.7554 , 0.7476 , 0.744  , 0.743  , 0.7417 , 0.741  ,\n",
       "            0.738  , 0.733  , 0.728  , 0.724  , 0.7163 , 0.715  , 0.7114 ,\n",
       "            0.7104 , 0.7017 , 0.7007 , 0.6987 , 0.682  , 0.6816 , 0.6777 ,\n",
       "            0.6636 , 0.66   , 0.654  , 0.6484 , 0.642  , 0.633  , 0.6235 ,\n",
       "            0.6216 , 0.617  , 0.599  , 0.589  , 0.5806 , 0.5728 , 0.564  ,\n",
       "            0.5522 , 0.5503 , 0.546  , 0.525  , 0.512  , 0.5005 , 0.4973 ,\n",
       "            0.4934 , 0.4907 , 0.4858 , 0.4763 , 0.4727 , 0.4712 , 0.4688 ,\n",
       "            0.4636 , 0.455  , 0.4517 , 0.4456 , 0.4407 , 0.4385 , 0.4382 ,\n",
       "            0.436  , 0.4324 , 0.431  , 0.429  , 0.4272 , 0.4263 , 0.4211 ,\n",
       "            0.4143 , 0.412  , 0.4065 , 0.401  , 0.3997 , 0.3962 , 0.3933 ,\n",
       "            0.3894 , 0.389  , 0.3884 , 0.3877 , 0.3865 , 0.3816 , 0.3792 ,\n",
       "            0.3748 , 0.3696 , 0.3657 , 0.3655 , 0.3645 , 0.3608 , 0.3604 ,\n",
       "            0.3594 , 0.3586 , 0.3584 , 0.3582 , 0.3577 , 0.356  , 0.355  ,\n",
       "            0.3538 , 0.3525 , 0.3516 , 0.3503 , 0.3499 , 0.3484 , 0.3474 ,\n",
       "            0.344  , 0.3425 , 0.3416 , 0.3408 , 0.3398 , 0.339  , 0.337  ,\n",
       "            0.3367 , 0.3364 , 0.335  , 0.3335 , 0.3328 , 0.3325 , 0.3323 ,\n",
       "            0.3313 , 0.3286 , 0.3284 , 0.3281 , 0.3276 , 0.327  , 0.325  ,\n",
       "            0.3247 , 0.3242 , 0.3232 , 0.323  , 0.3228 , 0.321  , 0.3208 ,\n",
       "            0.32   , 0.3198 , 0.3196 , 0.3188 , 0.3186 , 0.3174 , 0.3171 ,\n",
       "            0.317  , 0.3167 , 0.3162 , 0.3154 , 0.315  , 0.314  , 0.3115 ,\n",
       "            0.3105 , 0.3098 , 0.308  , 0.3064 , 0.3054 , 0.3052 , 0.305  ,\n",
       "            0.3044 , 0.3042 , 0.3032 , 0.303  , 0.3027 , 0.3022 , 0.302  ,\n",
       "            0.3013 , 0.3003 , 0.2993 , 0.2979 , 0.2964 , 0.2961 , 0.296  ,\n",
       "            0.2952 , 0.295  , 0.2935 , 0.293  , 0.292  , 0.2913 , 0.2898 ,\n",
       "            0.2893 , 0.288  , 0.2861 , 0.2854 , 0.28   , 0.2795 , 0.277  ,\n",
       "            0.2708 , 0.2646 , 0.2585 , 0.255  , 0.2517 , 0.2406 , 0.2352 ,\n",
       "            0.2319 , 0.2301 , 0.2246 , 0.2222 , 0.2009 , 0.1891 , 0.1815 ,\n",
       "            0.181  , 0.1792 , 0.1754 , 0.1716 , 0.1676 , 0.167  , 0.1665 ,\n",
       "            0.1544 , 0.1521 , 0.1475 , 0.133  , 0.1284 , 0.1166 , 0.1126 ,\n",
       "            0.0854 , 0.07104, 0.0656 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.02542373, dtype=float32),\n",
       "    'tpr': array(0.4848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33898306, 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.66101694, 0.66101694, 0.6694915 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.50757575, 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6439394 , 0.6439394 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.7651515 , 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.77272725, 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.81060606, 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9043 , 0.866  , 0.8657 , 0.8647 , 0.858  , 0.851  ,\n",
       "            0.849  , 0.848  , 0.8457 , 0.8433 , 0.837  , 0.8276 , 0.8193 ,\n",
       "            0.801  , 0.799  , 0.797  , 0.7944 , 0.7935 , 0.7925 , 0.7876 ,\n",
       "            0.7866 , 0.7856 , 0.7783 , 0.7744 , 0.774  , 0.772  , 0.7686 ,\n",
       "            0.7637 , 0.7593 , 0.755  , 0.747  , 0.7456 , 0.7417 , 0.741  ,\n",
       "            0.7324 , 0.7305 , 0.7295 , 0.7124 , 0.712  , 0.708  , 0.6924 ,\n",
       "            0.6885 , 0.682  , 0.6772 , 0.6704 , 0.6606 , 0.6504 , 0.6484 ,\n",
       "            0.643  , 0.624  , 0.612  , 0.604  , 0.596  , 0.589  , 0.5728 ,\n",
       "            0.572  , 0.567  , 0.543  , 0.5356 , 0.524  , 0.5166 , 0.512  ,\n",
       "            0.5093 , 0.5034 , 0.4927 , 0.488  , 0.4856 , 0.4802 , 0.473  ,\n",
       "            0.4673 , 0.4568 , 0.456  , 0.4556 , 0.4524 , 0.4507 , 0.45   ,\n",
       "            0.4456 , 0.4443 , 0.4426 , 0.4424 , 0.4365 , 0.4287 , 0.4258 ,\n",
       "            0.4114 , 0.4111 , 0.41   , 0.408  , 0.4004 , 0.399  , 0.3987 ,\n",
       "            0.3982 , 0.3962 , 0.396  , 0.3936 , 0.3928 , 0.3865 , 0.3804 ,\n",
       "            0.3718 , 0.371  , 0.3674 , 0.3672 , 0.365  , 0.363  , 0.3616 ,\n",
       "            0.3613 , 0.3604 , 0.3586 , 0.3572 , 0.3567 , 0.354  , 0.3506 ,\n",
       "            0.35   , 0.3499 , 0.3486 , 0.3481 , 0.3464 , 0.3457 , 0.345  ,\n",
       "            0.3447 , 0.3442 , 0.3435 , 0.3408 , 0.3376 , 0.3372 , 0.3362 ,\n",
       "            0.3354 , 0.3352 , 0.335  , 0.333  , 0.3328 , 0.3325 , 0.3318 ,\n",
       "            0.3315 , 0.329  , 0.3289 , 0.3276 , 0.327  , 0.3264 , 0.3262 ,\n",
       "            0.326  , 0.3252 , 0.325  , 0.3245 , 0.3242 , 0.324  , 0.3235 ,\n",
       "            0.3215 , 0.321  , 0.3208 , 0.3206 , 0.3198 , 0.3196 , 0.3188 ,\n",
       "            0.318  , 0.3179 , 0.317  , 0.3167 , 0.3154 , 0.3118 , 0.3108 ,\n",
       "            0.3103 , 0.3086 , 0.3074 , 0.3066 , 0.306  , 0.3054 , 0.3052 ,\n",
       "            0.3044 , 0.3032 , 0.3027 , 0.3015 , 0.3013 , 0.3005 , 0.3    ,\n",
       "            0.2996 , 0.298  , 0.2961 , 0.2957 , 0.2947 , 0.2944 , 0.294  ,\n",
       "            0.2932 , 0.2925 , 0.2915 , 0.291  , 0.2908 , 0.2898 , 0.2878 ,\n",
       "            0.2864 , 0.2844 , 0.279  , 0.278  , 0.2747 , 0.2732 , 0.2722 ,\n",
       "            0.2625 , 0.2563 , 0.2502 , 0.2466 , 0.243  , 0.2335 , 0.2319 ,\n",
       "            0.2266 , 0.2224 , 0.22   , 0.215  , 0.213  , 0.1901 , 0.1781 ,\n",
       "            0.1775 , 0.1696 , 0.1694 , 0.1674 , 0.1636 , 0.16   , 0.1556 ,\n",
       "            0.155  , 0.1431 , 0.1409 , 0.1357 , 0.122  , 0.11694, 0.1056 ,\n",
       "            0.1019 , 0.0752 , 0.06244, 0.05676], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.05084746, dtype=float32),\n",
       "    'tpr': array(0.5151515, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.33050847, 0.33050847, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5423729 ,\n",
       "            0.5508475 , 0.5677966 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.6101695 , 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.929  , 0.896  , 0.8955 , 0.895  , 0.8887 , 0.8823 ,\n",
       "            0.882  , 0.88   , 0.8784 , 0.8765 , 0.87   , 0.8696 , 0.861  ,\n",
       "            0.8545 , 0.837  , 0.8345 , 0.833  , 0.8306 , 0.829  , 0.8286 ,\n",
       "            0.8228 , 0.8223 , 0.8213 , 0.816  , 0.8105 , 0.8086 , 0.808  ,\n",
       "            0.8047 , 0.801  , 0.7964 , 0.7925 , 0.7847 , 0.783  , 0.78   ,\n",
       "            0.779  , 0.7725 , 0.768  , 0.767  , 0.752  , 0.7515 , 0.7485 ,\n",
       "            0.7295 , 0.725  , 0.719  , 0.717  , 0.709  , 0.6987 , 0.687  ,\n",
       "            0.6865 , 0.678  , 0.66   , 0.6455 , 0.637  , 0.6333 , 0.63   ,\n",
       "            0.6035 , 0.5996 , 0.578  , 0.5713 , 0.5684 , 0.553  , 0.548  ,\n",
       "            0.5425 , 0.535  , 0.532  , 0.526  , 0.523  , 0.5176 , 0.5107 ,\n",
       "            0.5024 , 0.5005 , 0.4949 , 0.4912 , 0.4883 , 0.488  , 0.4792 ,\n",
       "            0.479  , 0.4785 , 0.4773 , 0.475  , 0.4722 , 0.468  , 0.4531 ,\n",
       "            0.4407 , 0.437  , 0.432  , 0.4302 , 0.427  , 0.4263 , 0.4255 ,\n",
       "            0.425  , 0.4238 , 0.4211 , 0.418  , 0.4102 , 0.4094 , 0.4082 ,\n",
       "            0.4062 , 0.3938 , 0.3936 , 0.393  , 0.392  , 0.3901 , 0.3882 ,\n",
       "            0.386  , 0.38   , 0.3792 , 0.378  , 0.3777 , 0.3713 , 0.3704 ,\n",
       "            0.3687 , 0.3682 , 0.3677 , 0.3674 , 0.3672 , 0.364  , 0.3623 ,\n",
       "            0.362  , 0.3616 , 0.3613 , 0.361  , 0.3599 , 0.3584 , 0.3577 ,\n",
       "            0.356  , 0.3547 , 0.3538 , 0.353  , 0.351  , 0.35   , 0.3499 ,\n",
       "            0.3496 , 0.349  , 0.3477 , 0.3452 , 0.3442 , 0.3435 , 0.3428 ,\n",
       "            0.3425 , 0.342  , 0.3413 , 0.3403 , 0.3394 , 0.339  , 0.3386 ,\n",
       "            0.3381 , 0.338  , 0.3367 , 0.336  , 0.3354 , 0.3345 , 0.3342 ,\n",
       "            0.3335 , 0.3308 , 0.3293 , 0.329  , 0.3281 , 0.328  , 0.3267 ,\n",
       "            0.3252 , 0.3242 , 0.3223 , 0.3215 , 0.3206 , 0.3198 , 0.319  ,\n",
       "            0.3188 , 0.3184 , 0.318  , 0.3171 , 0.3162 , 0.316  , 0.3137 ,\n",
       "            0.312  , 0.3108 , 0.31   , 0.3086 , 0.3076 , 0.3052 , 0.304  ,\n",
       "            0.3032 , 0.3018 , 0.3015 , 0.299  , 0.2935 , 0.2932 , 0.292  ,\n",
       "            0.2903 , 0.2896 , 0.2856 , 0.2837 , 0.2825 , 0.2764 , 0.2722 ,\n",
       "            0.2705 , 0.259  , 0.2534 , 0.247  , 0.2434 , 0.2397 , 0.2328 ,\n",
       "            0.2286 , 0.2217 , 0.2179 , 0.214  , 0.2084 , 0.2073 , 0.1831 ,\n",
       "            0.1705 , 0.1697 , 0.1616 , 0.1614 , 0.1589 , 0.1554 , 0.1521 ,\n",
       "            0.148  , 0.1467 , 0.1462 , 0.135  , 0.1329 , 0.126  , 0.1142 ,\n",
       "            0.10724, 0.0962 , 0.0925 , 0.0672 , 0.05624, 0.04968],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.07627118, dtype=float32),\n",
       "    'tpr': array(0.5378788, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.30508474, 0.30508474, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33898306, 0.34745762, 0.3644068 , 0.37288135, 0.37288135,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.42372882, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.74242425, 0.74242425,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.77272725,\n",
       "            0.77272725, 0.77272725, 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.7878788 , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.82575756, 0.82575756,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9434 , 0.914  , 0.9136 , 0.9126 , 0.907  , 0.9014 ,\n",
       "            0.901  , 0.899  , 0.898  , 0.8965 , 0.8896 , 0.8804 , 0.8755 ,\n",
       "            0.859  , 0.8564 , 0.855  , 0.8535 , 0.851  , 0.8506 , 0.844  ,\n",
       "            0.8438 , 0.843  , 0.839  , 0.833  , 0.8325 , 0.831  , 0.8296 ,\n",
       "            0.8267 , 0.824  , 0.8193 , 0.8154 , 0.808  , 0.806  , 0.8037 ,\n",
       "            0.802  , 0.797  , 0.7905 , 0.79   , 0.7764 , 0.7754 , 0.7734 ,\n",
       "            0.752  , 0.747  , 0.7427 , 0.742  , 0.7324 , 0.723  , 0.7104 ,\n",
       "            0.7095 , 0.6997 , 0.682  , 0.6636 , 0.657  , 0.656  , 0.6553 ,\n",
       "            0.6226 , 0.6196 , 0.6187 , 0.606  , 0.5977 , 0.586  , 0.5757 ,\n",
       "            0.57   , 0.564  , 0.5625 , 0.554  , 0.546  , 0.545  , 0.5356 ,\n",
       "            0.535  , 0.5205 , 0.52   , 0.518  , 0.5107 , 0.5103 , 0.5083 ,\n",
       "            0.5034 , 0.501  , 0.4993 , 0.499  , 0.4949 , 0.4941 , 0.4907 ,\n",
       "            0.4888 , 0.4692 , 0.4587 , 0.455  , 0.4487 , 0.446  , 0.4438 ,\n",
       "            0.4434 , 0.4382 , 0.4358 , 0.4292 , 0.4287 , 0.4224 , 0.4126 ,\n",
       "            0.4116 , 0.4097 , 0.4077 , 0.4055 , 0.4053 , 0.4036 , 0.403  ,\n",
       "            0.4011 , 0.3936 , 0.387  , 0.386  , 0.3855 , 0.384  , 0.3833 ,\n",
       "            0.383  , 0.382  , 0.3816 , 0.3801 , 0.3757 , 0.3752 , 0.3735 ,\n",
       "            0.372  , 0.3718 , 0.3708 , 0.3706 , 0.3704 , 0.37   , 0.3687 ,\n",
       "            0.3672 , 0.367  , 0.3647 , 0.3638 , 0.3635 , 0.362  , 0.3604 ,\n",
       "            0.3591 , 0.3564 , 0.356  , 0.3557 , 0.3552 , 0.355  , 0.3547 ,\n",
       "            0.3542 , 0.3535 , 0.352  , 0.35   , 0.3477 , 0.3467 , 0.3464 ,\n",
       "            0.3462 , 0.346  , 0.3452 , 0.3442 , 0.3438 , 0.3418 , 0.341  ,\n",
       "            0.3408 , 0.3384 , 0.338  , 0.3374 , 0.3367 , 0.336  , 0.3357 ,\n",
       "            0.3354 , 0.3335 , 0.332  , 0.3313 , 0.331  , 0.3306 , 0.3296 ,\n",
       "            0.329  , 0.3289 , 0.3286 , 0.3281 , 0.328  , 0.3271 , 0.3262 ,\n",
       "            0.326  , 0.3254 , 0.3237 , 0.32   , 0.3196 , 0.3186 , 0.3167 ,\n",
       "            0.3162 , 0.311  , 0.3105 , 0.3098 , 0.3093 , 0.3086 , 0.3083 ,\n",
       "            0.3066 , 0.3044 , 0.3025 , 0.2988 , 0.2969 , 0.2966 , 0.2954 ,\n",
       "            0.2913 , 0.2878 , 0.2844 , 0.2795 , 0.2773 , 0.27   , 0.265  ,\n",
       "            0.2637 , 0.2522 , 0.2462 , 0.2391 , 0.2346 , 0.2314 , 0.223  ,\n",
       "            0.2189 , 0.2156 , 0.2068 , 0.2059 , 0.2006 , 0.2004 , 0.1735 ,\n",
       "            0.161  , 0.1588 , 0.1505 , 0.1483 , 0.1447 , 0.1411 , 0.1367 ,\n",
       "            0.1361 , 0.136  , 0.1241 , 0.1219 , 0.11676, 0.1034 , 0.09845,\n",
       "            0.0876 , 0.0845 , 0.059  , 0.04858, 0.04263], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.11016949, dtype=float32),\n",
       "    'tpr': array(0.5530303, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33898306, 0.3559322 ,\n",
       "            0.3559322 , 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.59322035, 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75757575, 0.7651515 , 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.77272725, 0.77272725, 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.7878788 , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.81060606, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8939394 , 0.9015151 , 0.90909094, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9575 , 0.932  , 0.931  , 0.927  , 0.922  , 0.9214 ,\n",
       "            0.919  , 0.9185 , 0.9175 , 0.911  , 0.903  , 0.899  , 0.8833 ,\n",
       "            0.881  , 0.88   , 0.8784 , 0.876  , 0.875  , 0.8696 , 0.869  ,\n",
       "            0.868  , 0.865  , 0.8594 , 0.8584 , 0.8574 , 0.856  , 0.853  ,\n",
       "            0.851  , 0.8457 , 0.8423 , 0.8354 , 0.8335 , 0.8315 , 0.829  ,\n",
       "            0.8257 , 0.8184 , 0.8057 , 0.8047 , 0.803  , 0.7803 , 0.776  ,\n",
       "            0.7725 , 0.7715 , 0.7617 , 0.7524 , 0.74   , 0.7383 , 0.728  ,\n",
       "            0.7104 , 0.6914 , 0.687  , 0.6846 , 0.648  , 0.645  , 0.6396 ,\n",
       "            0.633  , 0.61   , 0.6045 , 0.602  , 0.5986 , 0.5894 , 0.5796 ,\n",
       "            0.5728 , 0.5723 , 0.567  , 0.559  , 0.5513 , 0.5474 , 0.54   ,\n",
       "            0.5347 , 0.533  , 0.529  , 0.5273 , 0.5264 , 0.526  , 0.524  ,\n",
       "            0.5093 , 0.5083 , 0.4915 , 0.4824 , 0.4788 , 0.473  , 0.4724 ,\n",
       "            0.4663 , 0.4658 , 0.4644 , 0.4607 , 0.458  , 0.4558 , 0.4536 ,\n",
       "            0.4407 , 0.4377 , 0.4312 , 0.4277 , 0.423  , 0.4219 , 0.4216 ,\n",
       "            0.4204 , 0.4192 , 0.417  , 0.4124 , 0.4048 , 0.4023 , 0.402  ,\n",
       "            0.4016 , 0.4011 , 0.3992 , 0.3984 , 0.3965 , 0.3936 , 0.3933 ,\n",
       "            0.393  , 0.3916 , 0.3896 , 0.3892 , 0.386  , 0.3843 , 0.38   ,\n",
       "            0.3792 , 0.379  , 0.378  , 0.3762 , 0.3755 , 0.375  , 0.3735 ,\n",
       "            0.3733 , 0.3728 , 0.37   , 0.3696 , 0.3694 , 0.3682 , 0.3677 ,\n",
       "            0.3672 , 0.365  , 0.3635 , 0.361  , 0.3606 , 0.3586 , 0.3582 ,\n",
       "            0.3577 , 0.357  , 0.3564 , 0.3552 , 0.3542 , 0.3528 , 0.3525 ,\n",
       "            0.352  , 0.3516 , 0.3494 , 0.3489 , 0.3481 , 0.3477 , 0.3462 ,\n",
       "            0.3457 , 0.3452 , 0.3435 , 0.3433 , 0.343  , 0.3423 , 0.341  ,\n",
       "            0.3406 , 0.3394 , 0.339  , 0.3386 , 0.3384 , 0.3381 , 0.3372 ,\n",
       "            0.3333 , 0.3325 , 0.3315 , 0.3313 , 0.3293 , 0.326  , 0.3254 ,\n",
       "            0.3252 , 0.3208 , 0.32   , 0.3196 , 0.317  , 0.3164 , 0.3162 ,\n",
       "            0.3086 , 0.3071 , 0.307  , 0.3066 , 0.304  , 0.2957 , 0.2954 ,\n",
       "            0.2935 , 0.2925 , 0.2844 , 0.281  , 0.2756 , 0.2734 , 0.2656 ,\n",
       "            0.2612 , 0.259  , 0.2466 , 0.2406 , 0.2335 , 0.229  , 0.2256 ,\n",
       "            0.2194 , 0.2129 , 0.2086 , 0.1998 , 0.1985 , 0.1934 , 0.1929 ,\n",
       "            0.165  , 0.1526 , 0.1499 , 0.1416 , 0.1412 , 0.139  , 0.1355 ,\n",
       "            0.1323 , 0.128  , 0.1267 , 0.11536, 0.1134 , 0.1076 , 0.09515,\n",
       "            0.0896 , 0.0792 , 0.0763 , 0.05203, 0.04312, 0.03683],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.12711865, dtype=float32),\n",
       "    'tpr': array(0.56060606, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22033899, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75757575, 0.75757575, 0.7651515 , 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.79545456, 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.82575756, 0.8333333 , 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.968  , 0.9463 , 0.9453 , 0.9414 , 0.9375 , 0.9365 ,\n",
       "            0.9346 , 0.9336 , 0.9277 , 0.9272 , 0.92   , 0.917  , 0.903  ,\n",
       "            0.9004 , 0.8994 , 0.8984 , 0.896  , 0.895  , 0.8896 , 0.889  ,\n",
       "            0.888  , 0.886  , 0.8804 , 0.8794 , 0.8784 , 0.8765 , 0.874  ,\n",
       "            0.873  , 0.8677 , 0.864  , 0.8584 , 0.856  , 0.8545 , 0.8516 ,\n",
       "            0.849  , 0.842  , 0.8413 , 0.83   , 0.8296 , 0.8286 , 0.8047 ,\n",
       "            0.8    , 0.799  , 0.7964 , 0.7876 , 0.7783 , 0.766  , 0.7637 ,\n",
       "            0.7524 , 0.736  , 0.7153 , 0.714  , 0.71   , 0.7085 , 0.6714 ,\n",
       "            0.67   , 0.6685 , 0.6665 , 0.6646 , 0.636  , 0.631  , 0.6294 ,\n",
       "            0.6245 , 0.6133 , 0.603  , 0.5986 , 0.596  , 0.5957 , 0.5815 ,\n",
       "            0.5806 , 0.5728 , 0.566  , 0.5605 , 0.5586 , 0.5557 , 0.5547 ,\n",
       "            0.5527 , 0.5503 , 0.54   , 0.5264 , 0.526  , 0.511  , 0.504  ,\n",
       "            0.5005 , 0.4963 , 0.495  , 0.488  , 0.4868 , 0.4866 , 0.4763 ,\n",
       "            0.476  , 0.474  , 0.4607 , 0.4573 , 0.4514 , 0.4485 , 0.4438 ,\n",
       "            0.4402 , 0.439  , 0.4338 , 0.4297 , 0.4268 , 0.4226 , 0.4224 ,\n",
       "            0.4204 , 0.42   , 0.4177 , 0.4175 , 0.4155 , 0.4124 , 0.4119 ,\n",
       "            0.4092 , 0.4072 , 0.4055 , 0.3992 , 0.3977 , 0.3965 , 0.3953 ,\n",
       "            0.3945 , 0.392  , 0.3918 , 0.3904 , 0.3896 , 0.3894 , 0.3892 ,\n",
       "            0.3884 , 0.3882 , 0.3862 , 0.3853 , 0.385  , 0.3833 , 0.3816 ,\n",
       "            0.3809 , 0.3806 , 0.377  , 0.375  , 0.3726 , 0.3723 , 0.3716 ,\n",
       "            0.3699 , 0.369  , 0.3684 , 0.3682 , 0.3674 , 0.3647 , 0.3645 ,\n",
       "            0.363  , 0.3623 , 0.3618 , 0.3608 , 0.3606 , 0.358  , 0.3562 ,\n",
       "            0.356  , 0.3547 , 0.3538 , 0.3535 , 0.3533 , 0.3518 , 0.351  ,\n",
       "            0.3499 , 0.3489 , 0.3486 , 0.3477 , 0.3472 , 0.3467 , 0.3464 ,\n",
       "            0.3455 , 0.3445 , 0.336  , 0.3352 , 0.3315 , 0.3313 , 0.3298 ,\n",
       "            0.3296 , 0.3293 , 0.3286 , 0.328  , 0.3271 , 0.3257 , 0.324  ,\n",
       "            0.3215 , 0.3186 , 0.3132 , 0.3123 , 0.312  , 0.3035 , 0.3005 ,\n",
       "            0.3003 , 0.2915 , 0.2898 , 0.2795 , 0.2761 , 0.2708 , 0.2683 ,\n",
       "            0.2603 , 0.2556 , 0.2534 , 0.2401 , 0.234  , 0.2266 , 0.2218 ,\n",
       "            0.2185 , 0.2125 , 0.2048 , 0.2009 , 0.191  , 0.1904 , 0.1852 ,\n",
       "            0.1846 , 0.1562 , 0.1436 , 0.1403 , 0.1321 , 0.1316 , 0.1294 ,\n",
       "            0.1259 , 0.12286, 0.1188 , 0.1172 , 0.1063 , 0.1043 , 0.0986 ,\n",
       "            0.0863 , 0.08124, 0.0712 , 0.06854, 0.04535, 0.03754, 0.03143],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1440678, dtype=float32),\n",
       "    'tpr': array(0.6060606, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.37288135, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.3983051 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.70454544, 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.72727275, 0.72727275, 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8636364 , 0.8636364 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.976  , 0.959  , 0.9585 , 0.9575 , 0.954  , 0.9517 ,\n",
       "            0.95   , 0.9487 , 0.948  , 0.943  , 0.942  , 0.936  , 0.9336 ,\n",
       "            0.9214 , 0.919  , 0.9185 , 0.9175 , 0.915  , 0.9136 , 0.9087 ,\n",
       "            0.908  , 0.907  , 0.901  , 0.8994 , 0.899  , 0.8965 , 0.8945 ,\n",
       "            0.894  , 0.889  , 0.8853 , 0.8804 , 0.8784 , 0.877  , 0.874  ,\n",
       "            0.873  , 0.8647 , 0.8643 , 0.856  , 0.855  , 0.8296 , 0.827  ,\n",
       "            0.824  , 0.8223 , 0.815  , 0.806  , 0.795  , 0.7905 , 0.779  ,\n",
       "            0.7637 , 0.7505 , 0.7407 , 0.7383 , 0.735  , 0.7104 , 0.7075 ,\n",
       "            0.6987 , 0.6963 , 0.6904 , 0.685  , 0.6665 , 0.659  , 0.6523 ,\n",
       "            0.646  , 0.6367 , 0.635  , 0.634  , 0.629  , 0.627  , 0.6235 ,\n",
       "            0.61   , 0.609  , 0.606  , 0.6016 , 0.6006 , 0.5947 , 0.5933 ,\n",
       "            0.5913 , 0.5903 , 0.5864 , 0.5566 , 0.5527 , 0.5483 , 0.5425 ,\n",
       "            0.538  , 0.535  , 0.5347 , 0.5303 , 0.5273 , 0.52   , 0.5127 ,\n",
       "            0.5054 , 0.504  , 0.5    , 0.4858 , 0.4849 , 0.4731 , 0.4683 ,\n",
       "            0.4668 , 0.4604 , 0.4592 , 0.4548 , 0.4543 , 0.4539 , 0.4521 ,\n",
       "            0.4517 , 0.4507 , 0.4473 , 0.4468 , 0.446  , 0.4404 , 0.4395 ,\n",
       "            0.4375 , 0.432  , 0.4302 , 0.4294 , 0.4287 , 0.4243 , 0.4229 ,\n",
       "            0.4211 , 0.421  , 0.4207 , 0.4194 , 0.419  , 0.4182 , 0.4165 ,\n",
       "            0.4163 , 0.4158 , 0.4146 , 0.4097 , 0.4082 , 0.408  , 0.4072 ,\n",
       "            0.4001 , 0.4    , 0.3997 , 0.3992 , 0.399  , 0.3975 , 0.395  ,\n",
       "            0.3936 , 0.393  , 0.3914 , 0.3909 , 0.3896 , 0.3887 , 0.3867 ,\n",
       "            0.3848 , 0.3843 , 0.3833 , 0.3828 , 0.3823 , 0.382  , 0.3818 ,\n",
       "            0.3813 , 0.3801 , 0.38   , 0.3782 , 0.377  , 0.376  , 0.3752 ,\n",
       "            0.3733 , 0.3726 , 0.3723 , 0.372  , 0.3718 , 0.37   , 0.3696 ,\n",
       "            0.3684 , 0.368  , 0.367  , 0.3667 , 0.362  , 0.355  , 0.351  ,\n",
       "            0.35   , 0.3499 , 0.3496 , 0.3494 , 0.3474 , 0.3455 , 0.345  ,\n",
       "            0.3442 , 0.3438 , 0.3384 , 0.334  , 0.3315 , 0.3313 , 0.3306 ,\n",
       "            0.33   , 0.3262 , 0.3176 , 0.304  , 0.3008 , 0.2976 , 0.2908 ,\n",
       "            0.2893 , 0.2788 , 0.2754 , 0.2695 , 0.267  , 0.2585 , 0.2534 ,\n",
       "            0.2512 , 0.2374 , 0.231  , 0.2234 , 0.2179 , 0.2148 , 0.209  ,\n",
       "            0.1991 , 0.1967 , 0.1858 , 0.1849 , 0.1808 , 0.1799 , 0.1503 ,\n",
       "            0.1375 , 0.1333 , 0.1251 , 0.12463, 0.12244, 0.1188 , 0.1158 ,\n",
       "            0.1118 , 0.1105 , 0.1101 , 0.0993 , 0.0972 , 0.09204, 0.07965,\n",
       "            0.0752 , 0.06525, 0.0628 , 0.0403 , 0.0334 , 0.02737],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.16101696, dtype=float32),\n",
       "    'tpr': array(0.6287879, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22033899, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.2881356 , 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.33898306, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.37288135, 0.37288135, 0.37288135, 0.37288135,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.17424242, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.5378788 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.981  , 0.966  , 0.9653 , 0.9644 , 0.962  , 0.9595 ,\n",
       "            0.958  , 0.957  , 0.9565 , 0.9517 , 0.9507 , 0.945  , 0.9434 ,\n",
       "            0.9316 , 0.9297 , 0.929  , 0.928  , 0.9263 , 0.9243 , 0.92   ,\n",
       "            0.919  , 0.918  , 0.913  , 0.911  , 0.9106 , 0.908  , 0.907  ,\n",
       "            0.906  , 0.9014 , 0.898  , 0.893  , 0.891  , 0.8906 , 0.887  ,\n",
       "            0.8867 , 0.8784 , 0.877  , 0.8706 , 0.87   , 0.8696 , 0.8438 ,\n",
       "            0.838  , 0.8374 , 0.8306 , 0.8228 , 0.812  , 0.806  , 0.7935 ,\n",
       "            0.78   , 0.77   , 0.7583 , 0.75   , 0.7495 , 0.7344 , 0.7324 ,\n",
       "            0.7144 , 0.712  , 0.702  , 0.6865 , 0.6787 , 0.6646 , 0.6616 ,\n",
       "            0.6553 , 0.6514 , 0.65   , 0.6475 , 0.6304 , 0.63   , 0.6284 ,\n",
       "            0.627  , 0.6265 , 0.6167 , 0.616  , 0.6147 , 0.6084 , 0.5674 ,\n",
       "            0.56   , 0.559  , 0.5586 , 0.555  , 0.552  , 0.5513 , 0.5396 ,\n",
       "            0.5356 , 0.5254 , 0.522  , 0.521  , 0.5127 , 0.509  , 0.5073 ,\n",
       "            0.5005 , 0.4944 , 0.4863 , 0.4834 , 0.48   , 0.479  , 0.476  ,\n",
       "            0.4753 , 0.4746 , 0.4744 , 0.4734 , 0.4692 , 0.4666 , 0.4656 ,\n",
       "            0.4626 , 0.4592 , 0.4565 , 0.4438 , 0.4434 , 0.4424 , 0.4421 ,\n",
       "            0.442  , 0.4402 , 0.4397 , 0.4392 , 0.4385 , 0.4373 , 0.4365 ,\n",
       "            0.4363 , 0.435  , 0.4343 , 0.4336 , 0.4302 , 0.427  , 0.426  ,\n",
       "            0.4248 , 0.4216 , 0.4211 , 0.4175 , 0.417  , 0.4146 , 0.4143 ,\n",
       "            0.4124 , 0.4106 , 0.4102 , 0.4097 , 0.4087 , 0.407  , 0.4053 ,\n",
       "            0.4028 , 0.4026 , 0.4023 , 0.401  , 0.4001 , 0.4    , 0.3972 ,\n",
       "            0.3967 , 0.3962 , 0.3955 , 0.395  , 0.3948 , 0.3938 , 0.3933 ,\n",
       "            0.3918 , 0.3892 , 0.3877 , 0.3865 , 0.386  , 0.385  , 0.3845 ,\n",
       "            0.3835 , 0.3816 , 0.3804 , 0.3784 , 0.3762 , 0.376  , 0.3757 ,\n",
       "            0.3677 , 0.367  , 0.366  , 0.3625 , 0.3618 , 0.3616 , 0.3599 ,\n",
       "            0.3577 , 0.357  , 0.3523 , 0.3513 , 0.35   , 0.3489 , 0.3452 ,\n",
       "            0.3438 , 0.3425 , 0.3381 , 0.3354 , 0.33   , 0.3274 , 0.3262 ,\n",
       "            0.3008 , 0.2983 , 0.293  , 0.283  , 0.2825 , 0.274  , 0.27   ,\n",
       "            0.2634 , 0.261  , 0.2527 , 0.2462 , 0.2448 , 0.2316 , 0.2242 ,\n",
       "            0.2162 , 0.2089 , 0.2068 , 0.1978 , 0.191  , 0.1882 , 0.1791 ,\n",
       "            0.1746 , 0.174  , 0.1738 , 0.1417 , 0.1296 , 0.1239 , 0.1158 ,\n",
       "            0.1134 , 0.1099 , 0.1065 , 0.1025 , 0.1021 , 0.10175, 0.0903 ,\n",
       "            0.0882 , 0.08527, 0.0712 , 0.0688 , 0.05942, 0.05728, 0.03516,\n",
       "            0.02827, 0.02324], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1779661, dtype=float32),\n",
       "    'tpr': array(0.6363636, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 , 0.3644068 ,\n",
       "            0.37288135, 0.37288135, 0.3898305 , 0.3898305 , 0.3983051 ,\n",
       "            0.3983051 , 0.3983051 , 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.41666666,\n",
       "            0.42424244, 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.70454544, 0.70454544, 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.79545456, 0.79545456, 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.985  , 0.9717 , 0.9707 , 0.9683 , 0.9663 , 0.965  ,\n",
       "            0.9644 , 0.964  , 0.9595 , 0.958  , 0.953  , 0.952  , 0.942  ,\n",
       "            0.9395 , 0.9385 , 0.9365 , 0.934  , 0.93   , 0.929  , 0.9277 ,\n",
       "            0.9243 , 0.9224 , 0.922  , 0.9194 , 0.919  , 0.9165 , 0.9136 ,\n",
       "            0.9097 , 0.906  , 0.9033 , 0.9004 , 0.899  , 0.8916 , 0.8896 ,\n",
       "            0.8853 , 0.8843 , 0.86   , 0.8574 , 0.8525 , 0.851  , 0.846  ,\n",
       "            0.839  , 0.8286 , 0.822  , 0.8076 , 0.7964 , 0.789  , 0.7754 ,\n",
       "            0.7646 , 0.76   , 0.757  , 0.742  , 0.73   , 0.7275 , 0.713  ,\n",
       "            0.706  , 0.698  , 0.6855 , 0.6826 , 0.682  , 0.676  , 0.6753 ,\n",
       "            0.67   , 0.669  , 0.666  , 0.655  , 0.6533 , 0.652  , 0.65   ,\n",
       "            0.642  , 0.639  , 0.6377 , 0.6367 , 0.63   , 0.5815 , 0.581  ,\n",
       "            0.5776 , 0.576  , 0.574  , 0.572  , 0.571  , 0.5615 , 0.558  ,\n",
       "            0.5576 , 0.557  , 0.5503 , 0.5376 , 0.5366 , 0.5317 , 0.528  ,\n",
       "            0.5244 , 0.5146 , 0.514  , 0.505  , 0.5034 , 0.499  , 0.4988 ,\n",
       "            0.4976 , 0.497  , 0.4954 , 0.4934 , 0.491  , 0.488  , 0.4846 ,\n",
       "            0.484  , 0.4832 , 0.4778 , 0.4624 , 0.4617 , 0.4573 , 0.457  ,\n",
       "            0.4563 , 0.456  , 0.4543 , 0.4531 , 0.453  , 0.4526 , 0.4524 ,\n",
       "            0.4504 , 0.4502 , 0.4497 , 0.449  , 0.444  , 0.4429 , 0.4414 ,\n",
       "            0.4402 , 0.4382 , 0.434  , 0.4333 , 0.4321 , 0.4314 , 0.4294 ,\n",
       "            0.4275 , 0.4265 , 0.4263 , 0.4253 , 0.4246 , 0.4219 , 0.4216 ,\n",
       "            0.4207 , 0.4197 , 0.4185 , 0.416  , 0.415  , 0.412  , 0.4106 ,\n",
       "            0.4092 , 0.4087 , 0.4084 , 0.4082 , 0.408  , 0.405  , 0.4043 ,\n",
       "            0.4036 , 0.4023 , 0.4    , 0.399  , 0.3972 , 0.3967 , 0.3945 ,\n",
       "            0.392  , 0.3877 , 0.3826 , 0.3806 , 0.3792 , 0.3782 , 0.3743 ,\n",
       "            0.3733 , 0.3728 , 0.3718 , 0.3672 , 0.3613 , 0.3594 , 0.3584 ,\n",
       "            0.355  , 0.3523 , 0.351  , 0.3435 , 0.3423 , 0.34   , 0.3389 ,\n",
       "            0.336  , 0.3215 , 0.3193 , 0.302  , 0.2908 , 0.2832 , 0.2742 ,\n",
       "            0.2737 , 0.267  , 0.263  , 0.2556 , 0.2534 , 0.2452 , 0.2372 ,\n",
       "            0.2366 , 0.224  , 0.2161 , 0.2074 , 0.1987 , 0.1973 , 0.1853 ,\n",
       "            0.1843 , 0.1765 , 0.171  , 0.1676 , 0.1672 , 0.162  , 0.1326 ,\n",
       "            0.1214 , 0.1142 , 0.1063 , 0.10596, 0.1041 , 0.1005 , 0.09686,\n",
       "            0.0942 , 0.093  , 0.0925 , 0.08124, 0.0792 , 0.07837, 0.0629 ,\n",
       "            0.0627 , 0.0538 , 0.05194, 0.03027, 0.0237 , 0.0195 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.21186441, dtype=float32),\n",
       "    'tpr': array(0.6969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.2881356 , 0.30508474, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.3983051 , 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.58474576, 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.10606061, 0.11363637, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.6969697 , 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.79545456,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8636364 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9883 , 0.9775 , 0.977  , 0.976  , 0.974  , 0.973  ,\n",
       "            0.971  , 0.9707 , 0.97   , 0.967  , 0.9653 , 0.9604 , 0.951  ,\n",
       "            0.949  , 0.9487 , 0.9463 , 0.9443 , 0.941  , 0.94   , 0.939  ,\n",
       "            0.938  , 0.9355 , 0.9336 , 0.9326 , 0.9307 , 0.93   , 0.9277 ,\n",
       "            0.9253 , 0.922  , 0.918  , 0.916  , 0.9155 , 0.914  , 0.912  ,\n",
       "            0.9053 , 0.903  , 0.8994 , 0.899  , 0.8774 , 0.873  , 0.8687 ,\n",
       "            0.866  , 0.864  , 0.857  , 0.847  , 0.8394 , 0.8247 , 0.815  ,\n",
       "            0.8115 , 0.796  , 0.785  , 0.784  , 0.783  , 0.7754 , 0.7744 ,\n",
       "            0.7495 , 0.7485 , 0.731  , 0.7285 , 0.7227 , 0.715  , 0.7065 ,\n",
       "            0.7017 , 0.692  , 0.69   , 0.6885 , 0.6846 , 0.683  , 0.677  ,\n",
       "            0.669  , 0.6685 , 0.667  , 0.6646 , 0.664  , 0.658  , 0.6123 ,\n",
       "            0.605  , 0.6045 , 0.6016 , 0.601  , 0.6    , 0.5996 , 0.5884 ,\n",
       "            0.587  , 0.5845 , 0.584  , 0.5815 , 0.571  , 0.561  , 0.5605 ,\n",
       "            0.5557 , 0.544  , 0.5415 , 0.5376 , 0.536  , 0.5273 , 0.527  ,\n",
       "            0.525  , 0.524  , 0.522  , 0.5215 , 0.52   , 0.5195 , 0.511  ,\n",
       "            0.5093 , 0.509  , 0.5073 , 0.503  , 0.4888 , 0.4885 , 0.4873 ,\n",
       "            0.4834 , 0.4827 , 0.4805 , 0.4775 , 0.4758 , 0.4753 , 0.4744 ,\n",
       "            0.4731 , 0.4724 , 0.471  , 0.469  , 0.468  , 0.4668 , 0.466  ,\n",
       "            0.4631 , 0.4583 , 0.4568 , 0.4531 , 0.4507 , 0.4504 , 0.4495 ,\n",
       "            0.449  , 0.4478 , 0.4465 , 0.446  , 0.444  , 0.4438 , 0.443  ,\n",
       "            0.4424 , 0.439  , 0.433  , 0.4329 , 0.4321 , 0.43   , 0.4297 ,\n",
       "            0.4292 , 0.4268 , 0.4265 , 0.4263 , 0.4246 , 0.424  , 0.4238 ,\n",
       "            0.423  , 0.4224 , 0.4211 , 0.4207 , 0.4204 , 0.4187 , 0.4163 ,\n",
       "            0.414  , 0.4138 , 0.4104 , 0.4094 , 0.4043 , 0.4028 , 0.4    ,\n",
       "            0.3984 , 0.395  , 0.3943 , 0.3916 , 0.3906 , 0.3884 , 0.3872 ,\n",
       "            0.383  , 0.3792 , 0.3774 , 0.3757 , 0.3743 , 0.37   , 0.3674 ,\n",
       "            0.364  , 0.3552 , 0.3542 , 0.354  , 0.351  , 0.3384 , 0.3352 ,\n",
       "            0.3208 , 0.318  , 0.3066 , 0.2886 , 0.2795 , 0.2708 , 0.2698 ,\n",
       "            0.2646 , 0.2603 , 0.2527 , 0.25   , 0.2418 , 0.2327 , 0.2325 ,\n",
       "            0.2203 , 0.2115 , 0.2028 , 0.1929 , 0.1917 , 0.1797 , 0.1779 ,\n",
       "            0.1688 , 0.166  , 0.1625 , 0.1621 , 0.1543 , 0.1263 , 0.11536,\n",
       "            0.10724, 0.0997 , 0.09894, 0.0974 , 0.0939 , 0.0901 , 0.088  ,\n",
       "            0.0866 , 0.0857 , 0.07465, 0.07275, 0.07263, 0.0575 , 0.05685,\n",
       "            0.04895, 0.04724, 0.0267 , 0.02042, 0.01672], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.21186441, dtype=float32),\n",
       "    'tpr': array(0.6969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.42372882, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.10606061, 0.11363637, 0.12121212, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.20454545, 0.21212122, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.65909094, 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.70454544, 0.70454544, 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9897 , 0.9795 , 0.9785 , 0.9766 , 0.9756 , 0.974  ,\n",
       "            0.9736 , 0.973  , 0.9697 , 0.9683 , 0.964  , 0.9546 , 0.953  ,\n",
       "            0.9526 , 0.95   , 0.948  , 0.9453 , 0.9443 , 0.9434 , 0.9424 ,\n",
       "            0.9395 , 0.938  , 0.937  , 0.935  , 0.9326 , 0.93   , 0.927  ,\n",
       "            0.923  , 0.921  , 0.9204 , 0.919  , 0.917  , 0.9106 , 0.908  ,\n",
       "            0.905  , 0.9043 , 0.883  , 0.879  , 0.8745 , 0.8716 , 0.869  ,\n",
       "            0.8623 , 0.8525 , 0.845  , 0.8306 , 0.821  , 0.8164 , 0.8013 ,\n",
       "            0.7905 , 0.789  , 0.7886 , 0.7803 , 0.7793 , 0.7544 , 0.753  ,\n",
       "            0.735  , 0.7314 , 0.7266 , 0.7197 , 0.719  , 0.711  , 0.71   ,\n",
       "            0.705  , 0.695  , 0.6934 , 0.687  , 0.685  , 0.68   , 0.6724 ,\n",
       "            0.671  , 0.667  , 0.661  , 0.6157 , 0.61   , 0.607  , 0.6035 ,\n",
       "            0.603  , 0.6025 , 0.6016 , 0.59   , 0.5894 , 0.587  , 0.586  ,\n",
       "            0.5684 , 0.567  , 0.562  , 0.5615 , 0.548  , 0.547  , 0.544  ,\n",
       "            0.5366 , 0.5347 , 0.5312 , 0.531  , 0.5293 , 0.528  , 0.527  ,\n",
       "            0.5264 , 0.5244 , 0.518  , 0.5146 , 0.512  , 0.5107 , 0.509  ,\n",
       "            0.4954 , 0.495  , 0.493  , 0.4897 , 0.4885 , 0.486  , 0.4832 ,\n",
       "            0.4797 , 0.479  , 0.478  , 0.4778 , 0.4775 , 0.4766 , 0.476  ,\n",
       "            0.4753 , 0.4746 , 0.4731 , 0.472  , 0.471  , 0.4678 , 0.4675 ,\n",
       "            0.4658 , 0.463  , 0.4587 , 0.4585 , 0.456  , 0.4558 , 0.4546 ,\n",
       "            0.454  , 0.4521 , 0.4512 , 0.4507 , 0.45   , 0.4497 , 0.449  ,\n",
       "            0.4424 , 0.441  , 0.4382 , 0.4373 , 0.437  , 0.4355 , 0.4314 ,\n",
       "            0.4304 , 0.4302 , 0.4297 , 0.429  , 0.4287 , 0.428  , 0.4263 ,\n",
       "            0.4243 , 0.4236 , 0.4214 , 0.4211 , 0.419  , 0.4177 , 0.4138 ,\n",
       "            0.4136 , 0.4062 , 0.4058 , 0.4045 , 0.4019 , 0.3987 , 0.3975 ,\n",
       "            0.3965 , 0.396  , 0.3928 , 0.3914 , 0.3877 , 0.3853 , 0.3784 ,\n",
       "            0.3723 , 0.3708 , 0.3687 , 0.3645 , 0.3606 , 0.3577 , 0.3562 ,\n",
       "            0.3408 , 0.3289 , 0.325  , 0.3115 , 0.308  , 0.3047 , 0.2786 ,\n",
       "            0.268  , 0.2598 , 0.2588 , 0.2556 , 0.251  , 0.2428 , 0.2405 ,\n",
       "            0.2323 , 0.2229 , 0.2218 , 0.211  , 0.2021 , 0.193  , 0.1821 ,\n",
       "            0.1815 , 0.1718 , 0.166  , 0.1575 , 0.1573 , 0.1545 , 0.1543 ,\n",
       "            0.143  , 0.1172 , 0.1074 , 0.09845, 0.0914 , 0.0904 , 0.0891 ,\n",
       "            0.0856 , 0.082  , 0.0805 , 0.07904, 0.07764, 0.0673 , 0.0662 ,\n",
       "            0.0655 , 0.05176, 0.0504 , 0.04385, 0.04233, 0.02324, 0.01738,\n",
       "            0.01423], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.27118644, dtype=float32),\n",
       "    'tpr': array(0.780303, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.21186441, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.33898306, 0.33898306, 0.33898306, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.70454544, 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.79545456, 0.8030303 , 0.8030303 , 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8636364 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.992  , 0.984  , 0.983  , 0.9814 , 0.9805 , 0.979  ,\n",
       "            0.9785 , 0.9756 , 0.974  , 0.9707 , 0.963  , 0.9614 , 0.961  ,\n",
       "            0.959  , 0.957  , 0.9546 , 0.953  , 0.9526 , 0.9517 , 0.9497 ,\n",
       "            0.948  , 0.9478 , 0.9473 , 0.9453 , 0.945  , 0.943  , 0.941  ,\n",
       "            0.9375 , 0.9346 , 0.9326 , 0.932  , 0.931  , 0.929  , 0.9233 ,\n",
       "            0.921  , 0.9185 , 0.918  , 0.9175 , 0.899  , 0.8936 , 0.89   ,\n",
       "            0.8867 , 0.8857 , 0.8794 , 0.8706 , 0.863  , 0.8477 , 0.8394 ,\n",
       "            0.8384 , 0.8228 , 0.818  , 0.815  , 0.8096 , 0.807  , 0.7954 ,\n",
       "            0.775  , 0.7744 , 0.76   , 0.753  , 0.7515 , 0.7495 , 0.7476 ,\n",
       "            0.7427 , 0.7344 , 0.7314 , 0.728  , 0.719  , 0.7188 , 0.7183 ,\n",
       "            0.7173 , 0.708  , 0.704  , 0.703  , 0.701  , 0.6997 , 0.6953 ,\n",
       "            0.6904 , 0.649  , 0.644  , 0.6357 , 0.633  , 0.6274 , 0.627  ,\n",
       "            0.6255 , 0.6235 , 0.6157 , 0.6147 , 0.6084 , 0.604  , 0.5957 ,\n",
       "            0.5874 , 0.587  , 0.5806 , 0.578  , 0.5713 , 0.566  , 0.5654 ,\n",
       "            0.5625 , 0.561  , 0.5605 , 0.5596 , 0.559  , 0.553  , 0.5513 ,\n",
       "            0.5454 , 0.5425 , 0.5405 , 0.5347 , 0.5293 , 0.525  , 0.524  ,\n",
       "            0.521  , 0.517  , 0.515  , 0.5117 , 0.509  , 0.5073 , 0.506  ,\n",
       "            0.505  , 0.504  , 0.5034 , 0.501  , 0.4998 , 0.497  , 0.494  ,\n",
       "            0.4937 , 0.4934 , 0.4893 , 0.4885 , 0.487  , 0.4868 , 0.486  ,\n",
       "            0.4846 , 0.4834 , 0.4824 , 0.4817 , 0.4812 , 0.4807 , 0.4736 ,\n",
       "            0.4705 , 0.4673 , 0.4653 , 0.4646 , 0.4624 , 0.4617 , 0.4578 ,\n",
       "            0.4573 , 0.457  , 0.455  , 0.4548 , 0.4546 , 0.4514 , 0.4504 ,\n",
       "            0.448  , 0.4465 , 0.4458 , 0.4453 , 0.4438 , 0.4434 , 0.4421 ,\n",
       "            0.4407 , 0.4385 , 0.4377 , 0.4353 , 0.4333 , 0.4316 , 0.4268 ,\n",
       "            0.4258 , 0.424  , 0.4214 , 0.4207 , 0.4153 , 0.4138 , 0.413  ,\n",
       "            0.4114 , 0.411  , 0.4102 , 0.4    , 0.3943 , 0.3887 , 0.3828 ,\n",
       "            0.378  , 0.3752 , 0.3748 , 0.3713 , 0.3708 , 0.341  , 0.3289 ,\n",
       "            0.3257 , 0.3115 , 0.311  , 0.3074 , 0.2766 , 0.2651 , 0.2566 ,\n",
       "            0.2551 , 0.2534 , 0.2485 , 0.2399 , 0.2374 , 0.2292 , 0.2194 ,\n",
       "            0.2177 , 0.2076 , 0.1981 , 0.1887 , 0.1768 , 0.1765 , 0.1677 ,\n",
       "            0.16   , 0.153  , 0.1508 , 0.1503 , 0.1499 , 0.1364 , 0.111  ,\n",
       "            0.1019 , 0.09235, 0.0854 , 0.0845 , 0.0833 , 0.0798 , 0.076  ,\n",
       "            0.0752 , 0.07355, 0.07184, 0.0619 , 0.06143, 0.0601 , 0.04742,\n",
       "            0.0457 , 0.03995, 0.03845, 0.0205 , 0.01513, 0.01219],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.34745762, dtype=float32),\n",
       "    'tpr': array(0.84090906, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.33898306, 0.34745762, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.10606061, 0.11363637, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.82575756, 0.8333333 ,\n",
       "            0.8333333 , 0.84090906, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9937 , 0.987  , 0.986  , 0.985  , 0.984  , 0.983  ,\n",
       "            0.9824 , 0.982  , 0.9795 , 0.9785 , 0.975  , 0.9683 , 0.967  ,\n",
       "            0.965  , 0.963  , 0.961  , 0.9595 , 0.959  , 0.958  , 0.9565 ,\n",
       "            0.955  , 0.9546 , 0.954  , 0.9526 , 0.9517 , 0.95   , 0.948  ,\n",
       "            0.9453 , 0.9424 , 0.941  , 0.94   , 0.9375 , 0.932  , 0.93   ,\n",
       "            0.928  , 0.9277 , 0.9272 , 0.91   , 0.9043 , 0.9014 , 0.8975 ,\n",
       "            0.892  , 0.884  , 0.8755 , 0.8604 , 0.8545 , 0.8535 , 0.839  ,\n",
       "            0.838  , 0.8345 , 0.8306 , 0.8213 , 0.8076 , 0.791  , 0.7905 ,\n",
       "            0.7793 , 0.7783 , 0.7725 , 0.771  , 0.767  , 0.7603 , 0.756  ,\n",
       "            0.7534 , 0.752  , 0.744  , 0.741  , 0.7383 , 0.738  , 0.729  ,\n",
       "            0.727  , 0.7256 , 0.718  , 0.7134 , 0.711  , 0.709  , 0.677  ,\n",
       "            0.672  , 0.6597 , 0.658  , 0.6577 , 0.6567 , 0.651  , 0.648  ,\n",
       "            0.643  , 0.639  , 0.638  , 0.634  , 0.624  , 0.6216 , 0.609  ,\n",
       "            0.6084 , 0.6074 , 0.602  , 0.5947 , 0.593  , 0.5884 , 0.588  ,\n",
       "            0.5874 , 0.5864 , 0.5835 , 0.5825 , 0.5815 , 0.574  , 0.572  ,\n",
       "            0.5684 , 0.5674 , 0.5586 , 0.558  , 0.555  , 0.5527 , 0.5522 ,\n",
       "            0.549  , 0.544  , 0.5425 , 0.542  , 0.5337 , 0.5327 , 0.5303 ,\n",
       "            0.529  , 0.528  , 0.527  , 0.5244 , 0.5234 , 0.5225 , 0.521  ,\n",
       "            0.5195 , 0.5166 , 0.5137 , 0.5127 , 0.5117 , 0.5107 , 0.5093 ,\n",
       "            0.5083 , 0.508  , 0.507  , 0.506  , 0.5024 , 0.4927 , 0.4897 ,\n",
       "            0.4893 , 0.4849 , 0.483  , 0.4824 , 0.4822 , 0.4797 , 0.4795 ,\n",
       "            0.4766 , 0.476  , 0.4753 , 0.4714 , 0.4702 , 0.4685 , 0.4663 ,\n",
       "            0.4653 , 0.4648 , 0.4636 , 0.461  , 0.459  , 0.4575 , 0.4556 ,\n",
       "            0.4548 , 0.4543 , 0.4517 , 0.4482 , 0.4475 , 0.445  , 0.4426 ,\n",
       "            0.4414 , 0.4353 , 0.4333 , 0.4326 , 0.4304 , 0.429  , 0.428  ,\n",
       "            0.4194 , 0.4192 , 0.4138 , 0.4033 , 0.4026 , 0.3906 , 0.39   ,\n",
       "            0.385  , 0.3777 , 0.372  , 0.3398 , 0.3276 , 0.3242 , 0.3171 ,\n",
       "            0.3093 , 0.3054 , 0.274  , 0.261  , 0.2524 , 0.251  , 0.2505 ,\n",
       "            0.2452 , 0.2363 , 0.2338 , 0.2252 , 0.2152 , 0.2125 , 0.2039 ,\n",
       "            0.1936 , 0.1838 , 0.1711 , 0.1709 , 0.1632 , 0.1532 , 0.1482 ,\n",
       "            0.1455 , 0.145  , 0.1438 , 0.1294 , 0.1047 , 0.0964 , 0.0863 ,\n",
       "            0.07965, 0.0786 , 0.0775 , 0.0741 , 0.07043, 0.0698 , 0.0683 ,\n",
       "            0.0662 , 0.05664, 0.055  , 0.04327, 0.04123, 0.03607, 0.03476,\n",
       "            0.01799, 0.01312, 0.01045], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3898305, dtype=float32),\n",
       "    'tpr': array(0.8712121, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3644068 , 0.38135594,\n",
       "            0.38135594, 0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.46969697, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.7121212 , 0.7121212 ,\n",
       "            0.72727275, 0.74242425, 0.75      , 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.8333333 , 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.995  , 0.9893 , 0.989  , 0.9883 , 0.9873 , 0.987  ,\n",
       "            0.9854 , 0.985  , 0.983  , 0.982  , 0.979  , 0.9785 , 0.973  ,\n",
       "            0.9717 , 0.9697 , 0.968  , 0.967  , 0.965  , 0.9644 , 0.9634 ,\n",
       "            0.9624 , 0.961  , 0.9604 , 0.96   , 0.959  , 0.958  , 0.956  ,\n",
       "            0.9546 , 0.952  , 0.9497 , 0.948  , 0.9478 , 0.9473 , 0.9443 ,\n",
       "            0.94   , 0.9375 , 0.9365 , 0.936  , 0.9204 , 0.914  , 0.9116 ,\n",
       "            0.9087 , 0.9067 , 0.904  , 0.896  , 0.887  , 0.872  , 0.8696 ,\n",
       "            0.8667 , 0.856  , 0.8545 , 0.8535 , 0.8516 , 0.834  , 0.8184 ,\n",
       "            0.807  , 0.8057 , 0.803  , 0.7983 , 0.7954 , 0.792  , 0.7905 ,\n",
       "            0.7827 , 0.7725 , 0.772  , 0.769  , 0.7656 , 0.7583 , 0.757  ,\n",
       "            0.7544 , 0.7515 , 0.7505 , 0.75   , 0.7397 , 0.7373 , 0.7275 ,\n",
       "            0.721  , 0.7046 , 0.7007 , 0.6895 , 0.6846 , 0.684  , 0.682  ,\n",
       "            0.679  , 0.6704 , 0.6646 , 0.664  , 0.6636 , 0.662  , 0.6553 ,\n",
       "            0.653  , 0.64   , 0.6367 , 0.634  , 0.6313 , 0.63   , 0.625  ,\n",
       "            0.6235 , 0.617  , 0.6167 , 0.6147 , 0.6133 , 0.6094 , 0.604  ,\n",
       "            0.6025 , 0.599  , 0.5977 , 0.595  , 0.5947 , 0.593  , 0.589  ,\n",
       "            0.5884 , 0.583  , 0.5806 , 0.578  , 0.5776 , 0.574  , 0.572  ,\n",
       "            0.5713 , 0.5596 , 0.558  , 0.5547 , 0.554  , 0.553  , 0.5527 ,\n",
       "            0.552  , 0.5503 , 0.5493 , 0.547  , 0.546  , 0.543  , 0.5405 ,\n",
       "            0.539  , 0.537  , 0.536  , 0.534  , 0.533  , 0.531  , 0.527  ,\n",
       "            0.5186 , 0.5156 , 0.5083 , 0.5073 , 0.505  , 0.5044 , 0.5024 ,\n",
       "            0.4995 , 0.4983 , 0.4976 , 0.495  , 0.4922 , 0.4897 , 0.4846 ,\n",
       "            0.4841 , 0.482  , 0.4817 , 0.4807 , 0.48   , 0.4797 , 0.4785 ,\n",
       "            0.4739 , 0.4712 , 0.4705 , 0.467  , 0.4656 , 0.4646 , 0.4634 ,\n",
       "            0.462  , 0.457  , 0.4553 , 0.453  , 0.4524 , 0.4507 , 0.4448 ,\n",
       "            0.4385 , 0.4338 , 0.4297 , 0.4277 , 0.4229 , 0.4182 , 0.4067 ,\n",
       "            0.402  , 0.399  , 0.3809 , 0.3733 , 0.339  , 0.3267 , 0.3232 ,\n",
       "            0.3225 , 0.3083 , 0.304  , 0.2715 , 0.257  , 0.2487 , 0.2482 ,\n",
       "            0.2471 , 0.2428 , 0.2334 , 0.2307 , 0.2222 , 0.2118 , 0.2084 ,\n",
       "            0.2007 , 0.1898 , 0.1797 , 0.1663 , 0.1661 , 0.1593 , 0.1469 ,\n",
       "            0.1443 , 0.1415 , 0.1409 , 0.1376 , 0.1232 , 0.0995 , 0.0914 ,\n",
       "            0.08124, 0.07477, 0.07367, 0.07275, 0.0694 , 0.06573, 0.06537,\n",
       "            0.06384, 0.06152, 0.0527 , 0.05234, 0.05072, 0.0398 , 0.03748,\n",
       "            0.03302, 0.0318 , 0.01602, 0.01147, 0.00909], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.44067797, dtype=float32),\n",
       "    'tpr': array(0.9166667, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.03389831, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.04545455,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84090906, 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.996   , 0.991   , 0.9907  , 0.9897  , 0.9883  ,\n",
       "            0.988   , 0.986   , 0.985   , 0.983   , 0.9824  , 0.978   ,\n",
       "            0.9766  , 0.975   , 0.973   , 0.9727  , 0.97    , 0.9697  ,\n",
       "            0.9688  , 0.9683  , 0.9673  , 0.967   , 0.966   , 0.964   ,\n",
       "            0.9624  , 0.9614  , 0.9595  , 0.957   , 0.956   , 0.9556  ,\n",
       "            0.9546  , 0.952   , 0.948   , 0.9463  , 0.946   , 0.945   ,\n",
       "            0.9316  , 0.9243  , 0.923   , 0.9204  , 0.917   , 0.916   ,\n",
       "            0.909   , 0.9004  , 0.886   , 0.885   , 0.8813  , 0.8755  ,\n",
       "            0.8735  , 0.872   , 0.871   , 0.8486  , 0.829   , 0.8286  ,\n",
       "            0.8247  , 0.8228  , 0.8203  , 0.82    , 0.8184  , 0.812   ,\n",
       "            0.797   , 0.7954  , 0.7944  , 0.792   , 0.783   , 0.782   ,\n",
       "            0.7803  , 0.7783  , 0.778   , 0.777   , 0.775   , 0.765   ,\n",
       "            0.7637  , 0.749   , 0.736   , 0.7324  , 0.7314  , 0.7236  ,\n",
       "            0.713   , 0.712   , 0.7104  , 0.71    , 0.6973  , 0.6953  ,\n",
       "            0.693   , 0.691   , 0.6846  , 0.6836  , 0.6685  , 0.6587  ,\n",
       "            0.658   , 0.6577  , 0.657   , 0.656   , 0.6494  , 0.649   ,\n",
       "            0.647   , 0.645   , 0.6377  , 0.63    , 0.6294  , 0.6265  ,\n",
       "            0.625   , 0.6226  , 0.622   , 0.616   , 0.613   , 0.611   ,\n",
       "            0.6094  , 0.6035  , 0.603   , 0.5996  , 0.5923  , 0.5894  ,\n",
       "            0.589   , 0.5845  , 0.584   , 0.583   , 0.582   , 0.5806  ,\n",
       "            0.58    , 0.579   , 0.577   , 0.5737  , 0.5728  , 0.5723  ,\n",
       "            0.57    , 0.568   , 0.566   , 0.564   , 0.5635  , 0.5605  ,\n",
       "            0.5566  , 0.55    , 0.549   , 0.546   , 0.537   , 0.5366  ,\n",
       "            0.534   , 0.532   , 0.5303  , 0.53    , 0.529   , 0.5283  ,\n",
       "            0.5244  , 0.5234  , 0.5205  , 0.5137  , 0.5107  , 0.5083  ,\n",
       "            0.508   , 0.5063  , 0.4998  , 0.4993  , 0.497   , 0.491   ,\n",
       "            0.4873  , 0.4858  , 0.4844  , 0.4824  , 0.4814  , 0.4795  ,\n",
       "            0.4758  , 0.4749  , 0.4746  , 0.4639  , 0.4617  , 0.4585  ,\n",
       "            0.4583  , 0.4468  , 0.4363  , 0.4358  , 0.4316  , 0.4265  ,\n",
       "            0.4172  , 0.4155  , 0.3848  , 0.3755  , 0.3381  , 0.3315  ,\n",
       "            0.326   , 0.3206  , 0.3074  , 0.3025  , 0.2693  , 0.2527  ,\n",
       "            0.2462  , 0.2451  , 0.243   , 0.2401  , 0.2303  , 0.2277  ,\n",
       "            0.2191  , 0.2084  , 0.204   , 0.1976  , 0.1859  , 0.1752  ,\n",
       "            0.1614  , 0.1609  , 0.156   , 0.1404  , 0.14    , 0.138   ,\n",
       "            0.1375  , 0.1312  , 0.1166  , 0.0942  , 0.0863  , 0.076   ,\n",
       "            0.06995 , 0.06866 , 0.06793 , 0.0645  , 0.06097 , 0.06085 ,\n",
       "            0.05933 , 0.05676 , 0.04895 , 0.04794 , 0.0464  , 0.03662 ,\n",
       "            0.03384 , 0.03021 , 0.02904 , 0.014114, 0.009895, 0.00784 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.47457626, dtype=float32),\n",
       "    'tpr': array(0.9469697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.33898306, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.3559322 , 0.3644068 , 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.57575756, 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6136364 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.997   , 0.9927  , 0.992   , 0.9917  , 0.991   ,\n",
       "            0.99    , 0.9897  , 0.9883  , 0.9873  , 0.986   , 0.985   ,\n",
       "            0.981   , 0.98    , 0.9785  , 0.977   , 0.976   , 0.974   ,\n",
       "            0.9736  , 0.9727  , 0.9717  , 0.971   , 0.97    , 0.9688  ,\n",
       "            0.967   , 0.9663  , 0.9644  , 0.9624  , 0.9614  , 0.96    ,\n",
       "            0.9575  , 0.954   , 0.9526  , 0.952   , 0.9517  , 0.951   ,\n",
       "            0.939   , 0.9316  , 0.931   , 0.9287  , 0.925   , 0.9185  ,\n",
       "            0.9097  , 0.897   , 0.894   , 0.8916  , 0.8877  , 0.8867  ,\n",
       "            0.8843  , 0.883   , 0.8594  , 0.844   , 0.838   , 0.8374  ,\n",
       "            0.836   , 0.8354  , 0.8345  , 0.834   , 0.829   , 0.8267  ,\n",
       "            0.8145  , 0.811   , 0.809   , 0.8003  , 0.796   , 0.7944  ,\n",
       "            0.793   , 0.7925  , 0.791   , 0.7817  , 0.781   , 0.764   ,\n",
       "            0.757   , 0.754   , 0.747   , 0.7407  , 0.733   , 0.7324  ,\n",
       "            0.73    , 0.728   , 0.7207  , 0.716   , 0.7124  , 0.711   ,\n",
       "            0.7095  , 0.707   , 0.699   , 0.6934  , 0.691   , 0.6826  ,\n",
       "            0.682   , 0.6753  , 0.6733  , 0.6724  , 0.672   , 0.6714  ,\n",
       "            0.6675  , 0.6577  , 0.652   , 0.65    , 0.648   , 0.647   ,\n",
       "            0.644   , 0.641   , 0.6406  , 0.636   , 0.6353  , 0.635   ,\n",
       "            0.6274  , 0.6265  , 0.6216  , 0.6187  , 0.6147  , 0.613   ,\n",
       "            0.612   , 0.6113  , 0.6104  , 0.6074  , 0.6064  , 0.6045  ,\n",
       "            0.604   , 0.602   , 0.6016  , 0.6     , 0.5996  , 0.599   ,\n",
       "            0.597   , 0.595   , 0.594   , 0.591   , 0.59    , 0.589   ,\n",
       "            0.587   , 0.5864  , 0.584   , 0.5737  , 0.573   , 0.57    ,\n",
       "            0.5664  , 0.561   , 0.5605  , 0.558   , 0.552   , 0.551   ,\n",
       "            0.5483  , 0.5464  , 0.545   , 0.544   , 0.543   , 0.5347  ,\n",
       "            0.5327  , 0.532   , 0.5273  , 0.527   , 0.5264  , 0.526   ,\n",
       "            0.523   , 0.517   , 0.516   , 0.5156  , 0.513   , 0.5083  ,\n",
       "            0.5073  , 0.5044  , 0.4998  , 0.4958  , 0.4956  , 0.4907  ,\n",
       "            0.4814  , 0.48    , 0.4797  , 0.4768  , 0.4668  , 0.46    ,\n",
       "            0.452   , 0.4443  , 0.439   , 0.4329  , 0.4304  , 0.4302  ,\n",
       "            0.3845  , 0.375   , 0.338   , 0.3362  , 0.3237  , 0.3176  ,\n",
       "            0.3047  , 0.2998  , 0.2659  , 0.2485  , 0.2428  , 0.2406  ,\n",
       "            0.2384  , 0.2362  , 0.2263  , 0.2235  , 0.2148  , 0.2039  ,\n",
       "            0.199   , 0.1935  , 0.1814  , 0.1699  , 0.1561  , 0.1556  ,\n",
       "            0.1517  , 0.136   , 0.1342  , 0.1338  , 0.133   , 0.1251  ,\n",
       "            0.11084 , 0.0888  , 0.08136 , 0.07135 , 0.06537 , 0.0641  ,\n",
       "            0.06335 , 0.0602  , 0.05676 , 0.05655 , 0.0552  , 0.0526  ,\n",
       "            0.04526 , 0.04428 , 0.04263 , 0.03354 , 0.03073 , 0.02748 ,\n",
       "            0.02641 , 0.01257 , 0.008675, 0.00685 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5084746, dtype=float32),\n",
       "    'tpr': array(0.9621212, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.22881356, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.3898305 , 0.3983051 , 0.41525424, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.13636364, 0.14393939,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.57575756, 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6515151 , 0.6515151 ,\n",
       "            0.6515151 , 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.81060606,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9976 , 0.994  , 0.9937 , 0.993  , 0.9927 , 0.992  ,\n",
       "            0.9917 , 0.99   , 0.9893 , 0.9883 , 0.9873 , 0.984  , 0.983  ,\n",
       "            0.982  , 0.98   , 0.978  , 0.977  , 0.9766 , 0.9756 , 0.975  ,\n",
       "            0.9746 , 0.974  , 0.9727 , 0.971  , 0.9707 , 0.9688 , 0.967  ,\n",
       "            0.9663 , 0.965  , 0.9624 , 0.9595 , 0.9585 , 0.958  , 0.9575 ,\n",
       "            0.957  , 0.9463 , 0.939  , 0.9385 , 0.937  , 0.933  , 0.932  ,\n",
       "            0.9277 , 0.919  , 0.908  , 0.904  , 0.902  , 0.9    , 0.896  ,\n",
       "            0.895  , 0.87   , 0.8604 , 0.8525 , 0.851  , 0.8506 , 0.8486 ,\n",
       "            0.848  , 0.8467 , 0.8447 , 0.8413 , 0.8325 , 0.8267 , 0.824  ,\n",
       "            0.819  , 0.814  , 0.813  , 0.8115 , 0.808  , 0.801  , 0.7993 ,\n",
       "            0.799  , 0.78   , 0.779  , 0.7764 , 0.7725 , 0.7573 , 0.7524 ,\n",
       "            0.7495 , 0.7485 , 0.7476 , 0.746  , 0.7437 , 0.732  , 0.731  ,\n",
       "            0.729  , 0.721  , 0.716  , 0.7153 , 0.71   , 0.7085 , 0.6987 ,\n",
       "            0.698  , 0.6943 , 0.692  , 0.6855 , 0.681  , 0.677  , 0.6753 ,\n",
       "            0.675  , 0.6743 , 0.6714 , 0.669  , 0.6685 , 0.6655 , 0.663  ,\n",
       "            0.6626 , 0.6616 , 0.657  , 0.6543 , 0.6523 , 0.6465 , 0.6436 ,\n",
       "            0.6416 , 0.6387 , 0.6367 , 0.6357 , 0.6353 , 0.6333 , 0.6284 ,\n",
       "            0.628  , 0.6274 , 0.627  , 0.6265 , 0.624  , 0.623  , 0.622  ,\n",
       "            0.618  , 0.6177 , 0.6167 , 0.614  , 0.6123 , 0.612  , 0.611  ,\n",
       "            0.609  , 0.608  , 0.599  , 0.596  , 0.593  , 0.587  , 0.586  ,\n",
       "            0.5854 , 0.584  , 0.5767 , 0.575  , 0.5728 , 0.571  , 0.5693 ,\n",
       "            0.5674 , 0.566  , 0.56   , 0.5576 , 0.5537 , 0.55   , 0.548  ,\n",
       "            0.5474 , 0.547  , 0.537  , 0.5366 , 0.5356 , 0.533  , 0.5312 ,\n",
       "            0.531  , 0.524  , 0.5215 , 0.5176 , 0.517  , 0.5103 , 0.5024 ,\n",
       "            0.5    , 0.497  , 0.4875 , 0.4783 , 0.4692 , 0.4626 , 0.461  ,\n",
       "            0.4463 , 0.444  , 0.443  , 0.4326 , 0.3848 , 0.3748 , 0.3433 ,\n",
       "            0.333  , 0.321  , 0.3125 , 0.302  , 0.2964 , 0.2622 , 0.2438 ,\n",
       "            0.2391 , 0.2355 , 0.2332 , 0.2323 , 0.222  , 0.2194 , 0.2106 ,\n",
       "            0.1993 , 0.1936 , 0.1892 , 0.1768 , 0.1647 , 0.1506 , 0.1499 ,\n",
       "            0.1476 , 0.1316 , 0.1295 , 0.1289 , 0.1271 , 0.1186 , 0.1043 ,\n",
       "            0.0836 , 0.07666, 0.06647, 0.06076, 0.05942, 0.0589 , 0.05573,\n",
       "            0.0527 , 0.05212, 0.0511 , 0.0483 , 0.04178, 0.04037, 0.03882,\n",
       "            0.03067, 0.02759, 0.02493, 0.02396, 0.01103, 0.00746, 0.00589],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5254237, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.04545455,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.13636364, 0.14393939, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.8030303 , 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.82575756, 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.998   , 0.995   , 0.9946  , 0.994   , 0.993   ,\n",
       "            0.9927  , 0.9917  , 0.9907  , 0.9897  , 0.989   , 0.986   ,\n",
       "            0.985   , 0.984   , 0.9824  , 0.98    , 0.9795  , 0.979   ,\n",
       "            0.9785  , 0.978   , 0.9775  , 0.977   , 0.9756  , 0.9736  ,\n",
       "            0.972   , 0.97    , 0.9697  , 0.9683  , 0.966   , 0.9634  ,\n",
       "            0.963   , 0.962   , 0.9614  , 0.961   , 0.951   , 0.944   ,\n",
       "            0.9424  , 0.9385  , 0.9365  , 0.9336  , 0.9253  , 0.916   ,\n",
       "            0.9097  , 0.909   , 0.9087  , 0.9043  , 0.903   , 0.8774  ,\n",
       "            0.8726  , 0.863   , 0.862   , 0.8604  , 0.8594  , 0.857   ,\n",
       "            0.852   , 0.8477  , 0.845   , 0.84    , 0.8384  , 0.835   ,\n",
       "            0.834   , 0.8276  , 0.8267  , 0.823   , 0.821   , 0.8193  ,\n",
       "            0.8125  , 0.812   , 0.8037  , 0.8003  , 0.8     , 0.7974  ,\n",
       "            0.791   , 0.7817  , 0.7715  , 0.7705  , 0.7695  , 0.7656  ,\n",
       "            0.764   , 0.7563  , 0.75    , 0.7495  , 0.7476  , 0.747   ,\n",
       "            0.746   , 0.7407  , 0.7373  , 0.735   , 0.7275  , 0.726   ,\n",
       "            0.7246  , 0.724   , 0.7163  , 0.714   , 0.7104  , 0.7046  ,\n",
       "            0.7026  , 0.702   , 0.7017  , 0.701   , 0.697   , 0.696   ,\n",
       "            0.695   , 0.6914  , 0.689   , 0.6885  , 0.686   , 0.6816  ,\n",
       "            0.679   , 0.6743  , 0.672   , 0.6714  , 0.6675  , 0.6655  ,\n",
       "            0.6646  , 0.6626  , 0.6616  , 0.661   , 0.6597  , 0.655   ,\n",
       "            0.6543  , 0.6533  , 0.653   , 0.6523  , 0.652   , 0.6514  ,\n",
       "            0.6475  , 0.6465  , 0.646   , 0.6455  , 0.64    , 0.6396  ,\n",
       "            0.6387  , 0.6377  , 0.6357  , 0.6304  , 0.6265  , 0.6235  ,\n",
       "            0.6143  , 0.613   , 0.6123  , 0.6113  , 0.609   , 0.604   ,\n",
       "            0.6035  , 0.5996  , 0.597   , 0.5967  , 0.5938  , 0.5923  ,\n",
       "            0.592   , 0.5913  , 0.59    , 0.5854  , 0.583   , 0.576   ,\n",
       "            0.5737  , 0.573   , 0.5703  , 0.5693  , 0.562   , 0.5586  ,\n",
       "            0.557   , 0.556   , 0.555   , 0.5527  , 0.546   , 0.5454  ,\n",
       "            0.541   , 0.5405  , 0.527   , 0.5254  , 0.525   , 0.516   ,\n",
       "            0.5093  , 0.5083  , 0.4888  , 0.4824  , 0.4753  , 0.4639  ,\n",
       "            0.4607  , 0.459   , 0.4475  , 0.4268  , 0.385   , 0.374   ,\n",
       "            0.3503  , 0.3271  , 0.3171  , 0.302   , 0.2988  , 0.2922  ,\n",
       "            0.2573  , 0.2363  , 0.2356  , 0.2295  , 0.2285  , 0.2266  ,\n",
       "            0.2179  , 0.2152  , 0.2068  , 0.195   , 0.1877  , 0.186   ,\n",
       "            0.1725  , 0.1597  , 0.1454  , 0.1445  , 0.1438  , 0.128   ,\n",
       "            0.1262  , 0.1259  , 0.11816 , 0.11145 , 0.09705 , 0.0789  ,\n",
       "            0.07263 , 0.0619  , 0.05664 , 0.055   , 0.0548  , 0.05176 ,\n",
       "            0.0494  , 0.04803 , 0.0476  , 0.0441  , 0.03897 , 0.03662 ,\n",
       "            0.03516 , 0.02834 , 0.02461 , 0.02298 , 0.02216 , 0.00974 ,\n",
       "            0.006363, 0.00508 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5338983, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.06779661, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.41525424, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.04545455,\n",
       "            0.0530303 , 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.13636364, 0.14393939, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.27272728, 0.28030303, 0.28787878, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.4848485 , 0.49242425, 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9985  , 0.996   , 0.9956  , 0.995   , 0.9946  ,\n",
       "            0.994   , 0.993   , 0.992   , 0.991   , 0.9907  , 0.9883  ,\n",
       "            0.9873  , 0.9863  , 0.985   , 0.983   , 0.9824  , 0.982   ,\n",
       "            0.9814  , 0.981   , 0.9805  , 0.98    , 0.9785  , 0.9775  ,\n",
       "            0.977   , 0.9756  , 0.974   , 0.9727  , 0.97    , 0.968   ,\n",
       "            0.967   , 0.9663  , 0.9653  , 0.957   , 0.95    , 0.9497  ,\n",
       "            0.9487  , 0.946   , 0.942   , 0.941   , 0.933   , 0.9253  ,\n",
       "            0.92    , 0.919   , 0.9185  , 0.9175  , 0.9146  , 0.913   ,\n",
       "            0.8867  , 0.886   , 0.876   , 0.8755  , 0.8726  , 0.8677  ,\n",
       "            0.865   , 0.86    , 0.854   , 0.8525  , 0.8486  , 0.8438  ,\n",
       "            0.843   , 0.8374  , 0.836   , 0.833   , 0.828   , 0.82    ,\n",
       "            0.8174  , 0.8105  , 0.8057  , 0.802   , 0.7935  , 0.793   ,\n",
       "            0.7896  , 0.7837  , 0.782   , 0.7773  , 0.77    , 0.7686  ,\n",
       "            0.7666  , 0.763   , 0.7617  , 0.76    , 0.7573  , 0.7563  ,\n",
       "            0.749   , 0.7466  , 0.746   , 0.7427  , 0.738   , 0.733   ,\n",
       "            0.729   , 0.726   , 0.7256  , 0.723   , 0.72    , 0.7173  ,\n",
       "            0.7153  , 0.712   , 0.7075  , 0.707   , 0.7065  , 0.7046  ,\n",
       "            0.7017  , 0.6973  , 0.6963  , 0.692   , 0.6885  , 0.6875  ,\n",
       "            0.6846  , 0.6826  , 0.682   , 0.6807  , 0.6777  , 0.6772  ,\n",
       "            0.6753  , 0.675   , 0.6743  , 0.674   , 0.6714  , 0.668   ,\n",
       "            0.6675  , 0.667   , 0.661   , 0.6606  , 0.659   , 0.657   ,\n",
       "            0.6504  , 0.649   , 0.646   , 0.6367  , 0.635   , 0.634   ,\n",
       "            0.6304  , 0.625   , 0.6216  , 0.6206  , 0.6187  , 0.616   ,\n",
       "            0.615   , 0.6123  , 0.6113  , 0.6104  , 0.6094  , 0.6074  ,\n",
       "            0.6045  , 0.5947  , 0.5938  , 0.5894  , 0.588   , 0.583   ,\n",
       "            0.579   , 0.577   , 0.5747  , 0.573   , 0.569   , 0.565   ,\n",
       "            0.564   , 0.5605  , 0.56    , 0.547   , 0.544   , 0.537   ,\n",
       "            0.5312  , 0.528   , 0.514   , 0.5044  , 0.499   , 0.478   ,\n",
       "            0.4758  , 0.4695  , 0.4607  , 0.45    , 0.4253  , 0.3838  ,\n",
       "            0.3723  , 0.3535  , 0.3223  , 0.3135  , 0.2961  , 0.295   ,\n",
       "            0.288   , 0.253   , 0.2319  , 0.2303  , 0.2239  , 0.2238  ,\n",
       "            0.2208  , 0.213   , 0.2103  , 0.2018  , 0.19    , 0.1821  ,\n",
       "            0.1814  , 0.1675  , 0.154   , 0.1404  , 0.1399  , 0.138   ,\n",
       "            0.12366 , 0.12213 , 0.12177 , 0.1118  , 0.1056  , 0.09125 ,\n",
       "            0.0742  , 0.06854 , 0.0577  , 0.05283 , 0.0511  , 0.0509  ,\n",
       "            0.04794 , 0.0461  , 0.04434 , 0.0442  , 0.04053 , 0.03622 ,\n",
       "            0.03348 , 0.0321  , 0.0262  , 0.0222  , 0.02116 , 0.02045 ,\n",
       "            0.008675, 0.005535, 0.004433], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5423729, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.2457627 , 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.2881356 , 0.2881356 , 0.29661018, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.04545455,\n",
       "            0.06060606, 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.74242425, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.8181818 , 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9985  , 0.9966  , 0.996   , 0.9956  , 0.995   ,\n",
       "            0.9946  , 0.9937  , 0.993   , 0.992   , 0.9917  , 0.9893  ,\n",
       "            0.989   , 0.9883  , 0.988   , 0.9863  , 0.9844  , 0.984   ,\n",
       "            0.9834  , 0.983   , 0.9824  , 0.982   , 0.9805  , 0.979   ,\n",
       "            0.9775  , 0.976   , 0.9756  , 0.9746  , 0.972   , 0.97    ,\n",
       "            0.9697  , 0.969   , 0.9688  , 0.9673  , 0.96    , 0.953   ,\n",
       "            0.9526  , 0.9517  , 0.9487  , 0.945   , 0.9443  , 0.9365  ,\n",
       "            0.929   , 0.9243  , 0.923   , 0.9224  , 0.921   , 0.918   ,\n",
       "            0.917   , 0.8916  , 0.8906  , 0.882   , 0.8804  , 0.88    ,\n",
       "            0.877   , 0.8726  , 0.87    , 0.8647  , 0.859   , 0.8574  ,\n",
       "            0.855   , 0.854   , 0.8535  , 0.849   , 0.848   , 0.8423  ,\n",
       "            0.841   , 0.838   , 0.834   , 0.8335  , 0.8296  , 0.829   ,\n",
       "            0.827   , 0.8115  , 0.811   , 0.8105  , 0.805   , 0.8037  ,\n",
       "            0.799   , 0.79    , 0.789   , 0.7876  , 0.7812  , 0.777   ,\n",
       "            0.775   , 0.772   , 0.771   , 0.769   , 0.761   , 0.7583  ,\n",
       "            0.757   , 0.7554  , 0.7485  , 0.748   , 0.7407  , 0.7383  ,\n",
       "            0.737   , 0.736   , 0.735   , 0.734   , 0.733   , 0.7285  ,\n",
       "            0.728   , 0.7246  , 0.724   , 0.7173  , 0.7163  , 0.715   ,\n",
       "            0.714   , 0.713   , 0.7124  , 0.71    , 0.7085  , 0.7056  ,\n",
       "            0.7007  , 0.6963  , 0.6943  , 0.6934  , 0.6924  , 0.6904  ,\n",
       "            0.6895  , 0.689   , 0.6885  , 0.6875  , 0.6855  , 0.685   ,\n",
       "            0.684   , 0.678   , 0.6777  , 0.6753  , 0.674   , 0.672   ,\n",
       "            0.6714  , 0.665   , 0.662   , 0.6606  , 0.653   , 0.651   ,\n",
       "            0.65    , 0.641   , 0.6396  , 0.635   , 0.6343  , 0.631   ,\n",
       "            0.63    , 0.625   , 0.6245  , 0.623   , 0.622   , 0.6123  ,\n",
       "            0.6084  , 0.608   , 0.603   , 0.6006  , 0.5977  , 0.5903  ,\n",
       "            0.59    , 0.5845  , 0.58    , 0.579   , 0.577   , 0.5767  ,\n",
       "            0.5747  , 0.5645  , 0.56    , 0.5464  , 0.5435  , 0.5425  ,\n",
       "            0.5166  , 0.515   , 0.514   , 0.4907  , 0.4773  , 0.469   ,\n",
       "            0.4556  , 0.4482  , 0.4167  , 0.3787  , 0.3667  , 0.3547  ,\n",
       "            0.313   , 0.3054  , 0.2878  , 0.2842  , 0.28    , 0.2451  ,\n",
       "            0.2257  , 0.2212  , 0.2172  , 0.215   , 0.2119  , 0.2059  ,\n",
       "            0.2034  , 0.1952  , 0.183   , 0.1755  , 0.1741  , 0.1609  ,\n",
       "            0.1472  , 0.1359  , 0.1329  , 0.1298  , 0.1188  , 0.1178  ,\n",
       "            0.11755 , 0.1034  , 0.0979  , 0.08417 , 0.06915 , 0.0641  ,\n",
       "            0.0531  , 0.04858 , 0.0468  , 0.044   , 0.04263 , 0.04062 ,\n",
       "            0.04037 , 0.03656 , 0.03348 , 0.0301  , 0.02881 , 0.02405 ,\n",
       "            0.01968 , 0.01935 , 0.01869 , 0.007607, 0.00472 , 0.003809],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5423729, dtype=float32),\n",
       "    'tpr': array(0.97727275, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.19491525, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33050847, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.03030303, 0.04545455, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.13636364, 0.14393939, 0.1590909 , 0.16666667,\n",
       "            0.18181819, 0.18939394, 0.20454545, 0.21969697, 0.22727273,\n",
       "            0.24242425, 0.25      , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.6969697 , 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.75      , 0.75757575, 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.7878788 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.999   , 0.997   , 0.9966  , 0.996   , 0.9956  ,\n",
       "            0.995   , 0.9946  , 0.9937  , 0.993   , 0.991   , 0.9907  ,\n",
       "            0.99    , 0.989   , 0.9873  , 0.987   , 0.9863  , 0.986   ,\n",
       "            0.9854  , 0.984   , 0.983   , 0.9814  , 0.98    , 0.979   ,\n",
       "            0.977   , 0.975   , 0.974   , 0.9736  , 0.973   , 0.9663  ,\n",
       "            0.96    , 0.959   , 0.956   , 0.953   , 0.952   , 0.9453  ,\n",
       "            0.939   , 0.935   , 0.9326  , 0.932   , 0.9287  , 0.928   ,\n",
       "            0.905   , 0.9043  , 0.8955  , 0.894   , 0.8916  , 0.891   ,\n",
       "            0.887   , 0.885   , 0.8804  , 0.8735  , 0.871   , 0.87    ,\n",
       "            0.869   , 0.8643  , 0.864   , 0.859   , 0.858   , 0.8545  ,\n",
       "            0.8516  , 0.851   , 0.849   , 0.8486  , 0.846   , 0.833   ,\n",
       "            0.829   , 0.8286  , 0.828   , 0.8257  , 0.821   , 0.81    ,\n",
       "            0.8037  , 0.799   , 0.7964  , 0.7954  , 0.7944  , 0.7925  ,\n",
       "            0.789   , 0.784   , 0.7817  , 0.781   , 0.775   , 0.772   ,\n",
       "            0.7676  , 0.7627  , 0.762   , 0.7593  , 0.759   , 0.758   ,\n",
       "            0.757   , 0.7534  , 0.752   , 0.7495  , 0.7485  , 0.742   ,\n",
       "            0.7397  , 0.7393  , 0.739   , 0.7373  , 0.736   , 0.7334  ,\n",
       "            0.73    , 0.726   , 0.721   , 0.72    , 0.719   , 0.7188  ,\n",
       "            0.7173  , 0.717   , 0.7163  , 0.715   , 0.7124  , 0.7114  ,\n",
       "            0.7104  , 0.71    , 0.7026  , 0.702   , 0.7017  , 0.7     ,\n",
       "            0.6987  , 0.696   , 0.6924  , 0.6895  , 0.6846  , 0.68    ,\n",
       "            0.678   , 0.6772  , 0.668   , 0.663   , 0.661   , 0.6606  ,\n",
       "            0.657   , 0.6553  , 0.653   , 0.6504  , 0.65    , 0.6484  ,\n",
       "            0.648   , 0.6475  , 0.6465  , 0.637   , 0.634   , 0.633   ,\n",
       "            0.6294  , 0.6284  , 0.6255  , 0.625   , 0.6235  , 0.615   ,\n",
       "            0.6147  , 0.608   , 0.6055  , 0.602   , 0.601   , 0.6006  ,\n",
       "            0.6     , 0.588   , 0.584   , 0.5703  , 0.5645  , 0.563   ,\n",
       "            0.538   , 0.5356  , 0.5327  , 0.5103  , 0.4944  , 0.4832  ,\n",
       "            0.4685  , 0.462   , 0.4314  , 0.3877  , 0.3755  , 0.3628  ,\n",
       "            0.32    , 0.3123  , 0.293   , 0.292   , 0.2856  , 0.2482  ,\n",
       "            0.2274  , 0.226   , 0.2186  , 0.2175  , 0.2145  , 0.2074  ,\n",
       "            0.2047  , 0.1959  , 0.1835  , 0.1755  , 0.1746  , 0.1606  ,\n",
       "            0.1461  , 0.1339  , 0.1318  , 0.1283  , 0.1172  , 0.11554 ,\n",
       "            0.1152  , 0.1036  , 0.0964  , 0.0825  , 0.06647 , 0.0613  ,\n",
       "            0.0508  , 0.0462  , 0.0446  , 0.04453 , 0.04178 , 0.04025 ,\n",
       "            0.0384  , 0.03833 , 0.03482 , 0.03102 , 0.02844 , 0.02718 ,\n",
       "            0.02203 , 0.01837 , 0.01758 , 0.01692 , 0.00685 , 0.0043  ,\n",
       "            0.003376], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5423729, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.1440678 , 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.16949153, 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.2542373 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.2881356 , 0.2881356 , 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3983051 , 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.03030303, 0.0530303 , 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.1590909 , 0.16666667, 0.18181819,\n",
       "            0.1969697 , 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.27272728, 0.28030303, 0.28787878, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.79545456, 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.999   , 0.9976  , 0.997   , 0.9966  , 0.996   ,\n",
       "            0.9956  , 0.995   , 0.9946  , 0.9927  , 0.992   , 0.9917  ,\n",
       "            0.9907  , 0.9893  , 0.989   , 0.9883  , 0.988   , 0.9873  ,\n",
       "            0.9863  , 0.9854  , 0.9844  , 0.983   , 0.982   , 0.9805  ,\n",
       "            0.9785  , 0.978   , 0.9775  , 0.9766  , 0.9707  , 0.9653  ,\n",
       "            0.964   , 0.962   , 0.9585  , 0.958   , 0.952   , 0.9463  ,\n",
       "            0.944   , 0.9414  , 0.9404  , 0.94    , 0.9375  , 0.9365  ,\n",
       "            0.916   , 0.914   , 0.9077  , 0.9062  , 0.9053  , 0.9023  ,\n",
       "            0.902   , 0.898   , 0.8965  , 0.893   , 0.8867  , 0.886   ,\n",
       "            0.8833  , 0.8823  , 0.881   , 0.8774  , 0.877   , 0.8726  ,\n",
       "            0.8687  , 0.8657  , 0.8647  , 0.8643  , 0.863   , 0.8506  ,\n",
       "            0.847   , 0.844   , 0.8433  , 0.84    , 0.8394  , 0.8296  ,\n",
       "            0.8286  , 0.828   , 0.8247  , 0.818   , 0.8154  , 0.8135  ,\n",
       "            0.806   , 0.8057  , 0.803   , 0.8022  , 0.7935  , 0.7866  ,\n",
       "            0.785   , 0.7847  , 0.782   , 0.7812  , 0.7803  , 0.78    ,\n",
       "            0.7783  , 0.774   , 0.773   , 0.772   , 0.766   , 0.765   ,\n",
       "            0.7637  , 0.7617  , 0.761   , 0.7593  , 0.757   , 0.75    ,\n",
       "            0.7456  , 0.7446  , 0.7437  , 0.743   , 0.742   , 0.741   ,\n",
       "            0.7407  , 0.7363  , 0.735   , 0.7334  , 0.733   , 0.726   ,\n",
       "            0.7256  , 0.725   , 0.7246  , 0.724   , 0.723   , 0.7183  ,\n",
       "            0.717   , 0.714   , 0.7065  , 0.7046  , 0.703   , 0.702   ,\n",
       "            0.693   , 0.6855  , 0.685   , 0.682   , 0.6787  , 0.6753  ,\n",
       "            0.6743  , 0.6724  , 0.672   , 0.6704  , 0.6685  , 0.6626  ,\n",
       "            0.6577  , 0.6553  , 0.6514  , 0.6494  , 0.648   , 0.64    ,\n",
       "            0.6396  , 0.6377  , 0.63    , 0.6294  , 0.625   , 0.624   ,\n",
       "            0.6235  , 0.623   , 0.612   , 0.6074  , 0.595   , 0.5854  ,\n",
       "            0.58    , 0.5596  , 0.5576  , 0.5454  , 0.5303  , 0.508   ,\n",
       "            0.491   , 0.4753  , 0.471   , 0.4375  , 0.3923  , 0.3796  ,\n",
       "            0.3691  , 0.321   , 0.3137  , 0.2937  , 0.2913  , 0.2856  ,\n",
       "            0.2473  , 0.2268  , 0.2255  , 0.2175  , 0.2157  , 0.2125  ,\n",
       "            0.2059  , 0.2032  , 0.1942  , 0.181   , 0.1737  , 0.172   ,\n",
       "            0.158   , 0.1432  , 0.1311  , 0.1287  , 0.1243  , 0.1144  ,\n",
       "            0.1126  , 0.1122  , 0.0998  , 0.09235 , 0.0786  , 0.06305 ,\n",
       "            0.05814 , 0.0478  , 0.04337 , 0.04178 , 0.0417  , 0.03906 ,\n",
       "            0.0377  , 0.03583 , 0.0323  , 0.02881 , 0.0262  , 0.025   ,\n",
       "            0.02022 , 0.01672 , 0.01602 , 0.01543 , 0.006073, 0.00378 ,\n",
       "            0.002947], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5508475, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.04545455, 0.06818182, 0.07575758,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.18181819,\n",
       "            0.1969697 , 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.27272728, 0.28030303, 0.28787878, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.5       , 0.50757575,\n",
       "            0.52272725, 0.52272725, 0.5378788 , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6439394 , 0.6515151 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.998   , 0.9976  , 0.997   , 0.9966  ,\n",
       "            0.996   , 0.9956  , 0.994   , 0.9937  , 0.993   , 0.9927  ,\n",
       "            0.992   , 0.991   , 0.9907  , 0.99    , 0.9897  , 0.9893  ,\n",
       "            0.989   , 0.988   , 0.987   , 0.986   , 0.985   , 0.9834  ,\n",
       "            0.982   , 0.9814  , 0.981   , 0.98    , 0.9756  , 0.9697  ,\n",
       "            0.969   , 0.9673  , 0.964   , 0.9585  , 0.9546  , 0.9536  ,\n",
       "            0.951   , 0.948   , 0.9473  , 0.947   , 0.945   , 0.9297  ,\n",
       "            0.9233  , 0.923   , 0.9204  , 0.919   , 0.9146  , 0.914   ,\n",
       "            0.9097  , 0.9023  , 0.901   , 0.9004  , 0.8975  , 0.8945  ,\n",
       "            0.894   , 0.889   , 0.888   , 0.885   , 0.884   , 0.883   ,\n",
       "            0.8823  , 0.8726  , 0.871   , 0.8667  , 0.8623  , 0.861   ,\n",
       "            0.8555  , 0.853   , 0.852   , 0.8516  , 0.85    , 0.8438  ,\n",
       "            0.8423  , 0.8413  , 0.8403  , 0.8335  , 0.8315  , 0.8306  ,\n",
       "            0.829   , 0.8213  , 0.8145  , 0.811   , 0.81    , 0.809   ,\n",
       "            0.8086  , 0.805   , 0.804   , 0.803   , 0.8027  , 0.8022  ,\n",
       "            0.798   , 0.7974  , 0.796   , 0.7954  , 0.794   , 0.793   ,\n",
       "            0.7915  , 0.79    , 0.784   , 0.782   , 0.7773  , 0.7764  ,\n",
       "            0.776   , 0.7754  , 0.775   , 0.7734  , 0.773   , 0.7725  ,\n",
       "            0.7686  , 0.766   , 0.7646  , 0.764   , 0.762   , 0.7593  ,\n",
       "            0.7583  , 0.758   , 0.7563  , 0.756   , 0.7554  , 0.7495  ,\n",
       "            0.7485  , 0.7456  , 0.7373  , 0.737   , 0.7354  , 0.734   ,\n",
       "            0.7256  , 0.719   , 0.718   , 0.716   , 0.715   , 0.7104  ,\n",
       "            0.7095  , 0.7065  , 0.706   , 0.704   , 0.7017  , 0.699   ,\n",
       "            0.695   , 0.6904  , 0.687   , 0.6836  , 0.6826  , 0.682   ,\n",
       "            0.679   , 0.673   , 0.6694  , 0.6636  , 0.659   , 0.658   ,\n",
       "            0.657   , 0.655   , 0.652   , 0.643   , 0.6387  , 0.627   ,\n",
       "            0.6143  , 0.604   , 0.589   , 0.587   , 0.565   , 0.557   ,\n",
       "            0.5283  , 0.502   , 0.4875  , 0.4863  , 0.445   , 0.402   ,\n",
       "            0.389   , 0.3801  , 0.325   , 0.3188  , 0.2986  , 0.2915  ,\n",
       "            0.289   , 0.2493  , 0.2295  , 0.2249  , 0.2194  , 0.2166  ,\n",
       "            0.2133  , 0.2074  , 0.2045  , 0.1953  , 0.181   , 0.1747  ,\n",
       "            0.1715  , 0.1573  , 0.1421  , 0.1301  , 0.1273  , 0.1219  ,\n",
       "            0.11316 , 0.111   , 0.11084 , 0.0967  , 0.0896  , 0.07574 ,\n",
       "            0.06064 , 0.05594 , 0.04553 , 0.04123 , 0.03964 , 0.037   ,\n",
       "            0.03568 , 0.03384 , 0.03372 , 0.03021 , 0.02707 , 0.02443 ,\n",
       "            0.02324 , 0.0188  , 0.015305, 0.01484 , 0.01428 , 0.00547 ,\n",
       "            0.003338, 0.00259 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5508475, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.22881356, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.29661018, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.5       , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.03030303, 0.06818182, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.12878788, 0.14393939,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.24242425, 0.25      , 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.52272725, 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.9985  , 0.998   , 0.9976  , 0.997   ,\n",
       "            0.9966  , 0.996   , 0.995   , 0.9946  , 0.9937  , 0.9927  ,\n",
       "            0.992   , 0.9917  , 0.991   , 0.99    , 0.9897  , 0.989   ,\n",
       "            0.9883  , 0.988   , 0.9873  , 0.986   , 0.985   , 0.9844  ,\n",
       "            0.984   , 0.983   , 0.979   , 0.974   , 0.9736  , 0.9717  ,\n",
       "            0.9688  , 0.964   , 0.9604  , 0.96    , 0.9575  , 0.955   ,\n",
       "            0.954   , 0.9536  , 0.951   , 0.9385  , 0.932   , 0.9316  ,\n",
       "            0.9297  , 0.9287  , 0.924   , 0.92    , 0.9194  , 0.919   ,\n",
       "            0.913   , 0.912   , 0.9106  , 0.908   , 0.906   , 0.9053  ,\n",
       "            0.9004  , 0.9     , 0.8994  , 0.8975  , 0.897   , 0.8965  ,\n",
       "            0.895   , 0.894   , 0.8857  , 0.8804  , 0.8765  , 0.8745  ,\n",
       "            0.87    , 0.868   , 0.867   , 0.8667  , 0.8623  , 0.8604  ,\n",
       "            0.86    , 0.8594  , 0.858   , 0.857   , 0.8516  , 0.849   ,\n",
       "            0.848   , 0.8447  , 0.8403  , 0.8335  , 0.8306  , 0.83    ,\n",
       "            0.8296  , 0.8286  , 0.8276  , 0.826   , 0.823   , 0.8223  ,\n",
       "            0.822   , 0.821   , 0.818   , 0.8174  , 0.816   , 0.8154  ,\n",
       "            0.813   , 0.812   , 0.8096  , 0.8027  , 0.8022  , 0.801   ,\n",
       "            0.7974  , 0.797   , 0.7964  , 0.7954  , 0.7944  , 0.7905  ,\n",
       "            0.7896  , 0.786   , 0.7856  , 0.782   , 0.7817  , 0.7812  ,\n",
       "            0.7803  , 0.779   , 0.7773  , 0.777   , 0.7725  , 0.771   ,\n",
       "            0.7695  , 0.761   , 0.7593  , 0.7583  , 0.75    , 0.743   ,\n",
       "            0.742   , 0.74    , 0.7363  , 0.7354  , 0.735   , 0.7324  ,\n",
       "            0.731   , 0.7285  , 0.7256  , 0.725   , 0.722   , 0.7197  ,\n",
       "            0.7153  , 0.711   , 0.7085  , 0.708   , 0.703   , 0.6987  ,\n",
       "            0.6934  , 0.6895  , 0.684   , 0.683   , 0.682   , 0.6787  ,\n",
       "            0.6743  , 0.668   , 0.6636  , 0.653   , 0.6367  , 0.6216  ,\n",
       "            0.6123  , 0.611   , 0.58    , 0.579   , 0.544   , 0.513   ,\n",
       "            0.4978  , 0.4966  , 0.4563  , 0.4094  , 0.3958  , 0.3875  ,\n",
       "            0.3303  , 0.3232  , 0.3022  , 0.2961  , 0.292   , 0.251   ,\n",
       "            0.2303  , 0.2264  , 0.2198  , 0.2175  , 0.2144  , 0.2075  ,\n",
       "            0.2045  , 0.195   , 0.1803  , 0.174   , 0.171   , 0.156   ,\n",
       "            0.1406  , 0.1279  , 0.1257  , 0.1198  , 0.111   , 0.1086  ,\n",
       "            0.1084  , 0.096   , 0.0874  , 0.074   , 0.05823 , 0.0535  ,\n",
       "            0.04346 , 0.03918 , 0.0377  , 0.0376  , 0.03506 , 0.03366 ,\n",
       "            0.03198 , 0.03192 , 0.0286  , 0.02518 , 0.02298 , 0.02187 ,\n",
       "            0.0173  , 0.01428 , 0.013535, 0.01297 , 0.004925, 0.003052,\n",
       "            0.002314], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5677966, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.18644068, 0.18644068, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.3983051 , 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.03030303, 0.07575758, 0.08333334,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.13636364, 0.14393939,\n",
       "            0.1590909 , 0.18181819, 0.1969697 , 0.21969697, 0.22727273,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.40151516, 0.4090909 , 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.65909094, 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.75757575, 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   , 0.994   ,\n",
       "            0.9937  , 0.993   , 0.992   , 0.9917  , 0.991   , 0.9907  ,\n",
       "            0.99    , 0.9897  , 0.989   , 0.988   , 0.9873  , 0.986   ,\n",
       "            0.983   , 0.9785  , 0.978   , 0.9766  , 0.974   , 0.9736  ,\n",
       "            0.9697  , 0.968   , 0.965   , 0.9624  , 0.961   , 0.9595  ,\n",
       "            0.949   , 0.944   , 0.9414  , 0.9404  , 0.936   , 0.935   ,\n",
       "            0.9326  , 0.9316  , 0.9307  , 0.927   , 0.926   , 0.9243  ,\n",
       "            0.922   , 0.9204  , 0.92    , 0.914   , 0.913   , 0.9126  ,\n",
       "            0.912   , 0.9106  , 0.91    , 0.9097  , 0.904   , 0.9023  ,\n",
       "            0.8975  , 0.8945  , 0.8916  , 0.8877  , 0.886   , 0.8853  ,\n",
       "            0.879   , 0.8784  , 0.877   , 0.876   , 0.8755  , 0.8716  ,\n",
       "            0.869   , 0.8687  , 0.865   , 0.863   , 0.857   , 0.8545  ,\n",
       "            0.853   , 0.852   , 0.8506  , 0.848   , 0.8467  , 0.8457  ,\n",
       "            0.845   , 0.844   , 0.843   , 0.8423  , 0.841   , 0.8403  ,\n",
       "            0.8374  , 0.8335  , 0.827   , 0.8267  , 0.8257  , 0.823   ,\n",
       "            0.822   , 0.8203  , 0.816   , 0.815   , 0.812   , 0.807   ,\n",
       "            0.8066  , 0.8057  , 0.804   , 0.803   , 0.8027  , 0.8022  ,\n",
       "            0.801   , 0.7983  , 0.797   , 0.796   , 0.7876  , 0.7856  ,\n",
       "            0.785   , 0.7847  , 0.7764  , 0.77    , 0.7695  , 0.7666  ,\n",
       "            0.7637  , 0.7627  , 0.7617  , 0.7603  , 0.7583  , 0.756   ,\n",
       "            0.752   , 0.7485  , 0.7437  , 0.7383  , 0.7363  , 0.736   ,\n",
       "            0.7305  , 0.727   , 0.721   , 0.718   , 0.712   , 0.7114  ,\n",
       "            0.709   , 0.7065  , 0.7007  , 0.6953  , 0.6914  , 0.685   ,\n",
       "            0.681   , 0.663   , 0.6455  , 0.639   , 0.6377  , 0.604   ,\n",
       "            0.602   , 0.5664  , 0.53    , 0.513   , 0.47    , 0.4226  ,\n",
       "            0.4082  , 0.4023  , 0.3381  , 0.331   , 0.3098  , 0.3005  ,\n",
       "            0.2979  , 0.255   , 0.235   , 0.2285  , 0.2235  , 0.22    ,\n",
       "            0.2167  , 0.2106  , 0.2075  , 0.1976  , 0.1816  , 0.1761  ,\n",
       "            0.172   , 0.1565  , 0.1407  , 0.1283  , 0.1251  , 0.1184  ,\n",
       "            0.1103  , 0.108   , 0.09436 , 0.0854  , 0.07196 , 0.05634 ,\n",
       "            0.05176 , 0.04163 , 0.03748 , 0.0359  , 0.0334  , 0.0321  ,\n",
       "            0.03033 , 0.02696 , 0.02382 , 0.02153 , 0.02045 , 0.01622 ,\n",
       "            0.01317 , 0.01263 , 0.0121  , 0.00445 , 0.002705, 0.002043],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5677966, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.16949153, 0.18644068,\n",
       "            0.18644068, 0.20338982, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.27966103, 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.06060606, 0.08333334, 0.09848485,\n",
       "            0.10606061, 0.12878788, 0.14393939, 0.1590909 , 0.18181819,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.24242425, 0.25      ,\n",
       "            0.27272728, 0.28030303, 0.29545453, 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.4469697 , 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.5530303 , 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6439394 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.995   , 0.9946  , 0.994   ,\n",
       "            0.9937  , 0.993   , 0.9927  , 0.992   , 0.991   , 0.99    ,\n",
       "            0.9897  , 0.9893  , 0.9883  , 0.986   , 0.982   , 0.9814  ,\n",
       "            0.9805  , 0.9785  , 0.977   , 0.974   , 0.973   , 0.971   ,\n",
       "            0.9688  , 0.9673  , 0.966   , 0.9653  , 0.9585  , 0.954   ,\n",
       "            0.951   , 0.9497  , 0.948   , 0.9453  , 0.944   , 0.9434  ,\n",
       "            0.9414  , 0.939   , 0.938   , 0.9375  , 0.935   , 0.9326  ,\n",
       "            0.932   , 0.9272  , 0.927   , 0.9263  , 0.926   , 0.9233  ,\n",
       "            0.9224  , 0.9204  , 0.9175  , 0.9136  , 0.91    , 0.9053  ,\n",
       "            0.9043  , 0.9033  , 0.9023  , 0.897   , 0.8965  , 0.8955  ,\n",
       "            0.895   , 0.8945  , 0.89    , 0.888   , 0.887   , 0.884   ,\n",
       "            0.8823  , 0.882   , 0.8774  , 0.8755  , 0.874   , 0.873   ,\n",
       "            0.872   , 0.869   , 0.8687  , 0.868   , 0.8677  , 0.8667  ,\n",
       "            0.8657  , 0.865   , 0.8633  , 0.8604  , 0.86    , 0.8564  ,\n",
       "            0.853   , 0.8516  , 0.851   , 0.848   , 0.847   , 0.8467  ,\n",
       "            0.846   , 0.8457  , 0.845   , 0.8447  , 0.8403  , 0.84    ,\n",
       "            0.8374  , 0.837   , 0.8315  , 0.8306  , 0.829   , 0.8286  ,\n",
       "            0.824   , 0.823   , 0.8228  , 0.822   , 0.8193  , 0.814   ,\n",
       "            0.8125  , 0.812   , 0.8105  , 0.8037  , 0.7974  , 0.797   ,\n",
       "            0.7944  , 0.7925  , 0.7896  , 0.789   , 0.786   , 0.784   ,\n",
       "            0.7793  , 0.779   , 0.7783  , 0.7754  , 0.7725  , 0.766   ,\n",
       "            0.765   , 0.7646  , 0.759   , 0.756   , 0.75    , 0.7466  ,\n",
       "            0.741   , 0.737   , 0.7354  , 0.7275  , 0.724   , 0.7207  ,\n",
       "            0.7114  , 0.6963  , 0.691   , 0.6685  , 0.668   , 0.667   ,\n",
       "            0.6323  , 0.62    , 0.5874  , 0.5415  , 0.5264  , 0.5254  ,\n",
       "            0.4778  , 0.4329  , 0.4177  , 0.414   , 0.342   , 0.336   ,\n",
       "            0.3152  , 0.3013  , 0.3005  , 0.257   , 0.2379  , 0.2274  ,\n",
       "            0.2256  , 0.2208  , 0.2173  , 0.212   , 0.2089  , 0.1987  ,\n",
       "            0.1815  , 0.1771  , 0.1715  , 0.1559  , 0.1396  , 0.1278  ,\n",
       "            0.1238  , 0.11597 , 0.10876 , 0.1067  , 0.09155 , 0.0827  ,\n",
       "            0.0694  , 0.0541  , 0.0496  , 0.03955 , 0.03555 , 0.03403 ,\n",
       "            0.03397 , 0.03162 , 0.03033 , 0.0286  , 0.02855 , 0.02527 ,\n",
       "            0.02237 , 0.02007 , 0.01901 , 0.015015, 0.0121  , 0.01164 ,\n",
       "            0.01116 , 0.00399 , 0.002398, 0.001803], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5677966, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.18644068, 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.03787879, 0.08333334, 0.09848485,\n",
       "            0.10606061, 0.14393939, 0.15151516, 0.1590909 , 0.18939394,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.25757575, 0.27272728,\n",
       "            0.28030303, 0.29545453, 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.74242425, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.7878788 , 0.7878788 , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 1.      , 0.9995  , 0.999   , 0.9985  , 0.998   ,\n",
       "            0.9976  , 0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   ,\n",
       "            0.9946  , 0.994   , 0.9937  , 0.993   , 0.992   , 0.9917  ,\n",
       "            0.991   , 0.99    , 0.989   , 0.985   , 0.9844  , 0.984   ,\n",
       "            0.982   , 0.98    , 0.9795  , 0.9785  , 0.978   , 0.9766  ,\n",
       "            0.9746  , 0.9727  , 0.971   , 0.97    , 0.966   , 0.963   ,\n",
       "            0.96    , 0.958   , 0.9546  , 0.953   , 0.952   , 0.951   ,\n",
       "            0.9478  , 0.9473  , 0.9453  , 0.9434  , 0.943   , 0.9424  ,\n",
       "            0.9395  , 0.939   , 0.9375  , 0.9365  , 0.935   , 0.934   ,\n",
       "            0.9307  , 0.9277  , 0.9253  , 0.924   , 0.919   , 0.9185  ,\n",
       "            0.918   , 0.917   , 0.9126  , 0.912   , 0.911   , 0.91    ,\n",
       "            0.9067  , 0.9043  , 0.9033  , 0.8984  , 0.898   , 0.895   ,\n",
       "            0.894   , 0.8936  , 0.892   , 0.891   , 0.89    , 0.8896  ,\n",
       "            0.8887  , 0.8867  , 0.886   , 0.8857  , 0.8853  , 0.8833  ,\n",
       "            0.8823  , 0.88    , 0.877   , 0.876   , 0.874   , 0.872   ,\n",
       "            0.869   , 0.868   , 0.867   , 0.866   , 0.863   , 0.8623  ,\n",
       "            0.8594  , 0.8545  , 0.8535  , 0.853   , 0.8525  , 0.851   ,\n",
       "            0.8486  , 0.848   , 0.8457  , 0.8438  , 0.839   , 0.837   ,\n",
       "            0.8364  , 0.834   , 0.8286  , 0.8228  , 0.822   , 0.82    ,\n",
       "            0.8193  , 0.817   , 0.815   , 0.8135  , 0.8125  , 0.81    ,\n",
       "            0.806   , 0.8047  , 0.803   , 0.801   , 0.7983  , 0.7935  ,\n",
       "            0.793   , 0.7925  , 0.7915  , 0.7856  , 0.785   , 0.7827  ,\n",
       "            0.777   , 0.774   , 0.769   , 0.7686  , 0.763   , 0.7627  ,\n",
       "            0.7534  , 0.752   , 0.7495  , 0.74    , 0.718   , 0.71    ,\n",
       "            0.696   , 0.695   , 0.6914  , 0.659   , 0.638   , 0.6084  ,\n",
       "            0.5547  , 0.54    , 0.538   , 0.4888  , 0.4436  , 0.4275  ,\n",
       "            0.424   , 0.3481  , 0.3413  , 0.3213  , 0.3057  , 0.3035  ,\n",
       "            0.2598  , 0.2413  , 0.2285  , 0.2283  , 0.2225  , 0.219   ,\n",
       "            0.2137  , 0.2108  , 0.2002  , 0.1821  , 0.1787  , 0.1719  ,\n",
       "            0.1558  , 0.1392  , 0.1279  , 0.1229  , 0.1142  , 0.1078  ,\n",
       "            0.1058  , 0.0898  , 0.0806  , 0.0677  , 0.05225 , 0.04788 ,\n",
       "            0.0379  , 0.03397 , 0.03247 , 0.0324  , 0.0301  , 0.02887 ,\n",
       "            0.02718 , 0.02711 , 0.02391 , 0.02121 , 0.01883 , 0.01785 ,\n",
       "            0.014114, 0.0112  , 0.0109  , 0.01049 , 0.003622, 0.00215 ,\n",
       "            0.001604], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5762712, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.07575758, 0.09848485, 0.11363637,\n",
       "            0.15151516, 0.1590909 , 0.18939394, 0.21969697, 0.23484848,\n",
       "            0.25757575, 0.27272728, 0.28030303, 0.28787878, 0.3030303 ,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.5833333 , 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 , 0.6666667 ,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.74242425,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.7878788 , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 1.      , 0.9995  , 0.999   , 0.9985  , 0.998   ,\n",
       "            0.9976  , 0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   ,\n",
       "            0.9946  , 0.994   , 0.9937  , 0.993   , 0.992   , 0.991   ,\n",
       "            0.9883  , 0.988   , 0.9873  , 0.986   , 0.9844  , 0.983   ,\n",
       "            0.9824  , 0.9814  , 0.98    , 0.978   , 0.977   , 0.976   ,\n",
       "            0.973   , 0.9707  , 0.968   , 0.9663  , 0.963   , 0.9624  ,\n",
       "            0.9604  , 0.96    , 0.958   , 0.9575  , 0.9565  , 0.955   ,\n",
       "            0.9536  , 0.953   , 0.9526  , 0.951   , 0.9507  , 0.95    ,\n",
       "            0.9487  , 0.9478  , 0.947   , 0.9463  , 0.946   , 0.9453  ,\n",
       "            0.9434  , 0.9404  , 0.937   , 0.933   , 0.9326  , 0.9316  ,\n",
       "            0.931   , 0.9277  , 0.9263  , 0.926   , 0.9253  , 0.9224  ,\n",
       "            0.92    , 0.919   , 0.914   , 0.9136  , 0.912   , 0.9116  ,\n",
       "            0.9097  , 0.909   , 0.908   , 0.907   , 0.9067  , 0.905   ,\n",
       "            0.9043  , 0.904   , 0.9033  , 0.9004  , 0.8975  , 0.8955  ,\n",
       "            0.895   , 0.8945  , 0.893   , 0.891   , 0.889   , 0.8877  ,\n",
       "            0.887   , 0.886   , 0.884   , 0.883   , 0.8804  , 0.88    ,\n",
       "            0.876   , 0.8755  , 0.8745  , 0.8735  , 0.873   , 0.8706  ,\n",
       "            0.868   , 0.8643  , 0.862   , 0.86    , 0.8574  , 0.857   ,\n",
       "            0.852   , 0.846   , 0.845   , 0.844   , 0.8438  , 0.842   ,\n",
       "            0.8394  , 0.8374  , 0.8364  , 0.8345  , 0.832   , 0.8296  ,\n",
       "            0.8276  , 0.825   , 0.823   , 0.8193  , 0.819   , 0.818   ,\n",
       "            0.817   , 0.811   , 0.8086  , 0.803   , 0.8003  , 0.796   ,\n",
       "            0.7944  , 0.7896  , 0.789   , 0.78    , 0.779   , 0.7764  ,\n",
       "            0.768   , 0.745   , 0.7373  , 0.724   , 0.721   , 0.7183  ,\n",
       "            0.687   , 0.663   , 0.634   , 0.581   , 0.5615  , 0.561   ,\n",
       "            0.515   , 0.4624  , 0.4458  , 0.4382  , 0.3655  , 0.356   ,\n",
       "            0.3345  , 0.3208  , 0.3184  , 0.2698  , 0.2493  , 0.239   ,\n",
       "            0.2362  , 0.2311  , 0.2277  , 0.22    , 0.2168  , 0.2059  ,\n",
       "            0.187   , 0.1835  , 0.177   , 0.1589  , 0.1418  , 0.1293  ,\n",
       "            0.1252  , 0.11597 , 0.1086  , 0.10614 , 0.10596 , 0.0937  ,\n",
       "            0.08154 , 0.06915 , 0.05154 , 0.0468  , 0.0372  , 0.03314 ,\n",
       "            0.03174 , 0.03162 , 0.02931 , 0.02791 , 0.02646 , 0.02626 ,\n",
       "            0.02333 , 0.02017 , 0.01826 , 0.0173  , 0.013275, 0.01082 ,\n",
       "            0.01017 , 0.00971 , 0.003351, 0.002058, 0.001467], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5762712, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.16949153, 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.09848485, 0.12878788, 0.1590909 ,\n",
       "            0.18939394, 0.21969697, 0.24242425, 0.27272728, 0.28030303,\n",
       "            0.3030303 , 0.3181818 , 0.32575756, 0.33333334, 0.34848484,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.6515151 , 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.7348485 , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.7878788 , 0.7878788 , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.       , 1.       , 0.9995   , 0.999    , 0.9985   , 0.998    ,\n",
       "            0.9976   , 0.997    , 0.9966   , 0.996    , 0.9956   , 0.995    ,\n",
       "            0.994    , 0.9937   , 0.991    , 0.9907   , 0.9897   , 0.989    ,\n",
       "            0.988    , 0.9873   , 0.987    , 0.9854   , 0.983    , 0.9824   ,\n",
       "            0.9814   , 0.9805   , 0.978    , 0.976    , 0.9746   , 0.9717   ,\n",
       "            0.9707   , 0.969    , 0.9688   , 0.968    , 0.966    , 0.9653   ,\n",
       "            0.9644   , 0.9634   , 0.9624   , 0.962    , 0.9604   , 0.9595   ,\n",
       "            0.959    , 0.9585   , 0.958    , 0.957    , 0.9556   , 0.9536   ,\n",
       "            0.95     , 0.9487   , 0.9473   , 0.947    , 0.946    , 0.9453   ,\n",
       "            0.943    , 0.941    , 0.94     , 0.9385   , 0.936    , 0.9355   ,\n",
       "            0.9307   , 0.93     , 0.9297   , 0.929    , 0.9272   , 0.926    ,\n",
       "            0.925    , 0.9243   , 0.924    , 0.923    , 0.9224   , 0.922    ,\n",
       "            0.919    , 0.9165   , 0.915    , 0.914    , 0.9136   , 0.913    ,\n",
       "            0.9106   , 0.909    , 0.9077   , 0.907    , 0.906    , 0.9043   ,\n",
       "            0.9033   , 0.901    , 0.8975   , 0.897    , 0.8965   , 0.896    ,\n",
       "            0.8955   , 0.893    , 0.891    , 0.888    , 0.8867   , 0.8853   ,\n",
       "            0.884    , 0.8833   , 0.881    , 0.88     , 0.8765   , 0.871    ,\n",
       "            0.87     , 0.8696   , 0.8687   , 0.8677   , 0.8643   , 0.863    ,\n",
       "            0.8613   , 0.86     , 0.859    , 0.8555   , 0.854    , 0.8516   ,\n",
       "            0.849    , 0.8467   , 0.846    , 0.8447   , 0.8438   , 0.8384   ,\n",
       "            0.8354   , 0.831    , 0.828    , 0.824    , 0.8228   , 0.818    ,\n",
       "            0.817    , 0.808    , 0.807    , 0.8057   , 0.7974   , 0.775    ,\n",
       "            0.7666   , 0.755    , 0.75     , 0.7485   , 0.7183   , 0.6943   ,\n",
       "            0.6655   , 0.614    , 0.592    , 0.5903   , 0.545    , 0.4893   ,\n",
       "            0.4714   , 0.463    , 0.3872   , 0.3762   , 0.354    , 0.3396   ,\n",
       "            0.3357   , 0.2837   , 0.263    , 0.2512   , 0.2487   , 0.2426   ,\n",
       "            0.2391   , 0.2303   , 0.2269   , 0.2161   , 0.1952   , 0.1921   ,\n",
       "            0.1846   , 0.165    , 0.147    , 0.1339   , 0.1294   , 0.119    ,\n",
       "            0.11145  , 0.10876  , 0.1086   , 0.09686  , 0.083    , 0.07056  ,\n",
       "            0.05154  , 0.04654  , 0.03677  , 0.03265  , 0.03125  , 0.03114  ,\n",
       "            0.02876  , 0.02722  , 0.02596  , 0.02567  , 0.02284  , 0.01945  ,\n",
       "            0.01778  , 0.01678  , 0.01263  , 0.01033  , 0.009636 , 0.00919  ,\n",
       "            0.003088 , 0.0019045, 0.00133  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.58474576, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.2457627 , 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.29661018, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.03787879, 0.10606061, 0.15151516, 0.1969697 ,\n",
       "            0.22727273, 0.2651515 , 0.28030303, 0.3030303 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.36363637, 0.37878788,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.5681818 , 0.5681818 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 , 0.6515151 ,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.7348485 , 0.75      , 0.7651515 , 0.7651515 , 0.77272725,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 1.      , 0.9995  , 0.999   , 0.9985  , 0.998   ,\n",
       "            0.9976  , 0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   ,\n",
       "            0.993   , 0.9927  , 0.9917  , 0.99    , 0.9897  , 0.9893  ,\n",
       "            0.989   , 0.9863  , 0.986   , 0.9844  , 0.983   , 0.981   ,\n",
       "            0.98    , 0.977   , 0.9756  , 0.975   , 0.974   , 0.9736  ,\n",
       "            0.9717  , 0.971   , 0.9707  , 0.9697  , 0.969   , 0.9688  ,\n",
       "            0.968   , 0.9673  , 0.9663  , 0.966   , 0.9653  , 0.9644  ,\n",
       "            0.964   , 0.962   , 0.959   , 0.957   , 0.956   , 0.9546  ,\n",
       "            0.954   , 0.9526  , 0.9507  , 0.9497  , 0.9487  , 0.9463  ,\n",
       "            0.946   , 0.942   , 0.9414  , 0.941   , 0.939   , 0.9375  ,\n",
       "            0.9365  , 0.936   , 0.9355  , 0.9346  , 0.934   , 0.9336  ,\n",
       "            0.9316  , 0.931   , 0.929   , 0.9272  , 0.927   , 0.9263  ,\n",
       "            0.925   , 0.9243  , 0.9214  , 0.921   , 0.9204  , 0.9194  ,\n",
       "            0.917   , 0.9165  , 0.9146  , 0.9106  , 0.91    , 0.9097  ,\n",
       "            0.909   , 0.907   , 0.9062  , 0.9053  , 0.902   , 0.9014  ,\n",
       "            0.9004  , 0.8984  , 0.8975  , 0.895   , 0.8916  , 0.8867  ,\n",
       "            0.8853  , 0.885   , 0.8843  , 0.881   , 0.8804  , 0.8774  ,\n",
       "            0.876   , 0.8726  , 0.8687  , 0.866   , 0.8647  , 0.864   ,\n",
       "            0.863   , 0.861   , 0.8564  , 0.8535  , 0.849   , 0.846   ,\n",
       "            0.8423  , 0.841   , 0.837   , 0.836   , 0.827   , 0.8267  ,\n",
       "            0.8247  , 0.816   , 0.795   , 0.786   , 0.7754  , 0.7695  ,\n",
       "            0.7397  , 0.713   , 0.6865  , 0.6357  , 0.6104  , 0.6094  ,\n",
       "            0.5654  , 0.5054  , 0.4868  , 0.4734  , 0.401   , 0.3884  ,\n",
       "            0.3652  , 0.3516  , 0.3455  , 0.291   , 0.2693  , 0.2583  ,\n",
       "            0.255   , 0.2485  , 0.2452  , 0.235   , 0.2313  , 0.2207  ,\n",
       "            0.1982  , 0.1956  , 0.1879  , 0.1669  , 0.1483  , 0.1342  ,\n",
       "            0.1299  , 0.1195  , 0.11127 , 0.1082  , 0.1076  , 0.0981  ,\n",
       "            0.0828  , 0.07043 , 0.0504  , 0.04526 , 0.03574 , 0.03162 ,\n",
       "            0.03033 , 0.03015 , 0.02785 , 0.02615 , 0.02509 , 0.02466 ,\n",
       "            0.02203 , 0.01851 , 0.01698 , 0.01602 , 0.01192 , 0.00978 ,\n",
       "            0.00902 , 0.00861 , 0.002846, 0.001755, 0.001211], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59322035, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.08474576, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.13559322, 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.07575758, 0.14393939, 0.1969697 , 0.25      ,\n",
       "            0.28030303, 0.31060606, 0.3181818 , 0.33333334, 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.40151516, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.47727272, 0.4848485 , 0.4848485 , 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.54545456, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.6060606 , 0.6060606 , 0.6136364 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6515151 , 0.6515151 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.7121212 , 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.7878788 , 0.79545456,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.81060606, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 1.      , 0.9995  , 0.999   , 0.9985  , 0.998   ,\n",
       "            0.9976  , 0.997   , 0.9966  , 0.9946  , 0.994   , 0.9937  ,\n",
       "            0.9927  , 0.9917  , 0.9897  , 0.9893  , 0.989   , 0.9883  ,\n",
       "            0.9873  , 0.986   , 0.985   , 0.983   , 0.9814  , 0.981   ,\n",
       "            0.9805  , 0.98    , 0.9785  , 0.978   , 0.9775  , 0.977   ,\n",
       "            0.9766  , 0.976   , 0.975   , 0.974   , 0.9736  , 0.972   ,\n",
       "            0.9717  , 0.97    , 0.968   , 0.9663  , 0.9653  , 0.964   ,\n",
       "            0.9634  , 0.963   , 0.961   , 0.9604  , 0.9595  , 0.9575  ,\n",
       "            0.957   , 0.953   , 0.9526  , 0.951   , 0.949   , 0.948   ,\n",
       "            0.9473  , 0.9463  , 0.946   , 0.9443  , 0.9424  , 0.9404  ,\n",
       "            0.94    , 0.9395  , 0.938   , 0.935   , 0.9336  , 0.933   ,\n",
       "            0.9316  , 0.9307  , 0.929   , 0.926   , 0.9253  , 0.925   ,\n",
       "            0.9243  , 0.924   , 0.922   , 0.921   , 0.9204  , 0.9185  ,\n",
       "            0.916   , 0.9146  , 0.9136  , 0.909   , 0.905   , 0.9043  ,\n",
       "            0.903   , 0.9023  , 0.9     , 0.898   , 0.8955  , 0.895   ,\n",
       "            0.894   , 0.8926  , 0.8916  , 0.888   , 0.8853  , 0.884   ,\n",
       "            0.882   , 0.8804  , 0.8765  , 0.8735  , 0.8696  , 0.8667  ,\n",
       "            0.864   , 0.862   , 0.8584  , 0.8574  , 0.8496  , 0.849   ,\n",
       "            0.847   , 0.838   , 0.8193  , 0.819   , 0.8003  , 0.795   ,\n",
       "            0.7944  , 0.765   , 0.74    , 0.713   , 0.674   , 0.644   ,\n",
       "            0.6387  , 0.6074  , 0.5337  , 0.516   , 0.4907  , 0.4336  ,\n",
       "            0.4163  , 0.3901  , 0.3865  , 0.3706  , 0.3118  , 0.2861  ,\n",
       "            0.2832  , 0.2712  , 0.2676  , 0.265   , 0.25    , 0.2463  ,\n",
       "            0.2347  , 0.2108  , 0.2063  , 0.2012  , 0.1765  , 0.1572  ,\n",
       "            0.1387  , 0.1371  , 0.1271  , 0.11554 , 0.11145 , 0.1103  ,\n",
       "            0.10876 , 0.0883  , 0.0764  , 0.05212 , 0.0461  , 0.03683 ,\n",
       "            0.0324  , 0.0313  , 0.03091 , 0.02855 , 0.02635 , 0.02586 ,\n",
       "            0.02504 , 0.02284 , 0.01834 , 0.01752 , 0.01653 , 0.01169 ,\n",
       "            0.01009 , 0.00878 , 0.00835 , 0.0028  , 0.001818, 0.001188],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59322035, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.18644068, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.08333334, 0.1590909 , 0.22727273, 0.27272728,\n",
       "            0.31060606, 0.32575756, 0.33333334, 0.37121212, 0.37878788,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.50757575, 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.6060606 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6515151 ,\n",
       "            0.6515151 , 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.74242425, 0.75      , 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 1.      , 0.9995  , 0.999   , 0.9985  , 0.998   ,\n",
       "            0.9976  , 0.997   , 0.9956  , 0.995   , 0.994   , 0.9937  ,\n",
       "            0.993   , 0.9917  , 0.991   , 0.9907  , 0.9897  , 0.989   ,\n",
       "            0.9883  , 0.9863  , 0.985   , 0.9844  , 0.984   , 0.983   ,\n",
       "            0.9824  , 0.982   , 0.981   , 0.9805  , 0.98    , 0.9795  ,\n",
       "            0.979   , 0.9785  , 0.978   , 0.977   , 0.976   , 0.975   ,\n",
       "            0.973   , 0.972   , 0.971   , 0.97    , 0.969   , 0.9688  ,\n",
       "            0.9683  , 0.967   , 0.9663  , 0.966   , 0.9653  , 0.9634  ,\n",
       "            0.963   , 0.9604  , 0.96    , 0.9595  , 0.958   , 0.956   ,\n",
       "            0.955   , 0.954   , 0.9536  , 0.953   , 0.9526  , 0.9517  ,\n",
       "            0.9497  , 0.948   , 0.9478  , 0.947   , 0.946   , 0.9453  ,\n",
       "            0.9434  , 0.943   , 0.9424  , 0.942   , 0.94    , 0.9385  ,\n",
       "            0.938   , 0.9346  , 0.934   , 0.9336  , 0.932   , 0.9307  ,\n",
       "            0.93    , 0.9287  , 0.928   , 0.9253  , 0.925   , 0.9243  ,\n",
       "            0.924   , 0.9233  , 0.9185  , 0.915   , 0.9146  , 0.913   ,\n",
       "            0.9126  , 0.9106  , 0.908   , 0.9062  , 0.906   , 0.905   ,\n",
       "            0.904   , 0.902   , 0.9     , 0.897   , 0.8965  , 0.895   ,\n",
       "            0.893   , 0.8916  , 0.888   , 0.8877  , 0.8853  , 0.8813  ,\n",
       "            0.879   , 0.876   , 0.8745  , 0.8706  , 0.87    , 0.863   ,\n",
       "            0.8623  , 0.8604  , 0.8516  , 0.8457  , 0.833   , 0.815   ,\n",
       "            0.8115  , 0.809   , 0.7812  , 0.761   , 0.7305  , 0.706   ,\n",
       "            0.673   , 0.6626  , 0.646   , 0.5596  , 0.5435  , 0.505   ,\n",
       "            0.4683  , 0.4458  , 0.4277  , 0.4158  , 0.3984  , 0.336   ,\n",
       "            0.3145  , 0.3052  , 0.2908  , 0.2903  , 0.2898  , 0.269   ,\n",
       "            0.2646  , 0.2515  , 0.2272  , 0.2197  , 0.2189  , 0.1898  ,\n",
       "            0.1699  , 0.1492  , 0.146   , 0.1399  , 0.1254  , 0.12305 ,\n",
       "            0.1174  , 0.11536 , 0.09845 , 0.0863  , 0.05646 , 0.04932 ,\n",
       "            0.0403  , 0.03516 , 0.03442 , 0.0336  , 0.03114 , 0.02855 ,\n",
       "            0.02817 , 0.02696 , 0.02547 , 0.0195  , 0.0193  , 0.01848 ,\n",
       "            0.01224 , 0.01133 , 0.00919 , 0.008675, 0.003052, 0.0021  ,\n",
       "            0.001315], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.06666667, 0.075     , 0.08333334,\n",
       "            0.1       , 0.10833333, 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.5416667 , 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.64166665, 0.65      , 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.68333334, 0.68333334, 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.71666664, 0.73333335, 0.7416667 , 0.7416667 , 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.81666666, 0.8333333 ,\n",
       "            0.8333333 , 0.8333333 , 0.8333333 , 0.8333333 , 0.84166664,\n",
       "            0.84166664, 0.85833335, 0.85833335, 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.89166665,\n",
       "            0.89166665, 0.89166665, 0.89166665, 0.9       , 0.90833336,\n",
       "            0.925     , 0.925     , 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.06153846, 0.06153846, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.08461539, 0.08461539, 0.09230769, 0.09230769, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.14615385, 0.14615385, 0.14615385,\n",
       "            0.14615385, 0.15384616, 0.15384616, 0.15384616, 0.16153847,\n",
       "            0.16153847, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.18461539, 0.18461539, 0.18461539, 0.1923077 , 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.20769231, 0.21538462, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.26923078, 0.26923078, 0.26923078, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4076923 , 0.4076923 , 0.41538462, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.45384616, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.61538464, 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.484 , 0.4832, 0.4814, 0.48  , 0.477 , 0.4768, 0.4734,\n",
       "            0.473 , 0.472 , 0.4702, 0.4692, 0.469 , 0.4688, 0.4646, 0.4636,\n",
       "            0.4612, 0.461 , 0.4607, 0.4604, 0.46  , 0.4595, 0.459 , 0.4587,\n",
       "            0.4563, 0.456 , 0.4548, 0.4536, 0.4521, 0.4517, 0.4507, 0.4504,\n",
       "            0.4502, 0.4482, 0.4475, 0.4473, 0.4465, 0.445 , 0.443 , 0.4421,\n",
       "            0.4402, 0.44  , 0.4375, 0.4373, 0.4353, 0.435 , 0.4348, 0.4338,\n",
       "            0.4336, 0.4329, 0.4321, 0.4307, 0.4302, 0.4297, 0.429 , 0.4285,\n",
       "            0.4277, 0.427 , 0.426 , 0.4253, 0.4248, 0.4243, 0.4233, 0.4226,\n",
       "            0.4214, 0.421 , 0.4182, 0.418 , 0.4175, 0.4163, 0.416 , 0.4155,\n",
       "            0.4153, 0.4136, 0.4124, 0.4119, 0.4116, 0.4102, 0.4097, 0.4075,\n",
       "            0.4067, 0.4065, 0.4053, 0.405 , 0.4045, 0.4043, 0.404 , 0.4038,\n",
       "            0.4036, 0.4033, 0.4026, 0.4023, 0.4016, 0.4011, 0.4006, 0.4001,\n",
       "            0.4   , 0.3994, 0.3977, 0.3972, 0.3962, 0.3958, 0.395 , 0.3938,\n",
       "            0.3923, 0.392 , 0.3909, 0.3901, 0.39  , 0.3894, 0.3892, 0.389 ,\n",
       "            0.3887, 0.3884, 0.3882, 0.3877, 0.3867, 0.3862, 0.3855, 0.3845,\n",
       "            0.384 , 0.3828, 0.382 , 0.3818, 0.3813, 0.3809, 0.3804, 0.3801,\n",
       "            0.38  , 0.379 , 0.3772, 0.377 , 0.3752, 0.3748, 0.3743, 0.3735,\n",
       "            0.3728, 0.372 , 0.3718, 0.3716, 0.3713, 0.3691, 0.369 , 0.3687,\n",
       "            0.3684, 0.3677, 0.3674, 0.3657, 0.3628, 0.3625, 0.3616, 0.3594,\n",
       "            0.3591, 0.3562, 0.3547, 0.3545, 0.3518, 0.3513, 0.348 , 0.3477,\n",
       "            0.347 , 0.3462, 0.3452, 0.3447, 0.3435, 0.3416, 0.3408, 0.3398,\n",
       "            0.3384, 0.338 , 0.3362, 0.333 , 0.3325, 0.3323, 0.3318, 0.3315,\n",
       "            0.3274, 0.3257, 0.3228, 0.322 , 0.3218, 0.3215, 0.3213, 0.321 ,\n",
       "            0.3206, 0.3196, 0.3193, 0.3188, 0.3186, 0.3184, 0.3171, 0.317 ,\n",
       "            0.3167, 0.3154, 0.313 , 0.3127, 0.3125, 0.3115, 0.3108, 0.3105,\n",
       "            0.309 , 0.3088, 0.3079, 0.3062, 0.304 , 0.3025, 0.301 , 0.2988,\n",
       "            0.2983, 0.2942, 0.2925, 0.292 , 0.28  , 0.2566], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.1       , 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.53333336, 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.575     , 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.65833336, 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.725     , 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.80833334, 0.81666666, 0.81666666,\n",
       "            0.825     , 0.825     , 0.825     , 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.84166664, 0.84166664, 0.85      , 0.85833335,\n",
       "            0.875     , 0.875     , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.90833336, 0.90833336, 0.9166667 , 0.9166667 , 0.925     ,\n",
       "            0.925     , 0.93333334, 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06923077, 0.07692308, 0.09230769,\n",
       "            0.1       , 0.1       , 0.10769231, 0.12307692, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.13846155, 0.13846155, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.16923077, 0.17692308, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.22307692, 0.22307692,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.26153848, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.32307693,\n",
       "            0.32307693, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.34615386, 0.36153847, 0.36923078, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.3923077 , 0.3923077 ,\n",
       "            0.4       , 0.41538462, 0.42307693, 0.42307693, 0.42307693,\n",
       "            0.42307693, 0.43076923, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.4923077 , 0.4923077 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.454 , 0.4524, 0.451 , 0.4492, 0.4465, 0.4456, 0.444 ,\n",
       "            0.4438, 0.4426, 0.4404, 0.44  , 0.4373, 0.4368, 0.4355, 0.435 ,\n",
       "            0.4348, 0.433 , 0.4326, 0.432 , 0.4316, 0.4314, 0.4312, 0.4307,\n",
       "            0.4294, 0.428 , 0.4277, 0.427 , 0.426 , 0.4238, 0.4224, 0.421 ,\n",
       "            0.4204, 0.4192, 0.4187, 0.4185, 0.4158, 0.4155, 0.4146, 0.4124,\n",
       "            0.4111, 0.408 , 0.4065, 0.4058, 0.405 , 0.4043, 0.404 , 0.4033,\n",
       "            0.4004, 0.3994, 0.3982, 0.395 , 0.3926, 0.3906, 0.3892, 0.3877,\n",
       "            0.3865, 0.386 , 0.3835, 0.3828, 0.3784, 0.3782, 0.3772, 0.377 ,\n",
       "            0.3767, 0.3762, 0.3755, 0.375 , 0.3745, 0.3743, 0.3735, 0.3726,\n",
       "            0.3723, 0.3713, 0.371 , 0.369 , 0.3687, 0.3684, 0.3677, 0.3674,\n",
       "            0.3672, 0.365 , 0.3647, 0.3591, 0.359 , 0.3586, 0.3582, 0.3564,\n",
       "            0.3555, 0.3552, 0.3545, 0.3538, 0.3528, 0.3523, 0.352 , 0.3508,\n",
       "            0.35  , 0.3481, 0.3477, 0.3472, 0.347 , 0.3464, 0.3455, 0.3445,\n",
       "            0.344 , 0.3433, 0.343 , 0.342 , 0.341 , 0.3386, 0.3384, 0.337 ,\n",
       "            0.3367, 0.3357, 0.3354, 0.335 , 0.3347, 0.3335, 0.3328, 0.3323,\n",
       "            0.3315, 0.3313, 0.331 , 0.3308, 0.3303, 0.33  , 0.3293, 0.329 ,\n",
       "            0.3289, 0.3284, 0.3281, 0.3271, 0.327 , 0.326 , 0.3254, 0.3252,\n",
       "            0.3247, 0.3245, 0.3242, 0.3235, 0.323 , 0.3203, 0.32  , 0.3186,\n",
       "            0.3174, 0.3171, 0.3162, 0.3137, 0.3135, 0.313 , 0.3115, 0.3103,\n",
       "            0.3086, 0.3083, 0.3064, 0.3047, 0.304 , 0.3032, 0.302 , 0.3015,\n",
       "            0.299 , 0.2983, 0.2966, 0.2947, 0.294 , 0.2935, 0.2922, 0.289 ,\n",
       "            0.288 , 0.2878, 0.2874, 0.287 , 0.281 , 0.278 , 0.2773, 0.277 ,\n",
       "            0.2766, 0.2756, 0.275 , 0.2742, 0.274 , 0.2737, 0.2734, 0.2732,\n",
       "            0.2717, 0.271 , 0.2695, 0.2693, 0.269 , 0.2659, 0.2646, 0.2644,\n",
       "            0.2642, 0.263 , 0.2627, 0.2622, 0.262 , 0.2615, 0.2598, 0.2573,\n",
       "            0.2568, 0.256 , 0.2532, 0.253 , 0.2505, 0.2493, 0.2462, 0.2429,\n",
       "            0.2428, 0.2303, 0.2058], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.04166667,\n",
       "            0.05      , 0.06666667, 0.075     , 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.3       ,\n",
       "            0.30833334, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.59166664, 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.64166665, 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.69166666, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.7416667 , 0.75      , 0.75      , 0.7583333 , 0.7583333 ,\n",
       "            0.7583333 , 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85      ,\n",
       "            0.85      , 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.03846154, 0.05384615, 0.05384615, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.17692308, 0.17692308, 0.17692308, 0.18461539, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.20769231, 0.20769231,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23076923,\n",
       "            0.23076923, 0.23076923, 0.24615385, 0.24615385, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.3846154 , 0.3846154 , 0.3846154 ,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.43076923, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.45384616, 0.45384616, 0.45384616,\n",
       "            0.45384616, 0.45384616, 0.46923077, 0.47692308, 0.47692308,\n",
       "            0.4846154 , 0.4846154 , 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.7692308 , 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8153846 , 0.8230769 , 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4236, 0.4226, 0.4214, 0.4211, 0.418 , 0.4158, 0.4138,\n",
       "            0.412 , 0.4116, 0.411 , 0.41  , 0.4087, 0.406 , 0.4055, 0.405 ,\n",
       "            0.4048, 0.4045, 0.4033, 0.4026, 0.402 , 0.4016, 0.4014, 0.4   ,\n",
       "            0.3997, 0.3994, 0.3987, 0.396 , 0.3945, 0.3914, 0.391 , 0.3909,\n",
       "            0.3904, 0.3867, 0.3853, 0.3838, 0.383 , 0.3818, 0.3794, 0.3774,\n",
       "            0.375 , 0.3748, 0.3735, 0.3733, 0.371 , 0.3699, 0.3677, 0.3662,\n",
       "            0.3635, 0.3608, 0.3586, 0.3564, 0.3562, 0.356 , 0.3552, 0.352 ,\n",
       "            0.3425, 0.3384, 0.3376, 0.3352, 0.3335, 0.333 , 0.3325, 0.3323,\n",
       "            0.3315, 0.3313, 0.3293, 0.329 , 0.3289, 0.3281, 0.327 , 0.3257,\n",
       "            0.3245, 0.324 , 0.3232, 0.3223, 0.3218, 0.32  , 0.3176, 0.3171,\n",
       "            0.3164, 0.3157, 0.3142, 0.3135, 0.313 , 0.3123, 0.3108, 0.3103,\n",
       "            0.3098, 0.3088, 0.3066, 0.306 , 0.3057, 0.3054, 0.303 , 0.3025,\n",
       "            0.3015, 0.3013, 0.2998, 0.299 , 0.2986, 0.297 , 0.2964, 0.2961,\n",
       "            0.296 , 0.2957, 0.2954, 0.2952, 0.295 , 0.2942, 0.2935, 0.2925,\n",
       "            0.2917, 0.2915, 0.291 , 0.2908, 0.2905, 0.2903, 0.2898, 0.2883,\n",
       "            0.288 , 0.2878, 0.286 , 0.2847, 0.2844, 0.2842, 0.2837, 0.2834,\n",
       "            0.2825, 0.282 , 0.2812, 0.2808, 0.2803, 0.2788, 0.2786, 0.2783,\n",
       "            0.2769, 0.2764, 0.2761, 0.276 , 0.2756, 0.2751, 0.2747, 0.2742,\n",
       "            0.2737, 0.2732, 0.273 , 0.272 , 0.271 , 0.2708, 0.2703, 0.2695,\n",
       "            0.269 , 0.268 , 0.2678, 0.2668, 0.2664, 0.2654, 0.2644, 0.2634,\n",
       "            0.262 , 0.2605, 0.26  , 0.2588, 0.2576, 0.2573, 0.2563, 0.2542,\n",
       "            0.254 , 0.2517, 0.2507, 0.2505, 0.2498, 0.249 , 0.2471, 0.2434,\n",
       "            0.2422, 0.2417, 0.2397, 0.2391, 0.239 , 0.2379, 0.237 , 0.2368,\n",
       "            0.2366, 0.236 , 0.2356, 0.2351, 0.2344, 0.2335, 0.2327, 0.2319,\n",
       "            0.2311, 0.2294, 0.2252, 0.2251, 0.2249, 0.2246, 0.2239, 0.2234,\n",
       "            0.2218, 0.2213, 0.2202, 0.22  , 0.2177, 0.2162, 0.2156, 0.213 ,\n",
       "            0.2124, 0.211 , 0.2094, 0.2068, 0.2032, 0.201 , 0.1907, 0.166 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.15      , 0.15833333, 0.16666667, 0.19166666,\n",
       "            0.2       , 0.21666667, 0.225     , 0.23333333, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.53333336,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.575     , 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.6       , 0.6       ,\n",
       "            0.6       , 0.60833335, 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.68333334, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.7083333 ,\n",
       "            0.7083333 , 0.7083333 , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.73333335, 0.7416667 , 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.775     , 0.775     ,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.81666666, 0.81666666,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.81666666, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.84166664, 0.84166664,\n",
       "            0.85      , 0.85833335, 0.85833335, 0.8666667 , 0.8666667 ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.89166665, 0.89166665,\n",
       "            0.9       , 0.90833336, 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.925     , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.06153846, 0.06923077, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.17692308, 0.17692308, 0.17692308, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23846154, 0.24615385, 0.26153848,\n",
       "            0.26923078, 0.26923078, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.35384616, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3846154 , 0.3923077 , 0.4       , 0.41538462,\n",
       "            0.42307693, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.6       , 0.6076923 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3943, 0.394 , 0.3928, 0.3914, 0.391 , 0.3884, 0.3865,\n",
       "            0.3853, 0.3848, 0.3845, 0.383 , 0.3823, 0.3813, 0.3809, 0.3787,\n",
       "            0.3784, 0.3782, 0.3772, 0.3752, 0.3745, 0.3733, 0.3728, 0.3726,\n",
       "            0.372 , 0.3704, 0.3691, 0.369 , 0.3677, 0.3645, 0.3643, 0.3638,\n",
       "            0.3625, 0.362 , 0.36  , 0.358 , 0.3567, 0.356 , 0.3525, 0.35  ,\n",
       "            0.3494, 0.3477, 0.3474, 0.3438, 0.3425, 0.3423, 0.3418, 0.3396,\n",
       "            0.3386, 0.3362, 0.3306, 0.3276, 0.3271, 0.3237, 0.3215, 0.32  ,\n",
       "            0.3196, 0.313 , 0.306 , 0.3003, 0.296 , 0.295 , 0.2932, 0.292 ,\n",
       "            0.2903, 0.29  , 0.288 , 0.2876, 0.285 , 0.2847, 0.2842, 0.2832,\n",
       "            0.2825, 0.2803, 0.279 , 0.2773, 0.2761, 0.2756, 0.2742, 0.274 ,\n",
       "            0.2737, 0.2734, 0.2732, 0.273 , 0.2717, 0.2712, 0.27  , 0.2673,\n",
       "            0.2668, 0.2654, 0.2651, 0.2646, 0.2642, 0.2634, 0.2632, 0.263 ,\n",
       "            0.2605, 0.2595, 0.259 , 0.2576, 0.2568, 0.2566, 0.256 , 0.2554,\n",
       "            0.255 , 0.2542, 0.2537, 0.253 , 0.2527, 0.2524, 0.251 , 0.2498,\n",
       "            0.2487, 0.2478, 0.2471, 0.2462, 0.2456, 0.2455, 0.2452, 0.2448,\n",
       "            0.2426, 0.2424, 0.2422, 0.2417, 0.241 , 0.2406, 0.2399, 0.2397,\n",
       "            0.2391, 0.239 , 0.2388, 0.2384, 0.2382, 0.237 , 0.2368, 0.2366,\n",
       "            0.236 , 0.2358, 0.2351, 0.2346, 0.2344, 0.234 , 0.2338, 0.2332,\n",
       "            0.2322, 0.2314, 0.2302, 0.2301, 0.2297, 0.2295, 0.2281, 0.228 ,\n",
       "            0.2272, 0.2269, 0.2261, 0.2255, 0.2239, 0.2238, 0.2229, 0.2227,\n",
       "            0.2222, 0.222 , 0.2207, 0.2205, 0.2195, 0.2189, 0.218 , 0.2177,\n",
       "            0.2163, 0.2158, 0.2152, 0.2134, 0.2114, 0.2085, 0.2081, 0.2079,\n",
       "            0.2076, 0.2068, 0.2053, 0.2051, 0.2047, 0.2043, 0.2042, 0.2039,\n",
       "            0.2037, 0.2023, 0.2002, 0.1998, 0.199 , 0.1981, 0.196 , 0.1941,\n",
       "            0.1937, 0.1936, 0.1931, 0.1927, 0.1923, 0.1921, 0.1907, 0.19  ,\n",
       "            0.189 , 0.1885, 0.1864, 0.185 , 0.1842, 0.1838, 0.1821, 0.1816,\n",
       "            0.1799, 0.1791, 0.1782, 0.1754, 0.1724, 0.167 , 0.1598, 0.1356],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.575     , 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.59166664, 0.6       , 0.60833335,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65      , 0.65      , 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.6666667 , 0.675     , 0.675     , 0.68333334,\n",
       "            0.68333334, 0.69166666, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.69166666, 0.69166666, 0.7       , 0.7       , 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.71666664, 0.71666664,\n",
       "            0.725     , 0.725     , 0.73333335, 0.7416667 , 0.7416667 ,\n",
       "            0.7416667 , 0.7416667 , 0.7416667 , 0.7416667 , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.775     , 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.80833334, 0.80833334, 0.81666666,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.81666666, 0.81666666,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85      , 0.85      , 0.85      , 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.8666667 , 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.925     , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.9916667 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.09230769, 0.1       , 0.1       , 0.1       ,\n",
       "            0.10769231, 0.13076924, 0.13846155, 0.14615385, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.25384617,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.33846155, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.42307693,\n",
       "            0.42307693, 0.42307693, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46923077, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.5       , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63076925, 0.63076925, 0.63076925,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.86153847, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3645, 0.363 , 0.3625, 0.362 , 0.3618, 0.3596, 0.3594,\n",
       "            0.356 , 0.3552, 0.355 , 0.3538, 0.3528, 0.3525, 0.3518, 0.3516,\n",
       "            0.3513, 0.3508, 0.3499, 0.3486, 0.3484, 0.3481, 0.3474, 0.3464,\n",
       "            0.3457, 0.3455, 0.3452, 0.3433, 0.3428, 0.341 , 0.3396, 0.3376,\n",
       "            0.3374, 0.337 , 0.3354, 0.334 , 0.3335, 0.3325, 0.3318, 0.3306,\n",
       "            0.3274, 0.3245, 0.323 , 0.3228, 0.319 , 0.3184, 0.3164, 0.3154,\n",
       "            0.3137, 0.3125, 0.3113, 0.3105, 0.3062, 0.3032, 0.3022, 0.2998,\n",
       "            0.2896, 0.288 , 0.285 , 0.2825, 0.2803, 0.2688, 0.2673, 0.2666,\n",
       "            0.2654, 0.2634, 0.2607, 0.2605, 0.2585, 0.2578, 0.2568, 0.2566,\n",
       "            0.255 , 0.2534, 0.2483, 0.2482, 0.2451, 0.2444, 0.2438, 0.2421,\n",
       "            0.2418, 0.2415, 0.2399, 0.2395, 0.2391, 0.239 , 0.2386, 0.2372,\n",
       "            0.235 , 0.2346, 0.2343, 0.2335, 0.2316, 0.2314, 0.2311, 0.2303,\n",
       "            0.2299, 0.2297, 0.2294, 0.2292, 0.2286, 0.2283, 0.2246, 0.2238,\n",
       "            0.2234, 0.223 , 0.2227, 0.2225, 0.222 , 0.2216, 0.2213, 0.2205,\n",
       "            0.2191, 0.2189, 0.2179, 0.2172, 0.2166, 0.2163, 0.2162, 0.2158,\n",
       "            0.2157, 0.2147, 0.2145, 0.2144, 0.2142, 0.2137, 0.2124, 0.212 ,\n",
       "            0.2118, 0.2115, 0.211 , 0.2104, 0.2103, 0.2095, 0.2091, 0.2076,\n",
       "            0.2069, 0.2059, 0.2053, 0.2051, 0.205 , 0.2048, 0.204 , 0.2039,\n",
       "            0.2037, 0.2034, 0.2032, 0.2029, 0.2028, 0.2026, 0.2023, 0.2013,\n",
       "            0.2009, 0.2004, 0.2002, 0.2001, 0.2   , 0.1991, 0.1989, 0.1987,\n",
       "            0.1985, 0.1984, 0.1978, 0.1962, 0.195 , 0.1925, 0.1904, 0.19  ,\n",
       "            0.1893, 0.1886, 0.1879, 0.1876, 0.1874, 0.1873, 0.1871, 0.1869,\n",
       "            0.1853, 0.185 , 0.1848, 0.1843, 0.1838, 0.1837, 0.183 , 0.1829,\n",
       "            0.1827, 0.182 , 0.181 , 0.1797, 0.1787, 0.1776, 0.1766, 0.1764,\n",
       "            0.1761, 0.1755, 0.1752, 0.1749, 0.1747, 0.1744, 0.1743, 0.174 ,\n",
       "            0.1733, 0.1727, 0.1725, 0.172 , 0.1719, 0.171 , 0.1698, 0.1669,\n",
       "            0.1666, 0.1654, 0.1632, 0.1631, 0.1611, 0.1594, 0.1565, 0.1564,\n",
       "            0.1561, 0.1542, 0.1538, 0.1473, 0.1448, 0.1415, 0.118 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.09166667, 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.575     , 0.575     , 0.59166664, 0.59166664,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.59166664, 0.59166664,\n",
       "            0.6       , 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.64166665, 0.65      , 0.65      , 0.65      ,\n",
       "            0.65      , 0.65      , 0.65      , 0.65833336, 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.675     , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.69166666, 0.69166666, 0.7       , 0.71666664, 0.71666664,\n",
       "            0.725     , 0.725     , 0.725     , 0.725     , 0.725     ,\n",
       "            0.73333335, 0.73333335, 0.73333335, 0.7416667 , 0.7416667 ,\n",
       "            0.75      , 0.75      , 0.75      , 0.7583333 , 0.7583333 ,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.81666666, 0.81666666,\n",
       "            0.81666666, 0.81666666, 0.825     , 0.8333333 , 0.8333333 ,\n",
       "            0.85      , 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "            0.85833335, 0.85833335, 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.8833333 , 0.8833333 ,\n",
       "            0.8833333 , 0.8833333 , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.90833336,\n",
       "            0.90833336, 0.90833336, 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.90833336, 0.9166667 , 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.05384615, 0.06153846,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.1       , 0.10769231, 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.17692308, 0.18461539,\n",
       "            0.18461539, 0.1923077 , 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26923078, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.4076923 , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.50769234, 0.5153846 ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5769231 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7076923 , 0.7076923 ,\n",
       "            0.7153846 , 0.73846155, 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3335, 0.3323, 0.332 , 0.3315, 0.3313, 0.3308, 0.3284,\n",
       "            0.3271, 0.3264, 0.3262, 0.326 , 0.3254, 0.3252, 0.325 , 0.324 ,\n",
       "            0.3237, 0.3235, 0.323 , 0.3228, 0.3215, 0.3213, 0.3206, 0.32  ,\n",
       "            0.3188, 0.318 , 0.317 , 0.3167, 0.3157, 0.314 , 0.3135, 0.3132,\n",
       "            0.313 , 0.311 , 0.31  , 0.3079, 0.306 , 0.3044, 0.3025, 0.302 ,\n",
       "            0.3015, 0.3013, 0.2998, 0.299 , 0.2976, 0.2957, 0.2927, 0.29  ,\n",
       "            0.2864, 0.2856, 0.2852, 0.2832, 0.2817, 0.2815, 0.2805, 0.268 ,\n",
       "            0.2642, 0.2612, 0.2542, 0.2515, 0.2498, 0.2452, 0.2451, 0.2444,\n",
       "            0.2438, 0.2379, 0.2375, 0.236 , 0.2316, 0.2285, 0.228 , 0.2274,\n",
       "            0.2266, 0.2255, 0.2249, 0.2239, 0.2235, 0.2233, 0.2224, 0.2207,\n",
       "            0.2189, 0.2179, 0.2162, 0.2156, 0.2153, 0.215 , 0.2148, 0.2124,\n",
       "            0.2123, 0.2119, 0.2114, 0.2108, 0.21  , 0.2085, 0.2079, 0.2063,\n",
       "            0.2059, 0.2053, 0.2045, 0.2037, 0.2034, 0.2021, 0.201 , 0.2006,\n",
       "            0.1996, 0.199 , 0.1981, 0.1974, 0.1973, 0.197 , 0.1967, 0.1965,\n",
       "            0.196 , 0.195 , 0.1943, 0.1942, 0.1936, 0.1935, 0.1934, 0.1923,\n",
       "            0.1921, 0.1913, 0.1909, 0.1906, 0.1903, 0.1893, 0.1886, 0.188 ,\n",
       "            0.1876, 0.1874, 0.1873, 0.1869, 0.1866, 0.186 , 0.1859, 0.1858,\n",
       "            0.1855, 0.1852, 0.1848, 0.1837, 0.1836, 0.1831, 0.1827, 0.1823,\n",
       "            0.1816, 0.1791, 0.1788, 0.1774, 0.1771, 0.177 , 0.1764, 0.1763,\n",
       "            0.1761, 0.1759, 0.1757, 0.1753, 0.1749, 0.1746, 0.1743, 0.1737,\n",
       "            0.1735, 0.1733, 0.1731, 0.1725, 0.172 , 0.1719, 0.1716, 0.1711,\n",
       "            0.1709, 0.17  , 0.1698, 0.1697, 0.1696, 0.1688, 0.1685, 0.1676,\n",
       "            0.1675, 0.1659, 0.1658, 0.1636, 0.1633, 0.1632, 0.163 , 0.1626,\n",
       "            0.1625, 0.1622, 0.1621, 0.1619, 0.1615, 0.1614, 0.161 , 0.1605,\n",
       "            0.1598, 0.1597, 0.1588, 0.1567, 0.1565, 0.1564, 0.1556, 0.1555,\n",
       "            0.1554, 0.1552, 0.155 , 0.1534, 0.1527, 0.1512, 0.1508, 0.1504,\n",
       "            0.1492, 0.1487, 0.1456, 0.1453, 0.1443, 0.1436, 0.1431, 0.1427,\n",
       "            0.1411, 0.1409, 0.1382, 0.1315, 0.13  , 0.127 , 0.1216, 0.1078],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.025     , 0.04166667, 0.05833333,\n",
       "            0.075     , 0.08333334, 0.10833333, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.16666667, 0.18333334, 0.2       , 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.525     , 0.53333336,\n",
       "            0.53333336, 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.575     , 0.575     ,\n",
       "            0.575     , 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.6       , 0.6       , 0.60833335, 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.65      , 0.65      , 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.65833336, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.675     , 0.675     , 0.675     , 0.68333334,\n",
       "            0.68333334, 0.68333334, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.69166666, 0.7       , 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.725     , 0.725     , 0.725     ,\n",
       "            0.725     , 0.725     , 0.725     , 0.73333335, 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.75      , 0.7583333 , 0.7583333 ,\n",
       "            0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 ,\n",
       "            0.7583333 , 0.76666665, 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84166664, 0.84166664, 0.84166664, 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.9       , 0.9       ,\n",
       "            0.90833336, 0.90833336, 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.01538462, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.10769231, 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.18461539,\n",
       "            0.18461539, 0.2       , 0.20769231, 0.21538462, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43076923,\n",
       "            0.43846154, 0.45384616, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.54615384, 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5769231 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.7       , 0.7       , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.74615383, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3042 , 0.3035 , 0.3032 , 0.303  , 0.3025 , 0.3022 ,\n",
       "            0.302  , 0.3018 , 0.3015 , 0.3008 , 0.2998 , 0.2986 , 0.2983 ,\n",
       "            0.298  , 0.2979 , 0.2976 , 0.2974 , 0.2957 , 0.2954 , 0.2937 ,\n",
       "            0.2935 , 0.2927 , 0.292  , 0.2893 , 0.289  , 0.2886 , 0.2878 ,\n",
       "            0.287  , 0.2864 , 0.286  , 0.2852 , 0.2847 , 0.2832 , 0.282  ,\n",
       "            0.281  , 0.278  , 0.2769 , 0.2737 , 0.273  , 0.2688 , 0.2676 ,\n",
       "            0.2673 , 0.2666 , 0.266  , 0.2605 , 0.2573 , 0.2559 , 0.254  ,\n",
       "            0.2532 , 0.2429 , 0.2418 , 0.2388 , 0.2384 , 0.2366 , 0.2301 ,\n",
       "            0.2264 , 0.2224 , 0.2197 , 0.2179 , 0.2163 , 0.2139 , 0.2134 ,\n",
       "            0.213  , 0.2124 , 0.2074 , 0.2073 , 0.207  , 0.2053 , 0.2047 ,\n",
       "            0.2045 , 0.2043 , 0.2028 , 0.2021 , 0.2012 , 0.201  , 0.2006 ,\n",
       "            0.2002 , 0.1968 , 0.1962 , 0.1959 , 0.1956 , 0.1953 , 0.1952 ,\n",
       "            0.1946 , 0.1942 , 0.1941 , 0.1936 , 0.1934 , 0.1918 , 0.191  ,\n",
       "            0.1903 , 0.1897 , 0.189  , 0.1879 , 0.1869 , 0.186  , 0.1859 ,\n",
       "            0.1848 , 0.1838 , 0.1835 , 0.1831 , 0.183  , 0.1821 , 0.182  ,\n",
       "            0.1816 , 0.1814 , 0.1813 , 0.1807 , 0.1779 , 0.1776 , 0.1775 ,\n",
       "            0.1772 , 0.1768 , 0.1766 , 0.1761 , 0.1752 , 0.1746 , 0.1744 ,\n",
       "            0.1731 , 0.1721 , 0.1719 , 0.1718 , 0.1709 , 0.1703 , 0.17   ,\n",
       "            0.1699 , 0.1698 , 0.1697 , 0.1687 , 0.1683 , 0.1678 , 0.1677 ,\n",
       "            0.1675 , 0.1663 , 0.1661 , 0.166  , 0.1656 , 0.1649 , 0.1644 ,\n",
       "            0.1641 , 0.164  , 0.1638 , 0.1636 , 0.1635 , 0.1622 , 0.1621 ,\n",
       "            0.1617 , 0.1615 , 0.161  , 0.1606 , 0.1599 , 0.1598 , 0.1593 ,\n",
       "            0.1587 , 0.1586 , 0.1584 , 0.158  , 0.1577 , 0.1569 , 0.1567 ,\n",
       "            0.1565 , 0.1561 , 0.156  , 0.1555 , 0.1554 , 0.1552 , 0.1545 ,\n",
       "            0.1544 , 0.1543 , 0.1539 , 0.1532 , 0.153  , 0.1519 , 0.1517 ,\n",
       "            0.1514 , 0.149  , 0.1487 , 0.1486 , 0.1481 , 0.1476 , 0.1467 ,\n",
       "            0.1465 , 0.1461 , 0.1459 , 0.1456 , 0.1447 , 0.1442 , 0.144  ,\n",
       "            0.1437 , 0.1434 , 0.1428 , 0.1426 , 0.142  , 0.1417 , 0.1398 ,\n",
       "            0.1394 , 0.1364 , 0.1353 , 0.1346 , 0.1334 , 0.1332 , 0.1313 ,\n",
       "            0.1312 , 0.1298 , 0.1294 , 0.1283 , 0.1272 , 0.127  , 0.1222 ,\n",
       "            0.1213 , 0.1204 , 0.11816, 0.11694, 0.1076 , 0.1052 , 0.1034 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.16666667,\n",
       "            0.175     , 0.19166666, 0.2       , 0.21666667, 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.33333334, 0.34166667, 0.35833332, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.5       , 0.51666665, 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.575     , 0.575     ,\n",
       "            0.575     , 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.6       ,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.64166665, 0.65      , 0.65      ,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.68333334, 0.69166666,\n",
       "            0.69166666, 0.7       , 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.7083333 , 0.7083333 , 0.7083333 , 0.7083333 , 0.7083333 ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.71666664, 0.725     ,\n",
       "            0.725     , 0.725     , 0.725     , 0.725     , 0.725     ,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.7583333 , 0.7583333 ,\n",
       "            0.7583333 , 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.775     , 0.78333336, 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.825     , 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85      , 0.85      , 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.875     , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.89166665, 0.89166665, 0.90833336, 0.90833336,\n",
       "            0.90833336, 0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.11538462, 0.12307692, 0.13076924, 0.14615385,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26923078, 0.2846154 , 0.2846154 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.32307693,\n",
       "            0.33076924, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.4846154 , 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.64615387, 0.65384614, 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.7       , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.74615383, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2937 , 0.292  , 0.2917 , 0.289  , 0.2888 , 0.2886 ,\n",
       "            0.2878 , 0.2876 , 0.2869 , 0.2861 , 0.286  , 0.2854 , 0.2852 ,\n",
       "            0.285  , 0.2847 , 0.2834 , 0.283  , 0.2827 , 0.2822 , 0.282  ,\n",
       "            0.2815 , 0.2812 , 0.2795 , 0.2788 , 0.2786 , 0.2783 , 0.2776 ,\n",
       "            0.2773 , 0.2766 , 0.2764 , 0.2756 , 0.2754 , 0.2751 , 0.2742 ,\n",
       "            0.2737 , 0.2727 , 0.2712 , 0.271  , 0.2705 , 0.27   , 0.2686 ,\n",
       "            0.268  , 0.2656 , 0.2654 , 0.2644 , 0.263  , 0.2595 , 0.2566 ,\n",
       "            0.2542 , 0.2517 , 0.2487 , 0.2456 , 0.2451 , 0.2445 , 0.2399 ,\n",
       "            0.2375 , 0.2368 , 0.2355 , 0.2306 , 0.2266 , 0.2256 , 0.2252 ,\n",
       "            0.2238 , 0.2218 , 0.2211 , 0.2184 , 0.2147 , 0.2142 , 0.2124 ,\n",
       "            0.211  , 0.2106 , 0.2084 , 0.2064 , 0.206  , 0.2058 , 0.2047 ,\n",
       "            0.2045 , 0.2042 , 0.2035 , 0.2031 , 0.2028 , 0.2004 , 0.1982 ,\n",
       "            0.1979 , 0.1968 , 0.1965 , 0.1952 , 0.194  , 0.1936 , 0.1931 ,\n",
       "            0.1929 , 0.1921 , 0.1919 , 0.1918 , 0.1904 , 0.1903 , 0.1897 ,\n",
       "            0.1879 , 0.1873 , 0.1864 , 0.185  , 0.1843 , 0.1842 , 0.1838 ,\n",
       "            0.1835 , 0.1831 , 0.1824 , 0.182  , 0.1805 , 0.1798 , 0.1796 ,\n",
       "            0.1787 , 0.1785 , 0.1783 , 0.1772 , 0.1763 , 0.1758 , 0.1753 ,\n",
       "            0.1752 , 0.1748 , 0.1747 , 0.1744 , 0.1743 , 0.1738 , 0.173  ,\n",
       "            0.1727 , 0.1726 , 0.1724 , 0.172  , 0.171  , 0.1709 , 0.1707 ,\n",
       "            0.1705 , 0.1704 , 0.17   , 0.1698 , 0.1696 , 0.1688 , 0.1687 ,\n",
       "            0.1685 , 0.1681 , 0.1676 , 0.1675 , 0.167  , 0.1665 , 0.166  ,\n",
       "            0.1659 , 0.165  , 0.1649 , 0.1643 , 0.1637 , 0.1635 , 0.1632 ,\n",
       "            0.163  , 0.162  , 0.161  , 0.1608 , 0.1606 , 0.1604 , 0.1598 ,\n",
       "            0.1584 , 0.1577 , 0.1556 , 0.1547 , 0.1543 , 0.1533 , 0.1528 ,\n",
       "            0.1526 , 0.1517 , 0.1516 , 0.1512 , 0.1511 , 0.151  , 0.1505 ,\n",
       "            0.1503 , 0.1493 , 0.1492 , 0.1488 , 0.1484 , 0.1481 , 0.1471 ,\n",
       "            0.1466 , 0.1459 , 0.1455 , 0.1453 , 0.1448 , 0.1432 , 0.1426 ,\n",
       "            0.1425 , 0.1418 , 0.1406 , 0.1398 , 0.1396 , 0.1392 , 0.1384 ,\n",
       "            0.1377 , 0.1366 , 0.1359 , 0.1354 , 0.135  , 0.1346 , 0.1333 ,\n",
       "            0.1312 , 0.1311 , 0.1302 , 0.1296 , 0.1292 , 0.1265 , 0.126  ,\n",
       "            0.12335, 0.1201 , 0.1188 , 0.1166 , 0.115  , 0.11475, 0.11066,\n",
       "            0.1101 , 0.1043 , 0.10126], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.11666667, 0.125     , 0.13333334,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.18333334, 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.575     , 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.60833335, 0.60833335,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65      , 0.65      , 0.65      ,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7       , 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.7083333 , 0.7083333 , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.725     , 0.73333335, 0.73333335, 0.73333335,\n",
       "            0.73333335, 0.7416667 , 0.7416667 , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.7583333 , 0.7583333 , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.825     , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.8666667 , 0.875     , 0.875     , 0.8833333 ,\n",
       "            0.8833333 , 0.8833333 , 0.8833333 , 0.8833333 , 0.8833333 ,\n",
       "            0.89166665, 0.89166665, 0.89166665, 0.9       , 0.90833336,\n",
       "            0.90833336, 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06923077, 0.06923077, 0.06923077, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.10769231, 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.2       , 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.26923078, 0.2769231 , 0.2923077 , 0.3       , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.34615386, 0.36153847, 0.37692308,\n",
       "            0.3846154 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.45384616, 0.46153846, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.6615385 , 0.6615385 , 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.72307694,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8153846 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.8230769 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.293 , 0.2925, 0.291 , 0.2886, 0.2864, 0.2837, 0.2832,\n",
       "            0.2827, 0.2822, 0.2812, 0.2803, 0.28  , 0.2795, 0.279 , 0.278 ,\n",
       "            0.2776, 0.2773, 0.2766, 0.276 , 0.2756, 0.2751, 0.275 , 0.2747,\n",
       "            0.2744, 0.2742, 0.2737, 0.2732, 0.2727, 0.272 , 0.2703, 0.2698,\n",
       "            0.268 , 0.2676, 0.265 , 0.2637, 0.263 , 0.2622, 0.2612, 0.2605,\n",
       "            0.2603, 0.2598, 0.2595, 0.2578, 0.2573, 0.2556, 0.2554, 0.255 ,\n",
       "            0.2542, 0.2527, 0.252 , 0.2515, 0.2512, 0.2494, 0.249 , 0.2482,\n",
       "            0.244 , 0.2437, 0.243 , 0.2426, 0.2399, 0.236 , 0.2355, 0.2346,\n",
       "            0.2343, 0.2322, 0.2318, 0.231 , 0.2303, 0.2301, 0.2283, 0.2272,\n",
       "            0.2269, 0.2266, 0.2252, 0.2251, 0.2246, 0.224 , 0.2239, 0.2216,\n",
       "            0.2203, 0.2197, 0.2195, 0.2184, 0.2168, 0.2166, 0.2156, 0.2152,\n",
       "            0.215 , 0.2144, 0.2134, 0.2118, 0.2113, 0.211 , 0.2103, 0.2096,\n",
       "            0.2073, 0.2065, 0.2059, 0.2053, 0.2032, 0.2029, 0.2021, 0.202 ,\n",
       "            0.2018, 0.2015, 0.2006, 0.2002, 0.1995, 0.199 , 0.1989, 0.1985,\n",
       "            0.1984, 0.1982, 0.1981, 0.1979, 0.1976, 0.1971, 0.1967, 0.1965,\n",
       "            0.1964, 0.1959, 0.1958, 0.1948, 0.1942, 0.1941, 0.1934, 0.1931,\n",
       "            0.193 , 0.1923, 0.1918, 0.1903, 0.19  , 0.1886, 0.1884, 0.1882,\n",
       "            0.1874, 0.1871, 0.1869, 0.1863, 0.1858, 0.1853, 0.185 , 0.1843,\n",
       "            0.1842, 0.1836, 0.1835, 0.1833, 0.1821, 0.1813, 0.1808, 0.1807,\n",
       "            0.1804, 0.1798, 0.1796, 0.1794, 0.179 , 0.1788, 0.1772, 0.177 ,\n",
       "            0.1768, 0.1744, 0.1741, 0.174 , 0.1735, 0.1726, 0.1718, 0.1714,\n",
       "            0.1708, 0.1697, 0.1693, 0.1687, 0.1685, 0.1683, 0.1676, 0.1652,\n",
       "            0.1641, 0.1635, 0.1631, 0.1625, 0.1619, 0.1615, 0.161 , 0.1605,\n",
       "            0.1604, 0.1602, 0.16  , 0.1598, 0.1578, 0.1577, 0.1572, 0.1549,\n",
       "            0.1547, 0.1545, 0.1517, 0.1516, 0.1514, 0.1497, 0.1494, 0.149 ,\n",
       "            0.1487, 0.1484, 0.148 , 0.1478, 0.1473, 0.1471, 0.1462, 0.146 ,\n",
       "            0.1459, 0.1449, 0.1445, 0.144 , 0.1432, 0.142 , 0.1409, 0.1405,\n",
       "            0.1392, 0.139 , 0.1368, 0.1328, 0.1323, 0.13  , 0.126 , 0.1254,\n",
       "            0.1251, 0.1197, 0.1196, 0.1166, 0.1142], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.09166667,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.3       , 0.31666666, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.40833333, 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.46666667, 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.49166667, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.49166667, 0.5       ,\n",
       "            0.5       , 0.5       , 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.6       , 0.6       , 0.6       , 0.6       , 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65833336, 0.65833336, 0.68333334, 0.69166666,\n",
       "            0.69166666, 0.69166666, 0.7       , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.725     , 0.725     , 0.7416667 , 0.75      , 0.75      ,\n",
       "            0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 ,\n",
       "            0.7583333 , 0.7583333 , 0.76666665, 0.775     , 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.80833334, 0.81666666, 0.81666666,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.84166664, 0.84166664,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.8666667 ,\n",
       "            0.8666667 , 0.8666667 , 0.875     , 0.875     , 0.875     ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.89166665, 0.9       , 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.975     , 0.975     , 0.98333335, 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.03846154, 0.05384615,\n",
       "            0.06153846, 0.06153846, 0.06923077, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.22307692, 0.23076923,\n",
       "            0.23076923, 0.23076923, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.26153848, 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.2846154 , 0.2923077 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.4       , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43846154, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.72307694, 0.7307692 , 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.75384617, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.294 , 0.2932, 0.2917, 0.2898, 0.2888, 0.2866, 0.2842,\n",
       "            0.2837, 0.282 , 0.2803, 0.28  , 0.2795, 0.2778, 0.2776, 0.277 ,\n",
       "            0.2769, 0.2766, 0.2754, 0.2747, 0.274 , 0.2727, 0.2715, 0.2708,\n",
       "            0.2703, 0.27  , 0.2698, 0.2693, 0.269 , 0.2678, 0.2673, 0.267 ,\n",
       "            0.2666, 0.2659, 0.2646, 0.2642, 0.263 , 0.2622, 0.2617, 0.258 ,\n",
       "            0.2559, 0.2556, 0.2554, 0.2551, 0.2532, 0.2524, 0.252 , 0.2512,\n",
       "            0.251 , 0.2505, 0.2494, 0.2493, 0.2487, 0.2485, 0.2474, 0.2458,\n",
       "            0.2456, 0.2441, 0.2438, 0.2429, 0.2417, 0.2413, 0.2411, 0.2395,\n",
       "            0.2391, 0.239 , 0.2384, 0.2379, 0.2375, 0.237 , 0.2363, 0.2358,\n",
       "            0.2356, 0.2351, 0.2347, 0.234 , 0.2338, 0.2318, 0.2314, 0.231 ,\n",
       "            0.2297, 0.2292, 0.229 , 0.2285, 0.2283, 0.2281, 0.2274, 0.2268,\n",
       "            0.2263, 0.226 , 0.2252, 0.2251, 0.2249, 0.2246, 0.2244, 0.2239,\n",
       "            0.2222, 0.222 , 0.2212, 0.2203, 0.2202, 0.2181, 0.2177, 0.2166,\n",
       "            0.2163, 0.2156, 0.2128, 0.2123, 0.2115, 0.2113, 0.2109, 0.2106,\n",
       "            0.2104, 0.2103, 0.2101, 0.21  , 0.2091, 0.2079, 0.2069, 0.2068,\n",
       "            0.2059, 0.2058, 0.2035, 0.2029, 0.2023, 0.2018, 0.2017, 0.2007,\n",
       "            0.2004, 0.1996, 0.1984, 0.1981, 0.1976, 0.1965, 0.1958, 0.1953,\n",
       "            0.195 , 0.1943, 0.193 , 0.1927, 0.1912, 0.191 , 0.1901, 0.1898,\n",
       "            0.1891, 0.1879, 0.1876, 0.1866, 0.1863, 0.1852, 0.1837, 0.1833,\n",
       "            0.1816, 0.1814, 0.18  , 0.1792, 0.1791, 0.1788, 0.1783, 0.1768,\n",
       "            0.1766, 0.1763, 0.1761, 0.1758, 0.1748, 0.1747, 0.1736, 0.173 ,\n",
       "            0.1729, 0.1726, 0.171 , 0.1704, 0.17  , 0.1698, 0.1686, 0.1682,\n",
       "            0.1678, 0.1659, 0.1658, 0.1643, 0.1641, 0.1624, 0.1622, 0.162 ,\n",
       "            0.1619, 0.1614, 0.161 , 0.1602, 0.1588, 0.1583, 0.1569, 0.1566,\n",
       "            0.1561, 0.1555, 0.1554, 0.155 , 0.1534, 0.1531, 0.1512, 0.151 ,\n",
       "            0.1501, 0.1462, 0.1445, 0.1431, 0.1395, 0.1389, 0.1368, 0.1361,\n",
       "            0.1354, 0.1328, 0.1321, 0.1313], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.05833333, 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.175     , 0.175     ,\n",
       "            0.175     , 0.175     , 0.175     , 0.175     , 0.175     ,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.2       ,\n",
       "            0.2       , 0.20833333, 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.275     , 0.275     , 0.275     , 0.275     , 0.29166666,\n",
       "            0.29166666, 0.29166666, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.325     , 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.375     , 0.375     , 0.39166668, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.49166667, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65      , 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.725     , 0.725     ,\n",
       "            0.73333335, 0.73333335, 0.73333335, 0.73333335, 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.825     , 0.825     , 0.825     , 0.825     ,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85      , 0.85833335, 0.8666667 , 0.8666667 ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.90833336, 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.94166666, 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.06923077, 0.06923077, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.11538462, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.22307692, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.25384617, 0.25384617, 0.26923078, 0.26923078, 0.26923078,\n",
       "            0.26923078, 0.2769231 , 0.2769231 , 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.31538463, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.44615385, 0.44615385,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46153846, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.5       , 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.6615385 , 0.6615385 , 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7076923 ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.72307694, 0.73846155,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.304 , 0.3013, 0.3003, 0.299 , 0.2988, 0.2983, 0.298 ,\n",
       "            0.2961, 0.296 , 0.2954, 0.2944, 0.2932, 0.2927, 0.2925, 0.2917,\n",
       "            0.2915, 0.2913, 0.2903, 0.29  , 0.2898, 0.289 , 0.2886, 0.2878,\n",
       "            0.2876, 0.2869, 0.2854, 0.2844, 0.2842, 0.2827, 0.2817, 0.281 ,\n",
       "            0.2803, 0.28  , 0.2798, 0.279 , 0.2788, 0.2786, 0.278 , 0.2776,\n",
       "            0.2773, 0.2761, 0.2751, 0.275 , 0.2744, 0.2737, 0.2727, 0.2725,\n",
       "            0.2715, 0.2712, 0.2703, 0.27  , 0.2698, 0.269 , 0.2688, 0.2686,\n",
       "            0.2676, 0.2673, 0.2668, 0.2666, 0.2659, 0.2651, 0.265 , 0.2646,\n",
       "            0.2637, 0.2634, 0.2632, 0.263 , 0.2625, 0.2622, 0.262 , 0.2615,\n",
       "            0.2607, 0.2605, 0.2595, 0.2585, 0.2583, 0.2578, 0.2568, 0.2556,\n",
       "            0.2554, 0.255 , 0.2534, 0.253 , 0.2527, 0.2515, 0.2512, 0.2498,\n",
       "            0.249 , 0.2485, 0.2473, 0.2471, 0.247 , 0.2417, 0.2415, 0.2406,\n",
       "            0.2399, 0.2397, 0.2395, 0.2382, 0.2372, 0.2363, 0.2314, 0.2313,\n",
       "            0.231 , 0.2307, 0.2301, 0.2297, 0.2286, 0.2281, 0.2277, 0.2269,\n",
       "            0.2261, 0.2252, 0.2244, 0.2239, 0.2229, 0.2224, 0.2213, 0.2207,\n",
       "            0.2202, 0.22  , 0.2197, 0.2195, 0.2194, 0.2191, 0.219 , 0.2189,\n",
       "            0.2186, 0.2177, 0.2166, 0.2163, 0.2158, 0.215 , 0.2147, 0.2145,\n",
       "            0.2142, 0.2137, 0.213 , 0.2129, 0.212 , 0.2114, 0.2113, 0.2109,\n",
       "            0.2108, 0.2096, 0.2089, 0.2086, 0.2075, 0.207 , 0.2068, 0.206 ,\n",
       "            0.2056, 0.2051, 0.2048, 0.2047, 0.2039, 0.2037, 0.2015, 0.2009,\n",
       "            0.1996, 0.1984, 0.1965, 0.1964, 0.1958, 0.1954, 0.1953, 0.195 ,\n",
       "            0.194 , 0.1931, 0.1923, 0.1915, 0.1907, 0.1886, 0.1864, 0.1853,\n",
       "            0.1848, 0.1844, 0.1842, 0.1837, 0.1835, 0.1833, 0.1829, 0.1826,\n",
       "            0.1824, 0.1821, 0.1813, 0.1807, 0.18  , 0.1781, 0.1775, 0.1771,\n",
       "            0.1758, 0.1753, 0.1738, 0.1737, 0.172 , 0.171 , 0.1707, 0.169 ,\n",
       "            0.1646, 0.1643, 0.1622, 0.162 , 0.1604, 0.1597, 0.1589, 0.1584,\n",
       "            0.1575, 0.1559, 0.1554, 0.1549, 0.1525, 0.1517, 0.1504, 0.1461,\n",
       "            0.1362], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.075     , 0.075     , 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.1       , 0.1       , 0.1       , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15833333, 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.175     , 0.175     , 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.21666667, 0.225     , 0.23333333, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.31666666, 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.33333334, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.4       , 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55833334, 0.56666666, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.56666666, 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.6       , 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65      , 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.73333335, 0.7416667 , 0.7416667 , 0.75      ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85      , 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.875     , 0.8833333 , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.93333334, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.09230769, 0.1       , 0.1       , 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.18461539, 0.18461539, 0.18461539,\n",
       "            0.1923077 , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.3       , 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.34615386, 0.35384616, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.3846154 , 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.5       , 0.50769234,\n",
       "            0.52307695, 0.5307692 , 0.54615384, 0.54615384, 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.54615384, 0.54615384, 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.54615384, 0.54615384, 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.64615387, 0.65384614, 0.65384614,\n",
       "            0.65384614, 0.66923076, 0.66923076, 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7076923 , 0.7076923 , 0.7076923 , 0.7076923 ,\n",
       "            0.7076923 , 0.7076923 , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.8769231 , 0.8769231 , 0.88461536, 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3247, 0.3245, 0.3235, 0.323 , 0.32  , 0.3193, 0.318 ,\n",
       "            0.3176, 0.3171, 0.3162, 0.316 , 0.3147, 0.3145, 0.314 , 0.3135,\n",
       "            0.3132, 0.3127, 0.3125, 0.3123, 0.312 , 0.3108, 0.3105, 0.31  ,\n",
       "            0.3096, 0.3093, 0.309 , 0.3086, 0.3083, 0.3079, 0.3076, 0.3074,\n",
       "            0.3071, 0.3066, 0.3064, 0.3062, 0.306 , 0.3054, 0.3052, 0.3042,\n",
       "            0.3037, 0.3035, 0.303 , 0.3027, 0.3013, 0.3008, 0.3005, 0.3003,\n",
       "            0.2998, 0.2996, 0.2988, 0.298 , 0.2979, 0.2969, 0.2966, 0.2964,\n",
       "            0.2957, 0.2954, 0.295 , 0.294 , 0.2932, 0.293 , 0.2927, 0.2903,\n",
       "            0.2896, 0.2888, 0.287 , 0.2847, 0.2832, 0.2793, 0.276 , 0.274 ,\n",
       "            0.272 , 0.2712, 0.27  , 0.2695, 0.268 , 0.2676, 0.2673, 0.2664,\n",
       "            0.2656, 0.2646, 0.2637, 0.2625, 0.2615, 0.2605, 0.2585, 0.2566,\n",
       "            0.255 , 0.2546, 0.2522, 0.252 , 0.2493, 0.2489, 0.2483, 0.248 ,\n",
       "            0.2474, 0.247 , 0.2451, 0.2449, 0.2445, 0.2434, 0.243 , 0.2429,\n",
       "            0.2415, 0.2411, 0.2402, 0.2399, 0.2391, 0.2383, 0.2374, 0.237 ,\n",
       "            0.2367, 0.2366, 0.236 , 0.2356, 0.2352, 0.235 , 0.2347, 0.2344,\n",
       "            0.2334, 0.2332, 0.2323, 0.2319, 0.2316, 0.2314, 0.2307, 0.2303,\n",
       "            0.2301, 0.2297, 0.2283, 0.2281, 0.2268, 0.2263, 0.2261, 0.2257,\n",
       "            0.2255, 0.2247, 0.2244, 0.223 , 0.2229, 0.2218, 0.2216, 0.2195,\n",
       "            0.2191, 0.2184, 0.2177, 0.2168, 0.2163, 0.2158, 0.2157, 0.2153,\n",
       "            0.2152, 0.215 , 0.2147, 0.2145, 0.2139, 0.213 , 0.2119, 0.2113,\n",
       "            0.209 , 0.2076, 0.2074, 0.206 , 0.2056, 0.2054, 0.2048, 0.2043,\n",
       "            0.2042, 0.202 , 0.2006, 0.2002, 0.2001, 0.1989, 0.1985, 0.197 ,\n",
       "            0.1954, 0.1953, 0.1948, 0.1946, 0.1941, 0.1934, 0.1925, 0.1924,\n",
       "            0.1915, 0.1912, 0.1906, 0.1904, 0.1898, 0.1885, 0.1879, 0.1866,\n",
       "            0.1841, 0.1831, 0.1823, 0.1807, 0.1797, 0.1792, 0.1785, 0.1781,\n",
       "            0.178 , 0.1736, 0.1724, 0.1707, 0.1681, 0.1678, 0.1661, 0.1654,\n",
       "            0.1641, 0.1635, 0.1592, 0.1539, 0.1355], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.1       , 0.10833333,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.23333333, 0.23333333, 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.73333335,\n",
       "            0.7416667 , 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.8833333 , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.90833336, 0.9166667 , 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.06153846, 0.08461539, 0.11538462, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.16153847, 0.17692308, 0.1923077 ,\n",
       "            0.21538462, 0.23076923, 0.24615385, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.4923077 , 0.4923077 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.50769234, 0.50769234, 0.5153846 , 0.52307695, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.5538462 , 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5692308 , 0.5692308 , 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63076925, 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.64615387, 0.64615387,\n",
       "            0.65384614, 0.65384614, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.73846155, 0.75384617, 0.75384617,\n",
       "            0.75384617, 0.75384617, 0.75384617, 0.75384617, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.77692306, 0.77692306, 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3516, 0.3513, 0.351 , 0.3508, 0.3506, 0.3499, 0.3496,\n",
       "            0.3494, 0.349 , 0.3489, 0.3486, 0.3484, 0.3481, 0.348 , 0.3477,\n",
       "            0.3474, 0.3472, 0.3462, 0.346 , 0.3457, 0.3455, 0.3452, 0.345 ,\n",
       "            0.3447, 0.3433, 0.3418, 0.3403, 0.34  , 0.3394, 0.339 , 0.3386,\n",
       "            0.3381, 0.338 , 0.3376, 0.336 , 0.3357, 0.335 , 0.333 , 0.3325,\n",
       "            0.3318, 0.33  , 0.3296, 0.3271, 0.327 , 0.3262, 0.3254, 0.3252,\n",
       "            0.3225, 0.3218, 0.321 , 0.3206, 0.317 , 0.3164, 0.3147, 0.312 ,\n",
       "            0.3118, 0.309 , 0.3083, 0.3079, 0.3062, 0.306 , 0.3052, 0.3047,\n",
       "            0.3035, 0.3032, 0.3027, 0.3   , 0.2998, 0.2993, 0.2937, 0.2927,\n",
       "            0.289 , 0.286 , 0.2856, 0.2825, 0.2815, 0.2747, 0.2708, 0.2705,\n",
       "            0.2703, 0.2698, 0.2695, 0.269 , 0.2688, 0.2683, 0.268 , 0.2673,\n",
       "            0.2666, 0.2654, 0.2634, 0.2632, 0.2627, 0.2617, 0.2615, 0.2612,\n",
       "            0.2605, 0.26  , 0.2588, 0.2585, 0.2583, 0.258 , 0.2578, 0.2576,\n",
       "            0.2573, 0.256 , 0.2556, 0.2542, 0.253 , 0.2527, 0.2522, 0.252 ,\n",
       "            0.2517, 0.2512, 0.2498, 0.2482, 0.2477, 0.2467, 0.2466, 0.2463,\n",
       "            0.2462, 0.2452, 0.2451, 0.2448, 0.2434, 0.243 , 0.2428, 0.2422,\n",
       "            0.2421, 0.2413, 0.241 , 0.2407, 0.2401, 0.2397, 0.239 , 0.2388,\n",
       "            0.2386, 0.2384, 0.2383, 0.2379, 0.2372, 0.2362, 0.2358, 0.2344,\n",
       "            0.2343, 0.2332, 0.2323, 0.2314, 0.2292, 0.229 , 0.2289, 0.2285,\n",
       "            0.2261, 0.2256, 0.2234, 0.2216, 0.2208, 0.22  , 0.2198, 0.2191,\n",
       "            0.219 , 0.2181, 0.218 , 0.2166, 0.2157, 0.2147, 0.2144, 0.2129,\n",
       "            0.2124, 0.2114, 0.2109, 0.2108, 0.2084, 0.2079, 0.2058, 0.2053,\n",
       "            0.2051, 0.2047, 0.2037, 0.2034, 0.2032, 0.2031, 0.2029, 0.2024,\n",
       "            0.2021, 0.2012, 0.2002, 0.2   , 0.1993, 0.1964, 0.1935, 0.1931,\n",
       "            0.1921, 0.1915, 0.1897, 0.1882, 0.187 , 0.1855, 0.1838, 0.1819,\n",
       "            0.1764, 0.1757, 0.1741, 0.1733, 0.1704, 0.166 , 0.1638, 0.156 ,\n",
       "            0.1458, 0.1381], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.24166666, 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.28333333, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.325     , 0.33333334, 0.35      ,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45833334, 0.475     , 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.69166666, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.7583333 , 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.81666666, 0.825     , 0.84166664,\n",
       "            0.85      , 0.85      , 0.85833335, 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.925     , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.07692308,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.20769231, 0.21538462, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.2769231 ,\n",
       "            0.2846154 , 0.3       , 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5538462 , 0.5538462 ,\n",
       "            0.5538462 , 0.5538462 , 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.56153846, 0.56153846, 0.5692308 , 0.5692308 , 0.5692308 ,\n",
       "            0.5692308 , 0.5692308 , 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5769231 , 0.5769231 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.6230769 , 0.63076925, 0.63076925, 0.63076925,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7076923 , 0.7076923 , 0.7153846 , 0.7153846 , 0.7153846 ,\n",
       "            0.7153846 , 0.7307692 , 0.73846155, 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8076923 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.88461536, 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9307692 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4016, 0.4011, 0.4004, 0.3994, 0.3992, 0.3987, 0.3984,\n",
       "            0.398 , 0.3977, 0.3962, 0.3958, 0.3943, 0.394 , 0.3938, 0.3926,\n",
       "            0.392 , 0.3918, 0.3916, 0.391 , 0.3909, 0.3904, 0.3901, 0.39  ,\n",
       "            0.3892, 0.3884, 0.3882, 0.3872, 0.3865, 0.3862, 0.386 , 0.3857,\n",
       "            0.385 , 0.3848, 0.3843, 0.384 , 0.3833, 0.3826, 0.3823, 0.3804,\n",
       "            0.3782, 0.3774, 0.3772, 0.375 , 0.3745, 0.3743, 0.3728, 0.3723,\n",
       "            0.372 , 0.3696, 0.3657, 0.3645, 0.363 , 0.3608, 0.359 , 0.3577,\n",
       "            0.3545, 0.3533, 0.3513, 0.351 , 0.3464, 0.3418, 0.3384, 0.3374,\n",
       "            0.3364, 0.336 , 0.3352, 0.3335, 0.3318, 0.33  , 0.3298, 0.3274,\n",
       "            0.327 , 0.3257, 0.3242, 0.3193, 0.3147, 0.3145, 0.3142, 0.3108,\n",
       "            0.3105, 0.3086, 0.308 , 0.3027, 0.3025, 0.2974, 0.297 , 0.2961,\n",
       "            0.295 , 0.2937, 0.2935, 0.2915, 0.2908, 0.29  , 0.2883, 0.288 ,\n",
       "            0.2876, 0.287 , 0.2864, 0.286 , 0.2856, 0.2847, 0.2842, 0.2815,\n",
       "            0.279 , 0.2776, 0.2751, 0.2737, 0.2732, 0.273 , 0.2708, 0.2705,\n",
       "            0.2703, 0.27  , 0.2695, 0.2693, 0.269 , 0.2688, 0.2678, 0.2666,\n",
       "            0.2659, 0.2654, 0.2646, 0.264 , 0.2637, 0.2634, 0.263 , 0.262 ,\n",
       "            0.2615, 0.2605, 0.2603, 0.2595, 0.2588, 0.258 , 0.2578, 0.2573,\n",
       "            0.2554, 0.2551, 0.2542, 0.2532, 0.2527, 0.2522, 0.252 , 0.2483,\n",
       "            0.248 , 0.2471, 0.2466, 0.2444, 0.2429, 0.2424, 0.2417, 0.2415,\n",
       "            0.2401, 0.239 , 0.2384, 0.2379, 0.237 , 0.2367, 0.2363, 0.2356,\n",
       "            0.2351, 0.2343, 0.234 , 0.2332, 0.2322, 0.2302, 0.2299, 0.2297,\n",
       "            0.2273, 0.2269, 0.2263, 0.2244, 0.224 , 0.2239, 0.2218, 0.2205,\n",
       "            0.2198, 0.215 , 0.2148, 0.2139, 0.2134, 0.213 , 0.2103, 0.2091,\n",
       "            0.2086, 0.2074, 0.2069, 0.2059, 0.2024, 0.1971, 0.1959, 0.1929,\n",
       "            0.1921, 0.1913, 0.1896, 0.188 , 0.1852, 0.1837, 0.1824, 0.1823,\n",
       "            0.1816, 0.1796, 0.1782, 0.1774, 0.1744, 0.1705, 0.1664, 0.1582,\n",
       "            0.1537, 0.1486, 0.1427, 0.1368, 0.1311], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.2       , 0.2       ,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.35833332,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.44166666, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.5083333 , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65      ,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.7416667 , 0.75      , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.80833334, 0.81666666,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.875     , 0.875     , 0.875     , 0.8833333 , 0.8833333 ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.22307692, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.45384616, 0.46153846, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5692308 , 0.5692308 , 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5769231 , 0.5769231 , 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.6230769 , 0.6230769 , 0.63076925, 0.63076925,\n",
       "            0.64615387, 0.64615387, 0.64615387, 0.64615387, 0.64615387,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7076923 , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.86923075, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.88461536, 0.88461536, 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.45   , 0.449  , 0.4482 , 0.4465 , 0.4453 , 0.445  ,\n",
       "            0.4443 , 0.4436 , 0.4434 , 0.443  , 0.4424 , 0.442  , 0.441  ,\n",
       "            0.4407 , 0.4397 , 0.4392 , 0.439  , 0.4355 , 0.4343 , 0.434  ,\n",
       "            0.4329 , 0.4304 , 0.4302 , 0.43   , 0.4282 , 0.428  , 0.427  ,\n",
       "            0.4268 , 0.4253 , 0.4238 , 0.4229 , 0.4219 , 0.4216 , 0.421  ,\n",
       "            0.4204 , 0.4202 , 0.4197 , 0.4185 , 0.4177 , 0.4138 , 0.413  ,\n",
       "            0.4128 , 0.4097 , 0.4077 , 0.4067 , 0.406  , 0.402  , 0.4019 ,\n",
       "            0.3992 , 0.3987 , 0.3984 , 0.395  , 0.392  , 0.389  , 0.3882 ,\n",
       "            0.3835 , 0.3823 , 0.382  , 0.3796 , 0.3728 , 0.3713 , 0.363  ,\n",
       "            0.3555 , 0.3552 , 0.3528 , 0.35   , 0.3481 , 0.348  , 0.3467 ,\n",
       "            0.343  , 0.342  , 0.335  , 0.3335 , 0.3323 , 0.3284 , 0.3262 ,\n",
       "            0.3218 , 0.3213 , 0.3203 , 0.32   , 0.3176 , 0.315  , 0.3142 ,\n",
       "            0.3137 , 0.3127 , 0.3123 , 0.31   , 0.3093 , 0.309  , 0.3088 ,\n",
       "            0.3083 , 0.3076 , 0.3066 , 0.3064 , 0.3062 , 0.3044 , 0.3035 ,\n",
       "            0.3032 , 0.3015 , 0.2998 , 0.298  , 0.297  , 0.2954 , 0.2944 ,\n",
       "            0.2935 , 0.2925 , 0.2922 , 0.292  , 0.2893 , 0.2886 , 0.288  ,\n",
       "            0.2876 , 0.2852 , 0.285  , 0.2847 , 0.2842 , 0.2837 , 0.2834 ,\n",
       "            0.2822 , 0.282  , 0.2817 , 0.2815 , 0.2812 , 0.281  , 0.2803 ,\n",
       "            0.2798 , 0.2793 , 0.2788 , 0.2776 , 0.2773 , 0.277  , 0.2764 ,\n",
       "            0.2751 , 0.2747 , 0.2727 , 0.2725 , 0.2688 , 0.268  , 0.2673 ,\n",
       "            0.267  , 0.2668 , 0.2659 , 0.2654 , 0.2642 , 0.264  , 0.2637 ,\n",
       "            0.2632 , 0.2612 , 0.2603 , 0.26   , 0.2593 , 0.2588 , 0.2568 ,\n",
       "            0.2566 , 0.255  , 0.2542 , 0.2534 , 0.2532 , 0.2524 , 0.2517 ,\n",
       "            0.2505 , 0.2493 , 0.2483 , 0.2482 , 0.248  , 0.2474 , 0.2473 ,\n",
       "            0.2463 , 0.2458 , 0.2451 , 0.2449 , 0.2444 , 0.2422 , 0.2411 ,\n",
       "            0.2401 , 0.2388 , 0.2372 , 0.237  , 0.2367 , 0.2358 , 0.2307 ,\n",
       "            0.2301 , 0.2286 , 0.2277 , 0.2266 , 0.2257 , 0.2244 , 0.2242 ,\n",
       "            0.2239 , 0.2238 , 0.2208 , 0.2185 , 0.2173 , 0.217  , 0.2147 ,\n",
       "            0.2142 , 0.2139 , 0.2118 , 0.2073 , 0.2047 , 0.2002 , 0.2001 ,\n",
       "            0.1958 , 0.1942 , 0.1893 , 0.1877 , 0.186  , 0.1835 , 0.1833 ,\n",
       "            0.181  , 0.1803 , 0.1794 , 0.1764 , 0.1757 , 0.1714 , 0.1643 ,\n",
       "            0.1636 , 0.1558 , 0.1514 , 0.1428 , 0.1381 , 0.1364 , 0.1342 ,\n",
       "            0.1305 , 0.11755], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.00769231, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.1       , 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.24166666, 0.25      , 0.26666668, 0.26666668, 0.26666668,\n",
       "            0.275     , 0.275     , 0.28333333, 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.31666666, 0.33333334,\n",
       "            0.35833332, 0.36666667, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.525     , 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.775     , 0.775     , 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.85833335, 0.85833335, 0.85833335, 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5846154 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6       , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.63076925, 0.63076925, 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.64615387, 0.64615387,\n",
       "            0.64615387, 0.64615387, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.72307694, 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.501 , 0.4995, 0.499 , 0.4983, 0.4963, 0.4944, 0.4937,\n",
       "            0.4927, 0.4922, 0.492 , 0.4915, 0.4902, 0.4893, 0.489 , 0.488 ,\n",
       "            0.4858, 0.4854, 0.4841, 0.4802, 0.4792, 0.479 , 0.477 , 0.4734,\n",
       "            0.4724, 0.4722, 0.4712, 0.471 , 0.4685, 0.4675, 0.467 , 0.4658,\n",
       "            0.4656, 0.465 , 0.4646, 0.4644, 0.4631, 0.4622, 0.462 , 0.4604,\n",
       "            0.46  , 0.4575, 0.4568, 0.4565, 0.4563, 0.4548, 0.4546, 0.451 ,\n",
       "            0.4504, 0.449 , 0.4453, 0.4446, 0.4434, 0.4426, 0.44  , 0.437 ,\n",
       "            0.4343, 0.4336, 0.4302, 0.429 , 0.4277, 0.427 , 0.4255, 0.425 ,\n",
       "            0.4238, 0.4229, 0.4214, 0.4207, 0.4119, 0.4072, 0.405 , 0.4036,\n",
       "            0.3906, 0.3875, 0.3833, 0.3816, 0.373 , 0.369 , 0.3665, 0.361 ,\n",
       "            0.36  , 0.3557, 0.3552, 0.3525, 0.348 , 0.3462, 0.345 , 0.3433,\n",
       "            0.3425, 0.3386, 0.334 , 0.3337, 0.3333, 0.3328, 0.3323, 0.331 ,\n",
       "            0.3303, 0.33  , 0.3296, 0.3293, 0.329 , 0.3286, 0.3267, 0.3242,\n",
       "            0.3237, 0.3235, 0.32  , 0.3193, 0.3171, 0.3162, 0.3154, 0.3147,\n",
       "            0.3137, 0.3127, 0.3118, 0.3098, 0.3088, 0.3086, 0.3071, 0.3066,\n",
       "            0.3064, 0.306 , 0.3057, 0.3044, 0.304 , 0.3032, 0.3018, 0.3013,\n",
       "            0.301 , 0.3008, 0.3005, 0.3003, 0.2993, 0.2986, 0.298 , 0.2976,\n",
       "            0.2974, 0.297 , 0.2961, 0.2944, 0.2908, 0.2905, 0.2898, 0.2896,\n",
       "            0.2874, 0.286 , 0.2854, 0.283 , 0.2805, 0.2795, 0.2778, 0.2769,\n",
       "            0.2756, 0.275 , 0.2744, 0.274 , 0.273 , 0.2722, 0.2717, 0.27  ,\n",
       "            0.2688, 0.2686, 0.2678, 0.2673, 0.267 , 0.2668, 0.2666, 0.2646,\n",
       "            0.264 , 0.2607, 0.26  , 0.2598, 0.2593, 0.257 , 0.2566, 0.2563,\n",
       "            0.2554, 0.2527, 0.2507, 0.2489, 0.2463, 0.246 , 0.2444, 0.2434,\n",
       "            0.2433, 0.2421, 0.2413, 0.2394, 0.2368, 0.235 , 0.2328, 0.2323,\n",
       "            0.2301, 0.2299, 0.2297, 0.2264, 0.2256, 0.2227, 0.2224, 0.2207,\n",
       "            0.2202, 0.219 , 0.218 , 0.2168, 0.2134, 0.21  , 0.2079, 0.2048,\n",
       "            0.2039, 0.2007, 0.1976, 0.1948, 0.1937, 0.1936, 0.1921, 0.1842,\n",
       "            0.1803, 0.1707, 0.1681, 0.1643, 0.1632, 0.1598, 0.1504, 0.1503,\n",
       "            0.1412, 0.137 , 0.1367, 0.1279, 0.1232, 0.121 , 0.1193, 0.1054],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.32307693, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.13333334, 0.13333334, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.175     , 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.225     , 0.225     , 0.23333333, 0.24166666, 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.3       , 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.31666666, 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.46666667, 0.475     , 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.5083333 , 0.525     ,\n",
       "            0.525     , 0.53333336, 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.725     , 0.725     ,\n",
       "            0.73333335, 0.73333335, 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.05384615, 0.06153846, 0.06923077, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.12307692, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.2769231 , 0.2846154 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.5846154 , 0.5846154 , 0.5846154 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.6230769 , 0.6230769 ,\n",
       "            0.6230769 , 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.64615387, 0.64615387, 0.65384614, 0.65384614,\n",
       "            0.65384614, 0.6615385 , 0.6615385 , 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.7692308 , 0.7692308 ,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.5586 , 0.5557 , 0.554  , 0.5522 , 0.551  , 0.5454 ,\n",
       "            0.544  , 0.5435 , 0.543  , 0.5425 , 0.5405 , 0.5396 , 0.5386 ,\n",
       "            0.536  , 0.533  , 0.532  , 0.531  , 0.5264 , 0.523  , 0.522  ,\n",
       "            0.52   , 0.515  , 0.514  , 0.513  , 0.512  , 0.5117 , 0.51   ,\n",
       "            0.5093 , 0.5073 , 0.507  , 0.506  , 0.505  , 0.504  , 0.4998 ,\n",
       "            0.4988 , 0.4973 , 0.497  , 0.4963 , 0.4946 , 0.4941 , 0.4937 ,\n",
       "            0.4927 , 0.487  , 0.4868 , 0.4795 , 0.479  , 0.4773 , 0.4763 ,\n",
       "            0.4758 , 0.4753 , 0.4739 , 0.4734 , 0.4702 , 0.4695 , 0.4688 ,\n",
       "            0.465  , 0.462  , 0.4558 , 0.4553 , 0.4512 , 0.4495 , 0.4485 ,\n",
       "            0.4456 , 0.443  , 0.4333 , 0.4304 , 0.4202 , 0.4175 , 0.412  ,\n",
       "            0.4111 , 0.39   , 0.385  , 0.3848 , 0.38   , 0.3782 , 0.3762 ,\n",
       "            0.374  , 0.3704 , 0.3691 , 0.3667 , 0.364  , 0.3625 , 0.3606 ,\n",
       "            0.3594 , 0.3591 , 0.359  , 0.358  , 0.3574 , 0.3562 , 0.3552 ,\n",
       "            0.355  , 0.3545 , 0.3538 , 0.3523 , 0.3516 , 0.3506 , 0.3503 ,\n",
       "            0.35   , 0.3489 , 0.3455 , 0.344  , 0.3403 , 0.3386 , 0.3376 ,\n",
       "            0.3374 , 0.337  , 0.3354 , 0.335  , 0.3347 , 0.3342 , 0.334  ,\n",
       "            0.3335 , 0.3323 , 0.3313 , 0.3306 , 0.3286 , 0.3284 , 0.3274 ,\n",
       "            0.3262 , 0.3254 , 0.3252 , 0.3242 , 0.3235 , 0.323  , 0.3228 ,\n",
       "            0.321  , 0.3203 , 0.32   , 0.3198 , 0.319  , 0.318  , 0.3174 ,\n",
       "            0.3147 , 0.3103 , 0.31   , 0.3098 , 0.308  , 0.3071 , 0.3066 ,\n",
       "            0.3044 , 0.304  , 0.3037 , 0.3025 , 0.3022 , 0.3013 , 0.299  ,\n",
       "            0.2966 , 0.2944 , 0.2942 , 0.2935 , 0.2932 , 0.293  , 0.2922 ,\n",
       "            0.2908 , 0.2905 , 0.2896 , 0.287  , 0.2869 , 0.2847 , 0.2812 ,\n",
       "            0.279  , 0.2786 , 0.2769 , 0.2761 , 0.2683 , 0.268  , 0.2666 ,\n",
       "            0.2664 , 0.264  , 0.2627 , 0.2622 , 0.259  , 0.2527 , 0.2522 ,\n",
       "            0.248  , 0.2456 , 0.2445 , 0.2434 , 0.2422 , 0.2413 , 0.2395 ,\n",
       "            0.2358 , 0.2356 , 0.2352 , 0.2334 , 0.2332 , 0.2306 , 0.2292 ,\n",
       "            0.2285 , 0.2266 , 0.2233 , 0.2218 , 0.2177 , 0.2137 , 0.2103 ,\n",
       "            0.2094 , 0.2089 , 0.2079 , 0.2063 , 0.204  , 0.2034 , 0.2    ,\n",
       "            0.1979 , 0.194  , 0.1849 , 0.1808 , 0.1736 , 0.1587 , 0.158  ,\n",
       "            0.157  , 0.1537 , 0.1511 , 0.1494 , 0.1383 , 0.1381 , 0.1378 ,\n",
       "            0.1283 , 0.124  , 0.11475, 0.1101 , 0.1095 , 0.10913, 0.09467],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00833333, dtype=float32),\n",
       "    'tpr': array(0.5, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.15      , 0.15833333,\n",
       "            0.175     , 0.175     , 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.29166666, 0.29166666, 0.3       , 0.3       , 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.41666666, 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.625     , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.675     , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.7916667 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.35384616, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4       ,\n",
       "            0.4076923 , 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.6230769 , 0.63076925, 0.63076925, 0.63076925,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.6615385 , 0.6615385 , 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.7076923 , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.74615383, 0.74615383, 0.75384617, 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 , 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.86923075, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.8769231 , 0.8769231 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.614  , 0.606  , 0.6045 , 0.6006 , 0.595  , 0.594  ,\n",
       "            0.5938 , 0.5933 , 0.593  , 0.592  , 0.591  , 0.5903 , 0.59   ,\n",
       "            0.588  , 0.586  , 0.585  , 0.583  , 0.579  , 0.578  , 0.577  ,\n",
       "            0.5703 , 0.5674 , 0.5645 , 0.558  , 0.5566 , 0.556  , 0.555  ,\n",
       "            0.5537 , 0.5522 , 0.55   , 0.5493 , 0.5464 , 0.546  , 0.5444 ,\n",
       "            0.543  , 0.5415 , 0.536  , 0.5356 , 0.534  , 0.5337 , 0.5303 ,\n",
       "            0.5293 , 0.5283 , 0.523  , 0.522  , 0.521  , 0.518  , 0.5146 ,\n",
       "            0.512  , 0.5117 , 0.511  , 0.508  , 0.5054 , 0.5044 , 0.502  ,\n",
       "            0.501  , 0.4941 , 0.4902 , 0.483  , 0.4824 , 0.4807 , 0.4773 ,\n",
       "            0.4756 , 0.4749 , 0.4712 , 0.4631 , 0.4534 , 0.4485 , 0.4377 ,\n",
       "            0.4312 , 0.425  , 0.4102 , 0.4045 , 0.4001 , 0.398  , 0.3882 ,\n",
       "            0.3875 , 0.3853 , 0.384  , 0.383  , 0.3823 , 0.381  , 0.3806 ,\n",
       "            0.3804 , 0.38   , 0.3782 , 0.378  , 0.3767 , 0.3757 , 0.3755 ,\n",
       "            0.3748 , 0.3743 , 0.3733 , 0.3708 , 0.3694 , 0.3667 , 0.3662 ,\n",
       "            0.3635 , 0.363  , 0.3628 , 0.3613 , 0.3608 , 0.3591 , 0.358  ,\n",
       "            0.3574 , 0.3564 , 0.356  , 0.3557 , 0.3535 , 0.3533 , 0.3525 ,\n",
       "            0.352  , 0.3513 , 0.3506 , 0.349  , 0.348  , 0.3467 , 0.3464 ,\n",
       "            0.3452 , 0.3445 , 0.3425 , 0.3423 , 0.3403 , 0.3398 , 0.3394 ,\n",
       "            0.3386 , 0.3381 , 0.338  , 0.3374 , 0.3372 , 0.3362 , 0.3354 ,\n",
       "            0.334  , 0.333  , 0.3281 , 0.3262 , 0.3257 , 0.325  , 0.3237 ,\n",
       "            0.3232 , 0.3218 , 0.3208 , 0.3196 , 0.3186 , 0.3152 , 0.314  ,\n",
       "            0.3118 , 0.3113 , 0.311  , 0.3108 , 0.3103 , 0.3096 , 0.3093 ,\n",
       "            0.3079 , 0.3076 , 0.306  , 0.3047 , 0.3025 , 0.302  , 0.3008 ,\n",
       "            0.3003 , 0.2961 , 0.2952 , 0.2903 , 0.289  , 0.2876 , 0.2766 ,\n",
       "            0.2761 , 0.2651 , 0.263  , 0.2627 , 0.26   , 0.257  , 0.2566 ,\n",
       "            0.2542 , 0.2485 , 0.2466 , 0.2438 , 0.2429 , 0.2418 , 0.2413 ,\n",
       "            0.2397 , 0.2386 , 0.2374 , 0.2356 , 0.234  , 0.2328 , 0.2325 ,\n",
       "            0.231  , 0.2294 , 0.2278 , 0.2277 , 0.2263 , 0.2255 , 0.2233 ,\n",
       "            0.218  , 0.2145 , 0.2144 , 0.2139 , 0.209  , 0.2089 , 0.2039 ,\n",
       "            0.2024 , 0.2004 , 0.1991 , 0.1919 , 0.1896 , 0.1833 , 0.1776 ,\n",
       "            0.1752 , 0.1615 , 0.1464 , 0.1459 , 0.1448 , 0.1415 , 0.1384 ,\n",
       "            0.1372 , 0.1362 , 0.1256 , 0.1249 , 0.1152 , 0.11084, 0.10156,\n",
       "            0.09875, 0.09686, 0.0836 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.01666667, dtype=float32),\n",
       "    'tpr': array(0.5692308, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.16666667, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.26666668,\n",
       "            0.275     , 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.38333333, 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5       , 0.51666665,\n",
       "            0.525     , 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.6       , 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.75      , 0.7583333 ,\n",
       "            0.7583333 , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.3846154 , 0.3923077 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5692308 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63076925, 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.66923076, 0.6769231 ,\n",
       "            0.6769231 , 0.6769231 , 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.86153847, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.8769231 , 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.669  , 0.6577 , 0.6567 , 0.6562 , 0.656  , 0.6504 ,\n",
       "            0.646  , 0.643  , 0.6426 , 0.642  , 0.639  , 0.6387 , 0.6377 ,\n",
       "            0.636  , 0.635  , 0.6323 , 0.632  , 0.629  , 0.627  , 0.6245 ,\n",
       "            0.623  , 0.616  , 0.6147 , 0.613  , 0.6113 , 0.6064 , 0.6016 ,\n",
       "            0.6    , 0.5996 , 0.5977 , 0.5967 , 0.595  , 0.593  , 0.592  ,\n",
       "            0.5913 , 0.5894 , 0.588  , 0.5874 , 0.587  , 0.5864 , 0.583  ,\n",
       "            0.5806 , 0.58   , 0.578  , 0.575  , 0.5747 , 0.574  , 0.5737 ,\n",
       "            0.573  , 0.568  , 0.5674 , 0.565  , 0.5605 , 0.557  , 0.5513 ,\n",
       "            0.55   , 0.547  , 0.5454 , 0.5444 , 0.541  , 0.5386 , 0.535  ,\n",
       "            0.53   , 0.526  , 0.5215 , 0.5156 , 0.5137 , 0.5107 , 0.505  ,\n",
       "            0.503  , 0.502  , 0.4858 , 0.4795 , 0.4697 , 0.4695 , 0.4534 ,\n",
       "            0.4512 , 0.4404 , 0.4219 , 0.419  , 0.417  , 0.4167 , 0.4155 ,\n",
       "            0.4146 , 0.4138 , 0.4126 , 0.4119 , 0.4116 , 0.4106 , 0.409  ,\n",
       "            0.4084 , 0.408  , 0.4062 , 0.4033 , 0.403  , 0.4026 , 0.4    ,\n",
       "            0.3997 , 0.3994 , 0.399  , 0.3984 , 0.398  , 0.3975 , 0.3955 ,\n",
       "            0.3945 , 0.3914 , 0.3882 , 0.3877 , 0.3857 , 0.3848 , 0.3843 ,\n",
       "            0.3838 , 0.3835 , 0.382  , 0.3813 , 0.38   , 0.377  , 0.3762 ,\n",
       "            0.3752 , 0.3748 , 0.3723 , 0.3713 , 0.3708 , 0.3704 , 0.3699 ,\n",
       "            0.3682 , 0.3677 , 0.3667 , 0.3662 , 0.366  , 0.3655 , 0.3652 ,\n",
       "            0.363  , 0.3604 , 0.3591 , 0.3584 , 0.3557 , 0.3545 , 0.3538 ,\n",
       "            0.3528 , 0.35   , 0.3494 , 0.346  , 0.3455 , 0.3418 , 0.3403 ,\n",
       "            0.34   , 0.3396 , 0.3386 , 0.338  , 0.3376 , 0.3374 , 0.337  ,\n",
       "            0.3362 , 0.3333 , 0.333  , 0.3271 , 0.3257 , 0.3252 , 0.3193 ,\n",
       "            0.3188 , 0.317  , 0.3147 , 0.3118 , 0.3105 , 0.31   , 0.3066 ,\n",
       "            0.305  , 0.302  , 0.3018 , 0.3005 , 0.2925 , 0.2825 , 0.2737 ,\n",
       "            0.2722 , 0.2632 , 0.2622 , 0.262  , 0.2612 , 0.261  , 0.258  ,\n",
       "            0.2554 , 0.2537 , 0.2534 , 0.2515 , 0.2456 , 0.2441 , 0.2434 ,\n",
       "            0.2428 , 0.2415 , 0.2366 , 0.2325 , 0.2322 , 0.2318 , 0.2311 ,\n",
       "            0.2285 , 0.2281 , 0.228  , 0.2277 , 0.2224 , 0.222  , 0.2211 ,\n",
       "            0.2197 , 0.2181 , 0.2108 , 0.2073 , 0.1982 , 0.1962 , 0.1919 ,\n",
       "            0.1904 , 0.1896 , 0.1814 , 0.1797 , 0.173  , 0.1681 , 0.1508 ,\n",
       "            0.1401 , 0.136  , 0.1348 , 0.1343 , 0.1315 , 0.1272 , 0.127  ,\n",
       "            0.11475, 0.11316, 0.1036 , 0.0991 , 0.0899 , 0.0898 , 0.0868 ,\n",
       "            0.0856 , 0.07465], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.03333334, dtype=float32),\n",
       "    'tpr': array(0.5769231, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15      , 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25      , 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.6       , 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65833336, 0.675     , 0.68333334, 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.7083333 ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.42307693, 0.43076923, 0.44615385,\n",
       "            0.45384616, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5692308 , 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.6076923 , 0.6230769 ,\n",
       "            0.6230769 , 0.6230769 , 0.6230769 , 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6769231 , 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.7       , 0.7       , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.8769231 , 0.88461536, 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7144 , 0.7056 , 0.7026 , 0.7    , 0.6943 , 0.69   ,\n",
       "            0.687  , 0.686  , 0.6855 , 0.6816 , 0.681  , 0.6797 , 0.679  ,\n",
       "            0.677  , 0.674  , 0.6714 , 0.6694 , 0.666  , 0.664  , 0.6562 ,\n",
       "            0.6533 , 0.652  , 0.6475 , 0.64   , 0.638  , 0.6377 , 0.6353 ,\n",
       "            0.635  , 0.6304 , 0.6294 , 0.6284 , 0.627  , 0.626  , 0.6255 ,\n",
       "            0.6245 , 0.6235 , 0.623  , 0.6196 , 0.619  , 0.618  , 0.6123 ,\n",
       "            0.6104 , 0.61   , 0.6084 , 0.6074 , 0.605  , 0.602  , 0.599  ,\n",
       "            0.5894 , 0.5825 , 0.5786 , 0.578  , 0.576  , 0.5713 , 0.5693 ,\n",
       "            0.567  , 0.5645 , 0.56   , 0.558  , 0.555  , 0.54   , 0.5366 ,\n",
       "            0.5303 , 0.53   , 0.5264 , 0.5166 , 0.506  , 0.502  , 0.4958 ,\n",
       "            0.4844 , 0.4722 , 0.4683 , 0.4475 , 0.445  , 0.4448 , 0.4414 ,\n",
       "            0.4402 , 0.4375 , 0.4355 , 0.4348 , 0.4338 , 0.4329 , 0.4314 ,\n",
       "            0.4312 , 0.4297 , 0.4282 , 0.4272 , 0.426  , 0.4258 , 0.424  ,\n",
       "            0.4236 , 0.4224 , 0.4214 , 0.419  , 0.4182 , 0.4172 , 0.415  ,\n",
       "            0.4136 , 0.411  , 0.409  , 0.4084 , 0.408  , 0.4065 , 0.406  ,\n",
       "            0.4053 , 0.405  , 0.4045 , 0.4026 , 0.4023 , 0.402  , 0.4014 ,\n",
       "            0.3975 , 0.3967 , 0.3958 , 0.395  , 0.3948 , 0.393  , 0.392  ,\n",
       "            0.391  , 0.3904 , 0.3882 , 0.388  , 0.3872 , 0.3867 , 0.3853 ,\n",
       "            0.3843 , 0.3838 , 0.383  , 0.3816 , 0.3801 , 0.3782 , 0.375  ,\n",
       "            0.3743 , 0.374  , 0.3738 , 0.3733 , 0.3723 , 0.3713 , 0.37   ,\n",
       "            0.3699 , 0.366  , 0.3616 , 0.3594 , 0.3591 , 0.3586 , 0.3582 ,\n",
       "            0.357  , 0.3562 , 0.3552 , 0.3489 , 0.3486 , 0.3484 , 0.3442 ,\n",
       "            0.3438 , 0.3403 , 0.3372 , 0.3345 , 0.3293 , 0.3286 , 0.3271 ,\n",
       "            0.3257 , 0.3254 , 0.323  , 0.3176 , 0.3152 , 0.3118 , 0.3042 ,\n",
       "            0.3003 , 0.299  , 0.2988 , 0.2935 , 0.2822 , 0.2737 , 0.2722 ,\n",
       "            0.27   , 0.261  , 0.2598 , 0.2573 , 0.256  , 0.2534 , 0.2532 ,\n",
       "            0.2471 , 0.2458 , 0.2415 , 0.2397 , 0.2362 , 0.2344 , 0.2343 ,\n",
       "            0.228  , 0.2269 , 0.2249 , 0.2242 , 0.224  , 0.2208 , 0.2197 ,\n",
       "            0.2128 , 0.2125 , 0.2096 , 0.2018 , 0.1979 , 0.191  , 0.1864 ,\n",
       "            0.1833 , 0.182  , 0.1805 , 0.1763 , 0.171  , 0.1626 , 0.1586 ,\n",
       "            0.1395 , 0.1383 , 0.1251 , 0.1235 , 0.12317, 0.12054, 0.11633,\n",
       "            0.11554, 0.1036 , 0.10175, 0.09235, 0.088  , 0.0804 , 0.0792 ,\n",
       "            0.07684, 0.075  , 0.0656 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04166667, dtype=float32),\n",
       "    'tpr': array(0.5923077, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.13333334, 0.13333334, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "            0.2       , 0.2       , 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.28333333, 0.28333333,\n",
       "            0.29166666, 0.29166666, 0.29166666, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.56153846, 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5846154 , 0.5923077 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63076925, 0.63076925, 0.63076925,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.7307692 , 0.7307692 ,\n",
       "            0.7307692 , 0.7307692 , 0.7307692 , 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.74615383, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.88461536, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7603 , 0.758  , 0.7495 , 0.7456 , 0.7446 , 0.7397 ,\n",
       "            0.7363 , 0.7324 , 0.7314 , 0.7305 , 0.73   , 0.7266 , 0.7256 ,\n",
       "            0.724  , 0.723  , 0.7217 , 0.7188 , 0.7183 , 0.7163 , 0.7153 ,\n",
       "            0.7095 , 0.7075 , 0.7    , 0.699  , 0.6963 , 0.693  , 0.683  ,\n",
       "            0.68   , 0.6797 , 0.6787 , 0.678  , 0.6772 , 0.6763 , 0.6753 ,\n",
       "            0.6724 , 0.671  , 0.6694 , 0.668  , 0.6675 , 0.6655 , 0.664  ,\n",
       "            0.6636 , 0.6616 , 0.659  , 0.657  , 0.654  , 0.6514 , 0.65   ,\n",
       "            0.6494 , 0.6484 , 0.648  , 0.645  , 0.6406 , 0.6343 , 0.627  ,\n",
       "            0.626  , 0.6206 , 0.6187 , 0.6177 , 0.6143 , 0.6113 , 0.61   ,\n",
       "            0.6064 , 0.606  , 0.5996 , 0.597  , 0.596  , 0.5723 , 0.567  ,\n",
       "            0.5635 , 0.5586 , 0.5557 , 0.555  , 0.5537 , 0.53   , 0.508  ,\n",
       "            0.4963 , 0.4915 , 0.4846 , 0.4841 , 0.4766 , 0.4756 , 0.4739 ,\n",
       "            0.47   , 0.4695 , 0.4688 , 0.4675 , 0.4666 , 0.4648 , 0.4644 ,\n",
       "            0.4636 , 0.4634 , 0.4607 , 0.4602 , 0.4558 , 0.455  , 0.4548 ,\n",
       "            0.4526 , 0.4502 , 0.4495 , 0.4492 , 0.446  , 0.4443 , 0.4434 ,\n",
       "            0.4429 , 0.439  , 0.4385 , 0.4375 , 0.4373 , 0.4333 , 0.432  ,\n",
       "            0.4312 , 0.4307 , 0.4304 , 0.43   , 0.4294 , 0.4292 , 0.4287 ,\n",
       "            0.4275 , 0.427  , 0.4263 , 0.426  , 0.4238 , 0.4175 , 0.416  ,\n",
       "            0.4146 , 0.413  , 0.412  , 0.4119 , 0.4111 , 0.4106 , 0.4097 ,\n",
       "            0.4082 , 0.408  , 0.4053 , 0.4048 , 0.4043 , 0.4036 , 0.402  ,\n",
       "            0.4016 , 0.3992 , 0.398  , 0.3972 , 0.3967 , 0.3965 , 0.3936 ,\n",
       "            0.3933 , 0.3926 , 0.391  , 0.3904 , 0.3896 , 0.3875 , 0.3865 ,\n",
       "            0.3833 , 0.383  , 0.3804 , 0.3743 , 0.3682 , 0.3667 , 0.3657 ,\n",
       "            0.3643 , 0.3577 , 0.3555 , 0.3552 , 0.3472 , 0.3455 , 0.343  ,\n",
       "            0.3418 , 0.3396 , 0.3328 , 0.3318 , 0.3298 , 0.3293 , 0.317  ,\n",
       "            0.316  , 0.3147 , 0.3074 , 0.3    , 0.2986 , 0.298  , 0.2932 ,\n",
       "            0.2883 , 0.2856 , 0.2805 , 0.2751 , 0.2747 , 0.2727 , 0.2705 ,\n",
       "            0.2612 , 0.2585 , 0.2563 , 0.255  , 0.2517 , 0.2494 , 0.2438 ,\n",
       "            0.2433 , 0.2426 , 0.2415 , 0.241  , 0.2407 , 0.2297 , 0.2255 ,\n",
       "            0.2197 , 0.2189 , 0.2181 , 0.2167 , 0.2139 , 0.2086 , 0.2063 ,\n",
       "            0.2028 , 0.1952 , 0.191  , 0.1866 , 0.1807 , 0.179  , 0.1781 ,\n",
       "            0.1738 , 0.1725 , 0.1631 , 0.1531 , 0.1514 , 0.1423 , 0.13   ,\n",
       "            0.11615, 0.1138 , 0.11316, 0.11163, 0.1074 , 0.1056 , 0.0942 ,\n",
       "            0.09186, 0.0827 , 0.0785 , 0.07275, 0.0698 , 0.0684 , 0.0661 ,\n",
       "            0.058  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.08333334, dtype=float32),\n",
       "    'tpr': array(0.61538464, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.175     , 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.325     , 0.325     , 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.4       , 0.41666666,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.44166666, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.64166665, 0.65      , 0.65833336, 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.56153846, 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6       , 0.61538464, 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6769231 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.7153846 , 0.72307694, 0.72307694,\n",
       "            0.72307694, 0.72307694, 0.7307692 , 0.73846155, 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.75384617, 0.75384617,\n",
       "            0.75384617, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.8769231 , 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7993 , 0.798  , 0.7866 , 0.782  , 0.781  , 0.7773 ,\n",
       "            0.774  , 0.77   , 0.7686 , 0.7676 , 0.766  , 0.7627 , 0.761  ,\n",
       "            0.76   , 0.7583 , 0.756  , 0.755  , 0.7534 , 0.7515 , 0.746  ,\n",
       "            0.7437 , 0.737  , 0.7354 , 0.7324 , 0.73   , 0.7188 , 0.7173 ,\n",
       "            0.7153 , 0.715  , 0.7144 , 0.7124 , 0.711  , 0.7085 , 0.7075 ,\n",
       "            0.706  , 0.705  , 0.7046 , 0.7036 , 0.702  , 0.701  , 0.6997 ,\n",
       "            0.698  , 0.6973 , 0.694  , 0.6924 , 0.6914 , 0.6895 , 0.683  ,\n",
       "            0.6826 , 0.682  , 0.681  , 0.673  , 0.6724 , 0.6714 , 0.666  ,\n",
       "            0.6587 , 0.6562 , 0.6523 , 0.652  , 0.644  , 0.6406 , 0.6367 ,\n",
       "            0.635  , 0.6313 , 0.6284 , 0.626  , 0.5986 , 0.5923 , 0.592  ,\n",
       "            0.591  , 0.5874 , 0.5815 , 0.579  , 0.567  , 0.5576 , 0.5522 ,\n",
       "            0.5396 , 0.5283 , 0.516  , 0.5146 , 0.514  , 0.5044 , 0.5034 ,\n",
       "            0.503  , 0.4983 , 0.4966 , 0.495  , 0.494  , 0.4937 , 0.4915 ,\n",
       "            0.4902 , 0.4858 , 0.4856 , 0.482  , 0.48   , 0.479  , 0.4783 ,\n",
       "            0.4778 , 0.4727 , 0.4724 , 0.4717 , 0.4707 , 0.468  , 0.4673 ,\n",
       "            0.4653 , 0.4648 , 0.4626 , 0.4614 , 0.4585 , 0.4575 , 0.456  ,\n",
       "            0.4558 , 0.455  , 0.4548 , 0.4543 , 0.4536 , 0.4534 , 0.4521 ,\n",
       "            0.4512 , 0.4504 , 0.4465 , 0.4402 , 0.4377 , 0.4355 , 0.4343 ,\n",
       "            0.4338 , 0.4333 , 0.433  , 0.4326 , 0.4324 , 0.4316 , 0.4297 ,\n",
       "            0.4294 , 0.4287 , 0.4285 , 0.426  , 0.4253 , 0.424  , 0.4187 ,\n",
       "            0.418  , 0.4177 , 0.4172 , 0.4155 , 0.4146 , 0.4143 , 0.414  ,\n",
       "            0.4124 , 0.4102 , 0.41   , 0.4097 , 0.4094 , 0.4048 , 0.404  ,\n",
       "            0.4    , 0.3975 , 0.397  , 0.3845 , 0.3818 , 0.3792 , 0.3782 ,\n",
       "            0.374  , 0.372  , 0.3696 , 0.3616 , 0.3608 , 0.3599 , 0.358  ,\n",
       "            0.3542 , 0.343  , 0.3428 , 0.3398 , 0.3293 , 0.3284 , 0.328  ,\n",
       "            0.3274 , 0.3162 , 0.312  , 0.3074 , 0.3062 , 0.3008 , 0.2957 ,\n",
       "            0.294  , 0.2935 , 0.286  , 0.2842 , 0.284  , 0.2837 , 0.282  ,\n",
       "            0.2747 , 0.265  , 0.2595 , 0.252  , 0.2498 , 0.2494 , 0.2466 ,\n",
       "            0.243  , 0.2388 , 0.2374 , 0.237  , 0.223  , 0.2217 , 0.2119 ,\n",
       "            0.2108 , 0.2095 , 0.2091 , 0.2051 , 0.2024 , 0.1973 , 0.1935 ,\n",
       "            0.1859 , 0.1816 , 0.1805 , 0.1766 , 0.1758 , 0.1699 , 0.164  ,\n",
       "            0.1621 , 0.1539 , 0.1433 , 0.1432 , 0.1421 , 0.1197 , 0.1069 ,\n",
       "            0.1041 , 0.10266, 0.1023 , 0.09827, 0.09534, 0.08496, 0.082  ,\n",
       "            0.0733 , 0.0693 , 0.06537, 0.06085, 0.06064, 0.0577 , 0.0511 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.15, dtype=float32),\n",
       "    'tpr': array(0.65384614, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15      , 0.15833333,\n",
       "            0.175     , 0.175     , 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.225     , 0.225     , 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.23333333, 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.38333333, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45833334, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.49166667, 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.575     , 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.56153846, 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.6076923 , 0.61538464, 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.66923076, 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.7076923 , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.75384617, 0.75384617,\n",
       "            0.75384617, 0.75384617, 0.75384617, 0.75384617, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.77692306, 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8354 , 0.8315 , 0.8203 , 0.8164 , 0.8145 , 0.8115 ,\n",
       "            0.807  , 0.804  , 0.8022 , 0.8003 , 0.7974 , 0.797  , 0.7964 ,\n",
       "            0.7935 , 0.7925 , 0.7896 , 0.7876 , 0.7856 , 0.781  , 0.7783 ,\n",
       "            0.7705 , 0.7695 , 0.768  , 0.766  , 0.7646 , 0.756  , 0.753  ,\n",
       "            0.749  , 0.7485 , 0.748  , 0.747  , 0.7456 , 0.7446 , 0.741  ,\n",
       "            0.7407 , 0.7397 , 0.7373 , 0.737  , 0.736  , 0.735  , 0.7334 ,\n",
       "            0.7324 , 0.7305 , 0.7285 , 0.7266 , 0.726  , 0.7246 , 0.7173 ,\n",
       "            0.7153 , 0.714  , 0.7134 , 0.706  , 0.7056 , 0.705  , 0.7017 ,\n",
       "            0.695  , 0.69   , 0.6875 , 0.6836 , 0.682  , 0.675  , 0.6694 ,\n",
       "            0.6665 , 0.6646 , 0.6636 , 0.6567 , 0.6553 , 0.6265 , 0.6245 ,\n",
       "            0.6177 , 0.617  , 0.6064 , 0.6025 , 0.5996 , 0.584  , 0.575  ,\n",
       "            0.5684 , 0.56   , 0.5425 , 0.533  , 0.532  , 0.5312 , 0.5293 ,\n",
       "            0.528  , 0.525  , 0.521  , 0.52   , 0.5195 , 0.518  , 0.514  ,\n",
       "            0.5137 , 0.5083 , 0.5063 , 0.504  , 0.5034 , 0.5015 , 0.5    ,\n",
       "            0.496  , 0.4932 , 0.493  , 0.4888 , 0.4875 , 0.4868 , 0.484  ,\n",
       "            0.4824 , 0.4817 , 0.4814 , 0.4807 , 0.4797 , 0.4792 , 0.479  ,\n",
       "            0.4749 , 0.4746 , 0.4731 , 0.4722 , 0.472  , 0.4712 , 0.4705 ,\n",
       "            0.4688 , 0.4653 , 0.4636 , 0.4597 , 0.4563 , 0.4524 , 0.4514 ,\n",
       "            0.4504 , 0.45   , 0.4492 , 0.449  , 0.4473 , 0.447  , 0.4468 ,\n",
       "            0.4436 , 0.4434 , 0.4424 , 0.4414 , 0.4385 , 0.435  , 0.4338 ,\n",
       "            0.4326 , 0.43   , 0.4297 , 0.4294 , 0.429  , 0.4287 , 0.426  ,\n",
       "            0.423  , 0.4224 , 0.422  , 0.4165 , 0.4158 , 0.4053 , 0.403  ,\n",
       "            0.3918 , 0.3882 , 0.388  , 0.3828 , 0.3752 , 0.3733 , 0.3716 ,\n",
       "            0.369  , 0.362  , 0.3586 , 0.3508 , 0.349  , 0.3398 , 0.3394 ,\n",
       "            0.3352 , 0.3267 , 0.3245 , 0.3206 , 0.3176 , 0.3147 , 0.3096 ,\n",
       "            0.3035 , 0.3022 , 0.295  , 0.29   , 0.2898 , 0.2893 , 0.2886 ,\n",
       "            0.2842 , 0.284  , 0.2683 , 0.2659 , 0.2578 , 0.2546 , 0.2458 ,\n",
       "            0.2434 , 0.2421 , 0.2401 , 0.2347 , 0.2302 , 0.2294 , 0.2185 ,\n",
       "            0.2134 , 0.2029 , 0.2018 , 0.2009 , 0.2002 , 0.196  , 0.1947 ,\n",
       "            0.1879 , 0.1841 , 0.1761 , 0.1735 , 0.1731 , 0.1716 , 0.1697 ,\n",
       "            0.1602 , 0.1536 , 0.1519 , 0.1442 , 0.1421 , 0.1343 , 0.132  ,\n",
       "            0.1097 , 0.0977 , 0.09467, 0.0933 , 0.0927 , 0.0895 , 0.0856 ,\n",
       "            0.0761 , 0.07275, 0.06464, 0.06085, 0.05844, 0.0533 , 0.053  ,\n",
       "            0.05014, 0.04468], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.21666667, dtype=float32),\n",
       "    'tpr': array(0.72307694, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15      , 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.2       ,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.225     , 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.60833335, 0.60833335, 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.64166665, 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.21538462, 0.23076923, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.30769232, 0.31538463, 0.32307693, 0.33846155,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6769231 , 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.7       , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.75384617, 0.75384617, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.76153845, 0.76153845, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8677 , 0.862  , 0.85   , 0.8467 , 0.8447 , 0.843  ,\n",
       "            0.838  , 0.836  , 0.8354 , 0.8335 , 0.831  , 0.8286 , 0.827  ,\n",
       "            0.824  , 0.8237 , 0.821  , 0.819  , 0.817  , 0.8125 , 0.81   ,\n",
       "            0.802  , 0.801  , 0.8    , 0.798  , 0.7974 , 0.792  , 0.7847 ,\n",
       "            0.781  , 0.7803 , 0.78   , 0.7793 , 0.776  , 0.7734 , 0.773  ,\n",
       "            0.7715 , 0.7686 , 0.768  , 0.7666 , 0.765  , 0.7617 , 0.7603 ,\n",
       "            0.759  , 0.757  , 0.751  , 0.7466 , 0.746  , 0.7446 , 0.744  ,\n",
       "            0.7397 , 0.737  , 0.7363 , 0.7354 , 0.7314 , 0.7275 , 0.7163 ,\n",
       "            0.7153 , 0.712  , 0.704  , 0.6978 , 0.696  , 0.6924 , 0.6846 ,\n",
       "            0.684  , 0.662  , 0.6504 , 0.6484 , 0.6445 , 0.6416 , 0.634  ,\n",
       "            0.63   , 0.625  , 0.611  , 0.599  , 0.5977 , 0.5947 , 0.573  ,\n",
       "            0.5723 , 0.566  , 0.5605 , 0.5586 , 0.556  , 0.554  , 0.5493 ,\n",
       "            0.549  , 0.5483 , 0.548  , 0.5454 , 0.5405 , 0.54   , 0.534  ,\n",
       "            0.533  , 0.53   , 0.529  , 0.5283 , 0.525  , 0.5244 , 0.5234 ,\n",
       "            0.5186 , 0.5166 , 0.5156 , 0.512  , 0.5117 , 0.5103 , 0.509  ,\n",
       "            0.5083 , 0.5073 , 0.5054 , 0.5044 , 0.501  , 0.4988 , 0.4973 ,\n",
       "            0.4968 , 0.495  , 0.4944 , 0.4934 , 0.493  , 0.4915 , 0.4883 ,\n",
       "            0.487  , 0.479  , 0.4775 , 0.4763 , 0.4744 , 0.474  , 0.473  ,\n",
       "            0.4727 , 0.4712 , 0.4697 , 0.4678 , 0.4673 , 0.4668 , 0.465  ,\n",
       "            0.4646 , 0.4622 , 0.4607 , 0.4597 , 0.4585 , 0.4553 , 0.4534 ,\n",
       "            0.4526 , 0.4524 , 0.451  , 0.4504 , 0.4475 , 0.4468 , 0.4465 ,\n",
       "            0.4463 , 0.4443 , 0.444  , 0.4429 , 0.4414 , 0.439  , 0.421  ,\n",
       "            0.4204 , 0.4102 , 0.4087 , 0.406  , 0.4045 , 0.4011 , 0.3994 ,\n",
       "            0.3962 , 0.3936 , 0.3909 , 0.3882 , 0.3806 , 0.3735 , 0.3726 ,\n",
       "            0.3608 , 0.359  , 0.358  , 0.3535 , 0.345  , 0.338  , 0.3315 ,\n",
       "            0.3308 , 0.324  , 0.321  , 0.3203 , 0.313  , 0.311  , 0.3071 ,\n",
       "            0.3005 , 0.298  , 0.297  , 0.2964 , 0.2856 , 0.2832 , 0.2822 ,\n",
       "            0.2744 , 0.2737 , 0.2656 , 0.262  , 0.2422 , 0.2395 , 0.2367 ,\n",
       "            0.2332 , 0.2314 , 0.2229 , 0.2211 , 0.2145 , 0.2042 , 0.1934 ,\n",
       "            0.1924 , 0.1913 , 0.1903 , 0.1871 , 0.1863 , 0.1779 , 0.1738 ,\n",
       "            0.1709 , 0.1663 , 0.1656 , 0.1638 , 0.1611 , 0.1505 , 0.1428 ,\n",
       "            0.1416 , 0.141  , 0.1346 , 0.1256 , 0.12085, 0.0998 , 0.089  ,\n",
       "            0.0857 , 0.08466, 0.0828 , 0.08093, 0.076  , 0.0677 , 0.06396,\n",
       "            0.05646, 0.053  , 0.05194, 0.04654, 0.0456 , 0.0432 , 0.03876],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3, dtype=float32),\n",
       "    'tpr': array(0.7846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.15      , 0.15      ,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.23333333, 0.23333333, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.6       , 0.6       , 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.20769231, 0.22307692, 0.23076923, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.72307694, 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.76153845, 0.76153845,\n",
       "            0.76153845, 0.77692306, 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.8769231 , 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.893  , 0.886  , 0.875  , 0.872  , 0.8706 , 0.869  ,\n",
       "            0.8633 , 0.862  , 0.8604 , 0.8574 , 0.856  , 0.8535 , 0.851  ,\n",
       "            0.8506 , 0.848  , 0.8477 , 0.846  , 0.8438 , 0.8403 , 0.838  ,\n",
       "            0.8296 , 0.8286 , 0.826  , 0.8247 , 0.823  , 0.8125 , 0.8096 ,\n",
       "            0.8086 , 0.808  , 0.805  , 0.8022 , 0.802  , 0.8003 , 0.798  ,\n",
       "            0.797  , 0.7964 , 0.7954 , 0.7944 , 0.7915 , 0.791  , 0.7905 ,\n",
       "            0.7896 , 0.786  , 0.7817 , 0.7754 , 0.775  , 0.7734 , 0.7725 ,\n",
       "            0.77   , 0.7686 , 0.7656 , 0.764  , 0.7627 , 0.745  , 0.7446 ,\n",
       "            0.74   , 0.7324 , 0.727  , 0.7256 , 0.7236 , 0.7197 , 0.7124 ,\n",
       "            0.712  , 0.697  , 0.679  , 0.677  , 0.6714 , 0.6685 , 0.666  ,\n",
       "            0.6533 , 0.649  , 0.639  , 0.6343 , 0.631  , 0.6216 , 0.6055 ,\n",
       "            0.6045 , 0.5923 , 0.591  , 0.589  , 0.5874 , 0.581  , 0.5806 ,\n",
       "            0.578  , 0.576  , 0.571  , 0.5674 , 0.5635 , 0.5615 , 0.561  ,\n",
       "            0.56   , 0.556  , 0.5537 , 0.553  , 0.5522 , 0.55   , 0.548  ,\n",
       "            0.544  , 0.543  , 0.5425 , 0.5415 , 0.541  , 0.5386 , 0.537  ,\n",
       "            0.5366 , 0.534  , 0.5337 , 0.5303 , 0.529  , 0.527  , 0.5254 ,\n",
       "            0.525  , 0.523  , 0.52   , 0.5176 , 0.5166 , 0.5127 , 0.5107 ,\n",
       "            0.506  , 0.505  , 0.5034 , 0.5024 , 0.502  , 0.5005 , 0.496  ,\n",
       "            0.4958 , 0.4946 , 0.494  , 0.4927 , 0.4924 , 0.4907 , 0.4902 ,\n",
       "            0.487  , 0.4863 , 0.4844 , 0.4834 , 0.483  , 0.4805 , 0.4768 ,\n",
       "            0.4734 , 0.4722 , 0.4717 , 0.471  , 0.4695 , 0.4692 , 0.469  ,\n",
       "            0.4658 , 0.4624 , 0.4585 , 0.4329 , 0.429  , 0.4275 , 0.4236 ,\n",
       "            0.4219 , 0.421  , 0.4187 , 0.4172 , 0.417  , 0.4167 , 0.4114 ,\n",
       "            0.3992 , 0.3965 , 0.39   , 0.379  , 0.3782 , 0.3767 , 0.3733 ,\n",
       "            0.3625 , 0.3623 , 0.3542 , 0.3513 , 0.3418 , 0.3398 , 0.3298 ,\n",
       "            0.3289 , 0.3247 , 0.3208 , 0.32   , 0.3186 , 0.3154 , 0.3152 ,\n",
       "            0.3135 , 0.301  , 0.2932 , 0.293  , 0.2869 , 0.284  , 0.2803 ,\n",
       "            0.279  , 0.2786 , 0.2487 , 0.2375 , 0.2343 , 0.233  , 0.2307 ,\n",
       "            0.2194 , 0.2163 , 0.2157 , 0.1984 , 0.1877 , 0.1865 , 0.1858 ,\n",
       "            0.1835 , 0.1833 , 0.1797 , 0.1748 , 0.1709 , 0.1669 , 0.1636 ,\n",
       "            0.163  , 0.1587 , 0.1545 , 0.1492 , 0.1445 , 0.1356 , 0.1335 ,\n",
       "            0.1288 , 0.12054, 0.1124 , 0.09283, 0.0833 , 0.07947, 0.07904,\n",
       "            0.07556, 0.07544, 0.06903, 0.0619 , 0.05737, 0.0505 , 0.04794,\n",
       "            0.04742, 0.04208, 0.04025, 0.03818, 0.035  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.34166667, dtype=float32),\n",
       "    'tpr': array(0.8230769, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.15      , 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.2       , 0.20833333, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.225     , 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.275     , 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35833332, 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.6       , 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.6076923 , 0.61538464, 0.61538464, 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.6846154 , 0.6923077 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.72307694,\n",
       "            0.7307692 , 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.76153845, 0.76153845, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.88461536, 0.9       , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.91   , 0.9023 , 0.8916 , 0.889  , 0.887  , 0.8857 ,\n",
       "            0.8804 , 0.88   , 0.8794 , 0.8774 , 0.8745 , 0.8735 , 0.873  ,\n",
       "            0.871  , 0.868  , 0.8677 , 0.865  , 0.8643 , 0.8613 , 0.858  ,\n",
       "            0.8555 , 0.8477 , 0.8467 , 0.846  , 0.845  , 0.844  , 0.843  ,\n",
       "            0.833  , 0.831  , 0.8286 , 0.827  , 0.8267 , 0.826  , 0.823  ,\n",
       "            0.8213 , 0.82   , 0.819  , 0.8174 , 0.8154 , 0.815  , 0.814  ,\n",
       "            0.8135 , 0.8125 , 0.811  , 0.8105 , 0.8096 , 0.809  , 0.804  ,\n",
       "            0.802  , 0.794  , 0.793  , 0.792  , 0.7915 , 0.7905 , 0.7896 ,\n",
       "            0.7876 , 0.7856 , 0.7837 , 0.782  , 0.764  , 0.761  , 0.7583 ,\n",
       "            0.7495 , 0.7466 , 0.7417 , 0.7407 , 0.736  , 0.73   , 0.728  ,\n",
       "            0.7197 , 0.6987 , 0.6914 , 0.691  , 0.6875 , 0.678  , 0.6646 ,\n",
       "            0.66   , 0.658  , 0.6562 , 0.6504 , 0.633  , 0.6274 , 0.626  ,\n",
       "            0.6255 , 0.6113 , 0.61   , 0.6084 , 0.606  , 0.6    , 0.5996 ,\n",
       "            0.5967 , 0.5947 , 0.5894 , 0.589  , 0.5815 , 0.578  , 0.577  ,\n",
       "            0.576  , 0.5747 , 0.574  , 0.5703 , 0.5693 , 0.569  , 0.568  ,\n",
       "            0.5664 , 0.566  , 0.561  , 0.5605 , 0.56   , 0.5596 , 0.5586 ,\n",
       "            0.5566 , 0.556  , 0.555  , 0.5522 , 0.552  , 0.5513 , 0.5493 ,\n",
       "            0.546  , 0.5435 , 0.543  , 0.5415 , 0.5405 , 0.5386 , 0.5337 ,\n",
       "            0.5312 , 0.5254 , 0.5234 , 0.523  , 0.5215 , 0.521  , 0.5195 ,\n",
       "            0.517  , 0.5166 , 0.515  , 0.513  , 0.51   , 0.5093 , 0.509  ,\n",
       "            0.5063 , 0.505  , 0.504  , 0.5024 , 0.498  , 0.497  , 0.494  ,\n",
       "            0.4927 , 0.4895 , 0.4893 , 0.489  , 0.4875 , 0.4824 , 0.4805 ,\n",
       "            0.4802 , 0.4795 , 0.4739 , 0.4673 , 0.465  , 0.4622 , 0.4478 ,\n",
       "            0.438  , 0.4314 , 0.4292 , 0.4263 , 0.426  , 0.4238 , 0.4233 ,\n",
       "            0.4165 , 0.4146 , 0.407  , 0.3962 , 0.3914 , 0.3884 , 0.3845 ,\n",
       "            0.378  , 0.3735 , 0.3691 , 0.3667 , 0.3604 , 0.3562 , 0.3518 ,\n",
       "            0.3416 , 0.3357 , 0.3325 , 0.3318 , 0.3306 , 0.3218 , 0.3193 ,\n",
       "            0.316  , 0.3076 , 0.3071 , 0.3015 , 0.2925 , 0.2917 , 0.2915 ,\n",
       "            0.2903 , 0.2861 , 0.2683 , 0.266  , 0.247  , 0.2278 , 0.2272 ,\n",
       "            0.224  , 0.2207 , 0.2096 , 0.2089 , 0.2045 , 0.1859 , 0.1761 ,\n",
       "            0.1746 , 0.1743 , 0.1737 , 0.172  , 0.1705 , 0.1672 , 0.1582 ,\n",
       "            0.1562 , 0.1554 , 0.1542 , 0.1499 , 0.1466 , 0.1427 , 0.1339 ,\n",
       "            0.1241 , 0.1217 , 0.1188 , 0.1118 , 0.1007 , 0.08344, 0.0752 ,\n",
       "            0.0712 , 0.0678 , 0.0662 , 0.06052, 0.0546 , 0.04968, 0.04385,\n",
       "            0.0424 , 0.041  , 0.0367 , 0.03424, 0.03265, 0.03044],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.375, dtype=float32),\n",
       "    'tpr': array(0.84615386, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.225     , 0.225     , 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.275     , 0.275     ,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.525     , 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.6       , 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.72307694, 0.72307694, 0.7307692 , 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9253 , 0.918  , 0.9077 , 0.906  , 0.9043 , 0.904  ,\n",
       "            0.8994 , 0.8975 , 0.897  , 0.896  , 0.893  , 0.8926 , 0.8916 ,\n",
       "            0.889  , 0.8867 , 0.886  , 0.8843 , 0.8833 , 0.8823 , 0.8794 ,\n",
       "            0.878  , 0.8745 , 0.868  , 0.866  , 0.8657 , 0.8643 , 0.8623 ,\n",
       "            0.853  , 0.8506 , 0.849  , 0.848  , 0.847  , 0.8467 , 0.846  ,\n",
       "            0.844  , 0.842  , 0.841  , 0.84   , 0.8374 , 0.8354 , 0.835  ,\n",
       "            0.834  , 0.8335 , 0.8315 , 0.831  , 0.83   , 0.8257 , 0.8223 ,\n",
       "            0.815  , 0.8145 , 0.813  , 0.8125 , 0.811  , 0.8105 , 0.809  ,\n",
       "            0.8076 , 0.8066 , 0.804  , 0.785  , 0.7827 , 0.779  , 0.7725 ,\n",
       "            0.7676 , 0.763  , 0.761  , 0.7573 , 0.75   , 0.749  , 0.741  ,\n",
       "            0.7197 , 0.712  , 0.7114 , 0.707  , 0.698  , 0.6846 , 0.6797 ,\n",
       "            0.679  , 0.675  , 0.6694 , 0.649  , 0.6475 , 0.6445 , 0.644  ,\n",
       "            0.629  , 0.628  , 0.627  , 0.624  , 0.6177 , 0.6167 , 0.614  ,\n",
       "            0.612  , 0.606  , 0.5986 , 0.5947 , 0.594  , 0.5938 , 0.592  ,\n",
       "            0.5913 , 0.5874 , 0.587  , 0.5864 , 0.5854 , 0.5825 , 0.582  ,\n",
       "            0.578  , 0.5776 , 0.5767 , 0.575  , 0.5728 , 0.572  , 0.5703 ,\n",
       "            0.567  , 0.5664 , 0.5645 , 0.5605 , 0.56   , 0.5586 , 0.5566 ,\n",
       "            0.555  , 0.5483 , 0.5454 , 0.5396 , 0.5386 , 0.537  , 0.536  ,\n",
       "            0.5337 , 0.5317 , 0.5293 , 0.5254 , 0.525  , 0.5244 , 0.5234 ,\n",
       "            0.5225 , 0.522  , 0.5195 , 0.518  , 0.5176 , 0.512  , 0.51   ,\n",
       "            0.5054 , 0.505  , 0.504  , 0.5015 , 0.501  , 0.4998 , 0.4949 ,\n",
       "            0.4917 , 0.4915 , 0.4905 , 0.4792 , 0.4727 , 0.472  , 0.467  ,\n",
       "            0.4595 , 0.4502 , 0.4382 , 0.4363 , 0.4338 , 0.4326 , 0.429  ,\n",
       "            0.4285 , 0.4272 , 0.4177 , 0.4148 , 0.413  , 0.4014 , 0.3972 ,\n",
       "            0.391  , 0.3896 , 0.3818 , 0.3752 , 0.3743 , 0.3718 , 0.3667 ,\n",
       "            0.3591 , 0.3538 , 0.3496 , 0.341  , 0.3403 , 0.3367 , 0.3286 ,\n",
       "            0.326  , 0.3228 , 0.312  , 0.3064 , 0.303  , 0.3025 , 0.296  ,\n",
       "            0.2915 , 0.2896 , 0.2893 , 0.287  , 0.262  , 0.2598 , 0.2437 ,\n",
       "            0.2213 , 0.2205 , 0.2166 , 0.213  , 0.2037 , 0.2009 , 0.1958 ,\n",
       "            0.1771 , 0.1676 , 0.1666 , 0.1654 , 0.1652 , 0.1648 , 0.1617 ,\n",
       "            0.158  , 0.1498 , 0.1489 , 0.148  , 0.1476 , 0.145  , 0.1375 ,\n",
       "            0.1335 , 0.12494, 0.1152 , 0.1128 , 0.1103 , 0.10376, 0.0925 ,\n",
       "            0.076  , 0.0682 , 0.0643 , 0.0612 , 0.05933, 0.0539 , 0.04858,\n",
       "            0.04385, 0.03845, 0.03754, 0.0359 , 0.0321 , 0.02965, 0.02834,\n",
       "            0.0265 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.40833333, dtype=float32),\n",
       "    'tpr': array(0.85384613, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.14166667, 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.225     , 0.23333333,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.29166666, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.525     , 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.6076923 , 0.61538464, 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.76153845, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.939  , 0.9316 , 0.922  , 0.9204 , 0.919  , 0.915  ,\n",
       "            0.9126 , 0.912  , 0.9116 , 0.909  , 0.908  , 0.9077 , 0.905  ,\n",
       "            0.903  , 0.902  , 0.9    , 0.8994 , 0.8984 , 0.8955 , 0.8945 ,\n",
       "            0.891  , 0.8857 , 0.8833 , 0.883  , 0.882  , 0.879  , 0.872  ,\n",
       "            0.868  , 0.867  , 0.866  , 0.8647 , 0.8643 , 0.8623 , 0.86   ,\n",
       "            0.8594 , 0.8574 , 0.8564 , 0.8535 , 0.853  , 0.8525 , 0.8516 ,\n",
       "            0.8506 , 0.8496 , 0.849  , 0.844  , 0.842  , 0.834  , 0.833  ,\n",
       "            0.831  , 0.83   , 0.829  , 0.8257 , 0.823  , 0.804  , 0.801  ,\n",
       "            0.797  , 0.7905 , 0.787  , 0.7812 , 0.7793 , 0.775  , 0.7686 ,\n",
       "            0.7666 , 0.7637 , 0.7397 , 0.7344 , 0.728  , 0.725  , 0.713  ,\n",
       "            0.703  , 0.699  , 0.694  , 0.693  , 0.6895 , 0.673  , 0.666  ,\n",
       "            0.6646 , 0.662  , 0.649  , 0.6484 , 0.648  , 0.644  , 0.638  ,\n",
       "            0.636  , 0.633  , 0.631  , 0.626  , 0.625  , 0.617  , 0.6133 ,\n",
       "            0.613  , 0.6123 , 0.6113 , 0.6104 , 0.605  , 0.6035 , 0.602  ,\n",
       "            0.6016 , 0.6006 , 0.6    , 0.598  , 0.596  , 0.5957 , 0.594  ,\n",
       "            0.5938 , 0.592  , 0.588  , 0.5845 , 0.584  , 0.583  , 0.5815 ,\n",
       "            0.5786 , 0.576  , 0.5747 , 0.572  , 0.5645 , 0.5635 , 0.5615 ,\n",
       "            0.5596 , 0.5586 , 0.5566 , 0.5527 , 0.5513 , 0.551  , 0.5503 ,\n",
       "            0.548  , 0.5474 , 0.547  , 0.544  , 0.541  , 0.54   , 0.5386 ,\n",
       "            0.536  , 0.533  , 0.532  , 0.528  , 0.5244 , 0.523  , 0.5215 ,\n",
       "            0.5186 , 0.517  , 0.511  , 0.506  , 0.5044 , 0.5034 , 0.4822 ,\n",
       "            0.481  , 0.4797 , 0.475  , 0.472  , 0.4688 , 0.4502 , 0.4492 ,\n",
       "            0.449  , 0.4478 , 0.4392 , 0.4275 , 0.4253 , 0.425  , 0.4163 ,\n",
       "            0.414  , 0.4136 , 0.4116 , 0.4001 , 0.393  , 0.3904 , 0.3865 ,\n",
       "            0.3853 , 0.3806 , 0.3743 , 0.368  , 0.367  , 0.3599 , 0.352  ,\n",
       "            0.3518 , 0.3486 , 0.3372 , 0.3333 , 0.3218 , 0.32   , 0.3093 ,\n",
       "            0.3042 , 0.3018 , 0.2986 , 0.2969 , 0.2917 , 0.2903 , 0.2795 ,\n",
       "            0.251  , 0.2483 , 0.2444 , 0.2173 , 0.2119 , 0.2075 , 0.204  ,\n",
       "            0.2001 , 0.1907 , 0.185  , 0.1674 , 0.1658 , 0.1573 , 0.1562 ,\n",
       "            0.1545 , 0.1544 , 0.1514 , 0.1499 , 0.1464 , 0.1453 , 0.1416 ,\n",
       "            0.1375 , 0.1335 , 0.1268 , 0.1232 , 0.11597, 0.1052 , 0.10266,\n",
       "            0.1021 , 0.0964 , 0.0825 , 0.0684 , 0.0619 , 0.05814, 0.0577 ,\n",
       "            0.0552 , 0.05176, 0.047  , 0.04297, 0.03775, 0.03348, 0.03333,\n",
       "            0.03096, 0.0281 , 0.02513, 0.02419, 0.0232 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.40833333, dtype=float32),\n",
       "    'tpr': array(0.85384613, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.20833333, 0.20833333, 0.225     , 0.23333333,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.30833334, 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.36666667, 0.36666667,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.56666666, 0.56666666,\n",
       "            0.575     , 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.3       ,\n",
       "            0.31538463, 0.33076924, 0.33846155, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4076923 , 0.43076923,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.6076923 , 0.61538464, 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7076923 ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.95   , 0.943  , 0.934  , 0.932  , 0.9316 , 0.931  ,\n",
       "            0.9277 , 0.9253 , 0.9243 , 0.922  , 0.921  , 0.9185 , 0.9165 ,\n",
       "            0.9155 , 0.914  , 0.913  , 0.9126 , 0.9097 , 0.9087 , 0.9053 ,\n",
       "            0.9    , 0.898  , 0.8975 , 0.894  , 0.889  , 0.884  , 0.8823 ,\n",
       "            0.881  , 0.8804 , 0.88   , 0.8784 , 0.8765 , 0.875  , 0.873  ,\n",
       "            0.8696 , 0.869  , 0.868  , 0.8677 , 0.865  , 0.8604 , 0.86   ,\n",
       "            0.8506 , 0.85   , 0.8496 , 0.8477 , 0.842  , 0.84   , 0.8223 ,\n",
       "            0.8174 , 0.8145 , 0.8066 , 0.8057 , 0.7974 , 0.7964 , 0.7905 ,\n",
       "            0.7866 , 0.786  , 0.7837 , 0.76   , 0.7573 , 0.743  , 0.7427 ,\n",
       "            0.7275 , 0.727  , 0.7114 , 0.711  , 0.707  , 0.6973 , 0.69   ,\n",
       "            0.687  , 0.675  , 0.671  , 0.67   , 0.6694 , 0.667  , 0.6587 ,\n",
       "            0.6577 , 0.654  , 0.6523 , 0.648  , 0.646  , 0.6377 , 0.6357 ,\n",
       "            0.633  , 0.6323 , 0.632  , 0.629  , 0.625  , 0.623  , 0.6226 ,\n",
       "            0.6216 , 0.6206 , 0.619  , 0.615  , 0.6147 , 0.6123 , 0.6074 ,\n",
       "            0.6064 , 0.6045 , 0.6025 , 0.5986 , 0.597  , 0.594  , 0.593  ,\n",
       "            0.5884 , 0.586  , 0.5806 , 0.579  , 0.5786 , 0.5776 , 0.576  ,\n",
       "            0.5713 , 0.571  , 0.5693 , 0.568  , 0.5674 , 0.565  , 0.5615 ,\n",
       "            0.5605 , 0.56   , 0.5576 , 0.554  , 0.5527 , 0.5522 , 0.5483 ,\n",
       "            0.5474 , 0.5435 , 0.5405 , 0.5366 , 0.532  , 0.5317 , 0.527  ,\n",
       "            0.52   , 0.5166 , 0.509  , 0.4978 , 0.4917 , 0.4907 , 0.4854 ,\n",
       "            0.479  , 0.4707 , 0.4646 , 0.4607 , 0.4602 , 0.4485 , 0.4355 ,\n",
       "            0.4294 , 0.4263 , 0.4233 , 0.421  , 0.415  , 0.413  , 0.4097 ,\n",
       "            0.4094 , 0.398  , 0.395  , 0.3928 , 0.388  , 0.383  , 0.382  ,\n",
       "            0.377  , 0.3652 , 0.3645 , 0.3623 , 0.3474 , 0.344  , 0.3425 ,\n",
       "            0.3325 , 0.3206 , 0.3157 , 0.3123 , 0.3047 , 0.2969 , 0.291  ,\n",
       "            0.2908 , 0.2808 , 0.2722 , 0.2441 , 0.2401 , 0.2367 , 0.213  ,\n",
       "            0.2039 , 0.199  , 0.1962 , 0.1953 , 0.181  , 0.1748 , 0.1663 ,\n",
       "            0.155  , 0.1542 , 0.1498 , 0.1466 , 0.1451 , 0.1445 , 0.1407 ,\n",
       "            0.1389 , 0.1359 , 0.1357 , 0.127  , 0.1229 , 0.1172 , 0.1138 ,\n",
       "            0.1078 , 0.0964 , 0.09467, 0.0935 , 0.0896 , 0.0734 , 0.06177,\n",
       "            0.05624, 0.0527 , 0.05185, 0.05005, 0.04526, 0.04108, 0.03812,\n",
       "            0.0326 , 0.02992, 0.02893, 0.02681, 0.0247 , 0.02141, 0.02077,\n",
       "            0.02037], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.425, dtype=float32),\n",
       "    'tpr': array(0.86153847, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.225     ,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.35833332, 0.375     ,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.525     , 0.525     ,\n",
       "            0.53333336, 0.55      , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.16923077, 0.17692308, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.33076924,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.5153846 ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6       , 0.6       , 0.6076923 ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.6923077 , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.7307692 , 0.73846155, 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.83076924, 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9595 , 0.9526 , 0.9443 , 0.943  , 0.9424 , 0.942  ,\n",
       "            0.939  , 0.9365 , 0.936  , 0.9336 , 0.933  , 0.9326 , 0.93   ,\n",
       "            0.9287 , 0.9272 , 0.9263 , 0.9253 , 0.9224 , 0.9214 , 0.9185 ,\n",
       "            0.915  , 0.9136 , 0.9116 , 0.911  , 0.9077 , 0.905  , 0.8984 ,\n",
       "            0.8975 , 0.897  , 0.8955 , 0.895  , 0.8945 , 0.893  , 0.892  ,\n",
       "            0.89   , 0.889  , 0.888  , 0.8857 , 0.885  , 0.8843 , 0.8833 ,\n",
       "            0.881  , 0.877  , 0.8765 , 0.8696 , 0.869  , 0.8687 , 0.867  ,\n",
       "            0.8667 , 0.8657 , 0.8643 , 0.858  , 0.8564 , 0.841  , 0.835  ,\n",
       "            0.833  , 0.8267 , 0.8223 , 0.8154 , 0.8105 , 0.807  , 0.8057 ,\n",
       "            0.802  , 0.782  , 0.7812 , 0.7627 , 0.7607 , 0.757  , 0.7437 ,\n",
       "            0.736  , 0.7334 , 0.727  , 0.7266 , 0.7236 , 0.7183 , 0.713  ,\n",
       "            0.6973 , 0.697  , 0.6963 , 0.695  , 0.692  , 0.6855 , 0.6836 ,\n",
       "            0.679  , 0.678  , 0.6753 , 0.672  , 0.6665 , 0.663  , 0.659  ,\n",
       "            0.6587 , 0.658  , 0.657  , 0.6562 , 0.6543 , 0.653  , 0.6514 ,\n",
       "            0.65   , 0.6494 , 0.648  , 0.645  , 0.642  , 0.64   , 0.638  ,\n",
       "            0.6377 , 0.6313 , 0.6304 , 0.628  , 0.6274 , 0.623  , 0.6226 ,\n",
       "            0.62   , 0.6187 , 0.618  , 0.616  , 0.613  , 0.607  , 0.6064 ,\n",
       "            0.604  , 0.6035 , 0.603  , 0.6006 , 0.6    , 0.5957 , 0.5933 ,\n",
       "            0.592  , 0.5913 , 0.589  , 0.5884 , 0.5874 , 0.581  , 0.579  ,\n",
       "            0.578  , 0.5776 , 0.576  , 0.5703 , 0.567  , 0.558  , 0.5547 ,\n",
       "            0.553  , 0.551  , 0.541  , 0.5376 , 0.5264 , 0.5225 , 0.519  ,\n",
       "            0.5083 , 0.4944 , 0.4895 , 0.4885 , 0.4817 , 0.4805 , 0.48   ,\n",
       "            0.4783 , 0.4658 , 0.4553 , 0.4387 , 0.4368 , 0.431  , 0.428  ,\n",
       "            0.4263 , 0.4197 , 0.4182 , 0.4155 , 0.414  , 0.4138 , 0.4126 ,\n",
       "            0.4104 , 0.406  , 0.3896 , 0.3826 , 0.367  , 0.3667 , 0.3613 ,\n",
       "            0.3555 , 0.3445 , 0.343  , 0.3335 , 0.3196 , 0.3147 , 0.2983 ,\n",
       "            0.2942 , 0.291  , 0.2742 , 0.2705 , 0.251  , 0.2338 , 0.2294 ,\n",
       "            0.2142 , 0.2004 , 0.1974 , 0.195  , 0.1913 , 0.1755 , 0.1711 ,\n",
       "            0.1688 , 0.1641 , 0.1482 , 0.1459 , 0.141  , 0.1404 , 0.1396 ,\n",
       "            0.1384 , 0.1335 , 0.1311 , 0.1288 , 0.1197 , 0.11554, 0.11066,\n",
       "            0.108  , 0.10266, 0.0903 , 0.0899 , 0.0871 , 0.0856 , 0.0667 ,\n",
       "            0.05698, 0.05243, 0.04904, 0.0478 , 0.04648, 0.04047, 0.03677,\n",
       "            0.03455, 0.02881, 0.02759, 0.02576, 0.02377, 0.0223 , 0.01869,\n",
       "            0.01843, 0.01826], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.425, dtype=float32),\n",
       "    'tpr': array(0.86923075, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.15      , 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.175     ,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.225     , 0.225     , 0.23333333,\n",
       "            0.24166666, 0.24166666, 0.24166666, 0.25      , 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.26666668, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.35      , 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.69166666, 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.14615385, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33846155, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.65384614, 0.65384614,\n",
       "            0.65384614, 0.6615385 , 0.6615385 , 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7846154 , 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.966  , 0.96   , 0.9526 , 0.951  , 0.948  , 0.946  ,\n",
       "            0.9453 , 0.944  , 0.9424 , 0.942  , 0.94   , 0.9385 , 0.937  ,\n",
       "            0.936  , 0.935  , 0.932  , 0.9287 , 0.9253 , 0.9224 , 0.922  ,\n",
       "            0.9185 , 0.916  , 0.91   , 0.9097 , 0.9087 , 0.907  , 0.9062 ,\n",
       "            0.9053 , 0.904  , 0.9033 , 0.901  , 0.8994 , 0.898  , 0.8975 ,\n",
       "            0.897  , 0.8965 , 0.896  , 0.895  , 0.8945 , 0.89   , 0.889  ,\n",
       "            0.882  , 0.8813 , 0.8804 , 0.8794 , 0.878  , 0.877  , 0.8765 ,\n",
       "            0.872  , 0.8706 , 0.854  , 0.849  , 0.846  , 0.84   , 0.837  ,\n",
       "            0.83   , 0.829  , 0.823  , 0.8213 , 0.8193 , 0.816  , 0.7954 ,\n",
       "            0.7944 , 0.7764 , 0.7744 , 0.7695 , 0.758  , 0.748  , 0.7466 ,\n",
       "            0.741  , 0.7397 , 0.737  , 0.731  , 0.7256 , 0.709  , 0.7085 ,\n",
       "            0.708  , 0.707  , 0.7036 , 0.6973 , 0.6953 , 0.691  , 0.6895 ,\n",
       "            0.6865 , 0.683  , 0.6797 , 0.6743 , 0.67   , 0.6694 , 0.669  ,\n",
       "            0.668  , 0.667  , 0.666  , 0.664  , 0.662  , 0.6606 , 0.66   ,\n",
       "            0.6587 , 0.6553 , 0.655  , 0.654  , 0.651  , 0.649  , 0.6484 ,\n",
       "            0.648  , 0.6416 , 0.638  , 0.637  , 0.633  , 0.6304 , 0.63   ,\n",
       "            0.6284 , 0.6265 , 0.622  , 0.6187 , 0.6177 , 0.6147 , 0.6133 ,\n",
       "            0.613  , 0.61   , 0.6084 , 0.6025 , 0.602  , 0.601  , 0.6006 ,\n",
       "            0.599  , 0.598  , 0.591  , 0.5903 , 0.5864 , 0.5854 , 0.582  ,\n",
       "            0.579  , 0.5786 , 0.5664 , 0.5645 , 0.5615 , 0.561  , 0.5605 ,\n",
       "            0.5503 , 0.546  , 0.54   , 0.5366 , 0.5225 , 0.513  , 0.5005 ,\n",
       "            0.496  , 0.4902 , 0.488  , 0.487  , 0.4792 , 0.4717 , 0.467  ,\n",
       "            0.4624 , 0.4497 , 0.4448 , 0.4346 , 0.4297 , 0.425  , 0.4233 ,\n",
       "            0.4211 , 0.4202 , 0.4185 , 0.4177 , 0.4165 , 0.4006 , 0.3906 ,\n",
       "            0.3787 , 0.375  , 0.3684 , 0.3657 , 0.363  , 0.3523 , 0.3416 ,\n",
       "            0.3398 , 0.3245 , 0.3088 , 0.2979 , 0.2864 , 0.285  , 0.2656 ,\n",
       "            0.2637 , 0.2502 , 0.2249 , 0.2205 , 0.2101 , 0.1937 , 0.1927 ,\n",
       "            0.1871 , 0.1836 , 0.1703 , 0.167  , 0.1666 , 0.1599 , 0.1393 ,\n",
       "            0.1365 , 0.1327 , 0.1313 , 0.13   , 0.1285 , 0.12244, 0.1201 ,\n",
       "            0.11145, 0.10724, 0.10284, 0.10016, 0.0959 , 0.08374, 0.0831 ,\n",
       "            0.0801 , 0.0799 , 0.0602 , 0.05185, 0.04803, 0.04486, 0.04337,\n",
       "            0.0424 , 0.03583, 0.03253, 0.03096, 0.02522, 0.02493, 0.02263,\n",
       "            0.02084, 0.01984, 0.0164 , 0.01616, 0.0159 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.425, dtype=float32),\n",
       "    'tpr': array(0.86923075, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15833333, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.225     , 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.375     , 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.425     , 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.07692308, 0.08461539, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.5153846 , 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.74615383, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9707 , 0.9653 , 0.959  , 0.9575 , 0.957  , 0.955  ,\n",
       "            0.952  , 0.9507 , 0.949  , 0.9473 , 0.9453 , 0.9443 , 0.9434 ,\n",
       "            0.9424 , 0.94   , 0.9395 , 0.9365 , 0.933  , 0.93   , 0.9297 ,\n",
       "            0.927  , 0.9243 , 0.919  , 0.9185 , 0.9175 , 0.916  , 0.9155 ,\n",
       "            0.915  , 0.914  , 0.9126 , 0.912  , 0.9097 , 0.9087 , 0.907  ,\n",
       "            0.9067 , 0.9062 , 0.906  , 0.9053 , 0.9043 , 0.9033 , 0.899  ,\n",
       "            0.8984 , 0.891  , 0.8906 , 0.89   , 0.889  , 0.8877 , 0.886  ,\n",
       "            0.8813 , 0.8804 , 0.864  , 0.8584 , 0.856  , 0.85   , 0.846  ,\n",
       "            0.839  , 0.8335 , 0.83   , 0.8296 , 0.825  , 0.805  , 0.8047 ,\n",
       "            0.786  , 0.7827 , 0.7783 , 0.7656 , 0.758  , 0.7563 , 0.749  ,\n",
       "            0.7485 , 0.7446 , 0.7397 , 0.7344 , 0.7173 , 0.717  , 0.7153 ,\n",
       "            0.7095 , 0.705  , 0.7036 , 0.699  , 0.6978 , 0.695  , 0.6914 ,\n",
       "            0.6885 , 0.682  , 0.6787 , 0.6777 , 0.677  , 0.6763 , 0.676  ,\n",
       "            0.6733 , 0.672  , 0.67   , 0.6685 , 0.6675 , 0.666  , 0.664  ,\n",
       "            0.6626 , 0.6616 , 0.659  , 0.6562 , 0.656  , 0.655  , 0.6484 ,\n",
       "            0.645  , 0.644  , 0.639  , 0.6387 , 0.636  , 0.635  , 0.6294 ,\n",
       "            0.6284 , 0.627  , 0.626  , 0.6255 , 0.622  , 0.6206 , 0.619  ,\n",
       "            0.616  , 0.615  , 0.6084 , 0.608  , 0.607  , 0.605  , 0.6045 ,\n",
       "            0.5986 , 0.598  , 0.596  , 0.592  , 0.591  , 0.589  , 0.5854 ,\n",
       "            0.584  , 0.5713 , 0.57   , 0.567  , 0.5664 , 0.562  , 0.555  ,\n",
       "            0.5547 , 0.551  , 0.547  , 0.544  , 0.5205 , 0.515  , 0.5063 ,\n",
       "            0.4941 , 0.4934 , 0.491  , 0.4895 , 0.4873 , 0.4758 , 0.4731 ,\n",
       "            0.465  , 0.4563 , 0.4465 , 0.4365 , 0.4302 , 0.4294 , 0.4287 ,\n",
       "            0.428  , 0.424  , 0.4233 , 0.4192 , 0.4182 , 0.4114 , 0.4104 ,\n",
       "            0.406  , 0.3938 , 0.378  , 0.3708 , 0.3706 , 0.3704 , 0.3567 ,\n",
       "            0.3552 , 0.3455 , 0.3313 , 0.3245 , 0.2996 , 0.2942 , 0.2761 ,\n",
       "            0.2756 , 0.2542 , 0.2534 , 0.2467 , 0.2134 , 0.2084 , 0.2043 ,\n",
       "            0.1882 , 0.1837 , 0.178  , 0.1744 , 0.1671 , 0.1663 , 0.1571 ,\n",
       "            0.1497 , 0.1321 , 0.1315 , 0.1293 , 0.1238 , 0.12286, 0.1223 ,\n",
       "            0.121  , 0.1124 , 0.11066, 0.1021 , 0.09827, 0.0945 , 0.0922 ,\n",
       "            0.0888 , 0.0775 , 0.07587, 0.0745 , 0.0724 , 0.0534 , 0.0469 ,\n",
       "            0.04376, 0.04077, 0.03912, 0.03854, 0.03125, 0.02844, 0.02759,\n",
       "            0.0225 , 0.02187, 0.01979, 0.01819, 0.01758, 0.01456, 0.0139 ,\n",
       "            0.01374], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.45, dtype=float32),\n",
       "    'tpr': array(0.9, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.10833333, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "            0.175     , 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.24166666, 0.25      ,\n",
       "            0.25      , 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.425     ,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.6666667 , 0.675     , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.16153847, 0.16923077, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.32307693, 0.33076924, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.6       , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.64615387, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6923077 , 0.6923077 , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7       , 0.7076923 , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7846154 , 0.7846154 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.86923075, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9775 , 0.9727 , 0.967  , 0.966  , 0.9653 , 0.9634 ,\n",
       "            0.961  , 0.96   , 0.9585 , 0.958  , 0.9565 , 0.955  , 0.954  ,\n",
       "            0.953  , 0.9526 , 0.952  , 0.95   , 0.9473 , 0.9463 , 0.9443 ,\n",
       "            0.9424 , 0.942  , 0.941  , 0.9385 , 0.938  , 0.9316 , 0.931  ,\n",
       "            0.9307 , 0.929  , 0.928  , 0.9277 , 0.9272 , 0.927  , 0.9253 ,\n",
       "            0.924  , 0.922  , 0.921  , 0.9204 , 0.92   , 0.9194 , 0.9185 ,\n",
       "            0.9175 , 0.9146 , 0.9136 , 0.9097 , 0.909  , 0.908  , 0.906  ,\n",
       "            0.9053 , 0.903  , 0.9014 , 0.896  , 0.8955 , 0.8823 , 0.8755 ,\n",
       "            0.874  , 0.8706 , 0.863  , 0.859  , 0.8584 , 0.8564 , 0.8496 ,\n",
       "            0.8477 , 0.8438 , 0.8325 , 0.8286 , 0.813  , 0.8086 , 0.8022 ,\n",
       "            0.7866 , 0.785  , 0.7847 , 0.7812 , 0.7744 , 0.7676 , 0.766  ,\n",
       "            0.7637 , 0.7524 , 0.7505 , 0.749  , 0.74   , 0.736  , 0.731  ,\n",
       "            0.73   , 0.7295 , 0.729  , 0.7236 , 0.7197 , 0.7188 , 0.7144 ,\n",
       "            0.714  , 0.7114 , 0.711  , 0.7104 , 0.7085 , 0.708  , 0.7075 ,\n",
       "            0.7065 , 0.7036 , 0.7007 , 0.7    , 0.6987 , 0.6978 , 0.697  ,\n",
       "            0.6895 , 0.6855 , 0.6826 , 0.6807 , 0.6797 , 0.6787 , 0.676  ,\n",
       "            0.6743 , 0.673  , 0.6714 , 0.67   , 0.665  , 0.6646 , 0.661  ,\n",
       "            0.6606 , 0.66   , 0.6562 , 0.6514 , 0.649  , 0.6484 , 0.6475 ,\n",
       "            0.643  , 0.641  , 0.6406 , 0.64   , 0.6396 , 0.639  , 0.6367 ,\n",
       "            0.63   , 0.627  , 0.6245 , 0.623  , 0.6157 , 0.6025 , 0.602  ,\n",
       "            0.6006 , 0.597  , 0.5884 , 0.587  , 0.582  , 0.545  , 0.541  ,\n",
       "            0.536  , 0.529  , 0.524  , 0.5215 , 0.5137 , 0.509  , 0.5034 ,\n",
       "            0.5024 , 0.4995 , 0.4978 , 0.4895 , 0.477  , 0.474  , 0.4739 ,\n",
       "            0.468  , 0.4675 , 0.4668 , 0.4558 , 0.4456 , 0.445  , 0.4336 ,\n",
       "            0.4282 , 0.4277 , 0.422  , 0.412  , 0.4094 , 0.4033 , 0.395  ,\n",
       "            0.3818 , 0.3772 , 0.3638 , 0.3516 , 0.3376 , 0.3103 , 0.3037 ,\n",
       "            0.2815 , 0.277  , 0.2622 , 0.2573 , 0.252  , 0.2118 , 0.2113 ,\n",
       "            0.2053 , 0.1954 , 0.1859 , 0.1844 , 0.179  , 0.178  , 0.1746 ,\n",
       "            0.1556 , 0.1475 , 0.1357 , 0.132  , 0.126  , 0.12317, 0.1216 ,\n",
       "            0.12103, 0.1184 , 0.1082 , 0.10706, 0.09827, 0.094  , 0.0914 ,\n",
       "            0.0893 , 0.0868 , 0.07544, 0.0732 , 0.0725 , 0.0688 , 0.0495 ,\n",
       "            0.04428, 0.04193, 0.03897, 0.037  , 0.03683, 0.0286 , 0.02606,\n",
       "            0.02571, 0.02141, 0.01976, 0.01805, 0.01653, 0.0164 , 0.01363,\n",
       "            0.01248, 0.01243], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.45833334, dtype=float32),\n",
       "    'tpr': array(0.9230769, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.23333333, 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "            0.25      , 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.21538462,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.4846154 ,\n",
       "            0.4923077 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5923077 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.6615385 , 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6923077 , 0.6923077 , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7       , 0.7076923 , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.982   , 0.977   , 0.972   , 0.971   , 0.9707  ,\n",
       "            0.969   , 0.9673  , 0.967   , 0.966   , 0.9644  , 0.963   ,\n",
       "            0.962   , 0.9604  , 0.96    , 0.9595  , 0.959   , 0.9575  ,\n",
       "            0.957   , 0.9546  , 0.9517  , 0.95    , 0.9497  , 0.9487  ,\n",
       "            0.947   , 0.94    , 0.9395  , 0.9385  , 0.937   , 0.9365  ,\n",
       "            0.936   , 0.934   , 0.9336  , 0.9316  , 0.931   , 0.9307  ,\n",
       "            0.93    , 0.9297  , 0.929   , 0.9287  , 0.928   , 0.927   ,\n",
       "            0.9253  , 0.9233  , 0.922   , 0.921   , 0.92    , 0.9175  ,\n",
       "            0.9146  , 0.9136  , 0.912   , 0.906   , 0.9053  , 0.895   ,\n",
       "            0.8867  , 0.8843  , 0.875   , 0.874   , 0.8716  , 0.868   ,\n",
       "            0.864   , 0.8594  , 0.856   , 0.8506  , 0.844   , 0.8354  ,\n",
       "            0.8237  , 0.8154  , 0.809   , 0.8057  , 0.7983  , 0.797   ,\n",
       "            0.7866  , 0.7773  , 0.776   , 0.773   , 0.77    , 0.7637  ,\n",
       "            0.7573  , 0.756   , 0.752   , 0.7515  , 0.747   , 0.7446  ,\n",
       "            0.7417  , 0.7383  , 0.737   , 0.7363  , 0.736   , 0.7354  ,\n",
       "            0.734   , 0.732   , 0.7285  , 0.728   , 0.727   , 0.7246  ,\n",
       "            0.7217  , 0.7207  , 0.7188  , 0.714   , 0.7114  , 0.7085  ,\n",
       "            0.706   , 0.705   , 0.7036  , 0.7007  , 0.6987  , 0.6963  ,\n",
       "            0.696   , 0.6953  , 0.6943  , 0.692   , 0.6904  , 0.6875  ,\n",
       "            0.686   , 0.6846  , 0.683   , 0.6753  , 0.674   , 0.67    ,\n",
       "            0.668   , 0.6675  , 0.6665  , 0.6646  , 0.6636  , 0.6626  ,\n",
       "            0.6606  , 0.66    , 0.6533  , 0.649   , 0.6475  , 0.6377  ,\n",
       "            0.6255  , 0.624   , 0.6235  , 0.6187  , 0.615   , 0.614   ,\n",
       "            0.6094  , 0.609   , 0.604   , 0.594   , 0.569   , 0.5566  ,\n",
       "            0.55    , 0.544   , 0.5405  , 0.5396  , 0.527   , 0.52    ,\n",
       "            0.5176  , 0.5156  , 0.5107  , 0.504   , 0.502   , 0.4956  ,\n",
       "            0.4954  , 0.4932  , 0.4905  , 0.4868  , 0.476   , 0.4712  ,\n",
       "            0.4617  , 0.45    , 0.4355  , 0.435   , 0.4338  , 0.4282  ,\n",
       "            0.4263  , 0.4255  , 0.4243  , 0.4204  , 0.406   , 0.3772  ,\n",
       "            0.369   , 0.3655  , 0.3376  , 0.3196  , 0.3025  , 0.2815  ,\n",
       "            0.2734  , 0.2712  , 0.2556  , 0.2456  , 0.2153  , 0.2056  ,\n",
       "            0.1996  , 0.199   , 0.1987  , 0.1864  , 0.1826  , 0.1755  ,\n",
       "            0.1721  , 0.152   , 0.143   , 0.1376  , 0.1302  , 0.1223  ,\n",
       "            0.12103 , 0.118   , 0.1178  , 0.1144  , 0.1025  , 0.1021  ,\n",
       "            0.0933  , 0.089   , 0.0873  , 0.0856  , 0.08374 , 0.0729  ,\n",
       "            0.07135 , 0.06866 , 0.06476 , 0.04526 , 0.04163 , 0.04    ,\n",
       "            0.0371  , 0.03506 , 0.03482 , 0.02596 , 0.02396 , 0.02377 ,\n",
       "            0.02034 , 0.01785 , 0.01646 , 0.01525 , 0.015015, 0.01277 ,\n",
       "            0.011246], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.48333332, dtype=float32),\n",
       "    'tpr': array(0.93846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.09166667, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.21666667, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25      , 0.25      ,\n",
       "            0.25      , 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06923077, 0.07692308, 0.08461539,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.2769231 , 0.2923077 , 0.32307693,\n",
       "            0.33076924, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.44615385, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7       , 0.7       , 0.7076923 , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.7153846 , 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.86923075, 0.8769231 ,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.985   , 0.981   , 0.9766  , 0.9756  , 0.975   ,\n",
       "            0.974   , 0.972   , 0.9717  , 0.9707  , 0.9697  , 0.9683  ,\n",
       "            0.9673  , 0.9663  , 0.966   , 0.9653  , 0.965   , 0.9634  ,\n",
       "            0.9614  , 0.961   , 0.958   , 0.957   , 0.9565  , 0.9556  ,\n",
       "            0.9546  , 0.9536  , 0.9478  , 0.9473  , 0.947   , 0.9463  ,\n",
       "            0.945   , 0.9443  , 0.944   , 0.942   , 0.9395  , 0.939   ,\n",
       "            0.9375  , 0.937   , 0.9365  , 0.9355  , 0.934   , 0.932   ,\n",
       "            0.931   , 0.93    , 0.9272  , 0.924   , 0.923   , 0.9214  ,\n",
       "            0.915   , 0.9062  , 0.8975  , 0.897   , 0.896   , 0.889   ,\n",
       "            0.8843  , 0.8833  , 0.8794  , 0.8765  , 0.8706  , 0.8677  ,\n",
       "            0.866   , 0.859   , 0.8535  , 0.838   , 0.8286  , 0.8276  ,\n",
       "            0.8228  , 0.816   , 0.814   , 0.8086  , 0.8057  , 0.796   ,\n",
       "            0.7925  , 0.7896  , 0.7886  , 0.7876  , 0.7866  , 0.7837  ,\n",
       "            0.7773  , 0.777   , 0.7715  , 0.771   , 0.7695  , 0.769   ,\n",
       "            0.7646  , 0.76    , 0.7583  , 0.758   , 0.7554  , 0.755   ,\n",
       "            0.7544  , 0.7534  , 0.752   , 0.7505  , 0.7485  , 0.746   ,\n",
       "            0.745   , 0.741   , 0.74    , 0.738   , 0.7334  , 0.7314  ,\n",
       "            0.7256  , 0.725   , 0.7236  , 0.723   , 0.7188  , 0.7173  ,\n",
       "            0.7153  , 0.715   , 0.7144  , 0.7134  , 0.712   , 0.7095  ,\n",
       "            0.7075  , 0.7056  , 0.7036  , 0.6978  , 0.6963  , 0.6924  ,\n",
       "            0.691   , 0.6885  , 0.687   , 0.6846  , 0.684   , 0.683   ,\n",
       "            0.68    , 0.675   , 0.6724  , 0.6714  , 0.6704  , 0.6665  ,\n",
       "            0.656   , 0.6445  , 0.643   , 0.6406  , 0.6377  , 0.636   ,\n",
       "            0.6274  , 0.627   , 0.622   , 0.6064  , 0.592   , 0.5723  ,\n",
       "            0.5703  , 0.5645  , 0.563   , 0.559   , 0.553   , 0.5513  ,\n",
       "            0.537   , 0.5366  , 0.532   , 0.5293  , 0.523   , 0.5186  ,\n",
       "            0.5176  , 0.513   , 0.505   , 0.501   , 0.496   , 0.495   ,\n",
       "            0.477   , 0.4707  , 0.459   , 0.4546  , 0.444   , 0.4434  ,\n",
       "            0.437   , 0.43    , 0.4287  , 0.4285  , 0.4265  , 0.3848  ,\n",
       "            0.3765  , 0.3665  , 0.337   , 0.3274  , 0.2998  , 0.2803  ,\n",
       "            0.2783  , 0.2686  , 0.253   , 0.2383  , 0.2167  , 0.211   ,\n",
       "            0.2004  , 0.1987  , 0.1915  , 0.1909  , 0.1787  , 0.1711  ,\n",
       "            0.1678  , 0.1466  , 0.1373  , 0.137   , 0.1266  , 0.1193  ,\n",
       "            0.11475 , 0.1128  , 0.10895 , 0.096   , 0.0957  , 0.0874  ,\n",
       "            0.083   , 0.082   , 0.0805  , 0.07935 , 0.06903 , 0.06793 ,\n",
       "            0.06396 , 0.05988 , 0.04062 , 0.03824 , 0.03726 , 0.03442 ,\n",
       "            0.03253 , 0.03198 , 0.02303 , 0.0217  , 0.02116 , 0.01877 ,\n",
       "            0.01572 , 0.01456 , 0.013794, 0.013275, 0.0116  , 0.00986 ,\n",
       "            0.00978 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.93846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.1       , 0.10833333,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.175     , 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.275     , 0.28333333, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.31666666, 0.325     , 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.16153847, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.24615385, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.32307693, 0.33076924,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4923077 , 0.4923077 , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.6230769 , 0.63076925, 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.65384614, 0.65384614, 0.65384614,\n",
       "            0.66923076, 0.6769231 , 0.6769231 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.7153846 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9873  , 0.984   , 0.9795  , 0.979   , 0.9785  ,\n",
       "            0.9775  , 0.976   , 0.9756  , 0.975   , 0.9736  , 0.9727  ,\n",
       "            0.971   , 0.97    , 0.9697  , 0.969   , 0.968   , 0.9663  ,\n",
       "            0.966   , 0.9634  , 0.9624  , 0.9614  , 0.961   , 0.96    ,\n",
       "            0.959   , 0.9536  , 0.953   , 0.952   , 0.95    , 0.9497  ,\n",
       "            0.948   , 0.9478  , 0.9463  , 0.946   , 0.9453  , 0.944   ,\n",
       "            0.9434  , 0.943   , 0.942   , 0.941   , 0.9395  , 0.9385  ,\n",
       "            0.937   , 0.934   , 0.9307  , 0.9297  , 0.9287  , 0.9224  ,\n",
       "            0.922   , 0.9146  , 0.9062  , 0.9053  , 0.899   , 0.8926  ,\n",
       "            0.888   , 0.886   , 0.879   , 0.8774  , 0.8765  , 0.869   ,\n",
       "            0.8667  , 0.8486  , 0.844   , 0.8374  , 0.835   , 0.8296  ,\n",
       "            0.825   , 0.8184  , 0.818   , 0.8105  , 0.806   , 0.8027  ,\n",
       "            0.802   , 0.7983  , 0.796   , 0.7954  , 0.7905  , 0.789   ,\n",
       "            0.788   , 0.785   , 0.784   , 0.78    , 0.7783  , 0.776   ,\n",
       "            0.775   , 0.772   , 0.7705  , 0.77    , 0.769   , 0.7686  ,\n",
       "            0.7656  , 0.7637  , 0.7627  , 0.7593  , 0.756   , 0.755   ,\n",
       "            0.752   , 0.751   , 0.7495  , 0.7466  , 0.7456  , 0.7417  ,\n",
       "            0.7393  , 0.737   , 0.735   , 0.733   , 0.732   , 0.731   ,\n",
       "            0.7305  , 0.729   , 0.7285  , 0.7266  , 0.725   , 0.7188  ,\n",
       "            0.7173  , 0.7153  , 0.7114  , 0.7075  , 0.7056  , 0.7046  ,\n",
       "            0.7036  , 0.7007  , 0.7     , 0.694   , 0.6934  , 0.6895  ,\n",
       "            0.689   , 0.683   , 0.6826  , 0.6797  , 0.6714  , 0.665   ,\n",
       "            0.661   , 0.66    , 0.6553  , 0.6504  , 0.6436  , 0.643   ,\n",
       "            0.6377  , 0.6157  , 0.6133  , 0.59    , 0.5874  , 0.584   ,\n",
       "            0.582   , 0.5776  , 0.5767  , 0.559   , 0.556   , 0.5557  ,\n",
       "            0.5547  , 0.5537  , 0.5415  , 0.535   , 0.531   , 0.5273  ,\n",
       "            0.5234  , 0.523   , 0.521   , 0.5146  , 0.504   , 0.493   ,\n",
       "            0.4922  , 0.4836  , 0.476   , 0.4692  , 0.4634  , 0.453   ,\n",
       "            0.437   , 0.432   , 0.4297  , 0.423   , 0.4019  , 0.3743  ,\n",
       "            0.3657  , 0.3354  , 0.3347  , 0.2964  , 0.2866  , 0.278   ,\n",
       "            0.2627  , 0.2493  , 0.2301  , 0.2251  , 0.2189  , 0.2028  ,\n",
       "            0.1982  , 0.1912  , 0.1827  , 0.1752  , 0.1671  , 0.1638  ,\n",
       "            0.1415  , 0.1381  , 0.1312  , 0.12366 , 0.1172  , 0.10876 ,\n",
       "            0.1086  , 0.108   , 0.10376 , 0.0903  , 0.0895  , 0.0818  ,\n",
       "            0.0772  , 0.0771  , 0.076   , 0.07556 , 0.06573 , 0.06537 ,\n",
       "            0.05966 , 0.05542 , 0.0365  , 0.0354  , 0.035   , 0.0323  ,\n",
       "            0.0305  , 0.02959 , 0.0205  , 0.01984 , 0.01894 , 0.01752 ,\n",
       "            0.0139  , 0.01302 , 0.01257 , 0.011826, 0.01061 , 0.00871 ,\n",
       "            0.00861 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5083333, dtype=float32),\n",
       "    'tpr': array(0.95384616, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.1       , 0.1       , 0.10833333,\n",
       "            0.125     , 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.275     , 0.275     , 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06923077, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.23076923, 0.23846154, 0.24615385, 0.26923078,\n",
       "            0.2769231 , 0.2923077 , 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.35384616, 0.36923078, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.5307692 , 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.65384614, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6769231 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.7307692 ,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.989   , 0.9854  , 0.9814  , 0.981   , 0.9805  ,\n",
       "            0.98    , 0.978   , 0.9775  , 0.976   , 0.9756  , 0.9746  ,\n",
       "            0.9736  , 0.9727  , 0.972   , 0.9717  , 0.9707  , 0.97    ,\n",
       "            0.9688  , 0.9683  , 0.9663  , 0.965   , 0.9644  , 0.9634  ,\n",
       "            0.9624  , 0.962   , 0.9565  , 0.956   , 0.955   , 0.9536  ,\n",
       "            0.953   , 0.9517  , 0.949   , 0.9487  , 0.9478  , 0.9473  ,\n",
       "            0.9463  , 0.9443  , 0.943   , 0.942   , 0.941   , 0.938   ,\n",
       "            0.935   , 0.9336  , 0.9326  , 0.9272  , 0.927   , 0.9185  ,\n",
       "            0.9106  , 0.9097  , 0.904   , 0.898   , 0.8975  , 0.893   ,\n",
       "            0.891   , 0.8843  , 0.8823  , 0.882   , 0.8755  , 0.8745  ,\n",
       "            0.856   , 0.8545  , 0.843   , 0.8403  , 0.837   , 0.831   ,\n",
       "            0.8247  , 0.8237  , 0.8203  , 0.8135  , 0.811   , 0.809   ,\n",
       "            0.8086  , 0.808   , 0.8066  , 0.804   , 0.8003  , 0.799   ,\n",
       "            0.797   , 0.792   , 0.791   , 0.7905  , 0.787   , 0.7866  ,\n",
       "            0.7847  , 0.7817  , 0.7793  , 0.779   , 0.777   , 0.7754  ,\n",
       "            0.774   , 0.771   , 0.768   , 0.7676  , 0.7666  , 0.7656  ,\n",
       "            0.7617  , 0.7607  , 0.758   , 0.753   , 0.7524  , 0.751   ,\n",
       "            0.7495  , 0.7476  , 0.747   , 0.7446  , 0.744   , 0.743   ,\n",
       "            0.742   , 0.741   , 0.737   , 0.7363  , 0.735   , 0.734   ,\n",
       "            0.732   , 0.73    , 0.722   , 0.721   , 0.7183  , 0.7144  ,\n",
       "            0.714   , 0.7124  , 0.708   , 0.7026  , 0.7007  , 0.697   ,\n",
       "            0.696   , 0.689   , 0.683   , 0.6826  , 0.682   , 0.6763  ,\n",
       "            0.6753  , 0.6655  , 0.661   , 0.657   , 0.6567  , 0.651   ,\n",
       "            0.634   , 0.6196  , 0.6104  , 0.6084  , 0.6035  , 0.5996  ,\n",
       "            0.5933  , 0.5903  , 0.589   , 0.5825  , 0.5737  , 0.568   ,\n",
       "            0.5664  , 0.558   , 0.556   , 0.5474  , 0.5464  , 0.5405  ,\n",
       "            0.5337  , 0.527   , 0.5234  , 0.5146  , 0.5107  , 0.5073  ,\n",
       "            0.503   , 0.499   , 0.4963  , 0.4846  , 0.4797  , 0.4333  ,\n",
       "            0.4297  , 0.427   , 0.42    , 0.417   , 0.3696  , 0.362   ,\n",
       "            0.3435  , 0.3303  , 0.2954  , 0.291   , 0.274   , 0.2556  ,\n",
       "            0.2444  , 0.243   , 0.2216  , 0.2211  , 0.2068  , 0.2053  ,\n",
       "            0.1836  , 0.1747  , 0.1708  , 0.1625  , 0.1593  , 0.1396  ,\n",
       "            0.1361  , 0.1252  , 0.12085 , 0.11536 , 0.1045  , 0.1032  ,\n",
       "            0.103   , 0.09875 , 0.0848  , 0.0836  , 0.07666 , 0.07263 ,\n",
       "            0.07227 , 0.0721  , 0.0717  , 0.0631  , 0.0628  , 0.05582 ,\n",
       "            0.05136 , 0.03308 , 0.03302 , 0.03284 , 0.03038 , 0.0287  ,\n",
       "            0.02753 , 0.0184  , 0.01823 , 0.01704 , 0.01659 , 0.01238 ,\n",
       "            0.011734, 0.0116  , 0.01061 , 0.00986 , 0.007786, 0.007607],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5083333, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.09166667, 0.09166667,\n",
       "            0.1       , 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25      , 0.25      , 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.49166667, 0.49166667, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.05384615, 0.06153846, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23846154, 0.24615385, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.30769232, 0.32307693, 0.33846155, 0.34615386,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.4846154 ,\n",
       "            0.4923077 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.6615385 , 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.7307692 , 0.7307692 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.86923075, 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9907  , 0.988   , 0.985   , 0.9844  , 0.984   ,\n",
       "            0.982   , 0.9814  , 0.98    , 0.9795  , 0.979   , 0.978   ,\n",
       "            0.977   , 0.9766  , 0.976   , 0.9756  , 0.9746  , 0.973   ,\n",
       "            0.972   , 0.97    , 0.9697  , 0.9688  , 0.968   , 0.9673  ,\n",
       "            0.963   , 0.9624  , 0.9614  , 0.96    , 0.9595  , 0.959   ,\n",
       "            0.958   , 0.956   , 0.9556  , 0.955   , 0.954   , 0.9536  ,\n",
       "            0.953   , 0.951   , 0.9507  , 0.9497  , 0.9487  , 0.9478  ,\n",
       "            0.9453  , 0.9434  , 0.9414  , 0.9404  , 0.9365  , 0.936   ,\n",
       "            0.9272  , 0.9194  , 0.9185  , 0.913   , 0.909   , 0.9077  ,\n",
       "            0.904   , 0.9014  , 0.8955  , 0.8926  , 0.8867  , 0.8853  ,\n",
       "            0.8687  , 0.8657  , 0.855   , 0.852   , 0.8486  , 0.843   ,\n",
       "            0.837   , 0.8335  , 0.826   , 0.8257  , 0.8223  , 0.822   ,\n",
       "            0.821   , 0.82    , 0.816   , 0.814   , 0.8135  , 0.8096  ,\n",
       "            0.806   , 0.8047  , 0.8037  , 0.803   , 0.8027  , 0.802   ,\n",
       "            0.8013  , 0.7974  , 0.7954  , 0.7935  , 0.793   , 0.792   ,\n",
       "            0.7886  , 0.788   , 0.787   , 0.7856  , 0.781   , 0.7803  ,\n",
       "            0.7783  , 0.7744  , 0.7705  , 0.7666  , 0.7656  , 0.765   ,\n",
       "            0.7646  , 0.763   , 0.7627  , 0.761   , 0.76    , 0.7593  ,\n",
       "            0.7583  , 0.756   , 0.755   , 0.7534  , 0.7515  , 0.75    ,\n",
       "            0.7476  , 0.744   , 0.7393  , 0.737   , 0.734   , 0.732   ,\n",
       "            0.7295  , 0.729   , 0.7275  , 0.725   , 0.718   , 0.7134  ,\n",
       "            0.712   , 0.7104  , 0.709   , 0.7007  , 0.6963  , 0.695   ,\n",
       "            0.6924  , 0.69    , 0.678   , 0.6743  , 0.672   , 0.671   ,\n",
       "            0.665   , 0.6523  , 0.631   , 0.6304  , 0.6255  , 0.6157  ,\n",
       "            0.613   , 0.609   , 0.605   , 0.601   , 0.591   , 0.5874  ,\n",
       "            0.5825  , 0.5776  , 0.569   , 0.5645  , 0.562   , 0.556   ,\n",
       "            0.551   , 0.5337  , 0.5327  , 0.53    , 0.5215  , 0.5186  ,\n",
       "            0.518   , 0.5093  , 0.502   , 0.5015  , 0.4368  , 0.4348  ,\n",
       "            0.433   , 0.4302  , 0.4185  , 0.3708  , 0.3633  , 0.351   ,\n",
       "            0.3303  , 0.3027  , 0.2898  , 0.2725  , 0.2556  , 0.2522  ,\n",
       "            0.2418  , 0.223   , 0.2177  , 0.2125  , 0.2074  , 0.1791  ,\n",
       "            0.1703  , 0.1674  , 0.1588  , 0.1556  , 0.1401  , 0.1317  ,\n",
       "            0.12067 , 0.118   , 0.11316 , 0.1009  , 0.0991  , 0.09845 ,\n",
       "            0.0945  , 0.0805  , 0.07935 , 0.0724  , 0.0689  , 0.0688  ,\n",
       "            0.06805 , 0.06793 , 0.06064 , 0.05988 , 0.05234 , 0.04794 ,\n",
       "            0.03108 , 0.0305  , 0.03044 , 0.02855 , 0.02692 , 0.02556 ,\n",
       "            0.01672 , 0.01659 , 0.01549 , 0.015366, 0.01107 , 0.01065 ,\n",
       "            0.01057 , 0.00956 , 0.009056, 0.006958, 0.00677 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5083333, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.09166667, 0.09166667,\n",
       "            0.1       , 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.15833333, 0.175     , 0.18333334,\n",
       "            0.2       , 0.2       , 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.23333333, 0.25      , 0.25      , 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.49166667, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.05384615,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.6615385 , 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.72307694, 0.72307694,\n",
       "            0.7307692 , 0.7307692 , 0.7307692 , 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9927  , 0.99    , 0.9873  , 0.987   , 0.985   ,\n",
       "            0.9844  , 0.9834  , 0.983   , 0.9824  , 0.9814  , 0.981   ,\n",
       "            0.9805  , 0.98    , 0.9795  , 0.979   , 0.9775  , 0.9766  ,\n",
       "            0.9746  , 0.974   , 0.9736  , 0.9727  , 0.972   , 0.9688  ,\n",
       "            0.968   , 0.967   , 0.966   , 0.9653  , 0.965   , 0.964   ,\n",
       "            0.962   , 0.9614  , 0.9604  , 0.96    , 0.9595  , 0.958   ,\n",
       "            0.9575  , 0.9565  , 0.9556  , 0.9546  , 0.952   , 0.951   ,\n",
       "            0.9487  , 0.9478  , 0.945   , 0.9443  , 0.936   , 0.929   ,\n",
       "            0.9287  , 0.9277  , 0.923   , 0.9194  , 0.9175  , 0.914   ,\n",
       "            0.9116  , 0.9067  , 0.904   , 0.9033  , 0.898   , 0.8965  ,\n",
       "            0.8813  , 0.8784  , 0.8677  , 0.865   , 0.862   , 0.856   ,\n",
       "            0.8506  , 0.847   , 0.841   , 0.84    , 0.8384  , 0.8354  ,\n",
       "            0.835   , 0.8345  , 0.832   , 0.8286  , 0.8276  , 0.8237  ,\n",
       "            0.8213  , 0.8193  , 0.819   , 0.818   , 0.8174  , 0.817   ,\n",
       "            0.816   , 0.812   , 0.8096  , 0.8086  , 0.807   , 0.8047  ,\n",
       "            0.803   , 0.802   , 0.7954  , 0.795   , 0.793   , 0.7896  ,\n",
       "            0.7856  , 0.783   , 0.7817  , 0.7803  , 0.78    , 0.7793  ,\n",
       "            0.7783  , 0.775   , 0.7744  , 0.771   , 0.7705  , 0.77    ,\n",
       "            0.768   , 0.7676  , 0.7646  , 0.763   , 0.759   , 0.7563  ,\n",
       "            0.7534  , 0.7495  , 0.747   , 0.7466  , 0.7456  , 0.745   ,\n",
       "            0.742   , 0.7334  , 0.73    , 0.7285  , 0.7275  , 0.726   ,\n",
       "            0.719   , 0.7114  , 0.709   , 0.7085  , 0.706   , 0.6934  ,\n",
       "            0.689   , 0.6875  , 0.6865  , 0.6807  , 0.672   , 0.652   ,\n",
       "            0.648   , 0.645   , 0.643   , 0.638   , 0.634   , 0.629   ,\n",
       "            0.627   , 0.616   , 0.6094  , 0.609   , 0.5996  , 0.599   ,\n",
       "            0.5913  , 0.5796  , 0.576   , 0.5747  , 0.57    , 0.557   ,\n",
       "            0.5547  , 0.5444  , 0.5425  , 0.5405  , 0.5396  , 0.538   ,\n",
       "            0.525   , 0.523   , 0.519   , 0.4531  , 0.4434  , 0.44    ,\n",
       "            0.437   , 0.4229  , 0.3752  , 0.3677  , 0.3616  , 0.3335  ,\n",
       "            0.313   , 0.2915  , 0.274   , 0.2717  , 0.2517  , 0.2421  ,\n",
       "            0.2274  , 0.2211  , 0.2161  , 0.2118  , 0.1765  , 0.1672  ,\n",
       "            0.1663  , 0.1567  , 0.154   , 0.1426  , 0.1292  , 0.11755 ,\n",
       "            0.1166  , 0.1124  , 0.09845 , 0.09656 , 0.09515 , 0.09174 ,\n",
       "            0.0774  , 0.076   , 0.0694  , 0.0667  , 0.066   , 0.06525 ,\n",
       "            0.0649  , 0.0591  , 0.05792 , 0.04977 , 0.04535 , 0.02965 ,\n",
       "            0.02876 , 0.02834 , 0.02718 , 0.02562 , 0.02414 , 0.0156  ,\n",
       "            0.01519 , 0.01473 , 0.014114, 0.010056, 0.009895, 0.009674,\n",
       "            0.00871 , 0.00848 , 0.006313, 0.006123], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5083333, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.21666667, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.25      , 0.25      , 0.25      , 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.05384615,\n",
       "            0.06923077, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.13076924, 0.13846155, 0.15384616, 0.16153847,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.33076924, 0.33846155, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.6615385 , 0.6615385 , 0.6615385 , 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7153846 , 0.72307694, 0.72307694, 0.7307692 ,\n",
       "            0.7307692 , 0.73846155, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.994   , 0.992   , 0.9897  , 0.9893  , 0.988   ,\n",
       "            0.9873  , 0.9863  , 0.986   , 0.9854  , 0.9844  , 0.984   ,\n",
       "            0.9834  , 0.983   , 0.9824  , 0.981   , 0.9785  , 0.978   ,\n",
       "            0.9775  , 0.977   , 0.9766  , 0.9736  , 0.9727  , 0.972   ,\n",
       "            0.9717  , 0.9707  , 0.97    , 0.9688  , 0.968   , 0.9673  ,\n",
       "            0.967   , 0.9663  , 0.966   , 0.9653  , 0.965   , 0.9634  ,\n",
       "            0.962   , 0.9614  , 0.9604  , 0.9585  , 0.9575  , 0.955   ,\n",
       "            0.954   , 0.9526  , 0.9517  , 0.9434  , 0.9375  , 0.9365  ,\n",
       "            0.936   , 0.931   , 0.929   , 0.9263  , 0.924   , 0.9204  ,\n",
       "            0.917   , 0.9136  , 0.909   , 0.9062  , 0.8945  , 0.889   ,\n",
       "            0.8794  , 0.877   , 0.8745  , 0.8677  , 0.8633  , 0.863   ,\n",
       "            0.8613  , 0.8564  , 0.8545  , 0.854   , 0.851   , 0.8496  ,\n",
       "            0.849   , 0.8486  , 0.848   , 0.843   , 0.841   , 0.8374  ,\n",
       "            0.8354  , 0.8335  , 0.833   , 0.832   , 0.8315  , 0.831   ,\n",
       "            0.8257  , 0.8247  , 0.8237  , 0.8228  , 0.822   , 0.817   ,\n",
       "            0.811   , 0.808   , 0.8066  , 0.805   , 0.8037  , 0.801   ,\n",
       "            0.8     , 0.798   , 0.797   , 0.7964  , 0.795   , 0.7925  ,\n",
       "            0.792   , 0.7896  , 0.7866  , 0.786   , 0.7847  , 0.779   ,\n",
       "            0.7773  , 0.775   , 0.7715  , 0.7676  , 0.7656  , 0.763   ,\n",
       "            0.7627  , 0.762   , 0.761   , 0.7583  , 0.7515  , 0.751   ,\n",
       "            0.745   , 0.7437  , 0.743   , 0.7397  , 0.7275  , 0.7266  ,\n",
       "            0.7236  , 0.7227  , 0.709   , 0.705   , 0.7046  , 0.7036  ,\n",
       "            0.6978  , 0.694   , 0.676   , 0.6733  , 0.666   , 0.6636  ,\n",
       "            0.658   , 0.656   , 0.6533  , 0.646   , 0.634   , 0.63    ,\n",
       "            0.6226  , 0.618   , 0.617   , 0.6     , 0.5957  , 0.5923  ,\n",
       "            0.5874  , 0.5835  , 0.579   , 0.5703  , 0.564   , 0.557   ,\n",
       "            0.555   , 0.5527  , 0.551   , 0.547   , 0.5293  , 0.4753  ,\n",
       "            0.4514  , 0.447   , 0.444   , 0.43    , 0.381   , 0.3752  ,\n",
       "            0.3728  , 0.3376  , 0.3271  , 0.2947  , 0.2942  , 0.2761  ,\n",
       "            0.2532  , 0.2434  , 0.2346  , 0.2338  , 0.2189  , 0.2173  ,\n",
       "            0.1764  , 0.1671  , 0.167   , 0.1562  , 0.1538  , 0.1475  ,\n",
       "            0.128   , 0.11694 , 0.11633 , 0.1138  , 0.0979  , 0.0955  ,\n",
       "            0.0935  , 0.0903  , 0.07574 , 0.07434 , 0.0677  , 0.066   ,\n",
       "            0.0644  , 0.06384 , 0.06323 , 0.0589  , 0.0572  , 0.0483  ,\n",
       "            0.04385 , 0.02908 , 0.02791 , 0.02711 , 0.02661 , 0.02513 ,\n",
       "            0.02342 , 0.015076, 0.01445 , 0.01439 , 0.01333 , 0.00956 ,\n",
       "            0.00945 , 0.00916 , 0.008286, 0.008255, 0.00596 , 0.005753],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.51666665, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.10833333,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.15833333, 0.15833333, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.26666668,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.35      , 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03846154, 0.05384615,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.13846155, 0.15384616, 0.16153847, 0.16153847, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.32307693, 0.33846155, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.4923077 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.6230769 , 0.6230769 , 0.6230769 , 0.63076925,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.6615385 , 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7       , 0.7       , 0.72307694, 0.7307692 , 0.7307692 ,\n",
       "            0.73846155, 0.73846155, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9956  , 0.9937  , 0.9917  , 0.991   , 0.99    ,\n",
       "            0.9897  , 0.989   , 0.9883  , 0.9873  , 0.987   , 0.9863  ,\n",
       "            0.9854  , 0.985   , 0.9844  , 0.9824  , 0.982   , 0.9814  ,\n",
       "            0.9805  , 0.978   , 0.9775  , 0.977   , 0.9766  , 0.9756  ,\n",
       "            0.975   , 0.974   , 0.973   , 0.9727  , 0.972   , 0.971   ,\n",
       "            0.9707  , 0.9697  , 0.969   , 0.9683  , 0.968   , 0.9653  ,\n",
       "            0.964   , 0.962   , 0.961   , 0.9595  , 0.9585  , 0.952   ,\n",
       "            0.946   , 0.9434  , 0.938   , 0.936   , 0.933   , 0.9316  ,\n",
       "            0.9277  , 0.927   , 0.9243  , 0.92    , 0.914   , 0.903   ,\n",
       "            0.8955  , 0.8945  , 0.892   , 0.8843  , 0.8833  , 0.8813  ,\n",
       "            0.88    , 0.8765  , 0.876   , 0.8755  , 0.8726  , 0.8706  ,\n",
       "            0.8696  , 0.8633  , 0.863   , 0.86    , 0.859   , 0.857   ,\n",
       "            0.8564  , 0.856   , 0.855   , 0.8545  , 0.854   , 0.851   ,\n",
       "            0.8506  , 0.85    , 0.849   , 0.8477  , 0.8423  , 0.841   ,\n",
       "            0.837   , 0.8315  , 0.83    , 0.8296  , 0.829   , 0.828   ,\n",
       "            0.826   , 0.8257  , 0.824   , 0.8237  , 0.8223  , 0.8213  ,\n",
       "            0.821   , 0.8193  , 0.8174  , 0.8164  , 0.8125  , 0.8076  ,\n",
       "            0.805   , 0.803   , 0.8027  , 0.8022  , 0.801   , 0.7964  ,\n",
       "            0.796   , 0.792   , 0.791   , 0.79    , 0.786   , 0.7856  ,\n",
       "            0.78    , 0.7744  , 0.7725  , 0.7705  , 0.757   , 0.7563  ,\n",
       "            0.7534  , 0.7417  , 0.7373  , 0.7344  , 0.734   , 0.7334  ,\n",
       "            0.7305  , 0.727   , 0.716   , 0.7153  , 0.712   , 0.7007  ,\n",
       "            0.698   , 0.686   , 0.679   , 0.6787  , 0.6763  , 0.6655  ,\n",
       "            0.663   , 0.6616  , 0.657   , 0.651   , 0.6353  , 0.6323  ,\n",
       "            0.6304  , 0.63    , 0.621   , 0.617   , 0.607   , 0.606   ,\n",
       "            0.6     , 0.592   , 0.589   , 0.5737  , 0.57    , 0.5464  ,\n",
       "            0.515   , 0.465   , 0.463   , 0.4597  , 0.4412  , 0.4014  ,\n",
       "            0.3923  , 0.3855  , 0.3538  , 0.3484  , 0.334   , 0.303   ,\n",
       "            0.2856  , 0.2588  , 0.2573  , 0.2502  , 0.2494  , 0.2338  ,\n",
       "            0.22    , 0.1782  , 0.1715  , 0.1681  , 0.1592  , 0.1575  ,\n",
       "            0.1571  , 0.13    , 0.1198  , 0.118   , 0.1172  , 0.0991  ,\n",
       "            0.0964  , 0.0935  , 0.0906  , 0.0752  , 0.0734  , 0.06696 ,\n",
       "            0.0662  , 0.0641  , 0.0635  , 0.06223 , 0.05975 , 0.0576  ,\n",
       "            0.0477  , 0.04288 , 0.02893 , 0.02727 , 0.02646 , 0.02591 ,\n",
       "            0.02493 , 0.02298 , 0.01462 , 0.01439 , 0.01359 , 0.01267 ,\n",
       "            0.0093  , 0.00888 , 0.00871 , 0.008095, 0.00784 , 0.00562 ,\n",
       "            0.005386], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.51666665, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.14166667, 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.375     , 0.375     , 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03846154, 0.05384615,\n",
       "            0.08461539, 0.09230769, 0.10769231, 0.12307692, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.2769231 , 0.2923077 ,\n",
       "            0.31538463, 0.33846155, 0.34615386, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.52307695, 0.52307695, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5769231 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.6230769 , 0.6230769 , 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.65384614, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.66923076, 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.72307694, 0.72307694, 0.72307694, 0.72307694,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.77692306, 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.86923075, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9966  , 0.995   , 0.993   , 0.9927  , 0.9917  ,\n",
       "            0.9907  , 0.99    , 0.9893  , 0.989   , 0.9883  , 0.988   ,\n",
       "            0.987   , 0.9863  , 0.9854  , 0.985   , 0.9844  , 0.984   ,\n",
       "            0.9834  , 0.981   , 0.9805  , 0.98    , 0.979   , 0.9785  ,\n",
       "            0.978   , 0.9766  , 0.976   , 0.975   , 0.9746  , 0.974   ,\n",
       "            0.9736  , 0.973   , 0.9727  , 0.972   , 0.9697  , 0.968   ,\n",
       "            0.9663  , 0.966   , 0.9634  , 0.9624  , 0.958   , 0.9526  ,\n",
       "            0.952   , 0.951   , 0.9507  , 0.9434  , 0.943   , 0.939   ,\n",
       "            0.938   , 0.9365  , 0.933   , 0.9307  , 0.929   , 0.9277  ,\n",
       "            0.9116  , 0.908   , 0.906   , 0.9004  , 0.8984  , 0.898   ,\n",
       "            0.896   , 0.895   , 0.8945  , 0.894   , 0.8896  , 0.888   ,\n",
       "            0.884   , 0.883   , 0.882   , 0.8774  , 0.875   , 0.874   ,\n",
       "            0.872   , 0.871   , 0.869   , 0.868   , 0.867   , 0.8647  ,\n",
       "            0.864   , 0.8633  , 0.863   , 0.858   , 0.856   , 0.855   ,\n",
       "            0.8506  , 0.85    , 0.8477  , 0.847   , 0.8447  , 0.8438  ,\n",
       "            0.8433  , 0.843   , 0.8423  , 0.8413  , 0.8403  , 0.84    ,\n",
       "            0.8384  , 0.837   , 0.8345  , 0.8315  , 0.8276  , 0.8228  ,\n",
       "            0.8223  , 0.822   , 0.8193  , 0.819   , 0.8174  , 0.815   ,\n",
       "            0.8135  , 0.812   , 0.8105  , 0.8096  , 0.805   , 0.802   ,\n",
       "            0.7964  , 0.796   , 0.7944  , 0.7886  , 0.78    , 0.7783  ,\n",
       "            0.776   , 0.758   , 0.7573  , 0.757   , 0.7563  , 0.7544  ,\n",
       "            0.7524  , 0.75    , 0.7476  , 0.747   , 0.7456  , 0.735   ,\n",
       "            0.724   , 0.711   , 0.709   , 0.703   , 0.6963  , 0.6943  ,\n",
       "            0.693   , 0.6924  , 0.676   , 0.6753  , 0.666   , 0.662   ,\n",
       "            0.6606  , 0.66    , 0.6543  , 0.654   , 0.641   , 0.6367  ,\n",
       "            0.623   , 0.6187  , 0.6157  , 0.5835  , 0.58    , 0.5557  ,\n",
       "            0.548   , 0.4712  , 0.471   , 0.4673  , 0.4436  , 0.4229  ,\n",
       "            0.395   , 0.3914  , 0.3772  , 0.3723  , 0.3525  , 0.3057  ,\n",
       "            0.2898  , 0.2795  , 0.2622  , 0.2585  , 0.253   , 0.2466  ,\n",
       "            0.2173  , 0.1761  , 0.1743  , 0.1669  , 0.1649  , 0.16    ,\n",
       "            0.1581  , 0.13    , 0.1222  , 0.11615 , 0.0995  , 0.0964  ,\n",
       "            0.09174 , 0.0898  , 0.0733  , 0.0709  , 0.06635 , 0.065   ,\n",
       "            0.0629  , 0.06256 , 0.06097 , 0.0602  , 0.05792 , 0.04654 ,\n",
       "            0.04138 , 0.02898 , 0.02661 , 0.02646 , 0.025   , 0.02438 ,\n",
       "            0.02263 , 0.01462 , 0.01423 , 0.01277 , 0.01201 , 0.00919 ,\n",
       "            0.00835 , 0.008286, 0.008095, 0.00746 , 0.005344, 0.005062],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.51666665, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.08333334, 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.1       , 0.10833333, 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03846154, 0.05384615,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.10769231, 0.11538462,\n",
       "            0.13846155, 0.15384616, 0.16153847, 0.17692308, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.24615385, 0.2769231 , 0.2923077 , 0.30769232, 0.33076924,\n",
       "            0.33846155, 0.36923078, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5692308 , 0.5692308 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.6230769 , 0.6230769 , 0.63076925,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.66923076, 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.7692308 , 0.7692308 ,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86923075, 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.88461536, 0.88461536, 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.997   , 0.996   , 0.9946  , 0.994   , 0.9937  ,\n",
       "            0.993   , 0.9927  , 0.992   , 0.9917  , 0.991   , 0.9907  ,\n",
       "            0.99    , 0.9893  , 0.988   , 0.9873  , 0.987   , 0.9863  ,\n",
       "            0.9844  , 0.984   , 0.9834  , 0.9824  , 0.982   , 0.981   ,\n",
       "            0.9805  , 0.98    , 0.979   , 0.9785  , 0.978   , 0.9775  ,\n",
       "            0.977   , 0.975   , 0.973   , 0.9717  , 0.971   , 0.9697  ,\n",
       "            0.9688  , 0.9644  , 0.96    , 0.9595  , 0.959   , 0.9585  ,\n",
       "            0.952   , 0.951   , 0.949   , 0.948   , 0.9473  , 0.947   ,\n",
       "            0.943   , 0.941   , 0.9404  , 0.9395  , 0.9233  , 0.9224  ,\n",
       "            0.919   , 0.916   , 0.915   , 0.9126  , 0.912   , 0.9106  ,\n",
       "            0.908   , 0.906   , 0.9053  , 0.901   , 0.9004  , 0.9     ,\n",
       "            0.899   , 0.8984  , 0.8965  , 0.894   , 0.893   , 0.892   ,\n",
       "            0.8906  , 0.8887  , 0.888   , 0.886   , 0.8853  , 0.884   ,\n",
       "            0.8813  , 0.88    , 0.8794  , 0.877   , 0.875   , 0.874   ,\n",
       "            0.8726  , 0.8706  , 0.87    , 0.8687  , 0.8647  , 0.864   ,\n",
       "            0.8633  , 0.863   , 0.862   , 0.8613  , 0.861   , 0.859   ,\n",
       "            0.8564  , 0.853   , 0.8516  , 0.846   , 0.8438  , 0.8413  ,\n",
       "            0.841   , 0.8394  , 0.8384  , 0.837   , 0.8364  , 0.8354  ,\n",
       "            0.8325  , 0.828   , 0.8257  , 0.8228  , 0.82    , 0.8184  ,\n",
       "            0.8105  , 0.805   , 0.8027  , 0.8013  , 0.7876  , 0.784   ,\n",
       "            0.7827  , 0.782   , 0.7817  , 0.7793  , 0.7783  , 0.7754  ,\n",
       "            0.7734  , 0.771   , 0.7534  , 0.7446  , 0.74    , 0.734   ,\n",
       "            0.732   , 0.729   , 0.723   , 0.7153  , 0.706   , 0.7046  ,\n",
       "            0.7007  , 0.695   , 0.694   , 0.6934  , 0.693   , 0.6904  ,\n",
       "            0.678   , 0.6777  , 0.66    , 0.6504  , 0.6387  , 0.606   ,\n",
       "            0.6025  , 0.5854  , 0.5776  , 0.492   , 0.4912  , 0.4878  ,\n",
       "            0.4644  , 0.451   , 0.4155  , 0.4136  , 0.4094  , 0.4065  ,\n",
       "            0.3691  , 0.3203  , 0.3071  , 0.3037  , 0.2805  , 0.2708  ,\n",
       "            0.2651  , 0.2646  , 0.2286  , 0.1842  , 0.1824  , 0.1804  ,\n",
       "            0.1727  , 0.1671  , 0.1652  , 0.1355  , 0.1295  , 0.1283  ,\n",
       "            0.1207  , 0.1036  , 0.10016 , 0.09503 , 0.0932  , 0.07574 ,\n",
       "            0.0733  , 0.0688  , 0.0671  , 0.06476 , 0.06464 , 0.06396 ,\n",
       "            0.0619  , 0.0603  , 0.0478  , 0.04224 , 0.02992 , 0.02727 ,\n",
       "            0.02711 , 0.0258  , 0.0248  , 0.0231  , 0.01519 , 0.01445 ,\n",
       "            0.012825, 0.012054, 0.009415, 0.00835 , 0.008316, 0.00749 ,\n",
       "            0.005344, 0.00504 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5416667, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.19166666, 0.2       ,\n",
       "            0.2       , 0.21666667, 0.225     , 0.23333333, 0.23333333,\n",
       "            0.25      , 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.3       , 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.375     , 0.375     , 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.05384615,\n",
       "            0.06153846, 0.08461539, 0.1       , 0.10769231, 0.12307692,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.2       ,\n",
       "            0.21538462, 0.22307692, 0.23846154, 0.24615385, 0.26153848,\n",
       "            0.2846154 , 0.2923077 , 0.30769232, 0.33076924, 0.33846155,\n",
       "            0.35384616, 0.3846154 , 0.3923077 , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.56153846, 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.6076923 , 0.61538464, 0.61538464,\n",
       "            0.61538464, 0.63076925, 0.63076925, 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.66923076, 0.66923076,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.7307692 ,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.998   , 0.997   , 0.996   , 0.9956  , 0.995   ,\n",
       "            0.9946  , 0.994   , 0.9937  , 0.993   , 0.9927  , 0.992   ,\n",
       "            0.9917  , 0.991   , 0.99    , 0.9893  , 0.988   , 0.987   ,\n",
       "            0.9863  , 0.986   , 0.9854  , 0.985   , 0.9844  , 0.984   ,\n",
       "            0.9834  , 0.983   , 0.9824  , 0.982   , 0.9814  , 0.9795  ,\n",
       "            0.978   , 0.976   , 0.9756  , 0.975   , 0.974   , 0.97    ,\n",
       "            0.9663  , 0.966   , 0.9653  , 0.965   , 0.9595  , 0.9585  ,\n",
       "            0.956   , 0.9556  , 0.955   , 0.9526  , 0.951   , 0.9487  ,\n",
       "            0.948   , 0.9355  , 0.9336  , 0.9316  , 0.931   , 0.9307  ,\n",
       "            0.929   , 0.9287  , 0.928   , 0.9243  , 0.921   , 0.9204  ,\n",
       "            0.92    , 0.9185  , 0.9175  , 0.914   , 0.913   , 0.912   ,\n",
       "            0.911   , 0.9106  , 0.9067  , 0.9062  , 0.906   , 0.9043  ,\n",
       "            0.904   , 0.9014  , 0.901   , 0.8975  , 0.895   , 0.8945  ,\n",
       "            0.894   , 0.8936  , 0.8926  , 0.8906  , 0.8896  , 0.889   ,\n",
       "            0.8857  , 0.8853  , 0.8843  , 0.8833  , 0.883   , 0.8813  ,\n",
       "            0.8804  , 0.8765  , 0.875   , 0.8735  , 0.873   , 0.868   ,\n",
       "            0.8677  , 0.866   , 0.8647  , 0.863   , 0.8623  , 0.8604  ,\n",
       "            0.859   , 0.8584  , 0.8574  , 0.857   , 0.854   , 0.8496  ,\n",
       "            0.848   , 0.8467  , 0.8433  , 0.8413  , 0.832   , 0.829   ,\n",
       "            0.826   , 0.825   , 0.82    , 0.816   , 0.8154  , 0.8105  ,\n",
       "            0.8076  , 0.8066  , 0.806   , 0.8057  , 0.803   , 0.8003  ,\n",
       "            0.794   , 0.7817  , 0.7803  , 0.7715  , 0.768   , 0.764   ,\n",
       "            0.76    , 0.755   , 0.746   , 0.738   , 0.7363  , 0.7354  ,\n",
       "            0.729   , 0.7275  , 0.719   , 0.718   , 0.7     , 0.685   ,\n",
       "            0.6626  , 0.63    , 0.6265  , 0.626   , 0.6016  , 0.5146  ,\n",
       "            0.5137  , 0.5103  , 0.4854  , 0.4832  , 0.4656  , 0.4404  ,\n",
       "            0.433   , 0.429   , 0.387   , 0.34    , 0.3357  , 0.3188  ,\n",
       "            0.3025  , 0.2869  , 0.2837  , 0.278   , 0.2397  , 0.1965  ,\n",
       "            0.1924  , 0.1919  , 0.1803  , 0.1748  , 0.1727  , 0.1411  ,\n",
       "            0.1383  , 0.1355  , 0.1255  , 0.1082  , 0.1045  , 0.09827 ,\n",
       "            0.09656 , 0.07794 , 0.0753  , 0.0716  , 0.0689  , 0.06757 ,\n",
       "            0.0667  , 0.06335 , 0.0629  , 0.04895 , 0.04297 , 0.03091 ,\n",
       "            0.02817 , 0.02759 , 0.02661 , 0.02493 , 0.0236  , 0.01578 ,\n",
       "            0.01467 , 0.012726, 0.01196 , 0.0096  , 0.008575, 0.008286,\n",
       "            0.00822 , 0.00743 , 0.005302, 0.004963], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.55833334, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.225     , 0.23333333, 0.25      , 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.275     , 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.3       , 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.43333334, 0.44166666,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.05384615, 0.06923077,\n",
       "            0.08461539, 0.1       , 0.11538462, 0.14615385, 0.16153847,\n",
       "            0.17692308, 0.1923077 , 0.2       , 0.21538462, 0.22307692,\n",
       "            0.23846154, 0.24615385, 0.26153848, 0.2923077 , 0.30769232,\n",
       "            0.33076924, 0.34615386, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.4923077 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.5538462 , 0.56153846,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.64615387, 0.64615387, 0.64615387, 0.64615387,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 , 0.7076923 ,\n",
       "            0.7153846 , 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9985  , 0.9976  , 0.9966  , 0.996   , 0.9956  ,\n",
       "            0.995   , 0.9946  , 0.994   , 0.9937  , 0.993   , 0.992   ,\n",
       "            0.9917  , 0.991   , 0.9897  , 0.9893  , 0.989   , 0.9883  ,\n",
       "            0.988   , 0.9873  , 0.987   , 0.9863  , 0.986   , 0.9854  ,\n",
       "            0.985   , 0.9844  , 0.9834  , 0.9814  , 0.98    , 0.9795  ,\n",
       "            0.979   , 0.978   , 0.9746  , 0.972   , 0.9707  , 0.97    ,\n",
       "            0.9683  , 0.9653  , 0.9644  , 0.964   , 0.963   , 0.9624  ,\n",
       "            0.9614  , 0.958   , 0.9565  , 0.956   , 0.948   , 0.946   ,\n",
       "            0.9453  , 0.9434  , 0.943   , 0.942   , 0.9375  , 0.9355  ,\n",
       "            0.9346  , 0.934   , 0.933   , 0.931   , 0.9297  , 0.929   ,\n",
       "            0.9287  , 0.9277  , 0.9272  , 0.927   , 0.9233  , 0.9224  ,\n",
       "            0.922   , 0.9204  , 0.918   , 0.9175  , 0.9165  , 0.914   ,\n",
       "            0.912   , 0.911   , 0.9097  , 0.908   , 0.9077  , 0.9062  ,\n",
       "            0.905   , 0.9023  , 0.902   , 0.9     , 0.8984  , 0.8975  ,\n",
       "            0.895   , 0.8945  , 0.8936  , 0.8926  , 0.889   , 0.887   ,\n",
       "            0.885   , 0.8833  , 0.883   , 0.8823  , 0.88    , 0.878   ,\n",
       "            0.8765  , 0.876   , 0.8745  , 0.8706  , 0.8696  , 0.8647  ,\n",
       "            0.863   , 0.854   , 0.853   , 0.852   , 0.8486  , 0.848   ,\n",
       "            0.8467  , 0.842   , 0.841   , 0.8403  , 0.831   , 0.83    ,\n",
       "            0.8296  , 0.827   , 0.824   , 0.814   , 0.813   , 0.8086  ,\n",
       "            0.807   , 0.798   , 0.795   , 0.787   , 0.785   , 0.7847  ,\n",
       "            0.776   , 0.765   , 0.7637  , 0.763   , 0.761   , 0.7603  ,\n",
       "            0.757   , 0.755   , 0.7407  , 0.721   , 0.686   , 0.671   ,\n",
       "            0.6543  , 0.6514  , 0.6255  , 0.5396  , 0.5376  , 0.5347  ,\n",
       "            0.5254  , 0.519   , 0.507   , 0.4797  , 0.454   , 0.4514  ,\n",
       "            0.4075  , 0.3806  , 0.3535  , 0.3376  , 0.3281  , 0.313   ,\n",
       "            0.2986  , 0.2937  , 0.2507  , 0.2167  , 0.2037  , 0.2017  ,\n",
       "            0.1885  , 0.185   , 0.183   , 0.1497  , 0.1492  , 0.1449  ,\n",
       "            0.132   , 0.1142  , 0.1101  , 0.10284 , 0.10156 , 0.08124 ,\n",
       "            0.07806 , 0.07556 , 0.07263 , 0.0716  , 0.0698  , 0.0695  ,\n",
       "            0.0667  , 0.0656  , 0.0509  , 0.04443 , 0.03265 , 0.02971 ,\n",
       "            0.02855 , 0.0281  , 0.02538 , 0.02457 , 0.01692 , 0.01519 ,\n",
       "            0.01287 , 0.012146, 0.010056, 0.00909 , 0.008415, 0.008286,\n",
       "            0.007576, 0.005386, 0.005   ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.56666666, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.15833333, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.275     , 0.275     , 0.275     , 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03846154, 0.06923077,\n",
       "            0.09230769, 0.10769231, 0.13846155, 0.16153847, 0.17692308,\n",
       "            0.1923077 , 0.2       , 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.24615385, 0.26153848, 0.30769232, 0.33846155, 0.34615386,\n",
       "            0.37692308, 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.6230769 , 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.6615385 , 0.6769231 , 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7153846 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.88461536, 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.999   , 0.998   , 0.9976  , 0.997   , 0.9966  ,\n",
       "            0.996   , 0.9956  , 0.995   , 0.9946  , 0.994   , 0.9937  ,\n",
       "            0.993   , 0.992   , 0.9917  , 0.991   , 0.9907  , 0.99    ,\n",
       "            0.9897  , 0.9893  , 0.989   , 0.9883  , 0.988   , 0.987   ,\n",
       "            0.9854  , 0.984   , 0.9834  , 0.983   , 0.9824  , 0.9795  ,\n",
       "            0.978   , 0.977   , 0.976   , 0.9756  , 0.9717  , 0.9707  ,\n",
       "            0.9688  , 0.9683  , 0.9653  , 0.9644  , 0.9634  , 0.9595  ,\n",
       "            0.958   , 0.957   , 0.956   , 0.955   , 0.9526  , 0.952   ,\n",
       "            0.949   , 0.9487  , 0.948   , 0.947   , 0.9443  , 0.944   ,\n",
       "            0.9424  , 0.942   , 0.9414  , 0.941   , 0.9385  , 0.9375  ,\n",
       "            0.936   , 0.9355  , 0.9336  , 0.932   , 0.931   , 0.929   ,\n",
       "            0.9287  , 0.928   , 0.9277  , 0.927   , 0.9253  , 0.9243  ,\n",
       "            0.924   , 0.923   , 0.9204  , 0.92    , 0.9194  , 0.9175  ,\n",
       "            0.9155  , 0.914   , 0.9126  , 0.912   , 0.911   , 0.908   ,\n",
       "            0.9067  , 0.9043  , 0.904   , 0.9033  , 0.903   , 0.8994  ,\n",
       "            0.8984  , 0.898   , 0.897   , 0.895   , 0.8945  , 0.894   ,\n",
       "            0.8916  , 0.891   , 0.89    , 0.886   , 0.8843  , 0.883   ,\n",
       "            0.8755  , 0.8745  , 0.871   , 0.8706  , 0.869   , 0.866   ,\n",
       "            0.855   , 0.854   , 0.853   , 0.851   , 0.848   , 0.846   ,\n",
       "            0.841   , 0.836   , 0.834   , 0.8306  , 0.8228  , 0.8223  ,\n",
       "            0.815   , 0.8145  , 0.814   , 0.7993  , 0.799   , 0.7964  ,\n",
       "            0.794   , 0.793   , 0.7915  , 0.786   , 0.7856  , 0.7783  ,\n",
       "            0.756   , 0.7134  , 0.7124  , 0.681   , 0.6797  , 0.653   ,\n",
       "            0.582   , 0.5684  , 0.5645  , 0.5625  , 0.556   , 0.533   ,\n",
       "            0.52    , 0.4792  , 0.4766  , 0.431   , 0.4216  , 0.3743  ,\n",
       "            0.358   , 0.3557  , 0.3408  , 0.3162  , 0.311   , 0.2656  ,\n",
       "            0.2378  , 0.2162  , 0.2129  , 0.1993  , 0.1958  , 0.1936  ,\n",
       "            0.1609  , 0.1572  , 0.1542  , 0.1389  , 0.1201  , 0.1158  ,\n",
       "            0.1076  , 0.1063  , 0.08466 , 0.08124 , 0.0792  , 0.0772  ,\n",
       "            0.07434 , 0.07275 , 0.0724  , 0.07007 , 0.06793 , 0.0526  ,\n",
       "            0.0457  , 0.0339  , 0.03079 , 0.0292  , 0.02914 , 0.02571 ,\n",
       "            0.02518 , 0.01764 , 0.01543 , 0.01287 , 0.012146, 0.01025 ,\n",
       "            0.00934 , 0.008415, 0.00822 , 0.00755 , 0.005344, 0.004944],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.56666666, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.125     , 0.13333334, 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15833333, 0.15833333,\n",
       "            0.16666667, 0.175     , 0.175     , 0.175     , 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.225     , 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25      , 0.26666668, 0.26666668,\n",
       "            0.26666668, 0.28333333, 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.3       , 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.7       , 0.7083333 , 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.05384615, 0.08461539,\n",
       "            0.10769231, 0.14615385, 0.16153847, 0.1923077 , 0.2       ,\n",
       "            0.21538462, 0.23846154, 0.24615385, 0.2769231 , 0.31538463,\n",
       "            0.33846155, 0.36923078, 0.4       , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.66923076, 0.66923076, 0.6769231 ,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 , 0.7076923 ,\n",
       "            0.7076923 , 0.72307694, 0.7307692 , 0.73846155, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.88461536, 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.999   , 0.9985  , 0.998   , 0.9976  , 0.997   ,\n",
       "            0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  , 0.9937  ,\n",
       "            0.993   , 0.9927  , 0.992   , 0.9917  , 0.991   , 0.9907  ,\n",
       "            0.9897  , 0.988   , 0.987   , 0.9863  , 0.986   , 0.985   ,\n",
       "            0.9834  , 0.983   , 0.982   , 0.9805  , 0.9795  , 0.979   ,\n",
       "            0.9785  , 0.976   , 0.9756  , 0.974   , 0.9736  , 0.9717  ,\n",
       "            0.97    , 0.9697  , 0.969   , 0.9688  , 0.9683  , 0.9673  ,\n",
       "            0.967   , 0.966   , 0.963   , 0.961   , 0.9604  , 0.9595  ,\n",
       "            0.9575  , 0.957   , 0.956   , 0.955   , 0.9546  , 0.954   ,\n",
       "            0.9526  , 0.952   , 0.9517  , 0.951   , 0.95    , 0.9497  ,\n",
       "            0.948   , 0.947   , 0.946   , 0.945   , 0.9443  , 0.944   ,\n",
       "            0.9434  , 0.943   , 0.942   , 0.9414  , 0.941   , 0.94    ,\n",
       "            0.9395  , 0.9375  , 0.9365  , 0.936   , 0.9346  , 0.932   ,\n",
       "            0.9307  , 0.929   , 0.928   , 0.9272  , 0.926   , 0.9233  ,\n",
       "            0.923   , 0.922   , 0.919   , 0.9175  , 0.916   , 0.9146  ,\n",
       "            0.9136  , 0.9126  , 0.9116  , 0.9106  , 0.91    , 0.9097  ,\n",
       "            0.907   , 0.9053  , 0.9023  , 0.899   , 0.898   , 0.897   ,\n",
       "            0.895   , 0.894   , 0.8936  , 0.8896  , 0.8794  , 0.8784  ,\n",
       "            0.877   , 0.8755  , 0.8726  , 0.8623  , 0.862   , 0.857   ,\n",
       "            0.851   , 0.8506  , 0.8496  , 0.8433  , 0.8423  , 0.8374  ,\n",
       "            0.8335  , 0.8296  , 0.8276  , 0.8257  , 0.8247  , 0.8228  ,\n",
       "            0.815   , 0.8086  , 0.7905  , 0.7563  , 0.7344  , 0.7046  ,\n",
       "            0.704   , 0.676   , 0.644   , 0.5967  , 0.5947  , 0.587   ,\n",
       "            0.586   , 0.564   , 0.55    , 0.4993  , 0.497   , 0.4695  ,\n",
       "            0.4512  , 0.3901  , 0.387   , 0.3782  , 0.3726  , 0.3289  ,\n",
       "            0.3271  , 0.2727  , 0.2622  , 0.2292  , 0.2191  , 0.2056  ,\n",
       "            0.2037  , 0.1746  , 0.1647  , 0.1444  , 0.126   , 0.12103 ,\n",
       "            0.11084 , 0.11066 , 0.0865  , 0.0831  , 0.083   , 0.0821  ,\n",
       "            0.07574 , 0.0753  , 0.0745  , 0.074   , 0.0688  , 0.0539  ,\n",
       "            0.0462  , 0.0356  , 0.0323  , 0.03062 , 0.02982 , 0.02591 ,\n",
       "            0.02513 , 0.0188  , 0.01578 , 0.01257 , 0.012054, 0.01061 ,\n",
       "            0.00986 , 0.008415, 0.008095, 0.00752 , 0.00532 , 0.004868],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5833333, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.075     , 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.125     , 0.125     ,\n",
       "            0.14166667, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.175     , 0.175     , 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25      , 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.05384615, 0.08461539,\n",
       "            0.13076924, 0.16153847, 0.1923077 , 0.2       , 0.21538462,\n",
       "            0.22307692, 0.24615385, 0.2846154 , 0.33846155, 0.36923078,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.56153846, 0.5692308 ,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.6076923 , 0.61538464, 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.65384614, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6769231 , 0.6769231 ,\n",
       "            0.6846154 , 0.7       , 0.7076923 , 0.72307694, 0.7307692 ,\n",
       "            0.7307692 , 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.9       , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  ,\n",
       "            0.994   , 0.9937  , 0.993   , 0.9927  , 0.992   , 0.9917  ,\n",
       "            0.9897  , 0.9893  , 0.989   , 0.9883  , 0.988   , 0.9873  ,\n",
       "            0.987   , 0.9854  , 0.985   , 0.984   , 0.9834  , 0.983   ,\n",
       "            0.98    , 0.9795  , 0.9785  , 0.978   , 0.977   , 0.9766  ,\n",
       "            0.976   , 0.9756  , 0.975   , 0.974   , 0.9707  , 0.97    ,\n",
       "            0.9697  , 0.969   , 0.9688  , 0.968   , 0.967   , 0.9663  ,\n",
       "            0.9644  , 0.964   , 0.963   , 0.962   , 0.961   , 0.9604  ,\n",
       "            0.9595  , 0.9585  , 0.957   , 0.9565  , 0.956   , 0.955   ,\n",
       "            0.9546  , 0.953   , 0.9526  , 0.952   , 0.951   , 0.95    ,\n",
       "            0.9497  , 0.949   , 0.9478  , 0.945   , 0.944   , 0.943   ,\n",
       "            0.942   , 0.9404  , 0.9385  , 0.938   , 0.9375  , 0.937   ,\n",
       "            0.936   , 0.9346  , 0.933   , 0.93    , 0.929   , 0.9277  ,\n",
       "            0.9272  , 0.925   , 0.924   , 0.9224  , 0.922   , 0.92    ,\n",
       "            0.915   , 0.9146  , 0.914   , 0.912   , 0.9116  , 0.9087  ,\n",
       "            0.9     , 0.899   , 0.898   , 0.897   , 0.8965  , 0.895   ,\n",
       "            0.893   , 0.886   , 0.8843  , 0.8784  , 0.8726  , 0.8667  ,\n",
       "            0.865   , 0.861   , 0.856   , 0.8555  , 0.8516  , 0.8496  ,\n",
       "            0.847   , 0.844   , 0.8384  , 0.828   , 0.8193  , 0.792   ,\n",
       "            0.7554  , 0.727   , 0.7266  , 0.6978  , 0.696   , 0.6323  ,\n",
       "            0.6187  , 0.6104  , 0.608   , 0.603   , 0.57    , 0.521   ,\n",
       "            0.5166  , 0.5127  , 0.4712  , 0.4163  , 0.4065  , 0.4026  ,\n",
       "            0.3972  , 0.3428  , 0.3425  , 0.285   , 0.283   , 0.2415  ,\n",
       "            0.2273  , 0.2148  , 0.2129  , 0.2109  , 0.187   , 0.1743  ,\n",
       "            0.1715  , 0.1497  , 0.1313  , 0.126   , 0.1144  , 0.11395 ,\n",
       "            0.0887  , 0.0879  , 0.0863  , 0.08386 , 0.07764 , 0.0774  ,\n",
       "            0.0772  , 0.0764  , 0.0702  , 0.055   , 0.0468  , 0.03677 ,\n",
       "            0.03333 , 0.03162 , 0.03021 , 0.02641 , 0.02509 , 0.01953 ,\n",
       "            0.0159  , 0.01243 , 0.01196 , 0.01082 , 0.01013 , 0.008316,\n",
       "            0.007965, 0.00746 , 0.00526 , 0.00479 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59166664, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.1       , 0.10833333, 0.125     ,\n",
       "            0.125     , 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.15833333, 0.16666667, 0.16666667, 0.175     ,\n",
       "            0.175     , 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.24166666, 0.24166666, 0.24166666, 0.25      ,\n",
       "            0.25      , 0.25      , 0.25      , 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.26666668, 0.26666668, 0.275     , 0.275     ,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01538462, 0.05384615, 0.1       , 0.15384616,\n",
       "            0.1923077 , 0.21538462, 0.26923078, 0.3       , 0.35384616,\n",
       "            0.3846154 , 0.4076923 , 0.41538462, 0.42307693, 0.43846154,\n",
       "            0.44615385, 0.46153846, 0.46923077, 0.4846154 , 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.52307695, 0.53846157,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5846154 , 0.5846154 ,\n",
       "            0.6       , 0.6076923 , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.6230769 , 0.63076925, 0.63076925,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.7       , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8153846 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.996   , 0.9956  , 0.995   , 0.9946  , 0.994   ,\n",
       "            0.9937  , 0.992   , 0.9917  , 0.991   , 0.9907  , 0.9897  ,\n",
       "            0.9893  , 0.9883  , 0.9873  , 0.987   , 0.9844  , 0.984   ,\n",
       "            0.983   , 0.9824  , 0.9814  , 0.9805  , 0.9795  , 0.979   ,\n",
       "            0.9785  , 0.978   , 0.9775  , 0.9766  , 0.9756  , 0.974   ,\n",
       "            0.9736  , 0.973   , 0.9727  , 0.9717  , 0.971   , 0.9707  ,\n",
       "            0.97    , 0.969   , 0.9688  , 0.968   , 0.967   , 0.9663  ,\n",
       "            0.966   , 0.965   , 0.9644  , 0.964   , 0.963   , 0.962   ,\n",
       "            0.9614  , 0.9604  , 0.96    , 0.959   , 0.9585  , 0.958   ,\n",
       "            0.957   , 0.9565  , 0.956   , 0.9556  , 0.954   , 0.9526  ,\n",
       "            0.952   , 0.951   , 0.949   , 0.9487  , 0.9478  , 0.947   ,\n",
       "            0.946   , 0.945   , 0.944   , 0.9434  , 0.943   , 0.941   ,\n",
       "            0.94    , 0.939   , 0.9385  , 0.9375  , 0.935   , 0.9346  ,\n",
       "            0.933   , 0.932   , 0.93    , 0.9272  , 0.9204  , 0.9185  ,\n",
       "            0.918   , 0.9165  , 0.916   , 0.913   , 0.908   , 0.9077  ,\n",
       "            0.905   , 0.903   , 0.8945  , 0.8926  , 0.889   , 0.8877  ,\n",
       "            0.887   , 0.886   , 0.882   , 0.8804  , 0.876   , 0.874   ,\n",
       "            0.8716  , 0.871   , 0.867   , 0.853   , 0.847   , 0.8237  ,\n",
       "            0.784   , 0.759   , 0.757   , 0.7373  , 0.7285  , 0.668   ,\n",
       "            0.654   , 0.6436  , 0.6396  , 0.5996  , 0.5537  , 0.551   ,\n",
       "            0.546   , 0.5015  , 0.444   , 0.432   , 0.4304  , 0.424   ,\n",
       "            0.3652  , 0.3643  , 0.3044  , 0.3     , 0.2556  , 0.2407  ,\n",
       "            0.2269  , 0.2247  , 0.2233  , 0.1978  , 0.1835  , 0.1804  ,\n",
       "            0.1575  , 0.1366  , 0.1312  , 0.1194  , 0.1192  , 0.09204 ,\n",
       "            0.09125 , 0.089   , 0.0869  , 0.0799  , 0.07947 , 0.0789  ,\n",
       "            0.07227 , 0.05634 , 0.0477  , 0.037   , 0.03348 , 0.03168 ,\n",
       "            0.03021 , 0.02635 , 0.02509 , 0.01942 , 0.01567 , 0.01219 ,\n",
       "            0.011734, 0.01057 , 0.009895, 0.008095, 0.007725, 0.007233,\n",
       "            0.00504 , 0.004593], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59166664, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.08333334, 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.125     , 0.125     , 0.125     , 0.13333334,\n",
       "            0.15      , 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.175     , 0.175     , 0.18333334, 0.2       , 0.20833333,\n",
       "            0.20833333, 0.21666667, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.30833334, 0.325     , 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.01538462, 0.08461539, 0.15384616, 0.1923077 ,\n",
       "            0.21538462, 0.23846154, 0.2923077 , 0.35384616, 0.3846154 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.44615385,\n",
       "            0.46153846, 0.46923077, 0.4846154 , 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.50769234, 0.52307695, 0.53846157,\n",
       "            0.5538462 , 0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.6230769 , 0.6230769 ,\n",
       "            0.63846153, 0.6615385 , 0.6615385 , 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.7       , 0.7       , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.86923075, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  ,\n",
       "            0.9937  , 0.993   , 0.9927  , 0.992   , 0.9917  , 0.991   ,\n",
       "            0.99    , 0.9893  , 0.989   , 0.9873  , 0.987   , 0.9863  ,\n",
       "            0.986   , 0.9854  , 0.983   , 0.9824  , 0.982   , 0.9814  ,\n",
       "            0.9805  , 0.98    , 0.979   , 0.9785  , 0.978   , 0.977   ,\n",
       "            0.9766  , 0.976   , 0.9756  , 0.974   , 0.9736  , 0.973   ,\n",
       "            0.9727  , 0.972   , 0.9717  , 0.971   , 0.9707  , 0.97    ,\n",
       "            0.9697  , 0.9688  , 0.9683  , 0.968   , 0.967   , 0.966   ,\n",
       "            0.9644  , 0.964   , 0.9634  , 0.9624  , 0.961   , 0.96    ,\n",
       "            0.9595  , 0.9585  , 0.9565  , 0.9556  , 0.955   , 0.9546  ,\n",
       "            0.954   , 0.9526  , 0.952   , 0.9507  , 0.9487  , 0.948   ,\n",
       "            0.9478  , 0.9473  , 0.945   , 0.944   , 0.942   , 0.94    ,\n",
       "            0.9395  , 0.9365  , 0.932   , 0.9307  , 0.9287  , 0.928   ,\n",
       "            0.9277  , 0.927   , 0.924   , 0.9214  , 0.921   , 0.917   ,\n",
       "            0.916   , 0.908   , 0.9062  , 0.9023  , 0.9014  , 0.9004  ,\n",
       "            0.9     , 0.8975  , 0.895   , 0.891   , 0.888   , 0.885   ,\n",
       "            0.8843  , 0.869   , 0.865   , 0.8457  , 0.805   , 0.7817  ,\n",
       "            0.7793  , 0.77    , 0.753   , 0.696   , 0.6816  , 0.6714  ,\n",
       "            0.67    , 0.667   , 0.6284  , 0.585   , 0.5825  , 0.575   ,\n",
       "            0.53    , 0.4717  , 0.4592  , 0.4583  , 0.451   , 0.39    ,\n",
       "            0.3894  , 0.328   , 0.324   , 0.274   , 0.2605  , 0.2441  ,\n",
       "            0.2422  , 0.2418  , 0.2137  , 0.1981  , 0.1947  , 0.1707  ,\n",
       "            0.1471  , 0.1415  , 0.1294  , 0.1293  , 0.1     , 0.0991  ,\n",
       "            0.096   , 0.09467 , 0.0869  , 0.0865  , 0.086   , 0.0856  ,\n",
       "            0.0786  , 0.06097 , 0.05176 , 0.04    , 0.03616 , 0.0343  ,\n",
       "            0.0326  , 0.02838 , 0.02733 , 0.02112 , 0.01692 , 0.01317 ,\n",
       "            0.01263 , 0.01142 , 0.010735, 0.00871 , 0.008316, 0.007786,\n",
       "            0.005447, 0.004963], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.1641791 , 0.1716418 , 0.18656716, 0.20895523, 0.21641791,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3880597 , 0.40298507, 0.40298507,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.69402987, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7089552 , 0.7089552 , 0.7164179 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.76865673, 0.76865673, 0.7761194 , 0.7835821 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.85820895, 0.86567163, 0.86567163, 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9328358 , 0.9402985 , 0.9402985 ,\n",
       "            0.9477612 , 0.9477612 , 0.95522386, 0.95522386, 0.95522386,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.97761196, 0.97761196,\n",
       "            0.98507464, 0.98507464, 0.9925373 , 0.9925373 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.04310345,\n",
       "            0.04310345, 0.06034483, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.09482758, 0.10344828,\n",
       "            0.10344828, 0.10344828, 0.11206897, 0.12931034, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.19827586, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.31896552,\n",
       "            0.31896552, 0.3275862 , 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5258621 , 0.5258621 , 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.5689655 , 0.57758623, 0.57758623,\n",
       "            0.57758623, 0.57758623, 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.6810345 , 0.6810345 , 0.6810345 , 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4675, 0.4668, 0.4666, 0.4663, 0.4648, 0.4639, 0.4634,\n",
       "            0.4622, 0.462 , 0.4614, 0.4602, 0.4587, 0.4585, 0.4575, 0.457 ,\n",
       "            0.4565, 0.4563, 0.456 , 0.4558, 0.4556, 0.455 , 0.4548, 0.4546,\n",
       "            0.4524, 0.4512, 0.45  , 0.4492, 0.4485, 0.448 , 0.4473, 0.447 ,\n",
       "            0.446 , 0.4412, 0.4377, 0.4375, 0.4363, 0.435 , 0.4336, 0.433 ,\n",
       "            0.4324, 0.4297, 0.429 , 0.425 , 0.423 , 0.4224, 0.4158, 0.4133,\n",
       "            0.4104, 0.4087, 0.4084, 0.408 , 0.4072, 0.4016, 0.4011, 0.401 ,\n",
       "            0.398 , 0.3977, 0.3958, 0.391 , 0.39  , 0.3884, 0.386 , 0.3848,\n",
       "            0.384 , 0.3835, 0.3826, 0.3816, 0.378 , 0.3767, 0.3762, 0.3755,\n",
       "            0.374 , 0.3738, 0.3735, 0.371 , 0.3704, 0.3645, 0.364 , 0.3633,\n",
       "            0.3604, 0.3596, 0.3594, 0.357 , 0.3562, 0.3555, 0.3545, 0.3528,\n",
       "            0.3506, 0.3477, 0.3462, 0.3447, 0.3433, 0.3423, 0.341 , 0.3406,\n",
       "            0.3376, 0.3364, 0.3362, 0.3352, 0.3345, 0.3333, 0.3315, 0.3289,\n",
       "            0.3274, 0.3257, 0.3218, 0.32  , 0.3174, 0.316 , 0.3118, 0.3103,\n",
       "            0.3062, 0.3052, 0.3044, 0.3008, 0.3   , 0.2954, 0.2942, 0.294 ,\n",
       "            0.2927, 0.2915, 0.2908, 0.2896, 0.2842, 0.2805, 0.2786, 0.2761,\n",
       "            0.2754, 0.2676, 0.267 , 0.2668, 0.2664, 0.2656, 0.2646, 0.2632,\n",
       "            0.263 , 0.2612, 0.259 , 0.2588, 0.2585, 0.2542, 0.2537, 0.252 ,\n",
       "            0.2502, 0.2463, 0.2462, 0.2458, 0.2456, 0.2455, 0.2452, 0.2434,\n",
       "            0.2426, 0.2422, 0.2418, 0.2413, 0.2405, 0.2402, 0.2379, 0.2378,\n",
       "            0.2366, 0.2356, 0.2346, 0.234 , 0.2322, 0.2314, 0.2313, 0.2307,\n",
       "            0.2297, 0.2294, 0.2286, 0.2264, 0.2263, 0.2256, 0.2255, 0.2249,\n",
       "            0.2246, 0.2238, 0.2229, 0.2217, 0.2205, 0.219 , 0.2186, 0.218 ,\n",
       "            0.2177, 0.2152, 0.2148, 0.214 , 0.2128, 0.2109, 0.2094, 0.2081,\n",
       "            0.2076, 0.2074, 0.2045, 0.2031, 0.2024, 0.2013, 0.1996, 0.1974,\n",
       "            0.1946, 0.1906, 0.1884, 0.1865, 0.1859, 0.1799, 0.1785, 0.1782,\n",
       "            0.1774, 0.1761, 0.1738, 0.1725, 0.171 , 0.1709, 0.1683, 0.1669,\n",
       "            0.1633, 0.1586, 0.1583, 0.155 , 0.1467], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.14179105, 0.14925373, 0.1641791 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.40298507, 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6567164 , 0.6641791 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.70149255, 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73134327, 0.73880595, 0.73880595, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.76865673, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.7910448 , 0.7910448 , 0.79850745, 0.79850745,\n",
       "            0.79850745, 0.80597013, 0.80597013, 0.8208955 , 0.82835823,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.86567163, 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.880597  , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9328358 , 0.9402985 , 0.9402985 , 0.9402985 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.95522386, 0.95522386, 0.96268654,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.97761196, 0.97761196, 0.97761196, 0.98507464, 0.98507464,\n",
       "            0.98507464, 0.9925373 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06034483, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.27586207, 0.27586207, 0.27586207,\n",
       "            0.27586207, 0.28448275, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.62068963, 0.62068963, 0.62068963, 0.62068963,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4473 , 0.446  , 0.4456 , 0.4436 , 0.4426 , 0.4424 ,\n",
       "            0.4417 , 0.4412 , 0.4397 , 0.438  , 0.4373 , 0.437  , 0.4358 ,\n",
       "            0.4355 , 0.4353 , 0.4338 , 0.4333 , 0.433  , 0.4329 , 0.4326 ,\n",
       "            0.4316 , 0.4312 , 0.4307 , 0.4304 , 0.429  , 0.4275 , 0.4268 ,\n",
       "            0.4265 , 0.4258 , 0.4248 , 0.422  , 0.4214 , 0.4211 , 0.418  ,\n",
       "            0.4126 , 0.4119 , 0.4111 , 0.4082 , 0.4062 , 0.4055 , 0.405  ,\n",
       "            0.4045 , 0.4028 , 0.3982 , 0.3977 , 0.395  , 0.3901 , 0.3843 ,\n",
       "            0.3796 , 0.3794 , 0.3792 , 0.3784 , 0.3782 , 0.373  , 0.3704 ,\n",
       "            0.37   , 0.3638 , 0.3618 , 0.3616 , 0.361  , 0.3562 , 0.3533 ,\n",
       "            0.352  , 0.3503 , 0.3489 , 0.3474 , 0.3464 , 0.3457 , 0.3452 ,\n",
       "            0.3442 , 0.3376 , 0.335  , 0.3347 , 0.3342 , 0.3325 , 0.332  ,\n",
       "            0.3318 , 0.3308 , 0.3303 , 0.3293 , 0.3289 , 0.3203 , 0.3188 ,\n",
       "            0.3167 , 0.3157 , 0.3147 , 0.313  , 0.3088 , 0.3086 , 0.308  ,\n",
       "            0.3057 , 0.3054 , 0.3042 , 0.3018 , 0.3015 , 0.3003 , 0.2996 ,\n",
       "            0.299  , 0.2986 , 0.2947 , 0.2917 , 0.2883 , 0.2861 , 0.2856 ,\n",
       "            0.2854 , 0.2847 , 0.2825 , 0.2793 , 0.2786 , 0.278  , 0.2776 ,\n",
       "            0.2766 , 0.2725 , 0.2693 , 0.258  , 0.257  , 0.2554 , 0.2551 ,\n",
       "            0.2544 , 0.2542 , 0.253  , 0.2512 , 0.251  , 0.2507 , 0.2477 ,\n",
       "            0.2449 , 0.2433 , 0.2418 , 0.2375 , 0.2368 , 0.235  , 0.2325 ,\n",
       "            0.2314 , 0.2292 , 0.2286 , 0.2255 , 0.2235 , 0.2198 , 0.2166 ,\n",
       "            0.2163 , 0.2152 , 0.2145 , 0.2139 , 0.2133 , 0.2119 , 0.2104 ,\n",
       "            0.2096 , 0.2089 , 0.2085 , 0.2053 , 0.2007 , 0.2004 , 0.1995 ,\n",
       "            0.1989 , 0.1985 , 0.1976 , 0.1974 , 0.1971 , 0.197  , 0.1956 ,\n",
       "            0.1946 , 0.1941 , 0.1931 , 0.1929 , 0.1924 , 0.1918 , 0.1917 ,\n",
       "            0.1912 , 0.1892 , 0.189  , 0.1873 , 0.1863 , 0.1855 , 0.1842 ,\n",
       "            0.1838 , 0.1835 , 0.1813 , 0.1808 , 0.1804 , 0.1796 , 0.179  ,\n",
       "            0.1772 , 0.1771 , 0.1758 , 0.1754 , 0.1748 , 0.1738 , 0.1737 ,\n",
       "            0.1736 , 0.1726 , 0.1718 , 0.1699 , 0.1685 , 0.1677 , 0.1649 ,\n",
       "            0.1643 , 0.1638 , 0.1636 , 0.1617 , 0.1611 , 0.1608 , 0.1593 ,\n",
       "            0.1566 , 0.1562 , 0.1555 , 0.1537 , 0.1519 , 0.1515 , 0.1488 ,\n",
       "            0.1467 , 0.1425 , 0.1406 , 0.1346 , 0.134  , 0.133  , 0.1324 ,\n",
       "            0.1315 , 0.1257 , 0.1255 , 0.1254 , 0.1249 , 0.1204 , 0.1196 ,\n",
       "            0.1188 , 0.1152 , 0.1136 , 0.1122 , 0.10394], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.17910448, 0.18656716, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.63432837, 0.64179105, 0.64179105, 0.64179105,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73134327,\n",
       "            0.73134327, 0.73880595, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76119405, 0.76865673, 0.7761194 , 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.7910448 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.7910448 , 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.8134328 , 0.8134328 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8880597 , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9328358 , 0.9328358 , 0.9328358 , 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.9477612 , 0.95522386,\n",
       "            0.95522386, 0.96268654, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.97761196, 0.97761196, 0.97761196,\n",
       "            0.98507464, 0.98507464, 0.98507464, 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.05172414, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.14655173, 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.25862068, 0.2672414 , 0.2672414 , 0.27586207,\n",
       "            0.27586207, 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.38793105, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.44827586, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 0.9913793 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4263 , 0.4248 , 0.4243 , 0.424  , 0.423  , 0.421  ,\n",
       "            0.4207 , 0.42   , 0.4177 , 0.4158 , 0.4153 , 0.415  , 0.4136 ,\n",
       "            0.4119 , 0.4111 , 0.411  , 0.4106 , 0.4104 , 0.4102 , 0.409  ,\n",
       "            0.4084 , 0.4067 , 0.4065 , 0.405  , 0.4045 , 0.4036 , 0.402  ,\n",
       "            0.4014 , 0.4011 , 0.397  , 0.3962 , 0.3958 , 0.394  , 0.3877 ,\n",
       "            0.3862 , 0.385  , 0.3838 , 0.3801 , 0.3796 , 0.3784 , 0.3767 ,\n",
       "            0.3765 , 0.3723 , 0.3713 , 0.368  , 0.3643 , 0.3582 , 0.358  ,\n",
       "            0.3513 , 0.35   , 0.3489 , 0.3486 , 0.3435 , 0.3423 , 0.3398 ,\n",
       "            0.339  , 0.3315 , 0.329  , 0.3289 , 0.3245 , 0.3225 , 0.3188 ,\n",
       "            0.3186 , 0.3154 , 0.3123 , 0.3115 , 0.3108 , 0.3105 , 0.3018 ,\n",
       "            0.299  , 0.2988 , 0.2983 , 0.2964 , 0.2944 , 0.2937 , 0.2913 ,\n",
       "            0.2827 , 0.2817 , 0.28   , 0.279  , 0.2766 , 0.2751 , 0.2737 ,\n",
       "            0.2695 , 0.269  , 0.2686 , 0.2683 , 0.2666 , 0.266  , 0.2637 ,\n",
       "            0.2612 , 0.2588 , 0.258  , 0.2573 , 0.2537 , 0.2494 , 0.2456 ,\n",
       "            0.2444 , 0.2429 , 0.2426 , 0.2422 , 0.2421 , 0.2395 , 0.2388 ,\n",
       "            0.2367 , 0.2355 , 0.235  , 0.233  , 0.2274 , 0.2256 , 0.218  ,\n",
       "            0.2177 , 0.2156 , 0.2135 , 0.2129 , 0.2124 , 0.2119 , 0.2115 ,\n",
       "            0.2101 , 0.2095 , 0.2064 , 0.2028 , 0.2017 , 0.2015 , 0.1993 ,\n",
       "            0.1981 , 0.196  , 0.1953 , 0.189  , 0.1887 , 0.1886 , 0.1877 ,\n",
       "            0.1855 , 0.1814 , 0.1797 , 0.1787 , 0.174  , 0.1738 , 0.1737 ,\n",
       "            0.173  , 0.1726 , 0.1711 , 0.1705 , 0.1698 , 0.1696 , 0.1676 ,\n",
       "            0.166  , 0.1641 , 0.1636 , 0.1622 , 0.162  , 0.1616 , 0.1594 ,\n",
       "            0.159  , 0.1583 , 0.1572 , 0.1562 , 0.1558 , 0.1554 , 0.1545 ,\n",
       "            0.1544 , 0.1538 , 0.1532 , 0.1526 , 0.1521 , 0.1505 , 0.15   ,\n",
       "            0.1499 , 0.1492 , 0.1489 , 0.1483 , 0.145  , 0.1447 , 0.1438 ,\n",
       "            0.1436 , 0.1427 , 0.1426 , 0.1421 , 0.1415 , 0.1405 , 0.1398 ,\n",
       "            0.1368 , 0.1367 , 0.1366 , 0.1354 , 0.1349 , 0.1348 , 0.1345 ,\n",
       "            0.1342 , 0.1338 , 0.133  , 0.132  , 0.131  , 0.1305 , 0.1294 ,\n",
       "            0.128  , 0.1277 , 0.1272 , 0.1261 , 0.12366, 0.1232 , 0.12085,\n",
       "            0.12067, 0.1198 , 0.1197 , 0.1186 , 0.11755, 0.115  , 0.1138 ,\n",
       "            0.1124 , 0.1118 , 0.11163, 0.108  , 0.1025 , 0.10034, 0.09845,\n",
       "            0.09705, 0.0964 , 0.0933 , 0.09204, 0.0909 , 0.0887 , 0.0882 ,\n",
       "            0.0877 , 0.08344, 0.0827 , 0.0824 , 0.0802 , 0.07275],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.33582088,\n",
       "            0.35074627, 0.35820895, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.63432837, 0.63432837, 0.64179105, 0.6492537 , 0.6492537 ,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.6865672 , 0.69402987, 0.70149255, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73134327,\n",
       "            0.73134327, 0.74626863, 0.74626863, 0.75373137, 0.75373137,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7835821 , 0.7910448 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.80597013, 0.8134328 , 0.8134328 , 0.8134328 ,\n",
       "            0.8134328 , 0.82835823, 0.82835823, 0.82835823, 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.9328358 , 0.9328358 , 0.9328358 ,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.95522386, 0.95522386, 0.96268654, 0.96268654,\n",
       "            0.96268654, 0.96268654, 0.9701493 , 0.9701493 , 0.97761196,\n",
       "            0.97761196, 0.97761196, 0.97761196, 0.98507464, 0.98507464,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.21551724, 0.22413793,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.27586207, 0.27586207, 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.39655173, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.7241379 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4045 , 0.4026 , 0.402  , 0.4019 , 0.4016 , 0.399  ,\n",
       "            0.3982 , 0.398  , 0.3965 , 0.396  , 0.3943 , 0.3933 , 0.393  ,\n",
       "            0.3918 , 0.3914 , 0.391  , 0.3901 , 0.389  , 0.3884 , 0.3882 ,\n",
       "            0.388  , 0.3872 , 0.387  , 0.3862 , 0.3848 , 0.3826 , 0.3813 ,\n",
       "            0.381  , 0.3806 , 0.3792 , 0.3782 , 0.377  , 0.3748 , 0.3745 ,\n",
       "            0.3743 , 0.3733 , 0.3696 , 0.364  , 0.3628 , 0.362  , 0.3591 ,\n",
       "            0.3582 , 0.356  , 0.3557 , 0.3547 , 0.3523 , 0.3464 , 0.3428 ,\n",
       "            0.3381 , 0.3315 , 0.327  , 0.3245 , 0.3232 , 0.3228 , 0.3225 ,\n",
       "            0.321  , 0.316  , 0.313  , 0.3125 , 0.3096 , 0.307  , 0.306  ,\n",
       "            0.3022 , 0.2964 , 0.2957 , 0.2954 , 0.2903 , 0.29   , 0.2886 ,\n",
       "            0.2883 , 0.2876 , 0.287  , 0.2827 , 0.2751 , 0.2744 , 0.272  ,\n",
       "            0.2695 , 0.2686 , 0.2678 , 0.2664 , 0.2637 , 0.255  , 0.2534 ,\n",
       "            0.251  , 0.2494 , 0.2477 , 0.2466 , 0.2426 , 0.2424 , 0.2411 ,\n",
       "            0.2386 , 0.2384 , 0.2379 , 0.2351 , 0.2323 , 0.2303 , 0.2299 ,\n",
       "            0.2269 , 0.2256 , 0.2218 , 0.2157 , 0.2148 , 0.2147 , 0.2145 ,\n",
       "            0.2137 , 0.2128 , 0.2085 , 0.2075 , 0.2068 , 0.2059 , 0.2054 ,\n",
       "            0.2043 , 0.1989 , 0.1965 , 0.187  , 0.1863 , 0.1844 , 0.1829 ,\n",
       "            0.182  , 0.181  , 0.1803 , 0.1798 , 0.177  , 0.1768 , 0.1763 ,\n",
       "            0.1708 , 0.169  , 0.1688 , 0.1678 , 0.1666 , 0.1631 , 0.163  ,\n",
       "            0.1578 , 0.1566 , 0.1562 , 0.1548 , 0.153  , 0.1503 , 0.1489 ,\n",
       "            0.1461 , 0.1421 , 0.142  , 0.1417 , 0.1416 , 0.1412 , 0.139  ,\n",
       "            0.1385 , 0.1383 , 0.1376 , 0.1359 , 0.1356 , 0.1343 , 0.1342 ,\n",
       "            0.1326 , 0.1322 , 0.1316 , 0.1315 , 0.1292 , 0.1288 , 0.1279 ,\n",
       "            0.1259 , 0.1251 , 0.12476, 0.12445, 0.1241 , 0.1238 , 0.12335,\n",
       "            0.1232 , 0.12286, 0.12115, 0.12054, 0.1196 , 0.1192 , 0.118  ,\n",
       "            0.1178 , 0.11554, 0.11475, 0.1144 , 0.1128 , 0.1124 , 0.112  ,\n",
       "            0.11127, 0.11084, 0.1076 , 0.1069 , 0.1065 , 0.10504, 0.10486,\n",
       "            0.1047 , 0.10376, 0.1034 , 0.1025 , 0.1023 , 0.1011 , 0.1009 ,\n",
       "            0.10034, 0.09827, 0.0979 , 0.09534, 0.09503, 0.0933 , 0.0922 ,\n",
       "            0.09106, 0.0891 , 0.0879 , 0.086  , 0.0857 , 0.0854 , 0.08435,\n",
       "            0.082  , 0.0761 , 0.0752 , 0.0734 , 0.07227, 0.0717 , 0.06793,\n",
       "            0.0677 , 0.06696, 0.0643 , 0.0642 , 0.06396, 0.05997, 0.05988,\n",
       "            0.0589 , 0.0578 , 0.05167], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08955224, 0.09701493, 0.1119403 , 0.11940298,\n",
       "            0.13432837, 0.14179105, 0.15671642, 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.6492537 , 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.73880595, 0.73880595, 0.73880595,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7835821 , 0.7910448 , 0.7910448 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.7910448 , 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8432836 , 0.8432836 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.85820895, 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.880597  , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.92537314, 0.92537314, 0.9328358 , 0.9328358 ,\n",
       "            0.9402985 , 0.9402985 , 0.9477612 , 0.9477612 , 0.9477612 ,\n",
       "            0.95522386, 0.95522386, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.96268654, 0.9701493 , 0.9701493 , 0.97761196, 0.97761196,\n",
       "            0.97761196, 0.98507464, 0.98507464, 0.98507464, 0.9925373 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.04310345, 0.04310345,\n",
       "            0.05172414, 0.05172414, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06034483, 0.06896552, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12068965, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31034482, 0.31034482, 0.31896552,\n",
       "            0.31896552, 0.31896552, 0.3275862 , 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 ,\n",
       "            0.57758623, 0.57758623, 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.62068963, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.8189655 , 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.38   , 0.3784 , 0.3774 , 0.3772 , 0.3765 , 0.3752 ,\n",
       "            0.3745 , 0.3743 , 0.3735 , 0.3726 , 0.37   , 0.3687 , 0.3684 ,\n",
       "            0.3674 , 0.3667 , 0.3662 , 0.3655 , 0.3652 , 0.3643 , 0.3638 ,\n",
       "            0.3633 , 0.363  , 0.3625 , 0.362  , 0.3606 , 0.3586 , 0.3577 ,\n",
       "            0.3552 , 0.3547 , 0.354  , 0.352  , 0.3503 , 0.348  , 0.3457 ,\n",
       "            0.3447 , 0.344  , 0.343  , 0.3428 , 0.3384 , 0.3376 , 0.3315 ,\n",
       "            0.3313 , 0.3276 , 0.3257 , 0.3218 , 0.3193 , 0.3186 , 0.3147 ,\n",
       "            0.3113 , 0.306  , 0.3054 , 0.3047 , 0.3044 , 0.3013 , 0.3008 ,\n",
       "            0.2993 , 0.2988 , 0.2952 , 0.2942 , 0.2903 , 0.289  , 0.2874 ,\n",
       "            0.2844 , 0.283  , 0.2825 , 0.282  , 0.281  , 0.2722 , 0.2717 ,\n",
       "            0.2715 , 0.271  , 0.2695 , 0.2686 , 0.2664 , 0.2646 , 0.264  ,\n",
       "            0.2627 , 0.2612 , 0.2563 , 0.2556 , 0.25   , 0.2493 , 0.248  ,\n",
       "            0.2473 , 0.2451 , 0.2405 , 0.2401 , 0.2395 , 0.2378 , 0.2362 ,\n",
       "            0.236  , 0.2339 , 0.2313 , 0.2268 , 0.2205 , 0.22   , 0.2198 ,\n",
       "            0.2186 , 0.218  , 0.2158 , 0.2152 , 0.2135 , 0.2134 , 0.2114 ,\n",
       "            0.2109 , 0.2101 , 0.2076 , 0.2069 , 0.2063 , 0.2018 , 0.2013 ,\n",
       "            0.1998 , 0.1981 , 0.1947 , 0.193  , 0.1906 , 0.1886 , 0.1827 ,\n",
       "            0.1752 , 0.1736 , 0.1731 , 0.1677 , 0.1665 , 0.1658 , 0.1654 ,\n",
       "            0.1649 , 0.1644 , 0.162  , 0.156  , 0.1548 , 0.1533 , 0.1511 ,\n",
       "            0.1487 , 0.1486 , 0.1432 , 0.143  , 0.1414 , 0.1403 , 0.14   ,\n",
       "            0.1348 , 0.1342 , 0.1316 , 0.1289 , 0.1282 , 0.1273 , 0.127  ,\n",
       "            0.1265 , 0.126  , 0.1259 , 0.1242 , 0.1239 , 0.12286, 0.1217 ,\n",
       "            0.119  , 0.1172 , 0.11694, 0.11633, 0.1158 , 0.11536, 0.1144 ,\n",
       "            0.1142 , 0.11395, 0.1138 , 0.1126 , 0.1122 , 0.1118 , 0.1105 ,\n",
       "            0.1103 , 0.1095 , 0.1093 , 0.1074 , 0.10724, 0.1067 , 0.1054 ,\n",
       "            0.10504, 0.1036 , 0.1021 , 0.10126, 0.1005 , 0.10034, 0.1    ,\n",
       "            0.0991 , 0.0977 , 0.09705, 0.0959 , 0.09503, 0.0945 , 0.09436,\n",
       "            0.0942 , 0.0933 , 0.0932 , 0.09283, 0.0925 , 0.09174, 0.0903 ,\n",
       "            0.0898 , 0.0885 , 0.0873 , 0.0869 , 0.0857 , 0.08435, 0.08374,\n",
       "            0.0818 , 0.08167, 0.0804 , 0.0801 , 0.07935, 0.0789 , 0.0764 ,\n",
       "            0.0761 , 0.07477, 0.07434, 0.0733 , 0.06903, 0.0667 , 0.0642 ,\n",
       "            0.0635 , 0.06232, 0.06177, 0.06064, 0.058  , 0.0576 , 0.05603,\n",
       "            0.0556 , 0.0534 , 0.05203, 0.05145, 0.05032, 0.0495 , 0.0483 ,\n",
       "            0.04337], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.09701493, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.14179105, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.31343284, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3880597 , 0.3880597 , 0.3880597 ,\n",
       "            0.3955224 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.6268657 , 0.63432837, 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6641791 , 0.67164177, 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7089552 , 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.7238806 , 0.73134327, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76119405, 0.76865673, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7835821 , 0.7835821 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.79850745, 0.79850745, 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8134328 , 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8358209 , 0.8358209 , 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.92537314, 0.92537314, 0.9328358 , 0.9328358 , 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.9477612 , 0.95522386, 0.95522386,\n",
       "            0.95522386, 0.96268654, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.97761196, 0.98507464,\n",
       "            0.98507464, 0.98507464, 0.9925373 , 0.9925373 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.05172414, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.0862069 , 0.10344828, 0.10344828, 0.10344828, 0.10344828,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.12068965, 0.12068965,\n",
       "            0.12931034, 0.12931034, 0.13793103, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.20689656, 0.21551724, 0.22413793, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.29310346,\n",
       "            0.29310346, 0.30172414, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6551724 , 0.6551724 , 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3545 , 0.354  , 0.3525 , 0.3523 , 0.352  , 0.3516 ,\n",
       "            0.3513 , 0.351  , 0.35   , 0.3494 , 0.3484 , 0.3481 , 0.348  ,\n",
       "            0.3477 , 0.3474 , 0.347  , 0.3455 , 0.3447 , 0.344  , 0.3433 ,\n",
       "            0.3425 , 0.3416 , 0.3413 , 0.3408 , 0.3396 , 0.3386 , 0.338  ,\n",
       "            0.3376 , 0.3374 , 0.336  , 0.335  , 0.3328 , 0.3296 , 0.3289 ,\n",
       "            0.3281 , 0.328  , 0.3245 , 0.3225 , 0.321  , 0.3196 , 0.3179 ,\n",
       "            0.3176 , 0.313  , 0.3115 , 0.3098 , 0.309  , 0.3074 , 0.306  ,\n",
       "            0.3044 , 0.298  , 0.2966 , 0.2964 , 0.2947 , 0.292  , 0.2915 ,\n",
       "            0.2898 , 0.2893 , 0.2888 , 0.2878 , 0.287  , 0.2869 , 0.2861 ,\n",
       "            0.2847 , 0.2844 , 0.28   , 0.2795 , 0.2788 , 0.2742 , 0.2727 ,\n",
       "            0.2703 , 0.2686 , 0.2683 , 0.268  , 0.2664 , 0.2651 , 0.2605 ,\n",
       "            0.2603 , 0.2595 , 0.2566 , 0.2556 , 0.2507 , 0.2502 , 0.2498 ,\n",
       "            0.249  , 0.2487 , 0.2474 , 0.2433 , 0.2421 , 0.2388 , 0.2382 ,\n",
       "            0.2378 , 0.2358 , 0.2344 , 0.2319 , 0.2285 , 0.228  , 0.2269 ,\n",
       "            0.2263 , 0.2255 , 0.2222 , 0.2213 , 0.2186 , 0.2181 , 0.2177 ,\n",
       "            0.2175 , 0.2158 , 0.215  , 0.2139 , 0.2108 , 0.21   , 0.2075 ,\n",
       "            0.204  , 0.202  , 0.1913 , 0.191  , 0.1897 , 0.188  , 0.187  ,\n",
       "            0.1738 , 0.1735 , 0.1727 , 0.1698 , 0.167  , 0.1644 , 0.1633 ,\n",
       "            0.1624 , 0.1619 , 0.1606 , 0.1593 , 0.153  , 0.1525 , 0.1508 ,\n",
       "            0.1484 , 0.1483 , 0.1461 , 0.1445 , 0.1426 , 0.1396 , 0.1359 ,\n",
       "            0.1346 , 0.1344 , 0.1343 , 0.1326 , 0.1318 , 0.1317 , 0.131  ,\n",
       "            0.128  , 0.1276 , 0.1272 , 0.1241 , 0.12085, 0.12024, 0.1194 ,\n",
       "            0.11816, 0.1174 , 0.1172 , 0.11694, 0.11676, 0.1166 , 0.1158 ,\n",
       "            0.11554, 0.1152 , 0.11456, 0.1134 , 0.11316, 0.1124 , 0.1118 ,\n",
       "            0.1099 , 0.1097 , 0.10876, 0.1084 , 0.1076 , 0.1067 , 0.1065 ,\n",
       "            0.1058 , 0.1054 , 0.1034 , 0.103  , 0.10266, 0.1023 , 0.1021 ,\n",
       "            0.1019 , 0.10156, 0.10144, 0.1009 , 0.0997 , 0.0991 , 0.09894,\n",
       "            0.09845, 0.0977 , 0.0974 , 0.09656, 0.0964 , 0.0959 , 0.09515,\n",
       "            0.0933 , 0.093  , 0.0904 , 0.0896 , 0.0895 , 0.0891 , 0.0882 ,\n",
       "            0.0876 , 0.08405, 0.0833 , 0.0831 , 0.0824 , 0.08124, 0.0804 ,\n",
       "            0.0798 , 0.07825, 0.076  , 0.0724 , 0.07056, 0.0683 , 0.06793,\n",
       "            0.0673 , 0.0667 , 0.0661 , 0.0651 , 0.06198, 0.0619 , 0.0613 ,\n",
       "            0.0577 , 0.0575 , 0.05542, 0.0539 , 0.0532 , 0.05118, 0.0468 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.04477612, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1716418 , 0.17910448, 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.2238806 , 0.23880596,\n",
       "            0.23880596, 0.25373134, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.29850745, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.3283582 , 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6567164 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.70149255,\n",
       "            0.7089552 , 0.7089552 , 0.7089552 , 0.7089552 , 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.75373137, 0.76865673, 0.76865673,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.79850745, 0.79850745, 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.82835823,\n",
       "            0.82835823, 0.82835823, 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.85820895, 0.85820895,\n",
       "            0.85820895, 0.85820895, 0.86567163, 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8880597 , 0.8880597 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9328358 , 0.9328358 , 0.9328358 ,\n",
       "            0.9402985 , 0.9402985 , 0.9477612 , 0.9477612 , 0.95522386,\n",
       "            0.95522386, 0.96268654, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.96268654, 0.9701493 , 0.9701493 , 0.9701493 , 0.97761196,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 0.9925373 , 0.9925373 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.04310345, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.04310345, 0.04310345, 0.04310345,\n",
       "            0.05172414, 0.05172414, 0.05172414, 0.05172414, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.0862069 , 0.09482758, 0.11206897,\n",
       "            0.11206897, 0.12068965, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.13793103, 0.13793103, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.15517241, 0.15517241, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.20689656, 0.21551724, 0.21551724, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.36206895, 0.36206895,\n",
       "            0.36206895, 0.37068966, 0.38793105, 0.39655173, 0.39655173,\n",
       "            0.39655173, 0.4051724 , 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43965518, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.51724136, 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.54310346, 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.57758623, 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.7241379 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.8534483 , 0.8534483 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.92241377, 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3516 , 0.3484 , 0.3457 , 0.3394 , 0.3372 , 0.3337 ,\n",
       "            0.3335 , 0.333  , 0.3315 , 0.3308 , 0.3306 , 0.33   , 0.3296 ,\n",
       "            0.3293 , 0.329  , 0.3289 , 0.3286 , 0.3281 , 0.328  , 0.3271 ,\n",
       "            0.326  , 0.3252 , 0.325  , 0.324  , 0.3237 , 0.3223 , 0.322  ,\n",
       "            0.3218 , 0.321  , 0.3203 , 0.32   , 0.3188 , 0.3186 , 0.317  ,\n",
       "            0.3142 , 0.3127 , 0.3125 , 0.3115 , 0.3105 , 0.31   , 0.3093 ,\n",
       "            0.308  , 0.3052 , 0.305  , 0.3047 , 0.3037 , 0.3013 , 0.2998 ,\n",
       "            0.298  , 0.2944 , 0.2937 , 0.2925 , 0.2915 , 0.2903 , 0.289  ,\n",
       "            0.2888 , 0.2878 , 0.287  , 0.2844 , 0.2837 , 0.2834 , 0.283  ,\n",
       "            0.2817 , 0.2815 , 0.2803 , 0.28   , 0.279  , 0.2786 , 0.2773 ,\n",
       "            0.2766 , 0.2754 , 0.274  , 0.2732 , 0.2727 , 0.2722 , 0.2717 ,\n",
       "            0.27   , 0.2693 , 0.2678 , 0.2664 , 0.2646 , 0.2637 , 0.2605 ,\n",
       "            0.2573 , 0.2542 , 0.2532 , 0.252  , 0.249  , 0.2487 , 0.2482 ,\n",
       "            0.2471 , 0.246  , 0.243  , 0.2426 , 0.2375 , 0.2372 , 0.2368 ,\n",
       "            0.2311 , 0.2306 , 0.2299 , 0.223  , 0.2212 , 0.2198 , 0.2181 ,\n",
       "            0.2173 , 0.214  , 0.2104 , 0.207  , 0.1989 , 0.1946 , 0.1937 ,\n",
       "            0.1906 , 0.1903 , 0.1824 , 0.1815 , 0.1757 , 0.1733 , 0.1719 ,\n",
       "            0.1715 , 0.1665 , 0.1658 , 0.1648 , 0.1643 , 0.1617 , 0.1614 ,\n",
       "            0.16   , 0.1587 , 0.1552 , 0.155  , 0.1505 , 0.1493 , 0.1484 ,\n",
       "            0.1475 , 0.1473 , 0.1466 , 0.1455 , 0.1451 , 0.1448 , 0.1423 ,\n",
       "            0.141  , 0.1409 , 0.1395 , 0.138  , 0.1367 , 0.1355 , 0.134  ,\n",
       "            0.1311 , 0.1309 , 0.1295 , 0.1294 , 0.1292 , 0.1289 , 0.1278 ,\n",
       "            0.1277 , 0.127  , 0.1267 , 0.1265 , 0.126  , 0.1245 , 0.124  ,\n",
       "            0.12366, 0.1232 , 0.12305, 0.1223 , 0.1222 , 0.12213, 0.12115,\n",
       "            0.1198 , 0.1195 , 0.118  , 0.1174 , 0.11694, 0.11676, 0.11633,\n",
       "            0.11597, 0.11554, 0.1136 , 0.1134 , 0.1126 , 0.1122 , 0.112  ,\n",
       "            0.11145, 0.11084, 0.1103 , 0.1097 , 0.1095 , 0.10895, 0.10876,\n",
       "            0.1076 , 0.1067 , 0.10596, 0.1047 , 0.1041 , 0.10376, 0.10284,\n",
       "            0.1025 , 0.1005 , 0.0997 , 0.0986 , 0.0957 , 0.09485, 0.09467,\n",
       "            0.0942 , 0.09125, 0.089  , 0.0885 , 0.0873 , 0.0854 , 0.0848 ,\n",
       "            0.0833 , 0.0789 , 0.0786 , 0.0775 , 0.07684, 0.07434, 0.0741 ,\n",
       "            0.0734 , 0.07263, 0.0721 , 0.07007, 0.0695 , 0.0645 , 0.0635 ,\n",
       "            0.0621 , 0.05988, 0.05603], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.1641791 , 0.1716418 ,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.23880596, 0.23880596,\n",
       "            0.23880596, 0.26119402, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29104477, 0.29104477, 0.29850745,\n",
       "            0.29850745, 0.29850745, 0.30597016, 0.30597016, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6119403 ,\n",
       "            0.6119403 , 0.619403  , 0.619403  , 0.6268657 , 0.6268657 ,\n",
       "            0.6268657 , 0.6268657 , 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 , 0.73134327,\n",
       "            0.73134327, 0.74626863, 0.75373137, 0.75373137, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7761194 , 0.7835821 ,\n",
       "            0.7835821 , 0.7835821 , 0.7910448 , 0.7910448 , 0.79850745,\n",
       "            0.79850745, 0.80597013, 0.80597013, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.8208955 , 0.82835823, 0.8358209 , 0.8358209 ,\n",
       "            0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 , 0.8507463 ,\n",
       "            0.8507463 , 0.8507463 , 0.85820895, 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.880597  , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.91791046, 0.91791046, 0.92537314, 0.9328358 , 0.9328358 ,\n",
       "            0.9328358 , 0.9328358 , 0.9402985 , 0.9477612 , 0.9477612 ,\n",
       "            0.95522386, 0.95522386, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.98507464, 0.9925373 , 0.9925373 ,\n",
       "            0.9925373 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.03448276, 0.04310345, 0.05172414, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.0862069 , 0.09482758, 0.10344828, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.14655173, 0.14655173, 0.14655173,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.15517241, 0.15517241,\n",
       "            0.1637931 , 0.1637931 , 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18103448, 0.18103448, 0.18103448, 0.18965517, 0.18965517,\n",
       "            0.18965517, 0.18965517, 0.18965517, 0.18965517, 0.18965517,\n",
       "            0.18965517, 0.18965517, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.21551724, 0.21551724, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.23275863, 0.25      , 0.25862068, 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.27586207, 0.28448275, 0.28448275,\n",
       "            0.28448275, 0.28448275, 0.29310346, 0.29310346, 0.30172414,\n",
       "            0.30172414, 0.31896552, 0.3275862 , 0.3275862 , 0.33620688,\n",
       "            0.33620688, 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.38793105, 0.38793105, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.41379312, 0.41379312, 0.41379312, 0.41379312,\n",
       "            0.41379312, 0.4224138 , 0.4224138 , 0.4224138 , 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.44827586, 0.44827586, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.46551725, 0.46551725,\n",
       "            0.46551725, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.54310346, 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.6034483 , 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.62068963, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.8189655 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.86206895, 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3606 , 0.3538 , 0.3489 , 0.3481 , 0.345  , 0.3433 ,\n",
       "            0.3394 , 0.3374 , 0.3357 , 0.335  , 0.3335 , 0.3328 , 0.331  ,\n",
       "            0.33   , 0.328  , 0.3262 , 0.325  , 0.3245 , 0.3235 , 0.3232 ,\n",
       "            0.3225 , 0.3218 , 0.3215 , 0.3208 , 0.3196 , 0.3171 , 0.3162 ,\n",
       "            0.315  , 0.3147 , 0.3145 , 0.3142 , 0.3137 , 0.3127 , 0.3123 ,\n",
       "            0.312  , 0.3118 , 0.3113 , 0.3103 , 0.3096 , 0.3093 , 0.3086 ,\n",
       "            0.3079 , 0.3076 , 0.3074 , 0.3064 , 0.3062 , 0.306  , 0.3057 ,\n",
       "            0.3052 , 0.304  , 0.3025 , 0.3022 , 0.3018 , 0.3013 , 0.3003 ,\n",
       "            0.2993 , 0.2986 , 0.2983 , 0.298  , 0.2979 , 0.2976 , 0.297  ,\n",
       "            0.2969 , 0.295  , 0.2944 , 0.293  , 0.2925 , 0.2922 , 0.2908 ,\n",
       "            0.2903 , 0.2886 , 0.2874 , 0.2866 , 0.2856 , 0.2854 , 0.285  ,\n",
       "            0.2832 , 0.2817 , 0.2805 , 0.28   , 0.279  , 0.2786 , 0.277  ,\n",
       "            0.2766 , 0.275  , 0.2747 , 0.2744 , 0.2725 , 0.2722 , 0.2688 ,\n",
       "            0.2683 , 0.2678 , 0.2664 , 0.266  , 0.2642 , 0.264  , 0.2637 ,\n",
       "            0.2625 , 0.2573 , 0.2566 , 0.2466 , 0.244  , 0.2437 , 0.2418 ,\n",
       "            0.241  , 0.2394 , 0.2382 , 0.235  , 0.2335 , 0.2297 , 0.2255 ,\n",
       "            0.222  , 0.2139 , 0.2115 , 0.2103 , 0.2098 , 0.2056 , 0.1987 ,\n",
       "            0.1953 , 0.1892 , 0.1886 , 0.1842 , 0.1841 , 0.1823 , 0.1813 ,\n",
       "            0.1808 , 0.1798 , 0.1748 , 0.1731 , 0.1727 , 0.1716 , 0.1708 ,\n",
       "            0.1707 , 0.1693 , 0.1677 , 0.1666 , 0.1663 , 0.1649 , 0.1622 ,\n",
       "            0.1605 , 0.1594 , 0.159  , 0.1589 , 0.158  , 0.1561 , 0.1549 ,\n",
       "            0.1539 , 0.1534 , 0.1512 , 0.1504 , 0.1493 , 0.1477 , 0.1475 ,\n",
       "            0.1471 , 0.1465 , 0.1458 , 0.1447 , 0.1433 , 0.1428 , 0.1426 ,\n",
       "            0.1416 , 0.1415 , 0.141  , 0.1409 , 0.1403 , 0.1394 , 0.1392 ,\n",
       "            0.1389 , 0.1384 , 0.1377 , 0.1373 , 0.137  , 0.1351 , 0.1349 ,\n",
       "            0.1337 , 0.1334 , 0.1332 , 0.1328 , 0.1326 , 0.131  , 0.13   ,\n",
       "            0.129  , 0.1284 , 0.1278 , 0.127  , 0.1267 , 0.1251 , 0.1249 ,\n",
       "            0.12305, 0.1226 , 0.1225 , 0.12146, 0.12115, 0.1201 , 0.1195 ,\n",
       "            0.1194 , 0.11633, 0.11615, 0.1152 , 0.11456, 0.11395, 0.1124 ,\n",
       "            0.1103 , 0.1097 , 0.1069 , 0.1054 , 0.1045 , 0.1025 , 0.0995 ,\n",
       "            0.09894, 0.0977 , 0.09485, 0.0933 , 0.0925 , 0.09204, 0.09106,\n",
       "            0.0909 , 0.09076, 0.0888 , 0.0883 , 0.088  , 0.0871 , 0.0802 ,\n",
       "            0.07556, 0.07544, 0.0729 , 0.0698 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.13432837, 0.14179105,\n",
       "            0.14179105, 0.15671642, 0.1641791 , 0.17910448, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23880596,\n",
       "            0.23880596, 0.24626866, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2761194 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.6641791 ,\n",
       "            0.6641791 , 0.6641791 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.75373137, 0.76119405, 0.76119405, 0.76119405, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7761194 , 0.7761194 , 0.7835821 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.8731343 , 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.91791046, 0.91791046, 0.9328358 ,\n",
       "            0.9328358 , 0.9328358 , 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 , 0.97761196,\n",
       "            0.97761196, 0.97761196, 0.98507464, 0.98507464, 0.98507464,\n",
       "            0.9925373 , 0.9925373 , 0.9925373 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.25      , 0.25862068, 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.3275862 ,\n",
       "            0.33620688, 0.33620688, 0.33620688, 0.3448276 , 0.3448276 ,\n",
       "            0.3448276 , 0.3448276 , 0.35344827, 0.36206895, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.38793105, 0.38793105,\n",
       "            0.38793105, 0.38793105, 0.38793105, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.41379312, 0.41379312, 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.4224138 , 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43103448, 0.43103448,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.44827586, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.45689654, 0.45689654, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.46551725, 0.46551725,\n",
       "            0.46551725, 0.46551725, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.4827586 , 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.54310346, 0.54310346,\n",
       "            0.54310346, 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.57758623, 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 0.9913793 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3762 , 0.372  , 0.3691 , 0.3687 , 0.3677 , 0.3672 ,\n",
       "            0.3665 , 0.3645 , 0.3638 , 0.3628 , 0.3584 , 0.3572 , 0.357  ,\n",
       "            0.3552 , 0.3542 , 0.3538 , 0.3528 , 0.3516 , 0.3486 , 0.3452 ,\n",
       "            0.3435 , 0.343  , 0.3428 , 0.3386 , 0.3374 , 0.337  , 0.3367 ,\n",
       "            0.3362 , 0.336  , 0.3335 , 0.3323 , 0.3315 , 0.3313 , 0.3298 ,\n",
       "            0.3271 , 0.326  , 0.3247 , 0.3232 , 0.3225 , 0.322  , 0.3215 ,\n",
       "            0.3203 , 0.32   , 0.3196 , 0.3186 , 0.318  , 0.3176 , 0.3167 ,\n",
       "            0.3152 , 0.3147 , 0.314  , 0.3137 , 0.3135 , 0.3115 , 0.3093 ,\n",
       "            0.307  , 0.3054 , 0.3047 , 0.3022 , 0.302  , 0.2993 , 0.299  ,\n",
       "            0.2988 , 0.2983 , 0.2976 , 0.2974 , 0.2961 , 0.296  , 0.2954 ,\n",
       "            0.2952 , 0.295  , 0.2947 , 0.2915 , 0.2908 , 0.2888 , 0.2886 ,\n",
       "            0.2883 , 0.2878 , 0.2874 , 0.2869 , 0.2852 , 0.2847 , 0.284  ,\n",
       "            0.2822 , 0.282  , 0.281  , 0.28   , 0.2786 , 0.278  , 0.2732 ,\n",
       "            0.273  , 0.2715 , 0.2708 , 0.2664 , 0.2659 , 0.2654 , 0.263  ,\n",
       "            0.2627 , 0.2595 , 0.2588 , 0.2576 , 0.2566 , 0.256  , 0.255  ,\n",
       "            0.251  , 0.2483 , 0.2477 , 0.2452 , 0.2445 , 0.2422 , 0.2418 ,\n",
       "            0.2413 , 0.2405 , 0.2397 , 0.2346 , 0.2338 , 0.2292 , 0.2255 ,\n",
       "            0.2173 , 0.2172 , 0.2139 , 0.2134 , 0.2085 , 0.2064 , 0.2017 ,\n",
       "            0.2015 , 0.2012 , 0.1985 , 0.197  , 0.1953 , 0.1942 , 0.194  ,\n",
       "            0.1891 , 0.189  , 0.1873 , 0.1866 , 0.1863 , 0.1816 , 0.1808 ,\n",
       "            0.1799 , 0.1794 , 0.1792 , 0.179  , 0.1785 , 0.1783 , 0.178  ,\n",
       "            0.1766 , 0.1744 , 0.1733 , 0.1725 , 0.171  , 0.1705 , 0.1696 ,\n",
       "            0.1682 , 0.1678 , 0.1665 , 0.1664 , 0.1663 , 0.1647 , 0.1643 ,\n",
       "            0.1635 , 0.1626 , 0.1624 , 0.1614 , 0.1602 , 0.1599 , 0.1598 ,\n",
       "            0.1592 , 0.1567 , 0.1561 , 0.156  , 0.1559 , 0.1558 , 0.1555 ,\n",
       "            0.1545 , 0.1528 , 0.1517 , 0.1515 , 0.1514 , 0.1512 , 0.1499 ,\n",
       "            0.1497 , 0.1462 , 0.1455 , 0.1454 , 0.1448 , 0.144  , 0.1439 ,\n",
       "            0.1422 , 0.1411 , 0.1403 , 0.1394 , 0.1382 , 0.1372 , 0.1368 ,\n",
       "            0.1366 , 0.1365 , 0.1357 , 0.1342 , 0.1338 , 0.1327 , 0.1313 ,\n",
       "            0.1309 , 0.1268 , 0.1265 , 0.1256 , 0.1236 , 0.12213, 0.12115,\n",
       "            0.1144 , 0.1122 , 0.112  , 0.111  , 0.11066, 0.1105 , 0.1103 ,\n",
       "            0.1095 , 0.1069 , 0.1065 , 0.10614, 0.1058 , 0.10376, 0.1034 ,\n",
       "            0.10266, 0.0979 , 0.0899 , 0.0885 , 0.0871 , 0.08527],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.64179105, 0.6567164 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.6641791 , 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.69402987, 0.70149255, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.74626863, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.76865673, 0.76865673, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7835821 , 0.7835821 , 0.7910448 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.80597013, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.8208955 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8432836 , 0.8507463 , 0.8507463 , 0.8507463 , 0.85820895,\n",
       "            0.85820895, 0.85820895, 0.86567163, 0.86567163, 0.86567163,\n",
       "            0.8731343 , 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9402985 , 0.9402985 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.95522386, 0.95522386,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.98507464, 0.98507464,\n",
       "            0.9925373 , 0.9925373 , 0.9925373 , 0.9925373 , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43965518, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.45689654, 0.45689654, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.45689654, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.47413793, 0.47413793,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.47413793, 0.47413793,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.4827586 , 0.4827586 ,\n",
       "            0.4827586 , 0.4827586 , 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.5344828 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5603448 , 0.5603448 ,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7155172 , 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.8534483 , 0.8534483 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4104 , 0.4062 , 0.4043 , 0.4038 , 0.4014 , 0.4004 ,\n",
       "            0.3994 , 0.3972 , 0.397  , 0.3962 , 0.3953 , 0.3933 , 0.3926 ,\n",
       "            0.3909 , 0.3887 , 0.388  , 0.387  , 0.3857 , 0.384  , 0.3828 ,\n",
       "            0.381  , 0.3801 , 0.3782 , 0.374  , 0.3738 , 0.3735 , 0.3726 ,\n",
       "            0.3704 , 0.3699 , 0.3694 , 0.3687 , 0.368  , 0.361  , 0.36   ,\n",
       "            0.3599 , 0.3596 , 0.3591 , 0.357  , 0.353  , 0.3525 , 0.3508 ,\n",
       "            0.3428 , 0.3367 , 0.3362 , 0.3333 , 0.328  , 0.3254 , 0.3245 ,\n",
       "            0.3235 , 0.3218 , 0.321  , 0.3208 , 0.3179 , 0.3176 , 0.3157 ,\n",
       "            0.3142 , 0.314  , 0.3127 , 0.3093 , 0.3083 , 0.308  , 0.307  ,\n",
       "            0.3066 , 0.3057 , 0.3018 , 0.3013 , 0.3008 , 0.2993 , 0.2974 ,\n",
       "            0.2966 , 0.2954 , 0.295  , 0.2927 , 0.2913 , 0.2898 , 0.288  ,\n",
       "            0.2864 , 0.2861 , 0.2856 , 0.2852 , 0.2842 , 0.283  , 0.2815 ,\n",
       "            0.2795 , 0.279  , 0.278  , 0.275  , 0.2747 , 0.2737 , 0.2734 ,\n",
       "            0.2722 , 0.2717 , 0.2708 , 0.2695 , 0.269  , 0.268  , 0.2673 ,\n",
       "            0.2646 , 0.2622 , 0.261  , 0.2605 , 0.257  , 0.2546 , 0.2537 ,\n",
       "            0.252  , 0.2502 , 0.2498 , 0.2478 , 0.2467 , 0.2462 , 0.2451 ,\n",
       "            0.2441 , 0.2406 , 0.2399 , 0.2395 , 0.2386 , 0.2382 , 0.2351 ,\n",
       "            0.2332 , 0.2294 , 0.2278 , 0.2269 , 0.2266 , 0.2247 , 0.2229 ,\n",
       "            0.2224 , 0.222  , 0.219  , 0.2186 , 0.2179 , 0.2152 , 0.21   ,\n",
       "            0.208  , 0.207  , 0.2065 , 0.2048 , 0.2042 , 0.2026 , 0.2018 ,\n",
       "            0.2017 , 0.2012 , 0.1989 , 0.1987 , 0.1934 , 0.1927 , 0.1923 ,\n",
       "            0.1885 , 0.1877 , 0.1871 , 0.1869 , 0.1863 , 0.186  , 0.1855 ,\n",
       "            0.185  , 0.1849 , 0.1848 , 0.1837 , 0.1827 , 0.1816 , 0.1815 ,\n",
       "            0.1804 , 0.1792 , 0.1788 , 0.1787 , 0.1779 , 0.1776 , 0.1772 ,\n",
       "            0.1771 , 0.1768 , 0.1761 , 0.1748 , 0.1738 , 0.1736 , 0.1716 ,\n",
       "            0.1705 , 0.1703 , 0.1698 , 0.1694 , 0.1687 , 0.1665 , 0.1659 ,\n",
       "            0.1654 , 0.1653 , 0.1649 , 0.1635 , 0.161  , 0.1603 , 0.1592 ,\n",
       "            0.1586 , 0.1583 , 0.1566 , 0.1556 , 0.1544 , 0.153  , 0.1525 ,\n",
       "            0.1517 , 0.1515 , 0.1514 , 0.1511 , 0.1509 , 0.1499 , 0.1487 ,\n",
       "            0.1448 , 0.1426 , 0.1425 , 0.1418 , 0.14   , 0.1399 , 0.1398 ,\n",
       "            0.1375 , 0.1356 , 0.133  , 0.1326 , 0.131  , 0.1296 , 0.1283 ,\n",
       "            0.1279 , 0.1272 , 0.1268 , 0.12335, 0.12146, 0.1207 , 0.12054,\n",
       "            0.11676, 0.11615, 0.115  , 0.1142 , 0.1041 , 0.10126, 0.1011 ,\n",
       "            0.1009 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.64179105, 0.6492537 , 0.6641791 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6791045 , 0.6791045 , 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.70149255, 0.70149255,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.74626863, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.79850745, 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.8208955 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.85820895, 0.85820895,\n",
       "            0.86567163, 0.86567163, 0.8731343 , 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.91791046, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.97761196, 0.98507464, 0.98507464,\n",
       "            0.9925373 , 0.9925373 , 0.9925373 , 0.9925373 , 0.9925373 ,\n",
       "            0.9925373 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.4051724 ,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.47413793, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.4827586 , 0.4827586 , 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5086207 , 0.5086207 ,\n",
       "            0.5086207 , 0.51724136, 0.51724136, 0.51724136, 0.51724136,\n",
       "            0.51724136, 0.51724136, 0.51724136, 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.54310346, 0.54310346,\n",
       "            0.54310346, 0.54310346, 0.54310346, 0.54310346, 0.54310346,\n",
       "            0.54310346, 0.54310346, 0.54310346, 0.54310346, 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.55172414, 0.55172414, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.5603448 , 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.5689655 , 0.5689655 , 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.57758623, 0.57758623, 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4607 , 0.4575 , 0.4563 , 0.451  , 0.4492 , 0.4473 ,\n",
       "            0.4465 , 0.4463 , 0.4434 , 0.4414 , 0.4412 , 0.4397 , 0.434  ,\n",
       "            0.4321 , 0.427  , 0.4248 , 0.4243 , 0.4236 , 0.4233 , 0.422  ,\n",
       "            0.4185 , 0.4158 , 0.415  , 0.4133 , 0.413  , 0.4128 , 0.4126 ,\n",
       "            0.412  , 0.4094 , 0.4087 , 0.4084 , 0.4077 , 0.4075 , 0.407  ,\n",
       "            0.4055 , 0.4043 , 0.403  , 0.4023 , 0.399  , 0.398  , 0.3936 ,\n",
       "            0.3894 , 0.3735 , 0.37   , 0.368  , 0.367  , 0.3647 , 0.3645 ,\n",
       "            0.3608 , 0.3396 , 0.3347 , 0.3323 , 0.3313 , 0.3276 , 0.3274 ,\n",
       "            0.3271 , 0.3262 , 0.3257 , 0.3242 , 0.323  , 0.3157 , 0.314  ,\n",
       "            0.3125 , 0.3096 , 0.3086 , 0.3079 , 0.3076 , 0.307  , 0.3044 ,\n",
       "            0.303  , 0.3015 , 0.297  , 0.2969 , 0.2954 , 0.2944 , 0.2927 ,\n",
       "            0.2883 , 0.287  , 0.2798 , 0.2795 , 0.2786 , 0.278  , 0.2773 ,\n",
       "            0.277  , 0.2754 , 0.2742 , 0.274  , 0.2737 , 0.2727 , 0.2725 ,\n",
       "            0.27   , 0.2695 , 0.2688 , 0.2664 , 0.266  , 0.2659 , 0.2654 ,\n",
       "            0.2634 , 0.263  , 0.261  , 0.2598 , 0.2588 , 0.2583 , 0.2573 ,\n",
       "            0.2554 , 0.2542 , 0.254  , 0.2512 , 0.251  , 0.2507 , 0.2502 ,\n",
       "            0.25   , 0.2487 , 0.2483 , 0.248  , 0.2448 , 0.2444 , 0.2438 ,\n",
       "            0.2429 , 0.2426 , 0.2411 , 0.2406 , 0.2402 , 0.2401 , 0.2388 ,\n",
       "            0.2383 , 0.2379 , 0.2375 , 0.2368 , 0.2356 , 0.2346 , 0.2343 ,\n",
       "            0.2332 , 0.2325 , 0.2313 , 0.2311 , 0.2295 , 0.228  , 0.2277 ,\n",
       "            0.2274 , 0.2242 , 0.2239 , 0.2234 , 0.2233 , 0.2224 , 0.2208 ,\n",
       "            0.2205 , 0.2194 , 0.219  , 0.2181 , 0.217  , 0.2153 , 0.2147 ,\n",
       "            0.2145 , 0.2139 , 0.2137 , 0.2125 , 0.212  , 0.2109 , 0.2096 ,\n",
       "            0.2094 , 0.209  , 0.2085 , 0.2075 , 0.207  , 0.2042 , 0.2031 ,\n",
       "            0.2028 , 0.2026 , 0.2012 , 0.2002 , 0.1993 , 0.1985 , 0.1984 ,\n",
       "            0.1954 , 0.195  , 0.1946 , 0.1942 , 0.1941 , 0.1936 , 0.1929 ,\n",
       "            0.1907 , 0.19   , 0.1898 , 0.1893 , 0.1892 , 0.1891 , 0.188  ,\n",
       "            0.1876 , 0.1871 , 0.187  , 0.1823 , 0.1782 , 0.1765 , 0.1754 ,\n",
       "            0.1735 , 0.1726 , 0.1724 , 0.1708 , 0.1707 , 0.1699 , 0.1692 ,\n",
       "            0.1688 , 0.1685 , 0.1669 , 0.1649 , 0.1648 , 0.1647 , 0.1625 ,\n",
       "            0.1611 , 0.1608 , 0.1602 , 0.1592 , 0.159  , 0.1559 , 0.154  ,\n",
       "            0.1534 , 0.1523 , 0.1509 , 0.1505 , 0.1482 , 0.144  , 0.1421 ,\n",
       "            0.1414 , 0.1372 , 0.1367 , 0.1318 , 0.1261 , 0.12476, 0.1236 ,\n",
       "            0.1216 , 0.1188 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.05172414, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.33582088,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 , 0.7238806 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.75373137, 0.76119405, 0.76119405, 0.76865673,\n",
       "            0.76865673, 0.7761194 , 0.7910448 , 0.7910448 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.82835823, 0.8358209 , 0.8507463 , 0.8507463 , 0.85820895,\n",
       "            0.85820895, 0.85820895, 0.86567163, 0.86567163, 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.880597  , 0.8880597 , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.92537314, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.95522386, 0.96268654, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.97761196, 0.98507464, 0.98507464,\n",
       "            0.98507464, 0.98507464, 0.98507464, 0.98507464, 0.9925373 ,\n",
       "            0.9925373 , 0.9925373 , 0.9925373 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.5       , 0.5       , 0.5086207 ,\n",
       "            0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 ,\n",
       "            0.5086207 , 0.5086207 , 0.5086207 , 0.51724136, 0.51724136,\n",
       "            0.51724136, 0.51724136, 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.5258621 , 0.5344828 , 0.5344828 , 0.5344828 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.55172414, 0.55172414, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.57758623, 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.57758623, 0.57758623, 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.57758623, 0.57758623, 0.5862069 , 0.6034483 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6551724 , 0.6551724 , 0.6551724 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6551724 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.70689654, 0.70689654,\n",
       "            0.70689654, 0.70689654, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.70689654, 0.70689654, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7155172 , 0.7155172 , 0.7155172 ,\n",
       "            0.7155172 , 0.7155172 , 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.76724136, 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5146, 0.514 , 0.51  , 0.5093, 0.5054, 0.501 , 0.493 ,\n",
       "            0.4907, 0.4897, 0.488 , 0.487 , 0.4822, 0.4766, 0.476 , 0.4746,\n",
       "            0.471 , 0.468 , 0.4678, 0.4666, 0.4658, 0.4648, 0.4597, 0.4583,\n",
       "            0.457 , 0.456 , 0.4558, 0.4524, 0.4507, 0.4495, 0.4492, 0.4465,\n",
       "            0.4453, 0.4443, 0.444 , 0.4436, 0.4404, 0.4365, 0.434 , 0.432 ,\n",
       "            0.4302, 0.427 , 0.4258, 0.4226, 0.4148, 0.4126, 0.407 , 0.4067,\n",
       "            0.4011, 0.3975, 0.3928, 0.3765, 0.3752, 0.36  , 0.358 , 0.3562,\n",
       "            0.3513, 0.3503, 0.346 , 0.3452, 0.3442, 0.3428, 0.3418, 0.3303,\n",
       "            0.3264, 0.3242, 0.3237, 0.321 , 0.316 , 0.314 , 0.3132, 0.3113,\n",
       "            0.3108, 0.3098, 0.3066, 0.3064, 0.304 , 0.3027, 0.3022, 0.298 ,\n",
       "            0.2969, 0.296 , 0.2957, 0.2954, 0.2952, 0.2947, 0.2935, 0.2925,\n",
       "            0.2922, 0.2869, 0.285 , 0.2822, 0.2817, 0.2803, 0.2795, 0.2793,\n",
       "            0.2783, 0.2761, 0.276 , 0.2727, 0.2708, 0.2698, 0.2688, 0.2683,\n",
       "            0.2678, 0.267 , 0.2654, 0.2646, 0.2642, 0.2632, 0.263 , 0.2622,\n",
       "            0.262 , 0.261 , 0.2605, 0.2598, 0.2595, 0.2593, 0.2585, 0.258 ,\n",
       "            0.2576, 0.254 , 0.2522, 0.2517, 0.2515, 0.2512, 0.2502, 0.2494,\n",
       "            0.2485, 0.2478, 0.2473, 0.2466, 0.2452, 0.2448, 0.2445, 0.2438,\n",
       "            0.2428, 0.2421, 0.2411, 0.241 , 0.2401, 0.2386, 0.2384, 0.2383,\n",
       "            0.2375, 0.237 , 0.236 , 0.2356, 0.2343, 0.2339, 0.2338, 0.2335,\n",
       "            0.2334, 0.233 , 0.231 , 0.2306, 0.2295, 0.2294, 0.228 , 0.2274,\n",
       "            0.2272, 0.2263, 0.2256, 0.2251, 0.2249, 0.2246, 0.2234, 0.223 ,\n",
       "            0.2227, 0.222 , 0.2203, 0.22  , 0.2198, 0.219 , 0.2184, 0.218 ,\n",
       "            0.2179, 0.217 , 0.2142, 0.214 , 0.2129, 0.2124, 0.2108, 0.2104,\n",
       "            0.2098, 0.2096, 0.2094, 0.2065, 0.2054, 0.2043, 0.2035, 0.202 ,\n",
       "            0.2007, 0.2004, 0.2002, 0.2001, 0.1984, 0.1964, 0.1959, 0.1952,\n",
       "            0.1947, 0.1942, 0.1919, 0.1909, 0.1898, 0.1893, 0.189 , 0.1886,\n",
       "            0.1877, 0.1855, 0.185 , 0.1842, 0.1837, 0.1835, 0.183 , 0.1819,\n",
       "            0.1803, 0.1799, 0.1788, 0.1785, 0.1782, 0.1765, 0.1718, 0.171 ,\n",
       "            0.1707, 0.1681, 0.1666, 0.1653, 0.1594, 0.1543, 0.1508, 0.15  ,\n",
       "            0.1478, 0.1444, 0.139 , 0.1389], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.20689656, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20895523, 0.21641791,\n",
       "            0.21641791, 0.2238806 , 0.2238806 , 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.2835821 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.619403  , 0.619403  , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6567164 ,\n",
       "            0.67164177, 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.8134328 , 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8358209 , 0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8880597 , 0.8880597 , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.95522386, 0.96268654,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.4827586 , 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5       , 0.5086207 , 0.5086207 ,\n",
       "            0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.51724136, 0.5258621 , 0.5258621 ,\n",
       "            0.5258621 , 0.5258621 , 0.5344828 , 0.5344828 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.5344828 , 0.5344828 ,\n",
       "            0.54310346, 0.54310346, 0.54310346, 0.54310346, 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6637931 , 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.69827586, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.70689654, 0.70689654, 0.7155172 , 0.7155172 , 0.7241379 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 ,\n",
       "            0.8103448 , 0.8103448 , 0.8189655 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.579 , 0.5747, 0.566 , 0.5645, 0.56  , 0.557 , 0.547 ,\n",
       "            0.538 , 0.537 , 0.534 , 0.5312, 0.5303, 0.5264, 0.5254, 0.5244,\n",
       "            0.521 , 0.5195, 0.519 , 0.515 , 0.51  , 0.5054, 0.501 , 0.5005,\n",
       "            0.4983, 0.4973, 0.4956, 0.494 , 0.4912, 0.487 , 0.4868, 0.4849,\n",
       "            0.4802, 0.4792, 0.4778, 0.4736, 0.4724, 0.4707, 0.4656, 0.4636,\n",
       "            0.4626, 0.462 , 0.455 , 0.453 , 0.4473, 0.4456, 0.4424, 0.4321,\n",
       "            0.426 , 0.422 , 0.4219, 0.4016, 0.395 , 0.3843, 0.3833, 0.3823,\n",
       "            0.3816, 0.3755, 0.3684, 0.3638, 0.3564, 0.3481, 0.3457, 0.3452,\n",
       "            0.3374, 0.333 , 0.3325, 0.332 , 0.3303, 0.328 , 0.325 , 0.3247,\n",
       "            0.3235, 0.3228, 0.3223, 0.3176, 0.3154, 0.3142, 0.3123, 0.311 ,\n",
       "            0.3108, 0.3086, 0.3079, 0.3064, 0.3062, 0.3052, 0.3042, 0.3025,\n",
       "            0.3   , 0.2986, 0.2966, 0.2957, 0.295 , 0.2935, 0.2932, 0.293 ,\n",
       "            0.2913, 0.2908, 0.2905, 0.2903, 0.29  , 0.2898, 0.2893, 0.2888,\n",
       "            0.288 , 0.2866, 0.2864, 0.2834, 0.282 , 0.2812, 0.2795, 0.278 ,\n",
       "            0.2776, 0.2754, 0.2737, 0.2715, 0.271 , 0.2705, 0.27  , 0.2695,\n",
       "            0.2693, 0.2676, 0.2664, 0.266 , 0.2644, 0.2632, 0.2612, 0.261 ,\n",
       "            0.2607, 0.2605, 0.258 , 0.2573, 0.2568, 0.2563, 0.2559, 0.2554,\n",
       "            0.255 , 0.2544, 0.253 , 0.2524, 0.2522, 0.2515, 0.251 , 0.2507,\n",
       "            0.2498, 0.2487, 0.2483, 0.2478, 0.247 , 0.2462, 0.2448, 0.2437,\n",
       "            0.2417, 0.241 , 0.2406, 0.2395, 0.2382, 0.2378, 0.2372, 0.2347,\n",
       "            0.2344, 0.2339, 0.2327, 0.2322, 0.2319, 0.2318, 0.2313, 0.2306,\n",
       "            0.2301, 0.2297, 0.2285, 0.2281, 0.2268, 0.2266, 0.2261, 0.2255,\n",
       "            0.2252, 0.2247, 0.2235, 0.2233, 0.2225, 0.222 , 0.2213, 0.2211,\n",
       "            0.2207, 0.2195, 0.2194, 0.2185, 0.2184, 0.2177, 0.2172, 0.2167,\n",
       "            0.2163, 0.2162, 0.215 , 0.2148, 0.2139, 0.213 , 0.2129, 0.2113,\n",
       "            0.2109, 0.2101, 0.2098, 0.2084, 0.2081, 0.2079, 0.206 , 0.2051,\n",
       "            0.2029, 0.2028, 0.2007, 0.2004, 0.1998, 0.1996, 0.1991, 0.1985,\n",
       "            0.1981, 0.1947, 0.1931, 0.1919, 0.1891, 0.1821, 0.182 , 0.1819,\n",
       "            0.1779, 0.1716, 0.1709, 0.1694, 0.1682, 0.1653, 0.1602, 0.1592,\n",
       "            0.1511], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.33620688, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.1716418 , 0.17910448, 0.17910448,\n",
       "            0.18656716, 0.18656716, 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23880596,\n",
       "            0.24626866, 0.26119402, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.3283582 , 0.33582088, 0.35074627,\n",
       "            0.35820895, 0.35820895, 0.36567163, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.48507464, 0.49253732, 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.6641791 , 0.6641791 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.7238806 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.880597  , 0.8880597 , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.9328358 , 0.9328358 , 0.9328358 , 0.9402985 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.9701493 ,\n",
       "            0.97761196, 0.97761196, 0.98507464, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.4827586 , 0.4827586 , 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.5258621 , 0.5344828 , 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.54310346, 0.54310346,\n",
       "            0.54310346, 0.5603448 , 0.5603448 , 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.62931037, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7155172 , 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.8189655 , 0.82758623, 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6323, 0.6245, 0.6157, 0.6104, 0.6045, 0.603 , 0.592 ,\n",
       "            0.5796, 0.579 , 0.5767, 0.5737, 0.5728, 0.57  , 0.568 , 0.5664,\n",
       "            0.5625, 0.5596, 0.553 , 0.5493, 0.5386, 0.5376, 0.537 , 0.534 ,\n",
       "            0.5317, 0.5312, 0.531 , 0.5303, 0.5205, 0.518 , 0.515 , 0.514 ,\n",
       "            0.5127, 0.511 , 0.5073, 0.507 , 0.503 , 0.5024, 0.4963, 0.4954,\n",
       "            0.4922, 0.4912, 0.481 , 0.4773, 0.4768, 0.476 , 0.4707, 0.4587,\n",
       "            0.4495, 0.4468, 0.4456, 0.4363, 0.4229, 0.4143, 0.4119, 0.4014,\n",
       "            0.3953, 0.3887, 0.3813, 0.3782, 0.3767, 0.375 , 0.3674, 0.3672,\n",
       "            0.3652, 0.351 , 0.3472, 0.3464, 0.3435, 0.34  , 0.3381, 0.3325,\n",
       "            0.332 , 0.3298, 0.327 , 0.325 , 0.3237, 0.3228, 0.322 , 0.3213,\n",
       "            0.321 , 0.3206, 0.3193, 0.3188, 0.3186, 0.3162, 0.3147, 0.313 ,\n",
       "            0.3108, 0.3093, 0.307 , 0.306 , 0.3044, 0.3025, 0.3018, 0.3005,\n",
       "            0.2996, 0.2986, 0.297 , 0.2954, 0.295 , 0.2915, 0.29  , 0.2888,\n",
       "            0.2876, 0.2874, 0.2864, 0.2856, 0.285 , 0.2834, 0.2827, 0.2795,\n",
       "            0.2786, 0.278 , 0.2776, 0.2773, 0.2766, 0.2761, 0.275 , 0.2744,\n",
       "            0.2742, 0.2708, 0.2703, 0.2688, 0.2686, 0.2642, 0.2637, 0.263 ,\n",
       "            0.2615, 0.2612, 0.2605, 0.2595, 0.2578, 0.2556, 0.2542, 0.2527,\n",
       "            0.2524, 0.252 , 0.2505, 0.25  , 0.2478, 0.2477, 0.2471, 0.2467,\n",
       "            0.2462, 0.246 , 0.2458, 0.2452, 0.243 , 0.2421, 0.2418, 0.241 ,\n",
       "            0.2399, 0.2397, 0.2391, 0.2372, 0.2356, 0.2352, 0.2351, 0.2339,\n",
       "            0.2335, 0.2323, 0.2318, 0.2316, 0.2306, 0.2303, 0.2301, 0.2294,\n",
       "            0.2286, 0.2285, 0.2278, 0.2273, 0.2268, 0.2264, 0.2252, 0.2251,\n",
       "            0.224 , 0.2234, 0.2233, 0.223 , 0.2229, 0.2224, 0.2222, 0.2213,\n",
       "            0.2208, 0.2202, 0.219 , 0.2168, 0.2156, 0.215 , 0.2145, 0.2135,\n",
       "            0.2133, 0.2124, 0.212 , 0.2106, 0.209 , 0.2089, 0.2079, 0.2065,\n",
       "            0.2064, 0.206 , 0.2059, 0.2054, 0.2034, 0.2031, 0.2021, 0.1998,\n",
       "            0.1953, 0.195 , 0.1913, 0.19  , 0.1882, 0.1865, 0.1858, 0.1831,\n",
       "            0.183 , 0.1821, 0.1792, 0.179 , 0.1749, 0.1705, 0.164 , 0.1562,\n",
       "            0.1483, 0.143 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.4051724, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.11940298, 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.26119402, 0.26865673, 0.26865673,\n",
       "            0.2761194 , 0.2761194 , 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.47014925, 0.48507464, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76119405, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7761194 , 0.7910448 , 0.79850745, 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8134328 , 0.82835823, 0.8358209 , 0.8507463 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.91791046, 0.92537314,\n",
       "            0.9402985 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.0775862 , 0.09482758,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.4827586 , 0.49137932, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.54310346, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.62068963, 0.62068963, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6865, 0.677 , 0.6675, 0.659 , 0.6543, 0.65  , 0.6396,\n",
       "            0.624 , 0.6235, 0.615 , 0.614 , 0.61  , 0.607 , 0.6035, 0.603 ,\n",
       "            0.5977, 0.588 , 0.579 , 0.5767, 0.5757, 0.5747, 0.5723, 0.5684,\n",
       "            0.567 , 0.5566, 0.556 , 0.5537, 0.5464, 0.545 , 0.543 , 0.539 ,\n",
       "            0.5386, 0.534 , 0.5283, 0.526 , 0.5225, 0.5215, 0.5146, 0.51  ,\n",
       "            0.502 , 0.4946, 0.493 , 0.4744, 0.4702, 0.4697, 0.4644, 0.4502,\n",
       "            0.4434, 0.4404, 0.4214, 0.4148, 0.403 , 0.402 , 0.3975, 0.396 ,\n",
       "            0.3953, 0.3948, 0.3926, 0.3772, 0.3762, 0.3728, 0.3704, 0.3662,\n",
       "            0.3657, 0.362 , 0.36  , 0.3503, 0.35  , 0.3486, 0.3484, 0.344 ,\n",
       "            0.3433, 0.3423, 0.34  , 0.3394, 0.338 , 0.334 , 0.3315, 0.3313,\n",
       "            0.331 , 0.3306, 0.3298, 0.3293, 0.3284, 0.3267, 0.325 , 0.323 ,\n",
       "            0.3228, 0.3208, 0.3203, 0.32  , 0.3193, 0.3188, 0.3186, 0.3176,\n",
       "            0.3093, 0.306 , 0.3025, 0.3018, 0.301 , 0.2998, 0.2986, 0.2964,\n",
       "            0.2944, 0.2942, 0.294 , 0.2932, 0.292 , 0.2908, 0.2905, 0.2893,\n",
       "            0.2878, 0.2876, 0.286 , 0.285 , 0.284 , 0.2834, 0.2832, 0.282 ,\n",
       "            0.281 , 0.2788, 0.2776, 0.2764, 0.2737, 0.2734, 0.272 , 0.2712,\n",
       "            0.2708, 0.27  , 0.268 , 0.2673, 0.2668, 0.2646, 0.2627, 0.2603,\n",
       "            0.2593, 0.2578, 0.2573, 0.2568, 0.2563, 0.255 , 0.2532, 0.251 ,\n",
       "            0.2496, 0.249 , 0.2485, 0.2483, 0.246 , 0.2449, 0.2433, 0.2424,\n",
       "            0.2422, 0.2413, 0.2411, 0.241 , 0.2406, 0.2401, 0.2397, 0.239 ,\n",
       "            0.2383, 0.2379, 0.2352, 0.2346, 0.234 , 0.2335, 0.2313, 0.2306,\n",
       "            0.2294, 0.2289, 0.2273, 0.2244, 0.223 , 0.2227, 0.222 , 0.2213,\n",
       "            0.2203, 0.2181, 0.2162, 0.2157, 0.2156, 0.2145, 0.2135, 0.2133,\n",
       "            0.213 , 0.2128, 0.2123, 0.2115, 0.2106, 0.2101, 0.21  , 0.2098,\n",
       "            0.209 , 0.2086, 0.2064, 0.2056, 0.2009, 0.1984, 0.1979, 0.1974,\n",
       "            0.195 , 0.1948, 0.1941, 0.194 , 0.1937, 0.1919, 0.1912, 0.1877,\n",
       "            0.1863, 0.1849, 0.1837, 0.1796, 0.1748, 0.1714, 0.1678, 0.1663,\n",
       "            0.1592, 0.1587, 0.1472, 0.1326, 0.1274], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.44827586, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.10447761, 0.10447761, 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.19402985, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.20895523, 0.21641791,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.31343284, 0.32089552, 0.32089552, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.6492537 , 0.6492537 , 0.6567164 , 0.6567164 , 0.6567164 ,\n",
       "            0.6641791 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7835821 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.31034482,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5086207 , 0.5086207 , 0.51724136, 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62068963, 0.62068963, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 , 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.743  , 0.731  , 0.7227 , 0.7104 , 0.707  , 0.6987 ,\n",
       "            0.6914 , 0.68   , 0.6763 , 0.6724 , 0.672  , 0.6675 , 0.6665 ,\n",
       "            0.66   , 0.6577 , 0.6543 , 0.6514 , 0.649  , 0.6475 , 0.629  ,\n",
       "            0.6284 , 0.622  , 0.6216 , 0.621  , 0.616  , 0.613  , 0.6094 ,\n",
       "            0.609  , 0.604  , 0.598  , 0.5947 , 0.594  , 0.584  , 0.58   ,\n",
       "            0.5747 , 0.5723 , 0.569  , 0.56   , 0.559  , 0.5586 , 0.5557 ,\n",
       "            0.5537 , 0.5513 , 0.5435 , 0.531  , 0.5176 , 0.517  , 0.506  ,\n",
       "            0.502  , 0.4888 , 0.4858 , 0.4841 , 0.4824 , 0.4497 , 0.4492 ,\n",
       "            0.4463 , 0.4453 , 0.4429 , 0.4397 , 0.4258 , 0.4219 , 0.4194 ,\n",
       "            0.4167 , 0.415  , 0.4136 , 0.4048 , 0.4019 , 0.4    , 0.3987 ,\n",
       "            0.3977 , 0.393  , 0.388  , 0.3843 , 0.383  , 0.3826 , 0.3818 ,\n",
       "            0.3804 , 0.3792 , 0.3733 , 0.3718 , 0.3667 , 0.3647 , 0.3628 ,\n",
       "            0.3613 , 0.3586 , 0.3574 , 0.357  , 0.3516 , 0.3513 , 0.3496 ,\n",
       "            0.3472 , 0.3457 , 0.344  , 0.3425 , 0.3403 , 0.34   , 0.3381 ,\n",
       "            0.3367 , 0.3352 , 0.3335 , 0.3328 , 0.3315 , 0.3313 , 0.327  ,\n",
       "            0.326  , 0.3257 , 0.324  , 0.3235 , 0.3232 , 0.323  , 0.321  ,\n",
       "            0.32   , 0.3198 , 0.3152 , 0.3135 , 0.3123 , 0.3115 , 0.311  ,\n",
       "            0.31   , 0.3096 , 0.3093 , 0.305  , 0.3025 , 0.2993 , 0.298  ,\n",
       "            0.292  , 0.291  , 0.2908 , 0.2905 , 0.2898 , 0.2893 , 0.288  ,\n",
       "            0.2856 , 0.285  , 0.2842 , 0.2837 , 0.282  , 0.2812 , 0.2795 ,\n",
       "            0.279  , 0.2788 , 0.278  , 0.2776 , 0.2769 , 0.2761 , 0.2756 ,\n",
       "            0.2754 , 0.2742 , 0.274  , 0.2732 , 0.2727 , 0.2725 , 0.2715 ,\n",
       "            0.271  , 0.2708 , 0.2698 , 0.2695 , 0.2683 , 0.268  , 0.2673 ,\n",
       "            0.2664 , 0.2651 , 0.2642 , 0.2595 , 0.2563 , 0.2532 , 0.2524 ,\n",
       "            0.252  , 0.2512 , 0.251  , 0.2487 , 0.2474 , 0.2458 , 0.2451 ,\n",
       "            0.2449 , 0.2444 , 0.2388 , 0.2352 , 0.2338 , 0.2303 , 0.2295 ,\n",
       "            0.2294 , 0.2283 , 0.2274 , 0.2273 , 0.2263 , 0.2257 , 0.2255 ,\n",
       "            0.2251 , 0.2235 , 0.222  , 0.2216 , 0.2197 , 0.2158 , 0.2147 ,\n",
       "            0.2144 , 0.2125 , 0.2104 , 0.2103 , 0.2098 , 0.2096 , 0.209  ,\n",
       "            0.2084 , 0.2076 , 0.2064 , 0.206  , 0.2059 , 0.2053 , 0.2028 ,\n",
       "            0.201  , 0.199  , 0.1967 , 0.1964 , 0.1956 , 0.1924 , 0.1879 ,\n",
       "            0.1843 , 0.1841 , 0.1816 , 0.181  , 0.179  , 0.1741 , 0.1731 ,\n",
       "            0.1686 , 0.1685 , 0.159  , 0.1562 , 0.1527 , 0.1504 , 0.1439 ,\n",
       "            0.1315 , 0.11816, 0.1124 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00746269, dtype=float32),\n",
       "    'tpr': array(0.46551725, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1641791 , 0.1641791 , 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.25373134, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.29850745, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3880597 , 0.3955224 , 0.3955224 ,\n",
       "            0.3955224 , 0.3955224 , 0.40298507, 0.41044775, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.64179105, 0.6492537 , 0.6567164 , 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.70149255, 0.70149255, 0.70149255, 0.70149255, 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5       ,\n",
       "            0.5086207 , 0.5086207 , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5862069 , 0.5862069 , 0.5948276 , 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.62068963, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6551724 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.8189655 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7847 , 0.7715 , 0.763  , 0.7495 , 0.747  , 0.737  ,\n",
       "            0.7305 , 0.7217 , 0.716  , 0.71   , 0.7095 , 0.707  , 0.705  ,\n",
       "            0.696  , 0.6895 , 0.6885 , 0.6875 , 0.6826 , 0.665  , 0.662  ,\n",
       "            0.6577 , 0.657  , 0.6562 , 0.6484 , 0.6475 , 0.647  , 0.641  ,\n",
       "            0.634  , 0.6313 , 0.6304 , 0.627  , 0.6147 , 0.6084 , 0.6074 ,\n",
       "            0.6035 , 0.603  , 0.6016 , 0.5996 , 0.5903 , 0.589  , 0.586  ,\n",
       "            0.5854 , 0.5825 , 0.5815 , 0.578  , 0.553  , 0.551  , 0.5356 ,\n",
       "            0.529  , 0.5254 , 0.5156 , 0.514  , 0.5107 , 0.498  , 0.482  ,\n",
       "            0.4746 , 0.4727 , 0.4688 , 0.4683 , 0.4626 , 0.462  , 0.4524 ,\n",
       "            0.4463 , 0.445  , 0.4285 , 0.427  , 0.4268 , 0.4211 , 0.4143 ,\n",
       "            0.409  , 0.4084 , 0.405  , 0.4048 , 0.4028 , 0.4023 , 0.4014 ,\n",
       "            0.397  , 0.395  , 0.39   , 0.389  , 0.3853 , 0.384  , 0.3835 ,\n",
       "            0.3818 , 0.3796 , 0.378  , 0.3765 , 0.376  , 0.374  , 0.3687 ,\n",
       "            0.3665 , 0.3662 , 0.365  , 0.3628 , 0.3591 , 0.358  , 0.356  ,\n",
       "            0.3557 , 0.3545 , 0.3542 , 0.3518 , 0.3513 , 0.3508 , 0.3464 ,\n",
       "            0.3435 , 0.3425 , 0.342  , 0.3403 , 0.3396 , 0.339  , 0.3372 ,\n",
       "            0.3357 , 0.3354 , 0.335  , 0.333  , 0.3313 , 0.331  , 0.3289 ,\n",
       "            0.323  , 0.3225 , 0.3218 , 0.3208 , 0.3193 , 0.3167 , 0.3162 ,\n",
       "            0.3157 , 0.311  , 0.3076 , 0.3074 , 0.304  , 0.3022 , 0.302  ,\n",
       "            0.3013 , 0.301  , 0.2983 , 0.2961 , 0.296  , 0.2954 , 0.2952 ,\n",
       "            0.2942 , 0.2915 , 0.2903 , 0.2898 , 0.2876 , 0.2874 , 0.2869 ,\n",
       "            0.286  , 0.2856 , 0.2852 , 0.2842 , 0.284  , 0.2827 , 0.2817 ,\n",
       "            0.2808 , 0.28   , 0.2798 , 0.2793 , 0.279  , 0.278  , 0.2751 ,\n",
       "            0.2747 , 0.272  , 0.2683 , 0.268  , 0.2651 , 0.2646 , 0.2642 ,\n",
       "            0.2634 , 0.2627 , 0.2625 , 0.2615 , 0.261  , 0.259  , 0.258  ,\n",
       "            0.2568 , 0.2566 , 0.2556 , 0.2485 , 0.2449 , 0.2406 , 0.2405 ,\n",
       "            0.2368 , 0.2367 , 0.2366 , 0.2325 , 0.2323 , 0.2272 , 0.2257 ,\n",
       "            0.2222 , 0.2218 , 0.2207 , 0.2189 , 0.218  , 0.2162 , 0.2137 ,\n",
       "            0.2135 , 0.2129 , 0.211  , 0.2109 , 0.2079 , 0.2073 , 0.2028 ,\n",
       "            0.1998 , 0.1993 , 0.1982 , 0.1981 , 0.1974 , 0.1965 , 0.195  ,\n",
       "            0.1943 , 0.1924 , 0.1887 , 0.1885 , 0.183  , 0.1829 , 0.1815 ,\n",
       "            0.181  , 0.1779 , 0.1755 , 0.1718 , 0.1699 , 0.1672 , 0.1644 ,\n",
       "            0.1589 , 0.1534 , 0.1533 , 0.1439 , 0.1417 , 0.1382 , 0.1353 ,\n",
       "            0.1294 , 0.11676, 0.1047 , 0.09894], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.02985075, dtype=float32),\n",
       "    'tpr': array(0.5, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.18656716, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.26865673, 0.2761194 ,\n",
       "            0.2761194 , 0.2761194 , 0.2835821 , 0.2835821 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6567164 , 0.6567164 ,\n",
       "            0.6567164 , 0.6641791 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62068963, 0.62068963, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 , 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.829  , 0.8145 , 0.8076 , 0.792  , 0.791  , 0.778  ,\n",
       "            0.7744 , 0.7695 , 0.7607 , 0.753  , 0.752  , 0.751  , 0.7495 ,\n",
       "            0.74   , 0.736  , 0.733  , 0.7314 , 0.7295 , 0.722  , 0.709  ,\n",
       "            0.701  , 0.7007 , 0.7    , 0.6987 , 0.6973 , 0.695  , 0.688  ,\n",
       "            0.6855 , 0.679  , 0.678  , 0.67   , 0.668  , 0.6655 , 0.6514 ,\n",
       "            0.642  , 0.639  , 0.6387 , 0.6377 , 0.637  , 0.631  , 0.627  ,\n",
       "            0.6245 , 0.6206 , 0.6167 , 0.6157 , 0.596  , 0.58   , 0.5586 ,\n",
       "            0.557  , 0.556  , 0.5557 , 0.5527 , 0.552  , 0.5327 , 0.522  ,\n",
       "            0.518  , 0.515  , 0.5146 , 0.5127 , 0.5015 , 0.4963 , 0.4902 ,\n",
       "            0.4893 , 0.489  , 0.478  , 0.4756 , 0.4675 , 0.459  , 0.456  ,\n",
       "            0.4497 , 0.4475 , 0.4463 , 0.4446 , 0.4434 , 0.4397 , 0.4385 ,\n",
       "            0.437  , 0.4282 , 0.4246 , 0.424  , 0.422  , 0.419  , 0.4185 ,\n",
       "            0.418  , 0.4175 , 0.4165 , 0.4163 , 0.4148 , 0.414  , 0.4111 ,\n",
       "            0.4094 , 0.403  , 0.4026 , 0.4011 , 0.3972 , 0.3916 , 0.39   ,\n",
       "            0.3884 , 0.3875 , 0.387  , 0.385  , 0.3843 , 0.3838 , 0.3801 ,\n",
       "            0.3796 , 0.3777 , 0.3767 , 0.3757 , 0.3745 , 0.3716 , 0.371  ,\n",
       "            0.3706 , 0.368  , 0.3657 , 0.3586 , 0.3525 , 0.3513 , 0.3489 ,\n",
       "            0.348  , 0.3472 , 0.3445 , 0.3423 , 0.34   , 0.3376 , 0.3367 ,\n",
       "            0.3347 , 0.333  , 0.3315 , 0.331  , 0.3289 , 0.3284 , 0.3276 ,\n",
       "            0.327  , 0.3242 , 0.3228 , 0.322  , 0.3213 , 0.321  , 0.3193 ,\n",
       "            0.319  , 0.3184 , 0.3176 , 0.317  , 0.3162 , 0.3154 , 0.3152 ,\n",
       "            0.3142 , 0.314  , 0.3093 , 0.3086 , 0.3079 , 0.3064 , 0.3062 ,\n",
       "            0.3054 , 0.3044 , 0.3    , 0.2974 , 0.2905 , 0.288  , 0.2874 ,\n",
       "            0.2861 , 0.2854 , 0.285  , 0.2847 , 0.283  , 0.2798 , 0.2788 ,\n",
       "            0.2786 , 0.2773 , 0.2751 , 0.2744 , 0.2742 , 0.2725 , 0.2715 ,\n",
       "            0.2703 , 0.268  , 0.2632 , 0.263  , 0.2607 , 0.2605 , 0.2595 ,\n",
       "            0.258  , 0.2576 , 0.2563 , 0.2554 , 0.2551 , 0.2494 , 0.249  ,\n",
       "            0.246  , 0.2424 , 0.2411 , 0.2399 , 0.2347 , 0.234  , 0.2323 ,\n",
       "            0.2303 , 0.2278 , 0.224  , 0.2163 , 0.2058 , 0.2056 , 0.2021 ,\n",
       "            0.2006 , 0.2002 , 0.1952 , 0.195  , 0.1934 , 0.1921 , 0.1909 ,\n",
       "            0.1898 , 0.1876 , 0.1874 , 0.1871 , 0.1848 , 0.1842 , 0.1807 ,\n",
       "            0.18   , 0.1771 , 0.1721 , 0.1697 , 0.1685 , 0.1654 , 0.162  ,\n",
       "            0.1608 , 0.1566 , 0.1533 , 0.1504 , 0.145  , 0.1393 , 0.139  ,\n",
       "            0.1296 , 0.1279 , 0.1243 , 0.12103, 0.11554, 0.1032 , 0.0927 ,\n",
       "            0.0863 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04477612, dtype=float32),\n",
       "    'tpr': array(0.54310346, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.20149253, 0.20149253, 0.20149253,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.2835821 , 0.2835821 , 0.2835821 , 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.6641791 , 0.67164177, 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43103448, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.54310346,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.70689654, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8189655 , 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87931037, 0.87931037, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8604 , 0.8467 , 0.8403 , 0.824  , 0.81   , 0.808  ,\n",
       "            0.8047 , 0.796  , 0.789  , 0.7856 , 0.7847 , 0.784  , 0.7754 ,\n",
       "            0.769  , 0.7686 , 0.766  , 0.762  , 0.755  , 0.7446 , 0.7373 ,\n",
       "            0.736  , 0.733  , 0.7324 , 0.7314 , 0.722  , 0.7173 , 0.717  ,\n",
       "            0.7114 , 0.7026 , 0.698  , 0.683  , 0.672  , 0.6704 , 0.6694 ,\n",
       "            0.669  , 0.668  , 0.667  , 0.6665 , 0.664  , 0.663  , 0.656  ,\n",
       "            0.655  , 0.6455 , 0.645  , 0.6353 , 0.6055 , 0.5933 , 0.589  ,\n",
       "            0.587  , 0.5845 , 0.5776 , 0.5757 , 0.5713 , 0.556  , 0.5522 ,\n",
       "            0.5513 , 0.543  , 0.533  , 0.5303 , 0.527  , 0.523  , 0.521  ,\n",
       "            0.518  , 0.5156 , 0.5034 , 0.4978 , 0.4895 , 0.4863 , 0.4846 ,\n",
       "            0.4788 , 0.4749 , 0.4744 , 0.47   , 0.4663 , 0.4648 , 0.4634 ,\n",
       "            0.4631 , 0.4602 , 0.46   , 0.4543 , 0.4539 , 0.45   , 0.4487 ,\n",
       "            0.4482 , 0.447  , 0.4429 , 0.439  , 0.4387 , 0.435  , 0.4336 ,\n",
       "            0.432  , 0.4312 , 0.4302 , 0.428  , 0.4272 , 0.4253 , 0.4229 ,\n",
       "            0.4219 , 0.4207 , 0.4177 , 0.415  , 0.4143 , 0.4138 , 0.4104 ,\n",
       "            0.4092 , 0.4084 , 0.4045 , 0.3992 , 0.3953 , 0.3933 , 0.39   ,\n",
       "            0.388  , 0.3872 , 0.3867 , 0.3826 , 0.3752 , 0.371  , 0.3708 ,\n",
       "            0.3677 , 0.3662 , 0.3657 , 0.363  , 0.3623 , 0.3552 , 0.3542 ,\n",
       "            0.354  , 0.3525 , 0.352  , 0.3494 , 0.3484 , 0.3481 , 0.3477 ,\n",
       "            0.3474 , 0.3462 , 0.346  , 0.3455 , 0.3445 , 0.3423 , 0.338  ,\n",
       "            0.3345 , 0.3333 , 0.332  , 0.3318 , 0.3315 , 0.3313 , 0.3306 ,\n",
       "            0.3293 , 0.3242 , 0.3237 , 0.3225 , 0.321  , 0.3206 , 0.3154 ,\n",
       "            0.3145 , 0.3142 , 0.3127 , 0.3115 , 0.3093 , 0.3086 , 0.308  ,\n",
       "            0.3076 , 0.307  , 0.3042 , 0.2974 , 0.2932 , 0.2896 , 0.2808 ,\n",
       "            0.2773 , 0.277  , 0.2751 , 0.2742 , 0.272  , 0.2703 , 0.2695 ,\n",
       "            0.2686 , 0.2678 , 0.2673 , 0.2664 , 0.2617 , 0.2612 , 0.2598 ,\n",
       "            0.2559 , 0.2551 , 0.254  , 0.2534 , 0.252  , 0.2487 , 0.2466 ,\n",
       "            0.2411 , 0.241  , 0.2314 , 0.2294 , 0.222  , 0.2101 , 0.2096 ,\n",
       "            0.2069 , 0.1989 , 0.1954 , 0.194  , 0.1935 , 0.1934 , 0.1896 ,\n",
       "            0.1886 , 0.1864 , 0.1836 , 0.1829 , 0.1807 , 0.179  , 0.1766 ,\n",
       "            0.1759 , 0.1758 , 0.1719 , 0.1688 , 0.1671 , 0.1608 , 0.16   ,\n",
       "            0.1594 , 0.1592 , 0.1559 , 0.1552 , 0.1475 , 0.1432 , 0.1407 ,\n",
       "            0.1346 , 0.1292 , 0.1289 , 0.1193 , 0.11755, 0.11395, 0.11084,\n",
       "            0.1054 , 0.0935 , 0.08386, 0.07684], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04477612, dtype=float32),\n",
       "    'tpr': array(0.5603448, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.18656716, 0.19402985, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.25373134, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.2835821 , 0.2835821 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3283582 , 0.3283582 ,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.3880597 , 0.3880597 ,\n",
       "            0.3880597 , 0.3880597 , 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.67164177, 0.67164177, 0.6791045 , 0.69402987,\n",
       "            0.70149255, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.70689654, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87931037, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.883  , 0.8716 , 0.8647 , 0.8506 , 0.85   , 0.837  ,\n",
       "            0.8345 , 0.8296 , 0.8223 , 0.8145 , 0.8125 , 0.811  , 0.8105 ,\n",
       "            0.802  , 0.7964 , 0.795  , 0.793  , 0.7896 , 0.7817 , 0.771  ,\n",
       "            0.763  , 0.7617 , 0.76   , 0.7593 , 0.758  , 0.757  , 0.748  ,\n",
       "            0.743  , 0.74   , 0.7373 , 0.728  , 0.725  , 0.7236 , 0.708  ,\n",
       "            0.6973 , 0.694  , 0.6934 , 0.693  , 0.6914 , 0.689  , 0.686  ,\n",
       "            0.6855 , 0.6787 , 0.677  , 0.6685 , 0.6675 , 0.6562 , 0.6255 ,\n",
       "            0.6123 , 0.6074 , 0.606  , 0.605  , 0.6025 , 0.596  , 0.5938 ,\n",
       "            0.5903 , 0.5723 , 0.568  , 0.5674 , 0.559  , 0.546  , 0.545  ,\n",
       "            0.5415 , 0.537  , 0.536  , 0.533  , 0.5293 , 0.516  , 0.5103 ,\n",
       "            0.502  , 0.4976 , 0.4958 , 0.489  , 0.4856 , 0.4844 , 0.4792 ,\n",
       "            0.4768 , 0.4749 , 0.4727 , 0.4717 , 0.4697 , 0.4695 , 0.4636 ,\n",
       "            0.4622 , 0.458  , 0.4578 , 0.4563 , 0.455  , 0.4504 , 0.4468 ,\n",
       "            0.4458 , 0.4434 , 0.4397 , 0.4385 , 0.4382 , 0.4375 , 0.4368 ,\n",
       "            0.4365 , 0.4324 , 0.431  , 0.4292 , 0.427  , 0.4253 , 0.4233 ,\n",
       "            0.421  , 0.4194 , 0.4163 , 0.415  , 0.4146 , 0.4092 , 0.4023 ,\n",
       "            0.398  , 0.3977 , 0.396  , 0.3958 , 0.3928 , 0.392  , 0.3894 ,\n",
       "            0.3892 , 0.3853 , 0.3762 , 0.3752 , 0.3733 , 0.372  , 0.371  ,\n",
       "            0.3691 , 0.3667 , 0.3665 , 0.366  , 0.3628 , 0.3574 , 0.356  ,\n",
       "            0.3525 , 0.352  , 0.351  , 0.3508 , 0.3506 , 0.35   , 0.349  ,\n",
       "            0.3486 , 0.3484 , 0.3462 , 0.3457 , 0.3455 , 0.343  , 0.3428 ,\n",
       "            0.3367 , 0.3323 , 0.3315 , 0.3308 , 0.3306 , 0.329  , 0.3289 ,\n",
       "            0.324  , 0.3215 , 0.3213 , 0.321  , 0.3186 , 0.318  , 0.3125 ,\n",
       "            0.3123 , 0.3088 , 0.3086 , 0.308  , 0.3079 , 0.3074 , 0.3071 ,\n",
       "            0.3066 , 0.3047 , 0.3005 , 0.2937 , 0.2913 , 0.29   , 0.2856 ,\n",
       "            0.277  , 0.2744 , 0.2732 , 0.2725 , 0.2666 , 0.2646 , 0.2644 ,\n",
       "            0.2637 , 0.2612 , 0.2603 , 0.2598 , 0.2595 , 0.258  , 0.2563 ,\n",
       "            0.252  , 0.2517 , 0.251  , 0.2449 , 0.2448 , 0.2445 , 0.2444 ,\n",
       "            0.2399 , 0.2338 , 0.2301 , 0.22   , 0.2123 , 0.2053 , 0.1965 ,\n",
       "            0.196  , 0.1853 , 0.183  , 0.1826 , 0.1819 , 0.1797 , 0.1779 ,\n",
       "            0.1775 , 0.1737 , 0.1715 , 0.1694 , 0.167  , 0.1654 , 0.1646 ,\n",
       "            0.1631 , 0.1625 , 0.1582 , 0.1575 , 0.1549 , 0.1477 , 0.1473 ,\n",
       "            0.1464 , 0.146  , 0.1436 , 0.143  , 0.1338 , 0.1302 , 0.1271 ,\n",
       "            0.122  , 0.11554, 0.10614, 0.10504, 0.10156, 0.0981 , 0.0933 ,\n",
       "            0.08167, 0.07306, 0.0666 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.05970149, dtype=float32),\n",
       "    'tpr': array(0.5862069, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.1716418 , 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.24626866,\n",
       "            0.25373134, 0.25373134, 0.26119402, 0.26865673, 0.26865673,\n",
       "            0.2761194 , 0.2761194 , 0.2835821 , 0.2835821 , 0.29850745,\n",
       "            0.29850745, 0.29850745, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.32089552, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3880597 , 0.3880597 , 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6551724 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.899  , 0.888  , 0.8823 , 0.869  , 0.8687 , 0.856  ,\n",
       "            0.854  , 0.8486 , 0.8413 , 0.834  , 0.8325 , 0.8315 , 0.831  ,\n",
       "            0.8223 , 0.817  , 0.8154 , 0.8135 , 0.81   , 0.8027 , 0.792  ,\n",
       "            0.7847 , 0.783  , 0.781  , 0.7803 , 0.779  , 0.7773 , 0.769  ,\n",
       "            0.764  , 0.761  , 0.7583 , 0.749  , 0.746  , 0.7446 , 0.7285 ,\n",
       "            0.7173 , 0.715  , 0.7134 , 0.713  , 0.7114 , 0.7104 , 0.7075 ,\n",
       "            0.707  , 0.6987 , 0.6978 , 0.688  , 0.687  , 0.6772 , 0.643  ,\n",
       "            0.632  , 0.6274 , 0.626  , 0.6235 , 0.621  , 0.6157 , 0.6147 ,\n",
       "            0.611  , 0.5923 , 0.588  , 0.5874 , 0.5806 , 0.565  , 0.561  ,\n",
       "            0.5586 , 0.5576 , 0.554  , 0.553  , 0.5454 , 0.5347 , 0.5303 ,\n",
       "            0.519  , 0.5146 , 0.5137 , 0.5054 , 0.503  , 0.5005 , 0.498  ,\n",
       "            0.4946 , 0.4893 , 0.4866 , 0.486  , 0.4827 , 0.4802 , 0.4768 ,\n",
       "            0.476  , 0.473  , 0.4712 , 0.4705 , 0.465  , 0.4634 , 0.461  ,\n",
       "            0.4585 , 0.458  , 0.4563 , 0.4526 , 0.4521 , 0.4504 , 0.4487 ,\n",
       "            0.4434 , 0.442  , 0.437  , 0.4363 , 0.434  , 0.433  , 0.4321 ,\n",
       "            0.432  , 0.43   , 0.4275 , 0.4216 , 0.4155 , 0.412  , 0.4094 ,\n",
       "            0.4084 , 0.4072 , 0.402  , 0.401  , 0.3992 , 0.3953 , 0.3923 ,\n",
       "            0.3875 , 0.3872 , 0.3855 , 0.3843 , 0.3826 , 0.3774 , 0.3743 ,\n",
       "            0.3735 , 0.3691 , 0.368  , 0.365  , 0.364  , 0.3635 , 0.3633 ,\n",
       "            0.363  , 0.3616 , 0.3599 , 0.359  , 0.3574 , 0.357  , 0.3552 ,\n",
       "            0.3489 , 0.3462 , 0.345  , 0.3433 , 0.3428 , 0.3418 , 0.341  ,\n",
       "            0.3398 , 0.339  , 0.3354 , 0.3306 , 0.3289 , 0.3284 , 0.328  ,\n",
       "            0.3276 , 0.3252 , 0.324  , 0.3237 , 0.3223 , 0.3179 , 0.3176 ,\n",
       "            0.3174 , 0.316  , 0.314  , 0.3076 , 0.3071 , 0.306  , 0.3042 ,\n",
       "            0.3013 , 0.2983 , 0.2937 , 0.2932 , 0.286  , 0.2832 , 0.281  ,\n",
       "            0.2751 , 0.2727 , 0.2717 , 0.265  , 0.2612 , 0.261  , 0.2598 ,\n",
       "            0.2573 , 0.2559 , 0.255  , 0.2542 , 0.2537 , 0.2527 , 0.2483 ,\n",
       "            0.2463 , 0.243  , 0.2379 , 0.2375 , 0.2374 , 0.2366 , 0.2335 ,\n",
       "            0.226  , 0.2197 , 0.2157 , 0.2124 , 0.2042 , 0.193  , 0.1882 ,\n",
       "            0.1782 , 0.1772 , 0.1743 , 0.1737 , 0.1733 , 0.1726 , 0.1715 ,\n",
       "            0.1656 , 0.1643 , 0.1605 , 0.1588 , 0.1586 , 0.1566 , 0.1536 ,\n",
       "            0.1494 , 0.1486 , 0.1484 , 0.1392 , 0.1381 , 0.138  , 0.1367 ,\n",
       "            0.1365 , 0.1361 , 0.12476, 0.12036, 0.1174 , 0.112  , 0.10614,\n",
       "            0.10596, 0.09686, 0.0955 , 0.0922 , 0.089  , 0.08417, 0.0733 ,\n",
       "            0.0655 , 0.05856], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.14925373, dtype=float32),\n",
       "    'tpr': array(0.6465517, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.17910448, 0.17910448,\n",
       "            0.19402985, 0.20149253, 0.20149253, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.25373134, 0.25373134,\n",
       "            0.25373134, 0.25373134, 0.26119402, 0.26119402, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.36567163, 0.36567163, 0.36567163, 0.36567163,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.49253732, 0.5074627 ,\n",
       "            0.5074627 , 0.52238804, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6119403 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.6034483 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.73275864, 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.75      , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.921  , 0.9106 , 0.906  , 0.8936 , 0.893  , 0.881  ,\n",
       "            0.88   , 0.877  , 0.8687 , 0.8623 , 0.8604 , 0.859  , 0.851  ,\n",
       "            0.8447 , 0.8438 , 0.843  , 0.837  , 0.8306 , 0.8228 , 0.8154 ,\n",
       "            0.814  , 0.8105 , 0.809  , 0.8086 , 0.8    , 0.7954 , 0.7925 ,\n",
       "            0.7876 , 0.7793 , 0.775  , 0.774  , 0.7583 , 0.746  , 0.745  ,\n",
       "            0.744  , 0.7427 , 0.742  , 0.7417 , 0.7397 , 0.7305 , 0.7285 ,\n",
       "            0.7153 , 0.715  , 0.6704 , 0.669  , 0.666  , 0.664  , 0.662  ,\n",
       "            0.6606 , 0.651  , 0.6494 , 0.6333 , 0.6294 , 0.6274 , 0.627  ,\n",
       "            0.609  , 0.6074 , 0.6035 , 0.602  , 0.581  , 0.5776 , 0.575  ,\n",
       "            0.573  , 0.558  , 0.5576 , 0.556  , 0.5547 , 0.5464 , 0.5454 ,\n",
       "            0.54   , 0.5312 , 0.531  , 0.529  , 0.525  , 0.524  , 0.5146 ,\n",
       "            0.511  , 0.5093 , 0.509  , 0.5083 , 0.5073 , 0.5063 , 0.5054 ,\n",
       "            0.5015 , 0.501  , 0.4934 , 0.4873 , 0.4832 , 0.4822 , 0.4817 ,\n",
       "            0.4814 , 0.4805 , 0.4749 , 0.4712 , 0.4707 , 0.4702 , 0.466  ,\n",
       "            0.4648 , 0.4644 , 0.4558 , 0.453  , 0.4434 , 0.443  , 0.4414 ,\n",
       "            0.4407 , 0.4382 , 0.4338 , 0.4321 , 0.4316 , 0.4292 , 0.428  ,\n",
       "            0.4275 , 0.4226 , 0.421  , 0.4207 , 0.4182 , 0.4175 , 0.4082 ,\n",
       "            0.4053 , 0.405  , 0.4048 , 0.404  , 0.4023 , 0.3992 , 0.3977 ,\n",
       "            0.3948 , 0.3943 , 0.3928 , 0.3914 , 0.3892 , 0.3887 , 0.3772 ,\n",
       "            0.3767 , 0.374  , 0.3738 , 0.3723 , 0.372  , 0.371  , 0.3704 ,\n",
       "            0.3652 , 0.363  , 0.3628 , 0.357  , 0.3562 , 0.3528 , 0.3513 ,\n",
       "            0.351  , 0.3499 , 0.3481 , 0.348  , 0.3477 , 0.3406 , 0.328  ,\n",
       "            0.3267 , 0.3257 , 0.3254 , 0.322  , 0.3213 , 0.3147 , 0.3113 ,\n",
       "            0.31   , 0.3086 , 0.306  , 0.304  , 0.3035 , 0.2996 , 0.296  ,\n",
       "            0.2947 , 0.2908 , 0.2905 , 0.2761 , 0.264  , 0.2556 , 0.2554 ,\n",
       "            0.2527 , 0.251  , 0.2483 , 0.2482 , 0.2477 , 0.247  , 0.2421 ,\n",
       "            0.2351 , 0.2299 , 0.2297 , 0.2295 , 0.2268 , 0.2244 , 0.2235 ,\n",
       "            0.2125 , 0.1943 , 0.1927 , 0.1787 , 0.1754 , 0.1707 , 0.1683 ,\n",
       "            0.1682 , 0.1648 , 0.164  , 0.1624 , 0.1602 , 0.1534 , 0.1528 ,\n",
       "            0.1505 , 0.1503 , 0.1465 , 0.1434 , 0.1423 , 0.1422 , 0.1396 ,\n",
       "            0.1377 , 0.1317 , 0.1295 , 0.1278 , 0.1265 , 0.1263 , 0.11475,\n",
       "            0.10913, 0.1065 , 0.1011 , 0.0959 , 0.0957 , 0.0866 , 0.0851 ,\n",
       "            0.082  , 0.07904, 0.0742 , 0.0645 , 0.05792, 0.05023],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.21641791, dtype=float32),\n",
       "    'tpr': array(0.67241377, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.1119403 , 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.17910448, 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.25373134, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26119402, 0.26119402, 0.26119402, 0.26119402, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.35820895, 0.35820895, 0.36567163, 0.36567163, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.37313432, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.5948276 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6551724 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8189655 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9355 , 0.9263 , 0.922  , 0.91   , 0.899  , 0.898  ,\n",
       "            0.896  , 0.888  , 0.8823 , 0.8804 , 0.879  , 0.8716 , 0.8657 ,\n",
       "            0.8643 , 0.864  , 0.858  , 0.852  , 0.8447 , 0.8384 , 0.8364 ,\n",
       "            0.8345 , 0.8335 , 0.832  , 0.831  , 0.8228 , 0.8203 , 0.8145 ,\n",
       "            0.8105 , 0.803  , 0.799  , 0.7974 , 0.782  , 0.772  , 0.771  ,\n",
       "            0.7705 , 0.7686 , 0.7676 , 0.7666 , 0.7656 , 0.7637 , 0.763  ,\n",
       "            0.7563 , 0.753  , 0.7446 , 0.739  , 0.7383 , 0.7095 , 0.6978 ,\n",
       "            0.696  , 0.693  , 0.6885 , 0.687  , 0.6753 , 0.674  , 0.664  ,\n",
       "            0.6616 , 0.66   , 0.6577 , 0.6475 , 0.6436 , 0.642  , 0.6396 ,\n",
       "            0.6333 , 0.6123 , 0.6055 , 0.6045 , 0.598  , 0.597  , 0.591  ,\n",
       "            0.5884 , 0.583  , 0.5796 , 0.576  , 0.5703 , 0.5645 , 0.563  ,\n",
       "            0.561  , 0.5596 , 0.557  , 0.5566 , 0.552  , 0.546  , 0.544  ,\n",
       "            0.5405 , 0.5396 , 0.538  , 0.5366 , 0.535  , 0.53   , 0.5273 ,\n",
       "            0.525  , 0.519  , 0.518  , 0.516  , 0.514  , 0.513  , 0.5117 ,\n",
       "            0.5083 , 0.508  , 0.507  , 0.505  , 0.504  , 0.503  , 0.4995 ,\n",
       "            0.4978 , 0.4897 , 0.4834 , 0.482  , 0.4792 , 0.479  , 0.4707 ,\n",
       "            0.4705 , 0.4697 , 0.469  , 0.4683 , 0.4668 , 0.4658 , 0.4653 ,\n",
       "            0.4636 , 0.4595 , 0.4578 , 0.4453 , 0.445  , 0.4424 , 0.4382 ,\n",
       "            0.4375 , 0.4373 , 0.437  , 0.4333 , 0.4297 , 0.429  , 0.4287 ,\n",
       "            0.4285 , 0.4275 , 0.4202 , 0.4194 , 0.415  , 0.414  , 0.4111 ,\n",
       "            0.4102 , 0.407  , 0.4043 , 0.404  , 0.4001 , 0.3984 , 0.3962 ,\n",
       "            0.3955 , 0.3945 , 0.3928 , 0.3914 , 0.3867 , 0.3794 , 0.379  ,\n",
       "            0.3782 , 0.3733 , 0.3726 , 0.3672 , 0.367  , 0.3628 , 0.3584 ,\n",
       "            0.3574 , 0.349  , 0.3408 , 0.3396 , 0.3389 , 0.3357 , 0.3328 ,\n",
       "            0.3323 , 0.332  , 0.3306 , 0.3264 , 0.3154 , 0.3147 , 0.313  ,\n",
       "            0.3125 , 0.303  , 0.2986 , 0.2952 , 0.268  , 0.2656 , 0.2576 ,\n",
       "            0.2537 , 0.252  , 0.2512 , 0.2498 , 0.2477 , 0.2463 , 0.2441 ,\n",
       "            0.244  , 0.2395 , 0.2283 , 0.2256 , 0.2255 , 0.2247 , 0.2224 ,\n",
       "            0.2222 , 0.2106 , 0.1924 , 0.1886 , 0.1731 , 0.172  , 0.1686 ,\n",
       "            0.165  , 0.1617 , 0.1583 , 0.1575 , 0.1561 , 0.1559 , 0.1484 ,\n",
       "            0.146  , 0.1439 , 0.1436 , 0.1393 , 0.1373 , 0.1361 , 0.1349 ,\n",
       "            0.1324 , 0.1304 , 0.1256 , 0.1241 , 0.12366, 0.12036, 0.119  ,\n",
       "            0.1188 , 0.10724, 0.10126, 0.09875, 0.0933 , 0.0883 , 0.088  ,\n",
       "            0.0792 , 0.07764, 0.07465, 0.07184, 0.0672 , 0.05792, 0.05194,\n",
       "            0.04443], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.24626866, dtype=float32),\n",
       "    'tpr': array(0.69827586, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23134328,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.24626866, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.25373134, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.37313432, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.37313432, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.55172414, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9478 , 0.9395 , 0.9355 , 0.9253 , 0.915  , 0.914  ,\n",
       "            0.9126 , 0.905  , 0.9    , 0.8975 , 0.8965 , 0.8896 , 0.8843 ,\n",
       "            0.883  , 0.8823 , 0.877  , 0.871  , 0.8647 , 0.8584 , 0.8564 ,\n",
       "            0.855  , 0.854  , 0.8525 , 0.8516 , 0.844  , 0.842  , 0.8354 ,\n",
       "            0.832  , 0.8247 , 0.8203 , 0.8193 , 0.8037 , 0.796  , 0.7935 ,\n",
       "            0.793  , 0.791  , 0.7905 , 0.789  , 0.787  , 0.786  , 0.785  ,\n",
       "            0.78   , 0.7754 , 0.7695 , 0.7607 , 0.76   , 0.741  , 0.724  ,\n",
       "            0.723  , 0.7183 , 0.713  , 0.707  , 0.6973 , 0.6963 , 0.691  ,\n",
       "            0.69   , 0.687  , 0.6836 , 0.6743 , 0.6694 , 0.664  , 0.66   ,\n",
       "            0.6416 , 0.633  , 0.632  , 0.6265 , 0.619  , 0.6187 , 0.608  ,\n",
       "            0.607  , 0.603  , 0.602  , 0.596  , 0.5923 , 0.5913 , 0.59   ,\n",
       "            0.589  , 0.5854 , 0.584  , 0.5796 , 0.574  , 0.5684 , 0.565  ,\n",
       "            0.561  , 0.56   , 0.559  , 0.5557 , 0.5537 , 0.5503 , 0.545  ,\n",
       "            0.5425 , 0.5415 , 0.539  , 0.537  , 0.5366 , 0.5356 , 0.534  ,\n",
       "            0.5303 , 0.53   , 0.5264 , 0.524  , 0.523  , 0.5205 , 0.5117 ,\n",
       "            0.5107 , 0.5063 , 0.501  , 0.4998 , 0.4993 , 0.4968 , 0.4956 ,\n",
       "            0.495  , 0.4946 , 0.493  , 0.4917 , 0.4895 , 0.4875 , 0.4873 ,\n",
       "            0.469  , 0.4653 , 0.4648 , 0.464  , 0.4604 , 0.455  , 0.4536 ,\n",
       "            0.4521 , 0.4502 , 0.447  , 0.4453 , 0.4426 , 0.4424 , 0.4417 ,\n",
       "            0.4414 , 0.4387 , 0.4375 , 0.4363 , 0.4312 , 0.4282 , 0.428  ,\n",
       "            0.4265 , 0.4238 , 0.4229 , 0.4214 , 0.4192 , 0.4175 , 0.4155 ,\n",
       "            0.41   , 0.4053 , 0.4016 , 0.3992 , 0.398  , 0.395  , 0.3938 ,\n",
       "            0.385  , 0.3826 , 0.3818 , 0.3801 , 0.364  , 0.3591 , 0.356  ,\n",
       "            0.3545 , 0.354  , 0.3513 , 0.3486 , 0.347  , 0.3438 , 0.3352 ,\n",
       "            0.3325 , 0.331  , 0.3308 , 0.3289 , 0.32   , 0.315  , 0.3147 ,\n",
       "            0.3115 , 0.3    , 0.2952 , 0.2744 , 0.271  , 0.2695 , 0.2654 ,\n",
       "            0.2485 , 0.2473 , 0.2471 , 0.2448 , 0.2424 , 0.239  , 0.2388 ,\n",
       "            0.236  , 0.231  , 0.2197 , 0.2194 , 0.2191 , 0.2185 , 0.2166 ,\n",
       "            0.2075 , 0.1912 , 0.181  , 0.17   , 0.1659 , 0.1643 , 0.161  ,\n",
       "            0.1542 , 0.1512 , 0.1509 , 0.1492 , 0.1483 , 0.1432 , 0.1373 ,\n",
       "            0.1367 , 0.1355 , 0.1317 , 0.1312 , 0.1279 , 0.1261 , 0.1245 ,\n",
       "            0.1217 , 0.119  , 0.1184 , 0.1172 , 0.1122 , 0.11066, 0.1097 ,\n",
       "            0.0993 , 0.0925 , 0.0904 , 0.0848 , 0.0804 , 0.0801 , 0.0715 ,\n",
       "            0.06964, 0.0667 , 0.0644 , 0.05975, 0.05136, 0.0461 , 0.03845],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.24626866, dtype=float32),\n",
       "    'tpr': array(0.7241379, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1716418 , 0.1716418 , 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.24626866, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26119402, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.3432836 , 0.35074627, 0.35074627,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.35820895, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.37313432, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.5298507 , 0.53731346, 0.53731346, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.62068963, 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6551724 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.79310346, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.955  , 0.9478 , 0.944  , 0.9346 , 0.926  , 0.924  ,\n",
       "            0.9224 , 0.9155 , 0.91   , 0.909  , 0.908  , 0.907  , 0.901  ,\n",
       "            0.896  , 0.8955 , 0.894  , 0.89   , 0.885  , 0.8765 , 0.87   ,\n",
       "            0.8687 , 0.8667 , 0.866  , 0.865  , 0.857  , 0.853  , 0.8506 ,\n",
       "            0.846  , 0.839  , 0.836  , 0.8345 , 0.8184 , 0.807  , 0.8066 ,\n",
       "            0.8047 , 0.8037 , 0.803  , 0.8022 , 0.8003 , 0.7925 , 0.7896 ,\n",
       "            0.7793 , 0.7754 , 0.775  , 0.7495 , 0.7334 , 0.733  , 0.7285 ,\n",
       "            0.724  , 0.722  , 0.71   , 0.709  , 0.6987 , 0.6953 , 0.6924 ,\n",
       "            0.6816 , 0.6777 , 0.6772 , 0.677  , 0.668  , 0.6484 , 0.6387 ,\n",
       "            0.638  , 0.636  , 0.6284 , 0.625  , 0.6147 , 0.6123 , 0.612  ,\n",
       "            0.609  , 0.601  , 0.597  , 0.5957 , 0.595  , 0.594  , 0.5933 ,\n",
       "            0.59   , 0.5835 , 0.578  , 0.572  , 0.569  , 0.5654 , 0.5645 ,\n",
       "            0.5635 , 0.559  , 0.5576 , 0.554  , 0.5483 , 0.548  , 0.5474 ,\n",
       "            0.542  , 0.5405 , 0.54   , 0.5386 , 0.534  , 0.532  , 0.5303 ,\n",
       "            0.5273 , 0.527  , 0.5234 , 0.516  , 0.5137 , 0.509  , 0.505  ,\n",
       "            0.5034 , 0.5005 , 0.4988 , 0.498  , 0.4978 , 0.4973 , 0.4946 ,\n",
       "            0.4932 , 0.4902 , 0.4897 , 0.4714 , 0.468  , 0.4675 , 0.466  ,\n",
       "            0.4631 , 0.4614 , 0.4575 , 0.4573 , 0.4558 , 0.453  , 0.4521 ,\n",
       "            0.4487 , 0.4473 , 0.4446 , 0.4443 , 0.444  , 0.443  , 0.4412 ,\n",
       "            0.441  , 0.439  , 0.438  , 0.4321 , 0.4297 , 0.4294 , 0.4263 ,\n",
       "            0.4258 , 0.4243 , 0.4229 , 0.421  , 0.4185 , 0.4165 , 0.4094 ,\n",
       "            0.406  , 0.4028 , 0.4    , 0.3984 , 0.3958 , 0.3945 , 0.3867 ,\n",
       "            0.382  , 0.3809 , 0.3782 , 0.3606 , 0.3599 , 0.354  , 0.352  ,\n",
       "            0.3518 , 0.3513 , 0.3508 , 0.3452 , 0.3445 , 0.3428 , 0.3354 ,\n",
       "            0.3303 , 0.3286 , 0.3271 , 0.3267 , 0.315  , 0.309  , 0.3088 ,\n",
       "            0.293  , 0.29   , 0.2686 , 0.2668 , 0.2646 , 0.2598 , 0.2407 ,\n",
       "            0.2394 , 0.2384 , 0.2368 , 0.2339 , 0.2302 , 0.2299 , 0.2281 ,\n",
       "            0.224  , 0.212  , 0.2119 , 0.2114 , 0.2096 , 0.2073 , 0.1993 ,\n",
       "            0.183  , 0.1736 , 0.1619 , 0.158  , 0.1549 , 0.1528 , 0.1448 ,\n",
       "            0.143  , 0.1416 , 0.1415 , 0.1388 , 0.1348 , 0.1287 , 0.1274 ,\n",
       "            0.1263 , 0.1235 , 0.1222 , 0.119  , 0.1174 , 0.11554, 0.1138 ,\n",
       "            0.1103 , 0.1086 , 0.1036 , 0.1021 , 0.10175, 0.09106, 0.0845 ,\n",
       "            0.0823 , 0.07697, 0.0725 , 0.07227, 0.0641 , 0.0627 , 0.05988,\n",
       "            0.05737, 0.0531 , 0.04526, 0.04037, 0.03348], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.26865673, dtype=float32),\n",
       "    'tpr': array(0.75, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.1119403 , 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.1716418 , 0.1716418 , 0.17910448, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23134328, 0.23134328, 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.24626866, 0.24626866, 0.24626866,\n",
       "            0.24626866, 0.25373134, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2761194 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35074627, 0.35074627,\n",
       "            0.35820895, 0.35820895, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.37313432, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9614 , 0.955  , 0.9517 , 0.9434 , 0.943  , 0.935  ,\n",
       "            0.933  , 0.9307 , 0.9253 , 0.9204 , 0.9194 , 0.9185 , 0.9175 ,\n",
       "            0.911  , 0.9077 , 0.9062 , 0.905  , 0.9023 , 0.897  , 0.888  ,\n",
       "            0.8823 , 0.881  , 0.88   , 0.879  , 0.8774 , 0.8696 , 0.8643 ,\n",
       "            0.864  , 0.86   , 0.8525 , 0.8496 , 0.8486 , 0.8325 , 0.821  ,\n",
       "            0.8203 , 0.819  , 0.818  , 0.8174 , 0.817  , 0.8154 , 0.8145 ,\n",
       "            0.8057 , 0.8037 , 0.7915 , 0.7896 , 0.7876 , 0.7617 , 0.7456 ,\n",
       "            0.745  , 0.7407 , 0.737  , 0.7344 , 0.723  , 0.7227 , 0.711  ,\n",
       "            0.7104 , 0.7075 , 0.7036 , 0.6934 , 0.689  , 0.6885 , 0.685  ,\n",
       "            0.679  , 0.6597 , 0.6494 , 0.649  , 0.648  , 0.6396 , 0.6357 ,\n",
       "            0.6353 , 0.625  , 0.622  , 0.619  , 0.6167 , 0.6113 , 0.6064 ,\n",
       "            0.6055 , 0.605  , 0.6035 , 0.6025 , 0.5996 , 0.599  , 0.5986 ,\n",
       "            0.5938 , 0.587  , 0.5806 , 0.577  , 0.5737 , 0.5723 , 0.5713 ,\n",
       "            0.5674 , 0.5654 , 0.563  , 0.557  , 0.556  , 0.555  , 0.55   ,\n",
       "            0.548  , 0.5474 , 0.5464 , 0.541  , 0.54   , 0.538  , 0.535  ,\n",
       "            0.5337 , 0.5303 , 0.525  , 0.52   , 0.5156 , 0.515  , 0.513  ,\n",
       "            0.5127 , 0.5117 , 0.509  , 0.506  , 0.5044 , 0.504  , 0.503  ,\n",
       "            0.5015 , 0.4976 , 0.4956 , 0.4773 , 0.475  , 0.4746 , 0.4714 ,\n",
       "            0.47   , 0.4663 , 0.464  , 0.4636 , 0.4617 , 0.4575 , 0.4573 ,\n",
       "            0.4534 , 0.4521 , 0.4497 , 0.4495 , 0.4492 , 0.4482 , 0.448  ,\n",
       "            0.4443 , 0.443  , 0.4424 , 0.4353 , 0.435  , 0.4326 , 0.43   ,\n",
       "            0.4294 , 0.428  , 0.4268 , 0.423  , 0.4211 , 0.4133 , 0.41   ,\n",
       "            0.408  , 0.404  , 0.4023 , 0.4004 , 0.3992 , 0.3936 , 0.386  ,\n",
       "            0.3838 , 0.3804 , 0.3652 , 0.3586 , 0.3572 , 0.3552 , 0.3545 ,\n",
       "            0.354  , 0.3472 , 0.3464 , 0.3396 , 0.3394 , 0.3345 , 0.3323 ,\n",
       "            0.33   , 0.3235 , 0.3223 , 0.3137 , 0.3125 , 0.3047 , 0.304  ,\n",
       "            0.286  , 0.2825 , 0.27   , 0.2678 , 0.2612 , 0.259  , 0.2344 ,\n",
       "            0.233  , 0.231  , 0.2302 , 0.2255 , 0.2218 , 0.2217 , 0.2213 ,\n",
       "            0.2205 , 0.2051 , 0.2032 , 0.2031 , 0.2009 , 0.1989 , 0.1929 ,\n",
       "            0.178  , 0.1644 , 0.1561 , 0.1525 , 0.1466 , 0.1461 , 0.1365 ,\n",
       "            0.1364 , 0.1333 , 0.1327 , 0.1306 , 0.1283 , 0.1197 , 0.1196 ,\n",
       "            0.11816, 0.11694, 0.11395, 0.111  , 0.10876, 0.1076 , 0.10504,\n",
       "            0.10376, 0.1034 , 0.10175, 0.0957 , 0.09436, 0.0935 , 0.08344,\n",
       "            0.07654, 0.07477, 0.0695 , 0.0656 , 0.06537, 0.0575 , 0.05594,\n",
       "            0.0533 , 0.05118, 0.0471 , 0.04   , 0.03583, 0.02893],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.2835821, dtype=float32),\n",
       "    'tpr': array(0.7586207, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.12686567, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.23880596, 0.23880596,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26119402, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.2835821 , 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.35820895, 0.36567163,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.79850745,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62068963, 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9683 , 0.963  , 0.96   , 0.9526 , 0.952  , 0.9453 ,\n",
       "            0.944  , 0.9414 , 0.9365 , 0.9316 , 0.931  , 0.93   , 0.929  ,\n",
       "            0.924  , 0.921  , 0.9194 , 0.918  , 0.916  , 0.9106 , 0.9023 ,\n",
       "            0.897  , 0.8955 , 0.895  , 0.8936 , 0.8926 , 0.892  , 0.885  ,\n",
       "            0.8804 , 0.88   , 0.8765 , 0.8687 , 0.8677 , 0.8647 , 0.85   ,\n",
       "            0.84   , 0.8384 , 0.8374 , 0.8364 , 0.836  , 0.8354 , 0.835  ,\n",
       "            0.8335 , 0.833  , 0.824  , 0.8223 , 0.811  , 0.8086 , 0.807  ,\n",
       "            0.787  , 0.768  , 0.766  , 0.7617 , 0.758  , 0.755  , 0.7437 ,\n",
       "            0.7427 , 0.735  , 0.733  , 0.73   , 0.726  , 0.7183 , 0.714  ,\n",
       "            0.713  , 0.7056 , 0.702  , 0.6846 , 0.6787 , 0.673  , 0.6694 ,\n",
       "            0.661  , 0.66   , 0.6465 , 0.6426 , 0.6357 , 0.6343 , 0.632  ,\n",
       "            0.6313 , 0.6294 , 0.6274 , 0.627  , 0.6235 , 0.623  , 0.621  ,\n",
       "            0.614  , 0.6055 , 0.5996 , 0.594  , 0.5938 , 0.5933 , 0.5913 ,\n",
       "            0.5884 , 0.5874 , 0.582  , 0.573  , 0.572  , 0.5703 , 0.569  ,\n",
       "            0.565  , 0.5645 , 0.5605 , 0.557  , 0.556  , 0.5547 , 0.554  ,\n",
       "            0.5513 , 0.545  , 0.5415 , 0.5405 , 0.539  , 0.5386 , 0.537  ,\n",
       "            0.5366 , 0.531  , 0.5303 , 0.5264 , 0.5244 , 0.523  , 0.518  ,\n",
       "            0.516  , 0.501  , 0.5    , 0.4993 , 0.4949 , 0.4915 , 0.489  ,\n",
       "            0.4878 , 0.484  , 0.4824 , 0.4814 , 0.4788 , 0.4773 , 0.4766 ,\n",
       "            0.4746 , 0.4731 , 0.4717 , 0.4714 , 0.4702 , 0.4688 , 0.4653 ,\n",
       "            0.464  , 0.459  , 0.4575 , 0.4517 , 0.4512 , 0.451  , 0.4495 ,\n",
       "            0.4478 , 0.4456 , 0.4429 , 0.4412 , 0.4316 , 0.4302 , 0.4277 ,\n",
       "            0.423  , 0.421  , 0.4204 , 0.4197 , 0.4194 , 0.4043 , 0.3997 ,\n",
       "            0.3938 , 0.3877 , 0.3745 , 0.3735 , 0.3718 , 0.3696 , 0.3677 ,\n",
       "            0.3645 , 0.363  , 0.3596 , 0.3523 , 0.3494 , 0.347  , 0.3416 ,\n",
       "            0.3298 , 0.327  , 0.3247 , 0.321  , 0.3066 , 0.3052 , 0.2869 ,\n",
       "            0.2856 , 0.282  , 0.2761 , 0.2664 , 0.2642 , 0.2323 , 0.231  ,\n",
       "            0.2295 , 0.2261 , 0.2225 , 0.2216 , 0.2184 , 0.2179 , 0.2173 ,\n",
       "            0.2028 , 0.1995 , 0.1993 , 0.1962 , 0.1937 , 0.1901 , 0.1765 ,\n",
       "            0.1597 , 0.153  , 0.1494 , 0.1426 , 0.1399 , 0.1313 , 0.13   ,\n",
       "            0.1273 , 0.127  , 0.1242 , 0.12317, 0.1134 , 0.11163, 0.1074 ,\n",
       "            0.1043 , 0.1023 , 0.1011 , 0.0991 , 0.0977 , 0.0972 , 0.0957 ,\n",
       "            0.0893 , 0.0879 , 0.0876 , 0.07684, 0.0703 , 0.0683 , 0.06335,\n",
       "            0.05954, 0.0592 , 0.05176, 0.05032, 0.04788, 0.04578, 0.04193,\n",
       "            0.03528, 0.03143, 0.02513], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.30597016, dtype=float32),\n",
       "    'tpr': array(0.7844828, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23134328, 0.23880596, 0.23880596,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26119402, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2761194 , 0.2835821 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 , 0.5948276 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.6465517 , 0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9736 , 0.969  , 0.9663 , 0.96   , 0.9536 , 0.952  ,\n",
       "            0.949  , 0.9453 , 0.941  , 0.94   , 0.939  , 0.9336 , 0.931  ,\n",
       "            0.929  , 0.9287 , 0.927  , 0.922  , 0.914  , 0.9087 , 0.9077 ,\n",
       "            0.906  , 0.905  , 0.904  , 0.8975 , 0.894  , 0.8926 , 0.89   ,\n",
       "            0.8823 , 0.879  , 0.865  , 0.856  , 0.853  , 0.8525 , 0.852  ,\n",
       "            0.851  , 0.8506 , 0.849  , 0.848  , 0.8394 , 0.838  , 0.8267 ,\n",
       "            0.8247 , 0.823  , 0.8047 , 0.7856 , 0.7827 , 0.778  , 0.775  ,\n",
       "            0.7725 , 0.761  , 0.7603 , 0.753  , 0.75   , 0.747  , 0.7427 ,\n",
       "            0.7373 , 0.7324 , 0.7305 , 0.72   , 0.7197 , 0.7026 , 0.6978 ,\n",
       "            0.69   , 0.6865 , 0.6787 , 0.678  , 0.6777 , 0.664  , 0.663  ,\n",
       "            0.6597 , 0.655  , 0.6514 , 0.6494 , 0.6484 , 0.648  , 0.6465 ,\n",
       "            0.644  , 0.642  , 0.6406 , 0.6377 , 0.6313 , 0.6226 , 0.6157 ,\n",
       "            0.6104 , 0.6094 , 0.6084 , 0.605  , 0.603  , 0.599  , 0.5894 ,\n",
       "            0.588  , 0.586  , 0.584  , 0.5806 , 0.5786 , 0.5747 , 0.572  ,\n",
       "            0.571  , 0.5703 , 0.57   , 0.566  , 0.562  , 0.5566 , 0.5557 ,\n",
       "            0.5527 , 0.5522 , 0.5513 , 0.546  , 0.544  , 0.5396 , 0.539  ,\n",
       "            0.537  , 0.5366 , 0.5303 , 0.5293 , 0.5146 , 0.5137 , 0.511  ,\n",
       "            0.5083 , 0.503  , 0.502  , 0.5005 , 0.496  , 0.4944 , 0.4937 ,\n",
       "            0.4888 , 0.4885 , 0.4883 , 0.4846 , 0.483  , 0.4822 , 0.4814 ,\n",
       "            0.4795 , 0.4766 , 0.4753 , 0.4722 , 0.469  , 0.4639 , 0.462  ,\n",
       "            0.4604 , 0.457  , 0.4553 , 0.455  , 0.4531 , 0.4512 , 0.441  ,\n",
       "            0.4368 , 0.4326 , 0.4321 , 0.4312 , 0.4297 , 0.4294 , 0.413  ,\n",
       "            0.408  , 0.4011 , 0.3982 , 0.382  , 0.3818 , 0.38   , 0.3772 ,\n",
       "            0.3748 , 0.3723 , 0.37   , 0.3687 , 0.3677 , 0.3604 , 0.3564 ,\n",
       "            0.354  , 0.3408 , 0.3367 , 0.328  , 0.3245 , 0.324  , 0.3064 ,\n",
       "            0.3035 , 0.2927 , 0.283  , 0.279  , 0.2783 , 0.2686 , 0.2632 ,\n",
       "            0.2285 , 0.2269 , 0.2261 , 0.2207 , 0.2203 , 0.2163 , 0.2129 ,\n",
       "            0.2125 , 0.2113 , 0.1987 , 0.194  , 0.1937 , 0.1904 , 0.1873 ,\n",
       "            0.1858 , 0.1729 , 0.1534 , 0.1484 , 0.1453 , 0.1378 , 0.1328 ,\n",
       "            0.1259 , 0.1232 , 0.12054, 0.1201 , 0.1178 , 0.1174 , 0.1069 ,\n",
       "            0.1063 , 0.10486, 0.1007 , 0.0977 , 0.0957 , 0.0945 , 0.0925 ,\n",
       "            0.09186, 0.09125, 0.0898 , 0.0828 , 0.08167, 0.08136, 0.07056,\n",
       "            0.0642 , 0.06244, 0.0576 , 0.054  , 0.0537 , 0.04663, 0.0452 ,\n",
       "            0.04282, 0.04092, 0.03732, 0.0312 , 0.0278 , 0.02177],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.35820895, dtype=float32),\n",
       "    'tpr': array(0.87068963, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.08208955, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.1119403 , 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.19402985, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23880596, 0.23880596,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.26865673, 0.26865673,\n",
       "            0.2761194 , 0.2761194 , 0.2835821 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.35820895, 0.35820895, 0.36567163, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.54310346, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.69827586, 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9785 , 0.9746 , 0.972  , 0.967  , 0.9663 , 0.961  ,\n",
       "            0.9595 , 0.9575 , 0.953  , 0.9497 , 0.9487 , 0.9478 , 0.943  ,\n",
       "            0.941  , 0.939  , 0.9385 , 0.9365 , 0.932  , 0.9253 , 0.9204 ,\n",
       "            0.92   , 0.9194 , 0.918  , 0.917  , 0.9165 , 0.91   , 0.9067 ,\n",
       "            0.9062 , 0.903  , 0.896  , 0.8955 , 0.8926 , 0.88   , 0.8706 ,\n",
       "            0.8687 , 0.8677 , 0.867  , 0.8667 , 0.8657 , 0.865  , 0.864  ,\n",
       "            0.8564 , 0.855  , 0.8457 , 0.842  , 0.84   , 0.831  , 0.81   ,\n",
       "            0.8037 , 0.799  , 0.795  , 0.7896 , 0.781  , 0.7803 , 0.779  ,\n",
       "            0.774  , 0.7715 , 0.7666 , 0.766  , 0.761  , 0.757  , 0.745  ,\n",
       "            0.735  , 0.733  , 0.7324 , 0.716  , 0.7085 , 0.707  , 0.706  ,\n",
       "            0.7007 , 0.694  , 0.692  , 0.6875 , 0.6846 , 0.6826 , 0.679  ,\n",
       "            0.6787 , 0.6743 , 0.674  , 0.6714 , 0.6646 , 0.6636 , 0.66   ,\n",
       "            0.654  , 0.6465 , 0.645  , 0.6445 , 0.6426 , 0.6357 , 0.6353 ,\n",
       "            0.635  , 0.6323 , 0.63   , 0.6206 , 0.62   , 0.6157 , 0.612  ,\n",
       "            0.6104 , 0.61   , 0.607  , 0.6055 , 0.601  , 0.599  , 0.5967 ,\n",
       "            0.595  , 0.594  , 0.5938 , 0.593  , 0.5913 , 0.586  , 0.583  ,\n",
       "            0.5796 , 0.5776 , 0.577  , 0.5713 , 0.57   , 0.5693 , 0.5684 ,\n",
       "            0.5566 , 0.551  , 0.5493 , 0.547  , 0.5435 , 0.542  , 0.538  ,\n",
       "            0.537  , 0.536  , 0.5347 , 0.5312 , 0.5273 , 0.5264 , 0.522  ,\n",
       "            0.517  , 0.5156 , 0.5137 , 0.511  , 0.5107 , 0.509  , 0.5083 ,\n",
       "            0.507  , 0.505  , 0.5044 , 0.501  , 0.4995 , 0.493  , 0.4917 ,\n",
       "            0.4822 , 0.48   , 0.477  , 0.4736 , 0.4722 , 0.4712 , 0.4656 ,\n",
       "            0.463  , 0.462  , 0.4612 , 0.4607 , 0.4595 , 0.4563 , 0.4404 ,\n",
       "            0.4321 , 0.4216 , 0.41   , 0.4082 , 0.4072 , 0.4006 , 0.3997 ,\n",
       "            0.3987 , 0.3967 , 0.3943 , 0.388  , 0.3826 , 0.3801 , 0.3757 ,\n",
       "            0.3633 , 0.342  , 0.3372 , 0.334  , 0.327  , 0.3196 , 0.3123 ,\n",
       "            0.305  , 0.2942 , 0.2832 , 0.2776 , 0.2708 , 0.2286 , 0.2281 ,\n",
       "            0.2277 , 0.2274 , 0.2177 , 0.2134 , 0.211  , 0.2095 , 0.2085 ,\n",
       "            0.1996 , 0.1898 , 0.1897 , 0.1865 , 0.186  , 0.1841 , 0.1758 ,\n",
       "            0.1486 , 0.1483 , 0.1458 , 0.1368 , 0.1279 , 0.1235 , 0.1188 ,\n",
       "            0.1158 , 0.11536, 0.11475, 0.1128 , 0.1036 , 0.10266, 0.10156,\n",
       "            0.0998 , 0.0959 , 0.0927 , 0.0901 , 0.0896 , 0.0883 , 0.0874 ,\n",
       "            0.0869 , 0.086  , 0.07794, 0.07654, 0.076  , 0.06573, 0.0589 ,\n",
       "            0.0575 , 0.0526 , 0.0496 , 0.04922, 0.0424 , 0.04083, 0.0386 ,\n",
       "            0.0369 , 0.0334 , 0.02791, 0.02489, 0.01898], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.36567163, dtype=float32),\n",
       "    'tpr': array(0.8965517, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.1716418 , 0.1716418 ,\n",
       "            0.1716418 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20149253, 0.20895523, 0.20895523, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.24626866, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2761194 , 0.2761194 , 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.3283582 , 0.33582088, 0.33582088,\n",
       "            0.33582088, 0.33582088, 0.3432836 , 0.35074627, 0.35074627,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.62068963, 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.69827586, 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8362069 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.982  , 0.978  , 0.976  , 0.971  , 0.9707 , 0.966  ,\n",
       "            0.965  , 0.9624 , 0.959  , 0.9556 , 0.955  , 0.954  , 0.9497 ,\n",
       "            0.9478 , 0.946  , 0.9453 , 0.944  , 0.94   , 0.9326 , 0.928  ,\n",
       "            0.9272 , 0.9263 , 0.9253 , 0.9243 , 0.919  , 0.916  , 0.9146 ,\n",
       "            0.912  , 0.9062 , 0.9053 , 0.902  , 0.89   , 0.882  , 0.879  ,\n",
       "            0.8784 , 0.877  , 0.8765 , 0.875  , 0.8745 , 0.867  , 0.865  ,\n",
       "            0.857  , 0.8525 , 0.85   , 0.846  , 0.8237 , 0.8154 , 0.811  ,\n",
       "            0.8066 , 0.8013 , 0.794  , 0.793  , 0.7925 , 0.787  , 0.785  ,\n",
       "            0.7827 , 0.78   , 0.778  , 0.7715 , 0.76   , 0.754  , 0.749  ,\n",
       "            0.745  , 0.7305 , 0.724  , 0.7217 , 0.721  , 0.715  , 0.7134 ,\n",
       "            0.711  , 0.707  , 0.7026 , 0.702  , 0.701  , 0.697  , 0.6943 ,\n",
       "            0.692  , 0.691  , 0.689  , 0.6846 , 0.6777 , 0.674  , 0.6724 ,\n",
       "            0.669  , 0.667  , 0.662  , 0.6616 , 0.652  , 0.651  , 0.65   ,\n",
       "            0.649  , 0.645  , 0.64   , 0.6377 , 0.636  , 0.6357 , 0.6333 ,\n",
       "            0.631  , 0.625  , 0.621  , 0.6206 , 0.618  , 0.6177 , 0.616  ,\n",
       "            0.613  , 0.6123 , 0.61   , 0.607  , 0.606  , 0.604  , 0.6025 ,\n",
       "            0.5986 , 0.596  , 0.594  , 0.591  , 0.589  , 0.5884 , 0.575  ,\n",
       "            0.574  , 0.5737 , 0.5674 , 0.567  , 0.5654 , 0.562  , 0.5605 ,\n",
       "            0.5576 , 0.554  , 0.5527 , 0.549  , 0.5483 , 0.5444 , 0.537  ,\n",
       "            0.5356 , 0.534  , 0.5303 , 0.528  , 0.5264 , 0.5254 , 0.525  ,\n",
       "            0.5244 , 0.523  , 0.5225 , 0.5137 , 0.513  , 0.5127 , 0.501  ,\n",
       "            0.4995 , 0.4993 , 0.496  , 0.4888 , 0.4827 , 0.481  , 0.48   ,\n",
       "            0.4797 , 0.4792 , 0.4778 , 0.4739 , 0.4604 , 0.459  , 0.457  ,\n",
       "            0.446  , 0.4321 , 0.4297 , 0.426  , 0.425  , 0.422  , 0.417  ,\n",
       "            0.4158 , 0.4102 , 0.4092 , 0.408  , 0.4006 , 0.398  , 0.382  ,\n",
       "            0.3757 , 0.3423 , 0.3396 , 0.337  , 0.3325 , 0.322  , 0.3115 ,\n",
       "            0.3025 , 0.2996 , 0.2913 , 0.277  , 0.271  , 0.2295 , 0.2242 ,\n",
       "            0.224  , 0.223  , 0.2108 , 0.2058 , 0.2048 , 0.202  , 0.2017 ,\n",
       "            0.1959 , 0.1821 , 0.182  , 0.1788 , 0.1771 , 0.1741 , 0.1453 ,\n",
       "            0.1431 , 0.1407 , 0.1328 , 0.1207 , 0.1188 , 0.112  , 0.11084,\n",
       "            0.10913, 0.10706, 0.1063 , 0.0986 , 0.0967 , 0.0945 , 0.0933 ,\n",
       "            0.0893 , 0.0863 , 0.08344, 0.0823 , 0.08093, 0.0802 , 0.07184,\n",
       "            0.0703 , 0.06964, 0.0602 , 0.0533 , 0.05203, 0.04733, 0.04468,\n",
       "            0.04428, 0.03796, 0.0363 , 0.03424, 0.03284, 0.02942, 0.02461,\n",
       "            0.02199, 0.01634], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3880597, dtype=float32),\n",
       "    'tpr': array(0.92241377, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.1716418 , 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23134328, 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2761194 , 0.2835821 ,\n",
       "            0.2835821 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35074627, 0.35074627,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5597015 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.35344827, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43965518, 0.44827586, 0.44827586,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.4827586 , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.55172414, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.69827586, 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.7241379 , 0.7241379 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.985  , 0.982  , 0.98   , 0.976  , 0.9756 , 0.9717 ,\n",
       "            0.97   , 0.9683 , 0.965  , 0.962  , 0.9604 , 0.9565 , 0.9556 ,\n",
       "            0.953  , 0.9526 , 0.952  , 0.948  , 0.941  , 0.9375 , 0.937  ,\n",
       "            0.936  , 0.935  , 0.9346 , 0.933  , 0.9287 , 0.9263 , 0.9243 ,\n",
       "            0.923  , 0.9175 , 0.916  , 0.913  , 0.9014 , 0.894  , 0.891  ,\n",
       "            0.8906 , 0.889  , 0.887  , 0.8794 , 0.8774 , 0.87   , 0.866  ,\n",
       "            0.8633 , 0.8623 , 0.8394 , 0.83   , 0.826  , 0.822  , 0.8154 ,\n",
       "            0.8105 , 0.8076 , 0.8037 , 0.802  , 0.8003 , 0.796  , 0.789  ,\n",
       "            0.777  , 0.7754 , 0.7676 , 0.758  , 0.748  , 0.743  , 0.74   ,\n",
       "            0.739  , 0.7373 , 0.7305 , 0.73   , 0.7266 , 0.7227 , 0.721  ,\n",
       "            0.7183 , 0.7163 , 0.713  , 0.711  , 0.71   , 0.7085 , 0.7056 ,\n",
       "            0.6997 , 0.6953 , 0.693  , 0.6924 , 0.6826 , 0.6807 , 0.6777 ,\n",
       "            0.6743 , 0.6685 , 0.668  , 0.666  , 0.664  , 0.663  , 0.6626 ,\n",
       "            0.6577 , 0.6523 , 0.646  , 0.6455 , 0.643  , 0.6426 , 0.639  ,\n",
       "            0.637  , 0.631  , 0.629  , 0.628  , 0.623  , 0.621  , 0.6206 ,\n",
       "            0.6196 , 0.617  , 0.615  , 0.6094 , 0.6084 , 0.6074 , 0.5996 ,\n",
       "            0.5977 , 0.595  , 0.5938 , 0.593  , 0.591  , 0.584  , 0.582  ,\n",
       "            0.58   , 0.5786 , 0.5693 , 0.568  , 0.567  , 0.563  , 0.5547 ,\n",
       "            0.5503 , 0.549  , 0.5474 , 0.547  , 0.545  , 0.5444 , 0.5425 ,\n",
       "            0.54   , 0.5347 , 0.5337 , 0.5273 , 0.5205 , 0.5186 , 0.518  ,\n",
       "            0.504  , 0.5034 , 0.5005 , 0.4983 , 0.4973 , 0.4922 , 0.4888 ,\n",
       "            0.4814 , 0.4778 , 0.4636 , 0.4626 , 0.4495 , 0.446  , 0.4448 ,\n",
       "            0.4446 , 0.4429 , 0.4358 , 0.4324 , 0.4282 , 0.4275 , 0.4243 ,\n",
       "            0.42   , 0.4167 , 0.4023 , 0.3801 , 0.361  , 0.351  , 0.3354 ,\n",
       "            0.3347 , 0.3213 , 0.3142 , 0.3137 , 0.3022 , 0.298  , 0.2744 ,\n",
       "            0.2673 , 0.2334 , 0.2233 , 0.2218 , 0.2211 , 0.206  , 0.2009 ,\n",
       "            0.2007 , 0.197  , 0.1968 , 0.1943 , 0.1803 , 0.1765 , 0.1764 ,\n",
       "            0.1744 , 0.1733 , 0.172  , 0.1437 , 0.1422 , 0.1346 , 0.1305 ,\n",
       "            0.11536, 0.115  , 0.1076 , 0.1067 , 0.10394, 0.1011 , 0.1007 ,\n",
       "            0.09485, 0.09186, 0.0888 , 0.088  , 0.08405, 0.08105, 0.07965,\n",
       "            0.0785 , 0.07825, 0.0775 , 0.0771 , 0.0745 , 0.0666 , 0.0651 ,\n",
       "            0.0643 , 0.0555 , 0.0484 , 0.04752, 0.04282, 0.04062, 0.04016,\n",
       "            0.03418, 0.03247, 0.0305 , 0.02937, 0.02606, 0.02182, 0.0196 ,\n",
       "            0.01406], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.41044775, dtype=float32),\n",
       "    'tpr': array(0.9310345, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23134328, 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.26119402, 0.26119402, 0.26865673, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.32089552, 0.32089552, 0.3283582 ,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.4224138 , 0.43103448, 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.55172414, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.7241379 , 0.7241379 , 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8534483 , 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9873 , 0.985  , 0.983  , 0.9795 , 0.979  , 0.9756 ,\n",
       "            0.9746 , 0.9727 , 0.9697 , 0.9673 , 0.967  , 0.966  , 0.962  ,\n",
       "            0.9614 , 0.959  , 0.9585 , 0.9546 , 0.9478 , 0.9453 , 0.944  ,\n",
       "            0.9434 , 0.9424 , 0.942  , 0.94   , 0.936  , 0.9346 , 0.9316 ,\n",
       "            0.931  , 0.927  , 0.925  , 0.922  , 0.911  , 0.9043 , 0.902  ,\n",
       "            0.901  , 0.9004 , 0.899  , 0.8984 , 0.8975 , 0.897  , 0.889  ,\n",
       "            0.888  , 0.8804 , 0.877  , 0.874  , 0.8735 , 0.851  , 0.842  ,\n",
       "            0.838  , 0.8335 , 0.828  , 0.823  , 0.8203 , 0.82   , 0.816  ,\n",
       "            0.8145 , 0.814  , 0.809  , 0.8086 , 0.802  , 0.7905 , 0.7896 ,\n",
       "            0.7812 , 0.771  , 0.761  , 0.757  , 0.754  , 0.75   , 0.7485 ,\n",
       "            0.7446 , 0.744  , 0.7427 , 0.7383 , 0.7344 , 0.7314 , 0.731  ,\n",
       "            0.7266 , 0.7256 , 0.7246 , 0.7236 , 0.721  , 0.719  , 0.711  ,\n",
       "            0.7085 , 0.7075 , 0.698  , 0.695  , 0.692  , 0.689  , 0.684  ,\n",
       "            0.6816 , 0.6797 , 0.679  , 0.677  , 0.6724 , 0.6694 , 0.667  ,\n",
       "            0.665  , 0.6646 , 0.662  , 0.6587 , 0.6562 , 0.652  , 0.642  ,\n",
       "            0.6416 , 0.639  , 0.6377 , 0.6357 , 0.635  , 0.632  , 0.6304 ,\n",
       "            0.626  , 0.625  , 0.6245 , 0.62   , 0.6177 , 0.615  , 0.6147 ,\n",
       "            0.6084 , 0.6074 , 0.6016 , 0.598  , 0.5977 , 0.597  , 0.5854 ,\n",
       "            0.5835 , 0.583  , 0.582  , 0.5757 , 0.5703 , 0.5693 , 0.5664 ,\n",
       "            0.5654 , 0.5625 , 0.562  , 0.561  , 0.5605 , 0.556  , 0.5503 ,\n",
       "            0.5493 , 0.549  , 0.5474 , 0.5356 , 0.5347 , 0.5337 , 0.519  ,\n",
       "            0.5156 , 0.5137 , 0.5127 , 0.5107 , 0.5103 , 0.506  , 0.4993 ,\n",
       "            0.4956 , 0.4917 , 0.473  , 0.468  , 0.4644 , 0.4607 , 0.4587 ,\n",
       "            0.455  , 0.4536 , 0.4495 , 0.4426 , 0.438  , 0.433  , 0.4297 ,\n",
       "            0.4158 , 0.3813 , 0.3745 , 0.3542 , 0.3347 , 0.3345 , 0.319  ,\n",
       "            0.3186 , 0.313  , 0.306  , 0.295  , 0.2732 , 0.271  , 0.2644 ,\n",
       "            0.2322 , 0.2195 , 0.2175 , 0.217  , 0.2007 , 0.1954 , 0.1953 ,\n",
       "            0.1915 , 0.1913 , 0.1901 , 0.1758 , 0.1719 , 0.1718 , 0.171  ,\n",
       "            0.1676 , 0.1663 , 0.1395 , 0.1383 , 0.13   , 0.126  , 0.1103 ,\n",
       "            0.1095 , 0.10284, 0.1011 , 0.09845, 0.0959 , 0.0955 , 0.0898 ,\n",
       "            0.0866 , 0.08386, 0.0828 , 0.0789 , 0.076  , 0.07477, 0.0734 ,\n",
       "            0.0725 , 0.07227, 0.07007, 0.06165, 0.0602 , 0.0601 , 0.051  ,\n",
       "            0.04434, 0.04337, 0.03906, 0.03683, 0.03644, 0.03079, 0.02925,\n",
       "            0.02744, 0.02626, 0.02328, 0.01935, 0.0173 , 0.01234],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.42537314, dtype=float32),\n",
       "    'tpr': array(0.9396552, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.10447761, 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.21641791, 0.21641791, 0.21641791, 0.23134328, 0.23880596,\n",
       "            0.23880596, 0.24626866, 0.24626866, 0.24626866, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2761194 , 0.2835821 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.3283582 , 0.3283582 ,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.47761193, 0.47761193, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.7758621 , 0.7758621 , 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9897 , 0.9873 , 0.986  , 0.9824 , 0.979  , 0.978  ,\n",
       "            0.9766 , 0.974  , 0.9717 , 0.971  , 0.97   , 0.9673 , 0.967  ,\n",
       "            0.9644 , 0.964  , 0.9604 , 0.954  , 0.9517 , 0.9507 , 0.9497 ,\n",
       "            0.949  , 0.9487 , 0.9473 , 0.9434 , 0.9424 , 0.9395 , 0.939  ,\n",
       "            0.9355 , 0.9326 , 0.93   , 0.9204 , 0.914  , 0.912  , 0.911  ,\n",
       "            0.9097 , 0.909  , 0.9087 , 0.9077 , 0.907  , 0.8994 , 0.8984 ,\n",
       "            0.8926 , 0.8896 , 0.888  , 0.8857 , 0.8667 , 0.856  , 0.852  ,\n",
       "            0.8477 , 0.8413 , 0.841  , 0.8345 , 0.834  , 0.833  , 0.832  ,\n",
       "            0.831  , 0.8286 , 0.825  , 0.82   , 0.816  , 0.8076 , 0.8022 ,\n",
       "            0.7866 , 0.7847 , 0.7803 , 0.7783 , 0.775  , 0.767  , 0.7666 ,\n",
       "            0.7637 , 0.76   , 0.755  , 0.7524 , 0.75   , 0.7495 , 0.7476 ,\n",
       "            0.747  , 0.741  , 0.7324 , 0.7285 , 0.726  , 0.7207 , 0.7183 ,\n",
       "            0.7153 , 0.708  , 0.703  , 0.701  , 0.7    , 0.699  , 0.698  ,\n",
       "            0.6973 , 0.6963 , 0.6934 , 0.6914 , 0.678  , 0.668  , 0.667  ,\n",
       "            0.666  , 0.662  , 0.658  , 0.6567 , 0.656  , 0.6543 , 0.654  ,\n",
       "            0.6533 , 0.6523 , 0.652  , 0.651  , 0.65   , 0.6484 , 0.646  ,\n",
       "            0.641  , 0.6343 , 0.6333 , 0.6294 , 0.6265 , 0.6187 , 0.615  ,\n",
       "            0.6094 , 0.601  , 0.6    , 0.5967 , 0.594  , 0.5923 , 0.592  ,\n",
       "            0.5913 , 0.591  , 0.5894 , 0.589  , 0.5874 , 0.5815 , 0.581  ,\n",
       "            0.58   , 0.5674 , 0.567  , 0.564  , 0.562  , 0.5537 , 0.55   ,\n",
       "            0.5464 , 0.541  , 0.5366 , 0.5356 , 0.5347 , 0.534  , 0.5327 ,\n",
       "            0.52   , 0.509  , 0.496  , 0.4949 , 0.4878 , 0.4814 , 0.4785 ,\n",
       "            0.4739 , 0.4731 , 0.4666 , 0.463  , 0.461  , 0.4575 , 0.4548 ,\n",
       "            0.4453 , 0.406  , 0.3884 , 0.3677 , 0.3396 , 0.3357 , 0.3345 ,\n",
       "            0.3225 , 0.32   , 0.3184 , 0.2952 , 0.2803 , 0.2703 , 0.2622 ,\n",
       "            0.2399 , 0.2207 , 0.217  , 0.2167 , 0.1979 , 0.193  , 0.1918 ,\n",
       "            0.1907 , 0.1884 , 0.1879 , 0.1759 , 0.1738 , 0.1676 , 0.1675 ,\n",
       "            0.1635 , 0.1627 , 0.1403 , 0.139  , 0.1252 , 0.12494, 0.108  ,\n",
       "            0.10504, 0.1005 , 0.09686, 0.09436, 0.0914 , 0.09076, 0.0866 ,\n",
       "            0.0828 , 0.0792 , 0.0786 , 0.07477, 0.07184, 0.0716 , 0.07007,\n",
       "            0.0693 , 0.0689 , 0.0678 , 0.06537, 0.05737, 0.05603, 0.05573,\n",
       "            0.04715, 0.04053, 0.0397 , 0.0355 , 0.0336 , 0.03314, 0.0278 ,\n",
       "            0.02626, 0.02457, 0.02356, 0.02069, 0.0171 , 0.01543, 0.01065],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.47014925, dtype=float32),\n",
       "    'tpr': array(0.9655172, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.1119403 , 0.1119403 , 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.15671642, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.26865673, 0.26865673,\n",
       "            0.26865673, 0.26865673, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3448276 , 0.35344827, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.57758623, 0.5862069 , 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.62931037, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7155172 , 0.7155172 ,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.991  , 0.9893 , 0.9883 , 0.9854 , 0.985  , 0.982  ,\n",
       "            0.9814 , 0.98   , 0.9775 , 0.9756 , 0.975  , 0.974  , 0.971  ,\n",
       "            0.9707 , 0.9688 , 0.9683 , 0.9653 , 0.9595 , 0.9575 , 0.9565 ,\n",
       "            0.9556 , 0.955  , 0.9546 , 0.9536 , 0.9497 , 0.9487 , 0.947  ,\n",
       "            0.946  , 0.9424 , 0.9395 , 0.937  , 0.928  , 0.9224 , 0.921  ,\n",
       "            0.9204 , 0.9185 , 0.918  , 0.9175 , 0.9165 , 0.9097 , 0.908  ,\n",
       "            0.9053 , 0.904  , 0.898  , 0.8955 , 0.8823 , 0.87   , 0.866  ,\n",
       "            0.861  , 0.859  , 0.8535 , 0.852  , 0.849  , 0.8486 , 0.848  ,\n",
       "            0.8477 , 0.843  , 0.842  , 0.839  , 0.826  , 0.824  , 0.8184 ,\n",
       "            0.81   , 0.807  , 0.802  , 0.8003 , 0.7974 , 0.794  , 0.7925 ,\n",
       "            0.792  , 0.788  , 0.784  , 0.7817 , 0.7783 , 0.7773 , 0.776  ,\n",
       "            0.775  , 0.7734 , 0.77   , 0.7695 , 0.761  , 0.7573 , 0.753  ,\n",
       "            0.75   , 0.745  , 0.7407 , 0.737  , 0.7363 , 0.735  , 0.733  ,\n",
       "            0.7295 , 0.7285 , 0.7275 , 0.7256 , 0.723  , 0.7207 , 0.711  ,\n",
       "            0.708  , 0.7046 , 0.702  , 0.6987 , 0.6978 , 0.6943 , 0.69   ,\n",
       "            0.687  , 0.6855 , 0.684  , 0.6836 , 0.679  , 0.678  , 0.6763 ,\n",
       "            0.676  , 0.673  , 0.672  , 0.667  , 0.6655 , 0.663  , 0.6626 ,\n",
       "            0.66   , 0.6523 , 0.6504 , 0.643  , 0.6406 , 0.6353 , 0.635  ,\n",
       "            0.63   , 0.6294 , 0.629  , 0.6284 , 0.6265 , 0.6245 , 0.6177 ,\n",
       "            0.617  , 0.612  , 0.6074 , 0.6045 , 0.5986 , 0.597  , 0.591  ,\n",
       "            0.5884 , 0.584  , 0.5815 , 0.577  , 0.576  , 0.5693 , 0.5664 ,\n",
       "            0.5645 , 0.562  , 0.555  , 0.5386 , 0.5337 , 0.5283 , 0.526  ,\n",
       "            0.5254 , 0.517  , 0.5156 , 0.514  , 0.5024 , 0.501  , 0.4993 ,\n",
       "            0.4988 , 0.4958 , 0.487  , 0.486  , 0.477  , 0.452  , 0.4    ,\n",
       "            0.3896 , 0.365  , 0.3506 , 0.3489 , 0.3352 , 0.3289 , 0.3232 ,\n",
       "            0.2976 , 0.295  , 0.2717 , 0.2605 , 0.256  , 0.2268 , 0.2211 ,\n",
       "            0.2189 , 0.1981 , 0.1962 , 0.1942 , 0.1904 , 0.1882 , 0.1865 ,\n",
       "            0.1827 , 0.1805 , 0.1641 , 0.1622 , 0.1614 , 0.146  , 0.1448 ,\n",
       "            0.1279 , 0.121  , 0.1093 , 0.1025 , 0.10126, 0.09503, 0.0927 ,\n",
       "            0.0896 , 0.0866 , 0.0859 , 0.08154, 0.0761 , 0.07544, 0.07227,\n",
       "            0.0712 , 0.0693 , 0.0683 , 0.0671 , 0.0642 , 0.0613 , 0.0546 ,\n",
       "            0.0533 , 0.05203, 0.04486, 0.03748, 0.0371 , 0.0326 , 0.03143,\n",
       "            0.03091, 0.02576, 0.02391, 0.0223 , 0.0217 , 0.01869, 0.01567,\n",
       "            0.01428, 0.00938], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.49253732, dtype=float32),\n",
       "    'tpr': array(0.98275864, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.15671642, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.17910448, 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23134328, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2761194 , 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41044775, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.33620688, 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.43965518, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.6034483 , 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.7155172 , 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.992   , 0.9907  , 0.9893  , 0.987   , 0.984   ,\n",
       "            0.9834  , 0.982   , 0.98    , 0.978   , 0.9775  , 0.977   ,\n",
       "            0.974   , 0.9736  , 0.9717  , 0.971   , 0.9688  , 0.963   ,\n",
       "            0.9614  , 0.96    , 0.9595  , 0.959   , 0.958   , 0.9575  ,\n",
       "            0.9536  , 0.953   , 0.951   , 0.95    , 0.9478  , 0.9443  ,\n",
       "            0.942   , 0.933   , 0.929   , 0.9277  , 0.927   , 0.9243  ,\n",
       "            0.9233  , 0.923   , 0.9224  , 0.9155  , 0.914   , 0.9116  ,\n",
       "            0.91    , 0.9053  , 0.9033  , 0.8896  , 0.8774  , 0.8735  ,\n",
       "            0.8687  , 0.8667  , 0.862   , 0.8613  , 0.8574  , 0.857   ,\n",
       "            0.856   , 0.854   , 0.8496  , 0.847   , 0.835   , 0.833   ,\n",
       "            0.832   , 0.824   , 0.8213  , 0.812   , 0.809   , 0.807   ,\n",
       "            0.806   , 0.804   , 0.8037  , 0.803   , 0.7954  , 0.793   ,\n",
       "            0.7905  , 0.788   , 0.787   , 0.7866  , 0.786   , 0.785   ,\n",
       "            0.78    , 0.7793  , 0.7734  , 0.772   , 0.77    , 0.768   ,\n",
       "            0.76    , 0.757   , 0.756   , 0.7544  , 0.754   , 0.752   ,\n",
       "            0.751   , 0.7446  , 0.743   , 0.739   , 0.7383  , 0.7373  ,\n",
       "            0.735   , 0.734   , 0.7227  , 0.7188  , 0.7183  , 0.718   ,\n",
       "            0.7163  , 0.714   , 0.708   , 0.705   , 0.7026  , 0.701   ,\n",
       "            0.699   , 0.6987  , 0.6973  , 0.6963  , 0.6953  , 0.6904  ,\n",
       "            0.689   , 0.688   , 0.6846  , 0.6826  , 0.6772  , 0.677   ,\n",
       "            0.6763  , 0.675   , 0.6704  , 0.6675  , 0.6626  , 0.6567  ,\n",
       "            0.656   , 0.652   , 0.648   , 0.647   , 0.645   , 0.6445  ,\n",
       "            0.643   , 0.641   , 0.6406  , 0.635   , 0.6265  , 0.6157  ,\n",
       "            0.615   , 0.614   , 0.6064  , 0.6035  , 0.603   , 0.602   ,\n",
       "            0.593   , 0.59    , 0.585   , 0.583   , 0.579   , 0.5767  ,\n",
       "            0.5723  , 0.5596  , 0.5522  , 0.545   , 0.5435  , 0.5356  ,\n",
       "            0.5337  , 0.533   , 0.5186  , 0.5176  , 0.5166  , 0.516   ,\n",
       "            0.5137  , 0.505   , 0.5034  , 0.4844  , 0.474   , 0.4058  ,\n",
       "            0.4004  , 0.3794  , 0.3643  , 0.353   , 0.3374  , 0.3333  ,\n",
       "            0.3247  , 0.3005  , 0.2986  , 0.272   , 0.2622  , 0.2605  ,\n",
       "            0.2281  , 0.2213  , 0.2179  , 0.197   , 0.1964  , 0.1925  ,\n",
       "            0.1884  , 0.1863  , 0.1852  , 0.1843  , 0.1808  , 0.162   ,\n",
       "            0.1597  , 0.1587  , 0.1467  , 0.1455  , 0.1274  , 0.1184  ,\n",
       "            0.10706 , 0.0993  , 0.09875 , 0.09204 , 0.0896  , 0.0866  ,\n",
       "            0.08417 , 0.0828  , 0.0786  , 0.0732  , 0.0721  , 0.06915 ,\n",
       "            0.06866 , 0.0667  , 0.06635 , 0.06573 , 0.0642  , 0.06085 ,\n",
       "            0.05844 , 0.05167 , 0.05023 , 0.0494  , 0.04218 , 0.03488 ,\n",
       "            0.03455 , 0.03015 , 0.02908 , 0.0286  , 0.0237  , 0.02191 ,\n",
       "            0.02037 , 0.01979 , 0.01698 , 0.014175, 0.01287 , 0.008316],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.49253732, dtype=float32),\n",
       "    'tpr': array(0.98275864, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05970149, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.1119403 , 0.1119403 , 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.25373134, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.33582088, 0.33582088, 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.45689654, 0.46551725,\n",
       "            0.4827586 , 0.5       , 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.57758623, 0.5862069 , 0.5862069 , 0.5862069 ,\n",
       "            0.5862069 , 0.6034483 , 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.993  , 0.9917 , 0.9907 , 0.9883 , 0.986  , 0.985  ,\n",
       "            0.984  , 0.982  , 0.98   , 0.979  , 0.9766 , 0.976  , 0.974  ,\n",
       "            0.9717 , 0.9663 , 0.965  , 0.9634 , 0.963  , 0.9624 , 0.962  ,\n",
       "            0.961  , 0.9575 , 0.957  , 0.955  , 0.954  , 0.9526 , 0.948  ,\n",
       "            0.9463 , 0.938  , 0.9346 , 0.9336 , 0.9316 , 0.9297 , 0.929  ,\n",
       "            0.9287 , 0.9277 , 0.921  , 0.92   , 0.918  , 0.916  , 0.912  ,\n",
       "            0.91   , 0.8965 , 0.8843 , 0.881  , 0.876  , 0.8745 , 0.8696 ,\n",
       "            0.8657 , 0.865  , 0.8647 , 0.864  , 0.858  , 0.855  , 0.8447 ,\n",
       "            0.8433 , 0.8423 , 0.837  , 0.8345 , 0.822  , 0.8184 , 0.817  ,\n",
       "            0.8164 , 0.8135 , 0.806  , 0.8047 , 0.804  , 0.8037 , 0.798  ,\n",
       "            0.7974 , 0.7964 , 0.796  , 0.79   , 0.7886 , 0.786  , 0.7856 ,\n",
       "            0.782  , 0.7705 , 0.77   , 0.769  , 0.7686 , 0.768  , 0.7676 ,\n",
       "            0.759  , 0.757  , 0.75   , 0.7485 , 0.748  , 0.744  , 0.7383 ,\n",
       "            0.7373 , 0.736  , 0.735  , 0.7334 , 0.7314 , 0.728  , 0.725  ,\n",
       "            0.722  , 0.721  , 0.7173 , 0.715  , 0.7144 , 0.714  , 0.713  ,\n",
       "            0.708  , 0.7065 , 0.702  , 0.7017 , 0.699  , 0.6973 , 0.694  ,\n",
       "            0.6914 , 0.6885 , 0.6875 , 0.6836 , 0.6816 , 0.6787 , 0.6704 ,\n",
       "            0.6685 , 0.6655 , 0.6646 , 0.6606 , 0.66   , 0.659  , 0.657  ,\n",
       "            0.6562 , 0.6523 , 0.652  , 0.645  , 0.6406 , 0.632  , 0.6304 ,\n",
       "            0.6245 , 0.622  , 0.62   , 0.6123 , 0.6094 , 0.6006 , 0.599  ,\n",
       "            0.5986 , 0.5938 , 0.5894 , 0.5874 , 0.581  , 0.5713 , 0.5615 ,\n",
       "            0.558  , 0.553  , 0.552  , 0.5493 , 0.5405 , 0.5347 , 0.5327 ,\n",
       "            0.5317 , 0.5312 , 0.529  , 0.5244 , 0.5156 , 0.4949 , 0.4883 ,\n",
       "            0.4075 , 0.4067 , 0.3887 , 0.373  , 0.3535 , 0.3362 , 0.3337 ,\n",
       "            0.323  , 0.302  , 0.2961 , 0.269  , 0.2644 , 0.2578 , 0.2264 ,\n",
       "            0.218  , 0.2137 , 0.1948 , 0.1918 , 0.1882 , 0.1846 , 0.1837 ,\n",
       "            0.1816 , 0.1797 , 0.1783 , 0.1578 , 0.1577 , 0.1548 , 0.1539 ,\n",
       "            0.145  , 0.1438 , 0.1249 , 0.1144 , 0.10284, 0.09485, 0.09467,\n",
       "            0.0877 , 0.08527, 0.0823 , 0.0802 , 0.0788 , 0.07465, 0.06915,\n",
       "            0.06793, 0.06537, 0.065  , 0.06305, 0.06244, 0.0621 , 0.0603 ,\n",
       "            0.05698, 0.0548 , 0.04794, 0.04663, 0.0461 , 0.03882, 0.03192,\n",
       "            0.03156, 0.02753, 0.0265 , 0.026  , 0.02141, 0.01976, 0.01834,\n",
       "            0.01778, 0.01519, 0.01257, 0.01142, 0.00726], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14179105, 0.14925373, 0.14925373, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.26119402, 0.26119402, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.2835821 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12931034, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.21551724,\n",
       "            0.22413793, 0.2413793 , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.51724136, 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.5689655 , 0.57758623, 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.5948276 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.6896552 , 0.6896552 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.75      , 0.75      , 0.7586207 , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8189655 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.994   , 0.9927  , 0.9917  , 0.9897  , 0.988   ,\n",
       "            0.987   , 0.986   , 0.984   , 0.9824  , 0.982   , 0.9814  ,\n",
       "            0.979   , 0.977   , 0.9746  , 0.9697  , 0.9688  , 0.967   ,\n",
       "            0.9663  , 0.966   , 0.9644  , 0.9614  , 0.959   , 0.9585  ,\n",
       "            0.953   , 0.951   , 0.9434  , 0.942   , 0.9375  , 0.936   ,\n",
       "            0.9355  , 0.9346  , 0.9336  , 0.9277  , 0.9263  , 0.925   ,\n",
       "            0.923   , 0.92    , 0.9194  , 0.9043  , 0.8926  , 0.889   ,\n",
       "            0.885   , 0.8833  , 0.882   , 0.88    , 0.879   , 0.876   ,\n",
       "            0.8745  , 0.874   , 0.8735  , 0.867   , 0.865   , 0.861   ,\n",
       "            0.8535  , 0.853   , 0.851   , 0.8374  , 0.834   , 0.833   ,\n",
       "            0.8325  , 0.8296  , 0.8286  , 0.826   , 0.8228  , 0.8223  ,\n",
       "            0.818   , 0.8174  , 0.817   , 0.8115  , 0.811   , 0.81    ,\n",
       "            0.809   , 0.806   , 0.803   , 0.8027  , 0.801   , 0.8003  ,\n",
       "            0.791   , 0.7905  , 0.7896  , 0.789   , 0.7886  , 0.782   ,\n",
       "            0.7773  , 0.7744  , 0.7656  , 0.764   , 0.7637  , 0.763   ,\n",
       "            0.7627  , 0.7573  , 0.7563  , 0.7544  , 0.7495  , 0.7485  ,\n",
       "            0.7476  , 0.745   , 0.744   , 0.7393  , 0.739   , 0.738   ,\n",
       "            0.7334  , 0.733   , 0.7314  , 0.728   , 0.725   , 0.7207  ,\n",
       "            0.716   , 0.713   , 0.7124  , 0.7114  , 0.711   , 0.7104  ,\n",
       "            0.709   , 0.7075  , 0.706   , 0.7056  , 0.702   , 0.6914  ,\n",
       "            0.691   , 0.69    , 0.6885  , 0.6826  , 0.682   , 0.6816  ,\n",
       "            0.6797  , 0.6787  , 0.6763  , 0.6714  , 0.661   , 0.6553  ,\n",
       "            0.654   , 0.65    , 0.6455  , 0.6406  , 0.634   , 0.632   ,\n",
       "            0.623   , 0.6226  , 0.6187  , 0.615   , 0.6143  , 0.613   ,\n",
       "            0.6094  , 0.5996  , 0.5894  , 0.583   , 0.5825  , 0.5796  ,\n",
       "            0.5737  , 0.562   , 0.5596  , 0.559   , 0.5576  , 0.5537  ,\n",
       "            0.553   , 0.542   , 0.531   , 0.505   , 0.4282  , 0.4224  ,\n",
       "            0.4155  , 0.3994  , 0.3665  , 0.3477  , 0.3467  , 0.3337  ,\n",
       "            0.318   , 0.3052  , 0.282   , 0.2769  , 0.265   , 0.236   ,\n",
       "            0.2246  , 0.2198  , 0.2031  , 0.1967  , 0.1958  , 0.1931  ,\n",
       "            0.1873  , 0.186   , 0.1857  , 0.1831  , 0.1608  , 0.1606  ,\n",
       "            0.1581  , 0.1564  , 0.1528  , 0.1515  , 0.1299  , 0.1158  ,\n",
       "            0.1056  , 0.09686 , 0.0955  , 0.0883  , 0.086   , 0.0827  ,\n",
       "            0.0818  , 0.0785  , 0.0752  , 0.06915 , 0.0672  , 0.06586 ,\n",
       "            0.06525 , 0.0636  , 0.0627  , 0.06223 , 0.0601  , 0.05612 ,\n",
       "            0.0542  , 0.0471  , 0.04578 , 0.04526 , 0.03802 , 0.03085 ,\n",
       "            0.03056 , 0.02646 , 0.02556 , 0.02504 , 0.02052 , 0.01877 ,\n",
       "            0.01738 , 0.01692 , 0.014336, 0.01187 , 0.01086 , 0.006718],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.1119403 , 0.1119403 , 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14179105, 0.14925373, 0.14925373, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20149253, 0.21641791, 0.2238806 , 0.23134328, 0.23134328,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.24626866, 0.24626866,\n",
       "            0.26119402, 0.26119402, 0.26865673, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.2835821 , 0.2835821 , 0.29104477, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41044775,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12931034, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.2413793 , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.7155172 ,\n",
       "            0.7241379 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.76724136, 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.995   , 0.994   , 0.993   , 0.991   , 0.9893  ,\n",
       "            0.989   , 0.988   , 0.9863  , 0.985   , 0.9844  , 0.984   ,\n",
       "            0.982   , 0.98    , 0.978   , 0.973   , 0.9727  , 0.9707  ,\n",
       "            0.97    , 0.9697  , 0.969   , 0.9683  , 0.966   , 0.9634  ,\n",
       "            0.963   , 0.958   , 0.956   , 0.9487  , 0.9473  , 0.9434  ,\n",
       "            0.942   , 0.9414  , 0.941   , 0.9404  , 0.9395  , 0.9336  ,\n",
       "            0.933   , 0.931   , 0.929   , 0.927   , 0.9263  , 0.9116  ,\n",
       "            0.9004  , 0.8975  , 0.893   , 0.8916  , 0.889   , 0.888   ,\n",
       "            0.8867  , 0.885   , 0.8843  , 0.884   , 0.883   , 0.882   ,\n",
       "            0.876   , 0.874   , 0.869   , 0.863   , 0.862   , 0.86    ,\n",
       "            0.8467  , 0.8433  , 0.8423  , 0.8403  , 0.8394  , 0.8384  ,\n",
       "            0.8354  , 0.8325  , 0.8315  , 0.8286  , 0.8276  , 0.8267  ,\n",
       "            0.8213  , 0.821   , 0.8203  , 0.8193  , 0.819   , 0.8164  ,\n",
       "            0.8135  , 0.813   , 0.8125  , 0.811   , 0.8105  , 0.802   ,\n",
       "            0.8013  , 0.8003  , 0.8     , 0.799   , 0.7925  , 0.788   ,\n",
       "            0.785   , 0.776   , 0.7754  , 0.7744  , 0.7734  , 0.773   ,\n",
       "            0.7676  , 0.7646  , 0.7593  , 0.758   , 0.7563  , 0.7544  ,\n",
       "            0.75    , 0.749   , 0.7485  , 0.744   , 0.7437  , 0.7427  ,\n",
       "            0.7393  , 0.7363  , 0.731   , 0.726   , 0.7236  , 0.723   ,\n",
       "            0.722   , 0.7217  , 0.721   , 0.719   , 0.717   , 0.7163  ,\n",
       "            0.711   , 0.702   , 0.7017  , 0.7007  , 0.6997  , 0.694   ,\n",
       "            0.693   , 0.692   , 0.691   , 0.6895  , 0.6875  , 0.6826  ,\n",
       "            0.6714  , 0.6675  , 0.6665  , 0.6646  , 0.661   , 0.6567  ,\n",
       "            0.6484  , 0.6445  , 0.641   , 0.6333  , 0.633   , 0.628   ,\n",
       "            0.625   , 0.6245  , 0.6187  , 0.611   , 0.6     , 0.594   ,\n",
       "            0.5923  , 0.5903  , 0.584   , 0.5723  , 0.5693  , 0.569   ,\n",
       "            0.568   , 0.566   , 0.5645  , 0.5625  , 0.5513  , 0.5425  ,\n",
       "            0.508   , 0.4338  , 0.425   , 0.4229  , 0.406   , 0.3674  ,\n",
       "            0.3484  , 0.3452  , 0.3325  , 0.3193  , 0.3032  , 0.2834  ,\n",
       "            0.2742  , 0.262   , 0.234   , 0.2205  , 0.2158  , 0.2009  ,\n",
       "            0.1948  , 0.1921  , 0.1887  , 0.1833  , 0.1827  , 0.1815  ,\n",
       "            0.1787  , 0.1566  , 0.1565  , 0.1536  , 0.1516  , 0.1509  ,\n",
       "            0.1497  , 0.1268  , 0.111   , 0.10175 , 0.0933  , 0.09125 ,\n",
       "            0.08435 , 0.0821  , 0.0788  , 0.07837 , 0.0745  , 0.0715  ,\n",
       "            0.0655  , 0.06323 , 0.0627  , 0.06165 , 0.0603  , 0.05954 ,\n",
       "            0.05844 , 0.05646 , 0.05234 , 0.05072 , 0.04376 , 0.04248 ,\n",
       "            0.04218 , 0.03516 , 0.02821 , 0.02806 , 0.02405 , 0.02338 ,\n",
       "            0.02284 , 0.01862 , 0.01692 , 0.01567 , 0.01525 , 0.012825,\n",
       "            0.01065 , 0.00971 , 0.005867], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.10447761, 0.10447761, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23134328, 0.23134328, 0.23134328, 0.23134328, 0.23880596,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26865673, 0.26865673, 0.2761194 , 0.2761194 , 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.31343284, 0.31343284,\n",
       "            0.31343284, 0.31343284, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.33620688,\n",
       "            0.35344827, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43103448, 0.43965518, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.54310346, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.996   , 0.995   , 0.9946  , 0.9927  , 0.991   ,\n",
       "            0.9907  , 0.9897  , 0.9883  , 0.9873  , 0.987   , 0.9863  ,\n",
       "            0.985   , 0.9844  , 0.983   , 0.981   , 0.977   , 0.976   ,\n",
       "            0.975   , 0.9746  , 0.974   , 0.9736  , 0.973   , 0.9707  ,\n",
       "            0.97    , 0.9688  , 0.9683  , 0.968   , 0.9634  , 0.962   ,\n",
       "            0.955   , 0.954   , 0.9536  , 0.951   , 0.9487  , 0.948   ,\n",
       "            0.9478  , 0.9434  , 0.9424  , 0.941   , 0.939   , 0.935   ,\n",
       "            0.9346  , 0.925   , 0.913   , 0.91    , 0.9077  , 0.9067  ,\n",
       "            0.9053  , 0.902   , 0.9     , 0.8975  , 0.8965  , 0.8955  ,\n",
       "            0.892   , 0.8916  , 0.8906  , 0.8853  , 0.8833  , 0.8823  ,\n",
       "            0.88    , 0.873   , 0.8657  , 0.8647  , 0.86    , 0.8584  ,\n",
       "            0.858   , 0.8574  , 0.857   , 0.8525  , 0.85    , 0.8457  ,\n",
       "            0.8447  , 0.8438  , 0.8423  , 0.8413  , 0.839   , 0.8384  ,\n",
       "            0.837   , 0.8364  , 0.8354  , 0.8315  , 0.831   , 0.8306  ,\n",
       "            0.826   , 0.8174  , 0.8154  , 0.814   , 0.812   , 0.811   ,\n",
       "            0.81    , 0.8027  , 0.7993  , 0.799   , 0.798   , 0.7974  ,\n",
       "            0.795   , 0.7925  , 0.7915  , 0.7905  , 0.7886  , 0.7866  ,\n",
       "            0.785   , 0.7817  , 0.7803  , 0.778   , 0.7773  , 0.776   ,\n",
       "            0.773   , 0.7725  , 0.772   , 0.7715  , 0.769   , 0.761   ,\n",
       "            0.756   , 0.7554  , 0.755   , 0.7544  , 0.7495  , 0.747   ,\n",
       "            0.746   , 0.7437  , 0.7427  , 0.736   , 0.735   , 0.7344  ,\n",
       "            0.7314  , 0.7305  , 0.726   , 0.7236  , 0.723   , 0.722   ,\n",
       "            0.7217  , 0.719   , 0.7075  , 0.701   , 0.6997  , 0.698   ,\n",
       "            0.6978  , 0.693   , 0.678   , 0.6685  , 0.6665  , 0.666   ,\n",
       "            0.6655  , 0.6646  , 0.6597  , 0.656   , 0.6533  , 0.648   ,\n",
       "            0.6455  , 0.6367  , 0.6333  , 0.6265  , 0.623   , 0.6177  ,\n",
       "            0.6084  , 0.605   , 0.6025  , 0.602   , 0.5923  , 0.5874  ,\n",
       "            0.585   , 0.583   , 0.5195  , 0.4592  , 0.4539  , 0.4412  ,\n",
       "            0.4363  , 0.381   , 0.3623  , 0.3518  , 0.3416  , 0.337   ,\n",
       "            0.3105  , 0.3027  , 0.28    , 0.2654  , 0.2428  , 0.2251  ,\n",
       "            0.22    , 0.2081  , 0.2053  , 0.1943  , 0.1918  , 0.1897  ,\n",
       "            0.1838  , 0.1836  , 0.1798  , 0.1575  , 0.1565  , 0.1547  ,\n",
       "            0.1517  , 0.1301  , 0.10913 , 0.10284 , 0.094   , 0.0901  ,\n",
       "            0.08344 , 0.08136 , 0.0786  , 0.07794 , 0.07227 , 0.0708  ,\n",
       "            0.0641  , 0.06256 , 0.0611  , 0.05988 , 0.0591  , 0.05676 ,\n",
       "            0.0549  , 0.05023 , 0.04868 , 0.04208 , 0.04077 , 0.04025 ,\n",
       "            0.03372 , 0.02646 , 0.02246 , 0.02208 , 0.02153 , 0.01744 ,\n",
       "            0.01567 , 0.01445 , 0.01423 , 0.011734, 0.00982 , 0.00902 ,\n",
       "            0.00526 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.07462686, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.14925373, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.17910448, 0.17910448, 0.18656716,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.20895523, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23134328, 0.23880596, 0.23880596,\n",
       "            0.23880596, 0.25373134, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.31343284, 0.31343284, 0.31343284,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3283582 , 0.33582088,\n",
       "            0.33582088, 0.33582088, 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.11206897, 0.12931034, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.49137932, 0.5       ,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.5862069 , 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.7241379 , 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9966 , 0.9956 , 0.995  , 0.9937 , 0.992  , 0.9917 ,\n",
       "            0.991  , 0.9897 , 0.989  , 0.9883 , 0.9863 , 0.985  , 0.9834 ,\n",
       "            0.9795 , 0.979  , 0.9775 , 0.977  , 0.9766 , 0.9756 , 0.9736 ,\n",
       "            0.973  , 0.9717 , 0.971  , 0.967  , 0.9653 , 0.9595 , 0.959  ,\n",
       "            0.958  , 0.955  , 0.953  , 0.9526 , 0.952  , 0.9517 , 0.947  ,\n",
       "            0.946  , 0.9434 , 0.9404 , 0.94   , 0.9297 , 0.9185 , 0.916  ,\n",
       "            0.913  , 0.912  , 0.9116 , 0.91   , 0.9077 , 0.907  , 0.9033 ,\n",
       "            0.9023 , 0.8984 , 0.8975 , 0.8965 , 0.8916 , 0.89   , 0.888  ,\n",
       "            0.886  , 0.8804 , 0.8726 , 0.871  , 0.8667 , 0.865  , 0.8643 ,\n",
       "            0.864  , 0.8564 , 0.854  , 0.852  , 0.8516 , 0.849  , 0.8486 ,\n",
       "            0.8467 , 0.8457 , 0.845  , 0.8447 , 0.8423 , 0.8403 , 0.84   ,\n",
       "            0.8394 , 0.8384 , 0.834  , 0.8257 , 0.8237 , 0.822  , 0.8203 ,\n",
       "            0.8115 , 0.807  , 0.8066 , 0.8057 , 0.8037 , 0.8013 , 0.7983 ,\n",
       "            0.796  , 0.7915 , 0.7896 , 0.7876 , 0.787  , 0.786  , 0.7847 ,\n",
       "            0.7827 , 0.7817 , 0.7812 , 0.7793 , 0.7744 , 0.766  , 0.7646 ,\n",
       "            0.763  , 0.76   , 0.7593 , 0.757  , 0.7554 , 0.753  , 0.752  ,\n",
       "            0.747  , 0.746  , 0.7456 , 0.7417 , 0.7407 , 0.737  , 0.735  ,\n",
       "            0.734  , 0.7334 , 0.7324 , 0.731  , 0.7217 , 0.7114 , 0.71   ,\n",
       "            0.705  , 0.6904 , 0.679  , 0.678  , 0.6772 , 0.675  , 0.672  ,\n",
       "            0.6665 , 0.6626 , 0.662  , 0.6553 , 0.651  , 0.648  , 0.6406 ,\n",
       "            0.6343 , 0.63   , 0.622  , 0.6187 , 0.6177 , 0.6147 , 0.6143 ,\n",
       "            0.6025 , 0.601  , 0.596  , 0.594  , 0.5317 , 0.4683 , 0.4658 ,\n",
       "            0.448  , 0.4468 , 0.3855 , 0.3665 , 0.3574 , 0.3457 , 0.3416 ,\n",
       "            0.314  , 0.3083 , 0.2822 , 0.2688 , 0.2441 , 0.2242 , 0.219  ,\n",
       "            0.2091 , 0.208  , 0.1935 , 0.1906 , 0.1901 , 0.183  , 0.1824 ,\n",
       "            0.1788 , 0.1589 , 0.1581 , 0.157  , 0.1567 , 0.1532 , 0.1506 ,\n",
       "            0.1298 , 0.1086 , 0.10126, 0.0927 , 0.088  , 0.08136, 0.07935,\n",
       "            0.0772 , 0.076  , 0.0712 , 0.0689 , 0.06223, 0.0611 , 0.05933,\n",
       "            0.05814, 0.0578 , 0.0575 , 0.0547 , 0.05283, 0.0485 , 0.04742,\n",
       "            0.04016, 0.03897, 0.0321 , 0.02513, 0.02504, 0.02121, 0.0208 ,\n",
       "            0.02025, 0.01634, 0.01462, 0.01348, 0.01322, 0.0109 , 0.00909,\n",
       "            0.00835, 0.00479], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.21641791, 0.2238806 , 0.2238806 , 0.2238806 , 0.23134328,\n",
       "            0.23134328, 0.23880596, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26119402, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.3283582 , 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.09482758, 0.11206897, 0.12931034, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.21551724,\n",
       "            0.22413793, 0.2413793 , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.35344827, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.43965518, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.51724136, 0.51724136, 0.5258621 , 0.5344828 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9976  , 0.9966  , 0.996   , 0.995   , 0.9946  ,\n",
       "            0.9937  , 0.993   , 0.9927  , 0.9917  , 0.9907  , 0.99    ,\n",
       "            0.989   , 0.9873  , 0.986   , 0.9824  , 0.982   , 0.981   ,\n",
       "            0.9805  , 0.98    , 0.9795  , 0.977   , 0.976   , 0.975   ,\n",
       "            0.971   , 0.97    , 0.965   , 0.9644  , 0.964   , 0.9614  ,\n",
       "            0.959   , 0.958   , 0.956   , 0.9536  , 0.9526  , 0.951   ,\n",
       "            0.948   , 0.9473  , 0.9395  , 0.9287  , 0.9277  , 0.9263  ,\n",
       "            0.9253  , 0.9233  , 0.922   , 0.9204  , 0.919   , 0.9155  ,\n",
       "            0.914   , 0.913   , 0.91    , 0.9097  , 0.908   , 0.904   ,\n",
       "            0.901   , 0.9004  , 0.891   , 0.8896  , 0.888   , 0.8853  ,\n",
       "            0.884   , 0.8833  , 0.8823  , 0.881   , 0.879   , 0.8765  ,\n",
       "            0.8755  , 0.8716  , 0.8706  , 0.868   , 0.867   , 0.866   ,\n",
       "            0.8657  , 0.8643  , 0.8633  , 0.862   , 0.8594  , 0.856   ,\n",
       "            0.8555  , 0.8496  , 0.848   , 0.8467  , 0.846   , 0.8423  ,\n",
       "            0.8403  , 0.834   , 0.832   , 0.8286  , 0.828   , 0.8267  ,\n",
       "            0.8247  , 0.824   , 0.82    , 0.8184  , 0.818   , 0.8164  ,\n",
       "            0.813   , 0.8125  , 0.812   , 0.8096  , 0.807   , 0.8066  ,\n",
       "            0.806   , 0.805   , 0.8037  , 0.7964  , 0.794   , 0.7905  ,\n",
       "            0.787   , 0.7847  , 0.784   , 0.7783  , 0.7764  , 0.7754  ,\n",
       "            0.7744  , 0.774   , 0.772   , 0.768   , 0.765   , 0.7646  ,\n",
       "            0.763   , 0.7627  , 0.762   , 0.7617  , 0.7607  , 0.76    ,\n",
       "            0.755   , 0.7407  , 0.7393  , 0.7383  , 0.736   , 0.72    ,\n",
       "            0.714   , 0.7075  , 0.7056  , 0.703   , 0.7026  , 0.6997  ,\n",
       "            0.6943  , 0.6875  , 0.6826  , 0.6816  , 0.68    , 0.673   ,\n",
       "            0.662   , 0.6606  , 0.6543  , 0.6514  , 0.6504  , 0.645   ,\n",
       "            0.638   , 0.632   , 0.626   , 0.6216  , 0.5527  , 0.4988  ,\n",
       "            0.4963  , 0.4805  , 0.468   , 0.404   , 0.3848  , 0.372   ,\n",
       "            0.3635  , 0.3613  , 0.331   , 0.328   , 0.294   , 0.2786  ,\n",
       "            0.2563  , 0.2327  , 0.2272  , 0.2212  , 0.2194  , 0.1996  ,\n",
       "            0.1993  , 0.197   , 0.1886  , 0.1882  , 0.1842  , 0.1676  ,\n",
       "            0.1671  , 0.1615  , 0.161   , 0.1573  , 0.1543  , 0.1348  ,\n",
       "            0.1101  , 0.10376 , 0.09503 , 0.089   , 0.0823  , 0.0804  ,\n",
       "            0.0788  , 0.07666 , 0.07135 , 0.0695  , 0.0621  , 0.0619  ,\n",
       "            0.0589  , 0.05856 , 0.0578  , 0.05737 , 0.0542  , 0.05243 ,\n",
       "            0.04788 , 0.0469  , 0.03943 , 0.0384  , 0.03818 , 0.0313  ,\n",
       "            0.02428 , 0.02419 , 0.02034 , 0.02002 , 0.01945 , 0.0156  ,\n",
       "            0.0139  , 0.012726, 0.01257 , 0.01025 , 0.008545, 0.00787 ,\n",
       "            0.0044  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.51492536, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20149253, 0.20149253, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.2238806 , 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.23880596, 0.23880596, 0.24626866, 0.26119402,\n",
       "            0.26865673, 0.26865673, 0.2761194 , 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.10344828, 0.11206897,\n",
       "            0.12931034, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.20689656, 0.22413793, 0.2413793 , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.33620688, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.4051724 , 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.46551725, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.51724136, 0.5258621 ,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.61206895, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.88793105, 0.88793105, 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.998  , 0.997  , 0.996  , 0.995  , 0.9946 , 0.994  ,\n",
       "            0.993  , 0.992  , 0.9917 , 0.9907 , 0.9893 , 0.9883 , 0.9854 ,\n",
       "            0.985  , 0.984  , 0.9834 , 0.983  , 0.9805 , 0.98   , 0.9785 ,\n",
       "            0.9756 , 0.974  , 0.97   , 0.9697 , 0.9688 , 0.9673 , 0.965  ,\n",
       "            0.9644 , 0.964  , 0.96   , 0.9585 , 0.955  , 0.954  , 0.949  ,\n",
       "            0.941  , 0.9385 , 0.9365 , 0.936  , 0.933  , 0.932  , 0.931  ,\n",
       "            0.929  , 0.9277 , 0.9272 , 0.9253 , 0.9243 , 0.924  , 0.923  ,\n",
       "            0.9224 , 0.9185 , 0.918  , 0.914  , 0.9097 , 0.908  , 0.9043 ,\n",
       "            0.904  , 0.9014 , 0.9004 , 0.899  , 0.897  , 0.8965 , 0.893  ,\n",
       "            0.8926 , 0.8896 , 0.888  , 0.8867 , 0.886  , 0.8857 , 0.8853 ,\n",
       "            0.885  , 0.88   , 0.8794 , 0.876  , 0.875  , 0.874  , 0.873  ,\n",
       "            0.872  , 0.867  , 0.866  , 0.8633 , 0.8584 , 0.8555 , 0.855  ,\n",
       "            0.8525 , 0.851  , 0.8506 , 0.8496 , 0.849  , 0.847  , 0.846  ,\n",
       "            0.8438 , 0.8433 , 0.8423 , 0.8384 , 0.838  , 0.8354 , 0.835  ,\n",
       "            0.834  , 0.832  , 0.8306 , 0.83   , 0.8286 , 0.824  , 0.8213 ,\n",
       "            0.8203 , 0.8154 , 0.8125 , 0.808  , 0.806  , 0.8027 , 0.802  ,\n",
       "            0.8003 , 0.799  , 0.7983 , 0.797  , 0.7935 , 0.792  , 0.7915 ,\n",
       "            0.791  , 0.7905 , 0.79   , 0.787  , 0.7866 , 0.783  , 0.77   ,\n",
       "            0.7686 , 0.7676 , 0.765  , 0.764  , 0.7495 , 0.747  , 0.7363 ,\n",
       "            0.734  , 0.7334 , 0.7256 , 0.7246 , 0.722  , 0.7217 , 0.714  ,\n",
       "            0.711  , 0.7046 , 0.704  , 0.6904 , 0.6895 , 0.6855 , 0.684  ,\n",
       "            0.682  , 0.675  , 0.6743 , 0.659  , 0.655  , 0.645  , 0.572  ,\n",
       "            0.529  , 0.522  , 0.5093 , 0.4873 , 0.4207 , 0.4011 , 0.3848 ,\n",
       "            0.3833 , 0.3745 , 0.351  , 0.3396 , 0.3035 , 0.287  , 0.266  ,\n",
       "            0.2384 , 0.2327 , 0.2319 , 0.2273 , 0.206  , 0.2037 , 0.201  ,\n",
       "            0.1923 , 0.1917 , 0.1877 , 0.1741 , 0.1738 , 0.1644 , 0.1641 ,\n",
       "            0.1598 , 0.1565 , 0.1381 , 0.1105 , 0.1043 , 0.0955 , 0.0887 ,\n",
       "            0.08167, 0.0799 , 0.0786 , 0.0761 , 0.0708 , 0.0688 , 0.0613 ,\n",
       "            0.06085, 0.0578 , 0.0577 , 0.05685, 0.05624, 0.053  , 0.05118,\n",
       "            0.0468 , 0.04596, 0.03812, 0.03732, 0.03683, 0.03004, 0.0232 ,\n",
       "            0.02298, 0.0192 , 0.01894, 0.0184 , 0.01467, 0.01297, 0.01187,\n",
       "            0.01169, 0.00952, 0.00787, 0.00726, 0.00399], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.52238804, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.09701493, 0.1119403 , 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.13432837, 0.13432837,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.1641791 , 0.1716418 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.20149253, 0.20149253, 0.20149253,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.2238806 , 0.23134328, 0.23134328,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.26865673, 0.2761194 , 0.2761194 , 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.04310345, 0.06034483,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.19827586, 0.22413793, 0.2413793 , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.33620688, 0.3448276 , 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.4051724 , 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.51724136, 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.5689655 , 0.5862069 , 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.6465517 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.70689654, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.87068963, 0.87931037, 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9985  , 0.9976  , 0.9966  , 0.9956  , 0.995   ,\n",
       "            0.994   , 0.9937  , 0.993   , 0.9917  , 0.991   , 0.9907  ,\n",
       "            0.9897  , 0.9873  , 0.987   , 0.986   , 0.9854  , 0.983   ,\n",
       "            0.9824  , 0.9814  , 0.9785  , 0.9775  , 0.974   , 0.973   ,\n",
       "            0.9727  , 0.9717  , 0.969   , 0.9688  , 0.9683  , 0.968   ,\n",
       "            0.965   , 0.9634  , 0.96    , 0.959   , 0.955   , 0.9487  ,\n",
       "            0.9453  , 0.944   , 0.9434  , 0.941   , 0.94    , 0.939   ,\n",
       "            0.9365  , 0.9355  , 0.935   , 0.934   , 0.931   , 0.9307  ,\n",
       "            0.93    , 0.929   , 0.9272  , 0.923   , 0.922   , 0.9185  ,\n",
       "            0.9155  , 0.914   , 0.9126  , 0.9106  , 0.9097  , 0.9067  ,\n",
       "            0.9043  , 0.904   , 0.901   , 0.9     , 0.8994  , 0.899   ,\n",
       "            0.8984  , 0.898   , 0.8975  , 0.897   , 0.896   , 0.891   ,\n",
       "            0.8906  , 0.8896  , 0.889   , 0.8843  , 0.884   , 0.8804  ,\n",
       "            0.879   , 0.876   , 0.871   , 0.87    , 0.868   , 0.867   ,\n",
       "            0.8657  , 0.865   , 0.863   , 0.8623  , 0.8613  , 0.861   ,\n",
       "            0.86    , 0.8594  , 0.8564  , 0.855   , 0.854   , 0.8516  ,\n",
       "            0.8506  , 0.8486  , 0.848   , 0.846   , 0.8457  , 0.8447  ,\n",
       "            0.843   , 0.8423  , 0.8374  , 0.836   , 0.8315  , 0.8296  ,\n",
       "            0.8237  , 0.821   , 0.82    , 0.8174  , 0.814   , 0.8125  ,\n",
       "            0.812   , 0.81    , 0.8096  , 0.8086  , 0.808   , 0.8076  ,\n",
       "            0.805   , 0.804   , 0.7983  , 0.7896  , 0.787   , 0.786   ,\n",
       "            0.785   , 0.7817  , 0.7695  , 0.7686  , 0.7563  , 0.7534  ,\n",
       "            0.747   , 0.7407  , 0.74    , 0.7383  , 0.737   , 0.7354  ,\n",
       "            0.728   , 0.7256  , 0.721   , 0.7114  , 0.708   , 0.7075  ,\n",
       "            0.707   , 0.704   , 0.7     , 0.696   , 0.695   , 0.679   ,\n",
       "            0.676   , 0.663   , 0.591   , 0.553   , 0.5425  , 0.5337  ,\n",
       "            0.503   , 0.4348  , 0.4148  , 0.3997  , 0.3984  , 0.3877  ,\n",
       "            0.3684  , 0.3516  , 0.3142  , 0.2976  , 0.276   , 0.2452  ,\n",
       "            0.2426  , 0.239   , 0.2352  , 0.2133  , 0.209   , 0.206   ,\n",
       "            0.1974  , 0.1965  , 0.1927  , 0.1814  , 0.1813  , 0.1697  ,\n",
       "            0.1694  , 0.1635  , 0.1603  , 0.1423  , 0.11316 , 0.1067  ,\n",
       "            0.0977  , 0.0899  , 0.0828  , 0.08093 , 0.0802  , 0.0772  ,\n",
       "            0.07196 , 0.0695  , 0.06232 , 0.0611  , 0.05814 , 0.058   ,\n",
       "            0.05737 , 0.05624 , 0.053   , 0.0511  , 0.0468  , 0.0463  ,\n",
       "            0.0378  , 0.03748 , 0.03656 , 0.02975 , 0.02293 , 0.02258 ,\n",
       "            0.01883 , 0.01859 , 0.01805 , 0.014336, 0.01263 , 0.01155 ,\n",
       "            0.011375, 0.00919 , 0.007607, 0.00704 , 0.003809], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.52238804, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.07462686, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.13432837, 0.14179105, 0.14179105,\n",
       "            0.14179105, 0.14179105, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20149253,\n",
       "            0.20149253, 0.20149253, 0.20895523, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.26865673, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.29850745,\n",
       "            0.29850745, 0.29850745, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.36567163, 0.36567163, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41044775,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.46268657, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.04310345, 0.05172414,\n",
       "            0.06896552, 0.0775862 , 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.21551724, 0.22413793, 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.35344827,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.44827586, 0.45689654, 0.45689654, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.54310346, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9985  , 0.998   , 0.997   , 0.9966  , 0.996   ,\n",
       "            0.995   , 0.9946  , 0.994   , 0.993   , 0.9927  , 0.992   ,\n",
       "            0.991   , 0.9893  , 0.989   , 0.9883  , 0.988   , 0.9873  ,\n",
       "            0.9854  , 0.985   , 0.984   , 0.9814  , 0.9805  , 0.9775  ,\n",
       "            0.9766  , 0.976   , 0.9756  , 0.975   , 0.9736  , 0.973   ,\n",
       "            0.972   , 0.969   , 0.9688  , 0.968   , 0.965   , 0.964   ,\n",
       "            0.9624  , 0.959   , 0.953   , 0.9526  , 0.9517  , 0.951   ,\n",
       "            0.9473  , 0.947   , 0.9443  , 0.9434  , 0.943   , 0.9414  ,\n",
       "            0.94    , 0.939   , 0.9385  , 0.938   , 0.9336  , 0.932   ,\n",
       "            0.93    , 0.9272  , 0.9263  , 0.924   , 0.923   , 0.919   ,\n",
       "            0.918   , 0.917   , 0.9165  , 0.916   , 0.9146  , 0.914   ,\n",
       "            0.9126  , 0.912   , 0.911   , 0.9106  , 0.9097  , 0.9062  ,\n",
       "            0.906   , 0.901   , 0.8984  , 0.8975  , 0.896   , 0.8955  ,\n",
       "            0.894   , 0.8906  , 0.8896  , 0.889   , 0.8867  , 0.886   ,\n",
       "            0.8857  , 0.885   , 0.8813  , 0.8804  , 0.88    , 0.8794  ,\n",
       "            0.879   , 0.878   , 0.8774  , 0.876   , 0.871   , 0.8687  ,\n",
       "            0.867   , 0.8667  , 0.8657  , 0.865   , 0.8633  , 0.861   ,\n",
       "            0.854   , 0.8525  , 0.8467  , 0.8457  , 0.845   , 0.8447  ,\n",
       "            0.842   , 0.8403  , 0.8374  , 0.837   , 0.835   , 0.8345  ,\n",
       "            0.834   , 0.8335  , 0.833   , 0.832   , 0.8315  , 0.829   ,\n",
       "            0.8286  , 0.828   , 0.8228  , 0.8174  , 0.814   , 0.813   ,\n",
       "            0.8125  , 0.806   , 0.802   , 0.7964  , 0.7837  , 0.782   ,\n",
       "            0.7803  , 0.7783  , 0.769   , 0.767   , 0.7666  , 0.76    ,\n",
       "            0.759   , 0.757   , 0.75    , 0.7446  , 0.742   , 0.7407  ,\n",
       "            0.7393  , 0.7373  , 0.736   , 0.726   , 0.7246  , 0.7075  ,\n",
       "            0.706   , 0.6836  , 0.603   , 0.5884  , 0.5713  , 0.569   ,\n",
       "            0.5215  , 0.4514  , 0.4316  , 0.4229  , 0.4072  , 0.399   ,\n",
       "            0.394   , 0.3616  , 0.3228  , 0.3025  , 0.288   , 0.2578  ,\n",
       "            0.252   , 0.2455  , 0.2449  , 0.2224  , 0.2128  , 0.2106  ,\n",
       "            0.2004  , 0.2     , 0.1958  , 0.1917  , 0.1913  , 0.1708  ,\n",
       "            0.1705  , 0.166   , 0.1617  , 0.1477  , 0.112   , 0.1093  ,\n",
       "            0.1     , 0.0896  , 0.083   , 0.08167 , 0.08124 , 0.0772  ,\n",
       "            0.07043 , 0.06964 , 0.0629  , 0.0601  , 0.05792 , 0.0575  ,\n",
       "            0.05676 , 0.0552  , 0.05203 , 0.05023 , 0.04553 , 0.04477 ,\n",
       "            0.03662 , 0.03607 , 0.0354  , 0.02887 , 0.02182 , 0.02153 ,\n",
       "            0.01778 , 0.01772 , 0.01718 , 0.01359 , 0.011826, 0.01078 ,\n",
       "            0.010735, 0.008545, 0.007122, 0.00664 , 0.003456], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.52238804, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14179105, 0.14179105,\n",
       "            0.14179105, 0.14179105, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1641791 , 0.1641791 , 0.17910448, 0.17910448,\n",
       "            0.18656716, 0.18656716, 0.19402985, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23134328,\n",
       "            0.23134328, 0.23880596, 0.23880596, 0.24626866, 0.24626866,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29850745,\n",
       "            0.29850745, 0.29850745, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.04310345, 0.06034483,\n",
       "            0.06896552, 0.0775862 , 0.09482758, 0.11206897, 0.12931034,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.20689656,\n",
       "            0.22413793, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.30172414, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.35344827, 0.37931034, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.43103448, 0.43103448, 0.43965518, 0.43965518,\n",
       "            0.45689654, 0.45689654, 0.46551725, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.49137932, 0.5       , 0.51724136,\n",
       "            0.5258621 , 0.54310346, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.6034483 , 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6810345 , 0.6896552 , 0.6896552 , 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.999   , 0.9985  , 0.9976  , 0.997   , 0.9966  ,\n",
       "            0.996   , 0.9956  , 0.995   , 0.994   , 0.9937  , 0.9927  ,\n",
       "            0.9907  , 0.99    , 0.9897  , 0.9893  , 0.988   , 0.9873  ,\n",
       "            0.987   , 0.986   , 0.984   , 0.983   , 0.98    , 0.9795  ,\n",
       "            0.979   , 0.977   , 0.9766  , 0.9756  , 0.9736  , 0.9717  ,\n",
       "            0.9688  , 0.9683  , 0.9624  , 0.9614  , 0.961   , 0.9595  ,\n",
       "            0.959   , 0.958   , 0.9575  , 0.956   , 0.9536  , 0.9526  ,\n",
       "            0.952   , 0.95    , 0.949   , 0.948   , 0.9453  , 0.945   ,\n",
       "            0.9443  , 0.943   , 0.942   , 0.941   , 0.9395  , 0.9355  ,\n",
       "            0.935   , 0.934   , 0.9336  , 0.933   , 0.9326  , 0.9307  ,\n",
       "            0.93    , 0.9297  , 0.929   , 0.9277  , 0.9263  , 0.924   ,\n",
       "            0.923   , 0.92    , 0.9194  , 0.9155  , 0.9116  , 0.911   ,\n",
       "            0.91    , 0.9097  , 0.9077  , 0.9067  , 0.9053  , 0.9043  ,\n",
       "            0.903   , 0.901   , 0.899   , 0.898   , 0.8975  , 0.8965  ,\n",
       "            0.8955  , 0.8945  , 0.893   , 0.8916  , 0.886   , 0.8857  ,\n",
       "            0.8853  , 0.885   , 0.8843  , 0.8833  , 0.876   , 0.871   ,\n",
       "            0.8696  , 0.8667  , 0.866   , 0.8643  , 0.8604  , 0.8594  ,\n",
       "            0.859   , 0.8574  , 0.857   , 0.856   , 0.853   , 0.852   ,\n",
       "            0.85    , 0.8457  , 0.8413  , 0.84    , 0.839   , 0.834   ,\n",
       "            0.8315  , 0.8306  , 0.8247  , 0.8125  , 0.812   , 0.81    ,\n",
       "            0.8086  , 0.803   , 0.7993  , 0.7944  , 0.7896  , 0.781   ,\n",
       "            0.779   , 0.777   , 0.776   , 0.7734  , 0.773   , 0.7725  ,\n",
       "            0.77    , 0.7695  , 0.764   , 0.7583  , 0.756   , 0.738   ,\n",
       "            0.7373  , 0.7075  , 0.632   , 0.62    , 0.613   , 0.608   ,\n",
       "            0.5464  , 0.4746  , 0.4565  , 0.456   , 0.4312  , 0.422   ,\n",
       "            0.4163  , 0.3777  , 0.337   , 0.313   , 0.3083  , 0.283   ,\n",
       "            0.2651  , 0.263   , 0.2573  , 0.2379  , 0.2222  , 0.2211  ,\n",
       "            0.2096  , 0.2089  , 0.2086  , 0.2084  , 0.2037  , 0.1758  ,\n",
       "            0.1755  , 0.1733  , 0.1672  , 0.1586  , 0.11597 , 0.1136  ,\n",
       "            0.10614 , 0.09204 , 0.0863  , 0.0859  , 0.08417 , 0.0799  ,\n",
       "            0.07227 , 0.0707  , 0.0656  , 0.0611  , 0.05997 , 0.05975 ,\n",
       "            0.05707 , 0.05594 , 0.0526  , 0.0511  , 0.04553 , 0.04453 ,\n",
       "            0.03677 , 0.03574 , 0.0354  , 0.02898 , 0.02145 , 0.02129 ,\n",
       "            0.01758 , 0.01738 , 0.01698 , 0.01333 , 0.01142 , 0.01049 ,\n",
       "            0.01041 , 0.00822 , 0.00693 , 0.00651 , 0.003248], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5298507, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.07462686, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14179105, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.1641791 , 0.17910448, 0.17910448,\n",
       "            0.17910448, 0.17910448, 0.17910448, 0.17910448, 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23880596, 0.23880596, 0.23880596,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.29850745, 0.29850745, 0.29850745, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.35074627, 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41044775,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01724138, 0.02586207, 0.04310345, 0.06896552,\n",
       "            0.0775862 , 0.10344828, 0.11206897, 0.12931034, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18965517, 0.21551724,\n",
       "            0.22413793, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3448276 , 0.35344827, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.6034483 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8534483 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.999   , 0.9985  , 0.998   , 0.9976  , 0.997   ,\n",
       "            0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  , 0.994   ,\n",
       "            0.9927  , 0.992   , 0.9917  , 0.991   , 0.99    , 0.9897  ,\n",
       "            0.9893  , 0.989   , 0.987   , 0.9863  , 0.9854  , 0.9844  ,\n",
       "            0.984   , 0.9834  , 0.983   , 0.9814  , 0.981   , 0.98    ,\n",
       "            0.9795  , 0.979   , 0.9785  , 0.977   , 0.9766  , 0.9756  ,\n",
       "            0.974   , 0.9736  , 0.972   , 0.97    , 0.9697  , 0.969   ,\n",
       "            0.9688  , 0.9673  , 0.967   , 0.966   , 0.965   , 0.962   ,\n",
       "            0.9614  , 0.961   , 0.9604  , 0.958   , 0.9575  , 0.956   ,\n",
       "            0.954   , 0.9536  , 0.952   , 0.9507  , 0.949   , 0.9487  ,\n",
       "            0.948   , 0.947   , 0.9453  , 0.945   , 0.944   , 0.943   ,\n",
       "            0.941   , 0.939   , 0.9385  , 0.9355  , 0.9326  , 0.931   ,\n",
       "            0.929   , 0.9287  , 0.928   , 0.9272  , 0.926   , 0.9253  ,\n",
       "            0.9243  , 0.923   , 0.9224  , 0.9204  , 0.92    , 0.918   ,\n",
       "            0.9165  , 0.916   , 0.915   , 0.9146  , 0.914   , 0.913   ,\n",
       "            0.912   , 0.907   , 0.9067  , 0.9062  , 0.9053  , 0.905   ,\n",
       "            0.9043  , 0.904   , 0.899   , 0.8984  , 0.895   , 0.894   ,\n",
       "            0.893   , 0.89    , 0.8887  , 0.8857  , 0.885   , 0.884   ,\n",
       "            0.882   , 0.881   , 0.88    , 0.8784  , 0.878   , 0.8765  ,\n",
       "            0.873   , 0.872   , 0.869   , 0.867   , 0.8667  , 0.866   ,\n",
       "            0.8643  , 0.8594  , 0.8564  , 0.854   , 0.853   , 0.842   ,\n",
       "            0.8413  , 0.841   , 0.837   , 0.835   , 0.831   , 0.823   ,\n",
       "            0.8223  , 0.8135  , 0.81    , 0.8057  , 0.8022  , 0.798   ,\n",
       "            0.7974  , 0.7944  , 0.7905  , 0.7876  , 0.7705  , 0.768   ,\n",
       "            0.7393  , 0.674   , 0.655   , 0.6514  , 0.6455  , 0.5786  ,\n",
       "            0.505   , 0.492   , 0.4863  , 0.4695  , 0.4497  , 0.4448  ,\n",
       "            0.4038  , 0.361   , 0.334   , 0.332   , 0.31    , 0.2832  ,\n",
       "            0.283   , 0.2744  , 0.2556  , 0.236   , 0.2351  , 0.2283  ,\n",
       "            0.2273  , 0.2218  , 0.2217  , 0.2167  , 0.1874  , 0.187   ,\n",
       "            0.1837  , 0.177   , 0.1708  , 0.1236  , 0.1197  , 0.1126  ,\n",
       "            0.0962  , 0.09106 , 0.0899  , 0.0882  , 0.0836  , 0.07544 ,\n",
       "            0.07385 , 0.06854 , 0.06305 , 0.06232 , 0.06223 , 0.0592  ,\n",
       "            0.0576  , 0.0541  , 0.05243 , 0.04672 , 0.04596 , 0.03732 ,\n",
       "            0.0367  , 0.03595 , 0.02937 , 0.02153 , 0.02129 , 0.01758 ,\n",
       "            0.01738 , 0.01692 , 0.01322 , 0.011246, 0.01037 , 0.01021 ,\n",
       "            0.00803 , 0.006798, 0.006413, 0.00311 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5522388, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.12686567, 0.13432837, 0.13432837, 0.14179105, 0.14179105,\n",
       "            0.14179105, 0.14925373, 0.14925373, 0.15671642, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.17910448, 0.17910448,\n",
       "            0.17910448, 0.17910448, 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.19402985, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2835821 , 0.29104477, 0.29850745, 0.29850745,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.05172414, 0.06896552,\n",
       "            0.10344828, 0.11206897, 0.13793103, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.19827586, 0.22413793, 0.23275863, 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.3448276 ,\n",
       "            0.35344827, 0.37068966, 0.39655173, 0.4051724 , 0.4051724 ,\n",
       "            0.41379312, 0.41379312, 0.43103448, 0.44827586, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.47413793, 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.5603448 , 0.57758623,\n",
       "            0.57758623, 0.5948276 , 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.9956  , 0.9946  , 0.994   ,\n",
       "            0.9937  , 0.9927  , 0.992   , 0.9917  , 0.991   , 0.99    ,\n",
       "            0.9897  , 0.9893  , 0.988   , 0.9873  , 0.987   , 0.9863  ,\n",
       "            0.986   , 0.9854  , 0.9844  , 0.984   , 0.9834  , 0.9824  ,\n",
       "            0.982   , 0.981   , 0.979   , 0.9785  , 0.978   , 0.9775  ,\n",
       "            0.976   , 0.9746  , 0.9736  , 0.9717  , 0.971   , 0.9707  ,\n",
       "            0.97    , 0.9697  , 0.969   , 0.968   , 0.967   , 0.9653  ,\n",
       "            0.965   , 0.964   , 0.9634  , 0.963   , 0.9624  , 0.961   ,\n",
       "            0.96    , 0.9595  , 0.958   , 0.9575  , 0.9565  , 0.9546  ,\n",
       "            0.954   , 0.951   , 0.95    , 0.9497  , 0.948   , 0.9478  ,\n",
       "            0.947   , 0.9463  , 0.946   , 0.9434  , 0.943   , 0.9424  ,\n",
       "            0.941   , 0.9404  , 0.9375  , 0.9365  , 0.936   , 0.935   ,\n",
       "            0.9346  , 0.934   , 0.9326  , 0.929   , 0.928   , 0.9277  ,\n",
       "            0.9263  , 0.926   , 0.925   , 0.922   , 0.9214  , 0.9194  ,\n",
       "            0.919   , 0.916   , 0.9146  , 0.9116  , 0.911   , 0.9106  ,\n",
       "            0.909   , 0.9077  , 0.907   , 0.9043  , 0.904   , 0.902   ,\n",
       "            0.9014  , 0.8975  , 0.8955  , 0.8945  , 0.894   , 0.8867  ,\n",
       "            0.8833  , 0.883   , 0.882   , 0.8745  , 0.874   , 0.873   ,\n",
       "            0.8716  , 0.868   , 0.867   , 0.8647  , 0.857   , 0.854   ,\n",
       "            0.851   , 0.845   , 0.8413  , 0.84    , 0.8384  , 0.8335  ,\n",
       "            0.8296  , 0.828   , 0.827   , 0.8267  , 0.8257  , 0.8223  ,\n",
       "            0.805   , 0.8013  , 0.7686  , 0.7173  , 0.6978  , 0.6836  ,\n",
       "            0.676   , 0.608   , 0.5327  , 0.5254  , 0.513   , 0.5054  ,\n",
       "            0.471   , 0.4683  , 0.4258  , 0.38    , 0.3523  , 0.3484  ,\n",
       "            0.3342  , 0.3003  , 0.2969  , 0.2861  , 0.2683  , 0.2455  ,\n",
       "            0.2438  , 0.243   , 0.2422  , 0.2302  , 0.2294  , 0.2249  ,\n",
       "            0.1936  , 0.1935  , 0.1892  , 0.1821  , 0.1783  , 0.127   ,\n",
       "            0.1216  , 0.1152  , 0.09686 , 0.0925  , 0.09076 , 0.089   ,\n",
       "            0.08405 , 0.07544 , 0.074   , 0.06854 , 0.06223 , 0.06198 ,\n",
       "            0.0619  , 0.0589  , 0.05676 , 0.0532  , 0.05154 , 0.04587 ,\n",
       "            0.04535 , 0.03622 , 0.03595 , 0.03482 , 0.02834 , 0.0206  ,\n",
       "            0.02025 , 0.01666 , 0.01653 , 0.01602 , 0.01243 , 0.01045 ,\n",
       "            0.009636, 0.00948 , 0.007404, 0.006264, 0.005936, 0.0028  ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5597015, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.05970149,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14179105, 0.14179105, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.1641791 , 0.1641791 , 0.1716418 , 0.17910448, 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.25373134, 0.26119402, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29850745, 0.29850745, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.31343284, 0.31343284,\n",
       "            0.31343284, 0.31343284, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.02586207, 0.05172414, 0.0775862 , 0.11206897,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.1724138 , 0.18965517,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25862068, 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.3448276 ,\n",
       "            0.35344827, 0.37068966, 0.37068966, 0.38793105, 0.4051724 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5258621 , 0.5344828 , 0.5344828 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.70689654, 0.70689654, 0.7155172 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  ,\n",
       "            0.994   , 0.9937  , 0.993   , 0.992   , 0.9917  , 0.9907  ,\n",
       "            0.99    , 0.9893  , 0.989   , 0.9883  , 0.988   , 0.9873  ,\n",
       "            0.987   , 0.9854  , 0.985   , 0.9844  , 0.984   , 0.983   ,\n",
       "            0.9824  , 0.9805  , 0.9795  , 0.979   , 0.9785  , 0.978   ,\n",
       "            0.9766  , 0.976   , 0.9756  , 0.975   , 0.9746  , 0.974   ,\n",
       "            0.9736  , 0.9727  , 0.9717  , 0.9707  , 0.97    , 0.969   ,\n",
       "            0.968   , 0.9673  , 0.967   , 0.966   , 0.9644  , 0.9634  ,\n",
       "            0.963   , 0.9624  , 0.962   , 0.961   , 0.9595  , 0.958   ,\n",
       "            0.9575  , 0.956   , 0.9556  , 0.9536  , 0.953   , 0.9526  ,\n",
       "            0.951   , 0.9507  , 0.95    , 0.949   , 0.9487  , 0.948   ,\n",
       "            0.947   , 0.946   , 0.945   , 0.9443  , 0.943   , 0.9424  ,\n",
       "            0.941   , 0.9404  , 0.94    , 0.9395  , 0.9385  , 0.937   ,\n",
       "            0.9346  , 0.932   , 0.9316  , 0.931   , 0.9297  , 0.9287  ,\n",
       "            0.928   , 0.9253  , 0.925   , 0.9243  , 0.924   , 0.9233  ,\n",
       "            0.922   , 0.921   , 0.92    , 0.9175  , 0.917   , 0.9155  ,\n",
       "            0.9106  , 0.9077  , 0.9062  , 0.905   , 0.902   , 0.901   ,\n",
       "            0.8994  , 0.8975  , 0.8965  , 0.8936  , 0.893   , 0.8867  ,\n",
       "            0.8833  , 0.8804  , 0.8765  , 0.873   , 0.87    , 0.858   ,\n",
       "            0.857   , 0.856   , 0.8555  , 0.8535  , 0.853   , 0.852   ,\n",
       "            0.836   , 0.8315  , 0.798   , 0.7573  , 0.739   , 0.72    ,\n",
       "            0.7065  , 0.641   , 0.565   , 0.5635  , 0.546   , 0.545   ,\n",
       "            0.501   , 0.4998  , 0.4556  , 0.407   , 0.3784  , 0.3726  ,\n",
       "            0.3643  , 0.3232  , 0.3179  , 0.3062  , 0.2876  , 0.2632  ,\n",
       "            0.2627  , 0.262   , 0.2595  , 0.247   , 0.2437  , 0.2397  ,\n",
       "            0.2075  , 0.207   , 0.2007  , 0.1941  , 0.1919  , 0.1355  ,\n",
       "            0.1292  , 0.12213 , 0.10144 , 0.0977  , 0.09515 , 0.0932  ,\n",
       "            0.0882  , 0.0786  , 0.07794 , 0.0716  , 0.0643  , 0.06152 ,\n",
       "            0.05856 , 0.0548  , 0.053   , 0.04733 , 0.04724 , 0.0372  ,\n",
       "            0.0369  , 0.0355  , 0.02881 , 0.02092 , 0.02042 , 0.01672 ,\n",
       "            0.0161  , 0.01243 , 0.01041 , 0.00956 , 0.009415, 0.007317,\n",
       "            0.00619 , 0.005867, 0.002726], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5671642, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14179105, 0.14179105,\n",
       "            0.14925373, 0.1641791 , 0.1716418 , 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.17910448, 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20149253, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23134328, 0.23880596, 0.23880596,\n",
       "            0.24626866, 0.26119402, 0.26865673, 0.2761194 , 0.29104477,\n",
       "            0.29850745, 0.29850745, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.04310345, 0.0775862 , 0.11206897, 0.14655173,\n",
       "            0.1637931 , 0.1724138 , 0.20689656, 0.23275863, 0.25      ,\n",
       "            0.25862068, 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3448276 , 0.36206895, 0.37068966,\n",
       "            0.4051724 , 0.43103448, 0.43965518, 0.44827586, 0.46551725,\n",
       "            0.47413793, 0.5       , 0.5086207 , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.51724136, 0.55172414, 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5862069 , 0.5862069 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  ,\n",
       "            0.994   , 0.9937  , 0.993   , 0.9927  , 0.992   , 0.9917  ,\n",
       "            0.991   , 0.9907  , 0.99    , 0.9897  , 0.9893  , 0.989   ,\n",
       "            0.9863  , 0.986   , 0.9854  , 0.985   , 0.9844  , 0.984   ,\n",
       "            0.9834  , 0.983   , 0.9824  , 0.982   , 0.981   , 0.9805  ,\n",
       "            0.9795  , 0.979   , 0.9785  , 0.978   , 0.9775  , 0.977   ,\n",
       "            0.976   , 0.9756  , 0.9746  , 0.9736  , 0.9727  , 0.9717  ,\n",
       "            0.97    , 0.9697  , 0.969   , 0.9688  , 0.968   , 0.967   ,\n",
       "            0.9663  , 0.965   , 0.9644  , 0.9634  , 0.963   , 0.9624  ,\n",
       "            0.962   , 0.9614  , 0.961   , 0.9604  , 0.9585  , 0.958   ,\n",
       "            0.9565  , 0.956   , 0.9556  , 0.955   , 0.954   , 0.9536  ,\n",
       "            0.9526  , 0.95    , 0.9487  , 0.9478  , 0.947   , 0.9463  ,\n",
       "            0.9453  , 0.945   , 0.942   , 0.9414  , 0.9404  , 0.9395  ,\n",
       "            0.9385  , 0.936   , 0.9355  , 0.933   , 0.9277  , 0.927   ,\n",
       "            0.9253  , 0.924   , 0.9224  , 0.921   , 0.919   , 0.9185  ,\n",
       "            0.9165  , 0.915   , 0.913   , 0.9106  , 0.9087  , 0.903   ,\n",
       "            0.9014  , 0.8984  , 0.896   , 0.895   , 0.883   , 0.8813  ,\n",
       "            0.881   , 0.8794  , 0.879   , 0.8784  , 0.8755  , 0.8633  ,\n",
       "            0.8584  , 0.83    , 0.798   , 0.7817  , 0.7607  , 0.7407  ,\n",
       "            0.6836  , 0.6104  , 0.6064  , 0.596   , 0.5864  , 0.541   ,\n",
       "            0.5405  , 0.496   , 0.4448  , 0.4153  , 0.4062  , 0.4055  ,\n",
       "            0.3572  , 0.349   , 0.3364  , 0.3174  , 0.2937  , 0.2935  ,\n",
       "            0.2876  , 0.285   , 0.2725  , 0.2664  , 0.2632  , 0.2283  ,\n",
       "            0.2278  , 0.2198  , 0.214   , 0.1505  , 0.1412  , 0.1346  ,\n",
       "            0.1103  , 0.1076  , 0.10394 , 0.1019  , 0.0962  , 0.0857  ,\n",
       "            0.0848  , 0.07825 , 0.06995 , 0.0698  , 0.0693  , 0.06683 ,\n",
       "            0.0629  , 0.0589  , 0.05707 , 0.051   , 0.04    , 0.03934 ,\n",
       "            0.03775 , 0.03073 , 0.02216 , 0.02153 , 0.01772 , 0.01758 ,\n",
       "            0.01698 , 0.01302 , 0.01086 , 0.01001 , 0.00982 , 0.007607,\n",
       "            0.006462, 0.00617 , 0.00279 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.57462686, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.02985075, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.05970149,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.12686567, 0.13432837, 0.13432837, 0.13432837,\n",
       "            0.14179105, 0.14179105, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.17910448, 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20149253, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.35820895, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.06896552, 0.11206897, 0.14655173,\n",
       "            0.1637931 , 0.18103448, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.27586207, 0.28448275, 0.31034482, 0.31034482, 0.3448276 ,\n",
       "            0.36206895, 0.39655173, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.4827586 , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.55172414, 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.75      , 0.75      , 0.7586207 , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 1.      , 0.9995  , 0.999   , 0.9985  , 0.998   ,\n",
       "            0.9976  , 0.997   , 0.9966  , 0.996   , 0.9956  , 0.995   ,\n",
       "            0.9946  , 0.9937  , 0.993   , 0.9927  , 0.992   , 0.9917  ,\n",
       "            0.991   , 0.9907  , 0.99    , 0.9893  , 0.9883  , 0.988   ,\n",
       "            0.9873  , 0.987   , 0.9863  , 0.986   , 0.985   , 0.9844  ,\n",
       "            0.984   , 0.983   , 0.9824  , 0.982   , 0.9814  , 0.981   ,\n",
       "            0.9805  , 0.98    , 0.9795  , 0.979   , 0.9785  , 0.978   ,\n",
       "            0.9775  , 0.977   , 0.9766  , 0.9756  , 0.975   , 0.974   ,\n",
       "            0.9736  , 0.9727  , 0.972   , 0.971   , 0.97    , 0.9697  ,\n",
       "            0.969   , 0.9688  , 0.968   , 0.9673  , 0.966   , 0.965   ,\n",
       "            0.9644  , 0.964   , 0.9634  , 0.963   , 0.9624  , 0.962   ,\n",
       "            0.9614  , 0.9604  , 0.958   , 0.957   , 0.956   , 0.955   ,\n",
       "            0.9546  , 0.9536  , 0.953   , 0.951   , 0.9507  , 0.95    ,\n",
       "            0.949   , 0.9487  , 0.948   , 0.947   , 0.9453  , 0.943   ,\n",
       "            0.938   , 0.9355  , 0.935   , 0.9326  , 0.932   , 0.9307  ,\n",
       "            0.93    , 0.928   , 0.9263  , 0.9233  , 0.922   , 0.915   ,\n",
       "            0.9146  , 0.912   , 0.9097  , 0.9087  , 0.8975  , 0.895   ,\n",
       "            0.894   , 0.8936  , 0.8926  , 0.8896  , 0.8887  , 0.878   ,\n",
       "            0.8735  , 0.8457  , 0.8184  , 0.803   , 0.7812  , 0.755   ,\n",
       "            0.7046  , 0.6343  , 0.627   , 0.6226  , 0.607   , 0.561   ,\n",
       "            0.5576  , 0.5156  , 0.4631  , 0.4346  , 0.4292  , 0.4194  ,\n",
       "            0.3752  , 0.3655  , 0.3518  , 0.3337  , 0.311   , 0.3105  ,\n",
       "            0.3005  , 0.2979  , 0.2847  , 0.2786  , 0.2747  , 0.2372  ,\n",
       "            0.2367  , 0.2294  , 0.2263  , 0.2235  , 0.1587  , 0.1459  ,\n",
       "            0.1415  , 0.11456 , 0.11316 , 0.1082  , 0.1063  , 0.10016 ,\n",
       "            0.0893  , 0.0871  , 0.082   , 0.07306 , 0.0729  , 0.0716  ,\n",
       "            0.0689  , 0.065   , 0.06085 , 0.059   , 0.05234 , 0.05225 ,\n",
       "            0.04092 , 0.04047 , 0.03882 , 0.03168 , 0.02254 , 0.02203 ,\n",
       "            0.01816 , 0.01791 , 0.01738 , 0.01333 , 0.01103 , 0.01021 ,\n",
       "            0.00993 , 0.007694, 0.006588, 0.006363, 0.002811], dtype=float16)}}]],\n",
       " 'roc_results': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.00333333,\n",
       "         0.00333333, 0.00666667, 0.00666667, 0.01      , 0.01      ,\n",
       "         0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,\n",
       "         0.01333333, 0.01666667, 0.02      , 0.02666667, 0.04      ,\n",
       "         0.04666667, 0.05333333, 0.06333333, 0.06666667, 0.07      ,\n",
       "         0.07333333, 0.08666667, 0.09666666, 0.10333333, 0.10333333,\n",
       "         0.10333333, 0.11      , 0.12333333, 0.13333334, 0.13333334,\n",
       "         0.15      , 0.16666667, 0.18666667, 0.19      , 0.19666667,\n",
       "         0.21      , 0.22666667, 0.24      , 0.25666666, 0.26666668,\n",
       "         0.28333333, 0.29333332, 0.30666667, 0.32      , 0.34      ,\n",
       "         0.35      , 0.36      , 0.36666667, 0.37      , 0.38333333,\n",
       "         0.40333334, 0.41333333, 0.41666666, 0.42333335, 0.43333334,\n",
       "         0.44333333, 0.44666666, 0.45666668, 0.46      , 0.46333334,\n",
       "         0.47      , 0.48      , 0.48666668, 0.49      , 0.49      ,\n",
       "         0.49666667, 0.50333333, 0.52      , 0.52666664, 0.53      ,\n",
       "         0.53333336, 0.54      , 0.54333335, 0.55      , 0.55333334,\n",
       "         0.56333333, 0.56333333, 0.57      , 0.5833333 , 0.5933333 ,\n",
       "         0.5966667 , 0.5966667 , 0.61      , 0.61333334, 0.62      ,\n",
       "         0.62666667, 0.6333333 , 0.6333333 , 0.6333333 , 0.63666666,\n",
       "         0.64      , 0.64      , 0.6433333 , 0.65      , 0.6533333 ,\n",
       "         0.6533333 , 0.6566667 , 0.66      , 0.66333336, 0.6666667 ,\n",
       "         0.67333335, 0.6766667 , 0.6766667 , 0.68      , 0.6933333 ,\n",
       "         0.69666666, 0.7       , 0.7033333 , 0.70666665, 0.71      ,\n",
       "         0.7133333 , 0.7133333 , 0.7133333 , 0.72      , 0.72333336,\n",
       "         0.7266667 , 0.7266667 , 0.73      , 0.73      , 0.74      ,\n",
       "         0.74      , 0.74333334, 0.74333334, 0.75      , 0.75333333,\n",
       "         0.75666666, 0.76      , 0.76666665, 0.77      , 0.77      ,\n",
       "         0.77      , 0.7733333 , 0.77666664, 0.78      , 0.78333336,\n",
       "         0.78333336, 0.79      , 0.79333335, 0.7966667 , 0.8       ,\n",
       "         0.81      , 0.82      , 0.82      , 0.82      , 0.82      ,\n",
       "         0.82      , 0.82      , 0.8233333 , 0.82666665, 0.82666665,\n",
       "         0.82666665, 0.83      , 0.83      , 0.83      , 0.8333333 ,\n",
       "         0.83666664, 0.83666664, 0.84      , 0.84      , 0.8433333 ,\n",
       "         0.8433333 , 0.8433333 , 0.8466667 , 0.85      , 0.85      ,\n",
       "         0.85      , 0.85333335, 0.85333335, 0.86      , 0.86333334,\n",
       "         0.86333334, 0.87      , 0.87666667, 0.88      , 0.8833333 ,\n",
       "         0.89      , 0.89      , 0.89      , 0.8933333 , 0.8933333 ,\n",
       "         0.8933333 , 0.8933333 , 0.89666665, 0.89666665, 0.89666665,\n",
       "         0.9       , 0.9033333 , 0.9066667 , 0.9066667 , 0.9066667 ,\n",
       "         0.9066667 , 0.91      , 0.91333336, 0.91333336, 0.9166667 ,\n",
       "         0.9166667 , 0.9166667 , 0.92      , 0.92333335, 0.9266667 ,\n",
       "         0.93      , 0.93333334, 0.93666667, 0.9433333 , 0.94666666,\n",
       "         0.95      , 0.9533333 , 0.9533333 , 0.9533333 , 0.95666665,\n",
       "         0.96      , 0.96      , 0.96      , 0.9633333 , 0.9633333 ,\n",
       "         0.9633333 , 0.96666664, 0.96666664, 0.97      , 0.97333336,\n",
       "         0.97333336, 0.98      , 0.98      , 0.98333335, 0.9866667 ,\n",
       "         0.9866667 , 0.9866667 , 0.9866667 , 0.99      , 0.99333334,\n",
       "         0.99333334, 0.99333334, 0.99333334, 0.99333334, 0.99666667,\n",
       "         0.99666667, 0.99666667, 1.        , 1.        , 1.        ],\n",
       "        dtype=float32),\n",
       "  'tpr': array([0.        , 0.00333333, 0.00666667, 0.01      , 0.02      ,\n",
       "         0.03      , 0.05333333, 0.07333333, 0.07666667, 0.08      ,\n",
       "         0.1       , 0.11333334, 0.12666667, 0.13      , 0.14      ,\n",
       "         0.15      , 0.16      , 0.16666667, 0.17333333, 0.18666667,\n",
       "         0.19      , 0.19333333, 0.20333333, 0.21333334, 0.23333333,\n",
       "         0.23333333, 0.23666666, 0.24666667, 0.25333333, 0.26333332,\n",
       "         0.27333334, 0.28333333, 0.28666666, 0.29333332, 0.3       ,\n",
       "         0.30333334, 0.31333333, 0.31666666, 0.32      , 0.33      ,\n",
       "         0.33333334, 0.34666666, 0.34666666, 0.35333332, 0.36666667,\n",
       "         0.37      , 0.38      , 0.39      , 0.39      , 0.4       ,\n",
       "         0.40666667, 0.41666666, 0.42666668, 0.43333334, 0.43666667,\n",
       "         0.43666667, 0.44333333, 0.45      , 0.45      , 0.46      ,\n",
       "         0.47666666, 0.47666666, 0.48333332, 0.48333332, 0.48666668,\n",
       "         0.48666668, 0.49333334, 0.50666666, 0.51666665, 0.53      ,\n",
       "         0.54333335, 0.55      , 0.55      , 0.5566667 , 0.56666666,\n",
       "         0.56666666, 0.56666666, 0.5733333 , 0.57666665, 0.58666664,\n",
       "         0.5966667 , 0.5966667 , 0.5966667 , 0.60333335, 0.61      ,\n",
       "         0.61333334, 0.62      , 0.62      , 0.62333333, 0.62333333,\n",
       "         0.63      , 0.63      , 0.63666666, 0.63666666, 0.6433333 ,\n",
       "         0.65      , 0.6533333 , 0.6566667 , 0.66      , 0.66333336,\n",
       "         0.6666667 , 0.67333335, 0.6766667 , 0.68      , 0.68666667,\n",
       "         0.68666667, 0.68666667, 0.69      , 0.69666666, 0.69666666,\n",
       "         0.69666666, 0.7       , 0.7       , 0.7       , 0.7033333 ,\n",
       "         0.71      , 0.71666664, 0.71666664, 0.71666664, 0.71666664,\n",
       "         0.72      , 0.72      , 0.73      , 0.73333335, 0.73333335,\n",
       "         0.73333335, 0.73333335, 0.73333335, 0.73333335, 0.7366667 ,\n",
       "         0.74333334, 0.74666667, 0.75      , 0.75      , 0.75      ,\n",
       "         0.75      , 0.75333333, 0.75666666, 0.76      , 0.76      ,\n",
       "         0.7633333 , 0.77      , 0.7733333 , 0.77666664, 0.77666664,\n",
       "         0.78      , 0.78333336, 0.78333336, 0.78333336, 0.7866667 ,\n",
       "         0.79      , 0.79333335, 0.79333335, 0.79333335, 0.79333335,\n",
       "         0.7966667 , 0.7966667 , 0.7966667 , 0.7966667 , 0.7966667 ,\n",
       "         0.7966667 , 0.7966667 , 0.8       , 0.80333334, 0.8066667 ,\n",
       "         0.81      , 0.81333333, 0.81666666, 0.81666666, 0.8233333 ,\n",
       "         0.82666665, 0.83      , 0.8333333 , 0.83666664, 0.83666664,\n",
       "         0.83666664, 0.84      , 0.84      , 0.8433333 , 0.8433333 ,\n",
       "         0.8466667 , 0.85      , 0.85      , 0.85      , 0.85333335,\n",
       "         0.8566667 , 0.86      , 0.86333334, 0.8666667 , 0.8666667 ,\n",
       "         0.87      , 0.87666667, 0.87666667, 0.87666667, 0.87666667,\n",
       "         0.87666667, 0.88      , 0.8833333 , 0.8833333 , 0.88666666,\n",
       "         0.89      , 0.8933333 , 0.8933333 , 0.89666665, 0.9       ,\n",
       "         0.9       , 0.9       , 0.9       , 0.9033333 , 0.9066667 ,\n",
       "         0.91      , 0.91      , 0.91      , 0.91333336, 0.91333336,\n",
       "         0.9166667 , 0.92      , 0.92      , 0.92      , 0.92      ,\n",
       "         0.92      , 0.92      , 0.92      , 0.92      , 0.92333335,\n",
       "         0.92333335, 0.9266667 , 0.93      , 0.93333334, 0.93333334,\n",
       "         0.93666667, 0.94      , 0.9433333 , 0.94666666, 0.95      ,\n",
       "         0.9533333 , 0.9533333 , 0.95666665, 0.95666665, 0.95666665,\n",
       "         0.96      , 0.96      , 0.9633333 , 0.9633333 , 0.9633333 ,\n",
       "         0.96666664, 0.97      , 0.97333336, 0.97333336, 0.97333336,\n",
       "         0.9766667 , 0.98      , 0.98333335, 0.9866667 , 0.9866667 ,\n",
       "         0.99      , 0.99333334, 0.99333334, 0.99666667, 1.        ],\n",
       "        dtype=float32),\n",
       "  'thresholds': array([1.    , 0.5356, 0.535 , 0.5347, 0.534 , 0.5337, 0.533 , 0.5327,\n",
       "         0.532 , 0.5317, 0.5312, 0.531 , 0.5303, 0.53  , 0.5293, 0.529 ,\n",
       "         0.5283, 0.528 , 0.5273, 0.527 , 0.5264, 0.5254, 0.525 , 0.5244,\n",
       "         0.524 , 0.5234, 0.523 , 0.5225, 0.522 , 0.5215, 0.521 , 0.5205,\n",
       "         0.52  , 0.5195, 0.519 , 0.5186, 0.518 , 0.5176, 0.517 , 0.516 ,\n",
       "         0.5156, 0.515 , 0.5146, 0.5137, 0.513 , 0.5127, 0.512 , 0.5117,\n",
       "         0.511 , 0.5107, 0.5103, 0.51  , 0.5093, 0.509 , 0.5083, 0.508 ,\n",
       "         0.5073, 0.507 , 0.5063, 0.506 , 0.5054, 0.505 , 0.5044, 0.504 ,\n",
       "         0.5034, 0.503 , 0.5024, 0.502 , 0.5015, 0.501 , 0.5005, 0.5   ,\n",
       "         0.4998, 0.4995, 0.4993, 0.499 , 0.4988, 0.4985, 0.4983, 0.498 ,\n",
       "         0.4978, 0.4976, 0.4973, 0.497 , 0.4968, 0.4966, 0.4963, 0.4958,\n",
       "         0.4956, 0.4954, 0.495 , 0.4949, 0.4946, 0.4944, 0.4941, 0.4937,\n",
       "         0.4934, 0.4932, 0.493 , 0.4927, 0.4924, 0.4922, 0.492 , 0.4917,\n",
       "         0.4912, 0.491 , 0.4907, 0.4902, 0.49  , 0.4897, 0.4895, 0.489 ,\n",
       "         0.4885, 0.4883, 0.4868, 0.4863, 0.486 , 0.4856, 0.485 , 0.4849,\n",
       "         0.4844, 0.4841, 0.484 , 0.483 , 0.4827, 0.4822, 0.482 , 0.4812,\n",
       "         0.481 , 0.4807, 0.4805, 0.4802, 0.48  , 0.4797, 0.4795, 0.4792,\n",
       "         0.479 , 0.4788, 0.4783, 0.4778, 0.477 , 0.4768, 0.4766, 0.476 ,\n",
       "         0.4749, 0.4744, 0.474 , 0.4739, 0.4736, 0.4727, 0.4724, 0.472 ,\n",
       "         0.471 , 0.4707, 0.4697, 0.469 , 0.4688, 0.4685, 0.4683, 0.4678,\n",
       "         0.4675, 0.4673, 0.467 , 0.4668, 0.4663, 0.466 , 0.4653, 0.464 ,\n",
       "         0.4639, 0.4634, 0.4631, 0.463 , 0.4626, 0.4624, 0.462 , 0.4617,\n",
       "         0.4614, 0.4612, 0.4602, 0.46  , 0.4597, 0.4595, 0.4592, 0.4587,\n",
       "         0.4583, 0.458 , 0.4575, 0.457 , 0.4568, 0.4563, 0.4558, 0.4553,\n",
       "         0.455 , 0.4548, 0.454 , 0.4521, 0.452 , 0.4512, 0.4504, 0.4502,\n",
       "         0.4495, 0.4482, 0.4475, 0.4473, 0.4463, 0.4453, 0.4448, 0.4436,\n",
       "         0.4426, 0.4424, 0.4412, 0.441 , 0.4407, 0.4402, 0.44  , 0.438 ,\n",
       "         0.4373, 0.4355, 0.435 , 0.4348, 0.4346, 0.434 , 0.4324, 0.432 ,\n",
       "         0.431 , 0.43  , 0.4297, 0.4294, 0.429 , 0.4282, 0.4277, 0.4275,\n",
       "         0.4268, 0.426 , 0.4253, 0.425 , 0.424 , 0.4236, 0.4229, 0.4214,\n",
       "         0.4211, 0.421 , 0.4194, 0.418 , 0.4177, 0.4172, 0.4167, 0.415 ,\n",
       "         0.4138, 0.4136, 0.4128, 0.4106, 0.4094, 0.4082, 0.4053, 0.405 ,\n",
       "         0.4043, 0.3977, 0.3958, 0.381 ], dtype=float16),\n",
       "  'name': 'Original NN data1',\n",
       "  'auc': array(0.6139444, dtype=float32),\n",
       "  'model': LitClassifier(\n",
       "    (model): SimpleClassifier(\n",
       "      (layer_stack): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): BCEWithLogitsLoss()\n",
       "    (train_accuracy): BinaryAccuracy()\n",
       "    (test_accuracy): BinaryAccuracy()\n",
       "    (test_auc): BinaryAUROC()\n",
       "  )},\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x71378e8e1880>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Save the data\n",
    "save_to_pickle(list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader, filename='pickle/NN_data2_weighted.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3aba17",
   "metadata": {},
   "source": [
    "# Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "256006b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Load the data\n",
    "list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader = load_from_pickle(filename='pickle/NN_data2_weighted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5d9c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275941a6",
   "metadata": {},
   "source": [
    "### Ensemble prediction using voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586c430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a single ensemble from 156 models across all folds.\n",
      "Extracting full dataset...\n",
      "Getting predictions from all models...\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Loop through all the FPR values to generate the ensemble ROC curve ---\n",
    "\n",
    "\n",
    "\n",
    "results_tuple = predict_ensemble_and_evaluate(list_folds_best_models=list_folds_best_models,\n",
    "    test_loader=test_loader)\n",
    "\n",
    "ensemble_results_soft = results_tuple['soft_voting']\n",
    "ensemble_results_hard = results_tuple['hard_voting']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae1a225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Plotting all ROC curves for comparison ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "results_lists.append(ensemble_results_soft)\n",
    "results_lists.append(ensemble_results_hard)\n",
    "\n",
    "\n",
    "# --- Plot the final comparison ---\n",
    "print(\"\\n--- Plotting all ROC curves for comparison ---\")\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\", \"Ensemble_voting_soft\", \"Ensemble_voting_hard\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54a198",
   "metadata": {},
   "source": [
    "## Check performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ba0e7",
   "metadata": {},
   "source": [
    "## Check performance on test1 and test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f504bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_performance_tester(classifier_list, test_loader):\n",
    "\n",
    "    list_weighted_clfs = []  # Reset the list for final testing\n",
    "    for i, model_info in enumerate(classifier_list):\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "\n",
    "        model = model_info[\"model\"]\n",
    "        raw_threshold = model_info[\"threshold\"]\n",
    "\n",
    "\n",
    "        # CORRECTED: Use isinstance() to check if model is a string\n",
    "        if isinstance(model, str):\n",
    "            print(f\"Skipping model {i+1} as it is a string placeholder: '{model}'\")\n",
    "            continue\n",
    "\n",
    "        # Check if the stored threshold is a NumPy number or a PyTorch Tensor\n",
    "        if isinstance(raw_threshold, (np.number, torch.Tensor)):\n",
    "            # If it is, we can safely call .item() to extract the Python float\n",
    "            threshold = raw_threshold.item()\n",
    "        else:\n",
    "            # Otherwise, it's already a float or something that can be cast to one\n",
    "            threshold = float(raw_threshold)\n",
    "        model.current_test_threshold = threshold  # Set the threshold for this model\n",
    "\n",
    "        # This code will now only run if 'model' is a PyTorch Lightning module\n",
    "        # and not a string.\n",
    "        print(f\"--- Testing model {i+1} ---\")\n",
    "\n",
    "        trainer.test(model, dataloaders=test_loader, ckpt_path=None)\n",
    "        \n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "\n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not list_weighted_clfs or list_weighted_clfs[0]['fpr'] > 0.0:\n",
    "        list_weighted_clfs.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if list_weighted_clfs[-1]['fpr'] < 1.0 or list_weighted_clfs[-1]['tpr'] < 1.0:\n",
    "        list_weighted_clfs.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return list_weighted_clfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLlabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
