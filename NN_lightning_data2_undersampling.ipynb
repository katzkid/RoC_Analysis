{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f27ae675",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6227ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d840881",
   "metadata": {},
   "source": [
    "## Display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c24af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for displaying ROC curves of multiple classifiers\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_connected_points(results_list, results_original_roc, name=\"All Classifiers\"):\n",
    "    \"\"\"\n",
    "    Creates a plot showing the performance of all classifiers as points,\n",
    "    and connects them with a line, sorted by FPR.\n",
    "\n",
    "    Args:\n",
    "        results_list: A list of dictionaries, where each dict contains 'fpr', 'tpr'.\n",
    "    \"\"\"\n",
    "    if not results_list:\n",
    "        print(\"No results to plot.\")\n",
    "        return\n",
    "\n",
    "    # Convert results to a pandas DataFrame for easy sorting\n",
    "    df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Sort the models by their False Positive Rate to create a left-to-right line\n",
    "    df_sorted = df.sort_values(by='fpr').reset_index(drop=True)\n",
    "    \n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot all the individual model points as a scatter plot\n",
    "    # This helps see the actual performance of each model\n",
    "    plt.scatter(df_sorted['fpr'], df_sorted['tpr'], c='black', marker='o', \n",
    "                alpha=0.6, s=100, zorder=3) # zorder=3 puts dots on top\n",
    "\n",
    "    # Plot the line connecting the points\n",
    "    plt.plot(df_sorted['fpr'], df_sorted['tpr'], color='red', lw=1.5,\n",
    "             alpha=0.8, label=f'{name} (AUC = {auc(df_sorted[\"fpr\"], df_sorted[\"tpr\"]):.2f})')\n",
    "    \n",
    "    #plot the original ROC curve\n",
    "    plt.plot(results_original_roc[\"fpr\"], results_original_roc[\"tpr\"], color='blue', \n",
    "             label=f'{results_original_roc[\"name\"]} (AUC = {results_original_roc[\"auc\"]:.2f})')\n",
    "\n",
    "    # Plot the \"no-skill\" line for reference\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Performance Path of All Trained Classifiers')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23b1ea",
   "metadata": {},
   "source": [
    "## Best ROC envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e350c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def get_best_roc_envelope(results_list, results_original_roc=None):\n",
    "    \"\"\"\n",
    "    Constructs the upper envelope of multiple ROC curves to find the best\n",
    "    possible operating points from a collection of classifiers.\n",
    "\n",
    "    This function is guaranteed to produce a list of points that starts at\n",
    "    (FPR=0, TPR=0) and ends at (FPR=1, TPR=1), making it suitable for direct\n",
    "    plotting and AUC calculation.\n",
    "\n",
    "    Args:\n",
    "        results_list (list): A list of dictionaries. Each dictionary must\n",
    "                             contain a 'model' name and the full ROC results\n",
    "                             under the 'full_roc' key.\n",
    "        results_original_roc (dict, optional): A dictionary containing the\n",
    "                                               ROC results of a baseline model,\n",
    "                                               which will also be included in\n",
    "                                               the comparison. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of dictionaries representing the optimal ROC\n",
    "              envelope. Each dictionary includes 'model', 'fpr', 'tpr',\n",
    "              and 'threshold'.\n",
    "    \"\"\"\n",
    "    all_points = []\n",
    "\n",
    "    # Step 1: Gather all ROC points from all provided models\n",
    "    all_results = results_list[:]\n",
    "    if results_original_roc:\n",
    "        all_results.append({\n",
    "            'model': 'original_baseline',\n",
    "            'full_roc': results_original_roc\n",
    "        })\n",
    "\n",
    "    for result in all_results:\n",
    "        model_name = result.get('model', 'Unknown Model')\n",
    "        roc = result.get('full_roc')\n",
    "        if not roc: continue\n",
    "\n",
    "        fprs = roc.get('fpr', [])\n",
    "        tprs = roc.get('tpr', [])\n",
    "        thresholds = roc.get('thresholds', [])\n",
    "\n",
    "        for i in range(len(fprs)):\n",
    "            threshold = thresholds[i] if i < len(thresholds) else thresholds[-1]\n",
    "            all_points.append({\n",
    "                'model': model_name, 'fpr': fprs[i],\n",
    "                'tpr': tprs[i], 'threshold': threshold\n",
    "            })\n",
    "\n",
    "    # Handle case with no data by returning a default diagonal line\n",
    "    if not all_points:\n",
    "        return [\n",
    "            {'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf},\n",
    "            {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}\n",
    "        ]\n",
    "\n",
    "    # Step 2: Sort all points by FPR (asc), then by TPR (desc)\n",
    "    all_points.sort(key=lambda p: (p['fpr'], -p['tpr']))\n",
    "\n",
    "    # Step 3: Build the core ROC envelope\n",
    "    best_roc_envelope = []\n",
    "    max_tpr_so_far = -1.0\n",
    "    for point in all_points:\n",
    "        # Add a point only if it has a strictly higher TPR\n",
    "        if point['tpr'] > max_tpr_so_far:\n",
    "            # To prevent adding multiple points at the same FPR, check if the last point\n",
    "            # has the same FPR and replace it if so (since this one has a higher TPR)\n",
    "            if best_roc_envelope and best_roc_envelope[-1]['fpr'] == point['fpr']:\n",
    "                best_roc_envelope[-1] = point\n",
    "            else:\n",
    "                best_roc_envelope.append(point)\n",
    "            max_tpr_so_far = point['tpr']\n",
    "    \n",
    "    # Step 4: Manually add extremities if they are missing\n",
    "    \n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not best_roc_envelope or best_roc_envelope[0]['fpr'] > 0.0:\n",
    "        best_roc_envelope.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if best_roc_envelope[-1]['fpr'] < 1.0 or best_roc_envelope[-1]['tpr'] < 1.0:\n",
    "        best_roc_envelope.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return best_roc_envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b781e9",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c3deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_data(dataset):\n",
    "    if dataset == \"data1\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [0, 2], [2, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "    elif dataset == \"data2\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [1, 2], [1, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "    elif dataset == \"pneumoniaMNIST\":\n",
    "        import medmnist\n",
    "        print(medmnist.__version__)\n",
    "        # read in the PneumoniaMNIST dataset\n",
    "        from medmnist import PneumoniaMNIST\n",
    "        train_data = PneumoniaMNIST(split='train', download=True, size=224)\n",
    "        test_data = PneumoniaMNIST(split='test', download=True, size=224)\n",
    "        val_data = PneumoniaMNIST(split='val', download=True, size=224)\n",
    "        # print the dataset info\n",
    "        print(f\"Number of training samples: {len(train_data)}\")\n",
    "        print(f\"Number of test samples: {len(test_data)}\")\n",
    "        print(f\"Number of validation samples: {len(val_data)}\")\n",
    "\n",
    "    return train_data, test_data, val_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59034e",
   "metadata": {},
   "source": [
    "## Data1: NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74133e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a060ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 1\n",
    "NUM_CHANNELS = 1\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 4\n",
    "K_FOLDS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a702675",
   "metadata": {},
   "source": [
    "### Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3760e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "\n",
    "# A simple classifier head\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_features=2, hidden_units=32, num_classes=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_features (int): Number of input features (2 for your data)\n",
    "            hidden_units (int): Number of neurons in the hidden layer\n",
    "            num_classes (int): Number of output classes (1 for binary)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            # --- Hidden Layer 1 ---\n",
    "            # Takes 2 features in, outputs a hidden representation of size 32\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.ReLU(),  # <-- The crucial non-linear activation function\n",
    "\n",
    "            # --- Output Layer ---\n",
    "            # Takes the 16-unit hidden representation, outputs 1 logit\n",
    "            nn.Linear(in_features=hidden_units, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "# A new LightningModule just for training the classifier\n",
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_features=512, hidden_units=32, num_classes=1, learning_rate=1e-4, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = SimpleClassifier(\n",
    "            input_features=self.hparams.input_features,\n",
    "            hidden_units=self.hparams.hidden_units,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "        self.current_test_threshold = 0.5  # Default threshold for binary classification\n",
    "\n",
    "        # This ensures the model's structure is correct upon initialization\n",
    "        if self.hparams.pos_weight is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(self.hparams.pos_weight))\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        \n",
    "        \n",
    "        # --- METRICS ---\n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_auc = torchmetrics.AUROC(task=\"binary\")\n",
    "        \n",
    "        # This list will store outputs from each test step\n",
    "        self.test_step_outputs = []\n",
    "        # This dictionary will hold the final results\n",
    "        self.last_test_results = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self(features)\n",
    "        \n",
    "        # For the loss function, labels need to be reshaped to match outputs\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "        \n",
    "        # For metrics, squeeze predictions to match labels' shape\n",
    "        self.train_accuracy(outputs.squeeze(), labels.int())\n",
    "        \n",
    "        self.log('classifier_train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('classifier_train_acc', self.train_accuracy, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self.model(features)\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "\n",
    "        # Append predictions and labels to our list for aggregation\n",
    "        self.test_step_outputs.append({\"preds\": outputs.detach(), \"labels\": labels.detach()})\n",
    "        \n",
    "        self.log('test_loss', loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        if not self.test_step_outputs:\n",
    "            return # Avoid errors if test loop was empty\n",
    "\n",
    "        # Concatenate all predictions and labels\n",
    "        all_preds = torch.cat([x['preds'] for x in self.test_step_outputs])\n",
    "        all_labels = torch.cat([x['labels'] for x in self.test_step_outputs])\n",
    "\n",
    "        # --- FIX: Squeeze BOTH predictions and labels to ensure they match ---\n",
    "        squeezed_preds = all_preds.squeeze()\n",
    "        all_probs = torch.sigmoid(squeezed_preds)\n",
    "        # The labels tensor might also be [N, 1], so we squeeze it as well.\n",
    "        int_labels = all_labels.squeeze().int()\n",
    "\n",
    "        # Calculate final scalar metrics\n",
    "        test_acc = self.test_accuracy(squeezed_preds, int_labels)\n",
    "        test_auc_val = self.test_auc(squeezed_preds, int_labels)\n",
    "\n",
    "\n",
    "        # Get the confusion matrix stats at the default 0.0 logit threshold\n",
    "        tp, fp, tn, fn, _ = torchmetrics.functional.stat_scores(\n",
    "            all_probs, int_labels, task=\"binary\", threshold=self.current_test_threshold\n",
    "        ) \n",
    "        \n",
    "        # Calculate TPR and FPR from these raw scores\n",
    "        epsilon = 1e-6\n",
    "        tpr_at_0 = tp / (tp + fn + epsilon)\n",
    "        fpr_at_0 = fp / (fp + tn + epsilon)\n",
    "\n",
    "        # Calculate data for the full ROC Curve\n",
    "        fpr_full, tpr_full, thresholds_full = torchmetrics.functional.roc(\n",
    "            torch.sigmoid(squeezed_preds),\n",
    "            int_labels,\n",
    "            task=\"binary\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"\\n--- Final Classifier Test Metrics ---\")\n",
    "        print(f\"Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"AUC: {test_auc_val:.4f}\")\n",
    "        print(\"-------------------------------------\\n\")\n",
    "        \n",
    "        self.last_test_results = {\n",
    "            \"w\": self.hparams.get('w'),\n",
    "            \"fpr\": fpr_at_0.cpu().numpy(),\n",
    "            \"tpr\": tpr_at_0.cpu().numpy(),\n",
    "            \"threshold\": self.current_test_threshold,\n",
    "            \"auc\": test_auc_val.cpu().numpy(),\n",
    "            \"accuracy\": test_acc.cpu().numpy(),\n",
    "            \"full_roc\": {\n",
    "                \"fpr\": fpr_full.cpu().numpy(),\n",
    "                \"tpr\": tpr_full.cpu().numpy(),\n",
    "                \"thresholds\": thresholds_full.cpu().numpy()\n",
    "            }\n",
    "        }\n",
    "        self.test_step_outputs.clear()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ea652",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f28dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1000, 2), (1000,)\n",
      "Test data shape: (600, 2), (600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train_data, test_data, val_data = generate_data(\"data2\")\n",
    "\n",
    "\n",
    "train_data_tensor = data.TensorDataset(torch.tensor(train_data[:, :-1], dtype=torch.float32),\n",
    "                                        torch.tensor(train_data[:, -1], dtype=torch.float32))\n",
    "train_loader = data.DataLoader(train_data_tensor, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS) #over-write later for k-fold cross-validation\n",
    "test_data_tensor = data.TensorDataset(torch.tensor(test_data[:, :-1], dtype=torch.float32),\n",
    "                                       torch.tensor(test_data[:, -1], dtype=torch.float32))\n",
    "test_loader = data.DataLoader(test_data_tensor, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# initialize fold\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8065beae",
   "metadata": {},
   "source": [
    "### Regular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261a6f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training for 1 epochs on train_loader ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4664d3b57fbd49708e95da054c837cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model from Phase 1 saved to: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v16.ckpt\n",
      "\n",
      "--- Testing model from Phase 1 checkpoint: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v16.ckpt ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781ca11050f24d85a3236d51ebe3b780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5700\n",
      "AUC: 0.6139\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6873143315315247\n",
      "\n",
      "\n",
      "--- Manually Calculating Metrics on Test Set ---\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[176 124]\n",
      " [135 165]]\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.57      0.59      0.58       300\n",
      "     Class 1       0.57      0.55      0.56       300\n",
      "\n",
      "    accuracy                           0.57       600\n",
      "   macro avg       0.57      0.57      0.57       600\n",
      "weighted avg       0.57      0.57      0.57       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Instantiate the LightningModule\n",
    "model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    "\n",
    "checkpoint_callback_full_model = ModelCheckpoint(\n",
    "    monitor='classifier_train_acc',  # Monitor training accuracy\n",
    "    every_n_epochs=1,                # Save model every epoch\n",
    "    dirpath='checkpoints/',\n",
    "    filename='simple-clf-{epoch:02d}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "train_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',                 # Use GPUs\n",
    "    devices=1,                         # Number of GPUs to use\n",
    "    #strategy='ddp_notebook',                    # DistributedDataParallel strategy (best for multi-GPU)\n",
    "    max_epochs=NUM_EPOCHS,              # Total number of epochs\n",
    "    callbacks=[checkpoint_callback_full_model, progress_bar],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-train\"),\n",
    ")\n",
    "\n",
    "test_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=1,  # Use only one GPU\n",
    "    logger = pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-test\"),\n",
    "    # Add the callback here so the Trainer can find the 'best' path\n",
    "    callbacks=[checkpoint_callback_full_model],\n",
    "    precision='16-mixed'  # Use mixed precision for testing\n",
    ")\n",
    "\n",
    "# --- Phase 1 Training ---\n",
    "print(f\"--- Starting Training for {NUM_EPOCHS} epochs on train_loader ---\")\n",
    "train_trainer_1.fit(model, train_dataloaders=train_loader)\n",
    "\n",
    "# CRITICAL: Save the path to the best model from this phase\n",
    "path_after_phase1 = checkpoint_callback_full_model.best_model_path\n",
    "print(f\"Best model from Phase 1 saved to: {path_after_phase1}\")\n",
    "\n",
    "# --- Test 1: Evaluate the model from after Phase 1 ---\n",
    "print(f\"\\n--- Testing model from Phase 1 checkpoint: {path_after_phase1} ---\")\n",
    "model.current_test_title = \"ROC Curve after training on DataLoader 1\"\n",
    "model = LitClassifier.load_from_checkpoint(path_after_phase1)  # Load the model from Phase 1\n",
    "model.eval().to('cuda:0')  # Ensure the model is in evaluation mode and on GPU\n",
    "test_trainer_1.test(model, dataloaders=test_loader, ckpt_path=path_after_phase1)\n",
    "results_phase1 = model.last_test_results.copy()\n",
    "results_original_roc = {\"fpr\": results_phase1[\"full_roc\"][\"fpr\"], \"tpr\": results_phase1[\"full_roc\"][\"tpr\"], \"thresholds\": results_phase1[\"full_roc\"][\"thresholds\"], \"name\": \"Original NN data1\", \"auc\": results_phase1[\"auc\"], \"model\": model}\n",
    "\n",
    "# Metrics\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval() # Set to evaluation mode\n",
    "\n",
    "final_predictions = [] # This will store binary predictions (0s or 1s)\n",
    "true_labels = []\n",
    "\n",
    "print(\"\\n--- Manually Calculating Metrics on Test Set ---\")\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Move input data to the same device as the model\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # 1. Get the raw model output (logits) and convert to probabilities\n",
    "        outputs = torch.sigmoid(model(inputs))\n",
    "\n",
    "        # 2. Convert probabilities to binary class predictions (0 or 1) using a 0.5 threshold\n",
    "        preds = (outputs > 0.5).int()\n",
    "\n",
    "        final_predictions.extend(preds.cpu().numpy().flatten())\n",
    "        true_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "# Ensure they are numpy arrays for sklearn\n",
    "true_labels = np.array(true_labels)\n",
    "final_predictions = np.array(final_predictions)\n",
    "\n",
    "# Now, calculate metrics using the correct binary predictions\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(true_labels, final_predictions)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "report = classification_report(true_labels, final_predictions, target_names=['Class 0', 'Class 1'], zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c2d0a",
   "metadata": {},
   "source": [
    "### Undersampling ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "226e70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# --- This block generates the list of ratios for your experiment ---\n",
    "\n",
    "# 1. Get original class counts from your train_dataset\n",
    "def generate_ratios(train_data):\n",
    "   \n",
    "    try:\n",
    "        original_labels = np.array(train_data.targets).flatten()\n",
    "    except AttributeError:\n",
    "        original_labels = train_data[:, -1]\n",
    "\n",
    "    original_counts = Counter(original_labels)\n",
    "    num_pos_original = original_counts.get(1, 0)  \n",
    "    num_neg_original = original_counts.get(0, 0)  \n",
    "    print(f\"Original class counts: {num_pos_original} positives, {num_neg_original} negatives\")\n",
    "\n",
    "    # The pivot point for your function's logic\n",
    "    orig_sample_ratio = num_pos_original / num_neg_original \n",
    "\n",
    "    # 2. Define how many steps for each regime\n",
    "    N_POINTS_PER_REGIME = 25  # You can change this\n",
    "\n",
    "    # 3. Generate ratios for Regime 1 (from near 0 up to the pivot)\n",
    "    # This will test scenarios from extreme negative-class dominance up to the original balance.\n",
    "    print(f\"Generating ratios for Regime 1 (target ratio < {orig_sample_ratio})...\")\n",
    "    ratios_regime1 = np.geomspace(\n",
    "        start=1/num_neg_original,                      # A small starting ratio (e.g., 1 positive for every 10 negatives)\n",
    "        stop=orig_sample_ratio,         # Go up to the original ratio\n",
    "        num=N_POINTS_PER_REGIME,\n",
    "        endpoint=False                  # Exclude the pivot itself to avoid the 'else' block\n",
    "    )\n",
    "\n",
    "    # 4. Generate ratios for Regime 2 (from the pivot up to 3494)\n",
    "    # This will test scenarios from the original balance up to extreme positive-class dominance.\n",
    "    print(f\"Generating ratios for Regime 2 (target ratio > {orig_sample_ratio})...\")\n",
    "    ratios_regime2 = np.geomspace(\n",
    "        start=orig_sample_ratio, # Start just above the pivot\n",
    "        stop=num_pos_original,                      # Your specified upper limit\n",
    "        num=N_POINTS_PER_REGIME\n",
    "    )\n",
    "\n",
    "    # 5. Combine, sort, and create the final list for the loop\n",
    "    #    We also add the original ratio to ensure we have a baseline run.\n",
    "    all_ratios = sorted(list(np.concatenate([ratios_regime1, ratios_regime2, [orig_sample_ratio]])))\n",
    "\n",
    "    print(f\"\\nGenerated {len(all_ratios)} unique sample ratios to test.\")\n",
    "    print(\"First few ratios:\", np.round(all_ratios[:5], 3))\n",
    "    print(\"Last few ratios:\", np.round(all_ratios[-5:], 2))\n",
    "    return all_ratios, num_neg_original, num_pos_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfd1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def undersample_dataset(train_dataset, sample_ratio):\n",
    "\n",
    "    \n",
    "    \n",
    "    # Get the labels from the dataset (0 for normal, 1 for pneumonia)\n",
    "    try:\n",
    "        labels = np.array(train_dataset.targets).flatten()\n",
    "    except AttributeError:\n",
    "        labels = train_dataset[:, -1]\n",
    "\n",
    "    # Find the indices for the positive (pneumonia) and negative (normal) classes\n",
    "    positive_indices = np.where(labels == 1)[0]\n",
    "    negative_indices = np.where(labels == 0)[0]\n",
    "    num_orig_positive = len(positive_indices)\n",
    "    num_orig_negative = len(negative_indices)\n",
    "\n",
    "    orig_sample_ratio = num_orig_positive / num_orig_negative\n",
    "    print(f\"Original sample ratio (positive:negative): {orig_sample_ratio:.2f}\")\n",
    "\n",
    "    #based on sample ratio find the number of positive or negative samples\n",
    "    if sample_ratio>orig_sample_ratio:\n",
    "        neg_samples = int(num_orig_positive / sample_ratio)\n",
    "        pos_samples = num_orig_positive\n",
    "        sampled_negative_indices = np.random.choice(negative_indices, neg_samples, replace=False)\n",
    "        final_indices = np.concatenate([sampled_negative_indices, positive_indices])\n",
    "    elif sample_ratio<orig_sample_ratio:\n",
    "        pos_samples = int(sample_ratio * num_orig_negative)\n",
    "        neg_samples = num_orig_negative\n",
    "        sampled_positive_indices = np.random.choice(positive_indices, pos_samples, replace=False)\n",
    "        final_indices = np.concatenate([sampled_positive_indices, negative_indices])\n",
    "    else:\n",
    "        pos_samples = num_orig_positive\n",
    "        neg_samples = num_orig_negative\n",
    "        final_indices = np.concatenate([positive_indices, negative_indices])\n",
    "        \n",
    "    # Shuffle the final indices to mix positive and negative samples\n",
    "    np.random.shuffle(final_indices)\n",
    "\n",
    "    # Create a subset of the original dataset with the sampled indices\n",
    "    return train_dataset[final_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19d1bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 1/4 ---\n",
      "Original class counts: 378 positives, 372 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 1.0161290322580645)...\n",
      "Generating ratios for Regime 2 (target ratio > 1.0161290322580645)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.005 0.007]\n",
      "Last few ratios: [140.95 180.37 230.82 295.38 378.  ]\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8651a8c077442fa820a1a01f64af5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v17.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v17.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v17.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v17.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f08f12f2787475a91343de144439189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2749\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7430925369262695\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7876aa8e5b249cfa3f43317e0f6e85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b45f838e94409f979ca69b7dc3af4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2650\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7615585923194885\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346dfe6b4d5340f8a0c4ddc26a669894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ca2097f0ff4d7e8a7280c770a47291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2588\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7825551629066467\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca933515bf11493b9a3c171f5cd2f27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5cf57d7e0944daa39f0b91d1741946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2555\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8064152002334595\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ca94d2710e409ea9786878cc1233bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f49b31a25447339af593ad245e8584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2521\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8328529596328735\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5d23d2814c41bf8cf6b5f396a780b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a863760802449198b5cfcbacd891ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2507\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8618545532226562\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fb961a91a445e889d7cc61acd4a94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad2eda153fb461f833579b4d7e3351b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2515\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8924035429954529\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748a2315395242c59e78ac94d9e7fb50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eca0310be8e46538e65e6b0baaaea07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2528\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9256980419158936\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54ddfa409af4c92a28a49dadc8e9b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b2cdec787d4a558f95503c2ef186f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2519\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9628835320472717\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e6ced787fd4b418b9af4424192a902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db49f91e5a5d4939aed19beba8fbffc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2562\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9974338412284851\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435539a65ab14057972fbd46dff959cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81bd805e1e949e5a9b2f6e1f1a361f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2589\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            1.035998821258545\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27075c38255e45cda10b2abb551af363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6059b985ab240f89271e83ed0d8d516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2629\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.0825011730194092\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55457bdae6140cb9c3e3a6d6e514cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79525d837f0d45ca8c0bf78160c48bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2697\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            1.124325156211853\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd561cc9a2844c09691b1e69e5e7a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4635c6daf61c4b57b9ff7d4b0f92f64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2776\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.1641403436660767\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db8ed999d954b90b1aebb21d2d09b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046e6c7cf1054751bf0402f3c8c73b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2840\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.1971818208694458\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554f969004ef43ba96fd38e8d3b89eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a600defe31df4b36929f6ae550ac6b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2892\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.2099231481552124\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f441f7dac71c4468a955c957d82de775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba37e14b69774a0a85691f07390190fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2926\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            1.217329740524292\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50be631c85e44113b34b20e8eff063aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b2c8a5a5744b2dabff9eb3d7c055d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2983\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.1876742839813232\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2170ea4ff14749a3bbcec093ac672826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4965d9784b1c4c719ca537ee9813182e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3028\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.1474117040634155\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350adb15dea6442dad369a1c994b7282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60e69e07b0f415ab24836073b8e018e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3051\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            1.096774697303772\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ec74440ae64997a07327efdb83f244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b66d6ac662e452eac6ae92b3bf59faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3112\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.0390164852142334\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7b2a21cbcd43e8a4cc2f602f3770fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04aadd17dc924266bed00d9fd9f64457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3205\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            0.971116840839386\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938ac031b5be478580d03a27da904d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d76c64dae349858baeb31b42183400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3326\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9068917632102966\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f66b79f08b444ca46533c03bbc3b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97047ad58ab44f8a52e2cfedfceda56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3665\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8400854468345642\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2134129b7fdd4123a8ce1319105fa85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516e774e39ad4f3b9d464f7bf4d357e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4746\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7751419544219971\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ffc1d7abc54021afbfea3f1f0eb651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed95b4c949a149d99781ac0bda26007c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.6333\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7172993421554565\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb5264a59b647e4814179eab2c830fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a0c85d538548fd8613dc9a91b24365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.7233\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6729666590690613\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5654028d1c834cc3b2213babb583cca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acafd3d962d442c5aa62b11bbf357cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.7833\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6423667073249817\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65767d711c9844979d30a2cb156300de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6755b990e443cba60f33f72a50083e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8201\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6226012110710144\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a9d789bdc848ee8c71b173df895ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6663c51ecbbf41d3bf4fe2bccdb0aabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8355\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6109229326248169\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f06f0cd11174b38819bf770adec2a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b435e1d43634495bdff412e53145d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.8450\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6045517325401306\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b6d602c53d4e2fba90553456405cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1009012dec1344f9958c25a07433d7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6680\n",
      "AUC: 0.8488\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6026245355606079\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803552cc444c4a7292018ee5666e24c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1753edb8a4374d528717644ccf48a59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6760\n",
      "AUC: 0.8508\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6044471263885498\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fc6481c93f49fa88e8a6371954dab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30752c0e91e24dd89ede49066053afa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6600\n",
      "AUC: 0.8524\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            0.608582615852356\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681fc9d4a08044e3af7174a276a10f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57b9142ef7b4d61855e8418c96253e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.8534\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6152670979499817\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e638f22574411fb335e44cf85400a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54e3b070f8b4e1aaad026edb41b4f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.8535\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6237248778343201\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0d3c4d031c477f97f9fb19758a1a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7383c7ded14877bb64cd6abb0e942d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.8536\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6347448229789734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96788cba0cdc4f4b88e3269b737e1443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f04bb993854157aa4bcf8200e06e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.8543\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6476730704307556\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1514e39954df4e59a423e41dbc589368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef640db71694048a1dd22077f83176e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6120\n",
      "AUC: 0.8543\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6625935435295105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503e77ab8da94398b6452bc55e508b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20352976d79446299d9c5a47e29374f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6040\n",
      "AUC: 0.8534\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6796949505805969\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53ad50e746346aab3a4e639ca936820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8170a15c497a4db095746fab8e8b0e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5840\n",
      "AUC: 0.8524\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            0.699102520942688\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9d46346b574e5eaa9de04c8986be32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341dcd13890f4c1b89e41807317896b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5800\n",
      "AUC: 0.8522\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7209584712982178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb97bda9bab48de98f6eee6ec867001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529dc6b3f64447e78c6389eda6e425e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5760\n",
      "AUC: 0.8515\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7438458800315857\n",
      "\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684e4e86087d4d95a8a3e36119db737c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2332cd88de441eaa3e8ed40e00411ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5760\n",
      "AUC: 0.8506\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7646210789680481\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad350b730f434d0d829aaeb41f57dd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc818067351e4c8ca0b6ddcc83685a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5680\n",
      "AUC: 0.8501\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7862520813941956\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60476bf0c42042b2990de4387c889c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10920b6056ca40dbb46da791ba1d7326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5640\n",
      "AUC: 0.8494\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8097356557846069\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66445803884048dab00729f05770582e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d51e72c7174d22a7282c9a9990a156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5480\n",
      "AUC: 0.8488\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8344933986663818\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9803d9c4e0e47f695258bc982c010df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49e7880813541fc964f0e3b66d16d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5400\n",
      "AUC: 0.8482\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8601152300834656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215c351ddd9d499090342b9164b7b8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af45ee7bfd8f455196032bc407a55d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5400\n",
      "AUC: 0.8470\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8871428966522217\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d349c774d742559200f89b92ecb80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4984bdef87c451597d45c44d1c487f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.8462\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9159224629402161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af15b9fb5fe44e08f54151aa21af429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v5.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v5.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v5.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v5.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab199d9fec104460b3be18d73193e815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.8460\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9458543658256531\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 2/4 ---\n",
      "Original class counts: 368 positives, 382 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 0.9633507853403142)...\n",
      "Generating ratios for Regime 2 (target ratio > 0.9633507853403142)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.005 0.007]\n",
      "Last few ratios: [136.62 175.02 224.22 287.25 368.  ]\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e875e248ff476f847c0036683de198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034d3c9a2db345deaa7b33c2b4da0783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2047\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8057905435562134\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad345d1f10704c4d82ff1728820b5ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75de9fc057864514a98384661120ca71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1962\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8295233845710754\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303789f1a2b3474da39e7d08c13bdaa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681ef8e84273483396ea44f3b04d4118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1914\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8549324870109558\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e7aa57c77149fda89c1b00db007b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d47d36a06f04f58bbfa7918a848114d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1872\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8884616494178772\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12be8411c1d240b29ed0d204d3d25940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e78b75b88a4bdf8be764530f19ed03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1839\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9241988062858582\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f75d4e1433840c68023dcbc9c82c606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab98ebc8897f4ea4b92fa5dac78f8c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1821\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9616643190383911\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee37f76b6bb49448fe4663b400de23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a7dd2ac0cb4282aa1a073aff2dffb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1814\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.0013171434402466\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db7e88fe6bb4dc5ae132420c55c4030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7e603432394d7b87f56c12fb4a70e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1800\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.0433589220046997\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e55b25b532478cbf953344777b7692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6ac84739844bd6b61d377cf9ab40af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4720\n",
      "AUC: 0.1798\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.0865001678466797\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c486c0f28e148888d11a9af778909e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf2f74f61f140d48bb08efd27bb6a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1792\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.1352816820144653\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24fcc318e66410e99eec1f850886d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6190f50fd174078bc5a456535756af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1830\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.1753184795379639\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf066291fd44f5c948af41e38dfb757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180465d4f25d44cc80c5bffed0433e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1850\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.2204902172088623\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5eec7d97c1b40cdab6281d3408b282b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022b38386bc24b27abf2c7205ff85ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1916\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            1.251210331916809\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711511917cd749cc982a8718d091c786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93783676c153456a91843891c982ef18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2004\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.2826486825942993\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f424fce172974cfdaaad36b255d64a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e6a7b42a3245fa9741f445347ed915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2050\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.3060619831085205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd9aba05ef64f40aff58266edde11b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc07df5b9d540418a60fa441848ecca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2124\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.3226732015609741\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8ccc6350e04db784ab57fa7b70e722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e1d1fcae7a44c586298bddb21aba51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2174\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.3138558864593506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced8991f89964197b12a170ff51680db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dcf08002014ae2aba5ba84c34427a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2220\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.2791740894317627\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2649709724c44eab922051bbece58eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578ac32ee1d54e85928844ed20e8dee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2366\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            1.230324149131775\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed809f5658e423983cd83d48fb21a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1605442a8bb3416ba0357c17f64a3631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2515\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.1709167957305908\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e8916cc8594f2ca3d40aba4ca8e2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a1c1ef8ef349dba20476d1f748a284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2743\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.1189407110214233\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4365e002f9774a0c897baa726c579aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb269bfe6e240fbacbc395988c5906b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.3223\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            1.054006814956665\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2cdd03681b4480b6af3cd68498785a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3decf09135a84a6995fe3170cbc6d38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4028\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9864169359207153\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d206f5a2c448e589645630df11c31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf8b3cdb1a242e2bc80f06737b251fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5412\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9161723852157593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34213cf8d7d940f8b92feda4f75356c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2449b7408a18407bb44790a6be26d3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.6817\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8460894227027893\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748912e1c8d4449fb62ddab85dd94517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86d1168a9bd45d899e87cf0c8246489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.7652\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7768157720565796\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3bafe0e77545879141ad56f39c3a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29b658e7b40468d899eaf8833adee9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.8060\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7170367240905762\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b441986397847128146fc58ab622b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14dcb476a084aff872e6966688b9c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.8304\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6700695157051086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf89e420fc940c59f8749dd24700d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2584157de148db8c1a2dcba6b05d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6280\n",
      "AUC: 0.8439\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6334453225135803\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f03b4a395844a85973ccb3862ca0ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addff7b7411342b8ab41dc382e948fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.8496\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6061335206031799\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e71ce8e979a4e209e616dd5a0acacc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78201ef5de134b1f9ca3db7a071835da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7080\n",
      "AUC: 0.8520\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5864254236221313\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a537f69b85441a9a77d03a055623b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229d5a3f369d40789ac3feb7daafab8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8556\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5699397921562195\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea514adc9184496180e1dc165cf9d54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dd23ac6e3f4f15812103290c76d096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7520\n",
      "AUC: 0.8569\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5566287040710449\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305b92e3ccc14da1b385154637ce7021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cc0f397fdc4318859cc0257542a8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7600\n",
      "AUC: 0.8583\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            0.548261284828186\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe4ef2a240941848636808a161ce396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e1820dcee249df91e99605fd361870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8576\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5422207117080688\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39683b16dfad468d9cb6bfd62768a465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610c4d4ce3954c77a8700561cecff233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8574\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5387017726898193\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d22aeb410cb4922900bf1529647979e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c62c06b18884fffae6e3e4ac0317d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8568\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5371223092079163\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6a8f79cddd4df190b385fc9e0060b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400a097880c144218f5270845fac3ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8577\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5379713177680969\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4429a78b0888460f952877799554fb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a001bc84397044f99b1770b34a95f7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7080\n",
      "AUC: 0.8569\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5412276387214661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870321974bc043e0b51ea5a639e7ddef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c876db6e824e4f1ea6db44875b1b172f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.8562\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            0.545985758304596\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a7c3f382004780afae8a8e7098404a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee346854d4e4b3483ea7a270d3e41fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.8549\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5522181987762451\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b03c04c4c84d789099ab09f02ebcf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac247fe639f4b50acaa8e08c49185ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6960\n",
      "AUC: 0.8544\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5601263642311096\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9755d7e01ca542368d75633b70529faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4976dca36a9f4678a79f39b9721754ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.8540\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5700172781944275\n",
      "\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b307e11abe4056848f81d46e2bc928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf2f758f1a2432db6adb913be5255ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.8532\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5800992250442505\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873aaa998498459ba0d700fd3c3ad904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb33f726d24416595b431b57b49c75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6800\n",
      "AUC: 0.8528\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5916373133659363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa6b90511284d968cfd89f26725c00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ad4e22da764410a92ad9acb601bef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.8523\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6053287386894226\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3435c30cf3dd49d8863476665c63865f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7161076970404231b035b421932e062c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.8516\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6207806468009949\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a08f72440ac41d88442dc2136a4fb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f407d7074bf749308c7cb44078c508b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6640\n",
      "AUC: 0.8507\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6376273036003113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35d8f4bdc65491fb08f14bf5bf684fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d55a2f9e01f4697a66aa7ede199841b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6600\n",
      "AUC: 0.8503\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6549413800239563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77199bc3b424866bb8de1c138270bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d485ea26164dd4974c481aa6f9a4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6480\n",
      "AUC: 0.8497\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            0.674176037311554\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c587451b2e491f82521bc13ea5bf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v5.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v5.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v5.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v5.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669e8a81875d4f518142c2342a8208f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6440\n",
      "AUC: 0.8491\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6940557360649109\n",
      "\n",
      "--- Starting Fold 3/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class counts: 370 positives, 380 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 0.9736842105263158)...\n",
      "Generating ratios for Regime 2 (target ratio > 0.9736842105263158)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.005 0.007]\n",
      "Last few ratios: [137.48 176.09 225.54 288.88 370.  ]\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b72257d682b4691b66d114b24f67e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7292298a946460cb4374f589a0a105c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5160\n",
      "AUC: 0.5334\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7172581553459167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3920a0360b42109b1617aedc36c77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b09c1aeabf7454599cc41741589604f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4840\n",
      "AUC: 0.5027\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7156358361244202\n",
      "\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a743f94afcb492e84f192f8b7d2d050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798d60e314f7483aa90294aa4499cf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4440\n",
      "AUC: 0.4682\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7162420749664307\n",
      "\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4050a73acde4821895b8bbc3d8474e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2cf9ff281240af86d0b4148eaee384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4120\n",
      "AUC: 0.4339\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7189261317253113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036b318acd0f47fd8fc07c0bd282a57c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b818d7b237914d55bbfe649b2eb3a88e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.3960\n",
      "AUC: 0.4066\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7237836718559265\n",
      "\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e513d91fe44dd0906ae2949bcf3a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca8ca17019c4eb7aa2f598ee7d43ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4160\n",
      "AUC: 0.3851\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7308009266853333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111f78708d69450386ddf95c820748cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4294c72d659345efae13c7f6108ae1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4640\n",
      "AUC: 0.3614\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7414585947990417\n",
      "\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9bebae83174162a042528a595f177e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4541bd7e8d4ad98cc7bdac4ff95f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4560\n",
      "AUC: 0.3344\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            0.754833996295929\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3a2599d6b849fcac4330c7d0b94e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e683e93e1a4fa4889c69107799e410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4840\n",
      "AUC: 0.3127\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7673903703689575\n",
      "\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9ab4aaa14d44e487fb926a21578cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee43afb08ce3439484bb25a92bb58c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2822\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7832854986190796\n",
      "\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760d4b79c72146e9ba071a9f441c7969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27143c4afdc54cfeba931846899e2847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2390\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7989940047264099\n",
      "\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be12065485b14dee9f4fde0a515176bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45258d5fc374cdd9dad7687b670cabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2008\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8181977868080139\n",
      "\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1a245a0c6c417f91f1a0200e5e5887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98114c912a304ed6926f651a34a4b097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1819\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8347432017326355\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6206458f0b24311943019d023d4aee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c065bfd5e7ed4e02be1548698947a9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1699\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8555095195770264\n",
      "\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e8472878144f9fb9515fa95fe390e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5452788c66ef4dcdafdb68292f898511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1674\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8722931146621704\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f38ab4e48854aecb09c8ebc086c4464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c942d30620a43c39b8ef001d3a361cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1661\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8982598781585693\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de5dacf2732496abfa9ee24aa380c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827c1f873b524c82a0c62d888c45d0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1813\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9128673076629639\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7e585d770e4a2f8716cc7426f0773f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269e2552a3b54aeda3ac8b2c9c88e309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2010\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9194435477256775\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4043f55179404e249a0ecfc4b44d6061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525580bd467a4894816989425b5f2681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2503\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9127093553543091\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd42f1f6bbc841bd8ebaad8a444ce167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af5f2f27bc546d48836edd8b4a71a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2908\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9123475551605225\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9511985b376348c4b019d7daa4bbc7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e938dd5dac5b4775a3d55a8d6317de2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3544\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8846752643585205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9921daab7ca2480eb355df6b959f38cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8179b08768c44450aee6c88f06631f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4380\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            0.843661367893219\n",
      "\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80d52c4327d45f5af8c9ea054a05eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a18239bbee4bae86b9a31b98d9d5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.5260\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8055543303489685\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0c96cdfc1c41ac89015ae59694d5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b3bf712eda4fd792ee0d3c78f8ab30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.6205\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7596288323402405\n",
      "\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512f5cb834624ad5866908837149dd97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1741e5b856c94795ad4695ff00c9997c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.6984\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7156115770339966\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feac2a4b7b6444b2bc4ac69b465a6880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e621449edf4a058b482763d0844884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.7656\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6716550588607788\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84445c1c4b5047488d248ac8fee5168c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e3d77e2508428ab1550238e37a57da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.8019\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6362646818161011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3c9ae318c54d4da5804e796268caf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdec98a72b87466bb159bdbcfe0c054d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7680\n",
      "AUC: 0.8170\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6086018681526184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9757ed345d4680bbab7eddea217c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eeb2fbad3a548e793954680d009b55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8256\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5891926288604736\n",
      "\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15bba4c2dc79436c9ad7a0e392bf4891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2587a8ceac4e40d8831d4057872e5549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8279\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5766652226448059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d4c2a28fa24daa8868653ff6a037f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b18a7641794d9989fdfabfbd309197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8281\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5697757005691528\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f62476bf8b44fd0b4fd15b4dbf8c69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7e46cf72e448858d0bdb8f23faaeb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8257\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5659310221672058\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55bca5fc3bd422a8676d1884b815d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8940b435c9cd4bc3a690c2cf20c81011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8262\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5655063390731812\n",
      "\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28691c0af037420fb06700ee6f8fba11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc5eb04361b4283bfe8df65bb8c5a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8245\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            0.567673921585083\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cd459f444942499e405bbc56d27f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293f9a30ab004e1baf4a0d115926a81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7080\n",
      "AUC: 0.8233\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5720875263214111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443d97aebbfa4d8ea3ed5b547c279c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6f54bc7ad2437d966f733f19060354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.8205\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5798749923706055\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9df84048a3c4d5d8fe2ebc8cef91bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8831a8ef5834423090dcdd901510f0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.8189\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5902303457260132\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7705823c684379bbc0a51ad9eb908e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214970d4771545689020ddcd345341ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6960\n",
      "AUC: 0.8171\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6023295521736145\n",
      "\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa4f14e6f704f64884eec90f0d3948e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ae66e6941547639db1bb0c26f6dba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.8148\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6179484724998474\n",
      "\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63dea7d92afb4aa9ac5ff4b7acb31719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc02be54529044efb4e90b80cd9c1a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.8132\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6346496343612671\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7363a498b23d424b8f6e0f52578c2bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183588b463e54de8a390ddc8827ad4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.8117\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6513602137565613\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5287c41d5d4e1eaeebfad2aed8e67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480f833e10ba4fddad4c5dd9589711e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.8096\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6702102422714233\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3187a5753df84874b9b1b93fe750e14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c28bac6b28c45d8a3a34f7f7bc0798e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.8080\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6888540983200073\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6b8b2a51034ba19b7b32d4439a4c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0796956e581346a589dd07ec881a0dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6760\n",
      "AUC: 0.8071\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7112359404563904\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b894ae81fb45b6b373c57a8a62cd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633df12d1a184d9894aafab1d1333f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6680\n",
      "AUC: 0.8061\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7347466945648193\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d755f6499b54fdabb4d189b038a742b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f837ad0afd14d89a6df598d6795f501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6600\n",
      "AUC: 0.8045\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7606726884841919\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d11f8cde4942949896cf1172bd1d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b669f2a05d84aa9b2451ce5569a5860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6600\n",
      "AUC: 0.8029\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7867240309715271\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8595aca8b98743f3bbbeac0c619b25aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b24b181a4d44d51971c4cd8a4cb27c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.8023\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            0.813260555267334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1be8e270b55411d87e71905ffa14a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4612685f9e40487989d19c255f16e29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6480\n",
      "AUC: 0.8012\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8431553244590759\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1088f8e3e64b20aff065d3cdfb037c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54b02fcad83471c863f93ccfd30410a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6400\n",
      "AUC: 0.8008\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8747382760047913\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0316f4b8be6e46f98ab89e1771e725e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v5.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v5.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v5.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v5.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6975ef6fc54da1a38733e4fca9e608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.7994\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9067208766937256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 4/4 ---\n",
      "Original class counts: 384 positives, 366 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 1.0491803278688525)...\n",
      "Generating ratios for Regime 2 (target ratio > 1.0491803278688525)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.006 0.007]\n",
      "Last few ratios: [143.58 183.61 234.81 300.28 384.  ]\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25117be91fbf432dbbc2189682bdcc34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928c0f9a49554a929ef7ddf8b21efa35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4680\n",
      "AUC: 0.5574\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6888123750686646\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20eae18c25549d293cdb4dd72b9f109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8737410fb4cc49929eb37e121039349b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4520\n",
      "AUC: 0.4346\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            0.696405291557312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7acaea9a3144a98c63d14ebb9bc50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9400eae789474a2f9de0763d8d45d18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5080\n",
      "AUC: 0.3717\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7074582576751709\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca44a81f10c4538898f968b0802bb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83907b8be00c43b694c338864ff089bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5000\n",
      "AUC: 0.3299\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7218055129051208\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad692a203afc43b0ac0cc5f8483c0743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1930a371ab6c49ffb65fc623caac6de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5240\n",
      "AUC: 0.3083\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7394762635231018\n",
      "\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75b1e02af164f829fcb33532690dedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b0d50054f84bbbb29bfb352490959d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2986\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7602344751358032\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578aff0759a44c12a320c54ac5f50be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0067ac39bb445db53e12b1bb0016f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2916\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7840190529823303\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961f439ea49446e09b3ebc452848c5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a5d7b25a224393a7a6fd237a95230e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2878\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8103085160255432\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c09aa62a7444da93780e84d89bd807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031240e98e104f9eb9f7388e87089fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2854\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8392935991287231\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddc93b574c64ebdbd3b227407f4c5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f939c4bc2ba949db959f07f7d437e1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2859\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            0.868845522403717\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87d1720a2e04c16a0a69c051ea9ecc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57aaa78a29564babbd65763883b9735a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2858\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9015440940856934\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699c63479b32435097aca2d7a58ac57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45a179de047433cb38c7789eac0d232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2854\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9351975321769714\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2cd97300ac946b28dc257ff8821035a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ab62cc893644ad865b8632b4363a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2888\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9671075940132141\n",
      "\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7027872522f8444fae73127fc6d751f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651fe95586ff4eb8a92bb061604d08ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2905\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.0049251317977905\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c14d87a0044ae3a156e28c02ec9e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a271bb5de0a1441f87bb64bd5a9e623c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2953\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.0406962633132935\n",
      "\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9d398222134318b970b48af9c14415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c9c896787949788772e84a01665db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2983\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.0640822649002075\n",
      "\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ceb00b454fa4accac127e283a91dc26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8ff24dbadd4580a87dd22cca3aabea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3039\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            1.063159704208374\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25baa1def5ca48ee8dc38b05d7a9751c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54664e3379714ed489898bdce7198442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3070\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            1.031141996383667\n",
      "\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503f99c6d58d4aa9b08659b87a1d4cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ff2d7331524441a8b2fceead1fb763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3122\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9950731992721558\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2cb279fb409452a936e84215e89bc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c72fece1574cf0aac3883f7ce24467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3182\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9461104869842529\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53c3065e49344da9897b622e94465c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d9b719a8074bd2a69ce2d1a1800777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3316\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8954601883888245\n",
      "\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442c35f0e3364322ac8d5b30cd59bd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b0b8b0908947efb45be261ee49ad38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3746\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8478026390075684\n",
      "\n",
      "Original sample ratio (positive:negative): 1.05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691f4394a7754cc2b8515fd1194ea895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f749e1e759439f96393d9e8e4615ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4425\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7953307032585144\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00948c38fc694d84af75f48ba5b03c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3983f8ef5e845c1be2abb83e8d7bc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.5314\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7380992770195007\n",
      "\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbd3a4a2fba4a219acdc8b3a908c995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f5e0e93c0e41fb8db2663ce6eb2793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5520\n",
      "AUC: 0.5909\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6871799230575562\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9a4e95b4b54d8a84a818f21acc90c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f18d9b7e9d1450f8e980166ae569bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.7141\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6412854194641113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05293cd2d59e4c78825c70ca6759254f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35b0d1130344ab4b1ba1202b3c75fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8303\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6087271571159363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c040d42bc51b48e8a2e958cfbf768e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddeb2b6d22d3489f985a423f982a54c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8652\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5897067189216614\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef89092422fa43eda1f249cc597d5625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd94755e068c4bd8b4c6374ce908f331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8726\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5818029642105103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f3fbd2f9b3447b8e8b7ade8e393b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083c81149f6b499695f36c2fed033233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8732\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5822691321372986\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e8069f3f8445a7b7e47b917478af0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170031458617493bb5907551b986fedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.8705\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.5905090570449829\n",
      "\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4a01d1b0d5452e9f0a4ae5f14d2780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c367af01644085998f568b07f8d474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.8673\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6023442149162292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bac2c6746244eaa8f2a91af9263ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab56177432846d9a55a732c38b5ea72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6760\n",
      "AUC: 0.8638\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6229070425033569\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d314fa278241446dabf257dc62a57750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef107120b75419885169abe99415520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6560\n",
      "AUC: 0.8597\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6474140882492065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178343b5844b41f9abbc879f0cd96908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c801760bee4d189f354ccc2b1d8173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6320\n",
      "AUC: 0.8563\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.6718589067459106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fff929a24e4eb19e6f02c808c78550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a05852f2ef47ed88d9923bfb72734c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.8526\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7012943029403687\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cc8ea117944d17aa7b552dc7abb14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e839a1ae004497b8f8564ae1947d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.8485\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7359826564788818\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091bedb746814b43a3585543c36221b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e80a09f564f4228b0368f3b51bb0d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.8454\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.7746216058731079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f4741f7f7548089a2a91c1329f5092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62aea093c0a4be6ab39199c53dd84fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.8429\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8151555061340332\n",
      "\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b901fdfc4d4dc78c7457a07b908a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b485609887e42c3b333ab90c4cc904c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.8390\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.8576806783676147\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40e76525be14a4a9836f641cd9c3091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b95e822b41d42e8b5eb14c6bf0586a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6000\n",
      "AUC: 0.8360\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9037207961082458\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c860920977504926a5dcbb6d916055fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16457293a7874e8daa4b9040368437d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5920\n",
      "AUC: 0.8333\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           0.9530518651008606\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9a5f66320c4044992536e0b4891cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b318eb69fb4952bd7433f6d6faedd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5800\n",
      "AUC: 0.8311\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.0034219026565552\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89ed6f7e356460d91892936068ab6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52dc4dabdc06451eb42d382834971047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5760\n",
      "AUC: 0.8293\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            1.056376576423645\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46240c533d64369b1e251bcb87b5c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba891f9dc7947859642f5ac9b7180d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5720\n",
      "AUC: 0.8273\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.1121327877044678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190ece18e90e45cbb0486b47dde647b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb241a14a5a4bc9b9636325aff68223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5600\n",
      "AUC: 0.8249\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.1716508865356445\n",
      "\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbd8fff1d434c7ca732a40f5f3181cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07f2af3aa764c289d35ef4fc4926dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5480\n",
      "AUC: 0.8225\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.2298377752304077\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0459037c59ad4aef8506f0bcc76342b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03810e24c3f4549bc255c4452f20fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5280\n",
      "AUC: 0.8195\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.2937079668045044\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce46f43cd08c455b92cca38baf2cbb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1de361a31046c8987d21393512606b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5280\n",
      "AUC: 0.8171\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.3589792251586914\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fe8d66c01d47388433e8a89c4b6032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38b24d8a1d34262b8a2325bc5cff9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5280\n",
      "AUC: 0.8147\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss           1.4267653226852417\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a14c399e2448fe82bee2453218c648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v5.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v5.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v5.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v5.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92cd980d5ece43fea376fb10450cb9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5240\n",
      "AUC: 0.8149\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_loss            1.485900640487671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "#store the weighted classifiers of all the folds\n",
    "list_folds_weighted_clfs = []  # List to store classifiers from all folds\n",
    "#store the best classfiers of all the folds\n",
    "list_folds_best_models = []  # List to store best models from all folds\n",
    "\n",
    "# Dictionary to store the history of each fold\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "# 3. K-fold cross-validation loop\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data_tensor)):\n",
    "    list_weighted_clfs = [] # List to store the models trained at each stage\n",
    "    best_clfs = [] # List to store the best models from each stage\n",
    "    best_model_paths = [] # List to store the path of the best model from each stage\n",
    "    print(f\"--- Starting Fold {fold + 1}/{K_FOLDS} ---\")\n",
    "    # 1. Instantiate the LightningModule\n",
    "    model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    " \n",
    "    # --- Create datasets and dataloaders for the current fold ---\n",
    "    # FIX 2: Get the fold-specific data by indexing the underlying tensors of the TensorDataset\n",
    "    fold_train_features, fold_train_labels = train_data_tensor.tensors[0][train_ids], train_data_tensor.tensors[1][train_ids]\n",
    "    fold_val_features, fold_val_labels = train_data_tensor.tensors[0][val_ids], train_data_tensor.tensors[1][val_ids]\n",
    "\n",
    "    # Create the validation loader for this fold\n",
    "    fold_val_dataset = data.TensorDataset(fold_val_features, fold_val_labels)\n",
    "    fold_loader = data.DataLoader(fold_val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "    # Create a temporary dataset for the generate_ratios function\n",
    "    temp_train_dataset_for_ratios = np.c_[fold_train_features, fold_train_labels]\n",
    "    all_ratios, Class0_initial, Class1_initial = generate_ratios(train_data=temp_train_dataset_for_ratios)\n",
    "\n",
    "\n",
    "    for i, sample_ratio in enumerate(all_ratios):\n",
    "        undersampled_fold_train_data = undersample_dataset(temp_train_dataset_for_ratios, sample_ratio=sample_ratio)\n",
    "        # Create a new TensorDataset for the undersampled data\n",
    "        fold_train_dataset = data.TensorDataset(\n",
    "            torch.tensor(undersampled_fold_train_data[:, :-1], dtype=torch.float32),\n",
    "            torch.tensor(undersampled_fold_train_data[:, -1], dtype=torch.float32)\n",
    "        )\n",
    "        # Create a DataLoader for the undersampled training data\n",
    "        fold_train_loader = data.DataLoader(\n",
    "            fold_train_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,  # Shuffle the training data\n",
    "            num_workers=NUM_WORKERS,\n",
    "            drop_last=True  # Drop the last incomplete batch if it exists\n",
    "        )\n",
    "        \n",
    "        \n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            every_n_epochs=1,                # Save model every epoch\n",
    "            dirpath=f'checkpoints/stage_{i+1}/fold_{fold+1}/',\n",
    "            filename=f'best-model-fold{fold+1}-{{epoch:02d}}',\n",
    "            save_top_k=1,\n",
    "            mode='max',\n",
    "        )\n",
    "        \n",
    "        # 3. Instantiate a NEW Trainer for this specific stage\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}_fold_{fold+1}_ratio_{sample_ratio}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "        \n",
    "        # 4. Train the model. It will start with weights from the previous stage.\n",
    "        trainer.fit(model, train_dataloaders=fold_train_loader)\n",
    "        \n",
    "        # 5. Get the path to the best model from THIS stage and store it\n",
    "        if checkpoint_callback.best_model_path:\n",
    "            best_path_this_stage = checkpoint_callback.best_model_path\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. Best model path: {best_path_this_stage} ---\")\n",
    "            best_model_paths.append(best_path_this_stage)\n",
    "            \n",
    "            # 6. CRITICAL: Load the best weights back into the model object\n",
    "            # This ensures we carry forward the BEST model to the next stage, not the last.\n",
    "            print(f\"Loading best weights from {best_path_this_stage} to continue...\")\n",
    "            model = LitClassifier.load_from_checkpoint(best_path_this_stage, strict=False)  # Use strict=False to ignore missing keys if any\n",
    "        else:\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. No checkpoint was saved. ---\")\n",
    "            # If no checkpoint was saved, the model object will just have the weights from the last epoch.\n",
    "\n",
    "        # 7. Test the model after each stage\n",
    "        print(f\"\\n--- Testing model after Fold {fold+1} Stage {i+1} ---\")\n",
    "        trainer.test(model, dataloaders=fold_loader, ckpt_path=best_path_this_stage)\n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "        best_clfs = get_best_roc_envelope(list_weighted_clfs, results_original_roc)\n",
    "    list_folds_weighted_clfs.append(list_weighted_clfs)\n",
    "    list_folds_best_models.append(best_clfs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fd2a468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to pickle/NN_data2_undersampling.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_models': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.4918033),\n",
       "    'threshold': np.float16(0.5293)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0078125),\n",
       "    'tpr': np.float32(0.5081967),\n",
       "    'threshold': np.float16(0.525)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.015625),\n",
       "    'tpr': np.float32(0.5163934),\n",
       "    'threshold': np.float16(0.4788)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0390625),\n",
       "    'tpr': np.float32(0.52459013),\n",
       "    'threshold': np.float16(0.5195)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.046875),\n",
       "    'tpr': np.float32(0.5327869),\n",
       "    'threshold': np.float16(0.5176)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0546875),\n",
       "    'tpr': np.float32(0.5409836),\n",
       "    'threshold': np.float16(0.517)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0625),\n",
       "    'tpr': np.float32(0.55737704),\n",
       "    'threshold': np.float16(0.5566)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09375),\n",
       "    'tpr': np.float32(0.57377046),\n",
       "    'threshold': np.float16(0.4666)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1328125),\n",
       "    'tpr': np.float32(0.59016395),\n",
       "    'threshold': np.float16(0.4614)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.140625),\n",
       "    'tpr': np.float32(0.60655737),\n",
       "    'threshold': np.float16(0.4602)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15625),\n",
       "    'tpr': np.float32(0.63114756),\n",
       "    'threshold': np.float16(0.7197)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.171875),\n",
       "    'tpr': np.float32(0.6639344),\n",
       "    'threshold': np.float16(0.692)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1875),\n",
       "    'tpr': np.float32(0.6803279),\n",
       "    'threshold': np.float16(0.87)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1953125),\n",
       "    'tpr': np.float32(0.6885246),\n",
       "    'threshold': np.float16(0.8984)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.203125),\n",
       "    'tpr': np.float32(0.704918),\n",
       "    'threshold': np.float16(0.657)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2109375),\n",
       "    'tpr': np.float32(0.72131145),\n",
       "    'threshold': np.float16(0.701)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.21875),\n",
       "    'tpr': np.float32(0.7295082),\n",
       "    'threshold': np.float16(0.836)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2265625),\n",
       "    'tpr': np.float32(0.74590164),\n",
       "    'threshold': np.float16(0.8)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.234375),\n",
       "    'tpr': np.float32(0.7704918),\n",
       "    'threshold': np.float16(0.7163)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.25),\n",
       "    'tpr': np.float32(0.77868855),\n",
       "    'threshold': np.float16(0.777)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2578125),\n",
       "    'tpr': np.float32(0.78688526),\n",
       "    'threshold': np.float16(0.756)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2734375),\n",
       "    'tpr': np.float32(0.8114754),\n",
       "    'threshold': np.float16(0.791)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.28125),\n",
       "    'tpr': np.float32(0.8196721),\n",
       "    'threshold': np.float16(0.79)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2890625),\n",
       "    'tpr': np.float32(0.8278689),\n",
       "    'threshold': np.float16(0.771)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3046875),\n",
       "    'tpr': np.float32(0.8360656),\n",
       "    'threshold': np.float16(0.8477)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.328125),\n",
       "    'tpr': np.float32(0.86885244),\n",
       "    'threshold': np.float16(0.883)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3515625),\n",
       "    'tpr': np.float32(0.8770492),\n",
       "    'threshold': np.float16(0.8965)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.359375),\n",
       "    'tpr': np.float32(0.8852459),\n",
       "    'threshold': np.float16(0.713)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3828125),\n",
       "    'tpr': np.float32(0.89344263),\n",
       "    'threshold': np.float16(0.686)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.390625),\n",
       "    'tpr': np.float32(0.90163934),\n",
       "    'threshold': np.float16(0.6836)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.40625),\n",
       "    'tpr': np.float32(0.91803277),\n",
       "    'threshold': np.float16(0.604)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4140625),\n",
       "    'tpr': np.float32(0.92622954),\n",
       "    'threshold': np.float16(0.6284)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4375),\n",
       "    'tpr': np.float32(0.93442625),\n",
       "    'threshold': np.float16(0.621)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4453125),\n",
       "    'tpr': np.float32(0.9590164),\n",
       "    'threshold': np.float16(0.8564)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.453125),\n",
       "    'tpr': np.float32(0.9672131),\n",
       "    'threshold': np.float16(0.8066)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4609375),\n",
       "    'tpr': np.float32(0.9836066),\n",
       "    'threshold': np.float16(0.817)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4921875),\n",
       "    'tpr': np.float32(0.9918033),\n",
       "    'threshold': np.float16(0.7656)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.6015625),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.588)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.43939394),\n",
       "    'threshold': np.float16(0.666)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.008474576),\n",
       "    'tpr': np.float32(0.47727272),\n",
       "    'threshold': np.float16(0.4397)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025423728),\n",
       "    'tpr': np.float32(0.50757575),\n",
       "    'threshold': np.float16(0.521)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.042372882),\n",
       "    'tpr': np.float32(0.5151515),\n",
       "    'threshold': np.float16(0.5503)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.050847456),\n",
       "    'tpr': np.float32(0.530303),\n",
       "    'threshold': np.float16(0.577)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06779661),\n",
       "    'tpr': np.float32(0.54545456),\n",
       "    'threshold': np.float16(0.604)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.084745765),\n",
       "    'tpr': np.float32(0.5530303),\n",
       "    'threshold': np.float16(0.5435)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09322034),\n",
       "    'tpr': np.float32(0.56060606),\n",
       "    'threshold': np.float16(0.5073)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.10169491),\n",
       "    'tpr': np.float32(0.59090906),\n",
       "    'threshold': np.float16(0.4695)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.118644066),\n",
       "    'tpr': np.float32(0.6060606),\n",
       "    'threshold': np.float16(0.4666)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.12711865),\n",
       "    'tpr': np.float32(0.6136364),\n",
       "    'threshold': np.float16(0.4333)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.13559322),\n",
       "    'tpr': np.float32(0.6287879),\n",
       "    'threshold': np.float16(0.43)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1440678),\n",
       "    'tpr': np.float32(0.6363636),\n",
       "    'threshold': np.float16(0.4897)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15254237),\n",
       "    'tpr': np.float32(0.6439394),\n",
       "    'threshold': np.float16(0.488)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.16101696),\n",
       "    'tpr': np.float32(0.65909094),\n",
       "    'threshold': np.float16(0.4243)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.16949153),\n",
       "    'tpr': np.float32(0.6666667),\n",
       "    'threshold': np.float16(0.4236)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1779661),\n",
       "    'tpr': np.float32(0.6818182),\n",
       "    'threshold': np.float16(0.4224)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.18644068),\n",
       "    'tpr': np.float32(0.68939394),\n",
       "    'threshold': np.float16(0.4219)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.19491525),\n",
       "    'tpr': np.float32(0.6969697),\n",
       "    'threshold': np.float16(0.56)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.21186441),\n",
       "    'tpr': np.float32(0.7121212),\n",
       "    'threshold': np.float16(0.4458)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.22033899),\n",
       "    'tpr': np.float32(0.72727275),\n",
       "    'threshold': np.float16(0.385)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.23728813),\n",
       "    'tpr': np.float32(0.75),\n",
       "    'threshold': np.float16(0.501)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2457627),\n",
       "    'tpr': np.float32(0.75757575),\n",
       "    'threshold': np.float16(0.47)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.26271185),\n",
       "    'tpr': np.float32(0.780303),\n",
       "    'threshold': np.float16(0.8184)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.27118644),\n",
       "    'tpr': np.float32(0.79545456),\n",
       "    'threshold': np.float16(0.6836)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.27966103),\n",
       "    'tpr': np.float32(0.8181818),\n",
       "    'threshold': np.float16(0.6978)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29661018),\n",
       "    'tpr': np.float32(0.8333333),\n",
       "    'threshold': np.float16(0.64)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.30508474),\n",
       "    'tpr': np.float32(0.84090906),\n",
       "    'threshold': np.float16(0.764)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.31355932),\n",
       "    'tpr': np.float32(0.8484849),\n",
       "    'threshold': np.float16(0.729)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3220339),\n",
       "    'tpr': np.float32(0.8787879),\n",
       "    'threshold': np.float16(0.768)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3559322),\n",
       "    'tpr': np.float32(0.8863636),\n",
       "    'threshold': np.float16(0.805)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3983051),\n",
       "    'tpr': np.float32(0.8939394),\n",
       "    'threshold': np.float16(0.5503)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.40677965),\n",
       "    'tpr': np.float32(0.9166667),\n",
       "    'threshold': np.float16(0.4514)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41525424),\n",
       "    'tpr': np.float32(0.92424244),\n",
       "    'threshold': np.float16(0.4778)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.42372882),\n",
       "    'tpr': np.float32(0.9318182),\n",
       "    'threshold': np.float16(0.451)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.44067797),\n",
       "    'tpr': np.float32(0.9469697),\n",
       "    'threshold': np.float16(0.475)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.44915253),\n",
       "    'tpr': np.float32(0.95454544),\n",
       "    'threshold': np.float16(0.514)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4915254),\n",
       "    'tpr': np.float32(0.9621212),\n",
       "    'threshold': np.float16(0.5283)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5084746),\n",
       "    'tpr': np.float32(0.969697),\n",
       "    'threshold': np.float16(0.5996)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5677966),\n",
       "    'tpr': np.float32(0.97727275),\n",
       "    'threshold': np.float16(0.567)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5762712),\n",
       "    'tpr': np.float32(0.99242425),\n",
       "    'threshold': np.float16(0.5317)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.6694915),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.3667)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.17333333),\n",
       "    'threshold': np.float16(0.5273)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.0033333334),\n",
       "    'tpr': np.float32(0.19),\n",
       "    'threshold': np.float16(0.5264)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.006666667),\n",
       "    'tpr': np.float32(0.20333333),\n",
       "    'threshold': np.float16(0.525)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.01),\n",
       "    'tpr': np.float32(0.23333333),\n",
       "    'threshold': np.float16(0.524)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.013333334),\n",
       "    'tpr': np.float32(0.27333334),\n",
       "    'threshold': np.float16(0.521)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.016666668),\n",
       "    'tpr': np.float32(0.28333333),\n",
       "    'threshold': np.float16(0.5205)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.02),\n",
       "    'tpr': np.float32(0.28666666),\n",
       "    'threshold': np.float16(0.52)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025),\n",
       "    'tpr': np.float32(0.2923077),\n",
       "    'threshold': np.float16(0.7617)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.026666667),\n",
       "    'tpr': np.float32(0.29333332),\n",
       "    'threshold': np.float16(0.5195)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.033333335),\n",
       "    'tpr': np.float32(0.3846154),\n",
       "    'threshold': np.float16(0.6255)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.05),\n",
       "    'tpr': np.float32(0.4076923),\n",
       "    'threshold': np.float16(0.4927)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.058333334),\n",
       "    'tpr': np.float32(0.43076923),\n",
       "    'threshold': np.float16(0.647)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06666667),\n",
       "    'tpr': np.float32(0.43846154),\n",
       "    'threshold': np.float16(0.4915)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.075),\n",
       "    'tpr': np.float32(0.44615385),\n",
       "    'threshold': np.float16(0.614)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.083333336),\n",
       "    'tpr': np.float32(0.46153846),\n",
       "    'threshold': np.float16(0.611)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09166667),\n",
       "    'tpr': np.float32(0.4923077),\n",
       "    'threshold': np.float16(0.6987)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.108333334),\n",
       "    'tpr': np.float32(0.5307692),\n",
       "    'threshold': np.float16(0.5264)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.11666667),\n",
       "    'tpr': np.float32(0.54615384),\n",
       "    'threshold': np.float16(0.525)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.125),\n",
       "    'tpr': np.float32(0.5538462),\n",
       "    'threshold': np.float16(0.524)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.13333334),\n",
       "    'tpr': np.float32(0.5769231),\n",
       "    'threshold': np.float16(0.5615)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.14166667),\n",
       "    'tpr': np.float32(0.5923077),\n",
       "    'threshold': np.float16(0.5566)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15),\n",
       "    'tpr': np.float32(0.64615387),\n",
       "    'threshold': np.float16(0.586)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15833333),\n",
       "    'tpr': np.float32(0.6615385),\n",
       "    'threshold': np.float16(0.5503)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.16666667),\n",
       "    'tpr': np.float32(0.6846154),\n",
       "    'threshold': np.float16(0.5474)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.18333334),\n",
       "    'tpr': np.float32(0.7),\n",
       "    'threshold': np.float16(0.5054)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.19166666),\n",
       "    'tpr': np.float32(0.7307692),\n",
       "    'threshold': np.float16(0.5015)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.23333333),\n",
       "    'tpr': np.float32(0.74615383),\n",
       "    'threshold': np.float16(0.4534)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.24166666),\n",
       "    'tpr': np.float32(0.75384617),\n",
       "    'threshold': np.float16(0.4902)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.25),\n",
       "    'tpr': np.float32(0.8),\n",
       "    'threshold': np.float16(0.52)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.275),\n",
       "    'tpr': np.float32(0.8076923),\n",
       "    'threshold': np.float16(0.515)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.28333333),\n",
       "    'tpr': np.float32(0.8153846),\n",
       "    'threshold': np.float16(0.548)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29166666),\n",
       "    'tpr': np.float32(0.8230769),\n",
       "    'threshold': np.float16(0.5435)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3),\n",
       "    'tpr': np.float32(0.83076924),\n",
       "    'threshold': np.float16(0.5415)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.30833334),\n",
       "    'tpr': np.float32(0.8384615),\n",
       "    'threshold': np.float16(0.5386)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.325),\n",
       "    'tpr': np.float32(0.84615386),\n",
       "    'threshold': np.float16(0.5703)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.35833332),\n",
       "    'tpr': np.float32(0.85384613),\n",
       "    'threshold': np.float16(0.5605)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.38333333),\n",
       "    'tpr': np.float32(0.86153847),\n",
       "    'threshold': np.float16(0.6514)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.39166668),\n",
       "    'tpr': np.float32(0.8923077),\n",
       "    'threshold': np.float16(0.7637)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4),\n",
       "    'tpr': np.float32(0.9076923),\n",
       "    'threshold': np.float16(0.632)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.40833333),\n",
       "    'tpr': np.float32(0.9307692),\n",
       "    'threshold': np.float16(0.879)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41666666),\n",
       "    'tpr': np.float32(0.95384616),\n",
       "    'threshold': np.float16(0.8843)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.425),\n",
       "    'tpr': np.float32(0.96153843),\n",
       "    'threshold': np.float16(0.8813)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.45833334),\n",
       "    'tpr': np.float32(0.9846154),\n",
       "    'threshold': np.float16(0.753)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5083333),\n",
       "    'tpr': np.float32(0.99230766),\n",
       "    'threshold': np.float16(0.796)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.56666666),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.7104)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.47413793),\n",
       "    'threshold': np.float16(0.539)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.014925373),\n",
       "    'tpr': np.float32(0.49137932),\n",
       "    'threshold': np.float16(0.5327)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.02238806),\n",
       "    'tpr': np.float32(0.5086207),\n",
       "    'threshold': np.float16(0.5986)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.029850746),\n",
       "    'tpr': np.float32(0.51724136),\n",
       "    'threshold': np.float16(0.5303)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.04477612),\n",
       "    'tpr': np.float32(0.5258621),\n",
       "    'threshold': np.float16(0.594)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.052238807),\n",
       "    'tpr': np.float32(0.5344828),\n",
       "    'threshold': np.float16(0.5264)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.05970149),\n",
       "    'tpr': np.float32(0.5689655),\n",
       "    'threshold': np.float16(0.5864)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06716418),\n",
       "    'tpr': np.float32(0.57758623),\n",
       "    'threshold': np.float16(0.5225)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.08208955),\n",
       "    'tpr': np.float32(0.5862069),\n",
       "    'threshold': np.float16(0.585)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.104477614),\n",
       "    'tpr': np.float32(0.6034483),\n",
       "    'threshold': np.float16(0.5215)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1119403),\n",
       "    'tpr': np.float32(0.61206895),\n",
       "    'threshold': np.float16(0.521)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.11940298),\n",
       "    'tpr': np.float32(0.62931037),\n",
       "    'threshold': np.float16(0.52)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.12686567),\n",
       "    'tpr': np.float32(0.63793105),\n",
       "    'threshold': np.float16(0.5195)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.13432837),\n",
       "    'tpr': np.float32(0.6465517),\n",
       "    'threshold': np.float16(0.519)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.14179105),\n",
       "    'tpr': np.float32(0.6637931),\n",
       "    'threshold': np.float16(0.5747)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15671642),\n",
       "    'tpr': np.float32(0.6810345),\n",
       "    'threshold': np.float16(0.623)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.17910448),\n",
       "    'tpr': np.float32(0.6896552),\n",
       "    'threshold': np.float16(0.5137)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.18656716),\n",
       "    'tpr': np.float32(0.70689654),\n",
       "    'threshold': np.float16(0.6167)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.19402985),\n",
       "    'tpr': np.float32(0.7241379),\n",
       "    'threshold': np.float16(0.615)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.21641791),\n",
       "    'tpr': np.float32(0.73275864),\n",
       "    'threshold': np.float16(0.698)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2238806),\n",
       "    'tpr': np.float32(0.75),\n",
       "    'threshold': np.float16(0.611)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.23134328),\n",
       "    'tpr': np.float32(0.7586207),\n",
       "    'threshold': np.float16(0.695)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.24626866),\n",
       "    'tpr': np.float32(0.76724136),\n",
       "    'threshold': np.float16(0.6553)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2835821),\n",
       "    'tpr': np.float32(0.7758621),\n",
       "    'threshold': np.float16(0.5537)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29104477),\n",
       "    'tpr': np.float32(0.8189655),\n",
       "    'threshold': np.float16(0.6367)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29850745),\n",
       "    'tpr': np.float32(0.82758623),\n",
       "    'threshold': np.float16(0.636)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.30597016),\n",
       "    'tpr': np.float32(0.87068963),\n",
       "    'threshold': np.float16(0.708)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.32089552),\n",
       "    'tpr': np.float32(0.8965517),\n",
       "    'threshold': np.float16(0.662)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.33582088),\n",
       "    'tpr': np.float32(0.9137931),\n",
       "    'threshold': np.float16(0.5747)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.35820895),\n",
       "    'tpr': np.float32(0.92241377),\n",
       "    'threshold': np.float16(0.606)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3955224),\n",
       "    'tpr': np.float32(0.9396552),\n",
       "    'threshold': np.float16(0.6943)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.40298507),\n",
       "    'tpr': np.float32(0.95689654),\n",
       "    'threshold': np.float16(0.788)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41044775),\n",
       "    'tpr': np.float32(0.9655172),\n",
       "    'threshold': np.float16(0.8535)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.42537314),\n",
       "    'tpr': np.float32(0.98275864),\n",
       "    'threshold': np.float16(0.7515)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4477612),\n",
       "    'tpr': np.float32(0.9913793),\n",
       "    'threshold': np.float16(0.7715)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.858)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}]],\n",
       " 'weighted_clfs': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.078125 , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1328125, 0.1484375, 0.15625  , 0.1796875, 0.203125 ,\n",
       "            0.21875  , 0.25     , 0.2578125, 0.265625 , 0.28125  , 0.2890625,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6640625,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.703125 , 0.703125 , 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.75     , 0.7578125, 0.7578125, 0.765625 ,\n",
       "            0.765625 , 0.765625 , 0.765625 , 0.765625 , 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.7734375, 0.78125  , 0.796875 , 0.796875 ,\n",
       "            0.796875 , 0.8046875, 0.8046875, 0.8046875, 0.8125   , 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.8671875,\n",
       "            0.875    , 0.8828125, 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.04098361, 0.04918033,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.19672132, 0.19672132, 0.20491803, 0.21311475, 0.21311475,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.27868852, 0.29508197,\n",
       "            0.30327868, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.352459  , 0.352459  ,\n",
       "            0.37704918, 0.37704918, 0.39344263, 0.39344263, 0.40983605,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.45081967, 0.45081967, 0.45901638, 0.46721312, 0.48360655,\n",
       "            0.4918033 , 0.5163934 , 0.52459013, 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.6639344 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8032787 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4875, 0.4863, 0.4856, 0.4849, 0.4844, 0.4836, 0.4834,\n",
       "            0.483 , 0.4824, 0.4812, 0.4807, 0.48  , 0.4795, 0.4792, 0.479 ,\n",
       "            0.4788, 0.4785, 0.4783, 0.478 , 0.4778, 0.4775, 0.477 , 0.4768,\n",
       "            0.4766, 0.4763, 0.4756, 0.4753, 0.4744, 0.4731, 0.473 , 0.4724,\n",
       "            0.4722, 0.4714, 0.4712, 0.4646, 0.4644, 0.464 , 0.4639, 0.462 ,\n",
       "            0.4617, 0.4612, 0.4604, 0.4597, 0.4578, 0.4573, 0.455 , 0.4526,\n",
       "            0.451 , 0.4507, 0.45  , 0.4495, 0.449 , 0.4473, 0.4456, 0.445 ,\n",
       "            0.4448, 0.444 , 0.4414, 0.4404, 0.44  , 0.4395, 0.4382, 0.438 ,\n",
       "            0.437 , 0.4358, 0.4333, 0.4329, 0.4326, 0.4321, 0.432 , 0.4302,\n",
       "            0.4292, 0.4287, 0.4277, 0.4268, 0.4265, 0.4263, 0.426 , 0.4243,\n",
       "            0.4236, 0.4226, 0.4219, 0.4214, 0.4211, 0.421 , 0.4207, 0.4204,\n",
       "            0.4194, 0.4192, 0.4185, 0.418 , 0.4167, 0.4165, 0.415 , 0.4146,\n",
       "            0.414 , 0.4138, 0.4126, 0.4119, 0.411 , 0.4104, 0.4097, 0.4082,\n",
       "            0.408 , 0.4075, 0.4062, 0.406 , 0.4058, 0.4055, 0.4048, 0.4043,\n",
       "            0.404 , 0.4036, 0.4033, 0.4026, 0.402 , 0.4016, 0.401 , 0.4004,\n",
       "            0.3997, 0.3992, 0.399 , 0.3987, 0.3984, 0.3965, 0.3958, 0.3955,\n",
       "            0.3953, 0.3948, 0.3943, 0.3936, 0.3933, 0.3926, 0.3916, 0.3909,\n",
       "            0.3906, 0.3887, 0.3877, 0.3872, 0.3865, 0.3855, 0.384 , 0.3835,\n",
       "            0.383 , 0.3818, 0.3813, 0.3804, 0.3796, 0.3794, 0.3787, 0.3774,\n",
       "            0.3767, 0.3765, 0.375 , 0.3745, 0.3735, 0.373 , 0.3713, 0.3708,\n",
       "            0.3691, 0.369 , 0.368 , 0.3665, 0.3647, 0.3635, 0.363 , 0.3625,\n",
       "            0.3616, 0.3613, 0.3608, 0.3584, 0.3572, 0.355 , 0.3547, 0.3525,\n",
       "            0.351 , 0.3503, 0.35  , 0.3474, 0.3467, 0.3452, 0.344 , 0.3425,\n",
       "            0.34  , 0.3389, 0.3328, 0.3318, 0.3289, 0.3281, 0.3218, 0.303 ,\n",
       "            0.3015], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.09375  , 0.1015625, 0.1171875,\n",
       "            0.1328125, 0.15625  , 0.1796875, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.3046875,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.6640625, 0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6796875, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.734375 , 0.734375 , 0.734375 , 0.734375 , 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.75     , 0.7578125, 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.7734375, 0.7734375,\n",
       "            0.7734375, 0.78125  , 0.78125  , 0.78125  , 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8125   , 0.8125   ,\n",
       "            0.8203125, 0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.8671875, 0.875    ,\n",
       "            0.875    , 0.875    , 0.875    , 0.875    , 0.875    , 0.875    ,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.9453125,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.01639344, 0.02459016,\n",
       "            0.02459016, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13114753,\n",
       "            0.13934426, 0.13934426, 0.14754099, 0.16393442, 0.18032786,\n",
       "            0.18852459, 0.18852459, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.21311475, 0.21311475, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.23770492, 0.24590164,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.28688523,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.36885247, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.44262296, 0.45901638,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59836066, 0.6229508 , 0.63114756, 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.479 , 0.4766, 0.4756, 0.4749, 0.4744, 0.474 , 0.4739,\n",
       "            0.4724, 0.4722, 0.471 , 0.47  , 0.4697, 0.4695, 0.4692, 0.469 ,\n",
       "            0.4685, 0.4683, 0.468 , 0.4678, 0.4673, 0.467 , 0.4668, 0.4663,\n",
       "            0.466 , 0.465 , 0.4646, 0.4636, 0.4607, 0.46  , 0.4592, 0.459 ,\n",
       "            0.4587, 0.4585, 0.453 , 0.451 , 0.4492, 0.448 , 0.4473, 0.4463,\n",
       "            0.4426, 0.441 , 0.4382, 0.437 , 0.4343, 0.434 , 0.4338, 0.4329,\n",
       "            0.4321, 0.428 , 0.4272, 0.4255, 0.4233, 0.422 , 0.4214, 0.421 ,\n",
       "            0.4194, 0.4192, 0.4187, 0.4177, 0.4175, 0.4172, 0.4163, 0.415 ,\n",
       "            0.4126, 0.412 , 0.4104, 0.4102, 0.4077, 0.407 , 0.4053, 0.405 ,\n",
       "            0.4048, 0.404 , 0.4028, 0.4019, 0.4014, 0.4006, 0.4   , 0.3992,\n",
       "            0.399 , 0.3984, 0.3982, 0.398 , 0.3977, 0.3965, 0.396 , 0.3955,\n",
       "            0.395 , 0.3943, 0.3936, 0.3933, 0.393 , 0.3928, 0.3926, 0.391 ,\n",
       "            0.3896, 0.3894, 0.3887, 0.3877, 0.3857, 0.385 , 0.3848, 0.3845,\n",
       "            0.3843, 0.3838, 0.382 , 0.3818, 0.3809, 0.38  , 0.3794, 0.3792,\n",
       "            0.3787, 0.378 , 0.3765, 0.376 , 0.3752, 0.3748, 0.3745, 0.3738,\n",
       "            0.373 , 0.3726, 0.3718, 0.3708, 0.37  , 0.3699, 0.3691, 0.3684,\n",
       "            0.3667, 0.3665, 0.3662, 0.3657, 0.3652, 0.365 , 0.3647, 0.3635,\n",
       "            0.3633, 0.3628, 0.3623, 0.362 , 0.3613, 0.3606, 0.3599, 0.3591,\n",
       "            0.3577, 0.357 , 0.3567, 0.3564, 0.3538, 0.3533, 0.3523, 0.352 ,\n",
       "            0.3516, 0.3508, 0.35  , 0.3494, 0.349 , 0.3486, 0.3484, 0.3467,\n",
       "            0.3457, 0.3455, 0.3452, 0.3442, 0.341 , 0.3396, 0.339 , 0.3389,\n",
       "            0.3386, 0.338 , 0.3372, 0.3367, 0.3347, 0.3337, 0.3325, 0.331 ,\n",
       "            0.3306, 0.3298, 0.3293, 0.329 , 0.3286, 0.3267, 0.3254, 0.3235,\n",
       "            0.323 , 0.3218, 0.3184, 0.3164, 0.3162, 0.3137, 0.3135, 0.3115,\n",
       "            0.3066, 0.3064, 0.303 , 0.3022, 0.2986, 0.291 , 0.276 , 0.272 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.0859375, 0.1015625,\n",
       "            0.109375 , 0.125    , 0.140625 , 0.1640625, 0.1796875, 0.1875   ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.2890625, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.6171875, 0.6171875, 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6796875,\n",
       "            0.6796875, 0.6796875, 0.6796875, 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.734375 , 0.734375 , 0.734375 , 0.734375 ,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.7734375, 0.7734375, 0.7734375,\n",
       "            0.7734375, 0.78125  , 0.796875 , 0.796875 , 0.796875 , 0.796875 ,\n",
       "            0.796875 , 0.796875 , 0.796875 , 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8125   , 0.8203125, 0.8203125, 0.8203125, 0.828125 , 0.828125 ,\n",
       "            0.828125 , 0.8359375, 0.8359375, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.8828125,\n",
       "            0.8828125, 0.8828125, 0.8828125, 0.890625 , 0.890625 , 0.890625 ,\n",
       "            0.890625 , 0.8984375, 0.9140625, 0.9140625, 0.921875 , 0.921875 ,\n",
       "            0.921875 , 0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.20491803, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22131148, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.23770492, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.3442623 , 0.352459  , 0.352459  ,\n",
       "            0.352459  , 0.36065573, 0.36065573, 0.36885247, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.40983605, 0.40983605,\n",
       "            0.40983605, 0.40983605, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.44262296, 0.45081967, 0.45081967, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5081967 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.71311474, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4707, 0.4685, 0.4678, 0.4663, 0.4658, 0.4656, 0.465 ,\n",
       "            0.4648, 0.4631, 0.463 , 0.4624, 0.462 , 0.4612, 0.4604, 0.4602,\n",
       "            0.46  , 0.4597, 0.4595, 0.4592, 0.459 , 0.4587, 0.4583, 0.458 ,\n",
       "            0.457 , 0.4563, 0.4556, 0.4553, 0.4548, 0.4539, 0.453 , 0.4517,\n",
       "            0.4482, 0.4478, 0.4465, 0.4458, 0.4456, 0.445 , 0.4412, 0.437 ,\n",
       "            0.4343, 0.4338, 0.4329, 0.432 , 0.431 , 0.429 , 0.4275, 0.4226,\n",
       "            0.4216, 0.418 , 0.4175, 0.417 , 0.416 , 0.4153, 0.4143, 0.4094,\n",
       "            0.4084, 0.4072, 0.404 , 0.4038, 0.4028, 0.4019, 0.3992, 0.3987,\n",
       "            0.3984, 0.398 , 0.3962, 0.3938, 0.3936, 0.3923, 0.3916, 0.3909,\n",
       "            0.389 , 0.3884, 0.387 , 0.3848, 0.3833, 0.383 , 0.3826, 0.3823,\n",
       "            0.382 , 0.3816, 0.3784, 0.377 , 0.3765, 0.3757, 0.3752, 0.3748,\n",
       "            0.3745, 0.3743, 0.374 , 0.3733, 0.3728, 0.3726, 0.3716, 0.371 ,\n",
       "            0.3704, 0.3699, 0.3696, 0.3691, 0.369 , 0.3684, 0.368 , 0.366 ,\n",
       "            0.3652, 0.365 , 0.3628, 0.3625, 0.361 , 0.36  , 0.3596, 0.3594,\n",
       "            0.3591, 0.359 , 0.3586, 0.3582, 0.358 , 0.3567, 0.3555, 0.3538,\n",
       "            0.3535, 0.3533, 0.3528, 0.3525, 0.3523, 0.3513, 0.35  , 0.3494,\n",
       "            0.349 , 0.3489, 0.3484, 0.348 , 0.3477, 0.3474, 0.347 , 0.3462,\n",
       "            0.3457, 0.3452, 0.3447, 0.3433, 0.3425, 0.3416, 0.3408, 0.3406,\n",
       "            0.3403, 0.3398, 0.3396, 0.3394, 0.339 , 0.3386, 0.338 , 0.3376,\n",
       "            0.3374, 0.3354, 0.334 , 0.3333, 0.3328, 0.3323, 0.3318, 0.3308,\n",
       "            0.3303, 0.3298, 0.3284, 0.328 , 0.327 , 0.3257, 0.3245, 0.3242,\n",
       "            0.3235, 0.3225, 0.3213, 0.321 , 0.3208, 0.3203, 0.319 , 0.3184,\n",
       "            0.3176, 0.3167, 0.3152, 0.3145, 0.3132, 0.313 , 0.3093, 0.3088,\n",
       "            0.3083, 0.3071, 0.307 , 0.306 , 0.304 , 0.303 , 0.3027, 0.3003,\n",
       "            0.2986, 0.298 , 0.297 , 0.2969, 0.2957, 0.2937, 0.292 , 0.2883,\n",
       "            0.288 , 0.2869, 0.2852, 0.2847, 0.2805, 0.2793, 0.2764, 0.275 ,\n",
       "            0.2717, 0.2695, 0.2612, 0.2498, 0.2434], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.2109375, 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.625    , 0.625    , 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6796875, 0.6796875, 0.6796875, 0.6796875, 0.6796875,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.734375 , 0.734375 , 0.734375 , 0.734375 ,\n",
       "            0.734375 , 0.734375 , 0.734375 , 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.75     , 0.75     , 0.7578125, 0.7578125, 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.796875 , 0.796875 , 0.796875 , 0.796875 ,\n",
       "            0.8046875, 0.8046875, 0.8046875, 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.8359375, 0.8359375, 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.875    , 0.8828125, 0.8828125, 0.890625 ,\n",
       "            0.890625 , 0.890625 , 0.8984375, 0.8984375, 0.8984375, 0.8984375,\n",
       "            0.90625  , 0.90625  , 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 , 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.08196721,\n",
       "            0.09016393, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.20491803, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22131148, 0.23770492, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.31967214, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.40983605, 0.40983605, 0.40983605, 0.40983605,\n",
       "            0.40983605, 0.40983605, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5491803 ,\n",
       "            0.55737704, 0.57377046, 0.58196723, 0.58196723, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.74590164, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4622, 0.4602, 0.4597, 0.457 , 0.4568, 0.4565, 0.4548,\n",
       "            0.454 , 0.4536, 0.4534, 0.453 , 0.4526, 0.4524, 0.452 , 0.4517,\n",
       "            0.4512, 0.451 , 0.4507, 0.4504, 0.4502, 0.45  , 0.4497, 0.449 ,\n",
       "            0.4482, 0.448 , 0.4475, 0.4465, 0.4463, 0.445 , 0.4446, 0.4443,\n",
       "            0.4436, 0.4429, 0.4424, 0.4412, 0.44  , 0.4355, 0.434 , 0.433 ,\n",
       "            0.432 , 0.4312, 0.4292, 0.423 , 0.4197, 0.4194, 0.4185, 0.4175,\n",
       "            0.415 , 0.412 , 0.4119, 0.405 , 0.4043, 0.4014, 0.4006, 0.3992,\n",
       "            0.3977, 0.397 , 0.3967, 0.3965, 0.3916, 0.3862, 0.3845, 0.3828,\n",
       "            0.3823, 0.3801, 0.379 , 0.3784, 0.3782, 0.3774, 0.3757, 0.3755,\n",
       "            0.3752, 0.375 , 0.371 , 0.3706, 0.3696, 0.3684, 0.3667, 0.3665,\n",
       "            0.366 , 0.3628, 0.3599, 0.3594, 0.3591, 0.3584, 0.357 , 0.3557,\n",
       "            0.3535, 0.3528, 0.352 , 0.3518, 0.3513, 0.3508, 0.3506, 0.3503,\n",
       "            0.3499, 0.3477, 0.3474, 0.3467, 0.3457, 0.345 , 0.3435, 0.3428,\n",
       "            0.3418, 0.3406, 0.34  , 0.339 , 0.338 , 0.3376, 0.3374, 0.3357,\n",
       "            0.335 , 0.3345, 0.334 , 0.3335, 0.333 , 0.3328, 0.3325, 0.3323,\n",
       "            0.331 , 0.3298, 0.3284, 0.3281, 0.328 , 0.3276, 0.3274, 0.3271,\n",
       "            0.3267, 0.3262, 0.3254, 0.3252, 0.324 , 0.3237, 0.323 , 0.3228,\n",
       "            0.3225, 0.3223, 0.3218, 0.3215, 0.3213, 0.3208, 0.3206, 0.3203,\n",
       "            0.3198, 0.319 , 0.3186, 0.317 , 0.3162, 0.3147, 0.3135, 0.3127,\n",
       "            0.3123, 0.312 , 0.3108, 0.31  , 0.3098, 0.3096, 0.3079, 0.307 ,\n",
       "            0.3064, 0.3047, 0.3042, 0.304 , 0.3022, 0.3015, 0.3013, 0.3003,\n",
       "            0.3   , 0.2988, 0.2986, 0.298 , 0.297 , 0.2957, 0.295 , 0.2942,\n",
       "            0.2937, 0.293 , 0.2922, 0.2913, 0.2888, 0.2878, 0.2874, 0.286 ,\n",
       "            0.2856, 0.283 , 0.2827, 0.2817, 0.2812, 0.2805, 0.2786, 0.278 ,\n",
       "            0.2766, 0.2764, 0.2761, 0.2747, 0.2742, 0.2727, 0.2722, 0.272 ,\n",
       "            0.2712, 0.269 , 0.268 , 0.2668, 0.2656, 0.2637, 0.2595, 0.2588,\n",
       "            0.2583, 0.2559, 0.2515, 0.2478, 0.2463, 0.2422, 0.2386, 0.233 ,\n",
       "            0.2251, 0.2168], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0859375, 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.265625 , 0.2734375, 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.625    ,\n",
       "            0.625    , 0.625    , 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.75     , 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.765625 ,\n",
       "            0.765625 , 0.765625 , 0.78125  , 0.7890625, 0.796875 , 0.796875 ,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8125   , 0.8125   ,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.828125 , 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.8671875, 0.8671875, 0.8671875, 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8828125, 0.8984375, 0.8984375, 0.8984375, 0.8984375,\n",
       "            0.90625  , 0.90625  , 0.90625  , 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.921875 , 0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.984375 , 0.984375 , 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.1147541 , 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.16393442, 0.18032786, 0.19672132, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.22950819, 0.22950819,\n",
       "            0.22950819, 0.23770492, 0.23770492, 0.23770492, 0.23770492,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.27868852,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.40163934, 0.4180328 , 0.4180328 , 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45901638, 0.48360655, 0.5081967 ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.63114756, 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6967213 , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.75409836, 0.76229507, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4539, 0.4521, 0.452 , 0.448 , 0.4478, 0.4475, 0.4473,\n",
       "            0.4453, 0.4443, 0.444 , 0.4436, 0.4434, 0.443 , 0.4424, 0.4421,\n",
       "            0.4417, 0.4414, 0.4407, 0.4404, 0.4402, 0.4397, 0.439 , 0.4387,\n",
       "            0.438 , 0.4375, 0.4368, 0.4355, 0.434 , 0.4336, 0.4329, 0.4326,\n",
       "            0.4316, 0.4312, 0.4307, 0.429 , 0.4277, 0.423 , 0.4211, 0.4202,\n",
       "            0.418 , 0.4175, 0.417 , 0.409 , 0.4053, 0.4045, 0.4033, 0.4028,\n",
       "            0.4   , 0.397 , 0.3943, 0.3882, 0.3867, 0.3857, 0.3853, 0.3843,\n",
       "            0.3823, 0.379 , 0.378 , 0.377 , 0.3738, 0.366 , 0.3657, 0.3616,\n",
       "            0.3608, 0.3591, 0.3584, 0.358 , 0.3552, 0.3542, 0.353 , 0.3525,\n",
       "            0.35  , 0.3496, 0.3462, 0.3452, 0.345 , 0.343 , 0.3428, 0.341 ,\n",
       "            0.3376, 0.3367, 0.3345, 0.3333, 0.3323, 0.3318, 0.331 , 0.3306,\n",
       "            0.3303, 0.3293, 0.3289, 0.3281, 0.3276, 0.3271, 0.327 , 0.3267,\n",
       "            0.3242, 0.324 , 0.322 , 0.3218, 0.3213, 0.32  , 0.319 , 0.3171,\n",
       "            0.3164, 0.3162, 0.315 , 0.313 , 0.3118, 0.3105, 0.3103, 0.3098,\n",
       "            0.3093, 0.3088, 0.3086, 0.308 , 0.3074, 0.305 , 0.3047, 0.3037,\n",
       "            0.3032, 0.3027, 0.3025, 0.3018, 0.3013, 0.2996, 0.2993, 0.2986,\n",
       "            0.2974, 0.2969, 0.2964, 0.2961, 0.296 , 0.2957, 0.2952, 0.2944,\n",
       "            0.2935, 0.2925, 0.292 , 0.2903, 0.2898, 0.2878, 0.2869, 0.2864,\n",
       "            0.2861, 0.2854, 0.2842, 0.2837, 0.2834, 0.2832, 0.2812, 0.2798,\n",
       "            0.279 , 0.278 , 0.2776, 0.2766, 0.2761, 0.2756, 0.2751, 0.274 ,\n",
       "            0.2737, 0.2734, 0.2725, 0.2708, 0.2693, 0.2686, 0.267 , 0.266 ,\n",
       "            0.2656, 0.2651, 0.2627, 0.2622, 0.2612, 0.2583, 0.258 , 0.2563,\n",
       "            0.2542, 0.254 , 0.2537, 0.253 , 0.2527, 0.251 , 0.2493, 0.2482,\n",
       "            0.248 , 0.2474, 0.2467, 0.2466, 0.2462, 0.246 , 0.2452, 0.2437,\n",
       "            0.2422, 0.2399, 0.2397, 0.2372, 0.236 , 0.2347, 0.2327, 0.2322,\n",
       "            0.2318, 0.2285, 0.2278, 0.2263, 0.2222, 0.2166, 0.2161, 0.2085,\n",
       "            0.2065, 0.2017, 0.1919], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.15625  , 0.1640625,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.625    ,\n",
       "            0.625    , 0.625    , 0.6328125, 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.6640625,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.6796875, 0.6796875,\n",
       "            0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.6953125, 0.703125 , 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.75     , 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8046875, 0.8046875, 0.8046875, 0.8125   , 0.8125   , 0.8125   ,\n",
       "            0.8125   , 0.8125   , 0.8203125, 0.8203125, 0.828125 , 0.84375  ,\n",
       "            0.84375  , 0.84375  , 0.8515625, 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.8671875, 0.8671875, 0.8671875, 0.875    , 0.875    ,\n",
       "            0.890625 , 0.8984375, 0.8984375, 0.90625  , 0.90625  , 0.90625  ,\n",
       "            0.90625  , 0.9140625, 0.9140625, 0.9140625, 0.921875 , 0.921875 ,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.9453125, 0.9453125,\n",
       "            0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 , 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.03278688, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.16393442, 0.17213115,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.21311475, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.23770492, 0.23770492,\n",
       "            0.23770492, 0.25409836, 0.26229507, 0.2704918 , 0.2704918 ,\n",
       "            0.27868852, 0.27868852, 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.352459  ,\n",
       "            0.36065573, 0.37704918, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.48360655,\n",
       "            0.4918033 , 0.5163934 , 0.5163934 , 0.5163934 , 0.5327869 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.58196723, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4453, 0.4438, 0.4395, 0.4392, 0.439 , 0.4382, 0.438 ,\n",
       "            0.4375, 0.4373, 0.4353, 0.435 , 0.4343, 0.434 , 0.433 , 0.4326,\n",
       "            0.4324, 0.432 , 0.4312, 0.4304, 0.4297, 0.4294, 0.429 , 0.4287,\n",
       "            0.428 , 0.4265, 0.426 , 0.4248, 0.4229, 0.4226, 0.4224, 0.4214,\n",
       "            0.421 , 0.42  , 0.4197, 0.4185, 0.417 , 0.4155, 0.4104, 0.4084,\n",
       "            0.4072, 0.405 , 0.4043, 0.4038, 0.395 , 0.3909, 0.39  , 0.3882,\n",
       "            0.388 , 0.3845, 0.3818, 0.3772, 0.3757, 0.3716, 0.3691, 0.3682,\n",
       "            0.3677, 0.3657, 0.3613, 0.36  , 0.3572, 0.3562, 0.3477, 0.3457,\n",
       "            0.3445, 0.343 , 0.3408, 0.34  , 0.3396, 0.339 , 0.3384, 0.338 ,\n",
       "            0.3337, 0.3333, 0.331 , 0.3308, 0.3286, 0.3242, 0.3235, 0.3225,\n",
       "            0.321 , 0.3198, 0.3196, 0.316 , 0.3147, 0.314 , 0.3137, 0.312 ,\n",
       "            0.3118, 0.3115, 0.3113, 0.3108, 0.309 , 0.3086, 0.3083, 0.3076,\n",
       "            0.3062, 0.3057, 0.3052, 0.3044, 0.3035, 0.3032, 0.3018, 0.301 ,\n",
       "            0.3005, 0.299 , 0.2986, 0.298 , 0.297 , 0.295 , 0.2935, 0.2932,\n",
       "            0.293 , 0.2922, 0.292 , 0.289 , 0.2883, 0.2869, 0.2861, 0.286 ,\n",
       "            0.2856, 0.2852, 0.2847, 0.2842, 0.284 , 0.283 , 0.2825, 0.2803,\n",
       "            0.28  , 0.2795, 0.2788, 0.2786, 0.2773, 0.2769, 0.2761, 0.2751,\n",
       "            0.2747, 0.2744, 0.2742, 0.2737, 0.2727, 0.2722, 0.272 , 0.2708,\n",
       "            0.2703, 0.27  , 0.269 , 0.2683, 0.2676, 0.2664, 0.2656, 0.2651,\n",
       "            0.2646, 0.2637, 0.263 , 0.262 , 0.2615, 0.2612, 0.26  , 0.2595,\n",
       "            0.2585, 0.2583, 0.2578, 0.2568, 0.2566, 0.2563, 0.2542, 0.2534,\n",
       "            0.2527, 0.252 , 0.251 , 0.2502, 0.2493, 0.2487, 0.2482, 0.2477,\n",
       "            0.2474, 0.247 , 0.2456, 0.2451, 0.244 , 0.2433, 0.2426, 0.2421,\n",
       "            0.2395, 0.2391, 0.2386, 0.2356, 0.2352, 0.2343, 0.2325, 0.2322,\n",
       "            0.2306, 0.2303, 0.2289, 0.2278, 0.2268, 0.2266, 0.2252, 0.2229,\n",
       "            0.2217, 0.2216, 0.2213, 0.2207, 0.2205, 0.2203, 0.2195, 0.2186,\n",
       "            0.2173, 0.2129, 0.211 , 0.2095, 0.2094, 0.2081, 0.2064, 0.2053,\n",
       "            0.2007, 0.1991, 0.1979, 0.1917, 0.1892, 0.1819, 0.1813, 0.1797,\n",
       "            0.1687], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.6640625, 0.6640625, 0.6640625, 0.6640625, 0.6640625, 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6875   , 0.6953125, 0.6953125, 0.6953125, 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.75     , 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.796875 , 0.8046875, 0.8046875, 0.8046875,\n",
       "            0.8046875, 0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.828125 , 0.828125 , 0.828125 , 0.8359375, 0.8359375, 0.84375  ,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.8671875, 0.875    , 0.8828125, 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.8984375, 0.90625  , 0.90625  , 0.90625  , 0.9140625,\n",
       "            0.9140625, 0.9140625, 0.9140625, 0.921875 , 0.921875 , 0.9296875,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9375   , 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 0.9921875, 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.02459016, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.16393442, 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.21311475, 0.21311475, 0.22131148, 0.22950819, 0.22950819,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.23770492, 0.24590164,\n",
       "            0.24590164, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.27868852, 0.27868852, 0.28688523, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.3442623 , 0.352459  , 0.352459  ,\n",
       "            0.36065573, 0.3852459 , 0.39344263, 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5327869 , 0.5409836 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.59016395, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4368, 0.4358, 0.432 , 0.4307, 0.4304, 0.43  , 0.4297,\n",
       "            0.4292, 0.429 , 0.4268, 0.4258, 0.4253, 0.425 , 0.4238, 0.4233,\n",
       "            0.4226, 0.4224, 0.4219, 0.4216, 0.4211, 0.421 , 0.4197, 0.4192,\n",
       "            0.4187, 0.4185, 0.418 , 0.4177, 0.4158, 0.4153, 0.4143, 0.414 ,\n",
       "            0.4116, 0.4114, 0.4111, 0.41  , 0.4092, 0.4087, 0.4077, 0.4062,\n",
       "            0.4053, 0.4033, 0.3982, 0.3975, 0.3955, 0.3943, 0.3926, 0.3909,\n",
       "            0.3904, 0.3809, 0.3765, 0.3757, 0.3735, 0.3728, 0.3704, 0.3665,\n",
       "            0.365 , 0.3606, 0.3552, 0.3542, 0.353 , 0.3503, 0.349 , 0.344 ,\n",
       "            0.3433, 0.3386, 0.3384, 0.3298, 0.3281, 0.3271, 0.3235, 0.321 ,\n",
       "            0.3203, 0.32  , 0.3196, 0.3186, 0.3184, 0.317 , 0.3137, 0.3108,\n",
       "            0.3105, 0.3074, 0.304 , 0.3027, 0.3018, 0.3003, 0.2988, 0.2947,\n",
       "            0.294 , 0.2935, 0.2922, 0.292 , 0.2915, 0.2903, 0.29  , 0.2896,\n",
       "            0.288 , 0.2874, 0.2866, 0.2856, 0.2842, 0.2832, 0.283 , 0.2822,\n",
       "            0.2815, 0.281 , 0.2808, 0.2805, 0.2803, 0.279 , 0.277 , 0.2761,\n",
       "            0.276 , 0.2751, 0.272 , 0.2717, 0.2705, 0.27  , 0.2683, 0.266 ,\n",
       "            0.2646, 0.2642, 0.264 , 0.2637, 0.2634, 0.2632, 0.263 , 0.2607,\n",
       "            0.2605, 0.2593, 0.2585, 0.2573, 0.257 , 0.2566, 0.2559, 0.2556,\n",
       "            0.2554, 0.2542, 0.2537, 0.2532, 0.2524, 0.252 , 0.2515, 0.2507,\n",
       "            0.2496, 0.2494, 0.2493, 0.2487, 0.2466, 0.246 , 0.2456, 0.2445,\n",
       "            0.2438, 0.2433, 0.2426, 0.2422, 0.2406, 0.2394, 0.2386, 0.2384,\n",
       "            0.2382, 0.2372, 0.237 , 0.2368, 0.2352, 0.2351, 0.235 , 0.234 ,\n",
       "            0.2339, 0.2335, 0.2334, 0.2322, 0.2314, 0.2297, 0.2277, 0.2274,\n",
       "            0.2261, 0.226 , 0.2256, 0.2252, 0.2242, 0.2233, 0.2229, 0.2225,\n",
       "            0.2218, 0.2202, 0.2186, 0.2181, 0.2161, 0.2148, 0.2147, 0.2128,\n",
       "            0.2119, 0.2113, 0.2103, 0.21  , 0.2085, 0.2084, 0.2051, 0.2043,\n",
       "            0.2029, 0.2023, 0.2017, 0.2006, 0.1987, 0.1979, 0.197 , 0.1967,\n",
       "            0.1965, 0.1964, 0.1962, 0.196 , 0.1956, 0.1954, 0.1913, 0.1891,\n",
       "            0.1884, 0.1879, 0.1855, 0.1842, 0.1837, 0.1829, 0.1827, 0.1771,\n",
       "            0.1757, 0.1755, 0.1693, 0.1659, 0.1594, 0.1593, 0.1582, 0.1477],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0625   , 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5625   , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.6171875, 0.625    , 0.625    , 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6796875, 0.6796875,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6953125, 0.6953125, 0.6953125,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.75     , 0.75     ,\n",
       "            0.75     , 0.75     , 0.7578125, 0.765625 , 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.8359375, 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.9140625,\n",
       "            0.9140625, 0.9140625, 0.9140625, 0.921875 , 0.9296875, 0.9296875,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.9609375, 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625, 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.984375 , 0.984375 , 0.9921875, 0.9921875,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22131148, 0.22950819, 0.22950819,\n",
       "            0.22950819, 0.22950819, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.31967214, 0.32786885, 0.3442623 ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4262295 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.44262296, 0.44262296, 0.45081967, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.55737704, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6803279 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4282, 0.428 , 0.4277, 0.424 , 0.4233, 0.4219, 0.4216,\n",
       "            0.421 , 0.4197, 0.418 , 0.4165, 0.4163, 0.4158, 0.4146, 0.414 ,\n",
       "            0.4126, 0.4119, 0.4114, 0.4111, 0.411 , 0.4097, 0.4087, 0.4084,\n",
       "            0.4082, 0.408 , 0.4065, 0.405 , 0.4043, 0.4033, 0.4004, 0.4001,\n",
       "            0.3994, 0.3982, 0.3975, 0.3958, 0.3938, 0.3933, 0.3909, 0.3857,\n",
       "            0.3843, 0.3826, 0.381 , 0.3804, 0.3774, 0.3772, 0.3667, 0.362 ,\n",
       "            0.3618, 0.359 , 0.3572, 0.3564, 0.3538, 0.3513, 0.344 , 0.3396,\n",
       "            0.3386, 0.3384, 0.333 , 0.3325, 0.327 , 0.3262, 0.3213, 0.3198,\n",
       "            0.3115, 0.311 , 0.3086, 0.3079, 0.3018, 0.3013, 0.301 , 0.3005,\n",
       "            0.299 , 0.2988, 0.2937, 0.291 , 0.2908, 0.2861, 0.2842, 0.2827,\n",
       "            0.2815, 0.28  , 0.2786, 0.2783, 0.275 , 0.2737, 0.2727, 0.2703,\n",
       "            0.2698, 0.2695, 0.269 , 0.2666, 0.2656, 0.2646, 0.2644, 0.2622,\n",
       "            0.262 , 0.2607, 0.2605, 0.2603, 0.2595, 0.2585, 0.258 , 0.2578,\n",
       "            0.2556, 0.2542, 0.254 , 0.2507, 0.2493, 0.249 , 0.2485, 0.2452,\n",
       "            0.2451, 0.2448, 0.2437, 0.2433, 0.243 , 0.2417, 0.2415, 0.2413,\n",
       "            0.2411, 0.241 , 0.2384, 0.237 , 0.2358, 0.2356, 0.2355, 0.2346,\n",
       "            0.2343, 0.2339, 0.2328, 0.2316, 0.231 , 0.2302, 0.2301, 0.2295,\n",
       "            0.2286, 0.228 , 0.2278, 0.2274, 0.2266, 0.2263, 0.2261, 0.2257,\n",
       "            0.2239, 0.2238, 0.2233, 0.2227, 0.2218, 0.2213, 0.2211, 0.2205,\n",
       "            0.2203, 0.22  , 0.217 , 0.2167, 0.2166, 0.2153, 0.2152, 0.2147,\n",
       "            0.2145, 0.2144, 0.2128, 0.2115, 0.2114, 0.211 , 0.2103, 0.209 ,\n",
       "            0.2079, 0.2064, 0.2051, 0.2043, 0.2035, 0.2032, 0.2023, 0.202 ,\n",
       "            0.2017, 0.2   , 0.1989, 0.1982, 0.195 , 0.1947, 0.1946, 0.1925,\n",
       "            0.1915, 0.1906, 0.19  , 0.1886, 0.1884, 0.1876, 0.1863, 0.1835,\n",
       "            0.1824, 0.181 , 0.1797, 0.1796, 0.1791, 0.1771, 0.1761, 0.1758,\n",
       "            0.1755, 0.1737, 0.1735, 0.1733, 0.1719, 0.1709, 0.1685, 0.1683,\n",
       "            0.1666, 0.1648, 0.1646, 0.1643, 0.1605, 0.1599, 0.159 , 0.1556,\n",
       "            0.1547, 0.1543, 0.1483, 0.1447, 0.1409, 0.1387, 0.1372, 0.1282],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.59375  , 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.625    , 0.625    , 0.6328125, 0.6328125, 0.640625 , 0.640625 ,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.6953125, 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.75     , 0.75     , 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.7890625, 0.796875 , 0.796875 , 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8125   , 0.8125   , 0.8125   , 0.8203125, 0.828125 , 0.828125 ,\n",
       "            0.828125 , 0.828125 , 0.828125 , 0.828125 , 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.8359375, 0.84375  , 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.875    , 0.8828125,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.90625  ,\n",
       "            0.9140625, 0.9140625, 0.9140625, 0.921875 , 0.921875 , 0.9296875,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.953125 , 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 0.9921875, 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.01639344, 0.01639344,\n",
       "            0.03278688, 0.04098361, 0.04098361, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.1147541 ,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.17213115, 0.18852459,\n",
       "            0.18852459, 0.18852459, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22131148, 0.22131148, 0.22950819, 0.22950819, 0.22950819,\n",
       "            0.22950819, 0.24590164, 0.25409836, 0.25409836, 0.26229507,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.27868852, 0.27868852,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.44262296, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5081967 , 0.5163934 , 0.5163934 , 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.55737704, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.73770493, 0.74590164,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9918033 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.42   , 0.4194 , 0.4163 , 0.4158 , 0.4143 , 0.4128 ,\n",
       "            0.4126 , 0.4119 , 0.4102 , 0.4092 , 0.4072 , 0.407  , 0.4065 ,\n",
       "            0.4053 , 0.4045 , 0.403  , 0.4023 , 0.402  , 0.4014 , 0.4011 ,\n",
       "            0.4006 , 0.3994 , 0.3984 , 0.3982 , 0.3977 , 0.395  , 0.394  ,\n",
       "            0.3936 , 0.3926 , 0.3923 , 0.3887 , 0.3877 , 0.3865 , 0.3862 ,\n",
       "            0.3853 , 0.3835 , 0.3813 , 0.381  , 0.3782 , 0.3733 , 0.3708 ,\n",
       "            0.3694 , 0.368  , 0.364  , 0.3638 , 0.3523 , 0.3474 , 0.3472 ,\n",
       "            0.344  , 0.343  , 0.3416 , 0.3413 , 0.3357 , 0.3274 , 0.324  ,\n",
       "            0.3228 , 0.3223 , 0.3162 , 0.3154 , 0.3096 , 0.3086 , 0.304  ,\n",
       "            0.3008 , 0.2952 , 0.2922 , 0.2893 , 0.2842 , 0.2822 , 0.2817 ,\n",
       "            0.2812 , 0.28   , 0.279  , 0.2742 , 0.2703 , 0.2654 , 0.2644 ,\n",
       "            0.2617 , 0.2605 , 0.2595 , 0.2583 , 0.2576 , 0.2566 , 0.2537 ,\n",
       "            0.2534 , 0.251  , 0.2494 , 0.2485 , 0.248  , 0.2451 , 0.2445 ,\n",
       "            0.2441 , 0.2438 , 0.2437 , 0.2411 , 0.2401 , 0.239  , 0.2383 ,\n",
       "            0.2378 , 0.237  , 0.2368 , 0.2366 , 0.2347 , 0.2334 , 0.2325 ,\n",
       "            0.2323 , 0.2302 , 0.2274 , 0.2273 , 0.2272 , 0.2269 , 0.2244 ,\n",
       "            0.2229 , 0.2227 , 0.2218 , 0.2212 , 0.2207 , 0.2205 , 0.2197 ,\n",
       "            0.217  , 0.2161 , 0.2147 , 0.2144 , 0.2137 , 0.2134 , 0.2133 ,\n",
       "            0.2129 , 0.2119 , 0.2109 , 0.2108 , 0.2091 , 0.2085 , 0.2081 ,\n",
       "            0.2079 , 0.2076 , 0.206  , 0.2059 , 0.2053 , 0.205  , 0.2048 ,\n",
       "            0.2047 , 0.2032 , 0.2031 , 0.2023 , 0.202  , 0.201  , 0.2006 ,\n",
       "            0.2004 , 0.1995 , 0.1993 , 0.1987 , 0.196  , 0.1958 , 0.1953 ,\n",
       "            0.1952 , 0.195  , 0.1936 , 0.1934 , 0.1927 , 0.1923 , 0.1917 ,\n",
       "            0.1913 , 0.1912 , 0.1904 , 0.1901 , 0.1898 , 0.1892 , 0.1887 ,\n",
       "            0.1866 , 0.1864 , 0.1844 , 0.1841 , 0.1838 , 0.1826 , 0.1824 ,\n",
       "            0.1819 , 0.1814 , 0.1804 , 0.1798 , 0.1782 , 0.1768 , 0.1748 ,\n",
       "            0.1744 , 0.1733 , 0.1725 , 0.1707 , 0.1699 , 0.1698 , 0.1686 ,\n",
       "            0.1678 , 0.1656 , 0.1647 , 0.1641 , 0.1611 , 0.1608 , 0.16   ,\n",
       "            0.159  , 0.1578 , 0.157  , 0.1569 , 0.1565 , 0.1558 , 0.1548 ,\n",
       "            0.153  , 0.1525 , 0.1519 , 0.1504 , 0.15   , 0.1492 , 0.1484 ,\n",
       "            0.1464 , 0.1448 , 0.1443 , 0.1437 , 0.1401 , 0.1384 , 0.1377 ,\n",
       "            0.1357 , 0.1343 , 0.1334 , 0.1294 , 0.1242 , 0.1238 , 0.12   ,\n",
       "            0.1172 , 0.11066], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.625    , 0.625    , 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.703125 , 0.7109375, 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.7265625, 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.75     , 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.8203125, 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.828125 , 0.828125 , 0.828125 , 0.8359375, 0.8359375, 0.8359375,\n",
       "            0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.8671875,\n",
       "            0.875    , 0.8828125, 0.8828125, 0.890625 , 0.8984375, 0.8984375,\n",
       "            0.8984375, 0.90625  , 0.90625  , 0.9140625, 0.9140625, 0.9140625,\n",
       "            0.921875 , 0.921875 , 0.921875 , 0.9296875, 0.9296875, 0.9296875,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.9453125, 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 0.9921875, 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.21311475, 0.21311475, 0.22131148, 0.22131148, 0.22131148,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.24590164, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.26229507, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.3114754 , 0.32786885,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4180328 , 0.43442622,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45081967, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.59016395, 0.59836066, 0.59836066, 0.60655737, 0.60655737,\n",
       "            0.60655737, 0.6147541 , 0.6147541 , 0.6229508 , 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8606557 , 0.8770492 , 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4116 , 0.4111 , 0.411  , 0.4084 , 0.408  , 0.4065 ,\n",
       "            0.404  , 0.4038 , 0.4028 , 0.401  , 0.4004 , 0.3982 , 0.3977 ,\n",
       "            0.3975 , 0.397  , 0.3958 , 0.395  , 0.3933 , 0.3926 , 0.3923 ,\n",
       "            0.3914 , 0.39   , 0.3894 , 0.3877 , 0.3875 , 0.384  , 0.3835 ,\n",
       "            0.3826 , 0.3818 , 0.3816 , 0.3772 , 0.377  , 0.376  , 0.3752 ,\n",
       "            0.3745 , 0.3733 , 0.3716 , 0.3696 , 0.3691 , 0.3657 , 0.3616 ,\n",
       "            0.3574 , 0.3564 , 0.3552 , 0.3547 , 0.3518 , 0.3513 , 0.3381 ,\n",
       "            0.3345 , 0.333  , 0.332  , 0.3298 , 0.3293 , 0.3257 , 0.3208 ,\n",
       "            0.3123 , 0.3118 , 0.3108 , 0.3062 , 0.3    , 0.2996 , 0.2961 ,\n",
       "            0.2917 , 0.2869 , 0.2852 , 0.2798 , 0.279  , 0.2769 , 0.2747 ,\n",
       "            0.2742 , 0.2683 , 0.2673 , 0.2656 , 0.2646 , 0.2642 , 0.2627 ,\n",
       "            0.26   , 0.256  , 0.255  , 0.2542 , 0.247  , 0.2462 , 0.2456 ,\n",
       "            0.2448 , 0.2428 , 0.2421 , 0.2395 , 0.2391 , 0.2362 , 0.2347 ,\n",
       "            0.2344 , 0.2318 , 0.2316 , 0.2295 , 0.2294 , 0.2289 , 0.2283 ,\n",
       "            0.2257 , 0.2247 , 0.2242 , 0.2238 , 0.2225 , 0.2213 , 0.2194 ,\n",
       "            0.2185 , 0.2179 , 0.2172 , 0.2167 , 0.2166 , 0.2163 , 0.2162 ,\n",
       "            0.2142 , 0.2125 , 0.2113 , 0.2108 , 0.2106 , 0.2095 , 0.2074 ,\n",
       "            0.207  , 0.2058 , 0.2034 , 0.2031 , 0.2023 , 0.2009 , 0.2002 ,\n",
       "            0.1998 , 0.1996 , 0.1979 , 0.1976 , 0.1973 , 0.1958 , 0.1941 ,\n",
       "            0.1937 , 0.193  , 0.1929 , 0.1924 , 0.1919 , 0.1909 , 0.1907 ,\n",
       "            0.1904 , 0.1896 , 0.1891 , 0.1884 , 0.188  , 0.1876 , 0.1858 ,\n",
       "            0.1855 , 0.1848 , 0.1844 , 0.1833 , 0.1827 , 0.1824 , 0.1823 ,\n",
       "            0.1819 , 0.1813 , 0.1808 , 0.1804 , 0.1797 , 0.1794 , 0.179  ,\n",
       "            0.1787 , 0.1785 , 0.177  , 0.1765 , 0.1753 , 0.1744 , 0.174  ,\n",
       "            0.1738 , 0.1736 , 0.1735 , 0.1729 , 0.1718 , 0.1715 , 0.171  ,\n",
       "            0.17   , 0.1699 , 0.1678 , 0.1649 , 0.1648 , 0.1647 , 0.1646 ,\n",
       "            0.1632 , 0.1627 , 0.1621 , 0.1603 , 0.1598 , 0.158  , 0.1569 ,\n",
       "            0.1559 , 0.1538 , 0.1526 , 0.1525 , 0.1523 , 0.1505 , 0.1503 ,\n",
       "            0.1499 , 0.1481 , 0.1467 , 0.1456 , 0.1454 , 0.1444 , 0.1443 ,\n",
       "            0.1431 , 0.1421 , 0.1395 , 0.1388 , 0.1387 , 0.1378 , 0.1343 ,\n",
       "            0.1338 , 0.1329 , 0.1328 , 0.1317 , 0.1313 , 0.1295 , 0.1288 ,\n",
       "            0.1271 , 0.1251 , 0.12476, 0.12213, 0.12067, 0.1197 , 0.1192 ,\n",
       "            0.119  , 0.1186 , 0.1126 , 0.1105 , 0.1084 , 0.10376, 0.1036 ,\n",
       "            0.09534], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.078125 , 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2265625, 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.6171875, 0.625    , 0.625    , 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.7109375,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.7421875, 0.75     , 0.75     ,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.765625 , 0.765625 ,\n",
       "            0.765625 , 0.765625 , 0.78125  , 0.7890625, 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8046875, 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.8203125, 0.8203125, 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.8359375,\n",
       "            0.84375  , 0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.8515625, 0.859375 , 0.8671875, 0.8671875, 0.8671875,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.8828125, 0.890625 , 0.890625 ,\n",
       "            0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.921875 , 0.921875 , 0.921875 ,\n",
       "            0.921875 , 0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.984375 , 0.984375 , 0.9921875, 0.9921875, 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.13934426, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.20491803, 0.21311475, 0.21311475, 0.22131148, 0.22131148,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.23770492, 0.24590164,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.27868852, 0.27868852, 0.28688523, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.39344263, 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.43442622, 0.43442622,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.46721312, 0.46721312, 0.47540984, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59016395, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4036 , 0.4028 , 0.402  , 0.4004 , 0.4001 , 0.3984 ,\n",
       "            0.3955 , 0.395  , 0.3936 , 0.3914 , 0.389  , 0.3882 , 0.3877 ,\n",
       "            0.386  , 0.3857 , 0.3833 , 0.3828 , 0.3826 , 0.3813 , 0.381  ,\n",
       "            0.3794 , 0.3774 , 0.3772 , 0.377  , 0.3728 , 0.3716 , 0.371  ,\n",
       "            0.3706 , 0.3652 , 0.365  , 0.364  , 0.3623 , 0.361  , 0.3591 ,\n",
       "            0.358  , 0.3567 , 0.353  , 0.3499 , 0.344  , 0.343  , 0.3423 ,\n",
       "            0.3416 , 0.3396 , 0.3386 , 0.324  , 0.322  , 0.321  , 0.3186 ,\n",
       "            0.3174 , 0.3147 , 0.3098 , 0.3057 , 0.2993 , 0.298  , 0.297  ,\n",
       "            0.2905 , 0.2842 , 0.2837 , 0.2822 , 0.275  , 0.27   , 0.269  ,\n",
       "            0.2644 , 0.263  , 0.2617 , 0.259  , 0.2556 , 0.2527 , 0.2522 ,\n",
       "            0.249  , 0.248  , 0.2467 , 0.2455 , 0.2413 , 0.2384 , 0.2382 ,\n",
       "            0.2374 , 0.2301 , 0.2294 , 0.2283 , 0.2264 , 0.2257 , 0.222  ,\n",
       "            0.2212 , 0.219  , 0.2162 , 0.2158 , 0.215  , 0.2148 , 0.2134 ,\n",
       "            0.213  , 0.21   , 0.2089 , 0.2085 , 0.2063 , 0.2058 , 0.2051 ,\n",
       "            0.204  , 0.2039 , 0.2024 , 0.2002 , 0.2001 , 0.1995 , 0.1982 ,\n",
       "            0.1981 , 0.1973 , 0.1971 , 0.1967 , 0.1954 , 0.1947 , 0.194  ,\n",
       "            0.1931 , 0.1925 , 0.1923 , 0.1918 , 0.1906 , 0.1896 , 0.1879 ,\n",
       "            0.1874 , 0.1863 , 0.186  , 0.1826 , 0.182  , 0.1814 , 0.181  ,\n",
       "            0.1803 , 0.1798 , 0.1796 , 0.1794 , 0.1781 , 0.1753 , 0.1752 ,\n",
       "            0.1749 , 0.1741 , 0.1738 , 0.1736 , 0.173  , 0.1729 , 0.1725 ,\n",
       "            0.1716 , 0.1715 , 0.1708 , 0.1698 , 0.1693 , 0.169  , 0.1675 ,\n",
       "            0.167  , 0.1669 , 0.1664 , 0.1659 , 0.1658 , 0.1654 , 0.1647 ,\n",
       "            0.1644 , 0.1636 , 0.1635 , 0.1627 , 0.1615 , 0.161  , 0.1609 ,\n",
       "            0.1606 , 0.1602 , 0.1594 , 0.159  , 0.1584 , 0.1575 , 0.1567 ,\n",
       "            0.1565 , 0.1562 , 0.155  , 0.1544 , 0.1542 , 0.154  , 0.1536 ,\n",
       "            0.1533 , 0.1516 , 0.1486 , 0.1482 , 0.1467 , 0.1466 , 0.146  ,\n",
       "            0.1459 , 0.1453 , 0.1451 , 0.144  , 0.1437 , 0.1421 , 0.1409 ,\n",
       "            0.1384 , 0.1381 , 0.1366 , 0.1355 , 0.1353 , 0.1337 , 0.1332 ,\n",
       "            0.133  , 0.1323 , 0.132  , 0.1318 , 0.1317 , 0.1299 , 0.129  ,\n",
       "            0.1279 , 0.1268 , 0.126  , 0.1255 , 0.1241 , 0.1232 , 0.12244,\n",
       "            0.12177, 0.12115, 0.12103, 0.1172 , 0.11633, 0.1158 , 0.11536,\n",
       "            0.11395, 0.1138 , 0.111  , 0.11066, 0.108  , 0.1069 , 0.1067 ,\n",
       "            0.1056 , 0.10486, 0.103  , 0.1025 , 0.10175, 0.0974 , 0.0967 ,\n",
       "            0.0945 , 0.0904 , 0.0888 , 0.08154], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.625    , 0.625    , 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.7109375, 0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.765625 , 0.765625 , 0.7734375, 0.7734375, 0.7734375,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.796875 , 0.8046875, 0.8046875, 0.8046875, 0.8046875, 0.8125   ,\n",
       "            0.8125   , 0.8125   , 0.8203125, 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.828125 , 0.828125 , 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.84375  , 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.8671875, 0.875    , 0.875    ,\n",
       "            0.875    , 0.8828125, 0.8828125, 0.8828125, 0.890625 , 0.890625 ,\n",
       "            0.890625 , 0.890625 , 0.8984375, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.921875 , 0.921875 , 0.921875 , 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9375   , 0.9375   , 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.9921875,\n",
       "            0.9921875, 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.19672132, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.21311475, 0.21311475, 0.21311475,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.24590164, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.26229507, 0.2704918 , 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.3114754 , 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.647541  , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3936 , 0.3926 , 0.3914 , 0.3906 , 0.3904 , 0.3887 ,\n",
       "            0.3848 , 0.3843 , 0.3828 , 0.3806 , 0.3801 , 0.378  , 0.377  ,\n",
       "            0.3767 , 0.3765 , 0.3743 , 0.3716 , 0.371  , 0.3706 , 0.3699 ,\n",
       "            0.3691 , 0.3674 , 0.367  , 0.3652 , 0.3647 , 0.3643 , 0.364  ,\n",
       "            0.36   , 0.3599 , 0.3586 , 0.3582 , 0.358  , 0.351  , 0.3508 ,\n",
       "            0.3499 , 0.3481 , 0.3467 , 0.3445 , 0.342  , 0.3381 , 0.3364 ,\n",
       "            0.328  , 0.3271 , 0.326  , 0.3254 , 0.324  , 0.3079 , 0.3076 ,\n",
       "            0.3074 , 0.3035 , 0.3018 , 0.298  , 0.292  , 0.2886 , 0.285  ,\n",
       "            0.284  , 0.28   , 0.2722 , 0.2666 , 0.266  , 0.2659 , 0.2559 ,\n",
       "            0.251  , 0.2507 , 0.2467 , 0.2451 , 0.2448 , 0.2422 , 0.2352 ,\n",
       "            0.235  , 0.2303 , 0.2294 , 0.2268 , 0.2264 , 0.2207 , 0.2205 ,\n",
       "            0.2194 , 0.2184 , 0.2124 , 0.2104 , 0.2101 , 0.2081 , 0.2069 ,\n",
       "            0.2051 , 0.2032 , 0.201  , 0.2002 , 0.1967 , 0.196  , 0.1958 ,\n",
       "            0.1956 , 0.1934 , 0.1897 , 0.189  , 0.1876 , 0.186  , 0.1846 ,\n",
       "            0.1841 , 0.1827 , 0.1824 , 0.1819 , 0.1803 , 0.1785 , 0.178  ,\n",
       "            0.1768 , 0.1766 , 0.1761 , 0.1759 , 0.1758 , 0.1755 , 0.1754 ,\n",
       "            0.1752 , 0.1741 , 0.1731 , 0.1724 , 0.1721 , 0.1687 , 0.1683 ,\n",
       "            0.1676 , 0.1664 , 0.1633 , 0.1619 , 0.1615 , 0.1608 , 0.1605 ,\n",
       "            0.1597 , 0.1594 , 0.159  , 0.1584 , 0.1573 , 0.1562 , 0.1555 ,\n",
       "            0.1548 , 0.154  , 0.1537 , 0.1532 , 0.1528 , 0.1521 , 0.1514 ,\n",
       "            0.1512 , 0.151  , 0.1509 , 0.1498 , 0.1495 , 0.1483 , 0.1482 ,\n",
       "            0.148  , 0.1462 , 0.146  , 0.1458 , 0.145  , 0.1438 , 0.1436 ,\n",
       "            0.1434 , 0.1432 , 0.1431 , 0.1421 , 0.1415 , 0.1411 , 0.141  ,\n",
       "            0.1407 , 0.14   , 0.1399 , 0.139  , 0.1388 , 0.1387 , 0.1385 ,\n",
       "            0.138  , 0.1378 , 0.1368 , 0.1359 , 0.1354 , 0.1346 , 0.1344 ,\n",
       "            0.1317 , 0.1312 , 0.1304 , 0.129  , 0.1279 , 0.1277 , 0.1276 ,\n",
       "            0.1266 , 0.1262 , 0.1261 , 0.1256 , 0.12463, 0.12146, 0.1201 ,\n",
       "            0.1188 , 0.1174 , 0.1166 , 0.11633, 0.1158 , 0.11554, 0.115  ,\n",
       "            0.1144 , 0.11395, 0.1136 , 0.1134 , 0.11316, 0.1124 , 0.1084 ,\n",
       "            0.1078 , 0.10724, 0.1067 , 0.1056 , 0.1043 , 0.1041 , 0.103  ,\n",
       "            0.1009 , 0.0997 , 0.0993 , 0.09875, 0.0981 , 0.0977 , 0.096  ,\n",
       "            0.09467, 0.0925 , 0.09076, 0.0906 , 0.089  , 0.0874 , 0.0854 ,\n",
       "            0.0848 , 0.083  , 0.0821 , 0.0805 , 0.0772 , 0.0742 , 0.06793],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.6171875, 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.6484375, 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.6796875, 0.6796875,\n",
       "            0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.6953125, 0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.734375 , 0.734375 , 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.75     , 0.765625 , 0.765625 , 0.765625 , 0.7734375, 0.7734375,\n",
       "            0.7734375, 0.7734375, 0.7734375, 0.7734375, 0.78125  , 0.796875 ,\n",
       "            0.8046875, 0.8046875, 0.8046875, 0.8046875, 0.8046875, 0.8125   ,\n",
       "            0.8125   , 0.8125   , 0.8125   , 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.8671875, 0.8671875, 0.8671875, 0.875    , 0.875    ,\n",
       "            0.8828125, 0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.921875 , 0.921875 , 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9375   , 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625,\n",
       "            0.984375 , 0.984375 , 0.9921875, 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.03278688, 0.04098361, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.20491803, 0.20491803, 0.21311475,\n",
       "            0.21311475, 0.22131148, 0.22131148, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.3114754 , 0.31967214, 0.31967214,\n",
       "            0.31967214, 0.32786885, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.4918033 , 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.704918  , 0.71311474, 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.75409836, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3818 , 0.3809 , 0.3796 , 0.3794 , 0.379  , 0.3774 ,\n",
       "            0.3728 , 0.3726 , 0.3723 , 0.3708 , 0.3687 , 0.3684 , 0.3662 ,\n",
       "            0.365  , 0.3645 , 0.3625 , 0.3616 , 0.3591 , 0.359  , 0.3586 ,\n",
       "            0.358  , 0.3564 , 0.3552 , 0.354  , 0.3533 , 0.3523 , 0.35   ,\n",
       "            0.348  , 0.3467 , 0.346  , 0.3457 , 0.3452 , 0.3384 , 0.337  ,\n",
       "            0.3354 , 0.3352 , 0.3335 , 0.3333 , 0.3318 , 0.3303 , 0.3286 ,\n",
       "            0.3237 , 0.3235 , 0.3127 , 0.3115 , 0.3113 , 0.311  , 0.3108 ,\n",
       "            0.3105 , 0.2947 , 0.293  , 0.2922 , 0.2903 , 0.2861 , 0.282  ,\n",
       "            0.274  , 0.2727 , 0.2725 , 0.2712 , 0.2654 , 0.256  , 0.254  ,\n",
       "            0.251  , 0.2493 , 0.2394 , 0.2366 , 0.2335 , 0.229  , 0.2285 ,\n",
       "            0.2268 , 0.2224 , 0.217  , 0.2157 , 0.2156 , 0.2148 , 0.2108 ,\n",
       "            0.209  , 0.207  , 0.2051 , 0.202  , 0.2012 , 0.1991 , 0.197  ,\n",
       "            0.1952 , 0.1947 , 0.1925 , 0.186  , 0.1855 , 0.1848 , 0.1841 ,\n",
       "            0.183  , 0.1827 , 0.1792 , 0.1766 , 0.1743 , 0.174  , 0.1711 ,\n",
       "            0.1703 , 0.1698 , 0.1697 , 0.1688 , 0.1654 , 0.1646 , 0.1641 ,\n",
       "            0.164  , 0.1638 , 0.1632 , 0.1626 , 0.1605 , 0.16   , 0.1594 ,\n",
       "            0.1587 , 0.1582 , 0.1577 , 0.1575 , 0.1571 , 0.1562 , 0.1549 ,\n",
       "            0.154  , 0.1538 , 0.1537 , 0.1506 , 0.1505 , 0.1483 , 0.1444 ,\n",
       "            0.144  , 0.1439 , 0.1438 , 0.1436 , 0.1428 , 0.1427 , 0.1426 ,\n",
       "            0.1412 , 0.1407 , 0.1406 , 0.1401 , 0.1392 , 0.1385 , 0.1384 ,\n",
       "            0.1383 , 0.1377 , 0.136  , 0.1356 , 0.1355 , 0.1353 , 0.1345 ,\n",
       "            0.1342 , 0.1339 , 0.1329 , 0.1321 , 0.132  , 0.1309 , 0.1307 ,\n",
       "            0.13   , 0.1292 , 0.1289 , 0.1285 , 0.127  , 0.1267 , 0.1263 ,\n",
       "            0.1262 , 0.1257 , 0.1251 , 0.1245 , 0.12445, 0.1243 , 0.124  ,\n",
       "            0.12366, 0.12335, 0.12305, 0.12213, 0.1219 , 0.1217 , 0.1213 ,\n",
       "            0.12054, 0.12   , 0.11993, 0.119  , 0.1186 , 0.1178 , 0.11694,\n",
       "            0.11475, 0.1138 , 0.11145, 0.11127, 0.111  , 0.1101 , 0.1097 ,\n",
       "            0.1084 , 0.1063 , 0.1056 , 0.1041 , 0.103  , 0.10284, 0.1021 ,\n",
       "            0.10175, 0.1009 , 0.10016, 0.1    , 0.09894, 0.0981 , 0.0977 ,\n",
       "            0.09753, 0.0933 , 0.0927 , 0.0922 , 0.09174, 0.09076, 0.0893 ,\n",
       "            0.0883 , 0.0863 , 0.0851 , 0.08496, 0.08435, 0.0836 , 0.0833 ,\n",
       "            0.0818 , 0.08105, 0.0806 , 0.0788 , 0.07697, 0.07544, 0.0752 ,\n",
       "            0.0742 , 0.074  , 0.0721 , 0.0716 , 0.06903, 0.0688 , 0.06793,\n",
       "            0.06198, 0.05646], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.2265625, 0.234375 , 0.2421875, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6796875, 0.6796875,\n",
       "            0.6796875, 0.6796875, 0.6796875, 0.6875   , 0.6953125, 0.6953125,\n",
       "            0.6953125, 0.6953125, 0.703125 , 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.7265625, 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.75     , 0.75     , 0.765625 ,\n",
       "            0.765625 , 0.765625 , 0.7734375, 0.7734375, 0.78125  , 0.78125  ,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8046875, 0.8046875,\n",
       "            0.8046875, 0.8046875, 0.8046875, 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.8203125, 0.828125 , 0.828125 , 0.828125 ,\n",
       "            0.8359375, 0.8359375, 0.84375  , 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.8515625, 0.8515625, 0.859375 , 0.8671875, 0.8671875,\n",
       "            0.875    , 0.875    , 0.8828125, 0.8828125, 0.890625 , 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.921875 , 0.921875 ,\n",
       "            0.921875 , 0.921875 , 0.921875 , 0.9296875, 0.9296875, 0.9375   ,\n",
       "            0.9375   , 0.9375   , 0.9375   , 0.9453125, 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.9765625, 0.9765625, 0.984375 , 0.9921875, 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.01639344, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.03278688, 0.04098361, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.19672132, 0.20491803, 0.20491803, 0.21311475, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.23770492, 0.23770492,\n",
       "            0.24590164, 0.24590164, 0.25409836, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.3114754 , 0.31967214, 0.31967214,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.352459  , 0.352459  , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.48360655, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.5163934 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.77868855, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3704 , 0.3694 , 0.3684 , 0.3677 , 0.3667 , 0.3613 ,\n",
       "            0.361  , 0.3606 , 0.3596 , 0.3572 , 0.357  , 0.355  , 0.3538 ,\n",
       "            0.3535 , 0.353  , 0.351  , 0.3489 , 0.3472 , 0.347  , 0.3462 ,\n",
       "            0.3442 , 0.344  , 0.342  , 0.3416 , 0.34   , 0.3362 , 0.3354 ,\n",
       "            0.3345 , 0.3337 , 0.3335 , 0.3267 , 0.3232 , 0.3215 , 0.3206 ,\n",
       "            0.32   , 0.3193 , 0.317  , 0.3157 , 0.312  , 0.309  , 0.2988 ,\n",
       "            0.2986 , 0.298  , 0.2969 , 0.295  , 0.2944 , 0.2832 , 0.2788 ,\n",
       "            0.2786 , 0.2776 , 0.2712 , 0.267  , 0.262  , 0.2605 , 0.2576 ,\n",
       "            0.2563 , 0.2522 , 0.243  , 0.2411 , 0.2379 , 0.2335 , 0.2244 ,\n",
       "            0.2242 , 0.2181 , 0.2175 , 0.212  , 0.2113 , 0.2101 , 0.2095 ,\n",
       "            0.2031 , 0.2024 , 0.2    , 0.1978 , 0.1971 , 0.1962 , 0.1934 ,\n",
       "            0.1925 , 0.1887 , 0.1873 , 0.1863 , 0.1849 , 0.1835 , 0.1814 ,\n",
       "            0.1804 , 0.1731 , 0.1727 , 0.172  , 0.1711 , 0.169  , 0.1687 ,\n",
       "            0.1677 , 0.1644 , 0.1632 , 0.1631 , 0.1599 , 0.1593 , 0.1572 ,\n",
       "            0.1569 , 0.1558 , 0.1554 , 0.1542 , 0.1537 , 0.1532 , 0.1523 ,\n",
       "            0.1519 , 0.151  , 0.1509 , 0.1508 , 0.1497 , 0.1488 , 0.1473 ,\n",
       "            0.1464 , 0.1444 , 0.1443 , 0.143  , 0.1421 , 0.1416 , 0.141  ,\n",
       "            0.1409 , 0.1407 , 0.1405 , 0.1399 , 0.1376 , 0.1371 , 0.1343 ,\n",
       "            0.134  , 0.1329 , 0.1328 , 0.1322 , 0.1305 , 0.1294 , 0.1285 ,\n",
       "            0.1284 , 0.1279 , 0.1277 , 0.1276 , 0.127  , 0.1267 , 0.1256 ,\n",
       "            0.1254 , 0.12494, 0.1249 , 0.1226 , 0.12115, 0.12054, 0.12036,\n",
       "            0.12024, 0.12   , 0.11993, 0.1196 , 0.1194 , 0.119  , 0.1184 ,\n",
       "            0.1166 , 0.11633, 0.11536, 0.115  , 0.11475, 0.1138 , 0.1134 ,\n",
       "            0.11316, 0.1128 , 0.11163, 0.11127, 0.111  , 0.1103 , 0.1101 ,\n",
       "            0.1097 , 0.10913, 0.10895, 0.10876, 0.1084 , 0.1076 , 0.1074 ,\n",
       "            0.10724, 0.10706, 0.1067 , 0.1052 , 0.1043 , 0.10376, 0.1036 ,\n",
       "            0.103  , 0.10034, 0.0993 , 0.0991 , 0.0972 , 0.09686, 0.0967 ,\n",
       "            0.0959 , 0.0957 , 0.0955 , 0.0945 , 0.09436, 0.0933 , 0.09174,\n",
       "            0.0901 , 0.0893 , 0.0882 , 0.0874 , 0.0866 , 0.0863 , 0.0856 ,\n",
       "            0.0848 , 0.08435, 0.0804 , 0.0799 , 0.07935, 0.0788 , 0.07794,\n",
       "            0.0772 , 0.07666, 0.07654, 0.07587, 0.0741 , 0.074  , 0.07263,\n",
       "            0.0721 , 0.0715 , 0.0712 , 0.06995, 0.0688 , 0.0678 , 0.0672 ,\n",
       "            0.0655 , 0.0642 , 0.0637 , 0.0627 , 0.0611 , 0.06064, 0.05823,\n",
       "            0.05737, 0.05194, 0.047  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.2421875, 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.6328125, 0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.6796875, 0.6796875,\n",
       "            0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.6953125, 0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.71875  ,\n",
       "            0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.765625 , 0.765625 , 0.7734375, 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8046875, 0.8046875, 0.8046875,\n",
       "            0.8125   , 0.8125   , 0.8203125, 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.828125 , 0.8359375, 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.8671875, 0.875    , 0.875    , 0.8828125,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.921875 , 0.921875 , 0.921875 , 0.921875 ,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9375   , 0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.984375 , 0.9921875, 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.01639344, 0.02459016, 0.02459016, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.21311475,\n",
       "            0.22131148, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.3852459 , 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.59016395, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.6147541 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.358  , 0.357  , 0.3567 , 0.356  , 0.3552 , 0.3496 ,\n",
       "            0.3494 , 0.3481 , 0.348  , 0.3455 , 0.3452 , 0.3433 , 0.3418 ,\n",
       "            0.3416 , 0.3396 , 0.3364 , 0.3354 , 0.335  , 0.3345 , 0.3323 ,\n",
       "            0.3298 , 0.3293 , 0.3284 , 0.3245 , 0.3223 , 0.322  , 0.3218 ,\n",
       "            0.3213 , 0.3147 , 0.3103 , 0.3086 , 0.3083 , 0.308  , 0.306  ,\n",
       "            0.3044 , 0.3037 , 0.3005 , 0.296  , 0.2874 , 0.2852 , 0.2847 ,\n",
       "            0.2842 , 0.2803 , 0.279  , 0.272  , 0.2664 , 0.2646 , 0.264  ,\n",
       "            0.2578 , 0.2537 , 0.251  , 0.249  , 0.2448 , 0.2411 , 0.2407 ,\n",
       "            0.2328 , 0.2285 , 0.2269 , 0.22   , 0.214  , 0.2115 , 0.2089 ,\n",
       "            0.2042 , 0.2028 , 0.196  , 0.1952 , 0.1942 , 0.193  , 0.1923 ,\n",
       "            0.1873 , 0.1863 , 0.1848 , 0.1837 , 0.183  , 0.1803 , 0.1791 ,\n",
       "            0.1775 , 0.1765 , 0.1758 , 0.1709 , 0.1708 , 0.1688 , 0.1647 ,\n",
       "            0.1635 , 0.1622 , 0.1571 , 0.1547 , 0.1534 , 0.1531 , 0.1521 ,\n",
       "            0.1489 , 0.1481 , 0.1478 , 0.1459 , 0.145  , 0.1449 , 0.1443 ,\n",
       "            0.1438 , 0.1436 , 0.1427 , 0.1406 , 0.1401 , 0.1398 , 0.1395 ,\n",
       "            0.1385 , 0.1364 , 0.1359 , 0.1342 , 0.1335 , 0.1332 , 0.133  ,\n",
       "            0.1329 , 0.1301 , 0.1289 , 0.1282 , 0.1277 , 0.1267 , 0.1265 ,\n",
       "            0.1261 , 0.1255 , 0.12476, 0.1238 , 0.1216 , 0.12103, 0.12067,\n",
       "            0.12   , 0.1196 , 0.1186 , 0.1184 , 0.11676, 0.11536, 0.115  ,\n",
       "            0.11456, 0.1142 , 0.11395, 0.1138 , 0.113  , 0.1126 , 0.11127,\n",
       "            0.111  , 0.1101 , 0.10913, 0.1084 , 0.1082 , 0.1078 , 0.1074 ,\n",
       "            0.1069 , 0.1056 , 0.10486, 0.1047 , 0.1043 , 0.1032 , 0.103  ,\n",
       "            0.10266, 0.10156, 0.1011 , 0.1009 , 0.10034, 0.10016, 0.0997 ,\n",
       "            0.09894, 0.0977 , 0.09753, 0.09686, 0.09656, 0.0964 , 0.0962 ,\n",
       "            0.09503, 0.09485, 0.094  , 0.093  , 0.0927 , 0.09204, 0.0901 ,\n",
       "            0.0899 , 0.0891 , 0.0887 , 0.0871 , 0.0868 , 0.0859 , 0.0854 ,\n",
       "            0.0848 , 0.08466, 0.08405, 0.0836 , 0.08154, 0.07965, 0.07935,\n",
       "            0.0778 , 0.0774 , 0.0763 , 0.0761 , 0.076  , 0.075  , 0.07477,\n",
       "            0.0729 , 0.0708 , 0.07056, 0.0702 , 0.0694 , 0.06903, 0.0683 ,\n",
       "            0.0672 , 0.0671 , 0.0667 , 0.0644 , 0.0637 , 0.0635 , 0.06335,\n",
       "            0.06323, 0.06256, 0.0621 , 0.06143, 0.05988, 0.0591 , 0.05865,\n",
       "            0.05728, 0.05646, 0.0555 , 0.0544 , 0.0535 , 0.053  , 0.0504 ,\n",
       "            0.0494 , 0.04468, 0.0401 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6953125, 0.6953125,\n",
       "            0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.71875  , 0.7265625, 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.734375 , 0.734375 , 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.7734375,\n",
       "            0.7734375, 0.7734375, 0.7890625, 0.796875 , 0.796875 , 0.796875 ,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.8203125, 0.8203125, 0.828125 , 0.828125 ,\n",
       "            0.8359375, 0.8359375, 0.84375  , 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.8515625, 0.859375 , 0.859375 , 0.8671875, 0.8671875,\n",
       "            0.875    , 0.875    , 0.8828125, 0.890625 , 0.890625 , 0.8984375,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.921875 , 0.921875 ,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625,\n",
       "            0.984375 , 0.9921875, 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.01639344, 0.02459016, 0.03278688, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.04918033, 0.05737705, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.21311475,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.2704918 , 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.3852459 , 0.39344263, 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.704918  , 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3452 , 0.3442 , 0.344  , 0.3435 , 0.3428 , 0.3384 ,\n",
       "            0.3381 , 0.3364 , 0.3362 , 0.3342 , 0.3333 , 0.3323 , 0.3306 ,\n",
       "            0.3303 , 0.3286 , 0.3252 , 0.3247 , 0.3242 , 0.324  , 0.3235 ,\n",
       "            0.3218 , 0.321  , 0.319  , 0.318  , 0.3167 , 0.313  , 0.3118 ,\n",
       "            0.3115 , 0.3113 , 0.3103 , 0.31   , 0.3088 , 0.3042 , 0.3    ,\n",
       "            0.2986 , 0.2979 , 0.2957 , 0.2947 , 0.2942 , 0.2927 , 0.2903 ,\n",
       "            0.286  , 0.278  , 0.2751 , 0.275  , 0.2722 , 0.2695 , 0.268  ,\n",
       "            0.263  , 0.2556 , 0.2551 , 0.2524 , 0.2489 , 0.2449 , 0.2422 ,\n",
       "            0.2395 , 0.2362 , 0.2334 , 0.2313 , 0.2256 , 0.2211 , 0.2203 ,\n",
       "            0.2119 , 0.208  , 0.2043 , 0.2031 , 0.1974 , 0.1965 , 0.1877 ,\n",
       "            0.187  , 0.1866 , 0.1859 , 0.185  , 0.1827 , 0.1807 , 0.179  ,\n",
       "            0.1759 , 0.1757 , 0.1749 , 0.1733 , 0.1725 , 0.1719 , 0.1699 ,\n",
       "            0.1663 , 0.1659 , 0.1611 , 0.161  , 0.1597 , 0.159  , 0.1581 ,\n",
       "            0.1512 , 0.1511 , 0.149  , 0.1476 , 0.1475 , 0.1456 , 0.1449 ,\n",
       "            0.1438 , 0.1428 , 0.1411 , 0.1409 , 0.1398 , 0.1378 , 0.1361 ,\n",
       "            0.1355 , 0.1353 , 0.1333 , 0.133  , 0.1327 , 0.1321 , 0.1305 ,\n",
       "            0.1301 , 0.1299 , 0.1279 , 0.1278 , 0.1263 , 0.1241 , 0.124  ,\n",
       "            0.1238 , 0.1229 , 0.12286, 0.1222 , 0.122  , 0.1216 , 0.1193 ,\n",
       "            0.1192 , 0.1186 , 0.1174 , 0.11694, 0.1166 , 0.11597, 0.11554,\n",
       "            0.11456, 0.11395, 0.1138 , 0.1122 , 0.1118 , 0.1101 , 0.1099 ,\n",
       "            0.10913, 0.10876, 0.1078 , 0.1076 , 0.1074 , 0.1063 , 0.10504,\n",
       "            0.1045 , 0.10394, 0.10376, 0.1032 , 0.10284, 0.10266, 0.1025 ,\n",
       "            0.10175, 0.0998 , 0.0997 , 0.0991 , 0.09894, 0.09875, 0.0979 ,\n",
       "            0.0974 , 0.0972 , 0.0964 , 0.096  , 0.0957 , 0.09534, 0.0945 ,\n",
       "            0.0942 , 0.0932 , 0.093  , 0.09235, 0.09204, 0.09174, 0.09155,\n",
       "            0.0914 , 0.09125, 0.0895 , 0.0891 , 0.089  , 0.0882 , 0.088  ,\n",
       "            0.0876 , 0.0873 , 0.0856 , 0.0848 , 0.083  , 0.0823 , 0.08124,\n",
       "            0.08105, 0.0801 , 0.0799 , 0.0798 , 0.07935, 0.0775 , 0.07544,\n",
       "            0.075  , 0.0734 , 0.0733 , 0.0724 , 0.07227, 0.0717 , 0.07104,\n",
       "            0.0708 , 0.06866, 0.06744, 0.0667 , 0.06635, 0.06464, 0.0641 ,\n",
       "            0.06323, 0.0631 , 0.0629 , 0.0603 , 0.0601 , 0.05975, 0.05954,\n",
       "            0.05933, 0.05823, 0.05814, 0.05634, 0.05624, 0.0542 , 0.0537 ,\n",
       "            0.05234, 0.051  , 0.05072, 0.05023, 0.04733, 0.04602, 0.04193,\n",
       "            0.03738], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.625    , 0.625    , 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.7265625, 0.734375 , 0.734375 , 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.7578125, 0.765625 , 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.7734375, 0.7734375, 0.78125  , 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.796875 , 0.796875 , 0.8046875, 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.8203125, 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.828125 , 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.8671875, 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.921875 ,\n",
       "            0.921875 , 0.921875 , 0.9296875, 0.9296875, 0.9296875, 0.9296875,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.9453125, 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.984375 , 0.9921875, 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.01639344, 0.02459016, 0.03278688, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.04918033, 0.05737705, 0.06557377, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.21311475, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.2704918 ,\n",
       "            0.2704918 , 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.30327868, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.33606556,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36065573,\n",
       "            0.36885247, 0.36885247, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.44262296, 0.45081967, 0.46721312, 0.46721312,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.5       , 0.5       ,\n",
       "            0.5163934 , 0.52459013, 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.60655737, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.647541  , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.72131145, 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.334  , 0.3333 , 0.3325 , 0.332  , 0.3315 , 0.3303 ,\n",
       "            0.3271 , 0.327  , 0.3254 , 0.3247 , 0.3237 , 0.3218 , 0.3213 ,\n",
       "            0.3198 , 0.3196 , 0.3193 , 0.3179 , 0.315  , 0.3145 , 0.3137 ,\n",
       "            0.313  , 0.3115 , 0.3103 , 0.3086 , 0.308  , 0.304  , 0.3022 ,\n",
       "            0.302  , 0.3015 , 0.3013 , 0.3003 , 0.2996 , 0.296  , 0.2937 ,\n",
       "            0.2908 , 0.2896 , 0.2888 , 0.2876 , 0.2864 , 0.2856 , 0.2854 ,\n",
       "            0.283  , 0.28   , 0.2773 , 0.2693 , 0.2668 , 0.2666 , 0.261  ,\n",
       "            0.2588 , 0.2537 , 0.248  , 0.2437 , 0.2426 , 0.2415 , 0.2375 ,\n",
       "            0.2335 , 0.2299 , 0.229  , 0.2268 , 0.2235 , 0.2184 , 0.2147 ,\n",
       "            0.2053 , 0.2028 , 0.1985 , 0.1979 , 0.1925 , 0.1904 , 0.1833 ,\n",
       "            0.1827 , 0.1799 , 0.179  , 0.1787 , 0.1783 , 0.1765 , 0.1752 ,\n",
       "            0.1724 , 0.1698 , 0.1692 , 0.1688 , 0.1666 , 0.1653 , 0.1627 ,\n",
       "            0.1621 , 0.1582 , 0.1566 , 0.1558 , 0.1556 , 0.1548 , 0.1484 ,\n",
       "            0.1472 , 0.1465 , 0.1436 , 0.1426 , 0.1418 , 0.1409 , 0.1405 ,\n",
       "            0.1401 , 0.1388 , 0.1362 , 0.135  , 0.133  , 0.1327 , 0.1323 ,\n",
       "            0.131  , 0.1306 , 0.1287 , 0.1285 , 0.1279 , 0.1278 , 0.1277 ,\n",
       "            0.1259 , 0.12445, 0.1238 , 0.122  , 0.12177, 0.1214 , 0.1213 ,\n",
       "            0.12024, 0.119  , 0.1184 , 0.118  , 0.1178 , 0.11755, 0.11694,\n",
       "            0.115  , 0.11456, 0.11395, 0.1136 , 0.11316, 0.11084, 0.1105 ,\n",
       "            0.1103 , 0.10876, 0.10724, 0.10706, 0.1065 , 0.1054 , 0.1045 ,\n",
       "            0.1036 , 0.1023 , 0.10175, 0.10126, 0.1007 , 0.10016, 0.1    ,\n",
       "            0.0993 , 0.09875, 0.0981 , 0.0972 , 0.09656, 0.0964 , 0.0955 ,\n",
       "            0.09534, 0.09503, 0.0937 , 0.0935 , 0.0933 , 0.0932 , 0.09283,\n",
       "            0.09235, 0.09174, 0.0914 , 0.0906 , 0.0904 , 0.0901 , 0.0895 ,\n",
       "            0.0893 , 0.0891 , 0.0888 , 0.0885 , 0.0877 , 0.0866 , 0.0863 ,\n",
       "            0.086  , 0.0851 , 0.0845 , 0.08435, 0.08386, 0.0831 , 0.0818 ,\n",
       "            0.0806 , 0.0785 , 0.07837, 0.07825, 0.0774 , 0.0772 , 0.0771 ,\n",
       "            0.07587, 0.0752 , 0.0732 , 0.0724 , 0.07227, 0.07104, 0.0707 ,\n",
       "            0.0702 , 0.06903, 0.0689 , 0.06866, 0.0655 , 0.0649 , 0.06384,\n",
       "            0.0629 , 0.0621 , 0.06165, 0.0612 , 0.06097, 0.05835, 0.05823,\n",
       "            0.05792, 0.0578 , 0.0576 , 0.0572 , 0.05655, 0.05573, 0.0549 ,\n",
       "            0.0544 , 0.0527 , 0.05243, 0.0506 , 0.0494 , 0.04913, 0.04895,\n",
       "            0.0456 , 0.044  , 0.04053, 0.03595], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.65625  , 0.65625  ,\n",
       "            0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6953125, 0.6953125, 0.6953125,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.7109375, 0.71875  ,\n",
       "            0.71875  , 0.71875  , 0.7265625, 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.75     ,\n",
       "            0.75     , 0.75     , 0.7578125, 0.7578125, 0.765625 , 0.765625 ,\n",
       "            0.765625 , 0.765625 , 0.765625 , 0.7734375, 0.78125  , 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8125   ,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.828125 , 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.8828125, 0.890625 , 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.90625  , 0.9140625, 0.921875 , 0.921875 ,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.9921875,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.01639344, 0.02459016,\n",
       "            0.03278688, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.07377049, 0.08196721, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.25409836, 0.26229507, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.31967214, 0.31967214, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36065573, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.58196723, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.7295082 , 0.7295082 , 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90983605, 0.91803277, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.325  , 0.3245 , 0.3225 , 0.322  , 0.3215 , 0.321  ,\n",
       "            0.3208 , 0.32   , 0.3186 , 0.318  , 0.3176 , 0.3164 , 0.315  ,\n",
       "            0.3145 , 0.3142 , 0.313  , 0.3103 , 0.31   , 0.3096 , 0.3086 ,\n",
       "            0.3083 , 0.3076 , 0.3062 , 0.3052 , 0.305  , 0.3003 , 0.2988 ,\n",
       "            0.2986 , 0.2983 , 0.2969 , 0.2954 , 0.291  , 0.2898 , 0.2896 ,\n",
       "            0.2874 , 0.2861 , 0.286  , 0.2852 , 0.28   , 0.2783 , 0.2773 ,\n",
       "            0.2703 , 0.2678 , 0.2676 , 0.2612 , 0.2563 , 0.2544 , 0.2522 ,\n",
       "            0.2502 , 0.2438 , 0.241  , 0.2401 , 0.2372 , 0.2347 , 0.2323 ,\n",
       "            0.2314 , 0.2297 , 0.2252 , 0.2222 , 0.2203 , 0.2194 , 0.209  ,\n",
       "            0.2043 , 0.2037 , 0.199  , 0.1953 , 0.1906 , 0.1901 , 0.1865 ,\n",
       "            0.1836 , 0.1829 , 0.181  , 0.1804 , 0.1798 , 0.1796 , 0.178  ,\n",
       "            0.1771 , 0.174  , 0.1724 , 0.172  , 0.1708 , 0.1704 , 0.1697 ,\n",
       "            0.1669 , 0.165  , 0.1637 , 0.1631 , 0.1599 , 0.1569 , 0.1556 ,\n",
       "            0.1537 , 0.1505 , 0.1503 , 0.1495 , 0.1489 , 0.1481 , 0.1478 ,\n",
       "            0.1434 , 0.1427 , 0.1409 , 0.1401 , 0.1396 , 0.1377 , 0.1365 ,\n",
       "            0.1364 , 0.1359 , 0.1344 , 0.1338 , 0.133  , 0.1322 , 0.1315 ,\n",
       "            0.131  , 0.1305 , 0.1302 , 0.1299 , 0.1295 , 0.127  , 0.1261 ,\n",
       "            0.1259 , 0.1249 , 0.1243 , 0.1235 , 0.12335, 0.1232 , 0.12317,\n",
       "            0.1219 , 0.1214 , 0.12036, 0.11993, 0.1195 , 0.1178 , 0.1174 ,\n",
       "            0.1158 , 0.11554, 0.11456, 0.1138 , 0.11316, 0.1124 , 0.1122 ,\n",
       "            0.11084, 0.11066, 0.1103 , 0.1099 , 0.1093 , 0.10876, 0.1078 ,\n",
       "            0.10724, 0.1067 , 0.10614, 0.10596, 0.10504, 0.1045 , 0.1043 ,\n",
       "            0.10394, 0.1036 , 0.1034 , 0.1019 , 0.10175, 0.10156, 0.1007 ,\n",
       "            0.1    , 0.0991 , 0.09894, 0.09827, 0.0977 , 0.0974 , 0.0972 ,\n",
       "            0.09686, 0.09656, 0.0962 , 0.0957 , 0.09534, 0.09467, 0.0939 ,\n",
       "            0.0922 , 0.0914 , 0.09125, 0.0904 , 0.0903 , 0.0896 , 0.0893 ,\n",
       "            0.0891 , 0.0882 , 0.0876 , 0.0871 , 0.08374, 0.0828 , 0.0825 ,\n",
       "            0.0824 , 0.0818 , 0.08136, 0.08124, 0.0806 , 0.0786 , 0.07837,\n",
       "            0.07697, 0.07654, 0.0761 , 0.07574, 0.0745 , 0.074  , 0.07385,\n",
       "            0.07306, 0.0725 , 0.07135, 0.07104, 0.0702 , 0.06744, 0.06635,\n",
       "            0.066  , 0.06525, 0.0651 , 0.0649 , 0.06244, 0.06152, 0.06097,\n",
       "            0.06052, 0.05878, 0.058  , 0.05792, 0.05737, 0.0547 , 0.0544 ,\n",
       "            0.0539 , 0.0526 , 0.04904, 0.04648, 0.04385, 0.03876],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0625   , 0.078125 , 0.0859375, 0.09375  , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.625    , 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6796875, 0.6796875, 0.6796875, 0.6875   ,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.7109375, 0.71875  , 0.71875  ,\n",
       "            0.71875  , 0.71875  , 0.71875  , 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.734375 , 0.7421875, 0.7421875, 0.75     ,\n",
       "            0.75     , 0.75     , 0.75     , 0.75     , 0.75     , 0.75     ,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.7734375,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.796875 ,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.84375  , 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.8671875, 0.8671875,\n",
       "            0.875    , 0.875    , 0.8828125, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.9609375, 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.9765625,\n",
       "            0.984375 , 0.9921875, 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.09836066,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.24590164, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.26229507, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.352459  ,\n",
       "            0.36065573, 0.36065573, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.45901638, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.52459013, 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.58196723, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6885246 , 0.6967213 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.73770493, 0.73770493, 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.78688526, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3176 , 0.3171 , 0.316  , 0.3152 , 0.3142 , 0.314  ,\n",
       "            0.3137 , 0.313  , 0.3127 , 0.3118 , 0.3108 , 0.31   , 0.3098 ,\n",
       "            0.308  , 0.3079 , 0.3076 , 0.3062 , 0.306  , 0.3054 , 0.3042 ,\n",
       "            0.304  , 0.3032 , 0.3005 , 0.2986 , 0.2969 , 0.2964 , 0.2942 ,\n",
       "            0.2922 , 0.2915 , 0.291  , 0.2908 , 0.2896 , 0.289  , 0.2869 ,\n",
       "            0.2861 , 0.2852 , 0.2805 , 0.2803 , 0.279  , 0.2742 , 0.2722 ,\n",
       "            0.2715 , 0.265  , 0.258  , 0.2576 , 0.2559 , 0.2494 , 0.2467 ,\n",
       "            0.246  , 0.2397 , 0.2395 , 0.239  , 0.2382 , 0.2355 , 0.231  ,\n",
       "            0.2306 , 0.2294 , 0.2292 , 0.2273 , 0.2189 , 0.2162 , 0.214  ,\n",
       "            0.2124 , 0.2085 , 0.2034 , 0.2013 , 0.201  , 0.1976 , 0.1942 ,\n",
       "            0.1941 , 0.1919 , 0.1897 , 0.1887 , 0.1858 , 0.1852 , 0.1842 ,\n",
       "            0.1827 , 0.1821 , 0.1815 , 0.1805 , 0.179  , 0.177  , 0.1755 ,\n",
       "            0.1752 , 0.1748 , 0.169  , 0.1683 , 0.1682 , 0.1636 , 0.1621 ,\n",
       "            0.1617 , 0.1608 , 0.1605 , 0.1604 , 0.1602 , 0.1569 , 0.154  ,\n",
       "            0.1519 , 0.1517 , 0.1514 , 0.1503 , 0.1493 , 0.1483 , 0.1442 ,\n",
       "            0.143  , 0.1427 , 0.1425 , 0.1423 , 0.142  , 0.1406 , 0.1405 ,\n",
       "            0.1399 , 0.139  , 0.138  , 0.1378 , 0.136  , 0.1356 , 0.1355 ,\n",
       "            0.1349 , 0.1344 , 0.134  , 0.1337 , 0.1332 , 0.1328 , 0.1324 ,\n",
       "            0.1322 , 0.1318 , 0.1289 , 0.1284 , 0.1276 , 0.1263 , 0.1255 ,\n",
       "            0.1252 , 0.1251 , 0.1243 , 0.1241 , 0.1236 , 0.12335, 0.12244,\n",
       "            0.12213, 0.12103, 0.1207 , 0.1193 , 0.1188 , 0.1186 , 0.11816,\n",
       "            0.11676, 0.1158 , 0.115  , 0.11475, 0.11456, 0.1144 , 0.1142 ,\n",
       "            0.1136 , 0.11316, 0.113  , 0.1118 , 0.11145, 0.11127, 0.111  ,\n",
       "            0.11066, 0.1103 , 0.1093 , 0.10876, 0.1082 , 0.1076 , 0.10706,\n",
       "            0.1067 , 0.1065 , 0.1052 , 0.10504, 0.1045 , 0.1041 , 0.1036 ,\n",
       "            0.1025 , 0.1023 , 0.1019 , 0.0997 , 0.09894, 0.0986 , 0.09827,\n",
       "            0.09686, 0.0964 , 0.0962 , 0.09534, 0.0932 , 0.0925 , 0.09106,\n",
       "            0.09076, 0.0903 , 0.0896 , 0.0895 , 0.0888 , 0.0885 , 0.0874 ,\n",
       "            0.0845 , 0.08405, 0.08386, 0.0824 , 0.0823 , 0.0821 , 0.08154,\n",
       "            0.0804 , 0.0802 , 0.0792 , 0.0789 , 0.0774 , 0.0741 , 0.07385,\n",
       "            0.0721 , 0.0716 , 0.0715 , 0.0703 , 0.06995, 0.0698 , 0.0695 ,\n",
       "            0.06915, 0.06696, 0.06683, 0.0666 , 0.065  , 0.06464, 0.0645 ,\n",
       "            0.06223, 0.06165, 0.06152, 0.05865, 0.0551 , 0.05127, 0.04968,\n",
       "            0.04376], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0546875, 0.0625   , 0.078125 , 0.0859375, 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.265625 , 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.3515625, 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.640625 ,\n",
       "            0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.6796875, 0.6796875, 0.6796875, 0.6875   , 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.7109375, 0.7109375,\n",
       "            0.7109375, 0.71875  , 0.71875  , 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.75     , 0.75     , 0.75     , 0.75     , 0.75     , 0.75     ,\n",
       "            0.75     , 0.7578125, 0.7578125, 0.765625 , 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.8046875, 0.8046875, 0.8125   ,\n",
       "            0.8125   , 0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.84375  , 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.875    , 0.8828125,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9375   ,\n",
       "            0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.9921875,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.01639344, 0.02459016,\n",
       "            0.03278688, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.26229507, 0.26229507, 0.26229507, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.33606556, 0.33606556, 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.36885247, 0.37704918, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.45901638, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6229508 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.6557377 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.72131145, 0.73770493, 0.73770493, 0.73770493,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3125 , 0.3123 , 0.3118 , 0.3115 , 0.311  , 0.3108 ,\n",
       "            0.3088 , 0.3086 , 0.3083 , 0.308  , 0.3079 , 0.3076 , 0.3074 ,\n",
       "            0.3066 , 0.306  , 0.3052 , 0.3044 , 0.304  , 0.3032 , 0.303  ,\n",
       "            0.3025 , 0.2998 , 0.2996 , 0.2993 , 0.297  , 0.2969 , 0.2957 ,\n",
       "            0.295  , 0.2937 , 0.292  , 0.2913 , 0.2876 , 0.2866 , 0.2861 ,\n",
       "            0.2852 , 0.2805 , 0.2798 , 0.279  , 0.273  , 0.265  , 0.263  ,\n",
       "            0.2625 , 0.2588 , 0.2556 , 0.2502 , 0.249  , 0.2429 , 0.2411 ,\n",
       "            0.241  , 0.2407 , 0.239  , 0.2386 , 0.2379 , 0.2374 , 0.2332 ,\n",
       "            0.2316 , 0.2274 , 0.2257 , 0.2249 , 0.2205 , 0.2157 , 0.2156 ,\n",
       "            0.2152 , 0.2118 , 0.2089 , 0.2084 , 0.2065 , 0.2043 , 0.2035 ,\n",
       "            0.1971 , 0.1965 , 0.1964 , 0.1956 , 0.1954 , 0.1953 , 0.1943 ,\n",
       "            0.1934 , 0.1924 , 0.1903 , 0.1901 , 0.1853 , 0.1846 , 0.1842 ,\n",
       "            0.1815 , 0.1783 , 0.1779 , 0.1772 , 0.1771 , 0.1766 , 0.1761 ,\n",
       "            0.1749 , 0.1709 , 0.169  , 0.1677 , 0.1674 , 0.1669 , 0.1643 ,\n",
       "            0.1604 , 0.1592 , 0.1588 , 0.1577 , 0.1572 , 0.1567 , 0.1566 ,\n",
       "            0.1565 , 0.1547 , 0.1544 , 0.1542 , 0.1534 , 0.1519 , 0.1509 ,\n",
       "            0.1506 , 0.15   , 0.1497 , 0.1494 , 0.149  , 0.1489 , 0.1488 ,\n",
       "            0.1482 , 0.1475 , 0.147  , 0.1467 , 0.1438 , 0.1437 , 0.1427 ,\n",
       "            0.1415 , 0.1409 , 0.1404 , 0.1401 , 0.1399 , 0.1394 , 0.1387 ,\n",
       "            0.138  , 0.137  , 0.1366 , 0.1356 , 0.135  , 0.1346 , 0.1343 ,\n",
       "            0.1338 , 0.1329 , 0.1328 , 0.1315 , 0.1312 , 0.1304 , 0.1301 ,\n",
       "            0.1298 , 0.1295 , 0.1293 , 0.1284 , 0.127  , 0.1265 , 0.1262 ,\n",
       "            0.1261 , 0.12476, 0.12445, 0.1239 , 0.12335, 0.12274, 0.12177,\n",
       "            0.12146, 0.12103, 0.12   , 0.1195 , 0.119  , 0.1186 , 0.1184 ,\n",
       "            0.11597, 0.11456, 0.1138 , 0.1128 , 0.112  , 0.11163, 0.11145,\n",
       "            0.1097 , 0.1095 , 0.10913, 0.10706, 0.1069 , 0.10614, 0.1058 ,\n",
       "            0.1043 , 0.103  , 0.10266, 0.1023 , 0.10175, 0.1007 , 0.0979 ,\n",
       "            0.0972 , 0.0955 , 0.09503, 0.09467, 0.0939 , 0.0933 , 0.0927 ,\n",
       "            0.09204, 0.09155, 0.0901 , 0.086  , 0.0848 , 0.08344, 0.0825 ,\n",
       "            0.0824 , 0.0823 , 0.082  , 0.0818 , 0.08167, 0.08136, 0.08124,\n",
       "            0.07947, 0.07684, 0.07666, 0.07654, 0.0749 , 0.0742 , 0.074  ,\n",
       "            0.07355, 0.0724 , 0.06854, 0.06464, 0.0592 , 0.059  , 0.05203],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.09375  , 0.1015625, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.171875 , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.703125 , 0.703125 , 0.703125 , 0.703125 , 0.7109375,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.71875  , 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.7421875, 0.75     , 0.75     , 0.75     ,\n",
       "            0.75     , 0.75     , 0.75     , 0.75     , 0.75     , 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.765625 , 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8046875, 0.8125   ,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.8359375, 0.84375  ,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.8671875, 0.8671875,\n",
       "            0.8828125, 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.90625  ,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.22131148, 0.22950819,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.26229507, 0.26229507,\n",
       "            0.2704918 , 0.2704918 , 0.27868852, 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.39344263, 0.39344263, 0.40163934, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.47540984, 0.47540984, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.57377046, 0.59016395,\n",
       "            0.59836066, 0.6147541 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.74590164, 0.74590164, 0.74590164,\n",
       "            0.74590164, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3157 , 0.3147 , 0.3145 , 0.3137 , 0.3132 , 0.313  ,\n",
       "            0.3127 , 0.3123 , 0.312  , 0.3118 , 0.311  , 0.3108 , 0.3093 ,\n",
       "            0.309  , 0.3086 , 0.3079 , 0.3074 , 0.3071 , 0.307  , 0.3066 ,\n",
       "            0.3064 , 0.3062 , 0.3052 , 0.3042 , 0.304  , 0.3035 , 0.302  ,\n",
       "            0.3013 , 0.3003 , 0.2996 , 0.298  , 0.2957 , 0.2947 , 0.2925 ,\n",
       "            0.2917 , 0.2888 , 0.2869 , 0.2861 , 0.2825 , 0.279  , 0.2742 ,\n",
       "            0.2732 , 0.273  , 0.27   , 0.267  , 0.2644 , 0.259  , 0.2556 ,\n",
       "            0.2554 , 0.255  , 0.254  , 0.2505 , 0.2456 , 0.244  , 0.2437 ,\n",
       "            0.243  , 0.2429 , 0.2426 , 0.239  , 0.2356 , 0.2355 , 0.2327 ,\n",
       "            0.2325 , 0.2299 , 0.2281 , 0.2278 , 0.2257 , 0.2252 , 0.2181 ,\n",
       "            0.2167 , 0.2157 , 0.2156 , 0.2152 , 0.2142 , 0.2139 , 0.2118 ,\n",
       "            0.2109 , 0.2095 , 0.2073 , 0.2068 , 0.2065 , 0.2009 , 0.2006 ,\n",
       "            0.1995 , 0.1993 , 0.199  , 0.1984 , 0.1971 , 0.1946 , 0.1898 ,\n",
       "            0.1897 , 0.1896 , 0.189  , 0.1877 , 0.1873 , 0.1858 , 0.1816 ,\n",
       "            0.181  , 0.1798 , 0.178  , 0.1771 , 0.1764 , 0.1755 , 0.1753 ,\n",
       "            0.1741 , 0.1735 , 0.1726 , 0.1724 , 0.1711 , 0.171  , 0.1705 ,\n",
       "            0.1703 , 0.1685 , 0.1683 , 0.1676 , 0.1669 , 0.1659 , 0.1656 ,\n",
       "            0.1654 , 0.1641 , 0.1638 , 0.163  , 0.1622 , 0.162  , 0.1615 ,\n",
       "            0.1611 , 0.161  , 0.1604 , 0.1603 , 0.1582 , 0.1569 , 0.1559 ,\n",
       "            0.1556 , 0.1552 , 0.1548 , 0.1547 , 0.1545 , 0.1539 , 0.1514 ,\n",
       "            0.1505 , 0.1503 , 0.15   , 0.1498 , 0.1494 , 0.149  , 0.1487 ,\n",
       "            0.1484 , 0.1472 , 0.1469 , 0.1464 , 0.1442 , 0.143  , 0.1426 ,\n",
       "            0.1418 , 0.1417 , 0.1409 , 0.1407 , 0.1406 , 0.1403 , 0.1392 ,\n",
       "            0.1381 , 0.1376 , 0.1375 , 0.1371 , 0.136  , 0.1327 , 0.1317 ,\n",
       "            0.1315 , 0.1312 , 0.1311 , 0.1301 , 0.1295 , 0.1289 , 0.1263 ,\n",
       "            0.12463, 0.1235 , 0.1232 , 0.1223 , 0.12177, 0.1217 , 0.1207 ,\n",
       "            0.1197 , 0.1193 , 0.1192 , 0.1184 , 0.11816, 0.11633, 0.1158 ,\n",
       "            0.11536, 0.1142 , 0.11395, 0.112  , 0.11145, 0.111  , 0.1095 ,\n",
       "            0.1076 , 0.1063 , 0.10596, 0.1043 , 0.1021 , 0.1    , 0.09894,\n",
       "            0.09875, 0.09845, 0.0981 , 0.0972 , 0.09705, 0.0967 , 0.09656,\n",
       "            0.0957 , 0.09467, 0.09235, 0.0904 , 0.0903 , 0.0898 , 0.0895 ,\n",
       "            0.0887 , 0.0869 , 0.0866 , 0.08154, 0.0775 , 0.0715 , 0.06995,\n",
       "            0.06305], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.0859375, 0.09375  , 0.1015625, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2265625, 0.234375 , 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.2890625, 0.3046875, 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.703125 ,\n",
       "            0.703125 , 0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.75     ,\n",
       "            0.75     , 0.75     , 0.75     , 0.7578125, 0.765625 , 0.765625 ,\n",
       "            0.765625 , 0.765625 , 0.765625 , 0.7734375, 0.78125  , 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.796875 , 0.796875 , 0.8046875, 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.8359375,\n",
       "            0.8359375, 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.8671875, 0.8671875, 0.8671875, 0.875    , 0.875    ,\n",
       "            0.8828125, 0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625, 0.9765625,\n",
       "            0.984375 , 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.02459016, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.21311475, 0.21311475, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.27868852, 0.27868852, 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.45901638,\n",
       "            0.47540984, 0.47540984, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.60655737, 0.6147541 , 0.6147541 , 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3237 , 0.323  , 0.3228 , 0.3225 , 0.3223 , 0.3218 ,\n",
       "            0.321  , 0.3208 , 0.3198 , 0.3193 , 0.3188 , 0.3184 , 0.318  ,\n",
       "            0.3179 , 0.3176 , 0.3174 , 0.3171 , 0.317  , 0.3167 , 0.3154 ,\n",
       "            0.3152 , 0.3147 , 0.3145 , 0.3125 , 0.31   , 0.3096 , 0.3093 ,\n",
       "            0.3086 , 0.3083 , 0.3071 , 0.3047 , 0.3037 , 0.3008 , 0.2988 ,\n",
       "            0.2986 , 0.2976 , 0.2932 , 0.2903 , 0.29   , 0.2898 , 0.2896 ,\n",
       "            0.2874 , 0.2866 , 0.2854 , 0.283  , 0.2783 , 0.2769 , 0.276  ,\n",
       "            0.2751 , 0.271  , 0.2688 , 0.2664 , 0.266  , 0.2637 , 0.263  ,\n",
       "            0.2627 , 0.2605 , 0.258  , 0.2563 , 0.256  , 0.2559 , 0.255  ,\n",
       "            0.2544 , 0.2542 , 0.2524 , 0.2467 , 0.2466 , 0.2456 , 0.2437 ,\n",
       "            0.2429 , 0.2421 , 0.241  , 0.2407 , 0.2394 , 0.239  , 0.2383 ,\n",
       "            0.2363 , 0.2325 , 0.2323 , 0.2316 , 0.2297 , 0.2292 , 0.2286 ,\n",
       "            0.226  , 0.2255 , 0.2244 , 0.2235 , 0.2216 , 0.2205 , 0.22   ,\n",
       "            0.2191 , 0.2166 , 0.2161 , 0.2157 , 0.2153 , 0.2152 , 0.2128 ,\n",
       "            0.2118 , 0.2115 , 0.207  , 0.2059 , 0.2056 , 0.205  , 0.2045 ,\n",
       "            0.202  , 0.2018 , 0.2017 , 0.2015 , 0.2007 , 0.1996 , 0.1978 ,\n",
       "            0.1968 , 0.1967 , 0.196  , 0.1959 , 0.1958 , 0.1946 , 0.1925 ,\n",
       "            0.1924 , 0.1923 , 0.1921 , 0.1906 , 0.1896 , 0.1893 , 0.1891 ,\n",
       "            0.189  , 0.188  , 0.1877 , 0.1873 , 0.1858 , 0.1852 , 0.1849 ,\n",
       "            0.1833 , 0.1831 , 0.1827 , 0.1823 , 0.1821 , 0.182  , 0.1799 ,\n",
       "            0.1796 , 0.1792 , 0.1791 , 0.1783 , 0.178  , 0.1779 , 0.1774 ,\n",
       "            0.1768 , 0.1754 , 0.1748 , 0.174  , 0.1735 , 0.1718 , 0.1715 ,\n",
       "            0.1711 , 0.1707 , 0.1705 , 0.1704 , 0.1697 , 0.1693 , 0.1686 ,\n",
       "            0.1682 , 0.166  , 0.1643 , 0.1641 , 0.164  , 0.163  , 0.1626 ,\n",
       "            0.1624 , 0.1619 , 0.1615 , 0.1592 , 0.159  , 0.1582 , 0.156  ,\n",
       "            0.1554 , 0.1548 , 0.1542 , 0.1536 , 0.1514 , 0.1508 , 0.149  ,\n",
       "            0.1471 , 0.1467 , 0.1464 , 0.1455 , 0.1445 , 0.1444 , 0.1437 ,\n",
       "            0.1432 , 0.1431 , 0.1421 , 0.1418 , 0.1416 , 0.1392 , 0.139  ,\n",
       "            0.1388 , 0.138  , 0.1371 , 0.1361 , 0.1354 , 0.1335 , 0.1334 ,\n",
       "            0.1293 , 0.128  , 0.1265 , 0.126  , 0.1252 , 0.1242 , 0.12335,\n",
       "            0.12286, 0.1226 , 0.1204 , 0.12036, 0.1197 , 0.1193 , 0.118  ,\n",
       "            0.11615, 0.11597, 0.115  , 0.1144 , 0.1142 , 0.1103 , 0.1093 ,\n",
       "            0.10876, 0.1086 , 0.1054 , 0.10126, 0.09705, 0.0904 , 0.086  ,\n",
       "            0.0799 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.125    , 0.1328125, 0.140625 , 0.15625  ,\n",
       "            0.1640625, 0.1875   , 0.1953125, 0.203125 , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.40625  , 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.6171875, 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.71875  , 0.71875  , 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.75     , 0.765625 , 0.7734375, 0.78125  , 0.78125  ,\n",
       "            0.78125  , 0.78125  , 0.78125  , 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.828125 , 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.890625 , 0.8984375, 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.9296875, 0.9296875, 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625, 0.9765625,\n",
       "            0.984375 , 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.03278688, 0.04098361, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.05737705, 0.06557377, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.21311475, 0.22131148, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.2704918 ,\n",
       "            0.2704918 , 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.52459013, 0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.6229508 , 0.6229508 , 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.76229507, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.339  , 0.3386 , 0.3384 , 0.3357 , 0.3342 , 0.3337 ,\n",
       "            0.3335 , 0.333  , 0.3328 , 0.3325 , 0.332  , 0.3315 , 0.3298 ,\n",
       "            0.3296 , 0.3289 , 0.3284 , 0.3281 , 0.328  , 0.327  , 0.326  ,\n",
       "            0.3257 , 0.3252 , 0.3242 , 0.3237 , 0.3235 , 0.3228 , 0.3223 ,\n",
       "            0.3218 , 0.32   , 0.3196 , 0.3193 , 0.3186 , 0.3176 , 0.317  ,\n",
       "            0.3142 , 0.314  , 0.3132 , 0.3118 , 0.31   , 0.3088 , 0.3079 ,\n",
       "            0.3066 , 0.3035 , 0.3032 , 0.303  , 0.2993 , 0.298  , 0.2969 ,\n",
       "            0.2961 , 0.2954 , 0.2927 , 0.2922 , 0.2917 , 0.2913 , 0.291  ,\n",
       "            0.2908 , 0.2903 , 0.289  , 0.2878 , 0.2876 , 0.2861 , 0.286  ,\n",
       "            0.2837 , 0.2812 , 0.2795 , 0.2778 , 0.2764 , 0.2732 , 0.273  ,\n",
       "            0.2725 , 0.2708 , 0.27   , 0.2695 , 0.2693 , 0.268  , 0.2678 ,\n",
       "            0.2676 , 0.2666 , 0.2659 , 0.2644 , 0.263  , 0.2622 , 0.2612 ,\n",
       "            0.258  , 0.2554 , 0.2542 , 0.253  , 0.252  , 0.2512 , 0.2505 ,\n",
       "            0.2487 , 0.2485 , 0.248  , 0.2478 , 0.2471 , 0.2467 , 0.2463 ,\n",
       "            0.2462 , 0.2458 , 0.2452 , 0.243  , 0.2421 , 0.241  , 0.2401 ,\n",
       "            0.2382 , 0.237  , 0.2362 , 0.2356 , 0.2355 , 0.2346 , 0.2316 ,\n",
       "            0.2311 , 0.2306 , 0.2301 , 0.229  , 0.2285 , 0.2278 , 0.2273 ,\n",
       "            0.2269 , 0.2266 , 0.2256 , 0.2239 , 0.2235 , 0.2227 , 0.2225 ,\n",
       "            0.2224 , 0.2217 , 0.2216 , 0.2213 , 0.2211 , 0.2207 , 0.2205 ,\n",
       "            0.2175 , 0.2168 , 0.2156 , 0.2153 , 0.215  , 0.2147 , 0.2144 ,\n",
       "            0.214  , 0.2124 , 0.211  , 0.2101 , 0.2091 , 0.209  , 0.2086 ,\n",
       "            0.2081 , 0.2079 , 0.207  , 0.2065 , 0.2059 , 0.2048 , 0.2042 ,\n",
       "            0.2032 , 0.2026 , 0.2018 , 0.2002 , 0.199  , 0.1989 , 0.1967 ,\n",
       "            0.196  , 0.1959 , 0.195  , 0.1927 , 0.1923 , 0.1913 , 0.191  ,\n",
       "            0.1909 , 0.1901 , 0.1898 , 0.1879 , 0.1848 , 0.1844 , 0.1842 ,\n",
       "            0.1838 , 0.1794 , 0.1791 , 0.1776 , 0.1771 , 0.1763 , 0.1753 ,\n",
       "            0.1735 , 0.1718 , 0.1714 , 0.171  , 0.1705 , 0.1699 , 0.169  ,\n",
       "            0.1688 , 0.1678 , 0.1671 , 0.167  , 0.1665 , 0.1658 , 0.1656 ,\n",
       "            0.1599 , 0.1597 , 0.1589 , 0.1559 , 0.1552 , 0.1547 , 0.1542 ,\n",
       "            0.1526 , 0.1525 , 0.1503 , 0.1488 , 0.1471 , 0.1466 , 0.1455 ,\n",
       "            0.1453 , 0.1448 , 0.1444 , 0.1436 , 0.1406 , 0.1381 , 0.1359 ,\n",
       "            0.1345 , 0.1344 , 0.1316 , 0.1279 , 0.1255 , 0.12115, 0.1144 ,\n",
       "            0.10596, 0.10126], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2734375, 0.2890625, 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.3515625, 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.3671875, 0.375    , 0.3828125, 0.3828125,\n",
       "            0.390625 , 0.390625 , 0.390625 , 0.390625 , 0.3984375, 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.421875 , 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4296875, 0.4375   , 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.5      , 0.5      , 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.59375  , 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.625    , 0.625    , 0.6328125, 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.65625  , 0.6640625, 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6796875, 0.6796875, 0.6796875, 0.6796875, 0.6953125,\n",
       "            0.703125 , 0.703125 , 0.703125 , 0.703125 , 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.75     , 0.7578125, 0.765625 , 0.765625 , 0.765625 ,\n",
       "            0.765625 , 0.7734375, 0.7890625, 0.7890625, 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.875    , 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.9453125, 0.9453125, 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.02459016,\n",
       "            0.03278688, 0.04098361, 0.04098361, 0.04098361, 0.04918033,\n",
       "            0.04918033, 0.04918033, 0.05737705, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.08196721, 0.09016393, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.13934426, 0.14754099, 0.1557377 , 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.20491803,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.24590164, 0.24590164, 0.25409836, 0.25409836,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.3114754 , 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.39344263, 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.47540984, 0.47540984, 0.48360655, 0.4918033 , 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.52459013, 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6885246 , 0.6967213 , 0.6967213 , 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3591, 0.3582, 0.3574, 0.352 , 0.3516, 0.3513, 0.3508,\n",
       "            0.3506, 0.3503, 0.3477, 0.3472, 0.347 , 0.3464, 0.346 , 0.3457,\n",
       "            0.3442, 0.344 , 0.3438, 0.3425, 0.3413, 0.341 , 0.3406, 0.3394,\n",
       "            0.3389, 0.3386, 0.3374, 0.3372, 0.337 , 0.3367, 0.3354, 0.335 ,\n",
       "            0.3345, 0.334 , 0.333 , 0.3328, 0.332 , 0.33  , 0.3293, 0.329 ,\n",
       "            0.3289, 0.3286, 0.3284, 0.3276, 0.3274, 0.327 , 0.3267, 0.3264,\n",
       "            0.3262, 0.3257, 0.325 , 0.3247, 0.3245, 0.3225, 0.322 , 0.321 ,\n",
       "            0.3193, 0.3174, 0.3167, 0.3162, 0.3137, 0.3132, 0.313 , 0.312 ,\n",
       "            0.3118, 0.3113, 0.31  , 0.3093, 0.3088, 0.306 , 0.3044, 0.304 ,\n",
       "            0.3005, 0.3   , 0.2998, 0.298 , 0.2979, 0.2976, 0.2974, 0.2966,\n",
       "            0.2957, 0.2944, 0.293 , 0.2915, 0.2905, 0.2903, 0.289 , 0.288 ,\n",
       "            0.287 , 0.2869, 0.2854, 0.2852, 0.285 , 0.2847, 0.283 , 0.2817,\n",
       "            0.2815, 0.2812, 0.279 , 0.2788, 0.2786, 0.2778, 0.2776, 0.277 ,\n",
       "            0.2751, 0.2747, 0.2737, 0.273 , 0.2725, 0.2722, 0.2712, 0.271 ,\n",
       "            0.2703, 0.2688, 0.268 , 0.2678, 0.2676, 0.2666, 0.266 , 0.2656,\n",
       "            0.2651, 0.2637, 0.2634, 0.263 , 0.2617, 0.2612, 0.2605, 0.2603,\n",
       "            0.2578, 0.2563, 0.2559, 0.2556, 0.255 , 0.2546, 0.2544, 0.2542,\n",
       "            0.254 , 0.2537, 0.2532, 0.2527, 0.252 , 0.2502, 0.2496, 0.2494,\n",
       "            0.2489, 0.2452, 0.2445, 0.244 , 0.2437, 0.2434, 0.2413, 0.2411,\n",
       "            0.2406, 0.2379, 0.237 , 0.2366, 0.2363, 0.2347, 0.2328, 0.2299,\n",
       "            0.2289, 0.228 , 0.2274, 0.226 , 0.2227, 0.2225, 0.2222, 0.2216,\n",
       "            0.2211, 0.2203, 0.2186, 0.218 , 0.2162, 0.2156, 0.2147, 0.2135,\n",
       "            0.2123, 0.2091, 0.208 , 0.2079, 0.2076, 0.2068, 0.2064, 0.2047,\n",
       "            0.2043, 0.2028, 0.2004, 0.1998, 0.1965, 0.1948, 0.1941, 0.1927,\n",
       "            0.1919, 0.1893, 0.1886, 0.188 , 0.187 , 0.1857, 0.1848, 0.1844,\n",
       "            0.1835, 0.1824, 0.1816, 0.1783, 0.178 , 0.1735, 0.1731, 0.1725,\n",
       "            0.1698, 0.1686, 0.167 , 0.1624, 0.1584, 0.1583, 0.1543, 0.1477,\n",
       "            0.1339, 0.1315], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.2734375,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.2890625, 0.3046875, 0.3203125,\n",
       "            0.328125 , 0.34375  , 0.34375  , 0.3515625, 0.3515625, 0.3671875,\n",
       "            0.3828125, 0.390625 , 0.390625 , 0.390625 , 0.390625 , 0.390625 ,\n",
       "            0.390625 , 0.390625 , 0.3984375, 0.3984375, 0.3984375, 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.4765625, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5078125, 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.6484375, 0.65625  , 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.7421875, 0.75     , 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.8046875, 0.8046875, 0.8046875, 0.8046875,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.8359375, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.875    , 0.875    , 0.8828125, 0.8828125,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.984375 , 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.03278688, 0.04098361, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.09016393, 0.09016393, 0.09836066, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.12295082, 0.13114753, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.16393442,\n",
       "            0.16393442, 0.16393442, 0.17213115, 0.18032786, 0.18032786,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.21311475,\n",
       "            0.21311475, 0.21311475, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.23770492, 0.24590164, 0.24590164, 0.26229507,\n",
       "            0.26229507, 0.2704918 , 0.2704918 , 0.27868852, 0.27868852,\n",
       "            0.27868852, 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36065573, 0.36065573, 0.36065573,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.39344263, 0.40163934,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.59836066, 0.59836066, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.6393443 , 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6639344 , 0.6803279 , 0.6803279 , 0.6885246 ,\n",
       "            0.6885246 , 0.6967213 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.381 , 0.3801, 0.3782, 0.3777, 0.377 , 0.376 , 0.3752,\n",
       "            0.3745, 0.3738, 0.372 , 0.3718, 0.3716, 0.371 , 0.3708, 0.3706,\n",
       "            0.3704, 0.37  , 0.3684, 0.368 , 0.3677, 0.3672, 0.3665, 0.366 ,\n",
       "            0.3655, 0.3647, 0.3645, 0.364 , 0.3623, 0.362 , 0.3613, 0.361 ,\n",
       "            0.3608, 0.3606, 0.3604, 0.3599, 0.359 , 0.358 , 0.3572, 0.3567,\n",
       "            0.3564, 0.3552, 0.3545, 0.3538, 0.3535, 0.3528, 0.3523, 0.3516,\n",
       "            0.3506, 0.3496, 0.349 , 0.3486, 0.3474, 0.3472, 0.3467, 0.3464,\n",
       "            0.3455, 0.3452, 0.3438, 0.343 , 0.3428, 0.342 , 0.3416, 0.341 ,\n",
       "            0.3403, 0.3386, 0.3381, 0.3372, 0.3367, 0.3364, 0.3362, 0.3357,\n",
       "            0.3352, 0.3347, 0.3337, 0.3318, 0.3315, 0.3306, 0.3303, 0.33  ,\n",
       "            0.3289, 0.328 , 0.327 , 0.3264, 0.325 , 0.3245, 0.3237, 0.3218,\n",
       "            0.3215, 0.321 , 0.32  , 0.3193, 0.3188, 0.3167, 0.3154, 0.3137,\n",
       "            0.3135, 0.3132, 0.3123, 0.312 , 0.3118, 0.311 , 0.31  , 0.3093,\n",
       "            0.308 , 0.3079, 0.3076, 0.3064, 0.3062, 0.3052, 0.305 , 0.3044,\n",
       "            0.304 , 0.3027, 0.3022, 0.302 , 0.3013, 0.3005, 0.3   , 0.2998,\n",
       "            0.2993, 0.299 , 0.2986, 0.2961, 0.2957, 0.2954, 0.295 , 0.2944,\n",
       "            0.293 , 0.2925, 0.2922, 0.292 , 0.2893, 0.287 , 0.2866, 0.2852,\n",
       "            0.2847, 0.2842, 0.2832, 0.2827, 0.2825, 0.2778, 0.2769, 0.2764,\n",
       "            0.2732, 0.2712, 0.2708, 0.2705, 0.2693, 0.2688, 0.2686, 0.2676,\n",
       "            0.2673, 0.267 , 0.266 , 0.263 , 0.261 , 0.2605, 0.2595, 0.259 ,\n",
       "            0.258 , 0.2573, 0.257 , 0.2551, 0.2542, 0.253 , 0.2505, 0.2494,\n",
       "            0.2474, 0.2466, 0.2458, 0.2451, 0.2449, 0.2441, 0.2422, 0.2413,\n",
       "            0.2407, 0.2399, 0.2374, 0.2372, 0.234 , 0.2338, 0.2334, 0.2332,\n",
       "            0.228 , 0.2264, 0.2239, 0.223 , 0.2222, 0.2207, 0.218 , 0.2166,\n",
       "            0.214 , 0.2108, 0.2103, 0.2091, 0.2032, 0.2031, 0.1996, 0.1989,\n",
       "            0.1936, 0.1731, 0.172 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.125    , 0.125    , 0.125    , 0.125    , 0.125    ,\n",
       "            0.1328125, 0.1328125, 0.1484375, 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.2734375,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.421875 , 0.4375   , 0.4453125, 0.453125 , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5      , 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.625    , 0.6328125, 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6953125,\n",
       "            0.703125 , 0.703125 , 0.703125 , 0.7109375, 0.71875  , 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.734375 , 0.7421875, 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.78125  , 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.8125   , 0.8125   , 0.8203125, 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.8359375, 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.875    , 0.875    , 0.8828125,\n",
       "            0.8828125, 0.8828125, 0.890625 , 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.984375 , 0.984375 , 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.27868852, 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.3114754 , 0.3114754 ,\n",
       "            0.3114754 , 0.3114754 , 0.31967214, 0.33606556, 0.33606556,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.33606556, 0.352459  ,\n",
       "            0.36885247, 0.37704918, 0.39344263, 0.40163934, 0.40163934,\n",
       "            0.4180328 , 0.43442622, 0.45081967, 0.45081967, 0.45081967,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59016395, 0.59016395, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.60655737, 0.6147541 , 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6639344 ,\n",
       "            0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.428 , 0.4268, 0.4253, 0.4248, 0.4233, 0.4226, 0.422 ,\n",
       "            0.4219, 0.4216, 0.4204, 0.4194, 0.4192, 0.4185, 0.4175, 0.4172,\n",
       "            0.417 , 0.4163, 0.4158, 0.4155, 0.4153, 0.415 , 0.414 , 0.412 ,\n",
       "            0.4119, 0.4116, 0.4106, 0.4102, 0.4097, 0.4087, 0.4067, 0.4062,\n",
       "            0.4055, 0.405 , 0.4045, 0.404 , 0.4038, 0.4036, 0.4026, 0.4019,\n",
       "            0.4011, 0.4   , 0.3994, 0.399 , 0.3987, 0.3984, 0.3982, 0.398 ,\n",
       "            0.3972, 0.397 , 0.3955, 0.3953, 0.3928, 0.3926, 0.392 , 0.3916,\n",
       "            0.391 , 0.3901, 0.39  , 0.389 , 0.3875, 0.3872, 0.3867, 0.3865,\n",
       "            0.3843, 0.3828, 0.3818, 0.3813, 0.381 , 0.3806, 0.3794, 0.3784,\n",
       "            0.3782, 0.3772, 0.3752, 0.375 , 0.373 , 0.3726, 0.372 , 0.3713,\n",
       "            0.3704, 0.3696, 0.3694, 0.3687, 0.3684, 0.367 , 0.3667, 0.3665,\n",
       "            0.366 , 0.3655, 0.3652, 0.3638, 0.3635, 0.3633, 0.3628, 0.3623,\n",
       "            0.361 , 0.3608, 0.3604, 0.36  , 0.3599, 0.3596, 0.3594, 0.3591,\n",
       "            0.3584, 0.3582, 0.358 , 0.3574, 0.3567, 0.3564, 0.3562, 0.3555,\n",
       "            0.3547, 0.3545, 0.3542, 0.3538, 0.3528, 0.3525, 0.3523, 0.3513,\n",
       "            0.3508, 0.3494, 0.3486, 0.3481, 0.3472, 0.3457, 0.3445, 0.344 ,\n",
       "            0.3428, 0.3416, 0.3413, 0.3398, 0.3396, 0.3381, 0.3362, 0.336 ,\n",
       "            0.334 , 0.3335, 0.3328, 0.3323, 0.3315, 0.3313, 0.33  , 0.3298,\n",
       "            0.329 , 0.328 , 0.3276, 0.3274, 0.3271, 0.3267, 0.3264, 0.3254,\n",
       "            0.325 , 0.3247, 0.32  , 0.3198, 0.318 , 0.3176, 0.3154, 0.3152,\n",
       "            0.3132, 0.313 , 0.3103, 0.31  , 0.309 , 0.3086, 0.3083, 0.308 ,\n",
       "            0.3074, 0.307 , 0.3066, 0.3062, 0.3054, 0.3042, 0.3025, 0.3015,\n",
       "            0.3013, 0.2998, 0.298 , 0.2979, 0.2976, 0.2974, 0.295 , 0.2944,\n",
       "            0.2932, 0.292 , 0.2913, 0.288 , 0.2864, 0.2837, 0.2798, 0.278 ,\n",
       "            0.2776, 0.2747, 0.2695, 0.2683, 0.268 , 0.2656, 0.2622, 0.2605,\n",
       "            0.2595, 0.2583, 0.256 , 0.2527, 0.252 , 0.2517, 0.2482, 0.2264,\n",
       "            0.2198], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.078125 , 0.0859375, 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.1015625, 0.1171875, 0.1328125, 0.140625 , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3125   , 0.3125   , 0.3125   , 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.375    ,\n",
       "            0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.6015625,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.703125 , 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.765625 , 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.09016393, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.1557377 , 0.16393442, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4262295 , 0.43442622, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.46721312, 0.47540984, 0.47540984, 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.60655737, 0.60655737, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6721311 , 0.6721311 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.7295082 , 0.7295082 , 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4978, 0.4941, 0.4895, 0.4883, 0.4878, 0.4856, 0.4854,\n",
       "            0.4849, 0.4812, 0.4802, 0.4795, 0.4783, 0.4773, 0.4766, 0.475 ,\n",
       "            0.4749, 0.4739, 0.4734, 0.4731, 0.4722, 0.4717, 0.4714, 0.471 ,\n",
       "            0.4695, 0.4685, 0.4683, 0.468 , 0.4675, 0.466 , 0.4653, 0.4648,\n",
       "            0.464 , 0.4622, 0.462 , 0.4575, 0.4573, 0.4563, 0.455 , 0.4548,\n",
       "            0.4543, 0.4521, 0.4514, 0.4504, 0.45  , 0.4482, 0.4421, 0.4382,\n",
       "            0.436 , 0.4358, 0.4336, 0.4329, 0.4316, 0.4297, 0.429 , 0.4287,\n",
       "            0.4282, 0.428 , 0.4275, 0.4272, 0.427 , 0.4268, 0.426 , 0.4248,\n",
       "            0.4243, 0.423 , 0.4216, 0.4214, 0.421 , 0.4197, 0.419 , 0.4182,\n",
       "            0.418 , 0.4177, 0.4175, 0.4165, 0.414 , 0.4136, 0.4133, 0.4128,\n",
       "            0.4126, 0.4124, 0.412 , 0.4119, 0.4111, 0.4106, 0.4104, 0.4097,\n",
       "            0.409 , 0.4087, 0.4084, 0.4077, 0.4067, 0.4062, 0.405 , 0.4048,\n",
       "            0.404 , 0.4036, 0.402 , 0.4   , 0.3984, 0.3975, 0.3972, 0.397 ,\n",
       "            0.3953, 0.3943, 0.3936, 0.392 , 0.3918, 0.391 , 0.3909, 0.3906,\n",
       "            0.3901, 0.3892, 0.3887, 0.388 , 0.3877, 0.3875, 0.3867, 0.3862,\n",
       "            0.3853, 0.385 , 0.3843, 0.3838, 0.3835, 0.382 , 0.3818, 0.381 ,\n",
       "            0.3804, 0.3801, 0.3796, 0.3794, 0.3774, 0.3772, 0.3745, 0.374 ,\n",
       "            0.3738, 0.3718, 0.371 , 0.3704, 0.3699, 0.3696, 0.3684, 0.3682,\n",
       "            0.3674, 0.3667, 0.3662, 0.366 , 0.365 , 0.364 , 0.363 , 0.3623,\n",
       "            0.361 , 0.3608, 0.3591, 0.3574, 0.3564, 0.3562, 0.354 , 0.353 ,\n",
       "            0.3523, 0.3506, 0.35  , 0.3496, 0.3494, 0.349 , 0.3481, 0.3472,\n",
       "            0.3464, 0.3435, 0.343 , 0.3428, 0.342 , 0.3418, 0.3367, 0.336 ,\n",
       "            0.3323, 0.3313, 0.3303, 0.3296, 0.3274, 0.3267, 0.3245, 0.3235,\n",
       "            0.3228, 0.321 , 0.3184, 0.3179, 0.3176, 0.3162, 0.316 , 0.3137,\n",
       "            0.31  , 0.3064, 0.3052, 0.3032, 0.302 , 0.2979, 0.2932, 0.2927,\n",
       "            0.2869, 0.2754, 0.2734], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.43442622, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.046875 , 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.140625 , 0.1484375,\n",
       "            0.1796875, 0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.28125  , 0.2890625, 0.296875 , 0.3125   ,\n",
       "            0.328125 , 0.328125 , 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.4140625,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.484375 , 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.59375  , 0.59375  , 0.59375  , 0.6015625, 0.6171875, 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.7734375, 0.78125  , 0.796875 , 0.8046875,\n",
       "            0.8046875, 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.84375  ,\n",
       "            0.8515625, 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.8984375, 0.8984375, 0.90625  , 0.90625  ,\n",
       "            0.9140625, 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.12295082,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.23770492,\n",
       "            0.24590164, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.31967214, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.43442622, 0.45081967,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.58196723, 0.59016395, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.63114756, 0.63114756, 0.6393443 ,\n",
       "            0.6393443 , 0.647541  , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.571 , 0.5674, 0.561 , 0.5586, 0.558 , 0.557 , 0.554 ,\n",
       "            0.5483, 0.5444, 0.5415, 0.541 , 0.5396, 0.539 , 0.538 , 0.534 ,\n",
       "            0.5317, 0.5303, 0.53  , 0.5293, 0.5283, 0.528 , 0.527 , 0.5254,\n",
       "            0.525 , 0.524 , 0.5234, 0.521 , 0.5195, 0.519 , 0.5186, 0.518 ,\n",
       "            0.5166, 0.516 , 0.514 , 0.5127, 0.511 , 0.5093, 0.508 , 0.5073,\n",
       "            0.5063, 0.5054, 0.505 , 0.5015, 0.4978, 0.4946, 0.494 , 0.4927,\n",
       "            0.486 , 0.4856, 0.4854, 0.4824, 0.481 , 0.4795, 0.4788, 0.4775,\n",
       "            0.476 , 0.4753, 0.4734, 0.473 , 0.472 , 0.4717, 0.4712, 0.4702,\n",
       "            0.4697, 0.4688, 0.4685, 0.4666, 0.4646, 0.464 , 0.4636, 0.4631,\n",
       "            0.463 , 0.4614, 0.461 , 0.4604, 0.4602, 0.4597, 0.459 , 0.4587,\n",
       "            0.4578, 0.4575, 0.457 , 0.4563, 0.456 , 0.4556, 0.4546, 0.4534,\n",
       "            0.453 , 0.4526, 0.4521, 0.4514, 0.4512, 0.4495, 0.4492, 0.449 ,\n",
       "            0.4485, 0.4478, 0.4465, 0.4463, 0.4436, 0.4434, 0.4426, 0.4414,\n",
       "            0.4412, 0.4397, 0.4395, 0.439 , 0.4385, 0.4377, 0.4373, 0.4365,\n",
       "            0.436 , 0.4355, 0.434 , 0.4304, 0.43  , 0.4297, 0.4294, 0.428 ,\n",
       "            0.4275, 0.4253, 0.4238, 0.422 , 0.4211, 0.4204, 0.4187, 0.4165,\n",
       "            0.4158, 0.4133, 0.412 , 0.4114, 0.4097, 0.4092, 0.4077, 0.4065,\n",
       "            0.406 , 0.405 , 0.4043, 0.404 , 0.4033, 0.403 , 0.402 , 0.4016,\n",
       "            0.4014, 0.4011, 0.4001, 0.3994, 0.3982, 0.3977, 0.3972, 0.3967,\n",
       "            0.3965, 0.396 , 0.3958, 0.395 , 0.3943, 0.393 , 0.392 , 0.391 ,\n",
       "            0.39  , 0.3865, 0.3843, 0.3838, 0.3835, 0.3828, 0.3826, 0.3823,\n",
       "            0.3818, 0.38  , 0.3782, 0.3777, 0.3772, 0.3767, 0.3765, 0.376 ,\n",
       "            0.3745, 0.3735, 0.3726, 0.3694, 0.3682, 0.3647, 0.3586, 0.3582,\n",
       "            0.3572, 0.3557, 0.3547, 0.3542, 0.354 , 0.3528, 0.3477, 0.3452,\n",
       "            0.3438, 0.342 , 0.3352, 0.3306, 0.3286, 0.3267, 0.326 , 0.3196,\n",
       "            0.317 , 0.3052, 0.2922, 0.2825], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1875, dtype=float32),\n",
       "    'tpr': array(0.6393443, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1796875, 0.1796875, 0.1875   , 0.1953125, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2578125, 0.2578125, 0.265625 , 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.3046875, 0.3125   , 0.3125   , 0.3125   ,\n",
       "            0.3125   , 0.3125   , 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.375    , 0.375    , 0.3828125, 0.390625 , 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.453125 ,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.4921875, 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.515625 , 0.515625 , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.59836066, 0.6147541 ,\n",
       "            0.6229508 , 0.6393443 , 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.636 , 0.63  , 0.6265, 0.626 , 0.619 , 0.6177, 0.6167,\n",
       "            0.6025, 0.599 , 0.5986, 0.5947, 0.594 , 0.592 , 0.589 , 0.586 ,\n",
       "            0.5845, 0.584 , 0.5835, 0.583 , 0.5815, 0.58  , 0.5786, 0.5767,\n",
       "            0.576 , 0.5757, 0.575 , 0.574 , 0.5737, 0.573 , 0.5723, 0.5713,\n",
       "            0.5703, 0.57  , 0.5693, 0.567 , 0.5654, 0.563 , 0.56  , 0.5596,\n",
       "            0.559 , 0.558 , 0.556 , 0.5557, 0.5547, 0.554 , 0.548 , 0.5474,\n",
       "            0.546 , 0.5454, 0.5386, 0.5366, 0.5356, 0.5347, 0.5337, 0.53  ,\n",
       "            0.5293, 0.5264, 0.525 , 0.5244, 0.5225, 0.5195, 0.519 , 0.5176,\n",
       "            0.517 , 0.5166, 0.516 , 0.5156, 0.515 , 0.5146, 0.514 , 0.513 ,\n",
       "            0.511 , 0.51  , 0.509 , 0.507 , 0.5063, 0.506 , 0.505 , 0.504 ,\n",
       "            0.5034, 0.501 , 0.4998, 0.4993, 0.4983, 0.498 , 0.4966, 0.4958,\n",
       "            0.4956, 0.4946, 0.4944, 0.494 , 0.4934, 0.4927, 0.492 , 0.4917,\n",
       "            0.491 , 0.49  , 0.4895, 0.489 , 0.4885, 0.488 , 0.4878, 0.4873,\n",
       "            0.486 , 0.4858, 0.4844, 0.484 , 0.4836, 0.483 , 0.4827, 0.4817,\n",
       "            0.4807, 0.479 , 0.477 , 0.4724, 0.4722, 0.4707, 0.47  , 0.4697,\n",
       "            0.468 , 0.4675, 0.4656, 0.465 , 0.4631, 0.462 , 0.4614, 0.4595,\n",
       "            0.4592, 0.4583, 0.4578, 0.4526, 0.4524, 0.452 , 0.4514, 0.4465,\n",
       "            0.446 , 0.4456, 0.4436, 0.4434, 0.443 , 0.4414, 0.439 , 0.4387,\n",
       "            0.4382, 0.438 , 0.436 , 0.4355, 0.4353, 0.4343, 0.434 , 0.4324,\n",
       "            0.432 , 0.4312, 0.4275, 0.4272, 0.4268, 0.425 , 0.4246, 0.423 ,\n",
       "            0.422 , 0.4216, 0.421 , 0.4207, 0.42  , 0.4197, 0.4192, 0.4143,\n",
       "            0.4138, 0.4133, 0.4111, 0.4104, 0.4084, 0.4075, 0.4072, 0.407 ,\n",
       "            0.405 , 0.4045, 0.4016, 0.3967, 0.3955, 0.3945, 0.394 , 0.3928,\n",
       "            0.3896, 0.389 , 0.387 , 0.3857, 0.3855, 0.384 , 0.382 , 0.381 ,\n",
       "            0.3796, 0.3767, 0.3765, 0.3628, 0.3613, 0.3606, 0.358 , 0.3425,\n",
       "            0.3376, 0.3352, 0.3281, 0.3242, 0.3176, 0.3052, 0.2915, 0.2913,\n",
       "            0.2883], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3828125, dtype=float32),\n",
       "    'tpr': array(0.8114754, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375, 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.25     , 0.2578125,\n",
       "            0.265625 , 0.265625 , 0.265625 , 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.2890625, 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.328125 ,\n",
       "            0.34375  , 0.3515625, 0.3515625, 0.3515625, 0.359375 , 0.359375 ,\n",
       "            0.3671875, 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.390625 ,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.40625  , 0.40625  , 0.4140625,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.4765625, 0.4921875, 0.5      , 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.7421875, 0.7421875, 0.75     , 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.47540984, 0.48360655,\n",
       "            0.48360655, 0.5       , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5327869 , 0.5409836 ,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.58196723, 0.59836066,\n",
       "            0.60655737, 0.60655737, 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.74590164, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6904, 0.6875, 0.682 , 0.6763, 0.674 , 0.6685, 0.667 ,\n",
       "            0.65  , 0.6494, 0.649 , 0.6426, 0.639 , 0.635 , 0.633 , 0.632 ,\n",
       "            0.6304, 0.629 , 0.627 , 0.6255, 0.625 , 0.624 , 0.623 , 0.6226,\n",
       "            0.6216, 0.6196, 0.6187, 0.618 , 0.6177, 0.6157, 0.614 , 0.6123,\n",
       "            0.6113, 0.61  , 0.608 , 0.6045, 0.6016, 0.601 , 0.6   , 0.5986,\n",
       "            0.5967, 0.596 , 0.593 , 0.591 , 0.5903, 0.5835, 0.5815, 0.579 ,\n",
       "            0.574 , 0.5723, 0.572 , 0.5693, 0.5684, 0.568 , 0.5674, 0.565 ,\n",
       "            0.5645, 0.564 , 0.5625, 0.562 , 0.561 , 0.5605, 0.56  , 0.5576,\n",
       "            0.557 , 0.5566, 0.556 , 0.5557, 0.555 , 0.5537, 0.5522, 0.551 ,\n",
       "            0.5503, 0.55  , 0.5493, 0.548 , 0.5474, 0.5464, 0.546 , 0.5444,\n",
       "            0.544 , 0.543 , 0.5425, 0.542 , 0.539 , 0.5386, 0.537 , 0.5366,\n",
       "            0.535 , 0.534 , 0.5337, 0.533 , 0.5327, 0.532 , 0.5312, 0.5303,\n",
       "            0.5293, 0.529 , 0.5283, 0.528 , 0.5264, 0.525 , 0.5244, 0.5225,\n",
       "            0.522 , 0.5205, 0.519 , 0.516 , 0.515 , 0.5146, 0.512 , 0.5117,\n",
       "            0.509 , 0.508 , 0.507 , 0.5063, 0.505 , 0.502 , 0.5   , 0.4983,\n",
       "            0.4978, 0.4966, 0.4932, 0.4924, 0.4915, 0.4912, 0.491 , 0.4902,\n",
       "            0.49  , 0.4895, 0.4885, 0.4866, 0.4856, 0.4849, 0.4846, 0.4824,\n",
       "            0.4822, 0.481 , 0.4802, 0.4778, 0.4775, 0.4768, 0.4758, 0.4746,\n",
       "            0.4744, 0.4731, 0.473 , 0.4727, 0.4717, 0.471 , 0.4697, 0.468 ,\n",
       "            0.4653, 0.4648, 0.4622, 0.4597, 0.4592, 0.4573, 0.457 , 0.4565,\n",
       "            0.456 , 0.4524, 0.4521, 0.452 , 0.449 , 0.447 , 0.4448, 0.4395,\n",
       "            0.4358, 0.4353, 0.4343, 0.434 , 0.4321, 0.432 , 0.4304, 0.426 ,\n",
       "            0.424 , 0.4236, 0.4233, 0.4226, 0.4167, 0.416 , 0.4158, 0.415 ,\n",
       "            0.4148, 0.411 , 0.4053, 0.4036, 0.4019, 0.3967, 0.392 , 0.3901,\n",
       "            0.389 , 0.3887, 0.3877, 0.3833, 0.383 , 0.3718, 0.3677, 0.3662,\n",
       "            0.3657, 0.352 , 0.3416, 0.3394, 0.3303, 0.3289, 0.318 , 0.305 ,\n",
       "            0.2944, 0.2908, 0.2903], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.53125, dtype=float32),\n",
       "    'tpr': array(0.9508197, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.109375 , 0.125    , 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.15625  , 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.2421875, 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.25     , 0.2578125, 0.2734375, 0.28125  , 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3046875, 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.34375  , 0.34375  , 0.3515625, 0.3515625, 0.3515625, 0.3515625,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.3671875, 0.3828125,\n",
       "            0.3828125, 0.390625 , 0.390625 , 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.515625 , 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01639344, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.27868852, 0.28688523, 0.30327868, 0.3114754 , 0.32786885,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40163934, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45081967, 0.45901638, 0.46721312, 0.46721312,\n",
       "            0.48360655, 0.4918033 , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.6147541 , 0.6147541 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6721311 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.7295082 , 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7397, 0.7334, 0.7236, 0.7217, 0.715 , 0.714 , 0.6978,\n",
       "            0.697 , 0.6924, 0.6875, 0.6816, 0.677 , 0.673 , 0.6724, 0.672 ,\n",
       "            0.67  , 0.6685, 0.668 , 0.6675, 0.666 , 0.665 , 0.6636, 0.663 ,\n",
       "            0.662 , 0.6616, 0.66  , 0.659 , 0.6587, 0.657 , 0.6543, 0.65  ,\n",
       "            0.648 , 0.644 , 0.64  , 0.6377, 0.6367, 0.636 , 0.6323, 0.6274,\n",
       "            0.627 , 0.626 , 0.6255, 0.6226, 0.6206, 0.6196, 0.619 , 0.6143,\n",
       "            0.612 , 0.6104, 0.6094, 0.6064, 0.606 , 0.6055, 0.605 , 0.603 ,\n",
       "            0.602 , 0.6016, 0.6006, 0.5996, 0.598 , 0.597 , 0.5967, 0.595 ,\n",
       "            0.5947, 0.594 , 0.5938, 0.592 , 0.5903, 0.59  , 0.5884, 0.5874,\n",
       "            0.5864, 0.5854, 0.585 , 0.584 , 0.5835, 0.582 , 0.5815, 0.581 ,\n",
       "            0.5796, 0.579 , 0.578 , 0.5767, 0.575 , 0.573 , 0.5728, 0.5713,\n",
       "            0.5703, 0.569 , 0.5684, 0.568 , 0.5674, 0.567 , 0.5664, 0.564 ,\n",
       "            0.5635, 0.5625, 0.562 , 0.5605, 0.56  , 0.5596, 0.559 , 0.5586,\n",
       "            0.5576, 0.5566, 0.5547, 0.5513, 0.548 , 0.5474, 0.547 , 0.546 ,\n",
       "            0.545 , 0.5435, 0.543 , 0.5405, 0.5396, 0.539 , 0.5356, 0.535 ,\n",
       "            0.5337, 0.5317, 0.5312, 0.5293, 0.5283, 0.527 , 0.5234, 0.5225,\n",
       "            0.522 , 0.5215, 0.519 , 0.5156, 0.5137, 0.513 , 0.5127, 0.511 ,\n",
       "            0.5107, 0.5103, 0.51  , 0.5083, 0.5034, 0.502 , 0.5015, 0.4983,\n",
       "            0.4973, 0.497 , 0.4946, 0.4944, 0.494 , 0.4937, 0.4905, 0.4883,\n",
       "            0.4866, 0.4858, 0.4846, 0.4802, 0.477 , 0.4746, 0.4734, 0.471 ,\n",
       "            0.4705, 0.4683, 0.4673, 0.4624, 0.4595, 0.4521, 0.4502, 0.4495,\n",
       "            0.4487, 0.4482, 0.447 , 0.4446, 0.4436, 0.4375, 0.4348, 0.434 ,\n",
       "            0.4333, 0.4268, 0.4255, 0.4253, 0.4207, 0.4155, 0.4128, 0.4111,\n",
       "            0.4048, 0.3992, 0.397 , 0.3967, 0.395 , 0.3901, 0.39  , 0.386 ,\n",
       "            0.373 , 0.372 , 0.3716, 0.3713, 0.363 , 0.3481, 0.342 , 0.3335,\n",
       "            0.333 , 0.319 , 0.3052, 0.3005, 0.2905, 0.29  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6171875, dtype=float32),\n",
       "    'tpr': array(0.9672131, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.125    , 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.296875 , 0.296875 , 0.296875 , 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.328125 , 0.3359375, 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.3515625, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.3671875, 0.3671875, 0.3671875, 0.3671875, 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.4140625,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.14754099, 0.1557377 , 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.37704918, 0.37704918, 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.40983605, 0.43442622, 0.44262296,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.59836066, 0.60655737,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.71311474, 0.7295082 , 0.73770493, 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.78  , 0.7783, 0.7734, 0.763 , 0.758 , 0.7524, 0.751 ,\n",
       "            0.736 , 0.734 , 0.727 , 0.723 , 0.7188, 0.7163, 0.7134, 0.7104,\n",
       "            0.7075, 0.704 , 0.703 , 0.7026, 0.7017, 0.701 , 0.6997, 0.699 ,\n",
       "            0.6953, 0.6943, 0.694 , 0.6934, 0.692 , 0.6895, 0.687 , 0.683 ,\n",
       "            0.681 , 0.679 , 0.675 , 0.674 , 0.673 , 0.672 , 0.6685, 0.6665,\n",
       "            0.6636, 0.662 , 0.6616, 0.6577, 0.6553, 0.655 , 0.652 , 0.65  ,\n",
       "            0.649 , 0.6416, 0.6406, 0.64  , 0.639 , 0.6387, 0.637 , 0.636 ,\n",
       "            0.635 , 0.6343, 0.634 , 0.6333, 0.633 , 0.632 , 0.6313, 0.6304,\n",
       "            0.63  , 0.6294, 0.629 , 0.6284, 0.628 , 0.6265, 0.6255, 0.624 ,\n",
       "            0.6235, 0.623 , 0.6226, 0.622 , 0.6216, 0.621 , 0.6206, 0.62  ,\n",
       "            0.6177, 0.6167, 0.615 , 0.6147, 0.6133, 0.6113, 0.6104, 0.61  ,\n",
       "            0.6094, 0.609 , 0.6084, 0.603 , 0.6025, 0.6016, 0.6   , 0.5996,\n",
       "            0.599 , 0.598 , 0.5977, 0.597 , 0.5967, 0.595 , 0.5938, 0.5933,\n",
       "            0.591 , 0.5903, 0.59  , 0.5884, 0.5864, 0.5854, 0.5845, 0.5835,\n",
       "            0.5815, 0.581 , 0.5806, 0.5796, 0.579 , 0.577 , 0.5767, 0.5757,\n",
       "            0.5747, 0.574 , 0.5737, 0.5723, 0.57  , 0.5693, 0.569 , 0.5684,\n",
       "            0.567 , 0.566 , 0.5645, 0.5625, 0.56  , 0.5596, 0.557 , 0.5566,\n",
       "            0.5537, 0.5522, 0.5513, 0.55  , 0.5493, 0.549 , 0.5483, 0.545 ,\n",
       "            0.544 , 0.542 , 0.5415, 0.541 , 0.5396, 0.539 , 0.5366, 0.5347,\n",
       "            0.5337, 0.5312, 0.528 , 0.527 , 0.5234, 0.523 , 0.5176, 0.516 ,\n",
       "            0.515 , 0.513 , 0.511 , 0.5103, 0.5083, 0.508 , 0.5063, 0.5034,\n",
       "            0.4995, 0.4968, 0.4937, 0.4893, 0.487 , 0.4849, 0.4824, 0.4822,\n",
       "            0.4736, 0.4653, 0.4626, 0.4624, 0.4622, 0.4595, 0.4587, 0.4563,\n",
       "            0.455 , 0.4534, 0.4497, 0.4487, 0.4434, 0.4426, 0.4348, 0.4343,\n",
       "            0.4329, 0.4287, 0.4238, 0.4202, 0.4185, 0.411 , 0.4045, 0.4033,\n",
       "            0.4019, 0.4006, 0.4001, 0.3984, 0.3958, 0.3955, 0.3772, 0.377 ,\n",
       "            0.3757, 0.3755, 0.3708, 0.3535, 0.3433, 0.3372, 0.3345, 0.3193,\n",
       "            0.306 , 0.305 , 0.2898, 0.289 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6328125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0546875,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.1640625,\n",
       "            0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.203125 , 0.203125 , 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.2421875, 0.2421875, 0.25     , 0.25     , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.328125 , 0.328125 , 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3828125, 0.390625 , 0.390625 , 0.3984375, 0.3984375,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.421875 ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.59375  , 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.36885247, 0.37704918, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45901638, 0.45901638,\n",
       "            0.46721312, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.71311474, 0.72131145,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.7295082 , 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8164, 0.8135, 0.8096, 0.7993, 0.791 , 0.787 , 0.785 ,\n",
       "            0.7715, 0.769 , 0.76  , 0.7573, 0.7544, 0.7485, 0.748 , 0.7466,\n",
       "            0.741 , 0.7393, 0.7383, 0.736 , 0.7354, 0.7344, 0.734 , 0.7334,\n",
       "            0.733 , 0.7324, 0.7295, 0.727 , 0.725 , 0.7246, 0.7236, 0.7207,\n",
       "            0.719 , 0.718 , 0.7114, 0.7095, 0.707 , 0.705 , 0.7046, 0.704 ,\n",
       "            0.699 , 0.6987, 0.6978, 0.6963, 0.696 , 0.695 , 0.692 , 0.688 ,\n",
       "            0.6875, 0.684 , 0.6836, 0.683 , 0.6826, 0.682 , 0.678 , 0.6763,\n",
       "            0.673 , 0.6714, 0.669 , 0.6685, 0.668 , 0.6675, 0.667 , 0.6665,\n",
       "            0.666 , 0.6655, 0.664 , 0.6636, 0.663 , 0.662 , 0.661 , 0.66  ,\n",
       "            0.6597, 0.658 , 0.6577, 0.6567, 0.656 , 0.6553, 0.655 , 0.6543,\n",
       "            0.654 , 0.652 , 0.6514, 0.651 , 0.6504, 0.6494, 0.649 , 0.6484,\n",
       "            0.6475, 0.647 , 0.646 , 0.6455, 0.644 , 0.6426, 0.6406, 0.6387,\n",
       "            0.637 , 0.636 , 0.6353, 0.6333, 0.633 , 0.6323, 0.631 , 0.63  ,\n",
       "            0.628 , 0.6274, 0.626 , 0.6255, 0.625 , 0.624 , 0.6216, 0.6187,\n",
       "            0.618 , 0.6167, 0.616 , 0.6147, 0.6143, 0.6123, 0.612 , 0.6113,\n",
       "            0.6084, 0.608 , 0.6074, 0.607 , 0.606 , 0.6045, 0.604 , 0.603 ,\n",
       "            0.602 , 0.601 , 0.6006, 0.598 , 0.594 , 0.5933, 0.593 , 0.591 ,\n",
       "            0.589 , 0.5884, 0.587 , 0.586 , 0.5845, 0.5806, 0.5796, 0.576 ,\n",
       "            0.5757, 0.574 , 0.5737, 0.573 , 0.5723, 0.572 , 0.5703, 0.57  ,\n",
       "            0.5684, 0.568 , 0.5635, 0.559 , 0.5576, 0.555 , 0.554 , 0.549 ,\n",
       "            0.547 , 0.5454, 0.545 , 0.5415, 0.539 , 0.532 , 0.5312, 0.53  ,\n",
       "            0.5293, 0.5283, 0.5273, 0.527 , 0.5244, 0.522 , 0.521 , 0.5195,\n",
       "            0.518 , 0.5166, 0.507 , 0.497 , 0.4944, 0.489 , 0.4856, 0.4763,\n",
       "            0.4756, 0.4731, 0.4712, 0.4702, 0.4673, 0.4663, 0.466 , 0.4636,\n",
       "            0.4607, 0.453 , 0.452 , 0.4438, 0.4436, 0.4412, 0.4373, 0.433 ,\n",
       "            0.4282, 0.426 , 0.4177, 0.4124, 0.4106, 0.4072, 0.407 , 0.4062,\n",
       "            0.402 , 0.4016, 0.3823, 0.382 , 0.3806, 0.3804, 0.3599, 0.3457,\n",
       "            0.3418, 0.3372, 0.3206, 0.3127, 0.3054, 0.2898, 0.289 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6640625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.203125 ,\n",
       "            0.203125 , 0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.2421875, 0.25     , 0.25     , 0.25     , 0.2578125,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.2890625,\n",
       "            0.2890625, 0.3046875, 0.3203125, 0.3203125, 0.3203125, 0.3359375,\n",
       "            0.3359375, 0.34375  , 0.34375  , 0.34375  , 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.3828125, 0.3828125,\n",
       "            0.390625 , 0.390625 , 0.390625 , 0.40625  , 0.40625  , 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5859375, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.28688523, 0.29508197, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4262295 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.63114756, 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.844 , 0.84  , 0.8374, 0.827 , 0.8174, 0.814 , 0.8125,\n",
       "            0.7993, 0.797 , 0.786 , 0.784 , 0.782 , 0.776 , 0.7754, 0.775 ,\n",
       "            0.7686, 0.7676, 0.7666, 0.7627, 0.762 , 0.7617, 0.7603, 0.76  ,\n",
       "            0.7593, 0.758 , 0.757 , 0.7534, 0.751 , 0.75  , 0.7485, 0.746 ,\n",
       "            0.745 , 0.737 , 0.734 , 0.7314, 0.731 , 0.729 , 0.727 , 0.7246,\n",
       "            0.722 , 0.721 , 0.72  , 0.718 , 0.7173, 0.7163, 0.71  , 0.708 ,\n",
       "            0.7075, 0.707 , 0.705 , 0.7026, 0.7   , 0.698 , 0.697 , 0.696 ,\n",
       "            0.695 , 0.694 , 0.6934, 0.692 , 0.6914, 0.691 , 0.69  , 0.689 ,\n",
       "            0.6875, 0.686 , 0.684 , 0.6836, 0.683 , 0.682 , 0.681 , 0.6807,\n",
       "            0.68  , 0.6797, 0.679 , 0.677 , 0.6753, 0.675 , 0.6743, 0.6733,\n",
       "            0.6724, 0.6704, 0.67  , 0.6694, 0.6665, 0.666 , 0.6655, 0.662 ,\n",
       "            0.6606, 0.659 , 0.6587, 0.6577, 0.657 , 0.654 , 0.6533, 0.653 ,\n",
       "            0.651 , 0.65  , 0.6494, 0.6484, 0.648 , 0.6475, 0.647 , 0.644 ,\n",
       "            0.643 , 0.6426, 0.642 , 0.6416, 0.6406, 0.6377, 0.636 , 0.635 ,\n",
       "            0.634 , 0.6333, 0.6313, 0.631 , 0.6294, 0.6284, 0.628 , 0.627 ,\n",
       "            0.625 , 0.6245, 0.624 , 0.623 , 0.6216, 0.6187, 0.615 , 0.6143,\n",
       "            0.6133, 0.613 , 0.6094, 0.6055, 0.604 , 0.603 , 0.602 , 0.6016,\n",
       "            0.601 , 0.6006, 0.5996, 0.598 , 0.5977, 0.5957, 0.5947, 0.593 ,\n",
       "            0.588 , 0.579 , 0.578 , 0.574 , 0.5728, 0.5703, 0.565 , 0.5605,\n",
       "            0.555 , 0.5547, 0.5522, 0.548 , 0.5474, 0.5454, 0.5444, 0.544 ,\n",
       "            0.5366, 0.5356, 0.534 , 0.533 , 0.5283, 0.5234, 0.509 , 0.5073,\n",
       "            0.505 , 0.5044, 0.4956, 0.4883, 0.4868, 0.4824, 0.482 , 0.4807,\n",
       "            0.4797, 0.4758, 0.4746, 0.4724, 0.471 , 0.4607, 0.4592, 0.452 ,\n",
       "            0.451 , 0.448 , 0.4446, 0.4412, 0.435 , 0.4326, 0.424 , 0.4233,\n",
       "            0.417 , 0.4158, 0.4124, 0.4116, 0.411 , 0.4072, 0.407 , 0.388 ,\n",
       "            0.387 , 0.3862, 0.385 , 0.3848, 0.3655, 0.3474, 0.346 , 0.339 ,\n",
       "            0.321 , 0.3184, 0.3057, 0.2898, 0.2888], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6796875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.140625 , 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.15625  , 0.15625  , 0.15625  , 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.203125 , 0.203125 ,\n",
       "            0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.28125  ,\n",
       "            0.296875 , 0.3046875, 0.3203125, 0.3203125, 0.3203125, 0.328125 ,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.359375 , 0.359375 , 0.359375 ,\n",
       "            0.359375 , 0.359375 , 0.375    , 0.3828125, 0.390625 , 0.390625 ,\n",
       "            0.3984375, 0.3984375, 0.3984375, 0.40625  , 0.4140625, 0.4140625,\n",
       "            0.4140625, 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.36065573, 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45081967, 0.45901638, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.63114756, 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6639344 , 0.6639344 , 0.6639344 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.868 , 0.8633, 0.862 , 0.8516, 0.841 , 0.838 , 0.8364,\n",
       "            0.8247, 0.822 , 0.8105, 0.8086, 0.807 , 0.801 , 0.799 , 0.7935,\n",
       "            0.793 , 0.788 , 0.7876, 0.787 , 0.786 , 0.784 , 0.7837, 0.783 ,\n",
       "            0.7827, 0.7812, 0.778 , 0.7764, 0.776 , 0.774 , 0.772 , 0.771 ,\n",
       "            0.7695, 0.769 , 0.7603, 0.7593, 0.7573, 0.7563, 0.7554, 0.753 ,\n",
       "            0.752 , 0.7515, 0.7456, 0.745 , 0.7446, 0.744 , 0.7427, 0.74  ,\n",
       "            0.736 , 0.731 , 0.7305, 0.7295, 0.7256, 0.725 , 0.7246, 0.724 ,\n",
       "            0.7227, 0.722 , 0.7207, 0.72  , 0.7183, 0.7173, 0.7163, 0.716 ,\n",
       "            0.7144, 0.7134, 0.7124, 0.7114, 0.711 , 0.71  , 0.708 , 0.707 ,\n",
       "            0.706 , 0.705 , 0.7046, 0.7036, 0.7026, 0.702 , 0.7   , 0.6997,\n",
       "            0.699 , 0.6987, 0.698 , 0.6973, 0.697 , 0.695 , 0.6943, 0.6934,\n",
       "            0.693 , 0.692 , 0.69  , 0.6895, 0.689 , 0.683 , 0.6826, 0.6816,\n",
       "            0.681 , 0.6807, 0.6797, 0.6772, 0.6763, 0.676 , 0.675 , 0.6743,\n",
       "            0.674 , 0.673 , 0.6724, 0.6714, 0.6704, 0.67  , 0.6685, 0.6675,\n",
       "            0.6655, 0.664 , 0.6636, 0.6616, 0.6597, 0.658 , 0.6562, 0.656 ,\n",
       "            0.6553, 0.655 , 0.654 , 0.652 , 0.6504, 0.648 , 0.647 , 0.646 ,\n",
       "            0.6455, 0.6426, 0.641 , 0.6396, 0.635 , 0.633 , 0.632 , 0.6313,\n",
       "            0.631 , 0.63  , 0.629 , 0.6284, 0.6265, 0.626 , 0.6245, 0.621 ,\n",
       "            0.6206, 0.62  , 0.619 , 0.6187, 0.6157, 0.6147, 0.599 , 0.5977,\n",
       "            0.595 , 0.591 , 0.59  , 0.5884, 0.5874, 0.581 , 0.5796, 0.5767,\n",
       "            0.5747, 0.5728, 0.5664, 0.566 , 0.5625, 0.56  , 0.5576, 0.557 ,\n",
       "            0.5522, 0.5493, 0.5474, 0.5454, 0.54  , 0.5396, 0.5273, 0.518 ,\n",
       "            0.5156, 0.515 , 0.507 , 0.5015, 0.4993, 0.4988, 0.4912, 0.4907,\n",
       "            0.4863, 0.484 , 0.4827, 0.4824, 0.4697, 0.4675, 0.4612, 0.4595,\n",
       "            0.4558, 0.4531, 0.4507, 0.4434, 0.4404, 0.4377, 0.4307, 0.4248,\n",
       "            0.4224, 0.4192, 0.4172, 0.417 , 0.414 , 0.4138, 0.3962, 0.3933,\n",
       "            0.3918, 0.3909, 0.3904, 0.3728, 0.3518, 0.3506, 0.343 , 0.3257,\n",
       "            0.3235, 0.3074, 0.2915, 0.2903], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7109375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0703125, 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.1171875, 0.1171875, 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.15625  , 0.15625  , 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.25     , 0.265625 ,\n",
       "            0.2734375, 0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.3359375, 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.3984375, 0.40625  ,\n",
       "            0.40625  , 0.40625  , 0.4140625, 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.30327868, 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.33606556, 0.3442623 , 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5081967 , 0.5081967 , 0.5081967 , 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5491803 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6639344 ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.75409836, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.889 , 0.884 , 0.883 , 0.8735, 0.862 , 0.8594, 0.858 ,\n",
       "            0.8477, 0.8447, 0.832 , 0.8315, 0.8306, 0.8247, 0.8237, 0.821 ,\n",
       "            0.817 , 0.8164, 0.8154, 0.8115, 0.8105, 0.81  , 0.8086, 0.807 ,\n",
       "            0.806 , 0.8057, 0.805 , 0.8027, 0.801 , 0.8   , 0.7983, 0.796 ,\n",
       "            0.795 , 0.7935, 0.792 , 0.7915, 0.7827, 0.782 , 0.7817, 0.78  ,\n",
       "            0.779 , 0.778 , 0.7773, 0.774 , 0.7705, 0.77  , 0.7676, 0.767 ,\n",
       "            0.764 , 0.762 , 0.7603, 0.756 , 0.7534, 0.7524, 0.752 , 0.7505,\n",
       "            0.75  , 0.7485, 0.7476, 0.747 , 0.7466, 0.745 , 0.744 , 0.7417,\n",
       "            0.7407, 0.7397, 0.7393, 0.7383, 0.736 , 0.735 , 0.7344, 0.7334,\n",
       "            0.732 , 0.7314, 0.7295, 0.729 , 0.7285, 0.728 , 0.727 , 0.7266,\n",
       "            0.7256, 0.7246, 0.724 , 0.723 , 0.7227, 0.7217, 0.721 , 0.7197,\n",
       "            0.719 , 0.7188, 0.718 , 0.7163, 0.715 , 0.713 , 0.7124, 0.712 ,\n",
       "            0.7095, 0.7056, 0.705 , 0.7046, 0.704 , 0.703 , 0.702 , 0.7017,\n",
       "            0.701 , 0.7007, 0.6997, 0.6987, 0.6978, 0.697 , 0.6953, 0.6943,\n",
       "            0.694 , 0.6934, 0.6924, 0.692 , 0.688 , 0.686 , 0.6855, 0.685 ,\n",
       "            0.6846, 0.681 , 0.6807, 0.679 , 0.6787, 0.677 , 0.675 , 0.6743,\n",
       "            0.6724, 0.669 , 0.668 , 0.6665, 0.666 , 0.665 , 0.6597, 0.659 ,\n",
       "            0.658 , 0.6567, 0.653 , 0.652 , 0.651 , 0.6504, 0.65  , 0.649 ,\n",
       "            0.6475, 0.645 , 0.6445, 0.6426, 0.6396, 0.639 , 0.6387, 0.638 ,\n",
       "            0.632 , 0.6226, 0.6206, 0.6113, 0.611 , 0.61  , 0.6074, 0.6055,\n",
       "            0.6045, 0.604 , 0.598 , 0.592 , 0.5894, 0.582 , 0.58  , 0.578 ,\n",
       "            0.5767, 0.5703, 0.5693, 0.569 , 0.5684, 0.561 , 0.559 , 0.557 ,\n",
       "            0.5557, 0.5513, 0.5464, 0.5283, 0.5264, 0.5254, 0.5166, 0.5127,\n",
       "            0.512 , 0.5103, 0.501 , 0.5005, 0.5   , 0.4956, 0.4924, 0.4912,\n",
       "            0.4778, 0.4753, 0.4692, 0.467 , 0.463 , 0.4607, 0.458 , 0.4497,\n",
       "            0.4478, 0.4465, 0.4363, 0.4304, 0.4275, 0.4243, 0.422 , 0.4219,\n",
       "            0.4192, 0.4187, 0.4048, 0.3977, 0.3958, 0.395 , 0.3943, 0.3772,\n",
       "            0.355 , 0.3525, 0.3447, 0.3298, 0.3245, 0.3079, 0.2913, 0.29  ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.75, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.1171875, 0.1171875,\n",
       "            0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.1484375, 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.15625  , 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.21875  , 0.21875  , 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.2421875, 0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.2890625, 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.328125 , 0.3359375, 0.3359375, 0.3359375, 0.3359375,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.3828125,\n",
       "            0.3828125, 0.3828125, 0.390625 , 0.390625 , 0.3984375, 0.4140625,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5      , 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.21311475, 0.22131148, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.28688523, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36885247, 0.37704918, 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.40983605, 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.45081967, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.46721312, 0.48360655, 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59016395,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.907 , 0.902 , 0.9014, 0.8926, 0.881 , 0.879 , 0.8774,\n",
       "            0.868 , 0.865 , 0.8525, 0.852 , 0.8516, 0.8467, 0.8447, 0.8413,\n",
       "            0.8384, 0.838 , 0.8364, 0.8335, 0.832 , 0.831 , 0.829 , 0.828 ,\n",
       "            0.8276, 0.8257, 0.823 , 0.822 , 0.82  , 0.817 , 0.816 , 0.814 ,\n",
       "            0.8125, 0.8057, 0.8047, 0.8022, 0.802 , 0.801 , 0.8003, 0.7944,\n",
       "            0.794 , 0.788 , 0.7847, 0.783 , 0.7793, 0.775 , 0.7744, 0.774 ,\n",
       "            0.7734, 0.771 , 0.77  , 0.7686, 0.768 , 0.7666, 0.7637, 0.762 ,\n",
       "            0.7617, 0.7603, 0.758 , 0.757 , 0.756 , 0.7554, 0.755 , 0.7544,\n",
       "            0.7534, 0.753 , 0.752 , 0.7515, 0.7505, 0.75  , 0.748 , 0.7476,\n",
       "            0.7466, 0.746 , 0.745 , 0.7446, 0.744 , 0.743 , 0.7417, 0.741 ,\n",
       "            0.7407, 0.7383, 0.7373, 0.7354, 0.735 , 0.7344, 0.7334, 0.7295,\n",
       "            0.7285, 0.728 , 0.7275, 0.727 , 0.7266, 0.726 , 0.7246, 0.723 ,\n",
       "            0.7207, 0.7197, 0.719 , 0.7188, 0.717 , 0.7163, 0.716 , 0.7153,\n",
       "            0.7144, 0.714 , 0.7134, 0.713 , 0.711 , 0.7104, 0.71  , 0.7095,\n",
       "            0.708 , 0.7065, 0.706 , 0.7056, 0.702 , 0.7017, 0.701 , 0.6973,\n",
       "            0.695 , 0.694 , 0.6934, 0.693 , 0.6895, 0.687 , 0.6865, 0.686 ,\n",
       "            0.6855, 0.6836, 0.6807, 0.6777, 0.676 , 0.6753, 0.6743, 0.6724,\n",
       "            0.6704, 0.6694, 0.668 , 0.667 , 0.6665, 0.6655, 0.6606, 0.6597,\n",
       "            0.659 , 0.656 , 0.6484, 0.647 , 0.6416, 0.634 , 0.632 , 0.631 ,\n",
       "            0.6294, 0.6274, 0.623 , 0.621 , 0.6196, 0.6074, 0.604 , 0.599 ,\n",
       "            0.594 , 0.5938, 0.5933, 0.5854, 0.5845, 0.584 , 0.5815, 0.573 ,\n",
       "            0.5723, 0.572 , 0.569 , 0.5654, 0.5635, 0.539 , 0.537 , 0.5356,\n",
       "            0.5273, 0.527 , 0.525 , 0.5215, 0.511 , 0.5103, 0.506 , 0.503 ,\n",
       "            0.5015, 0.501 , 0.4866, 0.484 , 0.478 , 0.475 , 0.4707, 0.4688,\n",
       "            0.4668, 0.46  , 0.4573, 0.4539, 0.4426, 0.4375, 0.4338, 0.4307,\n",
       "            0.4277, 0.4272, 0.4253, 0.4248, 0.4138, 0.403 , 0.4006, 0.4001,\n",
       "            0.3992, 0.3833, 0.3596, 0.3552, 0.348 , 0.336 , 0.3262, 0.309 ,\n",
       "            0.2925, 0.2908], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.75, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.1015625, 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.140625 , 0.140625 , 0.1484375, 0.1484375, 0.15625  , 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.21875  , 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2734375, 0.2734375, 0.2734375, 0.2734375, 0.28125  ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3125   , 0.3125   , 0.328125 ,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.34375  , 0.359375 ,\n",
       "            0.359375 , 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.390625 , 0.3984375, 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5      , 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40983605, 0.4262295 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.59016395, 0.60655737, 0.6147541 , 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.647541  , 0.647541  ,\n",
       "            0.647541  , 0.6557377 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.923 , 0.917 , 0.909 , 0.8975, 0.896 , 0.8945, 0.886 ,\n",
       "            0.8833, 0.8706, 0.87  , 0.8657, 0.8643, 0.86  , 0.858 , 0.8555,\n",
       "            0.853 , 0.852 , 0.85  , 0.848 , 0.8477, 0.847 , 0.8447, 0.844 ,\n",
       "            0.842 , 0.841 , 0.84  , 0.8374, 0.835 , 0.833 , 0.832 , 0.827 ,\n",
       "            0.825 , 0.8223, 0.8213, 0.8203, 0.82  , 0.8164, 0.816 , 0.8135,\n",
       "            0.808 , 0.8076, 0.8047, 0.8037, 0.8027, 0.801 , 0.797 , 0.7964,\n",
       "            0.7954, 0.793 , 0.792 , 0.7905, 0.79  , 0.7896, 0.7886, 0.7856,\n",
       "            0.7847, 0.783 , 0.7827, 0.7817, 0.779 , 0.7783, 0.778 , 0.7773,\n",
       "            0.777 , 0.7764, 0.776 , 0.7744, 0.774 , 0.772 , 0.7715, 0.771 ,\n",
       "            0.77  , 0.7695, 0.769 , 0.7686, 0.766 , 0.7656, 0.7646, 0.7637,\n",
       "            0.763 , 0.762 , 0.76  , 0.758 , 0.757 , 0.7554, 0.7544, 0.7534,\n",
       "            0.753 , 0.7524, 0.75  , 0.7485, 0.747 , 0.7456, 0.7446, 0.743 ,\n",
       "            0.7417, 0.7407, 0.7397, 0.7393, 0.739 , 0.737 , 0.736 , 0.735 ,\n",
       "            0.7344, 0.7334, 0.7324, 0.732 , 0.731 , 0.7305, 0.73  , 0.7295,\n",
       "            0.727 , 0.726 , 0.723 , 0.7227, 0.72  , 0.7173, 0.715 , 0.714 ,\n",
       "            0.7134, 0.713 , 0.7124, 0.711 , 0.7095, 0.707 , 0.706 , 0.705 ,\n",
       "            0.701 , 0.6987, 0.698 , 0.6973, 0.696 , 0.6953, 0.6934, 0.6895,\n",
       "            0.689 , 0.688 , 0.6855, 0.685 , 0.6826, 0.679 , 0.678 , 0.673 ,\n",
       "            0.671 , 0.6646, 0.662 , 0.6597, 0.6543, 0.654 , 0.651 , 0.6484,\n",
       "            0.6426, 0.636 , 0.635 , 0.6226, 0.6187, 0.6167, 0.61  , 0.6094,\n",
       "            0.608 , 0.603 , 0.601 , 0.597 , 0.5933, 0.588 , 0.585 , 0.5845,\n",
       "            0.5835, 0.5796, 0.5747, 0.549 , 0.5474, 0.5454, 0.5425, 0.5376,\n",
       "            0.537 , 0.533 , 0.5205, 0.52  , 0.5186, 0.515 , 0.5137, 0.51  ,\n",
       "            0.4946, 0.4912, 0.486 , 0.4827, 0.4775, 0.4763, 0.4749, 0.4727,\n",
       "            0.4644, 0.4604, 0.4485, 0.4438, 0.4392, 0.436 , 0.4326, 0.4314,\n",
       "            0.4307, 0.4302, 0.421 , 0.408 , 0.4048, 0.4045, 0.4036, 0.3894,\n",
       "            0.3638, 0.3567, 0.3499, 0.3423, 0.327 , 0.3093, 0.2925, 0.2908],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7578125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.1015625, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.140625 , 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.234375 , 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2578125, 0.2578125, 0.265625 , 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.2890625, 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.4296875, 0.4375   , 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.29508197, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40983605, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59016395, 0.59836066, 0.6147541 , 0.6229508 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.73770493, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.936 , 0.9307, 0.93  , 0.9233, 0.912 , 0.9106, 0.9097,\n",
       "            0.9023, 0.8994, 0.8877, 0.8867, 0.8833, 0.8813, 0.8765, 0.8755,\n",
       "            0.8726, 0.871 , 0.8696, 0.8677, 0.865 , 0.8647, 0.862 , 0.8613,\n",
       "            0.86  , 0.859 , 0.8574, 0.856 , 0.8525, 0.85  , 0.8496, 0.8467,\n",
       "            0.8438, 0.8423, 0.8413, 0.8394, 0.839 , 0.838 , 0.8364, 0.836 ,\n",
       "            0.8315, 0.826 , 0.824 , 0.822 , 0.8213, 0.821 , 0.818 , 0.817 ,\n",
       "            0.814 , 0.8125, 0.812 , 0.8115, 0.811 , 0.8096, 0.8086, 0.808 ,\n",
       "            0.8076, 0.806 , 0.805 , 0.804 , 0.8027, 0.8022, 0.802 , 0.8013,\n",
       "            0.8   , 0.7993, 0.7983, 0.798 , 0.7974, 0.7964, 0.796 , 0.7954,\n",
       "            0.794 , 0.7925, 0.7915, 0.791 , 0.7905, 0.7896, 0.789 , 0.7886,\n",
       "            0.7876, 0.786 , 0.7856, 0.785 , 0.7847, 0.784 , 0.7837, 0.783 ,\n",
       "            0.7827, 0.7793, 0.778 , 0.7773, 0.777 , 0.775 , 0.7744, 0.7725,\n",
       "            0.7715, 0.7705, 0.769 , 0.768 , 0.7666, 0.7656, 0.7646, 0.7617,\n",
       "            0.761 , 0.7603, 0.7583, 0.7573, 0.757 , 0.7563, 0.756 , 0.755 ,\n",
       "            0.7544, 0.754 , 0.753 , 0.7524, 0.7515, 0.751 , 0.7505, 0.7495,\n",
       "            0.746 , 0.745 , 0.7446, 0.7437, 0.743 , 0.7417, 0.739 , 0.7373,\n",
       "            0.737 , 0.736 , 0.735 , 0.7324, 0.7314, 0.7285, 0.726 , 0.724 ,\n",
       "            0.723 , 0.7207, 0.719 , 0.7188, 0.718 , 0.716 , 0.713 , 0.7104,\n",
       "            0.709 , 0.7065, 0.703 , 0.7026, 0.6973, 0.697 , 0.694 , 0.6895,\n",
       "            0.6846, 0.682 , 0.6807, 0.6777, 0.675 , 0.6724, 0.67  , 0.6587,\n",
       "            0.652 , 0.65  , 0.6377, 0.6333, 0.633 , 0.6265, 0.6245, 0.622 ,\n",
       "            0.6196, 0.6167, 0.6113, 0.6055, 0.6035, 0.597 , 0.596 , 0.592 ,\n",
       "            0.587 , 0.5596, 0.558 , 0.556 , 0.549 , 0.548 , 0.5444, 0.5317,\n",
       "            0.5303, 0.5283, 0.5254, 0.524 , 0.519 , 0.5186, 0.5034, 0.4998,\n",
       "            0.4949, 0.491 , 0.4854, 0.4844, 0.4832, 0.483 , 0.4714, 0.4673,\n",
       "            0.455 , 0.4504, 0.4453, 0.442 , 0.4385, 0.4368, 0.4365, 0.436 ,\n",
       "            0.43  , 0.413 , 0.4097, 0.4094, 0.4082, 0.3945, 0.368 , 0.3594,\n",
       "            0.3525, 0.3467, 0.3284, 0.3103, 0.293 , 0.291 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7734375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.1171875,\n",
       "            0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.234375 , 0.234375 , 0.2421875,\n",
       "            0.2421875, 0.25     , 0.25     , 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.2890625, 0.2890625, 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.3203125, 0.328125 , 0.3359375, 0.3359375, 0.3515625,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.46875  ,\n",
       "            0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.37704918,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40983605, 0.40983605,\n",
       "            0.40983605, 0.40983605, 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.7704918 , 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.947 , 0.9424, 0.9414, 0.9355, 0.9253, 0.924 , 0.923 ,\n",
       "            0.916 , 0.9136, 0.903 , 0.9014, 0.901 , 0.899 , 0.8965, 0.8916,\n",
       "            0.888 , 0.8867, 0.8857, 0.8833, 0.882 , 0.8813, 0.8804, 0.878 ,\n",
       "            0.877 , 0.876 , 0.8745, 0.874 , 0.8726, 0.868 , 0.866 , 0.8657,\n",
       "            0.8643, 0.861 , 0.86  , 0.859 , 0.8584, 0.8555, 0.855 , 0.854 ,\n",
       "            0.848 , 0.8433, 0.843 , 0.8423, 0.8394, 0.8384, 0.8374, 0.836 ,\n",
       "            0.8315, 0.831 , 0.8306, 0.83  , 0.8286, 0.8276, 0.8267, 0.8247,\n",
       "            0.8237, 0.823 , 0.8223, 0.8213, 0.82  , 0.8193, 0.8184, 0.816 ,\n",
       "            0.8154, 0.8145, 0.814 , 0.813 , 0.8105, 0.81  , 0.8096, 0.8086,\n",
       "            0.808 , 0.8066, 0.804 , 0.8037, 0.803 , 0.8027, 0.8013, 0.8003,\n",
       "            0.799 , 0.798 , 0.796 , 0.7935, 0.7925, 0.7905, 0.79  , 0.7896,\n",
       "            0.789 , 0.7886, 0.785 , 0.7847, 0.783 , 0.781 , 0.7803, 0.78  ,\n",
       "            0.779 , 0.778 , 0.777 , 0.7764, 0.7744, 0.774 , 0.7734, 0.7725,\n",
       "            0.7715, 0.771 , 0.77  , 0.767 , 0.7656, 0.7646, 0.7637, 0.763 ,\n",
       "            0.7627, 0.762 , 0.7603, 0.756 , 0.7544, 0.754 , 0.751 , 0.75  ,\n",
       "            0.746 , 0.7446, 0.742 , 0.741 , 0.7407, 0.7393, 0.739 , 0.7373,\n",
       "            0.737 , 0.736 , 0.7305, 0.7295, 0.729 , 0.7236, 0.723 , 0.72  ,\n",
       "            0.719 , 0.716 , 0.715 , 0.708 , 0.706 , 0.701 , 0.7   , 0.6963,\n",
       "            0.6953, 0.6885, 0.674 , 0.667 , 0.6646, 0.6533, 0.6504, 0.6475,\n",
       "            0.642 , 0.641 , 0.636 , 0.632 , 0.625 , 0.6216, 0.619 , 0.618 ,\n",
       "            0.61  , 0.6094, 0.6035, 0.599 , 0.572 , 0.5703, 0.5693, 0.567 ,\n",
       "            0.562 , 0.559 , 0.5566, 0.542 , 0.541 , 0.5386, 0.5356, 0.5293,\n",
       "            0.528 , 0.5127, 0.5083, 0.5044, 0.4998, 0.4966, 0.4937, 0.493 ,\n",
       "            0.4922, 0.4797, 0.475 , 0.4624, 0.458 , 0.4521, 0.4487, 0.4448,\n",
       "            0.4434, 0.4429, 0.4426, 0.4387, 0.4192, 0.4153, 0.4138, 0.4019,\n",
       "            0.3735, 0.3625, 0.3562, 0.354 , 0.3306, 0.3123, 0.2944, 0.2925],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.09375  , 0.09375  , 0.109375 , 0.1171875, 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.15625  , 0.15625  , 0.1640625, 0.1640625, 0.1640625,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.2421875, 0.2421875, 0.2578125, 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.2734375, 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.3203125,\n",
       "            0.3359375, 0.3359375, 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.375    , 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36885247, 0.37704918, 0.37704918,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.43442622, 0.44262296, 0.45081967, 0.45081967,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.4918033 ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.63114756,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.956 , 0.952 , 0.951 , 0.9463, 0.9365, 0.9355, 0.934 ,\n",
       "            0.928 , 0.926 , 0.916 , 0.9146, 0.914 , 0.9126, 0.91  , 0.9062,\n",
       "            0.9053, 0.902 , 0.9014, 0.9   , 0.8975, 0.896 , 0.8955, 0.895 ,\n",
       "            0.892 , 0.891 , 0.8906, 0.889 , 0.8877, 0.883 , 0.8813, 0.881 ,\n",
       "            0.8804, 0.8765, 0.875 , 0.874 , 0.872 , 0.8716, 0.871 , 0.8706,\n",
       "            0.869 , 0.8633, 0.859 , 0.8584, 0.8564, 0.855 , 0.854 , 0.8535,\n",
       "            0.8486, 0.8477, 0.846 , 0.8447, 0.844 , 0.8438, 0.8423, 0.841 ,\n",
       "            0.84  , 0.839 , 0.8384, 0.8374, 0.837 , 0.8364, 0.8335, 0.8325,\n",
       "            0.832 , 0.831 , 0.8306, 0.83  , 0.8296, 0.8286, 0.8276, 0.827 ,\n",
       "            0.8267, 0.8257, 0.824 , 0.8237, 0.8228, 0.822 , 0.8213, 0.821 ,\n",
       "            0.8193, 0.819 , 0.8154, 0.815 , 0.8135, 0.811 , 0.81  , 0.8096,\n",
       "            0.8086, 0.807 , 0.8057, 0.803 , 0.8027, 0.801 , 0.8003, 0.8   ,\n",
       "            0.799 , 0.7983, 0.797 , 0.7964, 0.795 , 0.7944, 0.794 , 0.793 ,\n",
       "            0.7915, 0.791 , 0.7905, 0.79  , 0.7896, 0.7886, 0.788 , 0.7866,\n",
       "            0.786 , 0.785 , 0.784 , 0.782 , 0.7817, 0.7812, 0.7803, 0.7783,\n",
       "            0.7754, 0.7725, 0.7715, 0.769 , 0.7676, 0.7627, 0.762 , 0.7593,\n",
       "            0.7583, 0.758 , 0.755 , 0.7524, 0.75  , 0.749 , 0.745 , 0.742 ,\n",
       "            0.74  , 0.7373, 0.737 , 0.736 , 0.7334, 0.7324, 0.731 , 0.722 ,\n",
       "            0.7197, 0.7173, 0.715 , 0.7114, 0.706 , 0.689 , 0.682 , 0.6797,\n",
       "            0.6694, 0.6685, 0.6616, 0.658 , 0.6523, 0.6504, 0.6475, 0.6396,\n",
       "            0.639 , 0.635 , 0.6313, 0.623 , 0.616 , 0.612 , 0.59  , 0.5815,\n",
       "            0.5806, 0.5786, 0.576 , 0.571 , 0.57  , 0.5537, 0.5527, 0.549 ,\n",
       "            0.548 , 0.5474, 0.54  , 0.538 , 0.5225, 0.518 , 0.5146, 0.512 ,\n",
       "            0.5093, 0.503 , 0.489 , 0.4841, 0.471 , 0.467 , 0.46  , 0.4568,\n",
       "            0.452 , 0.4512, 0.4507, 0.4492, 0.4482, 0.4268, 0.422 , 0.4219,\n",
       "            0.4207, 0.4106, 0.3809, 0.3667, 0.3635, 0.3608, 0.334 , 0.315 ,\n",
       "            0.2974, 0.2952], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8203125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  , 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.234375 , 0.25     , 0.2578125,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.2890625, 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.22131148, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.28688523, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.45081967, 0.45081967, 0.45081967,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.6229508 , 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.964 , 0.9604, 0.9595, 0.955 , 0.9463, 0.9453, 0.9443,\n",
       "            0.939 , 0.9365, 0.9277, 0.9263, 0.926 , 0.925 , 0.9224, 0.919 ,\n",
       "            0.918 , 0.9175, 0.9146, 0.914 , 0.9126, 0.91  , 0.909 , 0.908 ,\n",
       "            0.9077, 0.905 , 0.9043, 0.903 , 0.902 , 0.9014, 0.896 , 0.895 ,\n",
       "            0.894 , 0.891 , 0.8906, 0.89  , 0.888 , 0.887 , 0.8853, 0.8843,\n",
       "            0.8833, 0.8774, 0.8745, 0.8735, 0.873 , 0.872 , 0.8716, 0.8696,\n",
       "            0.869 , 0.8687, 0.8647, 0.8643, 0.8633, 0.863 , 0.8613, 0.861 ,\n",
       "            0.86  , 0.8594, 0.8584, 0.8574, 0.8564, 0.8555, 0.8545, 0.854 ,\n",
       "            0.8535, 0.853 , 0.8525, 0.8496, 0.849 , 0.8486, 0.848 , 0.8477,\n",
       "            0.847 , 0.8457, 0.8447, 0.8438, 0.8433, 0.841 , 0.8403, 0.84  ,\n",
       "            0.8384, 0.838 , 0.8374, 0.836 , 0.8354, 0.835 , 0.833 , 0.8315,\n",
       "            0.83  , 0.8276, 0.8267, 0.8257, 0.824 , 0.823 , 0.8213, 0.8203,\n",
       "            0.82  , 0.8193, 0.8174, 0.8164, 0.816 , 0.815 , 0.814 , 0.8125,\n",
       "            0.812 , 0.8105, 0.81  , 0.8086, 0.808 , 0.807 , 0.8066, 0.806 ,\n",
       "            0.8057, 0.805 , 0.8047, 0.8022, 0.8003, 0.799 , 0.798 , 0.797 ,\n",
       "            0.7954, 0.7935, 0.7896, 0.7886, 0.786 , 0.784 , 0.781 , 0.78  ,\n",
       "            0.779 , 0.778 , 0.7773, 0.777 , 0.776 , 0.7744, 0.774 , 0.7725,\n",
       "            0.7686, 0.768 , 0.767 , 0.761 , 0.76  , 0.757 , 0.7563, 0.7534,\n",
       "            0.752 , 0.7505, 0.7495, 0.742 , 0.7383, 0.738 , 0.7373, 0.7334,\n",
       "            0.7266, 0.723 , 0.7046, 0.6973, 0.695 , 0.6865, 0.6855, 0.676 ,\n",
       "            0.675 , 0.6733, 0.6675, 0.6646, 0.6626, 0.6562, 0.655 , 0.65  ,\n",
       "            0.6455, 0.637 , 0.636 , 0.6294, 0.625 , 0.608 , 0.594 , 0.5933,\n",
       "            0.5913, 0.591 , 0.5845, 0.584 , 0.5664, 0.5654, 0.5615, 0.561 ,\n",
       "            0.56  , 0.5522, 0.55  , 0.534 , 0.5293, 0.529 , 0.5264, 0.5205,\n",
       "            0.515 , 0.514 , 0.5005, 0.495 , 0.4817, 0.4783, 0.4702, 0.467 ,\n",
       "            0.462 , 0.4617, 0.461 , 0.4607, 0.4587, 0.437 , 0.432 , 0.4314,\n",
       "            0.4302, 0.422 , 0.3909, 0.3755, 0.3745, 0.369 , 0.3408, 0.3215,\n",
       "            0.3037, 0.3013], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.828125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.1015625, 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.15625  , 0.15625  , 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.21875  , 0.21875  , 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.2421875, 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.28125  , 0.28125  , 0.28125  , 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3125   , 0.328125 , 0.328125 , 0.3359375, 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.359375 , 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.40625  , 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.21311475, 0.22131148, 0.23770492, 0.25409836, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.28688523,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.3852459 , 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40163934, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.6147541 , 0.6229508 , 0.6393443 ,\n",
       "            0.6393443 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.75409836, 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.78688526, 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9707, 0.9673, 0.9663, 0.963 , 0.9546, 0.9536, 0.953 ,\n",
       "            0.948 , 0.9463, 0.938 , 0.9365, 0.936 , 0.9355, 0.933 , 0.93  ,\n",
       "            0.929 , 0.928 , 0.926 , 0.9253, 0.9243, 0.922 , 0.921 , 0.92  ,\n",
       "            0.9194, 0.9165, 0.916 , 0.9146, 0.914 , 0.9087, 0.908 , 0.907 ,\n",
       "            0.9062, 0.906 , 0.9043, 0.9033, 0.9014, 0.901 , 0.8984, 0.897 ,\n",
       "            0.896 , 0.89  , 0.888 , 0.886 , 0.885 , 0.883 , 0.882 , 0.88  ,\n",
       "            0.8794, 0.878 , 0.877 , 0.8755, 0.8745, 0.8735, 0.873 , 0.8726,\n",
       "            0.872 , 0.8716, 0.87  , 0.8696, 0.869 , 0.8677, 0.8667, 0.8657,\n",
       "            0.865 , 0.864 , 0.8633, 0.863 , 0.862 , 0.8613, 0.8604, 0.8594,\n",
       "            0.8584, 0.857 , 0.8555, 0.855 , 0.854 , 0.8535, 0.853 , 0.8525,\n",
       "            0.8516, 0.85  , 0.8496, 0.847 , 0.8457, 0.8447, 0.8433, 0.842 ,\n",
       "            0.8413, 0.8403, 0.839 , 0.8374, 0.837 , 0.8364, 0.836 , 0.8354,\n",
       "            0.8345, 0.8335, 0.832 , 0.83  , 0.8286, 0.828 , 0.8276, 0.8257,\n",
       "            0.8247, 0.824 , 0.8237, 0.823 , 0.8228, 0.822 , 0.821 , 0.8154,\n",
       "            0.815 , 0.814 , 0.813 , 0.8115, 0.811 , 0.806 , 0.804 , 0.8027,\n",
       "            0.8003, 0.799 , 0.796 , 0.7954, 0.795 , 0.7925, 0.7905, 0.7896,\n",
       "            0.789 , 0.7847, 0.784 , 0.777 , 0.776 , 0.7754, 0.772 , 0.7715,\n",
       "            0.7695, 0.7676, 0.767 , 0.766 , 0.762 , 0.7583, 0.754 , 0.7534,\n",
       "            0.7515, 0.741 , 0.7397, 0.719 , 0.7124, 0.7095, 0.704 , 0.701 ,\n",
       "            0.6914, 0.69  , 0.6885, 0.683 , 0.6787, 0.6772, 0.673 , 0.669 ,\n",
       "            0.664 , 0.659 , 0.651 , 0.65  , 0.641 , 0.637 , 0.6255, 0.605 ,\n",
       "            0.6025, 0.5977, 0.5957, 0.577 , 0.5767, 0.5737, 0.572 , 0.5713,\n",
       "            0.563 , 0.5596, 0.545 , 0.5444, 0.5386, 0.537 , 0.5303, 0.5264,\n",
       "            0.524 , 0.5234, 0.51  , 0.5044, 0.49  , 0.4873, 0.478 , 0.475 ,\n",
       "            0.4695, 0.469 , 0.4688, 0.465 , 0.4443, 0.439 , 0.438 , 0.4368,\n",
       "            0.4314, 0.3984, 0.3857, 0.3782, 0.3738, 0.3438, 0.324 , 0.3062,\n",
       "            0.3037], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.828125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.125    , 0.1328125, 0.140625 , 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.2890625,\n",
       "            0.2890625, 0.296875 , 0.296875 , 0.3046875, 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.3828125, 0.390625 , 0.4140625, 0.421875 , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.4921875, 0.5      , 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.19672132, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.24590164, 0.25409836, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.44262296, 0.46721312, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.59016395, 0.60655737,\n",
       "            0.6229508 , 0.63114756, 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.795082  , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.975 , 0.972 , 0.971 , 0.9683, 0.9604, 0.96  , 0.959 ,\n",
       "            0.955 , 0.953 , 0.946 , 0.9443, 0.9434, 0.941 , 0.938 , 0.9375,\n",
       "            0.936 , 0.934 , 0.9326, 0.9307, 0.9297, 0.928 , 0.9253, 0.9243,\n",
       "            0.924 , 0.9233, 0.923 , 0.9185, 0.9175, 0.9165, 0.9155, 0.9146,\n",
       "            0.9136, 0.913 , 0.9116, 0.911 , 0.908 , 0.9062, 0.906 , 0.9004,\n",
       "            0.8994, 0.8975, 0.8965, 0.896 , 0.8926, 0.892 , 0.8916, 0.891 ,\n",
       "            0.89  , 0.8896, 0.8877, 0.8867, 0.8857, 0.8853, 0.885 , 0.8843,\n",
       "            0.884 , 0.8823, 0.882 , 0.8813, 0.8804, 0.88  , 0.879 , 0.8784,\n",
       "            0.8774, 0.877 , 0.8765, 0.876 , 0.8755, 0.875 , 0.8745, 0.874 ,\n",
       "            0.8735, 0.873 , 0.8716, 0.8706, 0.87  , 0.8677, 0.867 , 0.866 ,\n",
       "            0.865 , 0.8647, 0.864 , 0.8633, 0.863 , 0.862 , 0.8594, 0.8584,\n",
       "            0.858 , 0.8555, 0.854 , 0.853 , 0.852 , 0.8506, 0.8496, 0.848 ,\n",
       "            0.8477, 0.847 , 0.8467, 0.846 , 0.8457, 0.845 , 0.8447, 0.844 ,\n",
       "            0.8438, 0.8413, 0.84  , 0.839 , 0.838 , 0.8374, 0.837 , 0.8364,\n",
       "            0.836 , 0.8354, 0.835 , 0.8345, 0.8335, 0.829 , 0.8276, 0.827 ,\n",
       "            0.8267, 0.8257, 0.824 , 0.82  , 0.817 , 0.8154, 0.813 , 0.8096,\n",
       "            0.809 , 0.807 , 0.806 , 0.803 , 0.8027, 0.7983, 0.797 , 0.791 ,\n",
       "            0.7905, 0.7886, 0.784 , 0.782 , 0.781 , 0.7803, 0.78  , 0.778 ,\n",
       "            0.7744, 0.7676, 0.766 , 0.7534, 0.753 , 0.7314, 0.7246, 0.7217,\n",
       "            0.718 , 0.714 , 0.7046, 0.701 , 0.6963, 0.6904, 0.6895, 0.6875,\n",
       "            0.6807, 0.6763, 0.6704, 0.6626, 0.661 , 0.6514, 0.6475, 0.639 ,\n",
       "            0.616 , 0.6147, 0.6123, 0.6084, 0.6055, 0.587 , 0.5864, 0.584 ,\n",
       "            0.581 , 0.5806, 0.5723, 0.568 , 0.5576, 0.553 , 0.5474, 0.546 ,\n",
       "            0.5386, 0.5356, 0.532 , 0.5317, 0.5186, 0.512 , 0.498 , 0.4956,\n",
       "            0.4856, 0.4827, 0.478 , 0.477 , 0.4766, 0.4763, 0.472 , 0.4517,\n",
       "            0.446 , 0.4448, 0.4436, 0.44  , 0.4055, 0.3945, 0.3833, 0.3792,\n",
       "            0.3481, 0.3281, 0.31  , 0.3076], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.84375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.125    , 0.140625 , 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.25     , 0.2578125, 0.2578125, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.2734375, 0.28125  , 0.2890625, 0.2890625,\n",
       "            0.2890625, 0.296875 , 0.296875 , 0.296875 , 0.3046875, 0.3046875,\n",
       "            0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.3515625, 0.359375 , 0.359375 , 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4375   , 0.4375   , 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.23770492, 0.24590164, 0.25409836, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.36885247, 0.36885247, 0.3852459 , 0.39344263, 0.39344263,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.4918033 , 0.4918033 , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.7704918 , 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.979 , 0.9766, 0.9756, 0.9727, 0.966 , 0.9653, 0.9644,\n",
       "            0.961 , 0.9595, 0.9526, 0.951 , 0.95  , 0.948 , 0.9453, 0.945 ,\n",
       "            0.9434, 0.942 , 0.9404, 0.9385, 0.9375, 0.9365, 0.936 , 0.9336,\n",
       "            0.933 , 0.9326, 0.9316, 0.931 , 0.9307, 0.9277, 0.926 , 0.9253,\n",
       "            0.9243, 0.924 , 0.923 , 0.9224, 0.9214, 0.921 , 0.9204, 0.9175,\n",
       "            0.9155, 0.9146, 0.9097, 0.909 , 0.908 , 0.9077, 0.9062, 0.906 ,\n",
       "            0.9023, 0.902 , 0.9014, 0.901 , 0.898 , 0.8975, 0.8965, 0.896 ,\n",
       "            0.8955, 0.895 , 0.894 , 0.8936, 0.893 , 0.891 , 0.8906, 0.89  ,\n",
       "            0.889 , 0.888 , 0.8877, 0.887 , 0.886 , 0.8857, 0.8853, 0.8843,\n",
       "            0.8833, 0.883 , 0.881 , 0.8794, 0.8784, 0.8774, 0.877 , 0.8765,\n",
       "            0.876 , 0.8755, 0.875 , 0.874 , 0.873 , 0.8726, 0.8706, 0.87  ,\n",
       "            0.8696, 0.8667, 0.866 , 0.8657, 0.8647, 0.862 , 0.8613, 0.8604,\n",
       "            0.86  , 0.8594, 0.859 , 0.858 , 0.8574, 0.857 , 0.8564, 0.856 ,\n",
       "            0.854 , 0.8535, 0.8525, 0.852 , 0.8516, 0.8506, 0.8496, 0.849 ,\n",
       "            0.8486, 0.8477, 0.847 , 0.846 , 0.845 , 0.842 , 0.84  , 0.839 ,\n",
       "            0.8384, 0.838 , 0.8374, 0.8364, 0.832 , 0.8296, 0.828 , 0.826 ,\n",
       "            0.825 , 0.823 , 0.8223, 0.8213, 0.8193, 0.8154, 0.815 , 0.8115,\n",
       "            0.811 , 0.809 , 0.805 , 0.8037, 0.8003, 0.7964, 0.7944, 0.794 ,\n",
       "            0.793 , 0.7925, 0.7896, 0.7803, 0.78  , 0.7783, 0.7656, 0.7646,\n",
       "            0.743 , 0.7363, 0.7334, 0.7314, 0.726 , 0.7173, 0.7134, 0.713 ,\n",
       "            0.7095, 0.7017, 0.701 , 0.693 , 0.688 , 0.682 , 0.6743, 0.6724,\n",
       "            0.6616, 0.658 , 0.6523, 0.6274, 0.6245, 0.6226, 0.619 , 0.615 ,\n",
       "            0.596 , 0.5947, 0.591 , 0.59  , 0.5815, 0.5767, 0.5693, 0.562 ,\n",
       "            0.5557, 0.5547, 0.547 , 0.544 , 0.5405, 0.54  , 0.526 , 0.52  ,\n",
       "            0.5054, 0.503 , 0.4924, 0.4895, 0.4866, 0.4836, 0.4832, 0.4827,\n",
       "            0.478 , 0.458 , 0.452 , 0.4507, 0.4495, 0.4468, 0.4111, 0.4019,\n",
       "            0.3872, 0.3833, 0.3513, 0.3306, 0.3123, 0.3096], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8515625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.125    , 0.125    , 0.1328125, 0.1484375, 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.203125 , 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.21875  , 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.2578125, 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.2890625, 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.328125 ,\n",
       "            0.3359375, 0.3359375, 0.3515625, 0.359375 , 0.359375 , 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.2704918 , 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36885247,\n",
       "            0.36885247, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.55737704, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.6229508 , 0.6229508 , 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.71311474, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9824, 0.98  , 0.9795, 0.977 , 0.9707, 0.97  , 0.969 ,\n",
       "            0.9663, 0.965 , 0.9585, 0.957 , 0.956 , 0.9546, 0.9517, 0.95  ,\n",
       "            0.9487, 0.9478, 0.9453, 0.945 , 0.9434, 0.9414, 0.9404, 0.94  ,\n",
       "            0.9395, 0.9385, 0.938 , 0.936 , 0.9336, 0.933 , 0.9326, 0.9316,\n",
       "            0.9307, 0.93  , 0.9287, 0.926 , 0.924 , 0.923 , 0.9185, 0.918 ,\n",
       "            0.917 , 0.916 , 0.9146, 0.914 , 0.912 , 0.9116, 0.911 , 0.9106,\n",
       "            0.91  , 0.907 , 0.9067, 0.9062, 0.906 , 0.9053, 0.904 , 0.9033,\n",
       "            0.903 , 0.9014, 0.901 , 0.9   , 0.8994, 0.899 , 0.8984, 0.897 ,\n",
       "            0.8965, 0.896 , 0.8955, 0.894 , 0.8916, 0.8906, 0.8887, 0.888 ,\n",
       "            0.887 , 0.8867, 0.886 , 0.8843, 0.8833, 0.883 , 0.882 , 0.8813,\n",
       "            0.881 , 0.878 , 0.8774, 0.877 , 0.8765, 0.876 , 0.873 , 0.8726,\n",
       "            0.872 , 0.8716, 0.871 , 0.8706, 0.87  , 0.8687, 0.868 , 0.8667,\n",
       "            0.8657, 0.865 , 0.864 , 0.863 , 0.8623, 0.861 , 0.8594, 0.859 ,\n",
       "            0.8574, 0.8564, 0.8535, 0.8516, 0.8506, 0.8496, 0.849 , 0.848 ,\n",
       "            0.844 , 0.8413, 0.84  , 0.839 , 0.837 , 0.8364, 0.835 , 0.8345,\n",
       "            0.8335, 0.8315, 0.831 , 0.828 , 0.8276, 0.827 , 0.824 , 0.8237,\n",
       "            0.821 , 0.819 , 0.8184, 0.816 , 0.812 , 0.808 , 0.8076, 0.8066,\n",
       "            0.806 , 0.805 , 0.8047, 0.804 , 0.7935, 0.793 , 0.79  , 0.7783,\n",
       "            0.7764, 0.755 , 0.7485, 0.745 , 0.739 , 0.731 , 0.7256, 0.724 ,\n",
       "            0.722 , 0.7153, 0.7134, 0.7046, 0.7   , 0.694 , 0.6865, 0.684 ,\n",
       "            0.672 , 0.669 , 0.6665, 0.6396, 0.6353, 0.633 , 0.631 , 0.626 ,\n",
       "            0.607 , 0.6064, 0.6055, 0.601 , 0.5996, 0.592 , 0.586 , 0.5835,\n",
       "            0.5713, 0.565 , 0.5645, 0.5566, 0.554 , 0.55  , 0.549 , 0.5356,\n",
       "            0.5293, 0.514 , 0.512 , 0.501 , 0.498 , 0.4966, 0.4922, 0.4917,\n",
       "            0.491 , 0.4858, 0.4663, 0.46  , 0.4585, 0.4573, 0.4565, 0.4194,\n",
       "            0.4119, 0.3933, 0.39  , 0.3567, 0.3357, 0.3174, 0.3145],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8828125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.109375 , 0.109375 , 0.109375 , 0.125    , 0.125    , 0.1328125,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.25     , 0.2578125, 0.2578125, 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.2890625, 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.296875 , 0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.328125 , 0.328125 , 0.328125 , 0.3359375, 0.3359375, 0.34375  ,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.19672132, 0.20491803, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.29508197, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.36885247, 0.3852459 , 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.5       , 0.5163934 , 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.704918  , 0.72131145,\n",
       "            0.7295082 , 0.74590164, 0.74590164, 0.75409836, 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.91803277, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9854, 0.9834, 0.9824, 0.9805, 0.9746, 0.974 , 0.9736,\n",
       "            0.971 , 0.969 , 0.964 , 0.9624, 0.9614, 0.96  , 0.9575, 0.956 ,\n",
       "            0.955 , 0.9546, 0.954 , 0.9517, 0.951 , 0.9497, 0.9478, 0.9473,\n",
       "            0.9463, 0.946 , 0.9453, 0.945 , 0.9434, 0.9404, 0.94  , 0.9395,\n",
       "            0.939 , 0.938 , 0.9365, 0.9336, 0.931 , 0.9307, 0.9272, 0.927 ,\n",
       "            0.926 , 0.9253, 0.9224, 0.9214, 0.9204, 0.92  , 0.9194, 0.9185,\n",
       "            0.9165, 0.916 , 0.9155, 0.915 , 0.913 , 0.9116, 0.911 , 0.9106,\n",
       "            0.9097, 0.9087, 0.908 , 0.9067, 0.9062, 0.906 , 0.9053, 0.9043,\n",
       "            0.904 , 0.9014, 0.901 , 0.899 , 0.8984, 0.8975, 0.897 , 0.8965,\n",
       "            0.8955, 0.8936, 0.893 , 0.8926, 0.8916, 0.891 , 0.888 , 0.8877,\n",
       "            0.8867, 0.885 , 0.884 , 0.8833, 0.883 , 0.8823, 0.882 , 0.881 ,\n",
       "            0.88  , 0.879 , 0.8774, 0.877 , 0.876 , 0.8755, 0.8745, 0.873 ,\n",
       "            0.872 , 0.8716, 0.871 , 0.87  , 0.869 , 0.868 , 0.867 , 0.865 ,\n",
       "            0.8623, 0.8613, 0.861 , 0.8604, 0.8594, 0.856 , 0.8525, 0.851 ,\n",
       "            0.8506, 0.8486, 0.848 , 0.8467, 0.846 , 0.845 , 0.8438, 0.842 ,\n",
       "            0.84  , 0.839 , 0.8384, 0.836 , 0.832 , 0.828 , 0.8228, 0.821 ,\n",
       "            0.8193, 0.8184, 0.817 , 0.8164, 0.806 , 0.805 , 0.802 , 0.7905,\n",
       "            0.7876, 0.766 , 0.76  , 0.759 , 0.757 , 0.751 , 0.744 , 0.7373,\n",
       "            0.7354, 0.734 , 0.7285, 0.725 , 0.7246, 0.7163, 0.712 , 0.7056,\n",
       "            0.698 , 0.6953, 0.682 , 0.681 , 0.6797, 0.652 , 0.6455, 0.643 ,\n",
       "            0.6426, 0.636 , 0.6177, 0.617 , 0.6167, 0.612 , 0.6094, 0.602 ,\n",
       "            0.598 , 0.5957, 0.5815, 0.5747, 0.574 , 0.5664, 0.5654, 0.5596,\n",
       "            0.5586, 0.5454, 0.5396, 0.5234, 0.5225, 0.5103, 0.5073, 0.502 ,\n",
       "            0.501 , 0.5   , 0.4944, 0.4758, 0.469 , 0.4673, 0.467 , 0.466 ,\n",
       "            0.4292, 0.4236, 0.4006, 0.3975, 0.3633, 0.342 , 0.3237, 0.3206],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8984375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.09375  , 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.109375 , 0.125    , 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.203125 , 0.21875  , 0.234375 , 0.234375 , 0.2578125,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.265625 , 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.2890625, 0.296875 , 0.296875 , 0.3046875, 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.359375 , 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.671875 , 0.6875   , 0.6953125, 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22950819, 0.23770492, 0.25409836, 0.25409836, 0.25409836,\n",
       "            0.2704918 , 0.27868852, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36065573, 0.36885247, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.4918033 , 0.5       , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.988 , 0.986 , 0.9854, 0.9834, 0.9785, 0.978 , 0.9775,\n",
       "            0.975 , 0.9736, 0.9688, 0.9673, 0.9663, 0.9653, 0.963 , 0.9624,\n",
       "            0.9614, 0.9604, 0.96  , 0.9595, 0.9575, 0.957 , 0.9556, 0.954 ,\n",
       "            0.953 , 0.9526, 0.952 , 0.951 , 0.9507, 0.9478, 0.947 , 0.9463,\n",
       "            0.9453, 0.945 , 0.9434, 0.9404, 0.938 , 0.9375, 0.935 , 0.9346,\n",
       "            0.9336, 0.933 , 0.93  , 0.9297, 0.9287, 0.927 , 0.9263, 0.9253,\n",
       "            0.925 , 0.9243, 0.924 , 0.9224, 0.921 , 0.9204, 0.9194, 0.919 ,\n",
       "            0.918 , 0.9175, 0.916 , 0.9155, 0.915 , 0.9146, 0.914 , 0.913 ,\n",
       "            0.911 , 0.9106, 0.91  , 0.908 , 0.907 , 0.9067, 0.9062, 0.906 ,\n",
       "            0.9043, 0.903 , 0.9023, 0.902 , 0.9014, 0.901 , 0.8984, 0.898 ,\n",
       "            0.8965, 0.8936, 0.893 , 0.8916, 0.8906, 0.89  , 0.8896, 0.889 ,\n",
       "            0.8887, 0.8877, 0.886 , 0.8857, 0.8853, 0.883 , 0.8823, 0.882 ,\n",
       "            0.8804, 0.8794, 0.8784, 0.8774, 0.8755, 0.873 , 0.872 , 0.8706,\n",
       "            0.87  , 0.869 , 0.8667, 0.863 , 0.862 , 0.8613, 0.8604, 0.859 ,\n",
       "            0.858 , 0.8574, 0.856 , 0.8555, 0.852 , 0.8516, 0.8496, 0.8477,\n",
       "            0.847 , 0.845 , 0.844 , 0.843 , 0.84  , 0.834 , 0.8335, 0.8315,\n",
       "            0.83  , 0.8296, 0.8286, 0.8276, 0.819 , 0.817 , 0.813 , 0.8022,\n",
       "            0.7983, 0.777 , 0.771 , 0.7705, 0.7676, 0.7617, 0.7554, 0.749 ,\n",
       "            0.746 , 0.7417, 0.737 , 0.7354, 0.7275, 0.724 , 0.717 , 0.709 ,\n",
       "            0.706 , 0.694 , 0.693 , 0.6904, 0.6626, 0.656 , 0.6533, 0.6465,\n",
       "            0.6274, 0.627 , 0.622 , 0.6196, 0.612 , 0.6104, 0.6055, 0.591 ,\n",
       "            0.584 , 0.5757, 0.575 , 0.5693, 0.5684, 0.5547, 0.549 , 0.5327,\n",
       "            0.5312, 0.519 , 0.5186, 0.516 , 0.5103, 0.51  , 0.509 , 0.503 ,\n",
       "            0.4844, 0.4775, 0.4766, 0.4756, 0.4744, 0.4377, 0.4338, 0.4077,\n",
       "            0.405 , 0.3699, 0.3484, 0.3298, 0.3267], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8984375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.125    , 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.234375 , 0.234375 , 0.2421875, 0.2578125, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.2734375, 0.28125  , 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.328125 , 0.328125 , 0.328125 , 0.3359375, 0.3515625,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.3828125, 0.390625 ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.671875 , 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.1557377 , 0.16393442, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.22131148, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.27868852, 0.28688523, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.3852459 , 0.40163934, 0.40163934, 0.4180328 , 0.4262295 ,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.45901638, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.48360655, 0.5       ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.6147541 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.74590164, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9897, 0.9883, 0.988 , 0.986 , 0.9814, 0.981 , 0.9805,\n",
       "            0.9785, 0.977 , 0.9727, 0.9717, 0.9707, 0.9697, 0.968 , 0.9673,\n",
       "            0.966 , 0.965 , 0.9644, 0.9624, 0.961 , 0.9595, 0.9585, 0.9575,\n",
       "            0.957 , 0.9565, 0.954 , 0.9526, 0.9517, 0.951 , 0.9497, 0.9473,\n",
       "            0.9443, 0.944 , 0.9424, 0.941 , 0.94  , 0.9385, 0.938 , 0.9375,\n",
       "            0.937 , 0.9365, 0.934 , 0.9336, 0.933 , 0.9326, 0.932 , 0.9316,\n",
       "            0.9307, 0.929 , 0.9287, 0.9277, 0.9272, 0.927 , 0.9263, 0.926 ,\n",
       "            0.9253, 0.925 , 0.9243, 0.924 , 0.9233, 0.923 , 0.9224, 0.922 ,\n",
       "            0.9204, 0.9194, 0.919 , 0.917 , 0.916 , 0.9155, 0.915 , 0.9146,\n",
       "            0.9126, 0.912 , 0.91  , 0.9087, 0.907 , 0.9062, 0.906 , 0.9033,\n",
       "            0.903 , 0.902 , 0.9014, 0.901 , 0.9   , 0.8994, 0.899 , 0.8984,\n",
       "            0.8975, 0.8965, 0.896 , 0.895 , 0.8926, 0.8916, 0.89  , 0.889 ,\n",
       "            0.888 , 0.887 , 0.8857, 0.883 , 0.882 , 0.8804, 0.8784, 0.877 ,\n",
       "            0.873 , 0.8726, 0.871 , 0.8696, 0.8687, 0.8667, 0.8623, 0.862 ,\n",
       "            0.8604, 0.86  , 0.859 , 0.8584, 0.8574, 0.8564, 0.8535, 0.851 ,\n",
       "            0.8467, 0.844 , 0.8413, 0.841 , 0.8403, 0.8384, 0.8306, 0.828 ,\n",
       "            0.8237, 0.8135, 0.809 , 0.788 , 0.782 , 0.779 , 0.7734, 0.767 ,\n",
       "            0.7603, 0.758 , 0.7573, 0.7544, 0.7485, 0.7466, 0.739 , 0.736 ,\n",
       "            0.7285, 0.7207, 0.7173, 0.706 , 0.7036, 0.7017, 0.674 , 0.6665,\n",
       "            0.664 , 0.6567, 0.638 , 0.6377, 0.637 , 0.632 , 0.63  , 0.6226,\n",
       "            0.622 , 0.6147, 0.6006, 0.5938, 0.5854, 0.5845, 0.5786, 0.5776,\n",
       "            0.5635, 0.5576, 0.5415, 0.54  , 0.5293, 0.5273, 0.5244, 0.5186,\n",
       "            0.518 , 0.517 , 0.511 , 0.4922, 0.4854, 0.485 , 0.4832, 0.482 ,\n",
       "            0.445 , 0.4426, 0.4138, 0.4111, 0.3752, 0.3533, 0.3342, 0.3308],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.90625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.125    , 0.1328125, 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.25     , 0.2578125, 0.2734375, 0.2734375, 0.28125  ,\n",
       "            0.28125  , 0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.328125 ,\n",
       "            0.328125 , 0.328125 , 0.3359375, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.14754099, 0.16393442, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.22131148, 0.23770492, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.3442623 , 0.36065573, 0.36065573, 0.36065573, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40163934,\n",
       "            0.40983605, 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.4918033 ,\n",
       "            0.5       , 0.5163934 , 0.52459013, 0.52459013, 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.59836066, 0.6229508 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.74590164, 0.74590164, 0.75409836, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.991 , 0.99  , 0.9897, 0.9883, 0.9844, 0.984 , 0.9834,\n",
       "            0.982 , 0.9805, 0.9766, 0.9756, 0.975 , 0.9746, 0.9736, 0.972 ,\n",
       "            0.971 , 0.97  , 0.969 , 0.9673, 0.966 , 0.9644, 0.9634, 0.963 ,\n",
       "            0.9624, 0.962 , 0.9614, 0.96  , 0.9585, 0.958 , 0.9575, 0.957 ,\n",
       "            0.9565, 0.9556, 0.953 , 0.95  , 0.9487, 0.9478, 0.9473, 0.946 ,\n",
       "            0.945 , 0.944 , 0.9434, 0.943 , 0.942 , 0.941 , 0.94  , 0.9395,\n",
       "            0.9385, 0.938 , 0.9375, 0.937 , 0.936 , 0.9346, 0.934 , 0.9336,\n",
       "            0.933 , 0.9326, 0.932 , 0.9316, 0.931 , 0.9307, 0.93  , 0.9287,\n",
       "            0.928 , 0.9277, 0.9253, 0.925 , 0.924 , 0.9233, 0.923 , 0.9224,\n",
       "            0.9214, 0.92  , 0.9185, 0.918 , 0.9175, 0.917 , 0.916 , 0.9155,\n",
       "            0.915 , 0.914 , 0.9126, 0.912 , 0.9116, 0.9106, 0.91  , 0.909 ,\n",
       "            0.908 , 0.9077, 0.907 , 0.9067, 0.906 , 0.9053, 0.9043, 0.902 ,\n",
       "            0.9014, 0.8994, 0.8984, 0.8975, 0.8965, 0.8955, 0.893 , 0.8926,\n",
       "            0.8916, 0.89  , 0.887 , 0.883 , 0.8813, 0.881 , 0.8794, 0.879 ,\n",
       "            0.877 , 0.8726, 0.8716, 0.8706, 0.87  , 0.8696, 0.869 , 0.867 ,\n",
       "            0.864 , 0.862 , 0.8584, 0.8564, 0.8545, 0.852 , 0.851 , 0.849 ,\n",
       "            0.842 , 0.8394, 0.8345, 0.8247, 0.82  , 0.7983, 0.7944, 0.7925,\n",
       "            0.79  , 0.7847, 0.779 , 0.7715, 0.7695, 0.768 , 0.7666, 0.76  ,\n",
       "            0.7573, 0.7505, 0.7476, 0.7397, 0.7324, 0.7285, 0.7197, 0.715 ,\n",
       "            0.7134, 0.6855, 0.6772, 0.676 , 0.675 , 0.6675, 0.65  , 0.6484,\n",
       "            0.648 , 0.643 , 0.6406, 0.636 , 0.6323, 0.6255, 0.6113, 0.6045,\n",
       "            0.604 , 0.5957, 0.589 , 0.588 , 0.574 , 0.568 , 0.5513, 0.5503,\n",
       "            0.5415, 0.5376, 0.534 , 0.5283, 0.528 , 0.527 , 0.5205, 0.502 ,\n",
       "            0.4963, 0.4946, 0.4924, 0.4915, 0.455 , 0.4546, 0.422 , 0.4197,\n",
       "            0.3828, 0.3606, 0.3416, 0.338 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0390625, 0.0390625, 0.0390625, 0.0546875, 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.109375 , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.203125 , 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.234375 , 0.25     , 0.2578125,\n",
       "            0.2734375, 0.2734375, 0.28125  , 0.28125  , 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3046875, 0.3046875, 0.3125   ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.328125 ,\n",
       "            0.328125 , 0.3359375, 0.3515625, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.3984375, 0.40625  , 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.16393442, 0.18032786, 0.19672132,\n",
       "            0.20491803, 0.22131148, 0.22131148, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.26229507, 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.352459  , 0.36065573, 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4262295 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.52459013, 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.59836066, 0.6229508 ,\n",
       "            0.6229508 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9927, 0.9917, 0.991 , 0.99  , 0.9863, 0.986 , 0.9844,\n",
       "            0.9834, 0.98  , 0.979 , 0.9785, 0.978 , 0.977 , 0.9756, 0.9746,\n",
       "            0.974 , 0.973 , 0.971 , 0.9697, 0.9688, 0.968 , 0.9673, 0.967 ,\n",
       "            0.9663, 0.966 , 0.9653, 0.9634, 0.963 , 0.9624, 0.962 , 0.9614,\n",
       "            0.9604, 0.958 , 0.9556, 0.955 , 0.9546, 0.9536, 0.952 , 0.9517,\n",
       "            0.951 , 0.95  , 0.9497, 0.949 , 0.9487, 0.9478, 0.947 , 0.9463,\n",
       "            0.946 , 0.9453, 0.945 , 0.944 , 0.943 , 0.942 , 0.9414, 0.941 ,\n",
       "            0.9404, 0.94  , 0.9395, 0.939 , 0.9385, 0.9375, 0.937 , 0.9365,\n",
       "            0.9355, 0.935 , 0.933 , 0.9326, 0.9316, 0.931 , 0.9307, 0.929 ,\n",
       "            0.9272, 0.9263, 0.926 , 0.9253, 0.9243, 0.9233, 0.922 , 0.9214,\n",
       "            0.921 , 0.9204, 0.9194, 0.9185, 0.918 , 0.9165, 0.916 , 0.9155,\n",
       "            0.915 , 0.9146, 0.914 , 0.9136, 0.9106, 0.91  , 0.9097, 0.9087,\n",
       "            0.908 , 0.907 , 0.9062, 0.9053, 0.9043, 0.9023, 0.9014, 0.9004,\n",
       "            0.899 , 0.8965, 0.8955, 0.8926, 0.892 , 0.891 , 0.8896, 0.889 ,\n",
       "            0.8887, 0.8867, 0.886 , 0.8823, 0.8804, 0.88  , 0.8794, 0.878 ,\n",
       "            0.873 , 0.8726, 0.869 , 0.867 , 0.864 , 0.8623, 0.8613, 0.861 ,\n",
       "            0.859 , 0.8525, 0.85  , 0.8447, 0.836 , 0.83  , 0.809 , 0.806 ,\n",
       "            0.803 , 0.8003, 0.796 , 0.7905, 0.782 , 0.781 , 0.7793, 0.7783,\n",
       "            0.771 , 0.768 , 0.7617, 0.7593, 0.7515, 0.7437, 0.7397, 0.733 ,\n",
       "            0.726 , 0.7246, 0.6978, 0.688 , 0.687 , 0.6855, 0.678 , 0.661 ,\n",
       "            0.659 , 0.6587, 0.654 , 0.6514, 0.6504, 0.643 , 0.6357, 0.622 ,\n",
       "            0.615 , 0.6147, 0.6064, 0.599 , 0.5986, 0.5845, 0.5786, 0.5615,\n",
       "            0.561 , 0.5537, 0.5474, 0.5444, 0.5386, 0.538 , 0.5366, 0.5303,\n",
       "            0.512 , 0.5073, 0.5044, 0.502 , 0.501 , 0.4668, 0.4653, 0.4304,\n",
       "            0.4282, 0.3906, 0.368 , 0.3486, 0.345 ], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.23728813, 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5508475 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.61864406, 0.61864406, 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7288136 , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7711864 , 0.7881356 , 0.7881356 , 0.7881356 , 0.7881356 ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.7966102 , 0.7966102 ,\n",
       "            0.7966102 , 0.7966102 , 0.7966102 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8220339 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.83898306, 0.83898306, 0.83898306, 0.84745765,\n",
       "            0.84745765, 0.86440676, 0.86440676, 0.87288135, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9237288 , 0.9237288 , 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.94067794, 0.94067794, 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03787879, 0.04545455, 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.12878788, 0.12878788,\n",
       "            0.13636364, 0.13636364, 0.14393939, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.17424242, 0.18181819, 0.1969697 , 0.20454545,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.21969697, 0.22727273,\n",
       "            0.24242425, 0.25      , 0.25      , 0.25757575, 0.25757575,\n",
       "            0.27272728, 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.37878788, 0.37878788, 0.38636363,\n",
       "            0.38636363, 0.38636363, 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46969697, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5833333 , 0.5833333 , 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.68939394, 0.70454544, 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75      , 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.431 , 0.4268, 0.4192, 0.4177, 0.4167, 0.414 , 0.4133,\n",
       "            0.4128, 0.4124, 0.412 , 0.4119, 0.411 , 0.4104, 0.4092, 0.409 ,\n",
       "            0.4087, 0.4077, 0.4072, 0.407 , 0.4067, 0.4065, 0.4055, 0.4053,\n",
       "            0.4048, 0.4043, 0.404 , 0.4038, 0.4036, 0.403 , 0.4028, 0.4023,\n",
       "            0.402 , 0.4019, 0.4016, 0.4014, 0.4011, 0.401 , 0.4006, 0.4004,\n",
       "            0.3997, 0.3994, 0.3992, 0.398 , 0.3972, 0.3945, 0.3928, 0.392 ,\n",
       "            0.3918, 0.3877, 0.386 , 0.383 , 0.3826, 0.3818, 0.3796, 0.379 ,\n",
       "            0.3782, 0.3757, 0.3748, 0.3735, 0.369 , 0.3687, 0.3684, 0.368 ,\n",
       "            0.3672, 0.3665, 0.365 , 0.3647, 0.3645, 0.3643, 0.364 , 0.3638,\n",
       "            0.3628, 0.3616, 0.3613, 0.3606, 0.36  , 0.3591, 0.3584, 0.3572,\n",
       "            0.3567, 0.3564, 0.3562, 0.356 , 0.3557, 0.3555, 0.355 , 0.3525,\n",
       "            0.352 , 0.3513, 0.351 , 0.3508, 0.35  , 0.3496, 0.3494, 0.3489,\n",
       "            0.3477, 0.3472, 0.347 , 0.346 , 0.3452, 0.345 , 0.3447, 0.3445,\n",
       "            0.3442, 0.344 , 0.3435, 0.3433, 0.3428, 0.3425, 0.3423, 0.3416,\n",
       "            0.3413, 0.341 , 0.3406, 0.3398, 0.3396, 0.3394, 0.339 , 0.3384,\n",
       "            0.3374, 0.3372, 0.337 , 0.336 , 0.3352, 0.3347, 0.3345, 0.3342,\n",
       "            0.3337, 0.3335, 0.3328, 0.3323, 0.3315, 0.3308, 0.3306, 0.33  ,\n",
       "            0.3298, 0.3296, 0.329 , 0.3284, 0.3267, 0.3262, 0.326 , 0.3254,\n",
       "            0.3252, 0.3242, 0.324 , 0.3235, 0.323 , 0.3225, 0.3223, 0.322 ,\n",
       "            0.3218, 0.3215, 0.321 , 0.32  , 0.3198, 0.3193, 0.3186, 0.3179,\n",
       "            0.3174, 0.3167, 0.3164, 0.3162, 0.3157, 0.3154, 0.3152, 0.3147,\n",
       "            0.3142, 0.3137, 0.3127, 0.3115, 0.3108, 0.3105, 0.31  , 0.3093,\n",
       "            0.3079, 0.3074, 0.3057, 0.305 , 0.304 , 0.3037, 0.3035, 0.302 ,\n",
       "            0.2969, 0.294 , 0.2937, 0.2935, 0.2917, 0.2888, 0.2876, 0.2832,\n",
       "            0.282 , 0.2817, 0.2815, 0.2805, 0.2786, 0.2776, 0.275 , 0.2734,\n",
       "            0.273 , 0.25  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.05084746, 0.05932203, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.21186441, 0.22881356,\n",
       "            0.23728813, 0.2542373 , 0.26271185, 0.27118644, 0.2881356 ,\n",
       "            0.30508474, 0.3220339 , 0.33050847, 0.33898306, 0.3559322 ,\n",
       "            0.3644068 , 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.7033898 ,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.779661  , 0.779661  ,\n",
       "            0.779661  , 0.7881356 , 0.7881356 , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.7966102 , 0.7966102 , 0.7966102 ,\n",
       "            0.80508476, 0.80508476, 0.80508476, 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8220339 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.84745765, 0.8559322 , 0.8559322 ,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.88135594, 0.89830506,\n",
       "            0.89830506, 0.90677965, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9237288 , 0.9237288 , 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.94067794, 0.94067794, 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.14393939, 0.14393939, 0.1590909 , 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.21969697,\n",
       "            0.22727273, 0.22727273, 0.23484848, 0.23484848, 0.24242425,\n",
       "            0.2651515 , 0.2651515 , 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.31060606,\n",
       "            0.3181818 , 0.3181818 , 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.36363637, 0.36363637,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.43939394, 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5151515 , 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.54545456, 0.54545456, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.7121212 , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4138, 0.413 , 0.4072, 0.4053, 0.404 , 0.4026, 0.4006,\n",
       "            0.4001, 0.4   , 0.3997, 0.398 , 0.3972, 0.3955, 0.3953, 0.3945,\n",
       "            0.3943, 0.3938, 0.3936, 0.393 , 0.3928, 0.3918, 0.3916, 0.3914,\n",
       "            0.391 , 0.3901, 0.39  , 0.3896, 0.3894, 0.3892, 0.3887, 0.3884,\n",
       "            0.388 , 0.3877, 0.3867, 0.3818, 0.3794, 0.3787, 0.3782, 0.3752,\n",
       "            0.3733, 0.3694, 0.3684, 0.3657, 0.3655, 0.3643, 0.363 , 0.3628,\n",
       "            0.3618, 0.3591, 0.3567, 0.3533, 0.3513, 0.3508, 0.3503, 0.35  ,\n",
       "            0.3499, 0.3496, 0.3494, 0.3486, 0.3484, 0.3481, 0.3477, 0.346 ,\n",
       "            0.3457, 0.3455, 0.3452, 0.3447, 0.3442, 0.343 , 0.3425, 0.342 ,\n",
       "            0.3413, 0.3408, 0.3406, 0.34  , 0.3396, 0.3394, 0.338 , 0.337 ,\n",
       "            0.3367, 0.3364, 0.3357, 0.3347, 0.3345, 0.3337, 0.3333, 0.333 ,\n",
       "            0.3328, 0.3313, 0.331 , 0.3308, 0.3303, 0.3296, 0.3289, 0.3281,\n",
       "            0.328 , 0.3274, 0.327 , 0.326 , 0.3252, 0.325 , 0.3247, 0.3242,\n",
       "            0.324 , 0.3237, 0.3235, 0.3232, 0.3228, 0.3225, 0.3223, 0.322 ,\n",
       "            0.3218, 0.3215, 0.3213, 0.321 , 0.3203, 0.3196, 0.3193, 0.3184,\n",
       "            0.3174, 0.317 , 0.3167, 0.3162, 0.3157, 0.3154, 0.315 , 0.3147,\n",
       "            0.314 , 0.3137, 0.3132, 0.3123, 0.3118, 0.3113, 0.3108, 0.3105,\n",
       "            0.3098, 0.3079, 0.3074, 0.3071, 0.3066, 0.3064, 0.3047, 0.3044,\n",
       "            0.304 , 0.3035, 0.3032, 0.3025, 0.3018, 0.301 , 0.3005, 0.3   ,\n",
       "            0.2986, 0.2983, 0.298 , 0.2974, 0.297 , 0.2969, 0.2964, 0.2961,\n",
       "            0.295 , 0.2944, 0.2935, 0.2927, 0.2925, 0.2915, 0.2913, 0.2908,\n",
       "            0.2905, 0.2903, 0.2898, 0.289 , 0.2878, 0.2861, 0.286 , 0.2854,\n",
       "            0.2844, 0.284 , 0.2827, 0.282 , 0.2815, 0.28  , 0.2786, 0.278 ,\n",
       "            0.2778, 0.2761, 0.276 , 0.2712, 0.2693, 0.2673, 0.2668, 0.2622,\n",
       "            0.2607, 0.2566, 0.256 , 0.2546, 0.254 , 0.2507, 0.2502, 0.2471,\n",
       "            0.2456, 0.2451, 0.2207], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.08474576,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.15254237, 0.16101696, 0.1779661 , 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.23728813, 0.2457627 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.29661018, 0.30508474, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.3559322 , 0.3644068 , 0.38135594,\n",
       "            0.3898305 , 0.40677965, 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5508475 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.61864406, 0.61864406, 0.62711865, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.779661  , 0.779661  ,\n",
       "            0.779661  , 0.7881356 , 0.7881356 , 0.7881356 , 0.7881356 ,\n",
       "            0.7881356 , 0.7881356 , 0.7881356 , 0.7966102 , 0.7966102 ,\n",
       "            0.7966102 , 0.80508476, 0.80508476, 0.80508476, 0.80508476,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.84745765, 0.84745765,\n",
       "            0.8559322 , 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.89830506, 0.89830506, 0.89830506, 0.89830506, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.91525424, 0.91525424, 0.9237288 ,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.94067794, 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.08333334, 0.09090909, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.12121212, 0.12121212,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.13636364, 0.14393939,\n",
       "            0.1590909 , 0.16666667, 0.16666667, 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.22727273, 0.23484848, 0.23484848,\n",
       "            0.23484848, 0.23484848, 0.24242425, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.28787878, 0.29545453, 0.3030303 , 0.3181818 ,\n",
       "            0.3181818 , 0.32575756, 0.32575756, 0.33333334, 0.33333334,\n",
       "            0.3409091 , 0.3409091 , 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.37878788, 0.3939394 ,\n",
       "            0.40151516, 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5       , 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.5151515 , 0.52272725, 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6287879 , 0.6439394 ,\n",
       "            0.65909094, 0.65909094, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4006, 0.3955, 0.395 , 0.3938, 0.3914, 0.391 , 0.3904,\n",
       "            0.3882, 0.3877, 0.3875, 0.387 , 0.3867, 0.3855, 0.385 , 0.3843,\n",
       "            0.3838, 0.3833, 0.3828, 0.382 , 0.3818, 0.3816, 0.3809, 0.3804,\n",
       "            0.3801, 0.38  , 0.3794, 0.3792, 0.379 , 0.3787, 0.378 , 0.3777,\n",
       "            0.3774, 0.377 , 0.3762, 0.3757, 0.3755, 0.3723, 0.3691, 0.367 ,\n",
       "            0.3667, 0.3647, 0.3645, 0.3625, 0.3606, 0.356 , 0.3547, 0.3516,\n",
       "            0.3513, 0.3506, 0.3486, 0.3477, 0.347 , 0.3447, 0.3389, 0.3384,\n",
       "            0.3354, 0.3347, 0.3345, 0.3342, 0.334 , 0.3328, 0.3325, 0.332 ,\n",
       "            0.3318, 0.3313, 0.3306, 0.3296, 0.3289, 0.3284, 0.3267, 0.3264,\n",
       "            0.3262, 0.3254, 0.3252, 0.325 , 0.3245, 0.3242, 0.3237, 0.3228,\n",
       "            0.321 , 0.3184, 0.3179, 0.3174, 0.317 , 0.3167, 0.3164, 0.3162,\n",
       "            0.316 , 0.3154, 0.314 , 0.3135, 0.3132, 0.3127, 0.3125, 0.3115,\n",
       "            0.3108, 0.3105, 0.31  , 0.3079, 0.3076, 0.307 , 0.3066, 0.3064,\n",
       "            0.3062, 0.306 , 0.3052, 0.3047, 0.3044, 0.304 , 0.3035, 0.3032,\n",
       "            0.303 , 0.3025, 0.3018, 0.3015, 0.3013, 0.301 , 0.3005, 0.3   ,\n",
       "            0.299 , 0.2988, 0.2983, 0.298 , 0.2979, 0.2976, 0.2974, 0.2969,\n",
       "            0.2966, 0.2961, 0.296 , 0.2952, 0.2944, 0.2942, 0.2937, 0.2922,\n",
       "            0.2915, 0.2913, 0.29  , 0.2896, 0.2888, 0.2886, 0.288 , 0.287 ,\n",
       "            0.286 , 0.2852, 0.285 , 0.2847, 0.2844, 0.284 , 0.2837, 0.2827,\n",
       "            0.2817, 0.2815, 0.2808, 0.2803, 0.2795, 0.2788, 0.2786, 0.278 ,\n",
       "            0.2778, 0.2776, 0.277 , 0.2756, 0.275 , 0.2742, 0.2732, 0.272 ,\n",
       "            0.2717, 0.2715, 0.2708, 0.27  , 0.2698, 0.268 , 0.2676, 0.267 ,\n",
       "            0.2668, 0.2666, 0.2654, 0.2642, 0.263 , 0.2627, 0.2625, 0.2622,\n",
       "            0.2595, 0.259 , 0.2573, 0.256 , 0.2551, 0.2542, 0.2537, 0.2534,\n",
       "            0.252 , 0.2493, 0.2482, 0.243 , 0.2418, 0.2375, 0.2356, 0.2338,\n",
       "            0.231 , 0.2294, 0.229 , 0.2283, 0.2251, 0.2247, 0.2217, 0.2198,\n",
       "            0.2194, 0.1942], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.07627118, 0.10169491,\n",
       "            0.11016949, 0.12711865, 0.13559322, 0.1440678 , 0.16101696,\n",
       "            0.16101696, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22881356, 0.23728813, 0.2457627 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.33050847, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.38135594, 0.3983051 , 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.42372882, 0.44067797, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.720339  , 0.720339  ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7881356 , 0.7881356 , 0.7881356 , 0.7881356 , 0.7966102 ,\n",
       "            0.7966102 , 0.80508476, 0.80508476, 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8135593 , 0.8305085 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.84745765, 0.8559322 , 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.87288135, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.9237288 , 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.09090909, 0.09090909, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.15151516, 0.1590909 , 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.18939394, 0.1969697 ,\n",
       "            0.1969697 , 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.21969697, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25      , 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.29545453, 0.3030303 , 0.3030303 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.33333334, 0.3409091 ,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.4318182 , 0.43939394,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46969697, 0.4848485 ,\n",
       "            0.4848485 , 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3855, 0.381 , 0.3804, 0.3787, 0.376 , 0.3748, 0.3745,\n",
       "            0.3738, 0.3733, 0.372 , 0.3716, 0.3713, 0.371 , 0.37  , 0.3696,\n",
       "            0.3694, 0.369 , 0.3687, 0.3684, 0.368 , 0.3674, 0.3672, 0.367 ,\n",
       "            0.3667, 0.3662, 0.3655, 0.365 , 0.3647, 0.3645, 0.3643, 0.3638,\n",
       "            0.3635, 0.3633, 0.3623, 0.362 , 0.361 , 0.3599, 0.3542, 0.354 ,\n",
       "            0.352 , 0.3486, 0.348 , 0.3477, 0.3455, 0.3403, 0.3386, 0.3354,\n",
       "            0.335 , 0.334 , 0.3308, 0.3296, 0.3281, 0.3274, 0.3208, 0.3176,\n",
       "            0.317 , 0.3167, 0.3162, 0.315 , 0.3147, 0.3142, 0.314 , 0.313 ,\n",
       "            0.3123, 0.311 , 0.3103, 0.31  , 0.3098, 0.3093, 0.308 , 0.3076,\n",
       "            0.3066, 0.3064, 0.306 , 0.3054, 0.3047, 0.3044, 0.304 , 0.3037,\n",
       "            0.3035, 0.3008, 0.299 , 0.2988, 0.297 , 0.2969, 0.2966, 0.296 ,\n",
       "            0.2957, 0.295 , 0.2942, 0.294 , 0.2935, 0.2927, 0.2925, 0.292 ,\n",
       "            0.2908, 0.2905, 0.29  , 0.2896, 0.289 , 0.2874, 0.2866, 0.2864,\n",
       "            0.286 , 0.2856, 0.2854, 0.2852, 0.2847, 0.2844, 0.2842, 0.284 ,\n",
       "            0.2837, 0.2832, 0.2827, 0.2812, 0.281 , 0.28  , 0.2788, 0.2786,\n",
       "            0.278 , 0.2778, 0.2773, 0.2766, 0.2764, 0.276 , 0.2756, 0.2754,\n",
       "            0.2751, 0.275 , 0.274 , 0.2737, 0.273 , 0.2722, 0.2708, 0.27  ,\n",
       "            0.2683, 0.2678, 0.267 , 0.2668, 0.2664, 0.2651, 0.2646, 0.2644,\n",
       "            0.264 , 0.2632, 0.263 , 0.2622, 0.2617, 0.2607, 0.2605, 0.2603,\n",
       "            0.2593, 0.259 , 0.2583, 0.2576, 0.2573, 0.2568, 0.256 , 0.2556,\n",
       "            0.2554, 0.2551, 0.255 , 0.2546, 0.2544, 0.2534, 0.252 , 0.2515,\n",
       "            0.2502, 0.25  , 0.2493, 0.2487, 0.248 , 0.2478, 0.247 , 0.2467,\n",
       "            0.2463, 0.2441, 0.243 , 0.2426, 0.2413, 0.2407, 0.2397, 0.2391,\n",
       "            0.2379, 0.236 , 0.2355, 0.2352, 0.234 , 0.2319, 0.2313, 0.2292,\n",
       "            0.2285, 0.2264, 0.2257, 0.2249, 0.2246, 0.2239, 0.215 , 0.2135,\n",
       "            0.2091, 0.2076, 0.2073, 0.2023, 0.2006, 0.2001, 0.1993, 0.1959,\n",
       "            0.1927, 0.1909, 0.1903, 0.1648], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.06779661, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11864407, 0.13559322, 0.15254237, 0.16949153, 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.22033899, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.33050847, 0.33898306,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 , 0.5508475 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.6101695 , 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.63559324, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.720339  , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.779661  , 0.779661  , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8135593 , 0.8135593 , 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.8305085 , 0.83898306, 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.89830506, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.18939394, 0.1969697 , 0.1969697 , 0.1969697 , 0.20454545,\n",
       "            0.20454545, 0.20454545, 0.21969697, 0.22727273, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.28787878, 0.29545453, 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.32575756, 0.32575756, 0.32575756,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.4090909 , 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.4318182 , 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.46212122, 0.4848485 , 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3708, 0.3672, 0.366 , 0.3608, 0.3606, 0.3594, 0.3591,\n",
       "            0.359 , 0.3586, 0.3582, 0.3572, 0.357 , 0.356 , 0.3557, 0.3555,\n",
       "            0.3552, 0.355 , 0.3545, 0.354 , 0.3538, 0.3533, 0.353 , 0.3523,\n",
       "            0.352 , 0.3518, 0.3513, 0.351 , 0.35  , 0.3496, 0.3486, 0.3484,\n",
       "            0.3472, 0.3464, 0.346 , 0.3445, 0.344 , 0.339 , 0.3372, 0.3362,\n",
       "            0.3325, 0.3323, 0.331 , 0.3306, 0.3303, 0.3245, 0.3228, 0.3198,\n",
       "            0.3184, 0.3176, 0.3137, 0.3118, 0.31  , 0.3093, 0.3083, 0.3032,\n",
       "            0.2998, 0.299 , 0.2988, 0.2986, 0.2983, 0.297 , 0.2964, 0.2961,\n",
       "            0.2957, 0.2944, 0.294 , 0.2927, 0.292 , 0.2893, 0.289 , 0.2888,\n",
       "            0.2886, 0.2883, 0.288 , 0.2878, 0.2874, 0.2869, 0.286 , 0.2847,\n",
       "            0.283 , 0.2822, 0.282 , 0.2808, 0.28  , 0.2798, 0.278 , 0.2776,\n",
       "            0.2773, 0.2756, 0.2747, 0.274 , 0.2737, 0.2734, 0.2732, 0.2727,\n",
       "            0.271 , 0.2708, 0.2705, 0.2695, 0.2688, 0.2673, 0.267 , 0.2668,\n",
       "            0.2664, 0.2659, 0.2656, 0.2654, 0.265 , 0.2646, 0.2644, 0.264 ,\n",
       "            0.2634, 0.263 , 0.2625, 0.2612, 0.261 , 0.2607, 0.258 , 0.2578,\n",
       "            0.2576, 0.257 , 0.2563, 0.256 , 0.2559, 0.2554, 0.255 , 0.2546,\n",
       "            0.2542, 0.2534, 0.2527, 0.2524, 0.252 , 0.2517, 0.2515, 0.251 ,\n",
       "            0.2502, 0.2493, 0.2471, 0.2466, 0.2462, 0.246 , 0.2452, 0.2441,\n",
       "            0.2429, 0.2422, 0.2421, 0.2411, 0.2406, 0.2401, 0.2394, 0.239 ,\n",
       "            0.2378, 0.2358, 0.2356, 0.235 , 0.2344, 0.2343, 0.2339, 0.2338,\n",
       "            0.2335, 0.233 , 0.2325, 0.2319, 0.2316, 0.2303, 0.2297, 0.2294,\n",
       "            0.2286, 0.2272, 0.2268, 0.2264, 0.2257, 0.2251, 0.2249, 0.2224,\n",
       "            0.222 , 0.2202, 0.2198, 0.2189, 0.2186, 0.2168, 0.2161, 0.2148,\n",
       "            0.2142, 0.2137, 0.2123, 0.2114, 0.2108, 0.2098, 0.2089, 0.207 ,\n",
       "            0.2034, 0.2028, 0.2018, 0.2012, 0.2   , 0.1989, 0.1984, 0.19  ,\n",
       "            0.1877, 0.1843, 0.1838, 0.1815, 0.1768, 0.1753, 0.1744, 0.1735,\n",
       "            0.1704, 0.1699, 0.1674, 0.1653, 0.1647, 0.1396], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.10169491, 0.11016949, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.18644068,\n",
       "            0.19491525, 0.21186441, 0.22881356, 0.23728813, 0.2542373 ,\n",
       "            0.2542373 , 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.33898306, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.48305085, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.63559324, 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7881356 , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8135593 , 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 , 0.8305085 ,\n",
       "            0.83898306, 0.83898306, 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.89830506, 0.89830506, 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.08333334, 0.09090909,\n",
       "            0.09090909, 0.09848485, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.12121212, 0.13636364, 0.14393939, 0.15151516, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.18939394, 0.18939394,\n",
       "            0.1969697 , 0.1969697 , 0.1969697 , 0.20454545, 0.20454545,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.31060606, 0.31060606, 0.31060606, 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.49242425, 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.59090906, 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3564, 0.3542, 0.3538, 0.3533, 0.3477, 0.3467, 0.3464,\n",
       "            0.3462, 0.3457, 0.3455, 0.3452, 0.345 , 0.3447, 0.3445, 0.344 ,\n",
       "            0.3435, 0.3433, 0.343 , 0.3428, 0.3425, 0.3418, 0.3408, 0.34  ,\n",
       "            0.339 , 0.3389, 0.3386, 0.3376, 0.3374, 0.3372, 0.337 , 0.3364,\n",
       "            0.3362, 0.3354, 0.335 , 0.3337, 0.3318, 0.3315, 0.331 , 0.3284,\n",
       "            0.328 , 0.3242, 0.3223, 0.319 , 0.3167, 0.3154, 0.3147, 0.3135,\n",
       "            0.3086, 0.3066, 0.304 , 0.3015, 0.2964, 0.294 , 0.2927, 0.291 ,\n",
       "            0.2898, 0.2864, 0.282 , 0.2815, 0.281 , 0.2786, 0.278 , 0.277 ,\n",
       "            0.2766, 0.2761, 0.2751, 0.2742, 0.2712, 0.27  , 0.2695, 0.269 ,\n",
       "            0.2688, 0.2686, 0.2678, 0.2659, 0.2622, 0.2617, 0.2615, 0.2612,\n",
       "            0.2595, 0.2593, 0.2585, 0.2559, 0.2556, 0.255 , 0.2546, 0.254 ,\n",
       "            0.2534, 0.253 , 0.2524, 0.2522, 0.252 , 0.2517, 0.249 , 0.2487,\n",
       "            0.2482, 0.2478, 0.2477, 0.2467, 0.2463, 0.2462, 0.246 , 0.2458,\n",
       "            0.2452, 0.2449, 0.2448, 0.2445, 0.2437, 0.2429, 0.2421, 0.2418,\n",
       "            0.2415, 0.2388, 0.2383, 0.2382, 0.2375, 0.2367, 0.2363, 0.2358,\n",
       "            0.2356, 0.2352, 0.2351, 0.235 , 0.2347, 0.2338, 0.2334, 0.233 ,\n",
       "            0.2327, 0.2319, 0.2318, 0.2316, 0.2307, 0.2302, 0.2301, 0.2294,\n",
       "            0.2286, 0.2269, 0.2261, 0.2257, 0.2252, 0.224 , 0.2229, 0.222 ,\n",
       "            0.2218, 0.2211, 0.2203, 0.219 , 0.2181, 0.2175, 0.2167, 0.2161,\n",
       "            0.2142, 0.2139, 0.2137, 0.2135, 0.2134, 0.2133, 0.2125, 0.2108,\n",
       "            0.2106, 0.21  , 0.2098, 0.2096, 0.208 , 0.2074, 0.2064, 0.2063,\n",
       "            0.2056, 0.205 , 0.2043, 0.204 , 0.2026, 0.2024, 0.2   , 0.1993,\n",
       "            0.199 , 0.1981, 0.1978, 0.1968, 0.1947, 0.194 , 0.1936, 0.1913,\n",
       "            0.1906, 0.1893, 0.1891, 0.1886, 0.1877, 0.1873, 0.1846, 0.1805,\n",
       "            0.1799, 0.1797, 0.1787, 0.1768, 0.1755, 0.1754, 0.1677, 0.165 ,\n",
       "            0.163 , 0.1617, 0.159 , 0.1544, 0.153 , 0.1517, 0.1508, 0.1481,\n",
       "            0.1476, 0.1453, 0.1432, 0.1423, 0.1184], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.12711865, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.3220339 , 0.33050847, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.63559324, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.8305085 , 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.83898306, 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.89830506,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06818182, 0.06818182, 0.07575758, 0.07575758, 0.08333334,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.12878788, 0.14393939, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.17424242, 0.18181819,\n",
       "            0.18181819, 0.1969697 , 0.1969697 , 0.1969697 , 0.1969697 ,\n",
       "            0.20454545, 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.31060606, 0.31060606, 0.31060606, 0.31060606,\n",
       "            0.3181818 , 0.3181818 , 0.32575756, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.47727272, 0.49242425, 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.57575756, 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.84090906,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3423 , 0.3413 , 0.3408 , 0.3403 , 0.3345 , 0.334  ,\n",
       "            0.3337 , 0.333  , 0.3325 , 0.3323 , 0.332  , 0.3318 , 0.3315 ,\n",
       "            0.3313 , 0.3308 , 0.3306 , 0.3303 , 0.33   , 0.3293 , 0.3286 ,\n",
       "            0.3284 , 0.327  , 0.3264 , 0.3262 , 0.3254 , 0.3252 , 0.3237 ,\n",
       "            0.3235 , 0.323  , 0.3225 , 0.3213 , 0.321  , 0.3193 , 0.319  ,\n",
       "            0.3174 , 0.3162 , 0.313  , 0.3118 , 0.309  , 0.3074 , 0.3025 ,\n",
       "            0.301  , 0.3005 , 0.2983 , 0.297  , 0.2927 , 0.2908 , 0.2878 ,\n",
       "            0.2852 , 0.285  , 0.279  , 0.2764 , 0.2756 , 0.273  , 0.2717 ,\n",
       "            0.2693 , 0.2646 , 0.2644 , 0.2642 , 0.2637 , 0.2632 , 0.2612 ,\n",
       "            0.261  , 0.2595 , 0.2585 , 0.258  , 0.2576 , 0.2566 , 0.255  ,\n",
       "            0.2534 , 0.2522 , 0.252  , 0.2517 , 0.2512 , 0.251  , 0.2507 ,\n",
       "            0.2502 , 0.2498 , 0.2489 , 0.2477 , 0.2438 , 0.2433 , 0.2429 ,\n",
       "            0.2424 , 0.2422 , 0.2417 , 0.2411 , 0.2399 , 0.2374 , 0.237  ,\n",
       "            0.2366 , 0.2363 , 0.2352 , 0.2344 , 0.2339 , 0.2334 , 0.2332 ,\n",
       "            0.2319 , 0.2299 , 0.2294 , 0.2292 , 0.2289 , 0.2285 , 0.2281 ,\n",
       "            0.2277 , 0.2273 , 0.2272 , 0.2269 , 0.2266 , 0.2263 , 0.2257 ,\n",
       "            0.2247 , 0.2239 , 0.2238 , 0.223  , 0.2227 , 0.2216 , 0.2194 ,\n",
       "            0.2191 , 0.2186 , 0.2177 , 0.2175 , 0.2173 , 0.2163 , 0.2161 ,\n",
       "            0.2158 , 0.2148 , 0.2147 , 0.2145 , 0.2139 , 0.2135 , 0.2128 ,\n",
       "            0.2125 , 0.2115 , 0.2108 , 0.2106 , 0.2101 , 0.2098 , 0.2089 ,\n",
       "            0.2079 , 0.2076 , 0.2069 , 0.206  , 0.2058 , 0.2048 , 0.2035 ,\n",
       "            0.2028 , 0.2026 , 0.2017 , 0.201  , 0.1996 , 0.1982 , 0.1981 ,\n",
       "            0.1948 , 0.1943 , 0.194  , 0.1937 , 0.1936 , 0.193  , 0.1927 ,\n",
       "            0.1909 , 0.1903 , 0.1898 , 0.1892 , 0.1884 , 0.1882 , 0.1873 ,\n",
       "            0.1865 , 0.1855 , 0.1852 , 0.1846 , 0.1831 , 0.1821 , 0.1813 ,\n",
       "            0.1797 , 0.1791 , 0.1785 , 0.1782 , 0.1781 , 0.1775 , 0.1766 ,\n",
       "            0.1744 , 0.1741 , 0.1735 , 0.1704 , 0.1694 , 0.1693 , 0.1686 ,\n",
       "            0.1683 , 0.1678 , 0.1664 , 0.1646 , 0.1608 , 0.1602 , 0.1587 ,\n",
       "            0.1583 , 0.1559 , 0.1544 , 0.1481 , 0.1444 , 0.1432 , 0.142  ,\n",
       "            0.1392 , 0.1349 , 0.1333 , 0.132  , 0.1309 , 0.1285 , 0.1276 ,\n",
       "            0.126  , 0.1238 , 0.12305, 0.10034], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.02542373, 0.03389831, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.09322034, 0.12711865, 0.13559322,\n",
       "            0.15254237, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.31355932, 0.3220339 , 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.44067797, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8135593 ,\n",
       "            0.8220339 , 0.8220339 , 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.83898306, 0.83898306, 0.83898306, 0.84745765, 0.84745765,\n",
       "            0.8559322 , 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9237288 , 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.07575758, 0.08333334,\n",
       "            0.08333334, 0.09848485, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.1969697 , 0.1969697 , 0.20454545,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28030303, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.31060606, 0.31060606, 0.31060606, 0.3181818 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46212122, 0.47727272, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.5530303 , 0.56060606, 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.99242425,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3284 , 0.3281 , 0.327  , 0.3215 , 0.3208 , 0.3203 ,\n",
       "            0.319  , 0.3188 , 0.3186 , 0.3184 , 0.3179 , 0.3176 , 0.3171 ,\n",
       "            0.3164 , 0.316  , 0.315  , 0.3142 , 0.313  , 0.3125 , 0.3123 ,\n",
       "            0.3118 , 0.3115 , 0.3105 , 0.3098 , 0.3093 , 0.3088 , 0.3079 ,\n",
       "            0.3076 , 0.3074 , 0.3066 , 0.3047 , 0.303  , 0.3018 , 0.3013 ,\n",
       "            0.301  , 0.2979 , 0.2954 , 0.2947 , 0.293  , 0.2861 , 0.286  ,\n",
       "            0.2856 , 0.2825 , 0.2808 , 0.2776 , 0.2751 , 0.2722 , 0.2688 ,\n",
       "            0.2683 , 0.2622 , 0.2595 , 0.2588 , 0.2556 , 0.2544 , 0.2527 ,\n",
       "            0.2478 , 0.2474 , 0.2473 , 0.247  , 0.2462 , 0.2441 , 0.2438 ,\n",
       "            0.2422 , 0.2417 , 0.2413 , 0.2405 , 0.2395 , 0.2368 , 0.2363 ,\n",
       "            0.235  , 0.2344 , 0.2343 , 0.2339 , 0.2338 , 0.2334 , 0.2325 ,\n",
       "            0.2322 , 0.2316 , 0.2302 , 0.2299 , 0.2266 , 0.2252 , 0.2242 ,\n",
       "            0.2238 , 0.2234 , 0.2229 , 0.222  , 0.2195 , 0.2189 , 0.2186 ,\n",
       "            0.2184 , 0.2172 , 0.2162 , 0.2157 , 0.2152 , 0.2144 , 0.2128 ,\n",
       "            0.2115 , 0.2114 , 0.2113 , 0.2104 , 0.21   , 0.2095 , 0.2091 ,\n",
       "            0.209  , 0.2089 , 0.2085 , 0.2084 , 0.2073 , 0.2065 , 0.2058 ,\n",
       "            0.2051 , 0.2048 , 0.2047 , 0.2045 , 0.2021 , 0.2013 , 0.2012 ,\n",
       "            0.2007 , 0.1995 , 0.1993 , 0.1991 , 0.1984 , 0.1981 , 0.1979 ,\n",
       "            0.1974 , 0.1967 , 0.1959 , 0.1954 , 0.1953 , 0.195  , 0.1947 ,\n",
       "            0.1943 , 0.1942 , 0.1941 , 0.1923 , 0.1919 , 0.1913 , 0.1909 ,\n",
       "            0.1903 , 0.1896 , 0.189  , 0.1886 , 0.1879 , 0.1877 , 0.1876 ,\n",
       "            0.1873 , 0.1865 , 0.1852 , 0.1844 , 0.1842 , 0.1833 , 0.1826 ,\n",
       "            0.1813 , 0.1797 , 0.1794 , 0.1758 , 0.1757 , 0.1755 , 0.1753 ,\n",
       "            0.1752 , 0.1749 , 0.1748 , 0.1747 , 0.1743 , 0.1733 , 0.1724 ,\n",
       "            0.1719 , 0.171  , 0.1699 , 0.1694 , 0.1685 , 0.1682 , 0.167  ,\n",
       "            0.1661 , 0.1647 , 0.1637 , 0.1627 , 0.1616 , 0.1611 , 0.1599 ,\n",
       "            0.1597 , 0.1592 , 0.1582 , 0.1577 , 0.1559 , 0.1556 , 0.1547 ,\n",
       "            0.151  , 0.1509 , 0.1508 , 0.15   , 0.1499 , 0.1495 , 0.149  ,\n",
       "            0.1475 , 0.146  , 0.1425 , 0.1418 , 0.1395 , 0.1394 , 0.1393 ,\n",
       "            0.1367 , 0.1355 , 0.1354 , 0.13   , 0.1256 , 0.1252 , 0.1241 ,\n",
       "            0.1214 , 0.1172 , 0.1158 , 0.1142 , 0.113  , 0.111  , 0.1099 ,\n",
       "            0.10876, 0.1067 , 0.10596, 0.0845 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05932203, 0.06779661, 0.07627118, 0.11864407,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7118644 , 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.779661  , 0.779661  , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.8305085 , 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.84745765, 0.84745765, 0.8559322 , 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.89830506,\n",
       "            0.89830506, 0.90677965, 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9237288 , 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.12878788, 0.13636364, 0.13636364, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18181819, 0.18181819, 0.18939394,\n",
       "            0.18939394, 0.1969697 , 0.1969697 , 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25      , 0.25      , 0.25757575, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.29545453, 0.3030303 , 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.3181818 , 0.3181818 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.99242425,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.316  , 0.3157 , 0.3142 , 0.3137 , 0.3096 , 0.3086 ,\n",
       "            0.3083 , 0.307  , 0.3062 , 0.306  , 0.3054 , 0.3052 , 0.305  ,\n",
       "            0.3035 , 0.303  , 0.3018 , 0.3013 , 0.3005 , 0.3    , 0.2996 ,\n",
       "            0.2993 , 0.298  , 0.2979 , 0.2974 , 0.2966 , 0.2954 , 0.2952 ,\n",
       "            0.2944 , 0.2942 , 0.2932 , 0.2925 , 0.292  , 0.2903 , 0.2888 ,\n",
       "            0.2874 , 0.2864 , 0.286  , 0.283  , 0.2808 , 0.28   , 0.2786 ,\n",
       "            0.2712 , 0.271  , 0.2703 , 0.267  , 0.2654 , 0.2625 , 0.259  ,\n",
       "            0.2568 , 0.2524 , 0.2452 , 0.2428 , 0.2421 , 0.2388 , 0.2366 ,\n",
       "            0.2314 , 0.2306 , 0.2303 , 0.2302 , 0.2295 , 0.2277 , 0.2269 ,\n",
       "            0.2256 , 0.2251 , 0.2247 , 0.2239 , 0.2233 , 0.223  , 0.2197 ,\n",
       "            0.2189 , 0.2184 , 0.2177 , 0.2172 , 0.217  , 0.2168 , 0.2167 ,\n",
       "            0.2161 , 0.2157 , 0.2152 , 0.2139 , 0.2125 , 0.2124 , 0.2096 ,\n",
       "            0.2084 , 0.2079 , 0.2074 , 0.207  , 0.2063 , 0.2051 , 0.2048 ,\n",
       "            0.2045 , 0.2024 , 0.2015 , 0.2013 , 0.2012 , 0.2009 , 0.1993 ,\n",
       "            0.1987 , 0.1984 , 0.1981 , 0.196  , 0.1946 , 0.1943 , 0.1941 ,\n",
       "            0.1931 , 0.1927 , 0.1925 , 0.1921 , 0.1919 , 0.1918 , 0.1913 ,\n",
       "            0.1912 , 0.191  , 0.1898 , 0.1891 , 0.1884 , 0.188  , 0.1877 ,\n",
       "            0.1858 , 0.1855 , 0.1844 , 0.1842 , 0.1841 , 0.1833 , 0.1823 ,\n",
       "            0.1821 , 0.1816 , 0.1812 , 0.1807 , 0.1799 , 0.1794 , 0.1792 ,\n",
       "            0.1785 , 0.1782 , 0.1774 , 0.1771 , 0.1764 , 0.1759 , 0.1752 ,\n",
       "            0.1747 , 0.1746 , 0.1729 , 0.1725 , 0.1724 , 0.1714 , 0.1708 ,\n",
       "            0.1705 , 0.1699 , 0.1698 , 0.1693 , 0.1678 , 0.1671 , 0.167  ,\n",
       "            0.166  , 0.165  , 0.164  , 0.1624 , 0.1619 , 0.1594 , 0.1584 ,\n",
       "            0.1582 , 0.1581 , 0.158  , 0.1575 , 0.1573 , 0.1572 , 0.1565 ,\n",
       "            0.1558 , 0.1556 , 0.1549 , 0.1548 , 0.1545 , 0.1527 , 0.1517 ,\n",
       "            0.1514 , 0.1509 , 0.1506 , 0.1498 , 0.149  , 0.1483 , 0.1467 ,\n",
       "            0.1466 , 0.146  , 0.1444 , 0.144  , 0.1438 , 0.1425 , 0.1422 ,\n",
       "            0.1417 , 0.1401 , 0.1398 , 0.1385 , 0.1383 , 0.1354 , 0.1353 ,\n",
       "            0.1343 , 0.1342 , 0.1329 , 0.1326 , 0.1322 , 0.13   , 0.1296 ,\n",
       "            0.1257 , 0.12494, 0.1229 , 0.12286, 0.1225 , 0.1201 , 0.119  ,\n",
       "            0.1188 , 0.115  , 0.1095 , 0.10913, 0.10876, 0.10614, 0.1025 ,\n",
       "            0.1011 , 0.0993 , 0.0974 , 0.0967 , 0.09485, 0.0945 , 0.0925 ,\n",
       "            0.09155, 0.07196], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01694915, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.09322034, 0.11864407,\n",
       "            0.12711865, 0.15254237, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.22033899, 0.22881356, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.48305085, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.779661  , 0.779661  , 0.779661  , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.80508476, 0.8135593 , 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 , 0.8305085 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.84745765, 0.8559322 ,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.90677965, 0.91525424, 0.91525424, 0.9237288 , 0.9237288 ,\n",
       "            0.9237288 , 0.9322034 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.01515152, 0.01515152,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.08333334, 0.08333334, 0.09090909, 0.09090909, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.12878788, 0.12878788, 0.13636364,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.16666667, 0.18181819, 0.18181819, 0.18181819, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.1969697 , 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25      , 0.25757575, 0.25757575, 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.3030303 , 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.3030303 , 0.31060606, 0.31060606,\n",
       "            0.31060606, 0.3181818 , 0.3181818 , 0.32575756, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.37878788, 0.3939394 , 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5       , 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.304  , 0.3013 , 0.298  , 0.297  , 0.2964 , 0.2961 ,\n",
       "            0.2952 , 0.2942 , 0.294  , 0.2937 , 0.2935 , 0.2932 , 0.2927 ,\n",
       "            0.2925 , 0.2915 , 0.29   , 0.2886 , 0.2874 , 0.2869 , 0.2864 ,\n",
       "            0.2847 , 0.2842 , 0.284  , 0.2834 , 0.282  , 0.2817 , 0.2812 ,\n",
       "            0.281  , 0.2808 , 0.2788 , 0.2786 , 0.2769 , 0.2761 , 0.2747 ,\n",
       "            0.273  , 0.2717 , 0.2695 , 0.268  , 0.2659 , 0.2654 , 0.2642 ,\n",
       "            0.2566 , 0.2554 , 0.2551 , 0.255  , 0.2517 , 0.2496 , 0.2474 ,\n",
       "            0.243  , 0.2413 , 0.2363 , 0.2285 , 0.2264 , 0.2256 , 0.2222 ,\n",
       "            0.222  , 0.22   , 0.215  , 0.2139 , 0.2137 , 0.2135 , 0.2129 ,\n",
       "            0.2109 , 0.2101 , 0.2086 , 0.2084 , 0.2076 , 0.2068 , 0.2063 ,\n",
       "            0.2034 , 0.202  , 0.2017 , 0.2013 , 0.2009 , 0.2006 , 0.2004 ,\n",
       "            0.2002 , 0.1993 , 0.199  , 0.1984 , 0.1967 , 0.196  , 0.1947 ,\n",
       "            0.1927 , 0.1918 , 0.1906 , 0.1903 , 0.1887 , 0.1884 , 0.1874 ,\n",
       "            0.1866 , 0.1858 , 0.1849 , 0.1843 , 0.1841 , 0.1838 , 0.183  ,\n",
       "            0.1824 , 0.1814 , 0.1813 , 0.1783 , 0.178  , 0.1779 , 0.1774 ,\n",
       "            0.1772 , 0.1763 , 0.1759 , 0.1755 , 0.1754 , 0.1753 , 0.1752 ,\n",
       "            0.1749 , 0.1748 , 0.1747 , 0.1743 , 0.1731 , 0.173  , 0.1725 ,\n",
       "            0.1716 , 0.1711 , 0.1677 , 0.1676 , 0.1666 , 0.1656 , 0.1653 ,\n",
       "            0.1649 , 0.1647 , 0.164  , 0.1632 , 0.163  , 0.1619 , 0.1615 ,\n",
       "            0.1614 , 0.1609 , 0.1605 , 0.1597 , 0.1587 , 0.1582 , 0.1581 ,\n",
       "            0.158  , 0.1577 , 0.1571 , 0.157  , 0.1559 , 0.155  , 0.1549 ,\n",
       "            0.1548 , 0.1543 , 0.154  , 0.1533 , 0.1528 , 0.1527 , 0.1519 ,\n",
       "            0.1515 , 0.1506 , 0.1505 , 0.1497 , 0.1483 , 0.1476 , 0.1461 ,\n",
       "            0.1451 , 0.1427 , 0.142  , 0.1417 , 0.1416 , 0.1415 , 0.141  ,\n",
       "            0.1409 , 0.1407 , 0.139  , 0.1385 , 0.1383 , 0.138  , 0.1378 ,\n",
       "            0.1364 , 0.1346 , 0.1342 , 0.134  , 0.1335 , 0.1329 , 0.1327 ,\n",
       "            0.1317 , 0.1295 , 0.1289 , 0.1288 , 0.1279 , 0.1273 , 0.1272 ,\n",
       "            0.1265 , 0.1257 , 0.1251 , 0.12317, 0.1226 , 0.1225 , 0.1214 ,\n",
       "            0.1193 , 0.119  , 0.118  , 0.1172 , 0.11676, 0.11597, 0.11536,\n",
       "            0.11395, 0.1136 , 0.1103 , 0.1095 , 0.1065 , 0.1063 , 0.10596,\n",
       "            0.10376, 0.1025 , 0.1023 , 0.0997 , 0.094  , 0.0939 , 0.0937 ,\n",
       "            0.09106, 0.0877 , 0.0865 , 0.0845 , 0.0823 , 0.0804 , 0.0798 ,\n",
       "            0.07837, 0.0775 , 0.05954], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.07627118, 0.08474576,\n",
       "            0.10169491, 0.11864407, 0.1440678 , 0.15254237, 0.16949153,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.22033899, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.60169494, 0.60169494, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.65254235, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7033898 , 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.779661  , 0.779661  , 0.779661  , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8220339 ,\n",
       "            0.8305085 , 0.8305085 , 0.8305085 , 0.8305085 , 0.84745765,\n",
       "            0.84745765, 0.84745765, 0.8559322 , 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.89830506,\n",
       "            0.89830506, 0.89830506, 0.90677965, 0.90677965, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.9237288 , 0.9237288 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.94067794, 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 0.9915254 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03787879, 0.03787879, 0.03787879, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.0530303 , 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.09090909, 0.09090909,\n",
       "            0.09848485, 0.09848485, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.13636364,\n",
       "            0.13636364, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.1969697 , 0.20454545,\n",
       "            0.20454545, 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.25      , 0.25757575, 0.25757575, 0.2651515 ,\n",
       "            0.2651515 , 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.31060606, 0.31060606,\n",
       "            0.3181818 , 0.3181818 , 0.3181818 , 0.3181818 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.75      , 0.75757575,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2913 , 0.291  , 0.288  , 0.2874 , 0.286  , 0.2852 ,\n",
       "            0.2837 , 0.2832 , 0.2825 , 0.2822 , 0.282  , 0.2815 , 0.2812 ,\n",
       "            0.281  , 0.2805 , 0.279  , 0.277  , 0.2761 , 0.2747 , 0.2742 ,\n",
       "            0.2734 , 0.2722 , 0.272  , 0.2715 , 0.2705 , 0.269  , 0.2688 ,\n",
       "            0.2683 , 0.268  , 0.2676 , 0.266  , 0.2656 , 0.263  , 0.262  ,\n",
       "            0.2615 , 0.2598 , 0.2595 , 0.2576 , 0.2554 , 0.2542 , 0.2524 ,\n",
       "            0.2505 , 0.2438 , 0.2428 , 0.2415 , 0.2401 , 0.2384 , 0.2374 ,\n",
       "            0.2334 , 0.2277 , 0.2266 , 0.2208 , 0.2207 , 0.213  , 0.2109 ,\n",
       "            0.2098 , 0.2079 , 0.2039 , 0.1993 , 0.1982 , 0.1978 , 0.1974 ,\n",
       "            0.197  , 0.1952 , 0.1943 , 0.1931 , 0.1925 , 0.1924 , 0.1913 ,\n",
       "            0.1912 , 0.1877 , 0.1876 , 0.1865 , 0.1864 , 0.1858 , 0.1853 ,\n",
       "            0.185  , 0.1849 , 0.1848 , 0.1837 , 0.1827 , 0.1812 , 0.181  ,\n",
       "            0.1803 , 0.1771 , 0.1764 , 0.1763 , 0.1748 , 0.1747 , 0.1746 ,\n",
       "            0.1737 , 0.1735 , 0.1726 , 0.1718 , 0.1703 , 0.1694 , 0.1683 ,\n",
       "            0.1682 , 0.1676 , 0.167  , 0.1658 , 0.1637 , 0.1627 , 0.1626 ,\n",
       "            0.1622 , 0.1619 , 0.1617 , 0.1616 , 0.1614 , 0.1604 , 0.1602 ,\n",
       "            0.1599 , 0.1598 , 0.1597 , 0.1594 , 0.1593 , 0.1589 , 0.1586 ,\n",
       "            0.1572 , 0.1567 , 0.1562 , 0.1561 , 0.156  , 0.1543 , 0.1527 ,\n",
       "            0.1525 , 0.1523 , 0.1511 , 0.1504 , 0.1497 , 0.1495 , 0.1494 ,\n",
       "            0.1484 , 0.1477 , 0.1471 , 0.1466 , 0.146  , 0.1459 , 0.1458 ,\n",
       "            0.1449 , 0.1432 , 0.1431 , 0.143  , 0.1426 , 0.1422 , 0.1417 ,\n",
       "            0.141  , 0.1409 , 0.1399 , 0.1398 , 0.1394 , 0.139  , 0.138  ,\n",
       "            0.1378 , 0.1372 , 0.1364 , 0.1356 , 0.1354 , 0.1346 , 0.133  ,\n",
       "            0.1328 , 0.1326 , 0.1311 , 0.1299 , 0.128  , 0.1278 , 0.1272 ,\n",
       "            0.1268 , 0.1267 , 0.1266 , 0.1262 , 0.1257 , 0.1256 , 0.1245 ,\n",
       "            0.12366, 0.1236 , 0.12213, 0.1217 , 0.12103, 0.12   , 0.1188 ,\n",
       "            0.1186 , 0.1184 , 0.11816, 0.1172 , 0.1166 , 0.11633, 0.11597,\n",
       "            0.11456, 0.1138 , 0.1134 , 0.112  , 0.11127, 0.11084, 0.11066,\n",
       "            0.1101 , 0.10895, 0.1082 , 0.1069 , 0.10504, 0.10486, 0.1047 ,\n",
       "            0.10266, 0.1    , 0.0967 , 0.09656, 0.0964 , 0.0959 , 0.09515,\n",
       "            0.0939 , 0.0927 , 0.0922 , 0.09155, 0.086  , 0.08417, 0.0827 ,\n",
       "            0.08093, 0.0798 , 0.0786 , 0.0761 , 0.0745 , 0.0734 , 0.0729 ,\n",
       "            0.0712 , 0.0708 , 0.06995, 0.0533 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.08474576,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.22033899, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.63559324, 0.6440678 ,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.65254235, 0.66101694,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7033898 , 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.779661  , 0.779661  ,\n",
       "            0.779661  , 0.7881356 , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8220339 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.8305085 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.9322034 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.13636364, 0.13636364, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.16666667, 0.17424242, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.18939394, 0.1969697 , 0.1969697 ,\n",
       "            0.20454545, 0.20454545, 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.3181818 ,\n",
       "            0.3181818 , 0.3181818 , 0.3181818 , 0.3181818 , 0.32575756,\n",
       "            0.3409091 , 0.3560606 , 0.36363637, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.47727272, 0.47727272, 0.4848485 , 0.49242425, 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.6060606 , 0.6060606 , 0.6212121 ,\n",
       "            0.6287879 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6818182 , 0.6969697 , 0.70454544, 0.70454544, 0.719697  ,\n",
       "            0.72727275, 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2788 , 0.2783 , 0.2751 , 0.274  , 0.2737 , 0.2734 ,\n",
       "            0.2715 , 0.2712 , 0.2705 , 0.2703 , 0.27   , 0.2698 , 0.2695 ,\n",
       "            0.2693 , 0.2688 , 0.2686 , 0.2683 , 0.2678 , 0.2668 , 0.2642 ,\n",
       "            0.2637 , 0.2622 , 0.2617 , 0.2605 , 0.2595 , 0.2585 , 0.2576 ,\n",
       "            0.256  , 0.2559 , 0.2554 , 0.255  , 0.2546 , 0.253  , 0.2527 ,\n",
       "            0.2496 , 0.2482 , 0.247  , 0.2467 , 0.2463 , 0.2445 , 0.2421 ,\n",
       "            0.239  , 0.2372 , 0.2314 , 0.229  , 0.2277 , 0.2256 , 0.2247 ,\n",
       "            0.2246 , 0.2194 , 0.2128 , 0.2123 , 0.2054 , 0.1985 , 0.1979 ,\n",
       "            0.1956 , 0.1942 , 0.1935 , 0.1882 , 0.1844 , 0.1838 , 0.1833 ,\n",
       "            0.1829 , 0.1824 , 0.1823 , 0.1797 , 0.1794 , 0.1779 , 0.1774 ,\n",
       "            0.1771 , 0.1764 , 0.1753 , 0.1729 , 0.1716 , 0.1715 , 0.1708 ,\n",
       "            0.1704 , 0.17   , 0.1699 , 0.1694 , 0.1687 , 0.1675 , 0.1671 ,\n",
       "            0.1653 , 0.165  , 0.1633 , 0.1621 , 0.162  , 0.1611 , 0.1598 ,\n",
       "            0.1597 , 0.1594 , 0.159  , 0.1575 , 0.157  , 0.1552 , 0.1543 ,\n",
       "            0.1534 , 0.1532 , 0.1531 , 0.1525 , 0.1514 , 0.1509 , 0.1508 ,\n",
       "            0.148  , 0.1472 , 0.1469 , 0.1467 , 0.1466 , 0.1465 , 0.1455 ,\n",
       "            0.145  , 0.1449 , 0.1448 , 0.1445 , 0.1442 , 0.1436 , 0.1423 ,\n",
       "            0.1418 , 0.1414 , 0.1412 , 0.1382 , 0.138  , 0.1377 , 0.1364 ,\n",
       "            0.1359 , 0.135  , 0.1349 , 0.1345 , 0.1339 , 0.1337 , 0.1333 ,\n",
       "            0.1329 , 0.1327 , 0.1322 , 0.1312 , 0.1307 , 0.1301 , 0.1287 ,\n",
       "            0.1284 , 0.1282 , 0.1279 , 0.1274 , 0.1273 , 0.127  , 0.1267 ,\n",
       "            0.1266 , 0.1265 , 0.1256 , 0.1254 , 0.12476, 0.1236 , 0.12335,\n",
       "            0.1225 , 0.1222 , 0.1214 , 0.1213 , 0.12054, 0.1186 , 0.11694,\n",
       "            0.11676, 0.11633, 0.11554, 0.113  , 0.1128 , 0.1126 , 0.1124 ,\n",
       "            0.11163, 0.11145, 0.1099 , 0.1097 , 0.10876, 0.1082 , 0.108  ,\n",
       "            0.10724, 0.1063 , 0.1052 , 0.1047 , 0.1041 , 0.1036 , 0.1034 ,\n",
       "            0.1032 , 0.10126, 0.1005 , 0.10034, 0.1    , 0.0991 , 0.09894,\n",
       "            0.09875, 0.09705, 0.096  , 0.09485, 0.09467, 0.094  , 0.0939 ,\n",
       "            0.0898 , 0.0871 , 0.0865 , 0.0859 , 0.08435, 0.08405, 0.08344,\n",
       "            0.0827 , 0.0824 , 0.082  , 0.0774 , 0.0745 , 0.07367, 0.07135,\n",
       "            0.0702 , 0.06915, 0.0672 , 0.0662 , 0.065  , 0.0644 , 0.0629 ,\n",
       "            0.06232, 0.0619 , 0.04672], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.09322034, 0.12711865,\n",
       "            0.13559322, 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.63559324, 0.6440678 ,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.65254235, 0.66101694,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.779661  , 0.779661  , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.89830506,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.90677965, 0.91525424,\n",
       "            0.91525424, 0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.08333334, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.10606061, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.14393939, 0.14393939, 0.15151516, 0.15151516, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.1969697 , 0.20454545, 0.20454545,\n",
       "            0.21212122, 0.21212122, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28030303, 0.28030303,\n",
       "            0.28787878, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.33333334, 0.3409091 ,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.4090909 ,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2659 , 0.2654 , 0.262  , 0.2617 , 0.2612 , 0.2595 ,\n",
       "            0.2593 , 0.259  , 0.2588 , 0.2583 , 0.258  , 0.2578 , 0.2573 ,\n",
       "            0.2563 , 0.2551 , 0.253  , 0.2527 , 0.252  , 0.2515 , 0.251  ,\n",
       "            0.2502 , 0.25   , 0.2487 , 0.2483 , 0.2471 , 0.246  , 0.2448 ,\n",
       "            0.2444 , 0.2434 , 0.2428 , 0.2426 , 0.2417 , 0.239  , 0.2374 ,\n",
       "            0.237  , 0.236  , 0.2343 , 0.2338 , 0.2325 , 0.2322 , 0.2278 ,\n",
       "            0.226  , 0.223  , 0.2175 , 0.2173 , 0.2161 , 0.2147 , 0.2129 ,\n",
       "            0.2079 , 0.2004 , 0.1995 , 0.1927 , 0.1924 , 0.1913 , 0.1853 ,\n",
       "            0.1833 , 0.1823 , 0.1815 , 0.1772 , 0.1754 , 0.1715 , 0.1711 ,\n",
       "            0.1705 , 0.17   , 0.1685 , 0.1676 , 0.1674 , 0.1653 , 0.1652 ,\n",
       "            0.1647 , 0.1646 , 0.1638 , 0.1611 , 0.1603 , 0.159  , 0.1584 ,\n",
       "            0.1583 , 0.158  , 0.1578 , 0.157  , 0.1565 , 0.1561 , 0.1559 ,\n",
       "            0.1544 , 0.1533 , 0.1515 , 0.1503 , 0.1499 , 0.1492 , 0.1482 ,\n",
       "            0.148  , 0.1477 , 0.1469 , 0.1451 , 0.1447 , 0.1432 , 0.1422 ,\n",
       "            0.142  , 0.1418 , 0.1411 , 0.1409 , 0.1395 , 0.1388 , 0.1387 ,\n",
       "            0.1367 , 0.1366 , 0.1365 , 0.1356 , 0.1351 , 0.1349 , 0.134  ,\n",
       "            0.1338 , 0.1333 , 0.1329 , 0.1328 , 0.1326 , 0.1318 , 0.1313 ,\n",
       "            0.1302 , 0.1301 , 0.13   , 0.1299 , 0.1294 , 0.1279 , 0.1278 ,\n",
       "            0.1267 , 0.1261 , 0.1249 , 0.12463, 0.1239 , 0.1238 , 0.1229 ,\n",
       "            0.1226 , 0.1222 , 0.12146, 0.121  , 0.12036, 0.11993, 0.1194 ,\n",
       "            0.1193 , 0.1192 , 0.119  , 0.1186 , 0.1178 , 0.11755, 0.1172 ,\n",
       "            0.11694, 0.11633, 0.1158 , 0.11554, 0.11475, 0.1138 , 0.113  ,\n",
       "            0.112  , 0.11145, 0.111  , 0.1105 , 0.1103 , 0.1099 , 0.1078 ,\n",
       "            0.1074 , 0.10724, 0.1063 , 0.1043 , 0.1036 , 0.103  , 0.10266,\n",
       "            0.1023 , 0.1021 , 0.1019 , 0.10175, 0.10156, 0.10144, 0.1009 ,\n",
       "            0.1005 , 0.10034, 0.0997 , 0.0995 , 0.09827, 0.0981 , 0.09753,\n",
       "            0.0974 , 0.09705, 0.0964 , 0.096  , 0.0955 , 0.09534, 0.09467,\n",
       "            0.0945 , 0.0939 , 0.09235, 0.0906 , 0.0903 , 0.0888 , 0.0887 ,\n",
       "            0.0882 , 0.088  , 0.0854 , 0.08167, 0.0808 , 0.0801 , 0.07904,\n",
       "            0.0789 , 0.0785 , 0.0775 , 0.07684, 0.075  , 0.07434, 0.07367,\n",
       "            0.0698 , 0.0678 , 0.0667 , 0.0631 , 0.0628 , 0.06177, 0.0612 ,\n",
       "            0.0603 , 0.05966, 0.05856, 0.05823, 0.04428], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.05932203, 0.07627118, 0.11016949, 0.12711865, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.55932206, 0.5677966 ,\n",
       "            0.58474576, 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7033898 , 0.7033898 ,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7288136 ,\n",
       "            0.7372881 , 0.7542373 , 0.7542373 , 0.7542373 , 0.7542373 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.83898306, 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.87288135, 0.88135594, 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.90677965, 0.9237288 ,\n",
       "            0.9237288 , 0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.9322034 , 0.94067794, 0.94067794,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00757576,\n",
       "            0.00757576, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.09848485, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.12121212, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.14393939, 0.15151516, 0.15151516, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.20454545, 0.21212122,\n",
       "            0.21212122, 0.21212122, 0.21969697, 0.22727273, 0.22727273,\n",
       "            0.23484848, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.28030303, 0.28787878, 0.28787878, 0.29545453,\n",
       "            0.29545453, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.32575756, 0.33333334, 0.33333334, 0.3409091 ,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37878788,\n",
       "            0.37878788, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.4848485 , 0.5       , 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.719697  , 0.7348485 , 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2522 , 0.2517 , 0.2494 , 0.2493 , 0.2473 , 0.2471 ,\n",
       "            0.247  , 0.2463 , 0.2462 , 0.2458 , 0.2441 , 0.244  , 0.2434 ,\n",
       "            0.2429 , 0.2422 , 0.2417 , 0.241  , 0.2407 , 0.2394 , 0.2383 ,\n",
       "            0.2375 , 0.2374 , 0.236  , 0.2352 , 0.2339 , 0.2338 , 0.2328 ,\n",
       "            0.2327 , 0.2319 , 0.2314 , 0.2306 , 0.228  , 0.2273 , 0.2256 ,\n",
       "            0.2252 , 0.2244 , 0.2224 , 0.222  , 0.2175 , 0.2166 , 0.2144 ,\n",
       "            0.2073 , 0.2068 , 0.2058 , 0.2047 , 0.2002 , 0.1965 , 0.1886 ,\n",
       "            0.1859 , 0.1841 , 0.1799 , 0.1791 , 0.1735 , 0.1733 , 0.17   ,\n",
       "            0.1692 , 0.1688 , 0.1625 , 0.1616 , 0.1599 , 0.1584 , 0.1581 ,\n",
       "            0.1575 , 0.156  , 0.1549 , 0.1547 , 0.153  , 0.1519 , 0.1515 ,\n",
       "            0.151  , 0.1503 , 0.1487 , 0.1477 , 0.1467 , 0.1465 , 0.1455 ,\n",
       "            0.1454 , 0.1448 , 0.144  , 0.1421 , 0.1412 , 0.1411 , 0.1385 ,\n",
       "            0.1383 , 0.1376 , 0.1373 , 0.1372 , 0.1371 , 0.1365 , 0.1361 ,\n",
       "            0.1326 , 0.1312 , 0.1311 , 0.131  , 0.1307 , 0.1301 , 0.1295 ,\n",
       "            0.1289 , 0.1288 , 0.1278 , 0.1272 , 0.1268 , 0.1262 , 0.1251 ,\n",
       "            0.1239 , 0.1235 , 0.1229 , 0.12213, 0.122  , 0.1219 , 0.12177,\n",
       "            0.1217 , 0.1213 , 0.12103, 0.1207 , 0.1192 , 0.1188 , 0.1186 ,\n",
       "            0.1184 , 0.118  , 0.1178 , 0.1158 , 0.11536, 0.11475, 0.1134 ,\n",
       "            0.11316, 0.1126 , 0.1124 , 0.1122 , 0.112  , 0.11163, 0.11145,\n",
       "            0.1101 , 0.1099 , 0.1097 , 0.10895, 0.10876, 0.1084 , 0.1076 ,\n",
       "            0.1074 , 0.1069 , 0.1067 , 0.1065 , 0.1052 , 0.10504, 0.1043 ,\n",
       "            0.1034 , 0.10284, 0.1023 , 0.1009 , 0.10016, 0.0997 , 0.0995 ,\n",
       "            0.09753, 0.0974 , 0.09705, 0.0967 , 0.09656, 0.0964 , 0.096  ,\n",
       "            0.0959 , 0.094  , 0.0935 , 0.0933 , 0.093  , 0.09283, 0.0927 ,\n",
       "            0.0922 , 0.09204, 0.09106, 0.0909 , 0.0904 , 0.0899 , 0.0898 ,\n",
       "            0.0896 , 0.0876 , 0.0868 , 0.0866 , 0.086  , 0.0851 , 0.08496,\n",
       "            0.08405, 0.0831 , 0.08124, 0.0799 , 0.07947, 0.0774 , 0.07666,\n",
       "            0.0764 , 0.07574, 0.0742 , 0.0741 , 0.0733 , 0.0724 , 0.0709 ,\n",
       "            0.0707 , 0.07043, 0.0667 , 0.06635, 0.0661 , 0.066  , 0.06464,\n",
       "            0.0636 , 0.05988, 0.05975, 0.0589 , 0.05676, 0.0556 , 0.0549 ,\n",
       "            0.0541 , 0.04208], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.03389831, 0.05932203,\n",
       "            0.07627118, 0.10169491, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7881356 , 0.7966102 , 0.8135593 , 0.8135593 , 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.89830506, 0.89830506, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.90677965, 0.91525424,\n",
       "            0.91525424, 0.9237288 , 0.9237288 , 0.9237288 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 0.9915254 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12121212, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.15151516,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.1969697 , 0.21212122,\n",
       "            0.21212122, 0.21969697, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.24242425, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.31060606, 0.32575756, 0.32575756,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.37121212, 0.37121212, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.38636363, 0.3939394 , 0.40151516, 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.4469697 , 0.4469697 , 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.4848485 , 0.49242425,\n",
       "            0.5151515 , 0.5151515 , 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.6060606 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.70454544, 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.74242425, 0.74242425,\n",
       "            0.75      , 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2395 , 0.2388 , 0.2375 , 0.2358 , 0.2356 , 0.2355 ,\n",
       "            0.235  , 0.2347 , 0.2343 , 0.233  , 0.2319 , 0.2318 , 0.231  ,\n",
       "            0.2307 , 0.2306 , 0.2303 , 0.2299 , 0.229  , 0.2285 , 0.2273 ,\n",
       "            0.2268 , 0.2249 , 0.2246 , 0.2244 , 0.2234 , 0.2233 , 0.2222 ,\n",
       "            0.222  , 0.2218 , 0.2208 , 0.2203 , 0.2198 , 0.2181 , 0.2179 ,\n",
       "            0.2157 , 0.2156 , 0.2152 , 0.2128 , 0.2109 , 0.2069 , 0.206  ,\n",
       "            0.2059 , 0.2047 , 0.199  , 0.1976 , 0.1962 , 0.1959 , 0.1901 ,\n",
       "            0.1871 , 0.1794 , 0.1771 , 0.1758 , 0.1704 , 0.1693 , 0.1653 ,\n",
       "            0.1641 , 0.1636 , 0.1599 , 0.1592 , 0.1556 , 0.1532 , 0.1514 ,\n",
       "            0.1494 , 0.1493 , 0.149  , 0.1487 , 0.1476 , 0.1467 , 0.1462 ,\n",
       "            0.145  , 0.1444 , 0.1436 , 0.1434 , 0.1431 , 0.1426 , 0.1425 ,\n",
       "            0.1421 , 0.1392 , 0.1384 , 0.1381 , 0.1372 , 0.137  , 0.1368 ,\n",
       "            0.1362 , 0.1356 , 0.1343 , 0.134  , 0.1328 , 0.1322 , 0.1305 ,\n",
       "            0.13   , 0.1293 , 0.129  , 0.1284 , 0.128  , 0.1251 , 0.12445,\n",
       "            0.1235 , 0.12335, 0.12305, 0.1229 , 0.1222 , 0.12177, 0.1216 ,\n",
       "            0.12103, 0.12024, 0.1188 , 0.11755, 0.1174 , 0.11633, 0.11597,\n",
       "            0.1152 , 0.11456, 0.1144 , 0.1142 , 0.1138 , 0.1134 , 0.113  ,\n",
       "            0.1128 , 0.112  , 0.11163, 0.11145, 0.11127, 0.111  , 0.11084,\n",
       "            0.1103 , 0.1101 , 0.10913, 0.1086 , 0.1074 , 0.10724, 0.1065 ,\n",
       "            0.1063 , 0.10614, 0.10596, 0.10504, 0.1043 , 0.1032 , 0.103  ,\n",
       "            0.10284, 0.1019 , 0.10175, 0.10126, 0.1011 , 0.1007 , 0.1005 ,\n",
       "            0.0995 , 0.09845, 0.0981 , 0.09753, 0.09656, 0.096  , 0.0959 ,\n",
       "            0.0955 , 0.094  , 0.0939 , 0.0935 , 0.0933 , 0.093  , 0.0927 ,\n",
       "            0.0925 , 0.0914 , 0.0909 , 0.0906 , 0.0904 , 0.0898 , 0.0896 ,\n",
       "            0.0893 , 0.089  , 0.0885 , 0.0876 , 0.0873 , 0.0871 , 0.0869 ,\n",
       "            0.0866 , 0.0865 , 0.0862 , 0.0859 , 0.0857 , 0.08435, 0.08417,\n",
       "            0.08344, 0.0833 , 0.083  , 0.0828 , 0.0824 , 0.08124, 0.0806 ,\n",
       "            0.0805 , 0.0799 , 0.07935, 0.0792 , 0.07904, 0.07544, 0.07434,\n",
       "            0.0742 , 0.07355, 0.0733 , 0.0732 , 0.0712 , 0.0709 , 0.0707 ,\n",
       "            0.0703 , 0.06915, 0.06793, 0.0656 , 0.06537, 0.06384, 0.0631 ,\n",
       "            0.06232, 0.06152, 0.0613 , 0.06085, 0.0576 , 0.05737, 0.05685,\n",
       "            0.0547 , 0.0543 , 0.0535 , 0.05252, 0.04968, 0.04062],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.03389831, 0.05084746,\n",
       "            0.05932203, 0.08474576, 0.10169491, 0.11016949, 0.12711865,\n",
       "            0.13559322, 0.15254237, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.65254235, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.720339  , 0.7288136 ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.83898306, 0.83898306,\n",
       "            0.84745765, 0.84745765, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.87288135, 0.87288135, 0.87288135, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.89830506, 0.89830506, 0.89830506, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.94067794, 0.9491525 , 0.9491525 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.10606061, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.12878788, 0.13636364, 0.1590909 , 0.1590909 ,\n",
       "            0.16666667, 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.24242425, 0.25      ,\n",
       "            0.25      , 0.25757575, 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3030303 , 0.31060606,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.33333334,\n",
       "            0.3409091 , 0.3560606 , 0.37121212, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.4090909 , 0.4090909 ,\n",
       "            0.41666666, 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.54545456, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.7651515 , 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2274 , 0.2269 , 0.2268 , 0.2263 , 0.2261 , 0.226  ,\n",
       "            0.2257 , 0.2256 , 0.2252 , 0.2249 , 0.2225 , 0.2217 , 0.2216 ,\n",
       "            0.2212 , 0.2207 , 0.2195 , 0.2191 , 0.2184 , 0.2179 , 0.2177 ,\n",
       "            0.2157 , 0.2156 , 0.2152 , 0.2145 , 0.214  , 0.2134 , 0.2133 ,\n",
       "            0.2123 , 0.2118 , 0.2114 , 0.2108 , 0.2106 , 0.2091 , 0.2085 ,\n",
       "            0.2074 , 0.206  , 0.2026 , 0.2006 , 0.1991 , 0.1967 , 0.195  ,\n",
       "            0.194  , 0.191  , 0.1897 , 0.1884 , 0.1814 , 0.1796 , 0.1735 ,\n",
       "            0.1716 , 0.1666 , 0.162  , 0.1606 , 0.1602 , 0.1597 , 0.1564 ,\n",
       "            0.1525 , 0.152  , 0.1504 , 0.1451 , 0.1444 , 0.1426 , 0.1422 ,\n",
       "            0.1414 , 0.1412 , 0.1409 , 0.1405 , 0.1393 , 0.1392 , 0.1389 ,\n",
       "            0.1377 , 0.1373 , 0.1357 , 0.1342 , 0.132  , 0.1312 , 0.1307 ,\n",
       "            0.13   , 0.1298 , 0.1292 , 0.1289 , 0.1284 , 0.1278 , 0.1249 ,\n",
       "            0.1239 , 0.12317, 0.1223 , 0.122  , 0.12177, 0.1216 , 0.1197 ,\n",
       "            0.1186 , 0.1174 , 0.1172 , 0.11694, 0.11615, 0.11536, 0.1152 ,\n",
       "            0.115  , 0.11456, 0.11316, 0.1122 , 0.111  , 0.1101 , 0.1099 ,\n",
       "            0.1095 , 0.1086 , 0.1084 , 0.1082 , 0.1074 , 0.10724, 0.1069 ,\n",
       "            0.1067 , 0.1065 , 0.1056 , 0.10504, 0.10486, 0.1045 , 0.1043 ,\n",
       "            0.10394, 0.10376, 0.1034 , 0.1032 , 0.103  , 0.10266, 0.10144,\n",
       "            0.10126, 0.1005 , 0.10034, 0.1    , 0.0993 , 0.0991 , 0.0986 ,\n",
       "            0.09845, 0.0981 , 0.0974 , 0.09705, 0.0967 , 0.09656, 0.0964 ,\n",
       "            0.0959 , 0.0957 , 0.09503, 0.0937 , 0.0927 , 0.0922 , 0.09204,\n",
       "            0.09155, 0.09106, 0.0906 , 0.0904 , 0.0899 , 0.0898 , 0.0891 ,\n",
       "            0.0887 , 0.0882 , 0.0879 , 0.0877 , 0.0874 , 0.0871 , 0.0865 ,\n",
       "            0.0862 , 0.086  , 0.0856 , 0.08417, 0.08405, 0.08344, 0.0831 ,\n",
       "            0.082  , 0.0818 , 0.08167, 0.08093, 0.0806 , 0.0804 , 0.0799 ,\n",
       "            0.07935, 0.0788 , 0.07837, 0.07764, 0.0775 , 0.0774 , 0.0763 ,\n",
       "            0.07587, 0.07544, 0.07465, 0.07434, 0.0729 , 0.0725 , 0.0717 ,\n",
       "            0.0709 , 0.07043, 0.0695 , 0.06903, 0.0689 , 0.0688 , 0.0677 ,\n",
       "            0.0673 , 0.06696, 0.0629 , 0.0619 , 0.06165, 0.06085, 0.06064,\n",
       "            0.0576 , 0.05698, 0.05685, 0.05646, 0.0541 , 0.0533 , 0.05292,\n",
       "            0.05167, 0.0463 , 0.04037], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01694915, 0.03389831, 0.05932203, 0.07627118,\n",
       "            0.09322034, 0.11016949, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.1779661 , 0.18644068, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.31355932, 0.3220339 , 0.33050847, 0.34745762,\n",
       "            0.3559322 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.65254235, 0.65254235, 0.66101694,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.720339  , 0.720339  ,\n",
       "            0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7881356 , 0.7966102 , 0.7966102 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.8305085 , 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.87288135, 0.87288135, 0.87288135, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.90677965, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.91525424, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 , 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03787879, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.13636364, 0.14393939,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.1590909 , 0.16666667,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.25757575,\n",
       "            0.2651515 , 0.2651515 , 0.28030303, 0.28787878, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.31060606, 0.3181818 ,\n",
       "            0.3181818 , 0.3181818 , 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.5       , 0.50757575, 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.5833333 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.6969697 , 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.7348485 , 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.8484849 , 0.8636364 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2172 , 0.217  , 0.2168 , 0.2167 , 0.2166 , 0.2162 ,\n",
       "            0.2161 , 0.2157 , 0.2156 , 0.2152 , 0.2148 , 0.2134 , 0.2128 ,\n",
       "            0.212  , 0.2119 , 0.2113 , 0.2106 , 0.2101 , 0.21   , 0.2098 ,\n",
       "            0.2094 , 0.209  , 0.2081 , 0.2075 , 0.207  , 0.2069 , 0.2068 ,\n",
       "            0.2058 , 0.2056 , 0.2045 , 0.204  , 0.2024 , 0.2023 , 0.2012 ,\n",
       "            0.1971 , 0.195  , 0.1935 , 0.1927 , 0.1913 , 0.1896 , 0.1882 ,\n",
       "            0.187  , 0.1848 , 0.178  , 0.1768 , 0.1725 , 0.1692 , 0.164  ,\n",
       "            0.1599 , 0.1587 , 0.1584 , 0.1548 , 0.1527 , 0.1505 , 0.1482 ,\n",
       "            0.1439 , 0.1436 , 0.1434 , 0.1412 , 0.1405 , 0.1404 , 0.14   ,\n",
       "            0.1399 , 0.1398 , 0.1381 , 0.1375 , 0.1366 , 0.1348 , 0.133  ,\n",
       "            0.1329 , 0.1315 , 0.1313 , 0.1302 , 0.1301 , 0.1298 , 0.129  ,\n",
       "            0.1289 , 0.1285 , 0.1279 , 0.1278 , 0.1272 , 0.1251 , 0.124  ,\n",
       "            0.1236 , 0.12274, 0.1226 , 0.1217 , 0.1214 , 0.1201 , 0.11816,\n",
       "            0.1172 , 0.11694, 0.11676, 0.11633, 0.1158 , 0.11554, 0.115  ,\n",
       "            0.1144 , 0.11316, 0.1118 , 0.11163, 0.111  , 0.1099 , 0.1095 ,\n",
       "            0.1093 , 0.1084 , 0.1082 , 0.108  , 0.1078 , 0.10724, 0.1063 ,\n",
       "            0.10614, 0.10596, 0.1056 , 0.10486, 0.1047 , 0.1045 , 0.10394,\n",
       "            0.10376, 0.1034 , 0.103  , 0.10284, 0.10156, 0.10144, 0.1009 ,\n",
       "            0.10034, 0.1    , 0.0997 , 0.0993 , 0.0986 , 0.0979 , 0.0977 ,\n",
       "            0.0974 , 0.0972 , 0.09705, 0.09686, 0.0967 , 0.0962 , 0.0959 ,\n",
       "            0.09534, 0.0942 , 0.0939 , 0.0932 , 0.09283, 0.0925 , 0.09235,\n",
       "            0.09186, 0.09125, 0.09106, 0.0909 , 0.09076, 0.0904 , 0.0898 ,\n",
       "            0.089  , 0.0888 , 0.0882 , 0.088  , 0.0879 , 0.0876 , 0.0874 ,\n",
       "            0.0859 , 0.0854 , 0.0845 , 0.08417, 0.0833 , 0.0825 , 0.0824 ,\n",
       "            0.082  , 0.08136, 0.0806 , 0.0801 , 0.0799 , 0.07904, 0.0788 ,\n",
       "            0.0778 , 0.07764, 0.0775 , 0.07654, 0.0764 , 0.076  , 0.07574,\n",
       "            0.07556, 0.07544, 0.07477, 0.0745 , 0.07227, 0.0716 , 0.0715 ,\n",
       "            0.0703 , 0.0694 , 0.06757, 0.06586, 0.06464, 0.0645 , 0.0636 ,\n",
       "            0.0629 , 0.0612 , 0.05988, 0.05942, 0.05933, 0.05814, 0.0575 ,\n",
       "            0.05707, 0.05612, 0.05573, 0.0544 , 0.0471 , 0.04312],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.08474576, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.22033899,\n",
       "            0.23728813, 0.2542373 , 0.26271185, 0.27118644, 0.2881356 ,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.41525424, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.6101695 , 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.65254235, 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.720339  , 0.720339  , 0.720339  , 0.7288136 , 0.7288136 ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.779661  , 0.779661  , 0.7966102 , 0.7966102 , 0.7966102 ,\n",
       "            0.80508476, 0.80508476, 0.8220339 , 0.8220339 , 0.8220339 ,\n",
       "            0.8305085 , 0.8305085 , 0.8305085 , 0.8305085 , 0.8305085 ,\n",
       "            0.83898306, 0.83898306, 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.87288135, 0.87288135,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.89830506,\n",
       "            0.89830506, 0.90677965, 0.90677965, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.94067794,\n",
       "            0.94067794, 0.94067794, 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.14393939, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.1590909 , 0.16666667, 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.22727273, 0.22727273,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.27272728, 0.28030303, 0.28030303,\n",
       "            0.28787878, 0.28787878, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3181818 , 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.36363637, 0.37121212, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.47727272, 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.50757575, 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.5378788 , 0.5378788 , 0.54545456, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.6060606 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.7651515 , 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.8181818 , 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2124 , 0.212  , 0.2115 , 0.211  , 0.2104 , 0.2103 ,\n",
       "            0.2101 , 0.21   , 0.2098 , 0.2096 , 0.2095 , 0.2094 , 0.2091 ,\n",
       "            0.209  , 0.2086 , 0.2085 , 0.2084 , 0.2075 , 0.2074 , 0.2064 ,\n",
       "            0.2063 , 0.206  , 0.2058 , 0.2051 , 0.205  , 0.2047 , 0.2037 ,\n",
       "            0.2034 , 0.2028 , 0.2024 , 0.2021 , 0.1998 , 0.1995 , 0.1978 ,\n",
       "            0.196  , 0.1952 , 0.1936 , 0.1907 , 0.1897 , 0.1887 , 0.1865 ,\n",
       "            0.1864 , 0.1799 , 0.1794 , 0.1764 , 0.1724 , 0.1666 , 0.1649 ,\n",
       "            0.1637 , 0.1636 , 0.1617 , 0.159  , 0.1582 , 0.1552 , 0.1515 ,\n",
       "            0.1493 , 0.1488 , 0.1484 , 0.1466 , 0.1464 , 0.1456 , 0.1454 ,\n",
       "            0.1451 , 0.1449 , 0.1436 , 0.1431 , 0.1417 , 0.1398 , 0.1382 ,\n",
       "            0.1376 , 0.1371 , 0.1367 , 0.1348 , 0.1343 , 0.1342 , 0.1339 ,\n",
       "            0.1338 , 0.1332 , 0.1329 , 0.1323 , 0.1316 , 0.1313 , 0.1296 ,\n",
       "            0.1292 , 0.1289 , 0.1274 , 0.1273 , 0.127  , 0.1268 , 0.1267 ,\n",
       "            0.12445, 0.12335, 0.12274, 0.1225 , 0.122  , 0.12115, 0.12085,\n",
       "            0.12067, 0.1204 , 0.12024, 0.1198 , 0.1197 , 0.119  , 0.11694,\n",
       "            0.11676, 0.1152 , 0.11475, 0.1142 , 0.1138 , 0.1134 , 0.11316,\n",
       "            0.113  , 0.1126 , 0.112  , 0.1118 , 0.11163, 0.11145, 0.111  ,\n",
       "            0.1105 , 0.1103 , 0.1093 , 0.10913, 0.1086 , 0.1084 , 0.1074 ,\n",
       "            0.10724, 0.1069 , 0.1063 , 0.10596, 0.1058 , 0.1054 , 0.1043 ,\n",
       "            0.1041 , 0.10394, 0.10376, 0.1032 , 0.103  , 0.10284, 0.1019 ,\n",
       "            0.10144, 0.1011 , 0.10016, 0.0998 , 0.0995 , 0.0993 , 0.09845,\n",
       "            0.09827, 0.0981 , 0.0974 , 0.0972 , 0.09705, 0.09686, 0.0967 ,\n",
       "            0.09656, 0.0939 , 0.0933 , 0.09283, 0.0927 , 0.09235, 0.09155,\n",
       "            0.0914 , 0.09125, 0.0898 , 0.0896 , 0.0895 , 0.0893 , 0.0887 ,\n",
       "            0.0885 , 0.0877 , 0.0869 , 0.0862 , 0.0854 , 0.08435, 0.08417,\n",
       "            0.0836 , 0.083  , 0.0827 , 0.0824 , 0.0823 , 0.082  , 0.08167,\n",
       "            0.0804 , 0.0799 , 0.07935, 0.07904, 0.07806, 0.0778 , 0.0772 ,\n",
       "            0.07477, 0.0733 , 0.07306, 0.07227, 0.07196, 0.0709 , 0.0689 ,\n",
       "            0.0672 , 0.06696, 0.0666 , 0.0662 , 0.0642 , 0.0635 , 0.06335,\n",
       "            0.0629 , 0.0627 , 0.06165, 0.05185, 0.0495 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.08474576,\n",
       "            0.11016949, 0.11864407, 0.13559322, 0.15254237, 0.16949153,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.59322035, 0.59322035,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.65254235, 0.65254235, 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.69491524, 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.720339  , 0.720339  ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 , 0.7542373 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.7966102 , 0.7966102 , 0.80508476, 0.8135593 , 0.8135593 ,\n",
       "            0.8135593 , 0.8220339 , 0.8220339 , 0.8220339 , 0.8220339 ,\n",
       "            0.8220339 , 0.8220339 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.8559322 , 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.87288135, 0.87288135, 0.87288135,\n",
       "            0.87288135, 0.88135594, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.91525424, 0.9237288 ,\n",
       "            0.9237288 , 0.9237288 , 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.07575758, 0.08333334, 0.09090909, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.15151516, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18181819, 0.18181819, 0.18939394,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.23484848, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.27272728, 0.28030303, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.29545453, 0.29545453, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.3409091 ,\n",
       "            0.3560606 , 0.37121212, 0.37121212, 0.37878788, 0.37878788,\n",
       "            0.37878788, 0.38636363, 0.38636363, 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.5       , 0.5151515 ,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.5833333 , 0.59090906, 0.5984849 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.215  , 0.2142 , 0.2139 , 0.2135 , 0.2133 , 0.2124 ,\n",
       "            0.2123 , 0.2109 , 0.2104 , 0.2103 , 0.2091 , 0.209  , 0.2086 ,\n",
       "            0.2081 , 0.208  , 0.2079 , 0.2075 , 0.2074 , 0.2073 , 0.2068 ,\n",
       "            0.2065 , 0.2063 , 0.206  , 0.2059 , 0.2056 , 0.2053 , 0.205  ,\n",
       "            0.2048 , 0.2042 , 0.2031 , 0.2024 , 0.2015 , 0.2013 , 0.1987 ,\n",
       "            0.1984 , 0.1979 , 0.1978 , 0.1934 , 0.1921 , 0.1919 , 0.1893 ,\n",
       "            0.1871 , 0.1865 , 0.1858 , 0.1857 , 0.1848 , 0.1843 , 0.179  ,\n",
       "            0.1765 , 0.1735 , 0.1714 , 0.1703 , 0.1699 , 0.1671 , 0.1664 ,\n",
       "            0.1625 , 0.1622 , 0.1587 , 0.1581 , 0.1571 , 0.1562 , 0.1554 ,\n",
       "            0.1549 , 0.154  , 0.1539 , 0.1525 , 0.152  , 0.1519 , 0.1512 ,\n",
       "            0.1504 , 0.1495 , 0.1483 , 0.147  , 0.1456 , 0.1454 , 0.1439 ,\n",
       "            0.143  , 0.1423 , 0.1421 , 0.142  , 0.1417 , 0.1414 , 0.1411 ,\n",
       "            0.141  , 0.1405 , 0.1401 , 0.1384 , 0.1382 , 0.138  , 0.1376 ,\n",
       "            0.1357 , 0.1354 , 0.1343 , 0.1333 , 0.1326 , 0.1322 , 0.1312 ,\n",
       "            0.13   , 0.1293 , 0.1289 , 0.1283 , 0.1277 , 0.1274 , 0.127  ,\n",
       "            0.1267 , 0.126  , 0.1259 , 0.1255 , 0.1249 , 0.12445, 0.1239 ,\n",
       "            0.12305, 0.1229 , 0.12274, 0.1225 , 0.1219 , 0.1214 , 0.121  ,\n",
       "            0.12054, 0.12036, 0.11993, 0.1194 , 0.1186 , 0.1184 , 0.11816,\n",
       "            0.1172 , 0.11694, 0.11676, 0.11633, 0.1158 , 0.11554, 0.115  ,\n",
       "            0.11475, 0.11456, 0.1144 , 0.1142 , 0.11395, 0.1138 , 0.11316,\n",
       "            0.113  , 0.1126 , 0.1124 , 0.1122 , 0.112  , 0.1118 , 0.11145,\n",
       "            0.11084, 0.11066, 0.1105 , 0.1097 , 0.1093 , 0.10913, 0.10895,\n",
       "            0.10706, 0.1065 , 0.1063 , 0.10596, 0.1054 , 0.10486, 0.1047 ,\n",
       "            0.1045 , 0.1043 , 0.1023 , 0.1019 , 0.10175, 0.1009 , 0.1007 ,\n",
       "            0.1005 , 0.10034, 0.1    , 0.0991 , 0.0974 , 0.09705, 0.0967 ,\n",
       "            0.09656, 0.0964 , 0.09515, 0.09485, 0.0937 , 0.09283, 0.0922 ,\n",
       "            0.09204, 0.09155, 0.09125, 0.0909 , 0.0906 , 0.0896 , 0.0895 ,\n",
       "            0.0893 , 0.089  , 0.088  , 0.0874 , 0.0862 , 0.0851 , 0.08496,\n",
       "            0.0848 , 0.0836 , 0.0821 , 0.08093, 0.07965, 0.0792 , 0.07904,\n",
       "            0.0774 , 0.0764 , 0.07556, 0.075  , 0.07367, 0.0729 , 0.07056,\n",
       "            0.06964, 0.06052, 0.05844], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27966103, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.60169494, 0.60169494, 0.6101695 , 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.63559324, 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.65254235, 0.66101694, 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.66101694, 0.6694915 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.720339  , 0.720339  ,\n",
       "            0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7881356 , 0.7966102 , 0.7966102 , 0.7966102 , 0.8135593 ,\n",
       "            0.8220339 , 0.8220339 , 0.8220339 , 0.8220339 , 0.8220339 ,\n",
       "            0.8305085 , 0.8305085 , 0.8305085 , 0.83898306, 0.83898306,\n",
       "            0.84745765, 0.84745765, 0.8559322 , 0.86440676, 0.86440676,\n",
       "            0.87288135, 0.87288135, 0.87288135, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06818182, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.09090909, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.1969697 , 0.20454545, 0.20454545, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25      , 0.25757575, 0.2651515 , 0.2651515 ,\n",
       "            0.27272728, 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.4090909 , 0.4090909 , 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.50757575, 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.5378788 , 0.54545456, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.5984849 , 0.5984849 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.68939394, 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.79545456, 0.8030303 , 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8787879 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2207 , 0.22   , 0.2195 , 0.2194 , 0.219  , 0.2189 ,\n",
       "            0.2185 , 0.2179 , 0.2172 , 0.2144 , 0.2142 , 0.214  , 0.2137 ,\n",
       "            0.2134 , 0.2128 , 0.2125 , 0.2123 , 0.2119 , 0.2115 , 0.2113 ,\n",
       "            0.2109 , 0.2106 , 0.2103 , 0.2096 , 0.2091 , 0.209  , 0.2086 ,\n",
       "            0.2085 , 0.2084 , 0.2075 , 0.207  , 0.2069 , 0.2068 , 0.206  ,\n",
       "            0.2059 , 0.2056 , 0.205  , 0.2039 , 0.2034 , 0.2017 , 0.2001 ,\n",
       "            0.1981 , 0.1965 , 0.1959 , 0.1947 , 0.1935 , 0.1906 , 0.19   ,\n",
       "            0.1884 , 0.1871 , 0.1849 , 0.1841 , 0.1815 , 0.1814 , 0.1788 ,\n",
       "            0.1787 , 0.178  , 0.1779 , 0.1752 , 0.1743 , 0.1735 , 0.1707 ,\n",
       "            0.1694 , 0.1687 , 0.1678 , 0.1676 , 0.1675 , 0.1672 , 0.1669 ,\n",
       "            0.1652 , 0.1647 , 0.1644 , 0.1636 , 0.1632 , 0.1625 , 0.1624 ,\n",
       "            0.1597 , 0.1584 , 0.1582 , 0.1575 , 0.1565 , 0.1556 , 0.1555 ,\n",
       "            0.1554 , 0.1544 , 0.1542 , 0.1533 , 0.1532 , 0.153  , 0.1517 ,\n",
       "            0.1508 , 0.15   , 0.1488 , 0.1487 , 0.1486 , 0.1484 , 0.1483 ,\n",
       "            0.1466 , 0.1465 , 0.1444 , 0.1439 , 0.1437 , 0.1433 , 0.1422 ,\n",
       "            0.1421 , 0.1415 , 0.1409 , 0.1407 , 0.1403 , 0.1401 , 0.14   ,\n",
       "            0.1399 , 0.1395 , 0.1389 , 0.1384 , 0.1377 , 0.1376 , 0.1366 ,\n",
       "            0.1359 , 0.1354 , 0.1348 , 0.1343 , 0.1339 , 0.1332 , 0.1326 ,\n",
       "            0.1324 , 0.1322 , 0.1317 , 0.1313 , 0.131  , 0.1306 , 0.1304 ,\n",
       "            0.1301 , 0.1296 , 0.1295 , 0.1292 , 0.1288 , 0.1287 , 0.1285 ,\n",
       "            0.1282 , 0.1279 , 0.1278 , 0.1274 , 0.1272 , 0.127  , 0.1267 ,\n",
       "            0.1263 , 0.1262 , 0.1261 , 0.1259 , 0.1254 , 0.1251 , 0.12476,\n",
       "            0.12463, 0.1242 , 0.12305, 0.1229 , 0.12244, 0.1217 , 0.1214 ,\n",
       "            0.1213 , 0.1207 , 0.12   , 0.1195 , 0.1192 , 0.1186 , 0.1184 ,\n",
       "            0.1178 , 0.11755, 0.11694, 0.11597, 0.11395, 0.1134 , 0.113  ,\n",
       "            0.1126 , 0.1124 , 0.1122 , 0.11163, 0.111  , 0.1101 , 0.1099 ,\n",
       "            0.1097 , 0.1093 , 0.10913, 0.1082 , 0.1076 , 0.1074 , 0.1067 ,\n",
       "            0.1052 , 0.10376, 0.1032 , 0.10266, 0.10175, 0.10156, 0.10144,\n",
       "            0.10126, 0.1007 , 0.1005 , 0.10016, 0.1    , 0.0997 , 0.09686,\n",
       "            0.0959 , 0.0955 , 0.09515, 0.0933 , 0.0927 , 0.0925 , 0.09186,\n",
       "            0.09106, 0.0899 , 0.0896 , 0.08344, 0.08136, 0.0804 , 0.07544,\n",
       "            0.0688 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.1779661 ,\n",
       "            0.18644068, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.37288135, 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.65254235, 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6694915 , 0.6779661 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.720339  , 0.720339  ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8135593 , 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.83898306, 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.86440676, 0.86440676, 0.87288135, 0.87288135, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.9322034 , 0.94067794, 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03787879, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.07575758,\n",
       "            0.07575758, 0.07575758, 0.07575758, 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.09090909, 0.09090909, 0.09848485,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.13636364, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21212122,\n",
       "            0.21212122, 0.21969697, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.23484848, 0.24242425, 0.24242425, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.25757575, 0.27272728, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.3030303 , 0.3030303 , 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.5984849 , 0.6060606 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.6969697 , 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.780303  ,\n",
       "            0.780303  , 0.780303  , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2286 , 0.2281 , 0.2278 , 0.2269 , 0.2263 , 0.2247 ,\n",
       "            0.2242 , 0.2238 , 0.2234 , 0.2233 , 0.2217 , 0.2213 , 0.2208 ,\n",
       "            0.2197 , 0.2194 , 0.2185 , 0.2168 , 0.2166 , 0.2163 , 0.2153 ,\n",
       "            0.2152 , 0.215  , 0.2145 , 0.2142 , 0.2139 , 0.2119 , 0.2096 ,\n",
       "            0.2095 , 0.2094 , 0.2089 , 0.2086 , 0.2085 , 0.2081 , 0.208  ,\n",
       "            0.2069 , 0.206  , 0.2059 , 0.2058 , 0.2054 , 0.2051 , 0.204  ,\n",
       "            0.2031 , 0.2026 , 0.2021 , 0.2009 , 0.2006 , 0.2001 , 0.1993 ,\n",
       "            0.199  , 0.195  , 0.1936 , 0.1909 , 0.1904 , 0.189  , 0.1879 ,\n",
       "            0.1863 , 0.1855 , 0.1846 , 0.1844 , 0.1837 , 0.1824 , 0.1821 ,\n",
       "            0.1812 , 0.181  , 0.179  , 0.1788 , 0.177  , 0.1754 , 0.1752 ,\n",
       "            0.1748 , 0.1746 , 0.1744 , 0.174  , 0.1737 , 0.1733 , 0.1731 ,\n",
       "            0.1718 , 0.1698 , 0.1697 , 0.1674 , 0.167  , 0.1663 , 0.165  ,\n",
       "            0.1649 , 0.1648 , 0.1641 , 0.1637 , 0.1631 , 0.163  , 0.1627 ,\n",
       "            0.1624 , 0.1622 , 0.1621 , 0.162  , 0.1602 , 0.1598 , 0.159  ,\n",
       "            0.1589 , 0.1575 , 0.1572 , 0.157  , 0.1565 , 0.1559 , 0.1555 ,\n",
       "            0.1552 , 0.1543 , 0.1536 , 0.1532 , 0.1525 , 0.1521 , 0.1517 ,\n",
       "            0.1509 , 0.1504 , 0.15   , 0.1493 , 0.1489 , 0.1487 , 0.1484 ,\n",
       "            0.1481 , 0.1473 , 0.147  , 0.1466 , 0.1461 , 0.1459 , 0.1456 ,\n",
       "            0.1454 , 0.1453 , 0.1451 , 0.1449 , 0.1447 , 0.1445 , 0.144  ,\n",
       "            0.1437 , 0.1436 , 0.1434 , 0.1428 , 0.1422 , 0.1417 , 0.1411 ,\n",
       "            0.1407 , 0.1405 , 0.1401 , 0.14   , 0.1392 , 0.139  , 0.1381 ,\n",
       "            0.138  , 0.1378 , 0.1376 , 0.1373 , 0.1372 , 0.1368 , 0.1366 ,\n",
       "            0.1359 , 0.1355 , 0.1353 , 0.1345 , 0.1334 , 0.133  , 0.1328 ,\n",
       "            0.1326 , 0.1324 , 0.1318 , 0.1313 , 0.131  , 0.1298 , 0.1293 ,\n",
       "            0.1292 , 0.1288 , 0.1284 , 0.1279 , 0.1274 , 0.1268 , 0.1261 ,\n",
       "            0.1259 , 0.1257 , 0.12463, 0.1232 , 0.12286, 0.1226 , 0.1217 ,\n",
       "            0.1214 , 0.1213 , 0.12024, 0.1201 , 0.1194 , 0.119  , 0.11816,\n",
       "            0.1174 , 0.11554, 0.11475, 0.1144 , 0.11395, 0.1138 , 0.1128 ,\n",
       "            0.1126 , 0.112  , 0.111  , 0.11084, 0.1103 , 0.1101 , 0.1095 ,\n",
       "            0.1093 , 0.1084 , 0.1078 , 0.1036 , 0.1034 , 0.10156, 0.093  ,\n",
       "            0.09283, 0.09174, 0.0903 , 0.07837], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.2881356 , 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.69491524, 0.7033898 , 0.7033898 ,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.720339  , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.779661  , 0.779661  , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7881356 , 0.7881356 , 0.7966102 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8135593 , 0.8220339 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.86440676, 0.86440676, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.87288135, 0.87288135, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.90677965, 0.91525424, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03787879, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06818182, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.10606061, 0.11363637,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.12878788, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18181819, 0.18939394,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.23484848, 0.25      ,\n",
       "            0.25757575, 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28030303, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.5681818 , 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.7348485 , 0.74242425, 0.74242425,\n",
       "            0.75      , 0.75757575, 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.7878788 , 0.7878788 , 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.8333333 , 0.8333333 , 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2411 , 0.2401 , 0.239  , 0.2383 , 0.2375 , 0.2374 ,\n",
       "            0.2367 , 0.2352 , 0.2346 , 0.2334 , 0.2325 , 0.2318 , 0.231  ,\n",
       "            0.2306 , 0.2299 , 0.2297 , 0.2285 , 0.2273 , 0.2264 , 0.2249 ,\n",
       "            0.2238 , 0.223  , 0.2225 , 0.222  , 0.2216 , 0.2212 , 0.2211 ,\n",
       "            0.2208 , 0.2197 , 0.2194 , 0.2191 , 0.2181 , 0.2179 , 0.2166 ,\n",
       "            0.2137 , 0.2134 , 0.213  , 0.2123 , 0.2108 , 0.2106 , 0.2101 ,\n",
       "            0.2096 , 0.2095 , 0.2091 , 0.2089 , 0.208  , 0.2076 , 0.207  ,\n",
       "            0.2064 , 0.206  , 0.2059 , 0.2058 , 0.2054 , 0.2047 , 0.204  ,\n",
       "            0.2035 , 0.2029 , 0.2021 , 0.2017 , 0.2007 , 0.2006 , 0.2001 ,\n",
       "            0.1993 , 0.199  , 0.1987 , 0.1971 , 0.1964 , 0.1958 , 0.1948 ,\n",
       "            0.193  , 0.1919 , 0.1918 , 0.191  , 0.1907 , 0.1906 , 0.1897 ,\n",
       "            0.1892 , 0.1891 , 0.1884 , 0.1865 , 0.1863 , 0.1853 , 0.185  ,\n",
       "            0.1848 , 0.1841 , 0.1837 , 0.1836 , 0.1827 , 0.1824 , 0.1819 ,\n",
       "            0.181  , 0.1807 , 0.1804 , 0.1799 , 0.1791 , 0.179  , 0.1788 ,\n",
       "            0.1787 , 0.1785 , 0.178  , 0.1779 , 0.1772 , 0.177  , 0.1768 ,\n",
       "            0.1766 , 0.1765 , 0.1764 , 0.1759 , 0.1757 , 0.1753 , 0.1748 ,\n",
       "            0.1746 , 0.174  , 0.1737 , 0.1736 , 0.1731 , 0.1729 , 0.1719 ,\n",
       "            0.1707 , 0.1705 , 0.1696 , 0.1692 , 0.1688 , 0.1687 , 0.1686 ,\n",
       "            0.1674 , 0.1669 , 0.1653 , 0.1649 , 0.1647 , 0.1646 , 0.1644 ,\n",
       "            0.1638 , 0.1637 , 0.1636 , 0.1622 , 0.1617 , 0.1616 , 0.1614 ,\n",
       "            0.161  , 0.1609 , 0.1608 , 0.1606 , 0.1605 , 0.1602 , 0.1599 ,\n",
       "            0.1592 , 0.1586 , 0.1582 , 0.1581 , 0.158  , 0.1575 , 0.1572 ,\n",
       "            0.1565 , 0.1564 , 0.1558 , 0.1552 , 0.155  , 0.1547 , 0.1542 ,\n",
       "            0.1539 , 0.1536 , 0.1534 , 0.1531 , 0.153  , 0.1521 , 0.1519 ,\n",
       "            0.1515 , 0.1514 , 0.1512 , 0.1508 , 0.1499 , 0.1494 , 0.1489 ,\n",
       "            0.1483 , 0.148  , 0.1472 , 0.147  , 0.1466 , 0.1461 , 0.1458 ,\n",
       "            0.1455 , 0.1454 , 0.1436 , 0.1415 , 0.1411 , 0.141  , 0.1409 ,\n",
       "            0.1405 , 0.1392 , 0.1389 , 0.1385 , 0.1384 , 0.1383 , 0.138  ,\n",
       "            0.1375 , 0.1365 , 0.1364 , 0.1362 , 0.1353 , 0.135  , 0.1335 ,\n",
       "            0.1328 , 0.1324 , 0.1312 , 0.13   , 0.1295 , 0.1279 , 0.1271 ,\n",
       "            0.1265 , 0.126  , 0.1252 , 0.1249 , 0.12445, 0.1243 , 0.1201 ,\n",
       "            0.1196 , 0.1195 , 0.119  , 0.1076 , 0.1074 , 0.1056 , 0.0937 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.29661018, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.3559322 , 0.37288135, 0.37288135, 0.3898305 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.55932206, 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.7118644 , 0.7118644 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.720339  , 0.7288136 , 0.7288136 ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7288136 , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7881356 , 0.7881356 , 0.7881356 , 0.7966102 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8135593 , 0.8135593 , 0.8220339 ,\n",
       "            0.83898306, 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.88135594, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.9237288 , 0.9237288 , 0.9237288 ,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03787879, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.07575758, 0.08333334, 0.08333334, 0.09090909,\n",
       "            0.10606061, 0.11363637, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.15151516,\n",
       "            0.15151516, 0.15151516, 0.1590909 , 0.1590909 , 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.17424242, 0.18181819, 0.18181819,\n",
       "            0.18181819, 0.18939394, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.23484848, 0.23484848, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25      , 0.25      , 0.25757575,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.31060606, 0.32575756, 0.3409091 , 0.34848484, 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.3939394 , 0.40151516, 0.4090909 , 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75      , 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.257  , 0.256  , 0.2524 , 0.2522 , 0.252  , 0.2517 ,\n",
       "            0.2505 , 0.2498 , 0.2493 , 0.247  , 0.2466 , 0.2445 , 0.2441 ,\n",
       "            0.243  , 0.2429 , 0.2417 , 0.241  , 0.2401 , 0.2378 , 0.2374 ,\n",
       "            0.237  , 0.2368 , 0.2351 , 0.235  , 0.234  , 0.2334 , 0.2325 ,\n",
       "            0.2314 , 0.2311 , 0.2303 , 0.2297 , 0.2292 , 0.228  , 0.2278 ,\n",
       "            0.2269 , 0.2263 , 0.2252 , 0.2242 , 0.2239 , 0.2235 , 0.2234 ,\n",
       "            0.223  , 0.2225 , 0.2203 , 0.2195 , 0.218  , 0.2172 , 0.217  ,\n",
       "            0.2168 , 0.2167 , 0.2166 , 0.2161 , 0.2156 , 0.2152 , 0.215  ,\n",
       "            0.2147 , 0.2135 , 0.2129 , 0.212  , 0.2119 , 0.2115 , 0.2114 ,\n",
       "            0.2113 , 0.2106 , 0.2103 , 0.21   , 0.2098 , 0.2096 , 0.2095 ,\n",
       "            0.2091 , 0.2089 , 0.2084 , 0.208  , 0.2079 , 0.2073 , 0.2065 ,\n",
       "            0.206  , 0.2059 , 0.2056 , 0.2054 , 0.205  , 0.2047 , 0.204  ,\n",
       "            0.2035 , 0.2031 , 0.202  , 0.2012 , 0.201  , 0.2007 , 0.2006 ,\n",
       "            0.2002 , 0.2001 , 0.2    , 0.1993 , 0.199  , 0.1987 , 0.1985 ,\n",
       "            0.1982 , 0.1981 , 0.1978 , 0.1974 , 0.1968 , 0.1962 , 0.1959 ,\n",
       "            0.1958 , 0.195  , 0.1948 , 0.1937 , 0.193  , 0.1924 , 0.1923 ,\n",
       "            0.1919 , 0.1918 , 0.1913 , 0.1909 , 0.19   , 0.1898 , 0.1892 ,\n",
       "            0.1884 , 0.188  , 0.1874 , 0.1873 , 0.1864 , 0.1855 , 0.1853 ,\n",
       "            0.1852 , 0.185  , 0.1843 , 0.1842 , 0.1841 , 0.1836 , 0.1824 ,\n",
       "            0.1823 , 0.182  , 0.1815 , 0.1814 , 0.1807 , 0.1805 , 0.1804 ,\n",
       "            0.1803 , 0.1798 , 0.1797 , 0.1792 , 0.1788 , 0.1787 , 0.1781 ,\n",
       "            0.1775 , 0.177  , 0.1764 , 0.1763 , 0.1755 , 0.1752 , 0.1749 ,\n",
       "            0.1744 , 0.1743 , 0.1741 , 0.1738 , 0.1736 , 0.1735 , 0.1733 ,\n",
       "            0.173  , 0.172  , 0.1716 , 0.171  , 0.1708 , 0.17   , 0.1699 ,\n",
       "            0.1694 , 0.1692 , 0.1686 , 0.1685 , 0.1677 , 0.1675 , 0.1674 ,\n",
       "            0.1663 , 0.1661 , 0.1656 , 0.1648 , 0.1646 , 0.1643 , 0.1617 ,\n",
       "            0.1616 , 0.1615 , 0.161  , 0.1597 , 0.159  , 0.1588 , 0.158  ,\n",
       "            0.1571 , 0.1567 , 0.1558 , 0.1554 , 0.1543 , 0.1539 , 0.153  ,\n",
       "            0.1516 , 0.1505 , 0.1489 , 0.1484 , 0.147  , 0.1469 , 0.1466 ,\n",
       "            0.1464 , 0.1455 , 0.145  , 0.1444 , 0.1425 , 0.1421 , 0.1393 ,\n",
       "            0.1284 , 0.1272 , 0.1262 , 0.11395], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11864407, 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3559322 , 0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.38135594, 0.38135594, 0.38135594, 0.3898305 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.41525424, 0.41525424,\n",
       "            0.41525424, 0.43220338, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.5       ,\n",
       "            0.5       , 0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.5508475 , 0.5677966 , 0.5762712 , 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6694915 , 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8135593 , 0.8220339 ,\n",
       "            0.8220339 , 0.8220339 , 0.83898306, 0.84745765, 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.88135594, 0.88135594, 0.88135594,\n",
       "            0.88135594, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9830508 ,\n",
       "            0.9915254 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.01515152,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03030303, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.0530303 , 0.06060606,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.06818182, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.18939394, 0.18939394, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.22727273,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.24242425, 0.24242425,\n",
       "            0.24242425, 0.25      , 0.25      , 0.25      , 0.25757575,\n",
       "            0.25757575, 0.2651515 , 0.28030303, 0.28787878, 0.3030303 ,\n",
       "            0.3030303 , 0.3181818 , 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.38636363, 0.41666666,\n",
       "            0.42424244, 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.59090906, 0.6060606 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.7348485 , 0.7348485 , 0.7348485 ,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.2769, 0.2751, 0.273 , 0.2727, 0.2717, 0.2705, 0.269 ,\n",
       "            0.268 , 0.2678, 0.2673, 0.2664, 0.2656, 0.2646, 0.2627, 0.2612,\n",
       "            0.259 , 0.2583, 0.2578, 0.2573, 0.256 , 0.2556, 0.2554, 0.2551,\n",
       "            0.2544, 0.2542, 0.254 , 0.2537, 0.252 , 0.2515, 0.2512, 0.2502,\n",
       "            0.2482, 0.248 , 0.2478, 0.2473, 0.2471, 0.2467, 0.2462, 0.2452,\n",
       "            0.2451, 0.2449, 0.2445, 0.2444, 0.244 , 0.2438, 0.2433, 0.243 ,\n",
       "            0.2429, 0.2424, 0.2421, 0.2413, 0.241 , 0.2406, 0.2402, 0.2401,\n",
       "            0.2394, 0.2391, 0.2379, 0.2368, 0.2367, 0.236 , 0.2358, 0.2355,\n",
       "            0.2352, 0.2347, 0.2343, 0.234 , 0.2338, 0.2334, 0.2332, 0.2328,\n",
       "            0.2327, 0.2323, 0.2322, 0.2307, 0.2286, 0.2285, 0.2283, 0.2281,\n",
       "            0.2277, 0.2268, 0.2263, 0.2255, 0.2251, 0.2247, 0.2244, 0.2239,\n",
       "            0.2233, 0.2229, 0.2227, 0.2224, 0.2222, 0.2218, 0.2217, 0.2208,\n",
       "            0.2203, 0.2198, 0.219 , 0.2189, 0.2184, 0.2168, 0.2167, 0.2166,\n",
       "            0.2161, 0.2153, 0.2152, 0.215 , 0.2147, 0.2145, 0.2144, 0.2142,\n",
       "            0.2139, 0.2135, 0.2124, 0.212 , 0.2113, 0.211 , 0.2104, 0.2103,\n",
       "            0.2101, 0.21  , 0.2094, 0.208 , 0.2079, 0.2076, 0.2073, 0.207 ,\n",
       "            0.2068, 0.2063, 0.2059, 0.2058, 0.2048, 0.2047, 0.2043, 0.204 ,\n",
       "            0.2039, 0.2034, 0.2024, 0.2023, 0.202 , 0.2004, 0.2002, 0.1998,\n",
       "            0.1996, 0.1987, 0.1982, 0.1981, 0.1976, 0.1974, 0.1953, 0.195 ,\n",
       "            0.1946, 0.194 , 0.1936, 0.1934, 0.1929, 0.1924, 0.1918, 0.1917,\n",
       "            0.1915, 0.1901, 0.1897, 0.1896, 0.189 , 0.1876, 0.1866, 0.186 ,\n",
       "            0.1849, 0.1843, 0.1842, 0.1835, 0.182 , 0.1812, 0.1808, 0.1798,\n",
       "            0.1797, 0.1771, 0.1764, 0.1763, 0.1758, 0.1746, 0.1744, 0.1733,\n",
       "            0.1724, 0.1721, 0.172 , 0.1718, 0.1708, 0.1705, 0.1703, 0.1696,\n",
       "            0.1675, 0.165 , 0.1602, 0.1561, 0.1532, 0.1525, 0.1415],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.11016949, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11016949, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.21186441, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2457627 , 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44915253, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5169492 , 0.5254237 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.6440678 , 0.6440678 , 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.83898306, 0.83898306, 0.83898306, 0.84745765,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.87288135,\n",
       "            0.88135594, 0.88135594, 0.88135594, 0.8898305 , 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06818182, 0.07575758, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.3560606 , 0.36363637, 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.3939394 , 0.40151516, 0.40151516,\n",
       "            0.41666666, 0.41666666, 0.42424244, 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.46969697, 0.47727272, 0.49242425, 0.5       ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.59090906, 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.7121212 , 0.7121212 , 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3083, 0.3074, 0.3062, 0.3044, 0.304 , 0.3027, 0.3022,\n",
       "            0.3015, 0.2993, 0.299 , 0.2986, 0.2969, 0.2964, 0.2961, 0.296 ,\n",
       "            0.2957, 0.2954, 0.2944, 0.2935, 0.2932, 0.2925, 0.2922, 0.292 ,\n",
       "            0.2917, 0.2915, 0.2908, 0.2898, 0.2883, 0.2874, 0.2864, 0.2861,\n",
       "            0.2856, 0.2852, 0.2847, 0.2834, 0.283 , 0.2827, 0.2822, 0.2815,\n",
       "            0.2812, 0.2805, 0.2803, 0.2798, 0.2795, 0.2793, 0.279 , 0.2786,\n",
       "            0.2776, 0.2769, 0.2766, 0.2764, 0.2761, 0.276 , 0.2756, 0.275 ,\n",
       "            0.2747, 0.2744, 0.2742, 0.2737, 0.2734, 0.2722, 0.2715, 0.271 ,\n",
       "            0.2708, 0.2698, 0.269 , 0.2678, 0.2673, 0.2664, 0.2646, 0.2644,\n",
       "            0.2632, 0.263 , 0.2627, 0.2622, 0.2617, 0.261 , 0.2607, 0.2605,\n",
       "            0.26  , 0.2598, 0.2595, 0.2573, 0.257 , 0.2568, 0.2563, 0.2559,\n",
       "            0.255 , 0.2546, 0.2544, 0.2542, 0.2532, 0.2527, 0.252 , 0.2512,\n",
       "            0.2507, 0.2505, 0.2496, 0.2494, 0.2478, 0.2466, 0.2458, 0.2451,\n",
       "            0.2444, 0.244 , 0.2437, 0.2433, 0.2429, 0.2428, 0.2426, 0.2424,\n",
       "            0.2415, 0.241 , 0.2407, 0.2405, 0.239 , 0.2388, 0.2372, 0.237 ,\n",
       "            0.2363, 0.236 , 0.2356, 0.2352, 0.2343, 0.2339, 0.233 , 0.2325,\n",
       "            0.2318, 0.2311, 0.2306, 0.229 , 0.2281, 0.228 , 0.2274, 0.2273,\n",
       "            0.2272, 0.2269, 0.2251, 0.2247, 0.2244, 0.2242, 0.2239, 0.2234,\n",
       "            0.2229, 0.2222, 0.222 , 0.2216, 0.2212, 0.2208, 0.2203, 0.2202,\n",
       "            0.2198, 0.2197, 0.2195, 0.2186, 0.2185, 0.2175, 0.2172, 0.2168,\n",
       "            0.2166, 0.2162, 0.2147, 0.2142, 0.214 , 0.2137, 0.2134, 0.2129,\n",
       "            0.2125, 0.2123, 0.212 , 0.2113, 0.2104, 0.2094, 0.2091, 0.2085,\n",
       "            0.2075, 0.2073, 0.2063, 0.2054, 0.2048, 0.2043, 0.2028, 0.2023,\n",
       "            0.2015, 0.2007, 0.2006, 0.2001, 0.1962, 0.1909, 0.1874, 0.1865,\n",
       "            0.1836, 0.183 , 0.1766, 0.1724, 0.1674, 0.1627, 0.1549],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.1440678 , 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.2881356 , 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.55932206, 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.59322035, 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.7033898 ,\n",
       "            0.7118644 , 0.7118644 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.8559322 , 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.31060606,\n",
       "            0.3181818 , 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6136364 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.65909094, 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.72727275, 0.7348485 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.79545456, 0.79545456, 0.79545456, 0.81060606,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.356 , 0.353 , 0.3525, 0.3513, 0.351 , 0.3508, 0.3506,\n",
       "            0.3494, 0.3489, 0.3481, 0.3477, 0.3474, 0.3472, 0.3464, 0.346 ,\n",
       "            0.3457, 0.3455, 0.3445, 0.3433, 0.343 , 0.3425, 0.342 , 0.3418,\n",
       "            0.3413, 0.3408, 0.3406, 0.3403, 0.34  , 0.3396, 0.3394, 0.3386,\n",
       "            0.3384, 0.3381, 0.3376, 0.3367, 0.3362, 0.3354, 0.3347, 0.3345,\n",
       "            0.3342, 0.3335, 0.3333, 0.333 , 0.3328, 0.3325, 0.3303, 0.33  ,\n",
       "            0.327 , 0.3252, 0.3247, 0.3235, 0.323 , 0.3223, 0.3206, 0.3203,\n",
       "            0.3198, 0.3193, 0.3145, 0.314 , 0.3108, 0.3105, 0.31  , 0.3079,\n",
       "            0.3076, 0.3071, 0.3064, 0.3062, 0.306 , 0.304 , 0.3035, 0.303 ,\n",
       "            0.3022, 0.302 , 0.3013, 0.301 , 0.3005, 0.299 , 0.2988, 0.298 ,\n",
       "            0.2969, 0.2961, 0.2954, 0.2947, 0.2944, 0.2937, 0.2925, 0.2915,\n",
       "            0.2913, 0.2905, 0.29  , 0.2896, 0.2883, 0.2876, 0.2869, 0.2866,\n",
       "            0.2861, 0.286 , 0.2847, 0.2834, 0.281 , 0.2803, 0.2793, 0.2788,\n",
       "            0.2783, 0.278 , 0.2778, 0.2776, 0.277 , 0.2769, 0.276 , 0.274 ,\n",
       "            0.2737, 0.2734, 0.273 , 0.2727, 0.2717, 0.2712, 0.2708, 0.2705,\n",
       "            0.2703, 0.27  , 0.2698, 0.2695, 0.2693, 0.269 , 0.2688, 0.2683,\n",
       "            0.2678, 0.2676, 0.2673, 0.2668, 0.2666, 0.2654, 0.265 , 0.2644,\n",
       "            0.264 , 0.2637, 0.2632, 0.263 , 0.2627, 0.2607, 0.2603, 0.2598,\n",
       "            0.2595, 0.2593, 0.2576, 0.2573, 0.2563, 0.2559, 0.2554, 0.2551,\n",
       "            0.254 , 0.2537, 0.2534, 0.253 , 0.2524, 0.2515, 0.251 , 0.2507,\n",
       "            0.2502, 0.25  , 0.249 , 0.2483, 0.2478, 0.2471, 0.2449, 0.2415,\n",
       "            0.2405, 0.2402, 0.2399, 0.2394, 0.2386, 0.2374, 0.236 , 0.2318,\n",
       "            0.2289, 0.2273, 0.2246, 0.2234, 0.2233, 0.223 , 0.2218, 0.2203,\n",
       "            0.2202, 0.2172, 0.2162, 0.2158, 0.2156, 0.2152, 0.2119, 0.2059,\n",
       "            0.2015, 0.1874, 0.1819, 0.169 , 0.1633, 0.1586, 0.1504, 0.1501],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.19491525, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.2542373 , 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.33050847, 0.33050847, 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.40677965, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.44915253, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.4915254 , 0.4915254 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 , 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6864407 , 0.69491524, 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.11363637, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.1590909 , 0.17424242, 0.1969697 , 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.24242425, 0.25      , 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.34848484, 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.7348485 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75757575, 0.75757575, 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.82575756, 0.8333333 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4172, 0.4138, 0.4128, 0.4124, 0.412 , 0.4119, 0.4114,\n",
       "            0.4094, 0.4092, 0.4087, 0.4084, 0.408 , 0.4077, 0.407 , 0.4067,\n",
       "            0.4065, 0.4058, 0.4055, 0.4048, 0.4045, 0.4043, 0.404 , 0.4036,\n",
       "            0.4033, 0.4006, 0.3997, 0.3994, 0.3977, 0.3958, 0.3904, 0.39  ,\n",
       "            0.3896, 0.3865, 0.383 , 0.3826, 0.382 , 0.381 , 0.3809, 0.378 ,\n",
       "            0.3765, 0.3762, 0.3738, 0.3708, 0.3652, 0.365 , 0.364 , 0.3638,\n",
       "            0.3591, 0.3584, 0.3547, 0.352 , 0.3508, 0.3506, 0.3503, 0.3489,\n",
       "            0.346 , 0.3433, 0.3416, 0.3413, 0.3398, 0.3389, 0.3381, 0.338 ,\n",
       "            0.3376, 0.3354, 0.3352, 0.335 , 0.3347, 0.3342, 0.332 , 0.3306,\n",
       "            0.329 , 0.3276, 0.3262, 0.3252, 0.3247, 0.3245, 0.324 , 0.3232,\n",
       "            0.3228, 0.322 , 0.3218, 0.321 , 0.3208, 0.3206, 0.32  , 0.3198,\n",
       "            0.3193, 0.3188, 0.318 , 0.317 , 0.3154, 0.3145, 0.314 , 0.3137,\n",
       "            0.313 , 0.3125, 0.3123, 0.312 , 0.3115, 0.3113, 0.3108, 0.3105,\n",
       "            0.3098, 0.3093, 0.3088, 0.3076, 0.3071, 0.3066, 0.3064, 0.3062,\n",
       "            0.306 , 0.3052, 0.305 , 0.3047, 0.3042, 0.304 , 0.3037, 0.3035,\n",
       "            0.303 , 0.3025, 0.301 , 0.3008, 0.3003, 0.2993, 0.299 , 0.2988,\n",
       "            0.2986, 0.2983, 0.298 , 0.2969, 0.2966, 0.2964, 0.2961, 0.2947,\n",
       "            0.2937, 0.2927, 0.2917, 0.2915, 0.291 , 0.2896, 0.2893, 0.289 ,\n",
       "            0.2888, 0.288 , 0.2876, 0.2856, 0.2854, 0.2852, 0.2847, 0.2827,\n",
       "            0.2825, 0.2812, 0.281 , 0.2808, 0.2805, 0.2803, 0.2798, 0.2795,\n",
       "            0.2793, 0.2786, 0.2756, 0.2744, 0.2715, 0.2637, 0.263 , 0.2625,\n",
       "            0.262 , 0.2368, 0.2325, 0.2319, 0.2277, 0.2266, 0.2263, 0.2261,\n",
       "            0.2229, 0.2225, 0.22  , 0.2179, 0.2177, 0.2173, 0.217 , 0.213 ,\n",
       "            0.2058, 0.2009, 0.1874, 0.1783, 0.1641, 0.1583, 0.1531, 0.1447,\n",
       "            0.1445], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2457627 , 0.2457627 ,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.2542373 , 0.27966103, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.38135594, 0.3898305 ,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.6101695 , 0.6101695 , 0.6101695 ,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.14393939, 0.15151516, 0.1590909 , 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.25      , 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.6818182 , 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.82575756, 0.82575756,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4976, 0.4844, 0.4841, 0.4836, 0.4817, 0.48  , 0.4792,\n",
       "            0.4778, 0.4773, 0.477 , 0.4763, 0.4756, 0.4753, 0.4705, 0.468 ,\n",
       "            0.4663, 0.4658, 0.4656, 0.4646, 0.4634, 0.4631, 0.4626, 0.462 ,\n",
       "            0.4612, 0.461 , 0.4607, 0.4587, 0.4585, 0.4575, 0.457 , 0.4568,\n",
       "            0.4548, 0.4543, 0.452 , 0.4502, 0.446 , 0.444 , 0.4438, 0.443 ,\n",
       "            0.4414, 0.438 , 0.4355, 0.4353, 0.4312, 0.4294, 0.4292, 0.4272,\n",
       "            0.4268, 0.4265, 0.4197, 0.418 , 0.417 , 0.4167, 0.4084, 0.4053,\n",
       "            0.4014, 0.401 , 0.4   , 0.3977, 0.3955, 0.3948, 0.3936, 0.3923,\n",
       "            0.3843, 0.3804, 0.379 , 0.3782, 0.3765, 0.3757, 0.3752, 0.3745,\n",
       "            0.3735, 0.3728, 0.3706, 0.37  , 0.3694, 0.3687, 0.3665, 0.3662,\n",
       "            0.3647, 0.3633, 0.3625, 0.362 , 0.3616, 0.3606, 0.3604, 0.3599,\n",
       "            0.3594, 0.3591, 0.3584, 0.358 , 0.3574, 0.3572, 0.3564, 0.356 ,\n",
       "            0.3557, 0.3552, 0.355 , 0.3523, 0.352 , 0.3518, 0.3516, 0.351 ,\n",
       "            0.3503, 0.35  , 0.3499, 0.3489, 0.3486, 0.3484, 0.3472, 0.3464,\n",
       "            0.3462, 0.3452, 0.345 , 0.344 , 0.3438, 0.343 , 0.3428, 0.3425,\n",
       "            0.3418, 0.3416, 0.3413, 0.341 , 0.3408, 0.34  , 0.3394, 0.339 ,\n",
       "            0.3389, 0.3386, 0.3376, 0.3374, 0.3372, 0.337 , 0.3367, 0.3357,\n",
       "            0.3354, 0.335 , 0.3347, 0.3345, 0.3342, 0.334 , 0.3335, 0.3333,\n",
       "            0.3325, 0.332 , 0.3313, 0.3306, 0.3303, 0.3298, 0.3289, 0.328 ,\n",
       "            0.3274, 0.3271, 0.327 , 0.3267, 0.3262, 0.3252, 0.3247, 0.3232,\n",
       "            0.3225, 0.3213, 0.3208, 0.319 , 0.3188, 0.3186, 0.3184, 0.3179,\n",
       "            0.3137, 0.305 , 0.2974, 0.295 , 0.2935, 0.293 , 0.2915, 0.2903,\n",
       "            0.2886, 0.2864, 0.2852, 0.2842, 0.284 , 0.2717, 0.2715, 0.2708,\n",
       "            0.27  , 0.2415, 0.236 , 0.2306, 0.2299, 0.2295, 0.2294, 0.2289,\n",
       "            0.2252, 0.2249, 0.2222, 0.2197, 0.2195, 0.2186, 0.2142, 0.2056,\n",
       "            0.2001, 0.1877, 0.1754, 0.1598, 0.1539, 0.1481, 0.1399, 0.1392],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.29545453, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11016949, 0.11016949, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.43220338, 0.43220338, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 , 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.15151516, 0.1590909 , 0.17424242, 0.18181819,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.47727272, 0.4848485 , 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.5       , 0.5       , 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.72727275, 0.72727275, 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.77272725, 0.7878788 , 0.7878788 , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.571 , 0.5493, 0.549 , 0.546 , 0.543 , 0.5425, 0.541 ,\n",
       "            0.5405, 0.5366, 0.533 , 0.531 , 0.5234, 0.5225, 0.522 , 0.5215,\n",
       "            0.5205, 0.52  , 0.5186, 0.5166, 0.514 , 0.5137, 0.513 , 0.511 ,\n",
       "            0.5093, 0.5083, 0.5063, 0.506 , 0.5054, 0.505 , 0.5034, 0.502 ,\n",
       "            0.4988, 0.4946, 0.4937, 0.4934, 0.4897, 0.4888, 0.4817, 0.4812,\n",
       "            0.479 , 0.478 , 0.4768, 0.4722, 0.4683, 0.465 , 0.4648, 0.4597,\n",
       "            0.4558, 0.4548, 0.4517, 0.4448, 0.4436, 0.4429, 0.44  , 0.4397,\n",
       "            0.436 , 0.4343, 0.4336, 0.428 , 0.4277, 0.4253, 0.4236, 0.419 ,\n",
       "            0.4177, 0.4172, 0.4143, 0.4114, 0.4111, 0.4094, 0.409 , 0.4077,\n",
       "            0.4075, 0.407 , 0.4065, 0.4038, 0.4026, 0.4019, 0.4014, 0.4011,\n",
       "            0.4006, 0.4004, 0.3987, 0.3962, 0.396 , 0.3955, 0.3943, 0.394 ,\n",
       "            0.3936, 0.393 , 0.3928, 0.3926, 0.3887, 0.3884, 0.3882, 0.3867,\n",
       "            0.3862, 0.3857, 0.3855, 0.3853, 0.385 , 0.3845, 0.384 , 0.3838,\n",
       "            0.3835, 0.3823, 0.3813, 0.3809, 0.3806, 0.3804, 0.3796, 0.379 ,\n",
       "            0.3787, 0.3784, 0.378 , 0.3772, 0.377 , 0.376 , 0.3757, 0.3748,\n",
       "            0.3745, 0.3743, 0.3735, 0.3728, 0.3726, 0.3718, 0.371 , 0.3704,\n",
       "            0.369 , 0.3687, 0.3684, 0.368 , 0.3677, 0.3674, 0.3672, 0.3667,\n",
       "            0.3665, 0.3662, 0.3657, 0.3655, 0.3652, 0.365 , 0.3647, 0.3645,\n",
       "            0.364 , 0.3638, 0.3633, 0.3618, 0.3613, 0.361 , 0.36  , 0.3599,\n",
       "            0.3582, 0.358 , 0.357 , 0.3567, 0.3562, 0.356 , 0.3552, 0.355 ,\n",
       "            0.354 , 0.353 , 0.3513, 0.351 , 0.3508, 0.3486, 0.3481, 0.3433,\n",
       "            0.3413, 0.3357, 0.3347, 0.3267, 0.3083, 0.3064, 0.3052, 0.3044,\n",
       "            0.3032, 0.3   , 0.298 , 0.2974, 0.2964, 0.2957, 0.293 , 0.28  ,\n",
       "            0.2786, 0.2783, 0.2466, 0.2406, 0.2391, 0.2338, 0.2334, 0.2327,\n",
       "            0.2323, 0.2316, 0.2274, 0.2272, 0.2255, 0.2213, 0.2212, 0.2203,\n",
       "            0.2158, 0.2059, 0.2   , 0.1877, 0.1735, 0.1569, 0.1505, 0.1449,\n",
       "            0.136 , 0.1359], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.40151516, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22033899, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3898305 , 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5423729 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.72727275, 0.72727275, 0.72727275, 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.75757575, 0.75757575,\n",
       "            0.75757575, 0.75757575, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8787879 , 0.8863636 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.633 , 0.606 , 0.6045, 0.601 , 0.599 , 0.596 , 0.5957,\n",
       "            0.5947, 0.5894, 0.589 , 0.5835, 0.583 , 0.573 , 0.572 , 0.5713,\n",
       "            0.5693, 0.5674, 0.566 , 0.5654, 0.565 , 0.5645, 0.561 , 0.5596,\n",
       "            0.559 , 0.558 , 0.5576, 0.554 , 0.5522, 0.55  , 0.549 , 0.5474,\n",
       "            0.5454, 0.5444, 0.5435, 0.5376, 0.535 , 0.5327, 0.5317, 0.5283,\n",
       "            0.523 , 0.522 , 0.5176, 0.516 , 0.5127, 0.5054, 0.499 , 0.498 ,\n",
       "            0.4978, 0.4885, 0.488 , 0.485 , 0.4824, 0.4775, 0.476 , 0.4744,\n",
       "            0.4707, 0.4705, 0.469 , 0.4688, 0.4673, 0.4622, 0.4607, 0.4573,\n",
       "            0.4556, 0.4517, 0.4512, 0.4507, 0.4495, 0.4456, 0.4453, 0.4438,\n",
       "            0.4421, 0.4417, 0.4414, 0.4407, 0.44  , 0.4385, 0.437 , 0.4365,\n",
       "            0.4363, 0.4355, 0.4353, 0.4346, 0.434 , 0.4333, 0.4324, 0.4302,\n",
       "            0.43  , 0.4294, 0.429 , 0.428 , 0.4253, 0.4246, 0.4243, 0.4236,\n",
       "            0.4233, 0.4229, 0.4224, 0.422 , 0.4219, 0.4216, 0.421 , 0.4207,\n",
       "            0.4202, 0.42  , 0.4182, 0.4175, 0.416 , 0.4158, 0.4155, 0.4153,\n",
       "            0.4148, 0.4146, 0.414 , 0.4138, 0.4133, 0.413 , 0.4124, 0.412 ,\n",
       "            0.4106, 0.4102, 0.4094, 0.4092, 0.409 , 0.4087, 0.4082, 0.4077,\n",
       "            0.407 , 0.4067, 0.4062, 0.4058, 0.4053, 0.405 , 0.4048, 0.4045,\n",
       "            0.4038, 0.4033, 0.4028, 0.4019, 0.4014, 0.4011, 0.4006, 0.4001,\n",
       "            0.4   , 0.3977, 0.3972, 0.397 , 0.3965, 0.3962, 0.3948, 0.3936,\n",
       "            0.3933, 0.393 , 0.3918, 0.3916, 0.3909, 0.3901, 0.39  , 0.3896,\n",
       "            0.389 , 0.3887, 0.3877, 0.3872, 0.3835, 0.3828, 0.3823, 0.3813,\n",
       "            0.3804, 0.3782, 0.3767, 0.3752, 0.3748, 0.372 , 0.3694, 0.3672,\n",
       "            0.358 , 0.355 , 0.3494, 0.3477, 0.3386, 0.3188, 0.3174, 0.3164,\n",
       "            0.3152, 0.3147, 0.3108, 0.3093, 0.3071, 0.3064, 0.306 , 0.3018,\n",
       "            0.2886, 0.2883, 0.2866, 0.252 , 0.246 , 0.2429, 0.2383, 0.2367,\n",
       "            0.2362, 0.236 , 0.2346, 0.2301, 0.2297, 0.2295, 0.2238, 0.2233,\n",
       "            0.2225, 0.2181, 0.207 , 0.2009, 0.1882, 0.1729, 0.1555, 0.1482,\n",
       "            0.143 , 0.134 , 0.1333], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.02542373, dtype=float32),\n",
       "    'tpr': array(0.46969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.16949153, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.2542373 , 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.30508474, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.33898306, 0.3559322 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.47457626, 0.48305085,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 ,\n",
       "            0.65909094, 0.65909094, 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.7651515 , 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.7878788 , 0.7878788 , 0.8030303 , 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.8030303 , 0.8030303 , 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8636364 , 0.8787879 , 0.8863636 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.683 , 0.653 , 0.6523, 0.6504, 0.6465, 0.6455, 0.642 ,\n",
       "            0.641 , 0.6396, 0.634 , 0.632 , 0.6265, 0.626 , 0.615 , 0.6133,\n",
       "            0.613 , 0.6104, 0.6074, 0.6064, 0.6045, 0.604 , 0.6035, 0.6   ,\n",
       "            0.5986, 0.598 , 0.5977, 0.597 , 0.596 , 0.595 , 0.592 , 0.5894,\n",
       "            0.587 , 0.5864, 0.585 , 0.5835, 0.5796, 0.579 , 0.575 , 0.5737,\n",
       "            0.565 , 0.5645, 0.562 , 0.5605, 0.5566, 0.5522, 0.5483, 0.5474,\n",
       "            0.537 , 0.5303, 0.5293, 0.527 , 0.52  , 0.5176, 0.516 , 0.51  ,\n",
       "            0.5063, 0.5044, 0.504 , 0.503 , 0.5024, 0.4993, 0.4985, 0.4949,\n",
       "            0.4944, 0.494 , 0.4915, 0.4878, 0.4836, 0.4827, 0.4817, 0.4802,\n",
       "            0.4797, 0.4788, 0.4768, 0.4753, 0.4746, 0.4734, 0.4727, 0.472 ,\n",
       "            0.4707, 0.4705, 0.4702, 0.4695, 0.4688, 0.4683, 0.467 , 0.4666,\n",
       "            0.4646, 0.4636, 0.4626, 0.4612, 0.4602, 0.4595, 0.4585, 0.4573,\n",
       "            0.457 , 0.4558, 0.4548, 0.4534, 0.4531, 0.4517, 0.4512, 0.451 ,\n",
       "            0.4504, 0.4497, 0.4495, 0.4485, 0.4482, 0.4473, 0.4458, 0.4456,\n",
       "            0.4453, 0.445 , 0.4448, 0.444 , 0.443 , 0.4417, 0.439 , 0.4385,\n",
       "            0.4377, 0.4375, 0.4373, 0.437 , 0.4363, 0.4358, 0.4355, 0.4353,\n",
       "            0.434 , 0.4333, 0.4329, 0.4326, 0.432 , 0.4314, 0.4312, 0.4302,\n",
       "            0.4297, 0.4294, 0.428 , 0.427 , 0.4263, 0.425 , 0.4243, 0.424 ,\n",
       "            0.4238, 0.4236, 0.4233, 0.422 , 0.4219, 0.4216, 0.421 , 0.4194,\n",
       "            0.419 , 0.4185, 0.4182, 0.4165, 0.4163, 0.4158, 0.4153, 0.4143,\n",
       "            0.4138, 0.4124, 0.4084, 0.4077, 0.4055, 0.405 , 0.403 , 0.4026,\n",
       "            0.4011, 0.3982, 0.3965, 0.3953, 0.3945, 0.392 , 0.391 , 0.3833,\n",
       "            0.3806, 0.3716, 0.3677, 0.3618, 0.36  , 0.35  , 0.3289, 0.3276,\n",
       "            0.3267, 0.3252, 0.325 , 0.322 , 0.3184, 0.316 , 0.3157, 0.3152,\n",
       "            0.3105, 0.2969, 0.2961, 0.2944, 0.257 , 0.2507, 0.2473, 0.2424,\n",
       "            0.2406, 0.2401, 0.2397, 0.2384, 0.2338, 0.2334, 0.2332, 0.2266,\n",
       "            0.2263, 0.2255, 0.2252, 0.2208, 0.2089, 0.2023, 0.1903, 0.1729,\n",
       "            0.1545, 0.1473, 0.1418, 0.1326, 0.1321], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.11864407, dtype=float32),\n",
       "    'tpr': array(0.57575756, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.04237288, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.1779661 , 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2457627 , 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 , 0.3644068 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3898305 ,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3898305 , 0.3898305 ,\n",
       "            0.3898305 , 0.40677965, 0.40677965, 0.42372882, 0.42372882,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7118644 , 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.1590909 , 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.45454547, 0.45454547, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.73  , 0.697 , 0.6963, 0.694 , 0.69  , 0.6855, 0.6846,\n",
       "            0.684 , 0.682 , 0.676 , 0.6733, 0.668 , 0.6665, 0.6553, 0.6533,\n",
       "            0.6523, 0.65  , 0.646 , 0.642 , 0.641 , 0.638 , 0.6367, 0.6357,\n",
       "            0.6353, 0.635 , 0.633 , 0.632 , 0.6284, 0.6255, 0.623 , 0.6206,\n",
       "            0.6187, 0.6143, 0.614 , 0.6123, 0.612 , 0.6113, 0.597 , 0.5947,\n",
       "            0.591 , 0.5864, 0.5815, 0.5806, 0.5776, 0.569 , 0.5625, 0.559 ,\n",
       "            0.5557, 0.555 , 0.546 , 0.544 , 0.537 , 0.5356, 0.535 , 0.5347,\n",
       "            0.532 , 0.5317, 0.5303, 0.5273, 0.521 , 0.5205, 0.5186, 0.517 ,\n",
       "            0.5166, 0.513 , 0.512 , 0.5117, 0.5107, 0.5103, 0.5093, 0.509 ,\n",
       "            0.5083, 0.5073, 0.505 , 0.503 , 0.5024, 0.501 , 0.4998, 0.4988,\n",
       "            0.4983, 0.4978, 0.4973, 0.4963, 0.495 , 0.4932, 0.492 , 0.4907,\n",
       "            0.4897, 0.4883, 0.488 , 0.4858, 0.4849, 0.4844, 0.4841, 0.482 ,\n",
       "            0.4812, 0.4802, 0.4792, 0.4785, 0.478 , 0.4778, 0.4763, 0.476 ,\n",
       "            0.474 , 0.4734, 0.473 , 0.4714, 0.4712, 0.471 , 0.47  , 0.4697,\n",
       "            0.4695, 0.4675, 0.467 , 0.4668, 0.4663, 0.466 , 0.4653, 0.465 ,\n",
       "            0.4648, 0.464 , 0.4636, 0.463 , 0.4626, 0.4624, 0.462 , 0.4612,\n",
       "            0.4607, 0.46  , 0.4597, 0.4592, 0.4578, 0.4563, 0.456 , 0.4556,\n",
       "            0.455 , 0.4548, 0.4546, 0.4521, 0.452 , 0.4517, 0.4514, 0.4512,\n",
       "            0.451 , 0.4507, 0.4504, 0.4502, 0.4495, 0.4473, 0.444 , 0.4438,\n",
       "            0.4436, 0.4414, 0.4412, 0.4407, 0.4404, 0.4387, 0.4363, 0.4358,\n",
       "            0.4326, 0.4265, 0.424 , 0.4233, 0.4207, 0.4187, 0.4185, 0.414 ,\n",
       "            0.4106, 0.4104, 0.4102, 0.4092, 0.3977, 0.3945, 0.3853, 0.3806,\n",
       "            0.3745, 0.3723, 0.362 , 0.3386, 0.3376, 0.337 , 0.335 , 0.3335,\n",
       "            0.3276, 0.325 , 0.3245, 0.319 , 0.3047, 0.304 , 0.3018, 0.262 ,\n",
       "            0.255 , 0.2512, 0.2462, 0.244 , 0.2433, 0.243 , 0.2418, 0.2367,\n",
       "            0.2366, 0.2363, 0.2292, 0.229 , 0.2278, 0.2274, 0.2233, 0.2101,\n",
       "            0.2031, 0.1919, 0.1724, 0.1533, 0.1459, 0.1403, 0.1309, 0.1304],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.2457627, dtype=float32),\n",
       "    'tpr': array(0.75, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05932203, 0.06779661, 0.06779661, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.23728813, 0.23728813, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.37288135, 0.37288135,\n",
       "            0.37288135, 0.37288135, 0.38135594, 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.41666666,\n",
       "            0.42424244, 0.43939394, 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.6969697 , 0.6969697 , 0.70454544, 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.75757575, 0.75757575, 0.75757575,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.79545456, 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.772 , 0.738 , 0.7373, 0.7344, 0.7305, 0.726 , 0.725 ,\n",
       "            0.724 , 0.7217, 0.7153, 0.7124, 0.7075, 0.7046, 0.694 , 0.6914,\n",
       "            0.6904, 0.688 , 0.684 , 0.683 , 0.678 , 0.6777, 0.675 , 0.673 ,\n",
       "            0.672 , 0.671 , 0.6685, 0.667 , 0.664 , 0.6606, 0.659 , 0.658 ,\n",
       "            0.6577, 0.6553, 0.6523, 0.6475, 0.6465, 0.6313, 0.629 , 0.6284,\n",
       "            0.6265, 0.6245, 0.62  , 0.615 , 0.612 , 0.607 , 0.5996, 0.5933,\n",
       "            0.5894, 0.5884, 0.5835, 0.574 , 0.5728, 0.5713, 0.568 , 0.5664,\n",
       "            0.565 , 0.564 , 0.563 , 0.561 , 0.5605, 0.56  , 0.5596, 0.5557,\n",
       "            0.5527, 0.5503, 0.549 , 0.547 , 0.5464, 0.546 , 0.5454, 0.5435,\n",
       "            0.543 , 0.5386, 0.5347, 0.5337, 0.533 , 0.5312, 0.5303, 0.53  ,\n",
       "            0.529 , 0.5264, 0.5254, 0.5215, 0.521 , 0.519 , 0.5186, 0.518 ,\n",
       "            0.5176, 0.5146, 0.511 , 0.5107, 0.51  , 0.5093, 0.508 , 0.507 ,\n",
       "            0.506 , 0.5054, 0.505 , 0.504 , 0.5024, 0.502 , 0.5015, 0.501 ,\n",
       "            0.5005, 0.5   , 0.4998, 0.498 , 0.4976, 0.4973, 0.497 , 0.4966,\n",
       "            0.4958, 0.4946, 0.4937, 0.4927, 0.4922, 0.4912, 0.491 , 0.4907,\n",
       "            0.4895, 0.4885, 0.4873, 0.487 , 0.4863, 0.4858, 0.4854, 0.485 ,\n",
       "            0.4846, 0.4844, 0.484 , 0.4832, 0.483 , 0.4827, 0.4814, 0.4807,\n",
       "            0.4805, 0.4797, 0.479 , 0.4785, 0.4783, 0.4778, 0.4773, 0.477 ,\n",
       "            0.4766, 0.4758, 0.475 , 0.472 , 0.4714, 0.47  , 0.469 , 0.4688,\n",
       "            0.4673, 0.467 , 0.4658, 0.465 , 0.464 , 0.463 , 0.4592, 0.4573,\n",
       "            0.4517, 0.4443, 0.4412, 0.44  , 0.4355, 0.4336, 0.4297, 0.429 ,\n",
       "            0.427 , 0.426 , 0.425 , 0.4114, 0.4072, 0.3984, 0.3928, 0.3867,\n",
       "            0.3843, 0.3728, 0.3481, 0.3477, 0.347 , 0.345 , 0.3447, 0.3445,\n",
       "            0.3357, 0.3337, 0.3335, 0.333 , 0.3271, 0.3123, 0.3113, 0.3088,\n",
       "            0.266 , 0.2588, 0.2542, 0.2494, 0.2467, 0.246 , 0.2458, 0.2444,\n",
       "            0.2394, 0.239 , 0.2384, 0.2307, 0.2294, 0.2289, 0.2247, 0.2104,\n",
       "            0.2032, 0.1921, 0.1709, 0.1511, 0.1436, 0.138 , 0.1285, 0.1278],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.42372882, dtype=float32),\n",
       "    'tpr': array(0.92424244, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.22881356, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.26271185, 0.27118644,\n",
       "            0.2881356 , 0.2881356 , 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.33050847, 0.33898306, 0.33898306, 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3559322 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.41525424, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.3030303 , 0.31060606,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 , 0.6136364 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.6666667 , 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.74242425, 0.75      , 0.75757575, 0.75757575,\n",
       "            0.75757575, 0.77272725, 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.79545456, 0.79545456, 0.79545456, 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8712121 , 0.8712121 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.804 , 0.7695, 0.7686, 0.766 , 0.762 , 0.7617, 0.758 ,\n",
       "            0.7563, 0.7554, 0.753 , 0.7466, 0.7437, 0.7383, 0.7354, 0.724 ,\n",
       "            0.722 , 0.7217, 0.7207, 0.7183, 0.714 , 0.713 , 0.7075, 0.7065,\n",
       "            0.7046, 0.7026, 0.701 , 0.7007, 0.6997, 0.697 , 0.6953, 0.693 ,\n",
       "            0.6895, 0.6885, 0.6865, 0.686 , 0.683 , 0.68  , 0.676 , 0.6753,\n",
       "            0.675 , 0.659 , 0.655 , 0.6543, 0.653 , 0.652 , 0.6475, 0.642 ,\n",
       "            0.6377, 0.6313, 0.6255, 0.6187, 0.618 , 0.6123, 0.608 , 0.606 ,\n",
       "            0.6045, 0.5977, 0.597 , 0.596 , 0.5947, 0.5933, 0.5903, 0.5884,\n",
       "            0.5864, 0.586 , 0.583 , 0.5825, 0.58  , 0.5786, 0.577 , 0.5767,\n",
       "            0.576 , 0.575 , 0.5747, 0.574 , 0.5684, 0.5635, 0.5615, 0.5605,\n",
       "            0.56  , 0.559 , 0.5586, 0.5566, 0.555 , 0.5547, 0.5537, 0.553 ,\n",
       "            0.5522, 0.55  , 0.549 , 0.548 , 0.545 , 0.5425, 0.541 , 0.5405,\n",
       "            0.5396, 0.538 , 0.537 , 0.536 , 0.535 , 0.5337, 0.5327, 0.532 ,\n",
       "            0.531 , 0.5303, 0.53  , 0.529 , 0.5283, 0.528 , 0.527 , 0.5264,\n",
       "            0.5254, 0.525 , 0.5244, 0.5234, 0.5215, 0.521 , 0.52  , 0.517 ,\n",
       "            0.5166, 0.5156, 0.514 , 0.5137, 0.513 , 0.5127, 0.5117, 0.511 ,\n",
       "            0.5107, 0.5103, 0.508 , 0.507 , 0.5063, 0.506 , 0.5054, 0.5034,\n",
       "            0.5024, 0.5015, 0.501 , 0.5005, 0.4998, 0.498 , 0.4958, 0.4956,\n",
       "            0.495 , 0.4927, 0.492 , 0.4905, 0.4897, 0.4878, 0.4873, 0.4863,\n",
       "            0.486 , 0.4854, 0.4849, 0.4846, 0.4844, 0.4792, 0.4785, 0.4736,\n",
       "            0.463 , 0.4592, 0.4568, 0.449 , 0.4473, 0.4465, 0.4438, 0.441 ,\n",
       "            0.4382, 0.4238, 0.419 , 0.4106, 0.4043, 0.3977, 0.395 , 0.383 ,\n",
       "            0.3572, 0.3567, 0.3562, 0.355 , 0.3545, 0.3538, 0.344 , 0.3423,\n",
       "            0.341 , 0.335 , 0.3196, 0.3186, 0.316 , 0.3157, 0.2708, 0.2634,\n",
       "            0.258 , 0.2534, 0.25  , 0.2494, 0.249 , 0.2477, 0.2429, 0.2418,\n",
       "            0.2415, 0.2334, 0.2319, 0.2313, 0.2272, 0.212 , 0.2045, 0.1937,\n",
       "            0.171 , 0.1508, 0.1428, 0.1372, 0.1278, 0.1268], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5254237, dtype=float32),\n",
       "    'tpr': array(0.9621212, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.21186441, 0.21186441, 0.22881356, 0.23728813, 0.26271185,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.3220339 , 0.3220339 , 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.38135594, 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5508475 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.3030303 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.5       , 0.52272725, 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.7348485 , 0.74242425, 0.7651515 , 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.81060606, 0.82575756,\n",
       "            0.84090906, 0.84090906, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.833 , 0.7993, 0.7983, 0.7954, 0.7915, 0.791 , 0.7866,\n",
       "            0.786 , 0.7847, 0.782 , 0.776 , 0.7725, 0.768 , 0.764 , 0.7534,\n",
       "            0.751 , 0.7495, 0.747 , 0.742 , 0.741 , 0.736 , 0.7354, 0.735 ,\n",
       "            0.733 , 0.7305, 0.729 , 0.7285, 0.7275, 0.7246, 0.723 , 0.7207,\n",
       "            0.717 , 0.716 , 0.714 , 0.7104, 0.7075, 0.703 , 0.702 , 0.7017,\n",
       "            0.686 , 0.68  , 0.6797, 0.678 , 0.6743, 0.669 , 0.663 , 0.6553,\n",
       "            0.6504, 0.646 , 0.644 , 0.6367, 0.636 , 0.6357, 0.633 , 0.6313,\n",
       "            0.621 , 0.6196, 0.619 , 0.616 , 0.615 , 0.614 , 0.613 , 0.612 ,\n",
       "            0.611 , 0.609 , 0.608 , 0.6064, 0.6055, 0.6045, 0.604 , 0.6035,\n",
       "            0.602 , 0.5903, 0.59  , 0.5894, 0.5884, 0.588 , 0.5874, 0.587 ,\n",
       "            0.5835, 0.583 , 0.5825, 0.578 , 0.5776, 0.5767, 0.576 , 0.572 ,\n",
       "            0.5703, 0.57  , 0.568 , 0.567 , 0.5664, 0.565 , 0.5645, 0.564 ,\n",
       "            0.5635, 0.562 , 0.5615, 0.56  , 0.559 , 0.553 , 0.5527, 0.552 ,\n",
       "            0.5513, 0.551 , 0.5503, 0.55  , 0.5493, 0.5464, 0.546 , 0.545 ,\n",
       "            0.543 , 0.5425, 0.5415, 0.541 , 0.54  , 0.5396, 0.5386, 0.538 ,\n",
       "            0.5376, 0.5366, 0.5347, 0.5327, 0.532 , 0.5312, 0.5303, 0.5283,\n",
       "            0.528 , 0.527 , 0.5264, 0.526 , 0.5244, 0.5234, 0.522 , 0.521 ,\n",
       "            0.5205, 0.52  , 0.516 , 0.515 , 0.514 , 0.5127, 0.512 , 0.5117,\n",
       "            0.5093, 0.509 , 0.5073, 0.5063, 0.505 , 0.5024, 0.502 , 0.5   ,\n",
       "            0.4954, 0.4817, 0.4788, 0.473 , 0.4644, 0.4624, 0.4604, 0.4578,\n",
       "            0.457 , 0.455 , 0.4514, 0.4363, 0.4307, 0.4229, 0.4155, 0.409 ,\n",
       "            0.406 , 0.393 , 0.3667, 0.3662, 0.3657, 0.364 , 0.3633, 0.352 ,\n",
       "            0.351 , 0.3489, 0.343 , 0.3274, 0.3262, 0.3232, 0.323 , 0.2761,\n",
       "            0.2686, 0.2617, 0.258 , 0.2534, 0.2527, 0.251 , 0.2474, 0.2449,\n",
       "            0.2445, 0.2362, 0.2358, 0.2347, 0.2343, 0.2302, 0.214 , 0.2063,\n",
       "            0.1952, 0.172 , 0.1511, 0.1425, 0.1375, 0.1279, 0.1261],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.55932206, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.56060606,\n",
       "            0.57575756, 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.7121212 , 0.7121212 , 0.7121212 ,\n",
       "            0.72727275, 0.7348485 , 0.75757575, 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.8333333 , 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8787879 , 0.8787879 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8584, 0.8257, 0.8247, 0.822 , 0.8184, 0.818 , 0.8135,\n",
       "            0.813 , 0.8115, 0.809 , 0.803 , 0.7993, 0.795 , 0.791 , 0.7803,\n",
       "            0.778 , 0.776 , 0.774 , 0.7686, 0.7676, 0.762 , 0.7617, 0.761 ,\n",
       "            0.76  , 0.7573, 0.756 , 0.7554, 0.754 , 0.751 , 0.749 , 0.747 ,\n",
       "            0.743 , 0.7417, 0.74  , 0.7397, 0.7363, 0.7334, 0.729 , 0.728 ,\n",
       "            0.7275, 0.727 , 0.7124, 0.705 , 0.704 , 0.7036, 0.703 , 0.7   ,\n",
       "            0.695 , 0.687 , 0.6787, 0.675 , 0.6733, 0.669 , 0.668 , 0.6675,\n",
       "            0.666 , 0.6587, 0.6553, 0.6484, 0.6475, 0.646 , 0.645 , 0.6445,\n",
       "            0.6426, 0.6416, 0.6396, 0.639 , 0.638 , 0.637 , 0.6357, 0.6353,\n",
       "            0.634 , 0.6333, 0.633 , 0.6304, 0.63  , 0.6294, 0.628 , 0.619 ,\n",
       "            0.6177, 0.6147, 0.6143, 0.613 , 0.6123, 0.612 , 0.6094, 0.6055,\n",
       "            0.6035, 0.6025, 0.602 , 0.5986, 0.597 , 0.595 , 0.594 , 0.593 ,\n",
       "            0.5923, 0.5913, 0.591 , 0.588 , 0.587 , 0.5864, 0.5845, 0.581 ,\n",
       "            0.5796, 0.579 , 0.5786, 0.5776, 0.5767, 0.5757, 0.5747, 0.574 ,\n",
       "            0.5737, 0.573 , 0.5728, 0.5723, 0.572 , 0.5713, 0.571 , 0.5703,\n",
       "            0.5693, 0.569 , 0.5664, 0.566 , 0.5654, 0.565 , 0.564 , 0.5635,\n",
       "            0.563 , 0.5625, 0.562 , 0.5576, 0.5566, 0.554 , 0.553 , 0.5522,\n",
       "            0.5513, 0.5503, 0.5493, 0.5483, 0.5474, 0.547 , 0.5454, 0.545 ,\n",
       "            0.543 , 0.5425, 0.541 , 0.54  , 0.5366, 0.536 , 0.5356, 0.534 ,\n",
       "            0.532 , 0.531 , 0.529 , 0.5283, 0.526 , 0.524 , 0.5215, 0.5195,\n",
       "            0.5186, 0.517 , 0.516 , 0.5005, 0.4976, 0.489 , 0.482 , 0.4766,\n",
       "            0.4749, 0.473 , 0.4724, 0.4697, 0.465 , 0.4495, 0.4434, 0.4355,\n",
       "            0.4277, 0.421 , 0.418 , 0.4045, 0.3782, 0.3765, 0.3762, 0.376 ,\n",
       "            0.3745, 0.3733, 0.3613, 0.3606, 0.3604, 0.3582, 0.3518, 0.3357,\n",
       "            0.3342, 0.3315, 0.331 , 0.282 , 0.2742, 0.2668, 0.2634, 0.258 ,\n",
       "            0.2573, 0.2556, 0.252 , 0.2493, 0.2489, 0.2401, 0.2386, 0.2382,\n",
       "            0.2339, 0.2168, 0.2089, 0.1985, 0.1733, 0.152 , 0.1432, 0.138 ,\n",
       "            0.1285, 0.1266], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5762712, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16949153, 0.16949153, 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.33050847, 0.34745762,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3559322 , 0.37288135,\n",
       "            0.37288135, 0.37288135, 0.38135594, 0.3898305 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.42372882, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.7121212 , 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.72727275, 0.74242425,\n",
       "            0.74242425, 0.75757575, 0.7651515 , 0.77272725, 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.881 , 0.8496, 0.8486, 0.8457, 0.8423, 0.842 , 0.8374,\n",
       "            0.8354, 0.8335, 0.8276, 0.8237, 0.8193, 0.8154, 0.805 , 0.8027,\n",
       "            0.8013, 0.799 , 0.793 , 0.7925, 0.7866, 0.786 , 0.7856, 0.7847,\n",
       "            0.782 , 0.781 , 0.78  , 0.7783, 0.7754, 0.7734, 0.7715, 0.7676,\n",
       "            0.766 , 0.7646, 0.7607, 0.7573, 0.7534, 0.7524, 0.752 , 0.751 ,\n",
       "            0.7373, 0.7285, 0.7275, 0.7266, 0.7246, 0.7197, 0.71  , 0.701 ,\n",
       "            0.7007, 0.6997, 0.698 , 0.695 , 0.6934, 0.681 , 0.68  , 0.678 ,\n",
       "            0.675 , 0.674 , 0.673 , 0.67  , 0.668 , 0.6675, 0.6655, 0.665 ,\n",
       "            0.6636, 0.663 , 0.661 , 0.6597, 0.659 , 0.658 , 0.6562, 0.652 ,\n",
       "            0.65  , 0.648 , 0.6465, 0.642 , 0.6416, 0.641 , 0.6406, 0.64  ,\n",
       "            0.636 , 0.6357, 0.6353, 0.635 , 0.634 , 0.6323, 0.6304, 0.626 ,\n",
       "            0.6255, 0.625 , 0.6235, 0.6196, 0.618 , 0.6177, 0.616 , 0.6147,\n",
       "            0.6123, 0.6113, 0.611 , 0.6104, 0.609 , 0.608 , 0.6074, 0.605 ,\n",
       "            0.6045, 0.6025, 0.602 , 0.6016, 0.6   , 0.5986, 0.598 , 0.5977,\n",
       "            0.597 , 0.5967, 0.596 , 0.5957, 0.5947, 0.594 , 0.5938, 0.5933,\n",
       "            0.5923, 0.592 , 0.5903, 0.5894, 0.589 , 0.588 , 0.5835, 0.5825,\n",
       "            0.582 , 0.5786, 0.578 , 0.577 , 0.5757, 0.5747, 0.5723, 0.572 ,\n",
       "            0.5713, 0.57  , 0.5693, 0.5684, 0.568 , 0.5674, 0.565 , 0.5645,\n",
       "            0.561 , 0.5596, 0.559 , 0.557 , 0.556 , 0.5522, 0.5503, 0.55  ,\n",
       "            0.543 , 0.5425, 0.5386, 0.536 , 0.5347, 0.5317, 0.5186, 0.516 ,\n",
       "            0.505 , 0.499 , 0.4902, 0.4885, 0.4863, 0.484 , 0.4778, 0.462 ,\n",
       "            0.4553, 0.4478, 0.4392, 0.4321, 0.429 , 0.415 , 0.3882, 0.3857,\n",
       "            0.3855, 0.3853, 0.3838, 0.3823, 0.3696, 0.3694, 0.369 , 0.3662,\n",
       "            0.3596, 0.343 , 0.3413, 0.3386, 0.338 , 0.2861, 0.278 , 0.27  ,\n",
       "            0.2668, 0.2612, 0.2598, 0.2583, 0.255 , 0.252 , 0.2512, 0.2421,\n",
       "            0.2406, 0.2399, 0.2358, 0.2177, 0.2091, 0.1996, 0.1726, 0.1506,\n",
       "            0.1417, 0.1365, 0.127 , 0.1249], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59322035, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.20338982, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.23728813, 0.2542373 , 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.2881356 , 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.3644068 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.49242425, 0.49242425,\n",
       "            0.5       , 0.5151515 , 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6439394 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.70454544, 0.719697  ,\n",
       "            0.72727275, 0.72727275, 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.75      , 0.7651515 , 0.780303  , 0.79545456, 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.8333333 , 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9004, 0.871 , 0.87  , 0.867 , 0.864 , 0.8633, 0.859 ,\n",
       "            0.8574, 0.8555, 0.8496, 0.846 , 0.842 , 0.838 , 0.8286, 0.8257,\n",
       "            0.824 , 0.8223, 0.8154, 0.81  , 0.809 , 0.8086, 0.808 , 0.8057,\n",
       "            0.804 , 0.803 , 0.802 , 0.7983, 0.7964, 0.795 , 0.7905, 0.7886,\n",
       "            0.7876, 0.784 , 0.7803, 0.777 , 0.776 , 0.7754, 0.774 , 0.761 ,\n",
       "            0.7515, 0.7505, 0.75  , 0.7495, 0.748 , 0.743 , 0.7324, 0.727 ,\n",
       "            0.7256, 0.723 , 0.7227, 0.721 , 0.717 , 0.7104, 0.704 , 0.7026,\n",
       "            0.702 , 0.701 , 0.6973, 0.6963, 0.6943, 0.693 , 0.6914, 0.69  ,\n",
       "            0.6885, 0.688 , 0.687 , 0.684 , 0.6836, 0.682 , 0.6816, 0.681 ,\n",
       "            0.6763, 0.675 , 0.674 , 0.6714, 0.671 , 0.668 , 0.6665, 0.6655,\n",
       "            0.661 , 0.66  , 0.657 , 0.654 , 0.653 , 0.6523, 0.651 , 0.65  ,\n",
       "            0.649 , 0.648 , 0.6465, 0.6436, 0.6426, 0.642 , 0.641 , 0.6387,\n",
       "            0.638 , 0.6367, 0.636 , 0.6357, 0.6353, 0.635 , 0.6313, 0.631 ,\n",
       "            0.6304, 0.63  , 0.629 , 0.6274, 0.627 , 0.623 , 0.6226, 0.621 ,\n",
       "            0.6206, 0.62  , 0.619 , 0.6187, 0.618 , 0.6167, 0.615 , 0.6143,\n",
       "            0.614 , 0.6133, 0.613 , 0.6123, 0.6084, 0.6074, 0.6035, 0.603 ,\n",
       "            0.602 , 0.5996, 0.599 , 0.5977, 0.596 , 0.5947, 0.594 , 0.5938,\n",
       "            0.593 , 0.592 , 0.591 , 0.5903, 0.5894, 0.588 , 0.5874, 0.587 ,\n",
       "            0.586 , 0.583 , 0.582 , 0.5815, 0.579 , 0.576 , 0.574 , 0.5723,\n",
       "            0.5674, 0.5645, 0.564 , 0.5625, 0.56  , 0.5596, 0.5537, 0.5513,\n",
       "            0.548 , 0.5376, 0.5366, 0.521 , 0.517 , 0.505 , 0.5044, 0.5034,\n",
       "            0.501 , 0.4988, 0.4915, 0.475 , 0.468 , 0.4604, 0.4517, 0.444 ,\n",
       "            0.441 , 0.4263, 0.3997, 0.3958, 0.3955, 0.395 , 0.394 , 0.3923,\n",
       "            0.3787, 0.3784, 0.3782, 0.375 , 0.3684, 0.351 , 0.349 , 0.347 ,\n",
       "            0.3455, 0.2915, 0.2832, 0.2744, 0.2712, 0.2654, 0.2646, 0.2634,\n",
       "            0.262 , 0.2588, 0.2554, 0.255 , 0.2451, 0.2449, 0.2434, 0.2429,\n",
       "            0.2386, 0.2195, 0.2106, 0.2017, 0.1727, 0.1503, 0.1411, 0.1359,\n",
       "            0.1262, 0.1241], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6101695, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6694915 , 0.6864407 , 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.70454544, 0.7121212 , 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.8030303 , 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.917 , 0.89  , 0.889 , 0.8867, 0.8833, 0.8823, 0.8784,\n",
       "            0.8774, 0.8755, 0.87  , 0.8667, 0.8623, 0.8584, 0.849 , 0.8467,\n",
       "            0.846 , 0.8457, 0.8433, 0.837 , 0.831 , 0.8306, 0.83  , 0.8296,\n",
       "            0.827 , 0.8257, 0.8247, 0.823 , 0.8203, 0.8184, 0.817 , 0.8125,\n",
       "            0.8105, 0.8096, 0.806 , 0.8022, 0.799 , 0.7983, 0.7974, 0.796 ,\n",
       "            0.7837, 0.773 , 0.7725, 0.7715, 0.771 , 0.7705, 0.765 , 0.762 ,\n",
       "            0.7544, 0.754 , 0.7505, 0.749 , 0.744 , 0.743 , 0.7393, 0.7334,\n",
       "            0.732 , 0.7295, 0.724 , 0.723 , 0.721 , 0.719 , 0.7183, 0.718 ,\n",
       "            0.715 , 0.7144, 0.7114, 0.71  , 0.7085, 0.708 , 0.7075, 0.7065,\n",
       "            0.7036, 0.703 , 0.7026, 0.6987, 0.696 , 0.6953, 0.695 , 0.694 ,\n",
       "            0.6924, 0.6914, 0.688 , 0.686 , 0.685 , 0.6836, 0.683 , 0.68  ,\n",
       "            0.677 , 0.6753, 0.6743, 0.6733, 0.673 , 0.672 , 0.671 , 0.669 ,\n",
       "            0.668 , 0.6665, 0.6646, 0.6636, 0.663 , 0.6616, 0.661 , 0.66  ,\n",
       "            0.659 , 0.6587, 0.657 , 0.6567, 0.6562, 0.656 , 0.655 , 0.6533,\n",
       "            0.6523, 0.6504, 0.6484, 0.648 , 0.6475, 0.646 , 0.6455, 0.645 ,\n",
       "            0.6436, 0.643 , 0.6426, 0.642 , 0.6406, 0.64  , 0.6387, 0.638 ,\n",
       "            0.6377, 0.637 , 0.6367, 0.636 , 0.6333, 0.6323, 0.628 , 0.6274,\n",
       "            0.627 , 0.624 , 0.623 , 0.6206, 0.62  , 0.619 , 0.6187, 0.6167,\n",
       "            0.616 , 0.6157, 0.615 , 0.6123, 0.6113, 0.6094, 0.609 , 0.6084,\n",
       "            0.608 , 0.6074, 0.6064, 0.605 , 0.602 , 0.601 , 0.597 , 0.5967,\n",
       "            0.5947, 0.594 , 0.587 , 0.586 , 0.5854, 0.582 , 0.5815, 0.5767,\n",
       "            0.5713, 0.5684, 0.564 , 0.558 , 0.5576, 0.538 , 0.536 , 0.5225,\n",
       "            0.5186, 0.516 , 0.514 , 0.5054, 0.4888, 0.4807, 0.4739, 0.464 ,\n",
       "            0.4565, 0.4534, 0.4373, 0.4136, 0.4067, 0.4053, 0.403 , 0.3892,\n",
       "            0.3882, 0.3877, 0.384 , 0.3777, 0.3604, 0.3582, 0.3562, 0.354 ,\n",
       "            0.2979, 0.2898, 0.279 , 0.2776, 0.2703, 0.2693, 0.268 , 0.266 ,\n",
       "            0.2646, 0.259 , 0.2588, 0.2485, 0.2473, 0.2467, 0.2426, 0.2222,\n",
       "            0.2133, 0.2039, 0.1744, 0.1514, 0.1414, 0.1366, 0.1271, 0.124 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.61864406, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.3220339 , 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3559322 , 0.3559322 ,\n",
       "            0.3559322 , 0.3644068 , 0.38135594, 0.3898305 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.1590909 ,\n",
       "            0.16666667, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.67424244, 0.68939394,\n",
       "            0.68939394, 0.70454544, 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75757575, 0.75757575, 0.77272725, 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.9318182 ,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9287, 0.904 , 0.9033, 0.901 , 0.8975, 0.8965, 0.893 ,\n",
       "            0.892 , 0.89  , 0.8853, 0.882 , 0.8774, 0.874 , 0.865 , 0.863 ,\n",
       "            0.862 , 0.8613, 0.8594, 0.853 , 0.8477, 0.8467, 0.846 , 0.8438,\n",
       "            0.8423, 0.8413, 0.84  , 0.837 , 0.835 , 0.8335, 0.8296, 0.827 ,\n",
       "            0.8267, 0.8228, 0.8193, 0.816 , 0.815 , 0.8145, 0.814 , 0.8125,\n",
       "            0.801 , 0.79  , 0.7896, 0.7886, 0.788 , 0.7876, 0.785 , 0.7827,\n",
       "            0.776 , 0.771 , 0.7705, 0.7695, 0.762 , 0.761 , 0.7603, 0.7573,\n",
       "            0.7563, 0.754 , 0.7505, 0.7456, 0.7407, 0.74  , 0.7397, 0.7393,\n",
       "            0.737 , 0.736 , 0.7354, 0.7334, 0.729 , 0.728 , 0.726 , 0.7256,\n",
       "            0.725 , 0.7246, 0.721 , 0.7207, 0.72  , 0.7163, 0.7144, 0.7124,\n",
       "            0.7114, 0.7095, 0.709 , 0.706 , 0.705 , 0.7046, 0.703 , 0.7017,\n",
       "            0.6978, 0.6973, 0.6943, 0.693 , 0.692 , 0.6914, 0.6904, 0.69  ,\n",
       "            0.6895, 0.688 , 0.687 , 0.686 , 0.685 , 0.683 , 0.6816, 0.681 ,\n",
       "            0.6807, 0.68  , 0.679 , 0.6787, 0.678 , 0.6772, 0.676 , 0.6753,\n",
       "            0.673 , 0.6714, 0.67  , 0.669 , 0.667 , 0.6665, 0.666 , 0.6655,\n",
       "            0.663 , 0.6626, 0.662 , 0.661 , 0.659 , 0.658 , 0.6577, 0.657 ,\n",
       "            0.654 , 0.6533, 0.6523, 0.6504, 0.6484, 0.6475, 0.647 , 0.6426,\n",
       "            0.641 , 0.6396, 0.6377, 0.637 , 0.6367, 0.6353, 0.635 , 0.6343,\n",
       "            0.631 , 0.628 , 0.6274, 0.626 , 0.625 , 0.6245, 0.6235, 0.622 ,\n",
       "            0.6196, 0.619 , 0.615 , 0.6133, 0.613 , 0.612 , 0.605 , 0.6025,\n",
       "            0.601 , 0.5996, 0.5977, 0.591 , 0.586 , 0.582 , 0.5776, 0.575 ,\n",
       "            0.5522, 0.552 , 0.5366, 0.5317, 0.5312, 0.5293, 0.527 , 0.5176,\n",
       "            0.501 , 0.4924, 0.4856, 0.4756, 0.4678, 0.4644, 0.448 , 0.4255,\n",
       "            0.417 , 0.4167, 0.4155, 0.415 , 0.413 , 0.3987, 0.3977, 0.3967,\n",
       "            0.393 , 0.3867, 0.369 , 0.3667, 0.365 , 0.3623, 0.3044, 0.2969,\n",
       "            0.2847, 0.2837, 0.276 , 0.2747, 0.2732, 0.2715, 0.2708, 0.2642,\n",
       "            0.2637, 0.2534, 0.252 , 0.2512, 0.2473, 0.226 , 0.2168, 0.2079,\n",
       "            0.1771, 0.1536, 0.1432, 0.1387, 0.129 , 0.1254], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.62711865, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.1590909 , 0.16666667, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.34848484, 0.3560606 , 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.42424244, 0.4318182 , 0.4469697 ,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.4848485 , 0.4848485 , 0.49242425,\n",
       "            0.49242425, 0.49242425, 0.5       , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6363636 ,\n",
       "            0.6439394 , 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.70454544, 0.7121212 , 0.7121212 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.79545456, 0.79545456, 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 , 0.8560606 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9395, 0.9165, 0.9155, 0.9136, 0.9106, 0.9097, 0.9062,\n",
       "            0.906 , 0.9053, 0.9033, 0.899 , 0.8955, 0.891 , 0.888 , 0.8794,\n",
       "            0.8774, 0.877 , 0.8765, 0.874 , 0.868 , 0.863 , 0.862 , 0.8594,\n",
       "            0.8574, 0.857 , 0.8555, 0.8525, 0.8506, 0.849 , 0.845 , 0.8433,\n",
       "            0.843 , 0.839 , 0.8354, 0.832 , 0.831 , 0.8306, 0.83  , 0.829 ,\n",
       "            0.8174, 0.8066, 0.806 , 0.8047, 0.8037, 0.799 , 0.7964, 0.7896,\n",
       "            0.789 , 0.787 , 0.7837, 0.7783, 0.7773, 0.777 , 0.775 , 0.771 ,\n",
       "            0.7666, 0.7607, 0.7603, 0.759 , 0.758 , 0.756 , 0.7554, 0.755 ,\n",
       "            0.752 , 0.7476, 0.747 , 0.7466, 0.746 , 0.7456, 0.743 , 0.7427,\n",
       "            0.7417, 0.738 , 0.7373, 0.7344, 0.731 , 0.73  , 0.729 , 0.726 ,\n",
       "            0.7256, 0.725 , 0.7246, 0.72  , 0.719 , 0.718 , 0.716 , 0.7144,\n",
       "            0.71  , 0.709 , 0.7085, 0.708 , 0.706 , 0.705 , 0.7046, 0.703 ,\n",
       "            0.701 , 0.7007, 0.7   , 0.6997, 0.699 , 0.6987, 0.6973, 0.6963,\n",
       "            0.6934, 0.692 , 0.6914, 0.689 , 0.688 , 0.687 , 0.6865, 0.686 ,\n",
       "            0.685 , 0.684 , 0.6836, 0.6826, 0.682 , 0.6807, 0.6797, 0.679 ,\n",
       "            0.678 , 0.6777, 0.6772, 0.677 , 0.676 , 0.6743, 0.673 , 0.67  ,\n",
       "            0.6694, 0.6685, 0.667 , 0.662 , 0.6587, 0.658 , 0.6577, 0.657 ,\n",
       "            0.6567, 0.6553, 0.654 , 0.6533, 0.6523, 0.649 , 0.6455, 0.6445,\n",
       "            0.6426, 0.6416, 0.641 , 0.6396, 0.6377, 0.637 , 0.636 , 0.6333,\n",
       "            0.631 , 0.6304, 0.63  , 0.623 , 0.62  , 0.617 , 0.6157, 0.6133,\n",
       "            0.6055, 0.6   , 0.596 , 0.5923, 0.592 , 0.567 , 0.566 , 0.551 ,\n",
       "            0.546 , 0.544 , 0.542 , 0.54  , 0.53  , 0.5127, 0.5044, 0.4976,\n",
       "            0.487 , 0.479 , 0.4758, 0.459 , 0.4373, 0.4272, 0.427 , 0.4258,\n",
       "            0.425 , 0.4233, 0.4084, 0.4072, 0.4062, 0.4023, 0.396 , 0.3777,\n",
       "            0.3752, 0.3738, 0.3708, 0.311 , 0.3035, 0.2903, 0.2898, 0.2815,\n",
       "            0.2798, 0.278 , 0.2766, 0.269 , 0.2686, 0.2578, 0.2563, 0.2559,\n",
       "            0.252 , 0.2297, 0.2202, 0.2118, 0.1797, 0.1556, 0.1448, 0.1405,\n",
       "            0.1309, 0.1267], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.63559324, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.22881356,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 ,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.3644068 , 0.38135594, 0.3898305 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.13636364, 0.14393939, 0.1590909 , 0.16666667,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.45454547, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.5       , 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.7121212 , 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.7348485 , 0.74242425, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.79545456,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.948 , 0.9272, 0.927 , 0.925 , 0.9224, 0.9214, 0.918 ,\n",
       "            0.917 , 0.9155, 0.911 , 0.9077, 0.904 , 0.901 , 0.8926, 0.8906,\n",
       "            0.89  , 0.8877, 0.8823, 0.877 , 0.876 , 0.874 , 0.872 , 0.8716,\n",
       "            0.87  , 0.8667, 0.865 , 0.8643, 0.8604, 0.8584, 0.858 , 0.8574,\n",
       "            0.854 , 0.85  , 0.8477, 0.8457, 0.845 , 0.844 , 0.833 , 0.8267,\n",
       "            0.8223, 0.822 , 0.8203, 0.8193, 0.8154, 0.8145, 0.808 , 0.807 ,\n",
       "            0.8037, 0.803 , 0.799 , 0.7944, 0.7935, 0.7925, 0.7915, 0.79  ,\n",
       "            0.786 , 0.78  , 0.776 , 0.775 , 0.774 , 0.7725, 0.771 , 0.77  ,\n",
       "            0.7666, 0.766 , 0.765 , 0.764 , 0.7637, 0.7627, 0.762 , 0.76  ,\n",
       "            0.758 , 0.757 , 0.7544, 0.7534, 0.751 , 0.75  , 0.7456, 0.745 ,\n",
       "            0.7446, 0.744 , 0.743 , 0.742 , 0.7397, 0.7373, 0.736 , 0.735 ,\n",
       "            0.73  , 0.7295, 0.7285, 0.728 , 0.727 , 0.7266, 0.726 , 0.725 ,\n",
       "            0.7246, 0.7236, 0.7227, 0.7217, 0.719 , 0.718 , 0.7173, 0.717 ,\n",
       "            0.716 , 0.713 , 0.712 , 0.7085, 0.7075, 0.7065, 0.705 , 0.704 ,\n",
       "            0.7036, 0.702 , 0.7017, 0.6987, 0.6978, 0.6973, 0.697 , 0.6963,\n",
       "            0.696 , 0.695 , 0.694 , 0.693 , 0.692 , 0.6875, 0.6865, 0.686 ,\n",
       "            0.685 , 0.683 , 0.681 , 0.6772, 0.6763, 0.676 , 0.6743, 0.673 ,\n",
       "            0.671 , 0.6704, 0.67  , 0.6685, 0.665 , 0.6636, 0.661 , 0.66  ,\n",
       "            0.6577, 0.6553, 0.655 , 0.653 , 0.651 , 0.649 , 0.648 , 0.646 ,\n",
       "            0.6406, 0.637 , 0.6343, 0.6304, 0.6284, 0.6196, 0.6147, 0.6104,\n",
       "            0.6094, 0.609 , 0.6055, 0.582 , 0.58  , 0.5654, 0.56  , 0.557 ,\n",
       "            0.556 , 0.554 , 0.543 , 0.5254, 0.5166, 0.5103, 0.4993, 0.4912,\n",
       "            0.4878, 0.4705, 0.4512, 0.4385, 0.4382, 0.4373, 0.436 , 0.4343,\n",
       "            0.4192, 0.418 , 0.4163, 0.412 , 0.4058, 0.3875, 0.3848, 0.3838,\n",
       "            0.3801, 0.3186, 0.3115, 0.2974, 0.2969, 0.288 , 0.2861, 0.2844,\n",
       "            0.2837, 0.2827, 0.2751, 0.2744, 0.2634, 0.2622, 0.2615, 0.2576,\n",
       "            0.2344, 0.2247, 0.2166, 0.1833, 0.1587, 0.1472, 0.1434, 0.1339,\n",
       "            0.1288], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.66101694, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.29661018, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.4090909 , 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.4848485 , 0.49242425,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6515151 , 0.6515151 ,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.7121212 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.75      , 0.75757575,\n",
       "            0.77272725, 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.956 , 0.937 , 0.9365, 0.9346, 0.932 , 0.9316, 0.9287,\n",
       "            0.928 , 0.9277, 0.9263, 0.922 , 0.919 , 0.9155, 0.9126, 0.905 ,\n",
       "            0.903 , 0.9023, 0.9   , 0.8955, 0.895 , 0.89  , 0.889 , 0.8887,\n",
       "            0.887 , 0.8853, 0.885 , 0.8833, 0.8804, 0.8784, 0.878 , 0.874 ,\n",
       "            0.872 , 0.8716, 0.8677, 0.8643, 0.862 , 0.86  , 0.859 , 0.858 ,\n",
       "            0.848 , 0.845 , 0.837 , 0.8364, 0.8354, 0.835 , 0.8335, 0.833 ,\n",
       "            0.8296, 0.8257, 0.824 , 0.8228, 0.8184, 0.818 , 0.813 , 0.8086,\n",
       "            0.808 , 0.8076, 0.8047, 0.7983, 0.798 , 0.793 , 0.7896, 0.789 ,\n",
       "            0.787 , 0.786 , 0.7856, 0.785 , 0.7847, 0.784 , 0.7827, 0.7812,\n",
       "            0.7793, 0.7783, 0.7764, 0.776 , 0.7734, 0.772 , 0.771 , 0.7705,\n",
       "            0.768 , 0.7676, 0.7656, 0.7637, 0.762 , 0.761 , 0.76  , 0.758 ,\n",
       "            0.756 , 0.7554, 0.755 , 0.7544, 0.75  , 0.749 , 0.748 , 0.7466,\n",
       "            0.746 , 0.7456, 0.745 , 0.7446, 0.743 , 0.742 , 0.7417, 0.7397,\n",
       "            0.739 , 0.7383, 0.738 , 0.737 , 0.7363, 0.736 , 0.7354, 0.7344,\n",
       "            0.734 , 0.7334, 0.732 , 0.7314, 0.728 , 0.7275, 0.726 , 0.724 ,\n",
       "            0.723 , 0.7227, 0.7207, 0.7163, 0.716 , 0.7153, 0.715 , 0.7144,\n",
       "            0.713 , 0.7124, 0.7114, 0.7095, 0.7065, 0.705 , 0.7026, 0.701 ,\n",
       "            0.6997, 0.6987, 0.696 , 0.6953, 0.6943, 0.694 , 0.6904, 0.69  ,\n",
       "            0.6885, 0.6875, 0.687 , 0.6865, 0.684 , 0.6807, 0.6797, 0.6777,\n",
       "            0.6772, 0.6743, 0.674 , 0.673 , 0.67  , 0.6694, 0.6685, 0.6665,\n",
       "            0.665 , 0.6626, 0.658 , 0.655 , 0.652 , 0.6455, 0.6436, 0.635 ,\n",
       "            0.63  , 0.626 , 0.6255, 0.625 , 0.6206, 0.5977, 0.595 , 0.5806,\n",
       "            0.575 , 0.5713, 0.5703, 0.569 , 0.557 , 0.539 , 0.5303, 0.5244,\n",
       "            0.5127, 0.5044, 0.5015, 0.484 , 0.466 , 0.4514, 0.451 , 0.4502,\n",
       "            0.4485, 0.4468, 0.4316, 0.43  , 0.428 , 0.4238, 0.4175, 0.3992,\n",
       "            0.3962, 0.3955, 0.391 , 0.3281, 0.3213, 0.3066, 0.3054, 0.2964,\n",
       "            0.2944, 0.2927, 0.2925, 0.2908, 0.283 , 0.2822, 0.2708, 0.2695,\n",
       "            0.269 , 0.2651, 0.2407, 0.231 , 0.2235, 0.1886, 0.1635, 0.1512,\n",
       "            0.1478, 0.1382, 0.1323], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.66101694, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.16949153, 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.23728813, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.37288135, 0.38135594, 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18939394, 0.1969697 ,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.31060606, 0.3181818 , 0.32575756, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.42424244, 0.43939394, 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.67424244, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.79545456, 0.81060606,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.963 , 0.946 , 0.9453, 0.9434, 0.9414, 0.941 , 0.938 ,\n",
       "            0.9375, 0.937 , 0.936 , 0.9316, 0.929 , 0.926 , 0.923 , 0.916 ,\n",
       "            0.914 , 0.9136, 0.911 , 0.907 , 0.9062, 0.902 , 0.901 , 0.9004,\n",
       "            0.899 , 0.897 , 0.8955, 0.8926, 0.8906, 0.89  , 0.8867, 0.885 ,\n",
       "            0.8843, 0.8804, 0.877 , 0.875 , 0.873 , 0.872 , 0.871 , 0.8623,\n",
       "            0.8506, 0.85  , 0.849 , 0.8486, 0.8477, 0.8433, 0.842 , 0.8403,\n",
       "            0.8354, 0.8325, 0.83  , 0.825 , 0.8228, 0.8223, 0.816 , 0.8154,\n",
       "            0.8105, 0.81  , 0.8086, 0.805 , 0.8047, 0.8037, 0.803 , 0.801 ,\n",
       "            0.799 , 0.798 , 0.795 , 0.794 , 0.7935, 0.7925, 0.79  , 0.7896,\n",
       "            0.7886, 0.7856, 0.785 , 0.7847, 0.7817, 0.7793, 0.779 , 0.7783,\n",
       "            0.7764, 0.774 , 0.7734, 0.773 , 0.771 , 0.769 , 0.7676, 0.767 ,\n",
       "            0.765 , 0.7646, 0.7637, 0.763 , 0.7627, 0.7617, 0.7607, 0.76  ,\n",
       "            0.759 , 0.757 , 0.756 , 0.755 , 0.754 , 0.7534, 0.752 , 0.751 ,\n",
       "            0.75  , 0.747 , 0.746 , 0.7446, 0.744 , 0.742 , 0.7417, 0.7407,\n",
       "            0.7393, 0.7383, 0.734 , 0.7334, 0.733 , 0.7324, 0.732 , 0.7314,\n",
       "            0.7295, 0.729 , 0.7266, 0.726 , 0.725 , 0.7236, 0.723 , 0.7183,\n",
       "            0.718 , 0.7163, 0.7144, 0.714 , 0.7124, 0.712 , 0.707 , 0.7065,\n",
       "            0.706 , 0.7056, 0.704 , 0.7026, 0.701 , 0.698 , 0.6973, 0.6943,\n",
       "            0.6934, 0.6904, 0.69  , 0.686 , 0.6855, 0.6846, 0.6836, 0.682 ,\n",
       "            0.678 , 0.676 , 0.673 , 0.67  , 0.6597, 0.658 , 0.6484, 0.6436,\n",
       "            0.642 , 0.6406, 0.638 , 0.635 , 0.613 , 0.6084, 0.594 , 0.589 ,\n",
       "            0.5835, 0.5825, 0.5815, 0.569 , 0.551 , 0.542 , 0.5356, 0.5234,\n",
       "            0.515 , 0.512 , 0.495 , 0.4758, 0.4607, 0.4602, 0.4595, 0.4578,\n",
       "            0.456 , 0.4404, 0.4387, 0.4368, 0.4324, 0.426 , 0.4067, 0.4038,\n",
       "            0.4033, 0.3987, 0.333 , 0.3262, 0.3108, 0.31  , 0.3005, 0.2986,\n",
       "            0.2966, 0.295 , 0.2869, 0.2864, 0.2747, 0.2742, 0.2727, 0.2722,\n",
       "            0.268 , 0.2429, 0.2327, 0.2268, 0.1893, 0.1636, 0.1515, 0.1477,\n",
       "            0.138 , 0.1324], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6694915, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6694915 , 0.6779661 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18939394, 0.1969697 , 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.24242425, 0.25      , 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.40151516, 0.4090909 , 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.6818182 , 0.68939394, 0.70454544, 0.7121212 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.81060606, 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9688, 0.953 , 0.9526, 0.951 , 0.949 , 0.9463, 0.946 ,\n",
       "            0.9453, 0.9443, 0.9404, 0.938 , 0.935 , 0.9326, 0.926 , 0.924 ,\n",
       "            0.9233, 0.9214, 0.918 , 0.917 , 0.9126, 0.9116, 0.911 , 0.9097,\n",
       "            0.908 , 0.9062, 0.904 , 0.902 , 0.8984, 0.8965, 0.896 , 0.8926,\n",
       "            0.889 , 0.887 , 0.8853, 0.8843, 0.8833, 0.8774, 0.875 , 0.8647,\n",
       "            0.8633, 0.863 , 0.8623, 0.8613, 0.8604, 0.8564, 0.855 , 0.8525,\n",
       "            0.846 , 0.8457, 0.841 , 0.839 , 0.837 , 0.8364, 0.8354, 0.832 ,\n",
       "            0.831 , 0.8267, 0.8237, 0.8228, 0.8223, 0.821 , 0.82  , 0.8184,\n",
       "            0.817 , 0.8145, 0.814 , 0.811 , 0.8096, 0.808 , 0.807 , 0.806 ,\n",
       "            0.8027, 0.8022, 0.8013, 0.8003, 0.799 , 0.7964, 0.796 , 0.7944,\n",
       "            0.7915, 0.791 , 0.7905, 0.7876, 0.7866, 0.7856, 0.7847, 0.783 ,\n",
       "            0.7817, 0.7812, 0.781 , 0.78  , 0.779 , 0.778 , 0.7754, 0.775 ,\n",
       "            0.7744, 0.773 , 0.7725, 0.772 , 0.7715, 0.7705, 0.769 , 0.7676,\n",
       "            0.766 , 0.7656, 0.7646, 0.7637, 0.7627, 0.762 , 0.76  , 0.7593,\n",
       "            0.758 , 0.756 , 0.7554, 0.753 , 0.7515, 0.7505, 0.75  , 0.749 ,\n",
       "            0.7485, 0.748 , 0.7476, 0.7456, 0.7427, 0.7417, 0.741 , 0.7407,\n",
       "            0.74  , 0.7354, 0.734 , 0.7324, 0.7314, 0.7305, 0.73  , 0.7295,\n",
       "            0.7285, 0.724 , 0.7236, 0.722 , 0.7207, 0.7188, 0.7183, 0.715 ,\n",
       "            0.7104, 0.71  , 0.7065, 0.706 , 0.702 , 0.7017, 0.7   , 0.699 ,\n",
       "            0.6987, 0.698 , 0.6943, 0.6924, 0.6895, 0.687 , 0.674 , 0.672 ,\n",
       "            0.6616, 0.6577, 0.657 , 0.656 , 0.6514, 0.6475, 0.6284, 0.621 ,\n",
       "            0.608 , 0.601 , 0.5957, 0.5947, 0.594 , 0.5806, 0.562 , 0.5527,\n",
       "            0.5474, 0.534 , 0.526 , 0.5225, 0.505 , 0.489 , 0.471 , 0.4702,\n",
       "            0.4675, 0.466 , 0.45  , 0.4482, 0.445 , 0.4407, 0.4346, 0.4155,\n",
       "            0.4124, 0.4067, 0.3396, 0.3333, 0.3174, 0.315 , 0.3062, 0.3032,\n",
       "            0.3015, 0.2996, 0.2913, 0.2905, 0.2786, 0.277 , 0.2766, 0.2727,\n",
       "            0.2466, 0.236 , 0.2297, 0.1919, 0.1659, 0.1528, 0.1499, 0.1403,\n",
       "            0.1333], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6694915, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.18644068, 0.19491525, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.3644068 ,\n",
       "            0.37288135, 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.04545455,\n",
       "            0.0530303 , 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.4848485 , 0.49242425,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.54545456, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6515151 , 0.65909094, 0.65909094, 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.75      , 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.7878788 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9736, 0.9595, 0.958 , 0.956 , 0.954 , 0.953 , 0.9526,\n",
       "            0.9517, 0.948 , 0.946 , 0.9434, 0.941 , 0.9346, 0.933 , 0.932 ,\n",
       "            0.9307, 0.9277, 0.927 , 0.9224, 0.9214, 0.921 , 0.9194, 0.9185,\n",
       "            0.918 , 0.9165, 0.914 , 0.912 , 0.9087, 0.907 , 0.9067, 0.9033,\n",
       "            0.9   , 0.899 , 0.8965, 0.8955, 0.8945, 0.8916, 0.887 , 0.8784,\n",
       "            0.8755, 0.875 , 0.8745, 0.8735, 0.8726, 0.871 , 0.8706, 0.869 ,\n",
       "            0.8687, 0.868 , 0.8613, 0.8584, 0.8555, 0.8535, 0.85  , 0.849 ,\n",
       "            0.8486, 0.8477, 0.846 , 0.842 , 0.84  , 0.839 , 0.838 , 0.837 ,\n",
       "            0.8364, 0.834 , 0.833 , 0.8325, 0.832 , 0.829 , 0.8286, 0.8276,\n",
       "            0.827 , 0.825 , 0.8237, 0.822 , 0.8213, 0.8193, 0.817 , 0.8164,\n",
       "            0.8154, 0.814 , 0.813 , 0.811 , 0.81  , 0.809 , 0.8076, 0.805 ,\n",
       "            0.8027, 0.802 , 0.8013, 0.801 , 0.8   , 0.7993, 0.7983, 0.796 ,\n",
       "            0.793 , 0.7915, 0.791 , 0.7905, 0.79  , 0.789 , 0.788 , 0.7866,\n",
       "            0.786 , 0.784 , 0.7837, 0.7827, 0.782 , 0.781 , 0.7803, 0.78  ,\n",
       "            0.7793, 0.779 , 0.776 , 0.7744, 0.7725, 0.772 , 0.7705, 0.768 ,\n",
       "            0.767 , 0.7666, 0.7656, 0.764 , 0.7637, 0.761 , 0.7593, 0.7583,\n",
       "            0.758 , 0.757 , 0.7534, 0.752 , 0.7495, 0.7485, 0.7476, 0.746 ,\n",
       "            0.745 , 0.744 , 0.7417, 0.7393, 0.738 , 0.737 , 0.7363, 0.7354,\n",
       "            0.734 , 0.732 , 0.731 , 0.7256, 0.7227, 0.7217, 0.721 , 0.7183,\n",
       "            0.717 , 0.715 , 0.7134, 0.713 , 0.709 , 0.7085, 0.7056, 0.7036,\n",
       "            0.6875, 0.685 , 0.676 , 0.6733, 0.671 , 0.6704, 0.665 , 0.6626,\n",
       "            0.6436, 0.6353, 0.622 , 0.616 , 0.6094, 0.6084, 0.608 , 0.594 ,\n",
       "            0.5757, 0.5664, 0.561 , 0.5474, 0.539 , 0.5356, 0.519 , 0.5024,\n",
       "            0.4834, 0.4827, 0.4824, 0.4797, 0.4783, 0.4622, 0.4602, 0.457 ,\n",
       "            0.4524, 0.4463, 0.427 , 0.4236, 0.4177, 0.3489, 0.3425, 0.3262,\n",
       "            0.324 , 0.3145, 0.312 , 0.3115, 0.3098, 0.3079, 0.2996, 0.2988,\n",
       "            0.2864, 0.2847, 0.284 , 0.28  , 0.253 , 0.2422, 0.2375, 0.1971,\n",
       "            0.1705, 0.157 , 0.1543, 0.1447, 0.1371], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6694915, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.18644068,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.21186441, 0.21186441,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.30508474, 0.30508474, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9775, 0.9653, 0.965 , 0.964 , 0.9624, 0.962 , 0.9604,\n",
       "            0.9595, 0.959 , 0.958 , 0.955 , 0.953 , 0.9507, 0.948 , 0.9424,\n",
       "            0.9414, 0.941 , 0.9404, 0.939 , 0.936 , 0.935 , 0.931 , 0.93  ,\n",
       "            0.9297, 0.9287, 0.9277, 0.9272, 0.926 , 0.9233, 0.9214, 0.9185,\n",
       "            0.9175, 0.9165, 0.913 , 0.91  , 0.909 , 0.907 , 0.9067, 0.9062,\n",
       "            0.905 , 0.9043, 0.898 , 0.891 , 0.8867, 0.886 , 0.8857, 0.885 ,\n",
       "            0.8843, 0.884 , 0.8823, 0.8813, 0.8804, 0.875 , 0.87  , 0.869 ,\n",
       "            0.8677, 0.863 , 0.862 , 0.861 , 0.8604, 0.856 , 0.8555, 0.8545,\n",
       "            0.8525, 0.8516, 0.851 , 0.8477, 0.8467, 0.846 , 0.8447, 0.8433,\n",
       "            0.843 , 0.8423, 0.841 , 0.84  , 0.837 , 0.8364, 0.835 , 0.8345,\n",
       "            0.8315, 0.831 , 0.829 , 0.827 , 0.8257, 0.825 , 0.8247, 0.8237,\n",
       "            0.823 , 0.8213, 0.819 , 0.8184, 0.818 , 0.8174, 0.816 , 0.8154,\n",
       "            0.8145, 0.814 , 0.8125, 0.812 , 0.8076, 0.807 , 0.806 , 0.805 ,\n",
       "            0.8047, 0.804 , 0.803 , 0.8027, 0.8003, 0.7983, 0.7974, 0.7964,\n",
       "            0.796 , 0.7954, 0.795 , 0.7935, 0.7925, 0.792 , 0.7905, 0.7886,\n",
       "            0.788 , 0.785 , 0.784 , 0.783 , 0.7827, 0.782 , 0.781 , 0.7803,\n",
       "            0.7793, 0.779 , 0.7764, 0.7754, 0.7744, 0.774 , 0.772 , 0.768 ,\n",
       "            0.7666, 0.766 , 0.7646, 0.7637, 0.763 , 0.762 , 0.7607, 0.7593,\n",
       "            0.7583, 0.755 , 0.7534, 0.752 , 0.7515, 0.749 , 0.748 , 0.746 ,\n",
       "            0.7407, 0.7383, 0.737 , 0.7363, 0.734 , 0.7324, 0.732 , 0.73  ,\n",
       "            0.727 , 0.724 , 0.721 , 0.72  , 0.7017, 0.698 , 0.6895, 0.688 ,\n",
       "            0.685 , 0.6787, 0.6772, 0.659 , 0.6494, 0.6367, 0.6313, 0.6235,\n",
       "            0.6226, 0.6084, 0.59  , 0.5806, 0.575 , 0.561 , 0.553 , 0.55  ,\n",
       "            0.534 , 0.5186, 0.4973, 0.4968, 0.496 , 0.4934, 0.492 , 0.4756,\n",
       "            0.4736, 0.4705, 0.4656, 0.4592, 0.44  , 0.4368, 0.4363, 0.4304,\n",
       "            0.36  , 0.3542, 0.3374, 0.3347, 0.325 , 0.3232, 0.322 , 0.32  ,\n",
       "            0.3184, 0.3096, 0.309 , 0.2964, 0.296 , 0.2942, 0.2935, 0.2893,\n",
       "            0.2615, 0.2505, 0.2477, 0.2047, 0.1774, 0.1632, 0.1609, 0.1512,\n",
       "            0.1428], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7118644, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.22881356, 0.23728813, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6694915 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.34848484, 0.3560606 , 0.37878788, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5833333 , 0.5833333 , 0.5984849 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9814, 0.97  , 0.9688, 0.968 , 0.9673, 0.966 , 0.9653,\n",
       "            0.965 , 0.964 , 0.961 , 0.959 , 0.957 , 0.9546, 0.9497, 0.9487,\n",
       "            0.948 , 0.9478, 0.9463, 0.944 , 0.943 , 0.939 , 0.938 , 0.9375,\n",
       "            0.9365, 0.936 , 0.9355, 0.934 , 0.9316, 0.93  , 0.9272, 0.9263,\n",
       "            0.9253, 0.9224, 0.9194, 0.919 , 0.9165, 0.916 , 0.914 , 0.908 ,\n",
       "            0.9033, 0.8975, 0.897 , 0.8965, 0.8955, 0.895 , 0.8945, 0.893 ,\n",
       "            0.891 , 0.8877, 0.882 , 0.8813, 0.881 , 0.875 , 0.8745, 0.8735,\n",
       "            0.8726, 0.872 , 0.87  , 0.869 , 0.8687, 0.8667, 0.8657, 0.8643,\n",
       "            0.86  , 0.8594, 0.8574, 0.857 , 0.856 , 0.8555, 0.8516, 0.8506,\n",
       "            0.8496, 0.849 , 0.8477, 0.8467, 0.8457, 0.845 , 0.8447, 0.8438,\n",
       "            0.8413, 0.8403, 0.84  , 0.839 , 0.8384, 0.837 , 0.8345, 0.8335,\n",
       "            0.833 , 0.832 , 0.831 , 0.8296, 0.829 , 0.828 , 0.827 , 0.8267,\n",
       "            0.823 , 0.8228, 0.8213, 0.821 , 0.8203, 0.82  , 0.8193, 0.819 ,\n",
       "            0.818 , 0.8154, 0.814 , 0.8115, 0.811 , 0.8105, 0.81  , 0.809 ,\n",
       "            0.808 , 0.807 , 0.806 , 0.804 , 0.803 , 0.7993, 0.799 , 0.7983,\n",
       "            0.798 , 0.7974, 0.796 , 0.794 , 0.7935, 0.791 , 0.7905, 0.79  ,\n",
       "            0.7896, 0.786 , 0.7837, 0.7827, 0.781 , 0.7793, 0.7783, 0.7773,\n",
       "            0.777 , 0.776 , 0.7744, 0.7734, 0.7725, 0.7695, 0.7686, 0.7666,\n",
       "            0.7656, 0.764 , 0.7637, 0.7617, 0.756 , 0.7554, 0.7534, 0.751 ,\n",
       "            0.749 , 0.7476, 0.7466, 0.745 , 0.7407, 0.7383, 0.7363, 0.736 ,\n",
       "            0.715 , 0.712 , 0.703 , 0.7026, 0.699 , 0.698 , 0.6924, 0.675 ,\n",
       "            0.663 , 0.651 , 0.6465, 0.6377, 0.636 , 0.6226, 0.604 , 0.595 ,\n",
       "            0.5894, 0.575 , 0.568 , 0.564 , 0.5493, 0.535 , 0.511 , 0.51  ,\n",
       "            0.5073, 0.506 , 0.4895, 0.4873, 0.4841, 0.479 , 0.473 , 0.4531,\n",
       "            0.4502, 0.4495, 0.4434, 0.3716, 0.3665, 0.3489, 0.3464, 0.336 ,\n",
       "            0.3352, 0.333 , 0.3308, 0.3293, 0.3208, 0.32  , 0.3074, 0.3064,\n",
       "            0.3042, 0.3037, 0.2993, 0.2708, 0.2595, 0.2588, 0.2129, 0.1849,\n",
       "            0.17  , 0.1682, 0.1587, 0.1493], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.720339, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.1779661 , 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.34848484, 0.3560606 ,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.47727272, 0.4848485 , 0.4848485 , 0.49242425,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.780303  , 0.79545456, 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9844, 0.9746, 0.974 , 0.973 , 0.9727, 0.972 , 0.9707,\n",
       "            0.97  , 0.969 , 0.9688, 0.9663, 0.9644, 0.963 , 0.9604, 0.956 ,\n",
       "            0.955 , 0.954 , 0.953 , 0.9507, 0.9497, 0.946 , 0.9453, 0.945 ,\n",
       "            0.944 , 0.9434, 0.9424, 0.9414, 0.9395, 0.9375, 0.935 , 0.9346,\n",
       "            0.9336, 0.933 , 0.9307, 0.9277, 0.9272, 0.9263, 0.9253, 0.925 ,\n",
       "            0.923 , 0.9175, 0.914 , 0.909 , 0.9077, 0.907 , 0.9067, 0.9062,\n",
       "            0.906 , 0.9043, 0.904 , 0.9014, 0.899 , 0.893 , 0.8926, 0.8916,\n",
       "            0.8867, 0.8853, 0.8833, 0.883 , 0.8823, 0.882 , 0.881 , 0.88  ,\n",
       "            0.879 , 0.8765, 0.8726, 0.8716, 0.871 , 0.8706, 0.869 , 0.868 ,\n",
       "            0.8677, 0.8633, 0.863 , 0.862 , 0.8594, 0.858 , 0.8574, 0.8545,\n",
       "            0.8525, 0.852 , 0.8516, 0.851 , 0.848 , 0.8477, 0.847 , 0.8467,\n",
       "            0.8457, 0.845 , 0.8438, 0.8433, 0.843 , 0.842 , 0.841 , 0.839 ,\n",
       "            0.8384, 0.8374, 0.837 , 0.8354, 0.8345, 0.834 , 0.8335, 0.832 ,\n",
       "            0.8315, 0.8296, 0.829 , 0.8257, 0.825 , 0.824 , 0.823 , 0.8223,\n",
       "            0.8213, 0.821 , 0.8184, 0.818 , 0.8174, 0.814 , 0.8125, 0.812 ,\n",
       "            0.8105, 0.808 , 0.806 , 0.8047, 0.804 , 0.8   , 0.7983, 0.798 ,\n",
       "            0.796 , 0.794 , 0.792 , 0.7905, 0.79  , 0.787 , 0.7856, 0.7847,\n",
       "            0.7837, 0.7827, 0.7812, 0.7793, 0.779 , 0.7783, 0.776 , 0.77  ,\n",
       "            0.7695, 0.768 , 0.765 , 0.7646, 0.7637, 0.7627, 0.7607, 0.76  ,\n",
       "            0.756 , 0.7544, 0.7534, 0.7524, 0.7515, 0.751 , 0.7275, 0.725 ,\n",
       "            0.7163, 0.716 , 0.714 , 0.7114, 0.7065, 0.7056, 0.689 , 0.6763,\n",
       "            0.664 , 0.6616, 0.6514, 0.6494, 0.636 , 0.617 , 0.609 , 0.6025,\n",
       "            0.5884, 0.581 , 0.577 , 0.564 , 0.5483, 0.524 , 0.5234, 0.5225,\n",
       "            0.5195, 0.518 , 0.5015, 0.499 , 0.4966, 0.4912, 0.4849, 0.4646,\n",
       "            0.4617, 0.4607, 0.4546, 0.3806, 0.3755, 0.3577, 0.3557, 0.3445,\n",
       "            0.344 , 0.3418, 0.3396, 0.3381, 0.3296, 0.3289, 0.3162, 0.3145,\n",
       "            0.312 , 0.3115, 0.3066, 0.2773, 0.268 , 0.2656, 0.218 , 0.1896,\n",
       "            0.1747, 0.1726, 0.1631, 0.1534], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7457627, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.19491525, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.24242425, 0.25757575, 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.3030303 , 0.31060606, 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.34848484, 0.3560606 , 0.36363637, 0.37878788,\n",
       "            0.38636363, 0.40151516, 0.4090909 , 0.41666666, 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.5833333 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.77272725, 0.780303  , 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.84090906, 0.8636364 , 0.8636364 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.987 , 0.9785, 0.978 , 0.977 , 0.9766, 0.976 , 0.975 ,\n",
       "            0.9746, 0.9736, 0.973 , 0.9707, 0.969 , 0.9683, 0.966 , 0.962 ,\n",
       "            0.961 , 0.9604, 0.96  , 0.959 , 0.957 , 0.9556, 0.9526, 0.9517,\n",
       "            0.951 , 0.9507, 0.95  , 0.949 , 0.948 , 0.9463, 0.945 , 0.9424,\n",
       "            0.941 , 0.938 , 0.936 , 0.9355, 0.9336, 0.9326, 0.931 , 0.9263,\n",
       "            0.9243, 0.9194, 0.918 , 0.9155, 0.915 , 0.914 , 0.9136, 0.9106,\n",
       "            0.9097, 0.9043, 0.9033, 0.9014, 0.898 , 0.8965, 0.8955, 0.894 ,\n",
       "            0.893 , 0.8926, 0.892 , 0.8916, 0.891 , 0.8877, 0.8843, 0.8833,\n",
       "            0.883 , 0.8823, 0.882 , 0.8794, 0.879 , 0.877 , 0.875 , 0.8735,\n",
       "            0.8726, 0.871 , 0.8706, 0.87  , 0.8696, 0.869 , 0.8677, 0.866 ,\n",
       "            0.8657, 0.8647, 0.864 , 0.862 , 0.861 , 0.86  , 0.8584, 0.857 ,\n",
       "            0.8564, 0.855 , 0.8545, 0.854 , 0.8525, 0.851 , 0.8506, 0.85  ,\n",
       "            0.8486, 0.8477, 0.847 , 0.8467, 0.8457, 0.844 , 0.8438, 0.843 ,\n",
       "            0.84  , 0.8394, 0.8384, 0.838 , 0.8364, 0.836 , 0.8354, 0.8345,\n",
       "            0.8325, 0.832 , 0.8296, 0.828 , 0.8276, 0.8267, 0.826 , 0.8247,\n",
       "            0.822 , 0.8203, 0.8193, 0.8184, 0.813 , 0.8125, 0.811 , 0.808 ,\n",
       "            0.806 , 0.805 , 0.804 , 0.803 , 0.802 , 0.8003, 0.7983, 0.798 ,\n",
       "            0.7964, 0.795 , 0.7935, 0.7925, 0.79  , 0.7837, 0.783 , 0.7827,\n",
       "            0.779 , 0.7783, 0.7773, 0.7744, 0.774 , 0.771 , 0.767 , 0.7666,\n",
       "            0.766 , 0.765 , 0.7407, 0.7383, 0.7295, 0.729 , 0.7246, 0.721 ,\n",
       "            0.7183, 0.704 , 0.69  , 0.6777, 0.6763, 0.665 , 0.663 , 0.65  ,\n",
       "            0.631 , 0.623 , 0.616 , 0.602 , 0.5947, 0.591 , 0.579 , 0.564 ,\n",
       "            0.5376, 0.536 , 0.533 , 0.5317, 0.515 , 0.5127, 0.5103, 0.5044,\n",
       "            0.4983, 0.4775, 0.475 , 0.4736, 0.4673, 0.3918, 0.3872, 0.369 ,\n",
       "            0.3672, 0.3552, 0.3525, 0.35  , 0.3489, 0.3403, 0.3394, 0.3267,\n",
       "            0.3245, 0.3218, 0.3213, 0.3164, 0.2861, 0.2795, 0.2742, 0.2256,\n",
       "            0.1965, 0.1813, 0.1794, 0.1699, 0.1598], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7542373, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.2881356 , 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.34848484, 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.38636363, 0.40151516, 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.68939394, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.8333333 , 0.84090906,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9893, 0.982 , 0.9814, 0.9805, 0.98  , 0.9795, 0.979 ,\n",
       "            0.978 , 0.9775, 0.9766, 0.975 , 0.9736, 0.9727, 0.97  , 0.967 ,\n",
       "            0.966 , 0.965 , 0.9644, 0.9624, 0.961 , 0.958 , 0.9575, 0.957 ,\n",
       "            0.9565, 0.956 , 0.955 , 0.954 , 0.952 , 0.951 , 0.949 , 0.9487,\n",
       "            0.9478, 0.9473, 0.945 , 0.9443, 0.943 , 0.9424, 0.941 , 0.94  ,\n",
       "            0.938 , 0.934 , 0.9336, 0.929 , 0.9277, 0.9272, 0.924 , 0.9233,\n",
       "            0.922 , 0.9194, 0.914 , 0.9136, 0.91  , 0.908 , 0.907 , 0.9062,\n",
       "            0.9053, 0.9033, 0.903 , 0.9023, 0.902 , 0.8984, 0.895 , 0.8945,\n",
       "            0.894 , 0.8936, 0.8926, 0.89  , 0.889 , 0.886 , 0.885 , 0.8843,\n",
       "            0.884 , 0.8833, 0.882 , 0.8813, 0.881 , 0.88  , 0.8794, 0.879 ,\n",
       "            0.878 , 0.8774, 0.8765, 0.875 , 0.8745, 0.874 , 0.8735, 0.873 ,\n",
       "            0.871 , 0.8696, 0.869 , 0.8667, 0.8657, 0.865 , 0.864 , 0.8633,\n",
       "            0.862 , 0.8613, 0.861 , 0.86  , 0.859 , 0.8584, 0.857 , 0.8564,\n",
       "            0.856 , 0.8525, 0.851 , 0.85  , 0.8496, 0.8486, 0.8477, 0.847 ,\n",
       "            0.8467, 0.8457, 0.845 , 0.8413, 0.841 , 0.84  , 0.8394, 0.839 ,\n",
       "            0.8384, 0.837 , 0.835 , 0.834 , 0.833 , 0.832 , 0.83  , 0.827 ,\n",
       "            0.826 , 0.825 , 0.822 , 0.82  , 0.8193, 0.818 , 0.8154, 0.815 ,\n",
       "            0.8125, 0.811 , 0.8105, 0.81  , 0.8086, 0.8076, 0.8057, 0.8047,\n",
       "            0.8037, 0.7974, 0.797 , 0.7964, 0.7925, 0.792 , 0.791 , 0.788 ,\n",
       "            0.7876, 0.7856, 0.781 , 0.78  , 0.7793, 0.779 , 0.7534, 0.7515,\n",
       "            0.743 , 0.742 , 0.7373, 0.7344, 0.731 , 0.7188, 0.7026, 0.6914,\n",
       "            0.6904, 0.6777, 0.676 , 0.663 , 0.644 , 0.6357, 0.6294, 0.6147,\n",
       "            0.608 , 0.6035, 0.593 , 0.579 , 0.5503, 0.549 , 0.546 , 0.5444,\n",
       "            0.528 , 0.525 , 0.5225, 0.5166, 0.5103, 0.4895, 0.4873, 0.4854,\n",
       "            0.4788, 0.402 , 0.3977, 0.3787, 0.3772, 0.3655, 0.3647, 0.362 ,\n",
       "            0.3594, 0.3584, 0.3499, 0.3489, 0.336 , 0.333 , 0.3306, 0.3298,\n",
       "            0.3247, 0.2937, 0.2893, 0.2812, 0.2319, 0.2023, 0.1866, 0.185 ,\n",
       "            0.1757, 0.1647], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9916667, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.11666667, 0.125     , 0.125     , 0.13333334, 0.15      ,\n",
       "            0.15      , 0.15      , 0.16666667, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.24166666, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.36666667, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.51666665, 0.53333336, 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.575     , 0.5833333 ,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.64166665, 0.64166665, 0.64166665, 0.65833336,\n",
       "            0.6666667 , 0.69166666, 0.7       , 0.71666664, 0.725     ,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.8333333 ,\n",
       "            0.84166664, 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.95      , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13076924, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.15384616, 0.16153847, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.18461539, 0.1923077 , 0.1923077 ,\n",
       "            0.1923077 , 0.20769231, 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23846154, 0.23846154, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.31538463, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.3923077 , 0.4       , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.73846155, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.765 , 0.76  , 0.7383, 0.7363, 0.735 , 0.7324, 0.7314,\n",
       "            0.7285, 0.7275, 0.726 , 0.725 , 0.7246, 0.721 , 0.72  , 0.7183,\n",
       "            0.717 , 0.716 , 0.714 , 0.713 , 0.7104, 0.709 , 0.7075, 0.707 ,\n",
       "            0.706 , 0.7056, 0.704 , 0.7036, 0.7026, 0.702 , 0.7007, 0.6997,\n",
       "            0.699 , 0.6987, 0.6963, 0.6943, 0.6934, 0.6924, 0.6904, 0.6895,\n",
       "            0.689 , 0.6885, 0.688 , 0.6875, 0.6865, 0.686 , 0.685 , 0.6846,\n",
       "            0.684 , 0.6836, 0.6826, 0.6816, 0.681 , 0.6807, 0.68  , 0.679 ,\n",
       "            0.6753, 0.675 , 0.674 , 0.6733, 0.67  , 0.6685, 0.667 , 0.6665,\n",
       "            0.6655, 0.665 , 0.663 , 0.6626, 0.662 , 0.661 , 0.6597, 0.6587,\n",
       "            0.658 , 0.657 , 0.656 , 0.6543, 0.654 , 0.6514, 0.649 , 0.6475,\n",
       "            0.647 , 0.6455, 0.6445, 0.644 , 0.6436, 0.643 , 0.642 , 0.6416,\n",
       "            0.6396, 0.639 , 0.6387, 0.6343, 0.633 , 0.6323, 0.6313, 0.629 ,\n",
       "            0.6265, 0.626 , 0.6177, 0.6133, 0.6123, 0.6113, 0.6104, 0.61  ,\n",
       "            0.605 , 0.604 , 0.6035, 0.603 , 0.601 , 0.5996, 0.598 , 0.597 ,\n",
       "            0.596 , 0.5947, 0.5923, 0.5884, 0.5864, 0.586 , 0.585 , 0.5845,\n",
       "            0.582 , 0.58  , 0.579 , 0.5776, 0.576 , 0.5747, 0.5737, 0.573 ,\n",
       "            0.5728, 0.5723, 0.5713, 0.571 , 0.5693, 0.569 , 0.566 , 0.5654,\n",
       "            0.5645, 0.564 , 0.562 , 0.5615, 0.561 , 0.5605, 0.56  , 0.5576,\n",
       "            0.557 , 0.5566, 0.556 , 0.555 , 0.554 , 0.5537, 0.553 , 0.5522,\n",
       "            0.552 , 0.5513, 0.551 , 0.5503, 0.55  , 0.5493, 0.5483, 0.548 ,\n",
       "            0.547 , 0.5464, 0.546 , 0.544 , 0.543 , 0.5425, 0.542 , 0.5415,\n",
       "            0.541 , 0.54  , 0.5396, 0.538 , 0.5376, 0.537 , 0.536 , 0.5356,\n",
       "            0.5347, 0.5317, 0.53  , 0.529 , 0.5264, 0.5205, 0.518 , 0.515 ,\n",
       "            0.514 , 0.5117, 0.5093, 0.5024, 0.5015, 0.501 , 0.4927, 0.492 ,\n",
       "            0.4773], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9916667, dtype=float32),\n",
       "    'tpr': array(0.9230769, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.2       ,\n",
       "            0.2       , 0.20833333, 0.225     , 0.23333333, 0.23333333,\n",
       "            0.24166666, 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.29166666, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.65      , 0.6666667 , 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.7416667 , 0.75      , 0.7583333 , 0.775     ,\n",
       "            0.78333336, 0.8       , 0.8       , 0.8333333 , 0.84166664,\n",
       "            0.8666667 , 0.8833333 , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06923077, 0.06923077,\n",
       "            0.07692308, 0.09230769, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13076924, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.16923077, 0.17692308, 0.17692308, 0.17692308, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.26923078,\n",
       "            0.26923078, 0.26923078, 0.2769231 , 0.2846154 , 0.2846154 ,\n",
       "            0.3       , 0.31538463, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.37692308, 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.43846154, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.5       , 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7       , 0.7076923 ,\n",
       "            0.7076923 , 0.7076923 , 0.7076923 , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.73846155, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.76153845, 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8153846 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7393, 0.7344, 0.7124, 0.71  , 0.709 , 0.7085, 0.705 ,\n",
       "            0.7046, 0.703 , 0.701 , 0.7   , 0.698 , 0.6963, 0.6953, 0.6934,\n",
       "            0.691 , 0.688 , 0.6875, 0.687 , 0.6865, 0.685 , 0.684 , 0.683 ,\n",
       "            0.682 , 0.6816, 0.681 , 0.6807, 0.68  , 0.6797, 0.679 , 0.678 ,\n",
       "            0.676 , 0.6753, 0.675 , 0.6733, 0.672 , 0.6714, 0.671 , 0.67  ,\n",
       "            0.6694, 0.669 , 0.668 , 0.666 , 0.665 , 0.6646, 0.663 , 0.6626,\n",
       "            0.662 , 0.661 , 0.6606, 0.6562, 0.6553, 0.6543, 0.653 , 0.6523,\n",
       "            0.652 , 0.6514, 0.65  , 0.6484, 0.646 , 0.644 , 0.6436, 0.6416,\n",
       "            0.6406, 0.6396, 0.639 , 0.638 , 0.6377, 0.6353, 0.6343, 0.633 ,\n",
       "            0.6313, 0.6304, 0.6294, 0.628 , 0.627 , 0.6265, 0.625 , 0.6245,\n",
       "            0.623 , 0.6216, 0.621 , 0.6206, 0.62  , 0.6196, 0.617 , 0.6167,\n",
       "            0.6157, 0.6147, 0.614 , 0.6094, 0.6055, 0.6045, 0.601 , 0.5986,\n",
       "            0.592 , 0.587 , 0.5864, 0.5854, 0.5845, 0.5825, 0.5806, 0.5796,\n",
       "            0.579 , 0.5786, 0.575 , 0.5747, 0.5737, 0.572 , 0.57  , 0.5693,\n",
       "            0.569 , 0.568 , 0.5654, 0.565 , 0.564 , 0.563 , 0.5625, 0.562 ,\n",
       "            0.5615, 0.561 , 0.5596, 0.558 , 0.557 , 0.5566, 0.556 , 0.555 ,\n",
       "            0.554 , 0.5537, 0.553 , 0.5522, 0.5513, 0.551 , 0.55  , 0.549 ,\n",
       "            0.547 , 0.5464, 0.546 , 0.5454, 0.545 , 0.5444, 0.544 , 0.5435,\n",
       "            0.543 , 0.5425, 0.542 , 0.5415, 0.541 , 0.5405, 0.539 , 0.5386,\n",
       "            0.538 , 0.5366, 0.5356, 0.534 , 0.5317, 0.5293, 0.529 , 0.5283,\n",
       "            0.528 , 0.527 , 0.526 , 0.524 , 0.5234, 0.5225, 0.5215, 0.517 ,\n",
       "            0.5166, 0.515 , 0.5146, 0.514 , 0.5117, 0.5083, 0.508 , 0.506 ,\n",
       "            0.505 , 0.499 , 0.4966, 0.488 , 0.487 , 0.4854, 0.477 , 0.4734,\n",
       "            0.47  , 0.465 , 0.46  , 0.4575], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.96666664, dtype=float32),\n",
       "    'tpr': array(0.8230769, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.15833333,\n",
       "            0.16666667, 0.175     , 0.175     , 0.175     , 0.175     ,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.2       , 0.225     , 0.23333333, 0.25      , 0.25      ,\n",
       "            0.25833333, 0.275     , 0.275     , 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35      , 0.36666667,\n",
       "            0.36666667, 0.375     , 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.425     ,\n",
       "            0.43333334, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.525     , 0.525     , 0.53333336, 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.56666666, 0.575     , 0.59166664,\n",
       "            0.60833335, 0.625     , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.64166665, 0.65833336, 0.6666667 ,\n",
       "            0.68333334, 0.68333334, 0.7       , 0.7083333 , 0.73333335,\n",
       "            0.7416667 , 0.7416667 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.8       , 0.80833334, 0.825     , 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.02307692, 0.03846154, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.07692308, 0.08461539, 0.1       , 0.10769231,\n",
       "            0.10769231, 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.15384616, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.16923077, 0.16923077, 0.17692308,\n",
       "            0.17692308, 0.17692308, 0.18461539, 0.18461539, 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2846154 ,\n",
       "            0.2846154 , 0.2846154 , 0.2923077 , 0.30769232, 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.4846154 , 0.4923077 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.6076923 ,\n",
       "            0.6076923 , 0.61538464, 0.61538464, 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7076923 , 0.7076923 ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.7153846 , 0.7153846 ,\n",
       "            0.72307694, 0.72307694, 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.76153845, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.77692306, 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.712 , 0.708 , 0.686 , 0.6836, 0.682 , 0.681 , 0.6772,\n",
       "            0.676 , 0.6743, 0.674 , 0.672 , 0.6714, 0.67  , 0.6675, 0.665 ,\n",
       "            0.6646, 0.664 , 0.662 , 0.661 , 0.66  , 0.659 , 0.6587, 0.658 ,\n",
       "            0.6577, 0.657 , 0.6567, 0.6562, 0.656 , 0.655 , 0.6543, 0.654 ,\n",
       "            0.6514, 0.651 , 0.6504, 0.65  , 0.6484, 0.648 , 0.6475, 0.647 ,\n",
       "            0.646 , 0.6455, 0.645 , 0.6445, 0.6426, 0.6416, 0.641 , 0.6406,\n",
       "            0.6396, 0.6367, 0.636 , 0.635 , 0.6343, 0.6323, 0.631 , 0.6294,\n",
       "            0.6284, 0.626 , 0.6255, 0.624 , 0.6177, 0.6157, 0.615 , 0.6143,\n",
       "            0.613 , 0.6123, 0.612 , 0.611 , 0.6104, 0.61  , 0.609 , 0.6084,\n",
       "            0.6074, 0.607 , 0.6064, 0.606 , 0.605 , 0.6045, 0.602 , 0.6006,\n",
       "            0.6   , 0.5996, 0.598 , 0.597 , 0.5967, 0.5947, 0.5923, 0.584 ,\n",
       "            0.5835, 0.5825, 0.5786, 0.575 , 0.5703, 0.567 , 0.5654, 0.564 ,\n",
       "            0.5615, 0.561 , 0.558 , 0.557 , 0.5557, 0.553 , 0.5522, 0.552 ,\n",
       "            0.551 , 0.5503, 0.55  , 0.549 , 0.548 , 0.546 , 0.5454, 0.545 ,\n",
       "            0.5444, 0.543 , 0.5425, 0.542 , 0.5415, 0.541 , 0.5405, 0.54  ,\n",
       "            0.5396, 0.5386, 0.5376, 0.5366, 0.536 , 0.5347, 0.534 , 0.5337,\n",
       "            0.5327, 0.532 , 0.5317, 0.531 , 0.53  , 0.529 , 0.5273, 0.5264,\n",
       "            0.526 , 0.5254, 0.525 , 0.5244, 0.5234, 0.522 , 0.5215, 0.521 ,\n",
       "            0.5205, 0.52  , 0.5195, 0.5156, 0.515 , 0.5146, 0.514 , 0.5137,\n",
       "            0.513 , 0.511 , 0.5107, 0.5103, 0.509 , 0.5083, 0.5073, 0.507 ,\n",
       "            0.5063, 0.503 , 0.5   , 0.498 , 0.4978, 0.4976, 0.4966, 0.496 ,\n",
       "            0.4944, 0.4922, 0.49  , 0.4868, 0.4866, 0.4849, 0.4822, 0.4812,\n",
       "            0.4795, 0.4775, 0.4731, 0.4644, 0.4617, 0.4585, 0.4521, 0.4443,\n",
       "            0.4385, 0.4373, 0.437 , 0.4275], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.925, dtype=float32),\n",
       "    'tpr': array(0.72307694, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.23333333,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.35      , 0.35      , 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.48333332, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.5416667 , 0.55      , 0.56666666,\n",
       "            0.575     , 0.59166664, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7083333 , 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.75      , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.925     , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.05384615, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.1       , 0.10769231,\n",
       "            0.11538462, 0.11538462, 0.12307692, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.16153847, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.18461539, 0.18461539, 0.1923077 , 0.20769231, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.26923078, 0.26923078,\n",
       "            0.2846154 , 0.3       , 0.3       , 0.30769232, 0.30769232,\n",
       "            0.30769232, 0.31538463, 0.31538463, 0.31538463, 0.31538463,\n",
       "            0.33076924, 0.34615386, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.37692308, 0.3923077 , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.42307693, 0.42307693, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.5307692 , 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.6076923 , 0.6076923 , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.64615387, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6923077 , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7076923 , 0.7076923 ,\n",
       "            0.7076923 , 0.72307694, 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.75384617, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6846, 0.68  , 0.659 , 0.658 , 0.6562, 0.6543, 0.654 ,\n",
       "            0.653 , 0.6514, 0.6504, 0.65  , 0.649 , 0.6475, 0.647 , 0.6465,\n",
       "            0.646 , 0.6445, 0.642 , 0.6406, 0.64  , 0.6396, 0.6387, 0.637 ,\n",
       "            0.6367, 0.636 , 0.6357, 0.6353, 0.635 , 0.6333, 0.633 , 0.6323,\n",
       "            0.632 , 0.63  , 0.6294, 0.6284, 0.6274, 0.6265, 0.626 , 0.625 ,\n",
       "            0.6245, 0.6235, 0.622 , 0.621 , 0.6206, 0.62  , 0.619 , 0.617 ,\n",
       "            0.6157, 0.6147, 0.6133, 0.612 , 0.6113, 0.6104, 0.6094, 0.607 ,\n",
       "            0.6064, 0.606 , 0.6055, 0.605 , 0.604 , 0.5957, 0.594 , 0.5923,\n",
       "            0.592 , 0.5903, 0.5884, 0.588 , 0.587 , 0.5864, 0.5854, 0.5845,\n",
       "            0.5835, 0.583 , 0.582 , 0.5815, 0.581 , 0.5806, 0.58  , 0.578 ,\n",
       "            0.5767, 0.576 , 0.575 , 0.574 , 0.5737, 0.5728, 0.57  , 0.567 ,\n",
       "            0.5625, 0.5605, 0.5576, 0.553 , 0.549 , 0.548 , 0.5454, 0.544 ,\n",
       "            0.5435, 0.5415, 0.5405, 0.5386, 0.5376, 0.5366, 0.5356, 0.5337,\n",
       "            0.532 , 0.5317, 0.5312, 0.5303, 0.53  , 0.528 , 0.527 , 0.5264,\n",
       "            0.5254, 0.525 , 0.524 , 0.5234, 0.5225, 0.522 , 0.521 , 0.5205,\n",
       "            0.5195, 0.519 , 0.5186, 0.517 , 0.516 , 0.5156, 0.515 , 0.5146,\n",
       "            0.514 , 0.5137, 0.513 , 0.5107, 0.5103, 0.5093, 0.509 , 0.508 ,\n",
       "            0.5073, 0.503 , 0.5024, 0.502 , 0.5015, 0.501 , 0.5005, 0.5   ,\n",
       "            0.4995, 0.4983, 0.498 , 0.4973, 0.4966, 0.495 , 0.494 , 0.4934,\n",
       "            0.4907, 0.4902, 0.49  , 0.4873, 0.4856, 0.4834, 0.4827, 0.4814,\n",
       "            0.4812, 0.481 , 0.4773, 0.477 , 0.4692, 0.4678, 0.4673, 0.4653,\n",
       "            0.465 , 0.4648, 0.4646, 0.4602, 0.4587, 0.4583, 0.4568, 0.456 ,\n",
       "            0.451 , 0.442 , 0.4417, 0.4353, 0.432 , 0.4272, 0.4172, 0.4155,\n",
       "            0.4094, 0.4075, 0.3958], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.825, dtype=float32),\n",
       "    'tpr': array(0.6, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.04166667, 0.05      ,\n",
       "            0.05833333, 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.125     , 0.125     ,\n",
       "            0.15      , 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.175     , 0.175     , 0.175     , 0.18333334,\n",
       "            0.19166666, 0.20833333, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.25833333, 0.26666668,\n",
       "            0.275     , 0.275     , 0.28333333, 0.28333333, 0.28333333,\n",
       "            0.29166666, 0.29166666, 0.30833334, 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.425     ,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.56666666, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.7       , 0.7083333 , 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.825     , 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.89166665, 0.89166665, 0.9166667 , 0.925     , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.95      , 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06153846, 0.07692308,\n",
       "            0.08461539, 0.1       , 0.10769231, 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.14615385,\n",
       "            0.14615385, 0.16923077, 0.16923077, 0.16923077, 0.18461539,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.21538462, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.24615385, 0.26153848, 0.26153848, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2769231 , 0.2846154 , 0.2923077 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.30769232, 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.33846155, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.3923077 , 0.3923077 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.6       , 0.6       , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.61538464, 0.61538464,\n",
       "            0.61538464, 0.61538464, 0.61538464, 0.61538464, 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7076923 , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.656 , 0.6514, 0.6333, 0.631 , 0.63  , 0.628 , 0.6255,\n",
       "            0.6245, 0.6235, 0.6226, 0.6206, 0.6196, 0.619 , 0.6187, 0.618 ,\n",
       "            0.617 , 0.616 , 0.6157, 0.614 , 0.613 , 0.612 , 0.6104, 0.6094,\n",
       "            0.6084, 0.6074, 0.607 , 0.6064, 0.606 , 0.6055, 0.605 , 0.6035,\n",
       "            0.6025, 0.602 , 0.6016, 0.6006, 0.6   , 0.5996, 0.599 , 0.5986,\n",
       "            0.5977, 0.5967, 0.5957, 0.594 , 0.5938, 0.5933, 0.5923, 0.5913,\n",
       "            0.59  , 0.588 , 0.5874, 0.587 , 0.586 , 0.585 , 0.584 , 0.581 ,\n",
       "            0.5786, 0.575 , 0.5737, 0.573 , 0.5693, 0.5684, 0.568 , 0.5674,\n",
       "            0.565 , 0.5645, 0.563 , 0.5615, 0.561 , 0.5605, 0.56  , 0.5596,\n",
       "            0.5576, 0.556 , 0.554 , 0.5513, 0.55  , 0.5493, 0.547 , 0.5444,\n",
       "            0.541 , 0.5405, 0.5376, 0.5366, 0.5347, 0.534 , 0.5312, 0.531 ,\n",
       "            0.53  , 0.5273, 0.527 , 0.5254, 0.5244, 0.5234, 0.523 , 0.5225,\n",
       "            0.5215, 0.52  , 0.5195, 0.5186, 0.517 , 0.516 , 0.5156, 0.515 ,\n",
       "            0.5137, 0.513 , 0.5127, 0.512 , 0.5117, 0.511 , 0.51  , 0.5093,\n",
       "            0.509 , 0.508 , 0.5073, 0.507 , 0.506 , 0.505 , 0.504 , 0.503 ,\n",
       "            0.502 , 0.501 , 0.4993, 0.4983, 0.4978, 0.497 , 0.4968, 0.496 ,\n",
       "            0.4956, 0.4954, 0.494 , 0.4937, 0.492 , 0.4912, 0.4907, 0.4902,\n",
       "            0.4888, 0.4885, 0.4878, 0.4868, 0.4866, 0.4844, 0.484 , 0.483 ,\n",
       "            0.482 , 0.4812, 0.481 , 0.4807, 0.4788, 0.4744, 0.474 , 0.4739,\n",
       "            0.4734, 0.472 , 0.471 , 0.4705, 0.466 , 0.4653, 0.465 , 0.4648,\n",
       "            0.4644, 0.4634, 0.46  , 0.4517, 0.4502, 0.4492, 0.447 , 0.4436,\n",
       "            0.4424, 0.441 , 0.4407, 0.4397, 0.4395, 0.4382, 0.436 , 0.4343,\n",
       "            0.433 , 0.4321, 0.4272, 0.4268, 0.4204, 0.419 , 0.4104, 0.4092,\n",
       "            0.4053, 0.4026, 0.3975, 0.387 , 0.382 , 0.3767, 0.3643],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7, dtype=float32),\n",
       "    'tpr': array(0.52307695, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.05      , 0.05833333, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.23333333, 0.23333333,\n",
       "            0.25      , 0.25      , 0.25833333, 0.26666668, 0.26666668,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.525     ,\n",
       "            0.525     , 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.59166664, 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.65833336, 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.8       , 0.80833334, 0.81666666,\n",
       "            0.81666666, 0.825     , 0.825     , 0.825     , 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8833333 , 0.89166665, 0.89166665, 0.90833336,\n",
       "            0.925     , 0.925     , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.08461539, 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13846155, 0.13846155, 0.16153847, 0.16153847,\n",
       "            0.16153847, 0.17692308, 0.18461539, 0.20769231, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.22307692, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.25384617, 0.26153848,\n",
       "            0.2769231 , 0.2769231 , 0.2769231 , 0.2769231 , 0.2846154 ,\n",
       "            0.2846154 , 0.2923077 , 0.2923077 , 0.2923077 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.3       , 0.31538463, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43076923,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46153846, 0.46153846, 0.46923077, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.47692308, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.4923077 , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.5307692 , 0.5307692 , 0.5307692 , 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.61538464, 0.61538464,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.63846153, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6265, 0.621 , 0.6074, 0.6055, 0.6025, 0.6006, 0.5996,\n",
       "            0.598 , 0.597 , 0.5967, 0.596 , 0.5947, 0.594 , 0.5933, 0.593 ,\n",
       "            0.5923, 0.591 , 0.59  , 0.5894, 0.589 , 0.588 , 0.586 , 0.5854,\n",
       "            0.584 , 0.5835, 0.582 , 0.5815, 0.5806, 0.58  , 0.5796, 0.579 ,\n",
       "            0.578 , 0.577 , 0.5767, 0.576 , 0.5757, 0.575 , 0.574 , 0.5737,\n",
       "            0.573 , 0.5723, 0.5713, 0.571 , 0.5684, 0.5674, 0.567 , 0.5664,\n",
       "            0.565 , 0.5645, 0.564 , 0.5605, 0.56  , 0.5576, 0.5566, 0.5547,\n",
       "            0.553 , 0.5513, 0.5503, 0.5483, 0.546 , 0.544 , 0.5425, 0.5415,\n",
       "            0.541 , 0.5405, 0.539 , 0.5386, 0.538 , 0.5366, 0.5347, 0.534 ,\n",
       "            0.5337, 0.533 , 0.5312, 0.5303, 0.53  , 0.5283, 0.5273, 0.524 ,\n",
       "            0.5225, 0.5215, 0.521 , 0.52  , 0.5195, 0.519 , 0.5186, 0.5166,\n",
       "            0.5156, 0.5146, 0.514 , 0.512 , 0.511 , 0.5103, 0.5093, 0.509 ,\n",
       "            0.5073, 0.507 , 0.5063, 0.5054, 0.505 , 0.5044, 0.5034, 0.5024,\n",
       "            0.502 , 0.5015, 0.501 , 0.5   , 0.4985, 0.4983, 0.498 , 0.4976,\n",
       "            0.497 , 0.4963, 0.4958, 0.4956, 0.493 , 0.4922, 0.4912, 0.4902,\n",
       "            0.4883, 0.488 , 0.4878, 0.4875, 0.487 , 0.4866, 0.4844, 0.4841,\n",
       "            0.484 , 0.4834, 0.4832, 0.4805, 0.4785, 0.4783, 0.4753, 0.475 ,\n",
       "            0.4734, 0.4712, 0.4705, 0.4695, 0.4678, 0.4675, 0.4673, 0.4666,\n",
       "            0.4631, 0.4607, 0.4602, 0.46  , 0.4587, 0.4585, 0.4583, 0.4546,\n",
       "            0.451 , 0.4485, 0.4478, 0.447 , 0.4456, 0.4448, 0.4412, 0.4392,\n",
       "            0.4387, 0.4373, 0.4348, 0.432 , 0.4302, 0.4258, 0.422 , 0.4211,\n",
       "            0.421 , 0.42  , 0.4177, 0.4172, 0.4143, 0.4126, 0.4106, 0.4087,\n",
       "            0.4077, 0.407 , 0.4016, 0.3987, 0.397 , 0.3965, 0.3901, 0.3835,\n",
       "            0.3794, 0.3792, 0.3782, 0.3774, 0.359 , 0.3552, 0.3467, 0.334 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.43076923, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.06666667, 0.075     , 0.09166667, 0.1       ,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.425     ,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.575     , 0.59166664, 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65      , 0.6666667 , 0.675     , 0.675     , 0.68333334,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.80833334, 0.81666666, 0.81666666, 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.8666667 , 0.875     , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.06923077, 0.07692308, 0.08461539,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.12307692, 0.12307692,\n",
       "            0.13076924, 0.13076924, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.17692308,\n",
       "            0.1923077 , 0.2       , 0.21538462, 0.22307692, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.2846154 , 0.2846154 ,\n",
       "            0.2846154 , 0.2923077 , 0.2923077 , 0.2923077 , 0.3       ,\n",
       "            0.3       , 0.31538463, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3846154 , 0.3923077 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.44615385, 0.45384616, 0.45384616,\n",
       "            0.45384616, 0.45384616, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.46153846, 0.46153846, 0.46153846, 0.46153846, 0.46153846,\n",
       "            0.46923077, 0.46923077, 0.47692308, 0.4846154 , 0.4846154 ,\n",
       "            0.4923077 , 0.4923077 , 0.4923077 , 0.4923077 , 0.4923077 ,\n",
       "            0.4923077 , 0.4923077 , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.50769234, 0.50769234, 0.5153846 , 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.56153846, 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.59  , 0.584 , 0.575 , 0.5737, 0.572 , 0.5684, 0.568 ,\n",
       "            0.567 , 0.566 , 0.5654, 0.5645, 0.5635, 0.563 , 0.5625, 0.562 ,\n",
       "            0.5615, 0.561 , 0.5605, 0.5596, 0.559 , 0.5586, 0.558 , 0.5576,\n",
       "            0.557 , 0.556 , 0.5557, 0.555 , 0.5547, 0.5537, 0.5527, 0.5522,\n",
       "            0.552 , 0.5513, 0.5503, 0.55  , 0.5493, 0.549 , 0.5483, 0.5474,\n",
       "            0.547 , 0.5454, 0.5444, 0.544 , 0.543 , 0.542 , 0.5405, 0.54  ,\n",
       "            0.5396, 0.539 , 0.5376, 0.537 , 0.5366, 0.536 , 0.5347, 0.5312,\n",
       "            0.53  , 0.5283, 0.527 , 0.525 , 0.5244, 0.524 , 0.5234, 0.5225,\n",
       "            0.52  , 0.519 , 0.518 , 0.516 , 0.5156, 0.5127, 0.512 , 0.5093,\n",
       "            0.509 , 0.508 , 0.5073, 0.507 , 0.506 , 0.5054, 0.505 , 0.5044,\n",
       "            0.504 , 0.5034, 0.502 , 0.5015, 0.5005, 0.5   , 0.4993, 0.499 ,\n",
       "            0.4988, 0.4978, 0.497 , 0.4968, 0.4956, 0.4949, 0.4932, 0.493 ,\n",
       "            0.4927, 0.4924, 0.4917, 0.4915, 0.4905, 0.4897, 0.489 , 0.4888,\n",
       "            0.4885, 0.4878, 0.4866, 0.4856, 0.4854, 0.485 , 0.4846, 0.484 ,\n",
       "            0.4834, 0.483 , 0.4827, 0.4824, 0.481 , 0.4795, 0.4783, 0.478 ,\n",
       "            0.4775, 0.4766, 0.4731, 0.473 , 0.47  , 0.4692, 0.4688, 0.468 ,\n",
       "            0.4644, 0.4639, 0.4636, 0.4626, 0.4624, 0.461 , 0.46  , 0.4597,\n",
       "            0.4592, 0.4543, 0.4531, 0.4524, 0.4517, 0.4507, 0.4502, 0.446 ,\n",
       "            0.443 , 0.4429, 0.4407, 0.4397, 0.4395, 0.439 , 0.4375, 0.4368,\n",
       "            0.4353, 0.428 , 0.427 , 0.4258, 0.4248, 0.4202, 0.4194, 0.4177,\n",
       "            0.417 , 0.4163, 0.4155, 0.415 , 0.4048, 0.4026, 0.4004, 0.3997,\n",
       "            0.3987, 0.3984, 0.3975, 0.3962, 0.3958, 0.3945, 0.3892, 0.3855,\n",
       "            0.385 , 0.3833, 0.381 , 0.3806, 0.38  , 0.375 , 0.3743, 0.3706,\n",
       "            0.3665, 0.3635, 0.3562, 0.3547, 0.3542, 0.3506, 0.3496, 0.3447,\n",
       "            0.3276, 0.3252, 0.3137, 0.3005], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.375, dtype=float32),\n",
       "    'tpr': array(0.3, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.11666667, 0.14166667, 0.15      ,\n",
       "            0.175     , 0.175     , 0.18333334, 0.18333334, 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.23333333, 0.24166666, 0.24166666, 0.25      ,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.325     , 0.325     , 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.375     , 0.375     , 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.6666667 , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.73333335, 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.7583333 , 0.775     ,\n",
       "            0.7916667 , 0.80833334, 0.80833334, 0.80833334, 0.81666666,\n",
       "            0.81666666, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85      , 0.85833335, 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.925     , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.02307692, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.05384615, 0.06923077,\n",
       "            0.06923077, 0.08461539, 0.08461539, 0.08461539, 0.1       ,\n",
       "            0.11538462, 0.13076924, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.20769231, 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23076923, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.25384617, 0.26153848, 0.26153848, 0.26923078,\n",
       "            0.26923078, 0.26923078, 0.2769231 , 0.2769231 , 0.2846154 ,\n",
       "            0.2846154 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36153847, 0.36153847,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.36923078, 0.36923078, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.3846154 , 0.3923077 , 0.3923077 ,\n",
       "            0.3923077 , 0.3923077 , 0.3923077 , 0.3923077 , 0.3923077 ,\n",
       "            0.3923077 , 0.3923077 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.41538462, 0.43076923, 0.43846154, 0.43846154,\n",
       "            0.43846154, 0.43846154, 0.43846154, 0.43846154, 0.44615385,\n",
       "            0.44615385, 0.45384616, 0.45384616, 0.46153846, 0.46153846,\n",
       "            0.46153846, 0.46153846, 0.46923077, 0.47692308, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.4923077 , 0.4923077 , 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5527, 0.546 , 0.543 , 0.542 , 0.5405, 0.5386, 0.537 ,\n",
       "            0.5366, 0.5356, 0.535 , 0.5347, 0.534 , 0.533 , 0.532 , 0.5317,\n",
       "            0.5312, 0.531 , 0.5303, 0.53  , 0.5293, 0.528 , 0.5273, 0.527 ,\n",
       "            0.5264, 0.5254, 0.5244, 0.524 , 0.523 , 0.5225, 0.522 , 0.521 ,\n",
       "            0.5205, 0.5195, 0.519 , 0.5186, 0.5176, 0.5166, 0.5156, 0.515 ,\n",
       "            0.5146, 0.514 , 0.5137, 0.5127, 0.512 , 0.5117, 0.5107, 0.5103,\n",
       "            0.509 , 0.5063, 0.5034, 0.5024, 0.502 , 0.5015, 0.5   , 0.4998,\n",
       "            0.498 , 0.4968, 0.496 , 0.4956, 0.4949, 0.4946, 0.4941, 0.494 ,\n",
       "            0.4932, 0.4922, 0.4917, 0.4915, 0.4902, 0.49  , 0.4888, 0.4883,\n",
       "            0.4868, 0.4866, 0.4856, 0.4841, 0.484 , 0.4834, 0.4827, 0.4824,\n",
       "            0.4822, 0.4812, 0.4805, 0.4797, 0.4792, 0.479 , 0.4788, 0.4783,\n",
       "            0.4778, 0.4775, 0.4773, 0.4766, 0.4763, 0.4753, 0.4749, 0.474 ,\n",
       "            0.4731, 0.473 , 0.4724, 0.4707, 0.4697, 0.4695, 0.4692, 0.4688,\n",
       "            0.4683, 0.4673, 0.4666, 0.4656, 0.4653, 0.464 , 0.4639, 0.4626,\n",
       "            0.4624, 0.461 , 0.4604, 0.4602, 0.4595, 0.4592, 0.4578, 0.4543,\n",
       "            0.454 , 0.4531, 0.453 , 0.4526, 0.4521, 0.4492, 0.4487, 0.4482,\n",
       "            0.4446, 0.444 , 0.4434, 0.4421, 0.4414, 0.4392, 0.4382, 0.4373,\n",
       "            0.437 , 0.4353, 0.434 , 0.4326, 0.4277, 0.4229, 0.421 , 0.419 ,\n",
       "            0.4175, 0.415 , 0.4136, 0.4133, 0.4124, 0.4116, 0.409 , 0.4084,\n",
       "            0.4082, 0.408 , 0.4067, 0.3987, 0.396 , 0.3945, 0.394 , 0.3914,\n",
       "            0.391 , 0.3906, 0.3867, 0.386 , 0.3833, 0.382 , 0.3772, 0.3765,\n",
       "            0.3735, 0.3733, 0.368 , 0.3677, 0.3672, 0.3625, 0.3618, 0.3616,\n",
       "            0.3586, 0.3577, 0.357 , 0.3528, 0.3513, 0.3508, 0.3499, 0.346 ,\n",
       "            0.3457, 0.3428, 0.3425, 0.3354, 0.3328, 0.3325, 0.3313, 0.3262,\n",
       "            0.324 , 0.3235, 0.3213, 0.3115, 0.2976, 0.2966, 0.2822, 0.269 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.13333334, dtype=float32),\n",
       "    'tpr': array(0.13076924, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.06666667, 0.06666667,\n",
       "            0.08333334, 0.1       , 0.11666667, 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.13333334, 0.13333334, 0.15      , 0.15      ,\n",
       "            0.15      , 0.15      , 0.15      , 0.15833333, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.2       , 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.28333333,\n",
       "            0.29166666, 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.4       , 0.41666666,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.46666667, 0.475     , 0.48333332,\n",
       "            0.5       , 0.51666665, 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.71666664, 0.71666664, 0.73333335, 0.75      , 0.7583333 ,\n",
       "            0.775     , 0.775     , 0.775     , 0.775     , 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.8       , 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85833335, 0.85833335, 0.8666667 , 0.875     , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.07692308, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.13076924, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16153847, 0.16153847,\n",
       "            0.16153847, 0.16153847, 0.16153847, 0.16923077, 0.18461539,\n",
       "            0.18461539, 0.2       , 0.20769231, 0.21538462, 0.21538462,\n",
       "            0.22307692, 0.22307692, 0.23076923, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.24615385, 0.24615385, 0.25384617,\n",
       "            0.25384617, 0.25384617, 0.26153848, 0.26923078, 0.26923078,\n",
       "            0.26923078, 0.26923078, 0.2846154 , 0.2923077 , 0.2923077 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.31538463,\n",
       "            0.31538463, 0.32307693, 0.32307693, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.34615386, 0.34615386, 0.34615386,\n",
       "            0.34615386, 0.34615386, 0.34615386, 0.34615386, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.35384616, 0.35384616, 0.35384616,\n",
       "            0.35384616, 0.35384616, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.36923078, 0.36923078,\n",
       "            0.36923078, 0.36923078, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.3923077 , 0.3923077 , 0.3923077 ,\n",
       "            0.3923077 , 0.4       , 0.41538462, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.44615385, 0.44615385,\n",
       "            0.44615385, 0.45384616, 0.45384616, 0.45384616, 0.45384616,\n",
       "            0.45384616, 0.46153846, 0.46153846, 0.46153846, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.4923077 , 0.50769234, 0.50769234,\n",
       "            0.50769234, 0.50769234, 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.5153846 , 0.52307695, 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5923077 , 0.6       ,\n",
       "            0.61538464, 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8076923 , 0.8230769 , 0.83076924,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.515 , 0.51  , 0.5093, 0.5083, 0.508 , 0.507 , 0.5063,\n",
       "            0.506 , 0.5054, 0.5044, 0.5034, 0.503 , 0.5024, 0.502 , 0.5015,\n",
       "            0.501 , 0.5005, 0.5   , 0.4998, 0.4995, 0.4993, 0.499 , 0.4988,\n",
       "            0.4978, 0.497 , 0.4958, 0.4954, 0.4949, 0.4946, 0.4941, 0.494 ,\n",
       "            0.4937, 0.4934, 0.492 , 0.4902, 0.4897, 0.4893, 0.489 , 0.488 ,\n",
       "            0.4858, 0.4854, 0.4841, 0.484 , 0.4836, 0.4814, 0.4805, 0.4802,\n",
       "            0.4797, 0.4792, 0.479 , 0.4788, 0.4785, 0.478 , 0.4778, 0.4768,\n",
       "            0.4766, 0.4758, 0.4756, 0.4749, 0.4739, 0.4734, 0.4722, 0.472 ,\n",
       "            0.4717, 0.4712, 0.471 , 0.4705, 0.4695, 0.4692, 0.4688, 0.4683,\n",
       "            0.4675, 0.467 , 0.466 , 0.4658, 0.4656, 0.4653, 0.4648, 0.4644,\n",
       "            0.4639, 0.4631, 0.462 , 0.4617, 0.4604, 0.4597, 0.4595, 0.4587,\n",
       "            0.4575, 0.457 , 0.4563, 0.455 , 0.4534, 0.4531, 0.4524, 0.452 ,\n",
       "            0.4517, 0.45  , 0.4492, 0.4487, 0.4478, 0.4463, 0.446 , 0.4456,\n",
       "            0.4453, 0.445 , 0.4448, 0.4443, 0.4429, 0.4424, 0.4417, 0.4402,\n",
       "            0.4397, 0.4395, 0.4392, 0.4375, 0.4365, 0.4363, 0.4338, 0.4324,\n",
       "            0.432 , 0.4312, 0.4307, 0.4302, 0.429 , 0.4287, 0.4275, 0.4268,\n",
       "            0.4253, 0.4236, 0.422 , 0.421 , 0.4187, 0.4177, 0.4167, 0.4148,\n",
       "            0.414 , 0.4128, 0.4124, 0.4055, 0.402 , 0.4   , 0.3938, 0.3933,\n",
       "            0.3894, 0.3892, 0.3884, 0.3862, 0.3833, 0.3816, 0.3762, 0.3757,\n",
       "            0.374 , 0.3699, 0.368 , 0.3677, 0.3628, 0.3625, 0.362 , 0.3596,\n",
       "            0.3584, 0.356 , 0.3538, 0.3533, 0.3486, 0.3447, 0.3406, 0.3396,\n",
       "            0.336 , 0.3354, 0.3315, 0.33  , 0.3262, 0.3254, 0.325 , 0.3184,\n",
       "            0.3176, 0.3174, 0.316 , 0.3113, 0.3064, 0.3047, 0.3037, 0.2996,\n",
       "            0.2988, 0.2866, 0.2756, 0.2595, 0.2466], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.08333334, 0.08333334,\n",
       "            0.1       , 0.1       , 0.1       , 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.175     , 0.175     , 0.175     , 0.175     ,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.20833333, 0.225     , 0.225     , 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.31666666, 0.325     , 0.34166667, 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.60833335, 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.6666667 , 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.7583333 , 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.825     ,\n",
       "            0.8333333 , 0.8333333 , 0.84166664, 0.84166664, 0.85      ,\n",
       "            0.85      , 0.85      , 0.85      , 0.85      , 0.8666667 ,\n",
       "            0.875     , 0.875     , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.89166665, 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.00769231, 0.02307692,\n",
       "            0.02307692, 0.03846154, 0.04615385, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.07692308, 0.08461539,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.1       , 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.15384616, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.18461539, 0.18461539, 0.18461539, 0.2       , 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.21538462, 0.21538462, 0.22307692,\n",
       "            0.22307692, 0.22307692, 0.22307692, 0.22307692, 0.22307692,\n",
       "            0.22307692, 0.23076923, 0.23076923, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.23846154, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.26153848, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.2846154 , 0.2846154 ,\n",
       "            0.2846154 , 0.2846154 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.31538463, 0.32307693, 0.32307693, 0.32307693, 0.32307693,\n",
       "            0.32307693, 0.33076924, 0.33076924, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.34615386, 0.34615386, 0.35384616,\n",
       "            0.35384616, 0.35384616, 0.35384616, 0.36153847, 0.36153847,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36153847, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.3846154 , 0.3846154 ,\n",
       "            0.3846154 , 0.3846154 , 0.3923077 , 0.3923077 , 0.3923077 ,\n",
       "            0.3923077 , 0.4       , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.45384616, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.46923077, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.47692308, 0.47692308, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.478 , 0.4778, 0.4773, 0.477 , 0.4768, 0.4766, 0.4763,\n",
       "            0.476 , 0.4758, 0.4756, 0.4753, 0.4749, 0.4746, 0.474 , 0.4736,\n",
       "            0.4731, 0.473 , 0.4727, 0.4722, 0.472 , 0.4714, 0.471 , 0.4705,\n",
       "            0.4702, 0.47  , 0.4695, 0.4692, 0.4688, 0.4685, 0.4683, 0.4673,\n",
       "            0.4666, 0.466 , 0.4653, 0.4648, 0.4646, 0.464 , 0.4636, 0.463 ,\n",
       "            0.462 , 0.4614, 0.4612, 0.4592, 0.4583, 0.458 , 0.4578, 0.4573,\n",
       "            0.457 , 0.4568, 0.4565, 0.456 , 0.4558, 0.4556, 0.4553, 0.455 ,\n",
       "            0.4548, 0.4546, 0.4539, 0.4536, 0.4534, 0.4531, 0.453 , 0.4524,\n",
       "            0.452 , 0.4512, 0.4504, 0.4492, 0.4487, 0.4485, 0.448 , 0.4473,\n",
       "            0.447 , 0.4465, 0.4463, 0.446 , 0.4458, 0.4448, 0.444 , 0.4438,\n",
       "            0.4426, 0.4417, 0.4414, 0.439 , 0.4377, 0.4365, 0.4363, 0.4358,\n",
       "            0.4355, 0.4353, 0.435 , 0.433 , 0.4321, 0.4316, 0.4314, 0.4297,\n",
       "            0.4282, 0.4268, 0.4258, 0.4253, 0.4248, 0.4246, 0.424 , 0.4238,\n",
       "            0.422 , 0.4219, 0.4214, 0.4207, 0.4194, 0.419 , 0.4185, 0.4177,\n",
       "            0.4167, 0.4165, 0.4163, 0.4155, 0.4143, 0.414 , 0.4138, 0.413 ,\n",
       "            0.4124, 0.412 , 0.4116, 0.41  , 0.4094, 0.4092, 0.409 , 0.4065,\n",
       "            0.4062, 0.4045, 0.4026, 0.4011, 0.4004, 0.4   , 0.3997, 0.3977,\n",
       "            0.396 , 0.3953, 0.3901, 0.3875, 0.3853, 0.3838, 0.3806, 0.3782,\n",
       "            0.3728, 0.3699, 0.3667, 0.3662, 0.366 , 0.3643, 0.3633, 0.3618,\n",
       "            0.3606, 0.3582, 0.355 , 0.3494, 0.3486, 0.344 , 0.3416, 0.341 ,\n",
       "            0.3408, 0.3396, 0.3384, 0.3376, 0.3342, 0.3335, 0.3284, 0.3237,\n",
       "            0.3235, 0.321 , 0.3171, 0.3145, 0.3137, 0.313 , 0.311 , 0.3096,\n",
       "            0.3093, 0.306 , 0.3018, 0.3013, 0.3005, 0.2996, 0.2986, 0.298 ,\n",
       "            0.2927, 0.292 , 0.2908, 0.2869, 0.283 , 0.2825, 0.2812, 0.28  ,\n",
       "            0.2773, 0.2737, 0.2615, 0.254 , 0.2532, 0.2363, 0.2235],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.10833333, 0.11666667,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.2       , 0.2       , 0.20833333,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.275     , 0.28333333, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.35      , 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.44166666,\n",
       "            0.45      , 0.45      , 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.49166667, 0.5083333 ,\n",
       "            0.525     , 0.525     , 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.64166665, 0.65833336,\n",
       "            0.6666667 , 0.68333334, 0.68333334, 0.68333334, 0.69166666,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.76666665, 0.775     , 0.78333336, 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85      , 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.90833336, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.10769231, 0.11538462, 0.12307692, 0.12307692,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.13846155, 0.13846155,\n",
       "            0.14615385, 0.14615385, 0.14615385, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.16153847, 0.18461539, 0.1923077 , 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.20769231, 0.21538462, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.22307692, 0.22307692, 0.23076923,\n",
       "            0.23076923, 0.23846154, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.25384617, 0.25384617,\n",
       "            0.26153848, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.2923077 , 0.2923077 , 0.3       , 0.3       ,\n",
       "            0.3       , 0.3       , 0.30769232, 0.30769232, 0.30769232,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.34615386, 0.34615386, 0.35384616, 0.35384616, 0.35384616,\n",
       "            0.35384616, 0.36153847, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.36923078, 0.36923078, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.3846154 , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4076923 , 0.42307693, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.43846154, 0.44615385, 0.45384616, 0.45384616,\n",
       "            0.46153846, 0.46153846, 0.46923077, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4846154 , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.7       , 0.7076923 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.455 , 0.454 , 0.4524, 0.4521, 0.4517, 0.4514, 0.451 ,\n",
       "            0.4507, 0.4504, 0.4502, 0.45  , 0.4497, 0.4495, 0.4492, 0.449 ,\n",
       "            0.4487, 0.4485, 0.4482, 0.4475, 0.447 , 0.4465, 0.446 , 0.4456,\n",
       "            0.4446, 0.4443, 0.444 , 0.4438, 0.4436, 0.4434, 0.4429, 0.4424,\n",
       "            0.4421, 0.4414, 0.4412, 0.4407, 0.4404, 0.4402, 0.44  , 0.4392,\n",
       "            0.439 , 0.4387, 0.4385, 0.4382, 0.4377, 0.4375, 0.437 , 0.4363,\n",
       "            0.436 , 0.4355, 0.4348, 0.4346, 0.4343, 0.4336, 0.433 , 0.4329,\n",
       "            0.4326, 0.4324, 0.4321, 0.4314, 0.4307, 0.4297, 0.4285, 0.4282,\n",
       "            0.428 , 0.4263, 0.426 , 0.4255, 0.425 , 0.424 , 0.4238, 0.4229,\n",
       "            0.4226, 0.4219, 0.4214, 0.4204, 0.4194, 0.4192, 0.4185, 0.4177,\n",
       "            0.4175, 0.4167, 0.4163, 0.416 , 0.4155, 0.4153, 0.4148, 0.4133,\n",
       "            0.4126, 0.4124, 0.412 , 0.4116, 0.4104, 0.41  , 0.4092, 0.408 ,\n",
       "            0.407 , 0.4067, 0.4062, 0.4058, 0.405 , 0.4043, 0.4033, 0.4023,\n",
       "            0.401 , 0.3994, 0.3987, 0.3984, 0.398 , 0.3972, 0.3965, 0.3962,\n",
       "            0.3958, 0.3955, 0.3943, 0.3936, 0.3933, 0.3916, 0.3914, 0.3909,\n",
       "            0.3906, 0.3904, 0.3901, 0.3894, 0.3887, 0.3884, 0.3867, 0.3865,\n",
       "            0.3848, 0.3845, 0.3806, 0.3762, 0.3757, 0.3735, 0.3726, 0.3713,\n",
       "            0.3704, 0.3684, 0.3655, 0.3635, 0.3633, 0.3616, 0.355 , 0.3542,\n",
       "            0.351 , 0.3464, 0.3462, 0.3457, 0.3435, 0.343 , 0.3413, 0.3386,\n",
       "            0.3372, 0.3367, 0.3362, 0.336 , 0.3325, 0.3303, 0.3286, 0.3262,\n",
       "            0.324 , 0.3186, 0.3176, 0.3171, 0.3167, 0.3123, 0.31  , 0.3052,\n",
       "            0.3025, 0.3018, 0.299 , 0.2986, 0.2966, 0.2942, 0.2917, 0.2915,\n",
       "            0.2896, 0.2876, 0.2874, 0.2837, 0.2805, 0.2786, 0.2773, 0.277 ,\n",
       "            0.2766, 0.2722, 0.2712, 0.268 , 0.2673, 0.266 , 0.265 , 0.261 ,\n",
       "            0.2595, 0.2588, 0.2534, 0.2417, 0.2368, 0.2355, 0.2184, 0.2059],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.19166666, 0.2       , 0.2       , 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.23333333,\n",
       "            0.24166666, 0.26666668, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.29166666, 0.3       , 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.575     , 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.6       , 0.60833335, 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.725     , 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 ,\n",
       "            0.7583333 , 0.775     , 0.78333336, 0.80833334, 0.81666666,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.89166665, 0.9       , 0.90833336, 0.90833336,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.925     , 0.925     ,\n",
       "            0.925     , 0.93333334, 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.95      , 0.95      , 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.05384615, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.07692308, 0.07692308, 0.07692308, 0.07692308, 0.08461539,\n",
       "            0.08461539, 0.09230769, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.11538462, 0.11538462, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.14615385, 0.14615385, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16153847, 0.16923077, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.20769231, 0.21538462, 0.21538462,\n",
       "            0.21538462, 0.23076923, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.25384617, 0.25384617, 0.26153848,\n",
       "            0.26153848, 0.26153848, 0.26923078, 0.26923078, 0.26923078,\n",
       "            0.26923078, 0.26923078, 0.26923078, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.2923077 , 0.2923077 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.30769232, 0.30769232, 0.32307693,\n",
       "            0.32307693, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36153847, 0.36153847,\n",
       "            0.36923078, 0.36923078, 0.36923078, 0.36923078, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.43846154, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5769231 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4421, 0.442 , 0.4392, 0.4387, 0.4368, 0.436 , 0.435 ,\n",
       "            0.4348, 0.4338, 0.4336, 0.432 , 0.4316, 0.431 , 0.4307, 0.4304,\n",
       "            0.4302, 0.4297, 0.429 , 0.4287, 0.4285, 0.4277, 0.4272, 0.427 ,\n",
       "            0.4265, 0.4263, 0.426 , 0.4258, 0.425 , 0.424 , 0.4236, 0.4233,\n",
       "            0.4229, 0.4226, 0.4224, 0.422 , 0.4219, 0.4216, 0.4214, 0.421 ,\n",
       "            0.4207, 0.4202, 0.4197, 0.4194, 0.4187, 0.4185, 0.4182, 0.4175,\n",
       "            0.417 , 0.4163, 0.416 , 0.4158, 0.4153, 0.4148, 0.4146, 0.4143,\n",
       "            0.414 , 0.4136, 0.413 , 0.4128, 0.4119, 0.4116, 0.4114, 0.4111,\n",
       "            0.4104, 0.41  , 0.4097, 0.4092, 0.4084, 0.408 , 0.4072, 0.4065,\n",
       "            0.406 , 0.405 , 0.4048, 0.4043, 0.4038, 0.403 , 0.4014, 0.401 ,\n",
       "            0.4006, 0.4001, 0.3997, 0.3994, 0.3992, 0.398 , 0.3977, 0.3965,\n",
       "            0.396 , 0.3958, 0.3955, 0.395 , 0.3948, 0.3943, 0.3916, 0.3909,\n",
       "            0.3896, 0.3894, 0.3887, 0.388 , 0.3877, 0.3872, 0.3867, 0.3862,\n",
       "            0.3853, 0.384 , 0.3838, 0.3835, 0.3833, 0.382 , 0.3813, 0.3809,\n",
       "            0.3804, 0.378 , 0.3772, 0.3765, 0.3755, 0.3748, 0.3743, 0.3733,\n",
       "            0.3728, 0.3713, 0.3708, 0.37  , 0.3696, 0.3691, 0.369 , 0.3687,\n",
       "            0.3682, 0.368 , 0.3677, 0.3674, 0.3652, 0.365 , 0.3647, 0.3613,\n",
       "            0.3606, 0.3586, 0.3564, 0.3562, 0.3528, 0.3523, 0.35  , 0.3486,\n",
       "            0.3477, 0.347 , 0.346 , 0.3457, 0.3452, 0.3435, 0.3386, 0.3381,\n",
       "            0.3376, 0.3367, 0.3325, 0.33  , 0.3271, 0.3254, 0.325 , 0.323 ,\n",
       "            0.319 , 0.3188, 0.3154, 0.3145, 0.3115, 0.311 , 0.31  , 0.3096,\n",
       "            0.3093, 0.3079, 0.3071, 0.3032, 0.299 , 0.2966, 0.2961, 0.2954,\n",
       "            0.2944, 0.2856, 0.2825, 0.2815, 0.2808, 0.2793, 0.278 , 0.275 ,\n",
       "            0.2742, 0.273 , 0.2722, 0.2693, 0.2688, 0.2651, 0.2637, 0.2595,\n",
       "            0.2568, 0.2551, 0.2532, 0.2512, 0.251 , 0.2498, 0.2485, 0.2467,\n",
       "            0.2466, 0.2456, 0.2413, 0.2402, 0.2372, 0.2328, 0.2211, 0.2191,\n",
       "            0.217 , 0.1998, 0.1879], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.53333336, 0.5416667 ,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.65833336, 0.65833336,\n",
       "            0.675     , 0.675     , 0.68333334, 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.80833334, 0.81666666, 0.81666666,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.85      , 0.85833335, 0.8666667 , 0.8833333 ,\n",
       "            0.8833333 , 0.8833333 , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.925     , 0.93333334, 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.95      , 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03846154, 0.05384615,\n",
       "            0.05384615, 0.05384615, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.08461539, 0.09230769, 0.09230769, 0.1       , 0.1       ,\n",
       "            0.10769231, 0.10769231, 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.14615385, 0.14615385,\n",
       "            0.14615385, 0.15384616, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.2       , 0.2       , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.22307692, 0.23076923, 0.23076923,\n",
       "            0.23846154, 0.23846154, 0.24615385, 0.24615385, 0.26153848,\n",
       "            0.26153848, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2769231 , 0.2846154 , 0.2923077 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.3       , 0.30769232, 0.30769232,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.31538463, 0.31538463,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.34615386, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.36923078, 0.37692308, 0.37692308, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4297, 0.429 , 0.4265, 0.425 , 0.4248, 0.4233, 0.423 ,\n",
       "            0.4224, 0.4216, 0.4202, 0.4197, 0.4194, 0.418 , 0.4177, 0.4175,\n",
       "            0.4163, 0.4155, 0.4153, 0.415 , 0.4148, 0.4146, 0.413 , 0.4128,\n",
       "            0.4119, 0.4106, 0.4104, 0.4092, 0.409 , 0.408 , 0.4077, 0.4067,\n",
       "            0.4065, 0.4062, 0.406 , 0.4038, 0.4036, 0.4033, 0.4019, 0.4016,\n",
       "            0.4014, 0.4011, 0.4001, 0.3987, 0.3984, 0.3977, 0.3972, 0.397 ,\n",
       "            0.3967, 0.3962, 0.396 , 0.3958, 0.395 , 0.3945, 0.3943, 0.394 ,\n",
       "            0.3936, 0.3933, 0.3923, 0.392 , 0.3918, 0.3901, 0.39  , 0.3896,\n",
       "            0.389 , 0.3887, 0.3882, 0.388 , 0.3877, 0.3875, 0.3872, 0.3853,\n",
       "            0.385 , 0.3845, 0.384 , 0.3838, 0.3835, 0.3833, 0.383 , 0.382 ,\n",
       "            0.3816, 0.3813, 0.381 , 0.3809, 0.3806, 0.3804, 0.3801, 0.3794,\n",
       "            0.379 , 0.3784, 0.378 , 0.3765, 0.3755, 0.3752, 0.375 , 0.3743,\n",
       "            0.3738, 0.3718, 0.3716, 0.3708, 0.3706, 0.3691, 0.369 , 0.3684,\n",
       "            0.3682, 0.3674, 0.3657, 0.3655, 0.3652, 0.365 , 0.3638, 0.3635,\n",
       "            0.363 , 0.3623, 0.3618, 0.3608, 0.36  , 0.3591, 0.3584, 0.3582,\n",
       "            0.358 , 0.3577, 0.3572, 0.356 , 0.3542, 0.3533, 0.3528, 0.3525,\n",
       "            0.3516, 0.35  , 0.3496, 0.349 , 0.346 , 0.3457, 0.3452, 0.344 ,\n",
       "            0.3435, 0.3423, 0.342 , 0.3418, 0.3403, 0.34  , 0.3396, 0.3386,\n",
       "            0.3381, 0.3347, 0.3345, 0.3337, 0.3323, 0.331 , 0.3303, 0.3284,\n",
       "            0.3281, 0.3257, 0.325 , 0.3223, 0.3188, 0.3186, 0.318 , 0.3162,\n",
       "            0.3145, 0.3108, 0.3093, 0.3088, 0.3086, 0.3071, 0.3052, 0.3015,\n",
       "            0.3003, 0.2988, 0.2979, 0.297 , 0.2961, 0.292 , 0.2915, 0.291 ,\n",
       "            0.2878, 0.2866, 0.284 , 0.281 , 0.2805, 0.2783, 0.2769, 0.2676,\n",
       "            0.2673, 0.2656, 0.2654, 0.2644, 0.2612, 0.2607, 0.2605, 0.2603,\n",
       "            0.2593, 0.2559, 0.2534, 0.2494, 0.2467, 0.2452, 0.2418, 0.2399,\n",
       "            0.2374, 0.237 , 0.2362, 0.2352, 0.2346, 0.2332, 0.233 , 0.2301,\n",
       "            0.2295, 0.2263, 0.2227, 0.2191, 0.2085, 0.2079, 0.2058, 0.1886,\n",
       "            0.1772], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.59166664, 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.675     , 0.69166666, 0.69166666, 0.7       , 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.71666664, 0.71666664,\n",
       "            0.71666664, 0.725     , 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.80833334, 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.825     , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84166664, 0.84166664, 0.84166664, 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.9       , 0.90833336,\n",
       "            0.90833336, 0.90833336, 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.02307692, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.04615385, 0.06923077,\n",
       "            0.07692308, 0.07692308, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.09230769, 0.09230769, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.10769231, 0.10769231, 0.12307692, 0.12307692,\n",
       "            0.12307692, 0.12307692, 0.12307692, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.16153847, 0.16153847,\n",
       "            0.16923077, 0.16923077, 0.17692308, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.21538462, 0.21538462, 0.21538462, 0.21538462, 0.23076923,\n",
       "            0.23846154, 0.23846154, 0.24615385, 0.24615385, 0.25384617,\n",
       "            0.25384617, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2923077 , 0.2923077 , 0.2923077 , 0.2923077 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.3       , 0.3       , 0.30769232,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4175, 0.416 , 0.4136, 0.4124, 0.4114, 0.4111, 0.4106,\n",
       "            0.4097, 0.4094, 0.4077, 0.4075, 0.4067, 0.406 , 0.4048, 0.4045,\n",
       "            0.404 , 0.4023, 0.402 , 0.4011, 0.4006, 0.4004, 0.3994, 0.3975,\n",
       "            0.3962, 0.396 , 0.395 , 0.3943, 0.3938, 0.3928, 0.392 , 0.3906,\n",
       "            0.39  , 0.3887, 0.3882, 0.3848, 0.3828, 0.381 , 0.3809, 0.3806,\n",
       "            0.3801, 0.3782, 0.378 , 0.377 , 0.3765, 0.376 , 0.3755, 0.375 ,\n",
       "            0.3738, 0.3735, 0.3723, 0.3718, 0.3706, 0.3704, 0.3687, 0.3684,\n",
       "            0.3677, 0.3674, 0.3672, 0.367 , 0.3667, 0.3665, 0.366 , 0.3657,\n",
       "            0.3655, 0.3652, 0.365 , 0.3638, 0.363 , 0.362 , 0.3618, 0.3616,\n",
       "            0.3608, 0.3606, 0.3599, 0.3596, 0.3591, 0.3584, 0.358 , 0.3574,\n",
       "            0.357 , 0.3557, 0.3552, 0.3545, 0.3542, 0.3538, 0.3535, 0.3533,\n",
       "            0.353 , 0.3525, 0.3523, 0.352 , 0.3518, 0.3516, 0.3513, 0.35  ,\n",
       "            0.3499, 0.348 , 0.3474, 0.3447, 0.3445, 0.344 , 0.343 , 0.3428,\n",
       "            0.342 , 0.3418, 0.3416, 0.341 , 0.3389, 0.338 , 0.3374, 0.336 ,\n",
       "            0.335 , 0.3345, 0.333 , 0.3315, 0.3308, 0.3303, 0.3298, 0.3296,\n",
       "            0.3293, 0.327 , 0.3267, 0.3242, 0.3235, 0.3232, 0.3228, 0.322 ,\n",
       "            0.3213, 0.321 , 0.3198, 0.3193, 0.3179, 0.3171, 0.3164, 0.3162,\n",
       "            0.316 , 0.3142, 0.3137, 0.3118, 0.3108, 0.3105, 0.3103, 0.3088,\n",
       "            0.3079, 0.3071, 0.3066, 0.3015, 0.301 , 0.2996, 0.298 , 0.2976,\n",
       "            0.2969, 0.2932, 0.2925, 0.292 , 0.2917, 0.2915, 0.2908, 0.2905,\n",
       "            0.2903, 0.29  , 0.286 , 0.2832, 0.283 , 0.2825, 0.281 , 0.2805,\n",
       "            0.28  , 0.278 , 0.2737, 0.2727, 0.2725, 0.2717, 0.2708, 0.2637,\n",
       "            0.2634, 0.26  , 0.2598, 0.258 , 0.2512, 0.251 , 0.2505, 0.2483,\n",
       "            0.2482, 0.2477, 0.2474, 0.2463, 0.2458, 0.2456, 0.2367, 0.2363,\n",
       "            0.236 , 0.2322, 0.2292, 0.2281, 0.2252, 0.2242, 0.2229, 0.2208,\n",
       "            0.2207, 0.219 , 0.2179, 0.2177, 0.2157, 0.2137, 0.2129, 0.2106,\n",
       "            0.2063, 0.2037, 0.1956, 0.1927, 0.1925, 0.1754, 0.1647],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.34166667, 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.425     , 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.49166667, 0.5       ,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.525     , 0.525     ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.5833333 , 0.5833333 , 0.59166664, 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.65      , 0.65      ,\n",
       "            0.65833336, 0.65833336, 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.71666664, 0.725     , 0.73333335, 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.775     , 0.775     ,\n",
       "            0.775     , 0.775     , 0.78333336, 0.78333336, 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.84166664, 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.8666667 , 0.8666667 ,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.9       , 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.925     , 0.925     , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.06923077, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.07692308, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.11538462, 0.13076924, 0.13846155, 0.13846155, 0.14615385,\n",
       "            0.14615385, 0.14615385, 0.15384616, 0.15384616, 0.15384616,\n",
       "            0.16153847, 0.16153847, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.2       , 0.2       , 0.2       , 0.20769231,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.22307692, 0.22307692,\n",
       "            0.23076923, 0.23076923, 0.23076923, 0.23846154, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.24615385, 0.24615385, 0.25384617,\n",
       "            0.25384617, 0.25384617, 0.25384617, 0.26923078, 0.26923078,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.36923078, 0.37692308, 0.3846154 , 0.3846154 ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.44615385, 0.45384616, 0.46153846, 0.46153846,\n",
       "            0.47692308, 0.4846154 , 0.4846154 , 0.4846154 , 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.52307695, 0.52307695,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.75384617, 0.76153845, 0.7692308 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4055, 0.4028, 0.401 , 0.4006, 0.4   , 0.3982, 0.3977,\n",
       "            0.397 , 0.3965, 0.3955, 0.394 , 0.3936, 0.3923, 0.3916, 0.39  ,\n",
       "            0.3896, 0.3892, 0.389 , 0.388 , 0.387 , 0.386 , 0.3857, 0.3838,\n",
       "            0.3833, 0.383 , 0.3828, 0.3823, 0.3801, 0.3796, 0.378 , 0.3752,\n",
       "            0.373 , 0.3706, 0.3699, 0.3677, 0.3672, 0.3635, 0.362 , 0.3591,\n",
       "            0.3584, 0.358 , 0.3564, 0.355 , 0.3538, 0.3523, 0.3518, 0.3516,\n",
       "            0.351 , 0.3508, 0.3506, 0.3499, 0.3496, 0.3484, 0.348 , 0.3474,\n",
       "            0.347 , 0.3457, 0.3455, 0.3452, 0.3447, 0.3438, 0.3435, 0.343 ,\n",
       "            0.3425, 0.3418, 0.3413, 0.341 , 0.3408, 0.3403, 0.3389, 0.3386,\n",
       "            0.3384, 0.3381, 0.337 , 0.336 , 0.3357, 0.335 , 0.3347, 0.3345,\n",
       "            0.3335, 0.3333, 0.3318, 0.3315, 0.3298, 0.3296, 0.3293, 0.3289,\n",
       "            0.3286, 0.3284, 0.328 , 0.3271, 0.3267, 0.3264, 0.3262, 0.326 ,\n",
       "            0.3257, 0.3252, 0.325 , 0.3247, 0.3232, 0.3228, 0.3225, 0.3213,\n",
       "            0.3203, 0.3188, 0.3184, 0.3167, 0.3164, 0.316 , 0.3154, 0.3137,\n",
       "            0.3127, 0.3123, 0.3103, 0.3098, 0.3086, 0.308 , 0.3064, 0.3052,\n",
       "            0.305 , 0.3044, 0.3032, 0.3025, 0.3022, 0.3013, 0.3   , 0.2996,\n",
       "            0.2983, 0.298 , 0.2979, 0.2976, 0.2974, 0.297 , 0.2954, 0.2944,\n",
       "            0.294 , 0.2937, 0.2927, 0.2917, 0.291 , 0.29  , 0.2886, 0.2878,\n",
       "            0.2866, 0.2852, 0.2842, 0.2837, 0.2825, 0.2815, 0.2805, 0.28  ,\n",
       "            0.2798, 0.2793, 0.278 , 0.2761, 0.2756, 0.275 , 0.2747, 0.274 ,\n",
       "            0.2722, 0.2705, 0.269 , 0.2688, 0.2676, 0.2666, 0.2659, 0.2656,\n",
       "            0.2646, 0.2637, 0.2632, 0.2617, 0.2595, 0.2573, 0.2542, 0.2527,\n",
       "            0.2522, 0.2478, 0.2456, 0.2422, 0.2418, 0.2413, 0.2399, 0.2372,\n",
       "            0.237 , 0.2355, 0.2335, 0.2251, 0.2235, 0.2213, 0.2203, 0.2195,\n",
       "            0.2173, 0.2166, 0.2152, 0.2133, 0.2125, 0.2114, 0.2094, 0.2089,\n",
       "            0.2084, 0.2063, 0.2026, 0.2017, 0.1968, 0.1952, 0.1893, 0.1859,\n",
       "            0.1846, 0.1692, 0.1588], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.525     , 0.525     , 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.65833336, 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7       , 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.7416667 , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.775     , 0.775     , 0.775     , 0.775     ,\n",
       "            0.775     , 0.775     , 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.8       , 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.8333333 , 0.8333333 , 0.85      , 0.85      ,\n",
       "            0.85      , 0.85      , 0.85833335, 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.8666667 , 0.8666667 , 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.90833336, 0.90833336, 0.90833336, 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.1       , 0.10769231,\n",
       "            0.11538462, 0.11538462, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13846155, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.15384616, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.2       , 0.2       , 0.21538462, 0.21538462, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.4076923 , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43076923, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.46923077, 0.47692308, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.50769234, 0.52307695, 0.53846157, 0.54615384, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.56153846, 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5846154 , 0.5846154 , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.65384614, 0.6615385 , 0.66923076, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3936, 0.3896, 0.3884, 0.3882, 0.388 , 0.3857, 0.3848,\n",
       "            0.3845, 0.384 , 0.3835, 0.382 , 0.3804, 0.38  , 0.379 , 0.3777,\n",
       "            0.3772, 0.3762, 0.3757, 0.3755, 0.373 , 0.3728, 0.3716, 0.3708,\n",
       "            0.3704, 0.37  , 0.3696, 0.3691, 0.3677, 0.3667, 0.3657, 0.3625,\n",
       "            0.3572, 0.3547, 0.3542, 0.3538, 0.3513, 0.3506, 0.3486, 0.348 ,\n",
       "            0.344 , 0.343 , 0.3408, 0.3403, 0.3381, 0.3376, 0.337 , 0.3364,\n",
       "            0.3362, 0.3357, 0.3333, 0.333 , 0.3325, 0.332 , 0.3306, 0.3303,\n",
       "            0.3289, 0.3286, 0.328 , 0.3271, 0.3264, 0.3262, 0.326 , 0.3247,\n",
       "            0.324 , 0.3237, 0.3232, 0.3228, 0.3223, 0.3218, 0.3213, 0.321 ,\n",
       "            0.3206, 0.3203, 0.32  , 0.3196, 0.3193, 0.3184, 0.3174, 0.3171,\n",
       "            0.3152, 0.3132, 0.3127, 0.3123, 0.3113, 0.3108, 0.3105, 0.3096,\n",
       "            0.3093, 0.309 , 0.3083, 0.3079, 0.3076, 0.3074, 0.305 , 0.3044,\n",
       "            0.304 , 0.3032, 0.303 , 0.3015, 0.3013, 0.3005, 0.2998, 0.299 ,\n",
       "            0.2961, 0.2944, 0.2937, 0.2935, 0.293 , 0.2927, 0.292 , 0.291 ,\n",
       "            0.2908, 0.2903, 0.2886, 0.2876, 0.286 , 0.2856, 0.2837, 0.2825,\n",
       "            0.282 , 0.2815, 0.2795, 0.2793, 0.279 , 0.2773, 0.277 , 0.2769,\n",
       "            0.2761, 0.2756, 0.2751, 0.2737, 0.273 , 0.2722, 0.272 , 0.2712,\n",
       "            0.271 , 0.2708, 0.2698, 0.2686, 0.2673, 0.267 , 0.2664, 0.2646,\n",
       "            0.2644, 0.263 , 0.2622, 0.2612, 0.261 , 0.2607, 0.259 , 0.2588,\n",
       "            0.2585, 0.2576, 0.2573, 0.2568, 0.256 , 0.253 , 0.2527, 0.2515,\n",
       "            0.25  , 0.249 , 0.2477, 0.246 , 0.2458, 0.2448, 0.2444, 0.2428,\n",
       "            0.2424, 0.2417, 0.2411, 0.2394, 0.2378, 0.2356, 0.2355, 0.2352,\n",
       "            0.2299, 0.2297, 0.2295, 0.2274, 0.2273, 0.2261, 0.2257, 0.2251,\n",
       "            0.222 , 0.2217, 0.2202, 0.2167, 0.2161, 0.2156, 0.2076, 0.2047,\n",
       "            0.2042, 0.2035, 0.2034, 0.1989, 0.1985, 0.1981, 0.1958, 0.1954,\n",
       "            0.1941, 0.1931, 0.193 , 0.1884, 0.1858, 0.1857, 0.183 , 0.1805,\n",
       "            0.1796, 0.1758, 0.172 , 0.1694, 0.1555, 0.1456], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.15      , 0.15833333, 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.49166667, 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.6       , 0.60833335,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.68333334, 0.68333334,\n",
       "            0.69166666, 0.69166666, 0.69166666, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7       , 0.71666664, 0.725     , 0.725     ,\n",
       "            0.73333335, 0.73333335, 0.75      , 0.7583333 , 0.7583333 ,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.825     , 0.825     , 0.825     , 0.825     , 0.8333333 ,\n",
       "            0.8333333 , 0.8333333 , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.89166665, 0.89166665, 0.89166665, 0.89166665, 0.89166665,\n",
       "            0.9       , 0.9       , 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 0.9916667 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.04615385, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.09230769, 0.09230769,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.10769231, 0.10769231,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13076924, 0.13846155, 0.14615385, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.16923077, 0.16923077,\n",
       "            0.17692308, 0.17692308, 0.17692308, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.1923077 , 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26153848, 0.26153848, 0.2846154 ,\n",
       "            0.2846154 , 0.3       , 0.3       , 0.31538463, 0.32307693,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5692308 , 0.5769231 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63076925,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.6615385 , 0.6769231 , 0.6769231 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.73846155, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.382 , 0.378 , 0.377 , 0.3767, 0.375 , 0.3748, 0.3738,\n",
       "            0.373 , 0.3728, 0.3726, 0.3713, 0.3696, 0.3682, 0.3665, 0.3662,\n",
       "            0.3655, 0.3647, 0.3635, 0.3625, 0.361 , 0.3608, 0.3596, 0.3594,\n",
       "            0.3591, 0.3572, 0.3535, 0.3503, 0.3442, 0.3413, 0.3406, 0.3389,\n",
       "            0.3374, 0.3372, 0.337 , 0.335 , 0.3345, 0.3303, 0.3264, 0.3245,\n",
       "            0.3242, 0.3232, 0.3228, 0.3223, 0.3213, 0.3193, 0.3186, 0.318 ,\n",
       "            0.3171, 0.316 , 0.3154, 0.3127, 0.3123, 0.3113, 0.311 , 0.3108,\n",
       "            0.3103, 0.31  , 0.3086, 0.3079, 0.3074, 0.3066, 0.306 , 0.3057,\n",
       "            0.3042, 0.3032, 0.3022, 0.302 , 0.3018, 0.3008, 0.3005, 0.2998,\n",
       "            0.2996, 0.2993, 0.299 , 0.2986, 0.298 , 0.2976, 0.2969, 0.2961,\n",
       "            0.2957, 0.2954, 0.2944, 0.294 , 0.293 , 0.2922, 0.2915, 0.291 ,\n",
       "            0.2908, 0.2905, 0.2898, 0.289 , 0.2888, 0.287 , 0.2869, 0.2847,\n",
       "            0.2844, 0.2842, 0.2832, 0.282 , 0.2808, 0.2798, 0.2786, 0.2773,\n",
       "            0.277 , 0.2769, 0.2766, 0.2761, 0.2756, 0.2727, 0.2722, 0.272 ,\n",
       "            0.2703, 0.2678, 0.2668, 0.2664, 0.2659, 0.2654, 0.2642, 0.264 ,\n",
       "            0.2637, 0.263 , 0.2607, 0.2595, 0.2588, 0.258 , 0.2576, 0.2573,\n",
       "            0.2563, 0.2554, 0.2551, 0.255 , 0.2546, 0.2544, 0.2542, 0.2537,\n",
       "            0.2534, 0.253 , 0.2527, 0.252 , 0.2517, 0.2512, 0.25  , 0.2482,\n",
       "            0.2466, 0.2463, 0.2462, 0.2449, 0.2448, 0.2424, 0.2421, 0.2415,\n",
       "            0.2411, 0.239 , 0.2386, 0.2374, 0.2362, 0.2355, 0.2334, 0.2332,\n",
       "            0.2322, 0.2316, 0.2314, 0.2307, 0.2297, 0.2294, 0.229 , 0.2289,\n",
       "            0.2285, 0.2266, 0.224 , 0.2235, 0.2234, 0.2229, 0.2222, 0.2213,\n",
       "            0.2203, 0.2202, 0.2186, 0.2184, 0.2175, 0.2173, 0.2144, 0.212 ,\n",
       "            0.2101, 0.2094, 0.2089, 0.2064, 0.202 , 0.2018, 0.199 , 0.1989,\n",
       "            0.1974, 0.1964, 0.1958, 0.1937, 0.1925, 0.1919, 0.1912, 0.1907,\n",
       "            0.1896, 0.1887, 0.188 , 0.1829, 0.1821, 0.1808, 0.1766, 0.1765,\n",
       "            0.1763, 0.1748, 0.1707, 0.1665, 0.1543, 0.145 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.425     , 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.5416667 , 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.675     , 0.68333334, 0.68333334, 0.68333334,\n",
       "            0.69166666, 0.69166666, 0.69166666, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7       , 0.71666664,\n",
       "            0.725     , 0.725     , 0.73333335, 0.73333335, 0.75      ,\n",
       "            0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.775     , 0.775     , 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.7916667 , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.80833334, 0.80833334, 0.81666666, 0.81666666,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.8333333 , 0.84166664,\n",
       "            0.84166664, 0.84166664, 0.85      , 0.85      , 0.85833335,\n",
       "            0.85833335, 0.85833335, 0.8666667 , 0.8666667 , 0.875     ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.9       , 0.9       , 0.90833336, 0.9166667 , 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.925     , 0.925     , 0.925     ,\n",
       "            0.925     , 0.925     , 0.925     , 0.925     , 0.925     ,\n",
       "            0.93333334, 0.93333334, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.06153846, 0.06923077, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.09230769, 0.09230769, 0.09230769,\n",
       "            0.1       , 0.1       , 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.14615385, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.15384616, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.17692308, 0.18461539, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.30769232,\n",
       "            0.30769232, 0.31538463, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.4076923 , 0.41538462, 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4846154 , 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5769231 , 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.6230769 , 0.63076925, 0.63076925, 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.72307694, 0.72307694,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.7692308 , 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.95384616, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3726, 0.37  , 0.3699, 0.3684, 0.367 , 0.3667, 0.3652,\n",
       "            0.3645, 0.3643, 0.363 , 0.362 , 0.3606, 0.36  , 0.3591, 0.3584,\n",
       "            0.3567, 0.356 , 0.3555, 0.3552, 0.3538, 0.3533, 0.3528, 0.3525,\n",
       "            0.352 , 0.3516, 0.3494, 0.3486, 0.3474, 0.3457, 0.3452, 0.3418,\n",
       "            0.3376, 0.3335, 0.3318, 0.331 , 0.3289, 0.327 , 0.3254, 0.3245,\n",
       "            0.3242, 0.3235, 0.3228, 0.3186, 0.316 , 0.3135, 0.3132, 0.3125,\n",
       "            0.3096, 0.3093, 0.3088, 0.3071, 0.3054, 0.3052, 0.3047, 0.3037,\n",
       "            0.3032, 0.303 , 0.2996, 0.2988, 0.2983, 0.2976, 0.2969, 0.296 ,\n",
       "            0.2957, 0.294 , 0.2932, 0.2925, 0.292 , 0.2915, 0.2898, 0.289 ,\n",
       "            0.2886, 0.2883, 0.2866, 0.2861, 0.2856, 0.2852, 0.2847, 0.2844,\n",
       "            0.2842, 0.284 , 0.2837, 0.2827, 0.2822, 0.2808, 0.2805, 0.2803,\n",
       "            0.2788, 0.278 , 0.2778, 0.2776, 0.277 , 0.2764, 0.276 , 0.2751,\n",
       "            0.275 , 0.2732, 0.273 , 0.2727, 0.2708, 0.2705, 0.2698, 0.2688,\n",
       "            0.2673, 0.2668, 0.2664, 0.2654, 0.2644, 0.2642, 0.2632, 0.263 ,\n",
       "            0.2625, 0.2622, 0.2617, 0.2612, 0.26  , 0.259 , 0.2588, 0.2578,\n",
       "            0.2563, 0.2556, 0.255 , 0.2534, 0.2524, 0.2517, 0.2515, 0.2512,\n",
       "            0.251 , 0.2507, 0.2493, 0.249 , 0.2487, 0.2483, 0.248 , 0.2478,\n",
       "            0.244 , 0.2434, 0.2433, 0.243 , 0.2422, 0.2421, 0.2406, 0.2401,\n",
       "            0.2399, 0.2397, 0.2395, 0.2394, 0.2388, 0.2383, 0.2382, 0.237 ,\n",
       "            0.2362, 0.2358, 0.2352, 0.2351, 0.2347, 0.2344, 0.234 , 0.2328,\n",
       "            0.2322, 0.231 , 0.2306, 0.2301, 0.2281, 0.2272, 0.2261, 0.2257,\n",
       "            0.2255, 0.2252, 0.2247, 0.2235, 0.2229, 0.2227, 0.2208, 0.2203,\n",
       "            0.2195, 0.219 , 0.2184, 0.2177, 0.2175, 0.2167, 0.2158, 0.2156,\n",
       "            0.2153, 0.2142, 0.2137, 0.2129, 0.2123, 0.21  , 0.208 , 0.2074,\n",
       "            0.2063, 0.2042, 0.2028, 0.202 , 0.2009, 0.2004, 0.1984, 0.1978,\n",
       "            0.1965, 0.1959, 0.1952, 0.1935, 0.193 , 0.1921, 0.1915, 0.1909,\n",
       "            0.1901, 0.1893, 0.1884, 0.1858, 0.1821, 0.182 , 0.1804, 0.1799,\n",
       "            0.1764, 0.1758, 0.1715, 0.1671, 0.1556, 0.1467], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01666667, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.325     , 0.33333334, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.45      , 0.45      , 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.525     , 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.65      , 0.65833336, 0.65833336, 0.65833336, 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.675     , 0.675     , 0.675     ,\n",
       "            0.675     , 0.675     , 0.675     , 0.675     , 0.69166666,\n",
       "            0.69166666, 0.69166666, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.7583333 , 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.775     , 0.775     , 0.775     , 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.80833334, 0.80833334,\n",
       "            0.80833334, 0.80833334, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.825     , 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85      , 0.85833335, 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.875     , 0.875     , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 0.9916667 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06153846, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.11538462,\n",
       "            0.12307692, 0.12307692, 0.13076924, 0.13076924, 0.13076924,\n",
       "            0.13076924, 0.13846155, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.15384616, 0.16923077, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.2       , 0.2       ,\n",
       "            0.2       , 0.20769231, 0.20769231, 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.41538462, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.46923077, 0.47692308, 0.4846154 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.52307695,\n",
       "            0.52307695, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.6076923 , 0.61538464, 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.66923076, 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7076923 , 0.7076923 , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3647, 0.3643, 0.3625, 0.3618, 0.3606, 0.3584, 0.3577,\n",
       "            0.3557, 0.3555, 0.3552, 0.3542, 0.3538, 0.3528, 0.352 , 0.3518,\n",
       "            0.3513, 0.35  , 0.3489, 0.3452, 0.3445, 0.3442, 0.342 , 0.3418,\n",
       "            0.3413, 0.3406, 0.3372, 0.335 , 0.3342, 0.3335, 0.3328, 0.332 ,\n",
       "            0.329 , 0.325 , 0.3208, 0.318 , 0.317 , 0.316 , 0.3157, 0.3147,\n",
       "            0.3123, 0.3096, 0.3093, 0.3088, 0.3052, 0.3037, 0.3018, 0.2986,\n",
       "            0.2966, 0.2954, 0.2942, 0.2937, 0.2935, 0.293 , 0.2908, 0.2898,\n",
       "            0.2893, 0.289 , 0.2886, 0.2883, 0.2864, 0.286 , 0.2852, 0.2847,\n",
       "            0.2842, 0.284 , 0.283 , 0.2815, 0.2795, 0.2793, 0.2788, 0.278 ,\n",
       "            0.2776, 0.2769, 0.2761, 0.276 , 0.2754, 0.275 , 0.2744, 0.2742,\n",
       "            0.2737, 0.2734, 0.2732, 0.273 , 0.2722, 0.272 , 0.2708, 0.2705,\n",
       "            0.2703, 0.2695, 0.2688, 0.2676, 0.2668, 0.2656, 0.2654, 0.2651,\n",
       "            0.264 , 0.2637, 0.2634, 0.2627, 0.2622, 0.2615, 0.2612, 0.2603,\n",
       "            0.26  , 0.2595, 0.2593, 0.2588, 0.2585, 0.258 , 0.257 , 0.2559,\n",
       "            0.255 , 0.2534, 0.2532, 0.253 , 0.2522, 0.251 , 0.2505, 0.2502,\n",
       "            0.2498, 0.2496, 0.2494, 0.2487, 0.2485, 0.2477, 0.2456, 0.2434,\n",
       "            0.2433, 0.2428, 0.2422, 0.2421, 0.2394, 0.2386, 0.2383, 0.2367,\n",
       "            0.2362, 0.2351, 0.2344, 0.2334, 0.2332, 0.233 , 0.2327, 0.231 ,\n",
       "            0.2303, 0.2301, 0.2289, 0.2283, 0.228 , 0.2277, 0.2274, 0.2268,\n",
       "            0.2255, 0.2238, 0.2234, 0.223 , 0.2229, 0.222 , 0.2216, 0.2211,\n",
       "            0.2194, 0.218 , 0.2173, 0.2172, 0.2166, 0.2161, 0.2152, 0.2142,\n",
       "            0.214 , 0.2135, 0.2114, 0.2094, 0.2091, 0.209 , 0.2085, 0.2084,\n",
       "            0.2075, 0.2063, 0.2047, 0.2042, 0.204 , 0.2028, 0.2024, 0.2023,\n",
       "            0.2018, 0.2013, 0.201 , 0.2006, 0.1998, 0.1985, 0.1979, 0.1962,\n",
       "            0.1958, 0.1941, 0.1935, 0.1931, 0.1921, 0.1904, 0.1887, 0.1886,\n",
       "            0.1885, 0.1884, 0.1871, 0.1865, 0.1849, 0.1844, 0.1838, 0.1797,\n",
       "            0.178 , 0.1763, 0.172 , 0.1692, 0.1617, 0.1604], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.48333332, 0.5083333 , 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.575     , 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.59166664, 0.6       , 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.65      , 0.65      , 0.65833336, 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.68333334, 0.68333334, 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.7583333 , 0.7583333 , 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.775     , 0.775     , 0.78333336, 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.8       , 0.8       , 0.80833334, 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.825     , 0.825     , 0.825     ,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.85833335, 0.85833335, 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.8666667 , 0.875     , 0.875     , 0.8833333 ,\n",
       "            0.8833333 , 0.8833333 , 0.8833333 , 0.89166665, 0.89166665,\n",
       "            0.89166665, 0.9       , 0.9       , 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.925     , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.09230769, 0.1       , 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.14615385, 0.14615385, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.15384616, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.18461539, 0.1923077 , 0.1923077 ,\n",
       "            0.1923077 , 0.1923077 , 0.20769231, 0.21538462, 0.23076923,\n",
       "            0.23076923, 0.23846154, 0.25384617, 0.26153848, 0.26153848,\n",
       "            0.26923078, 0.2846154 , 0.3       , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.33846155,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.36923078, 0.3923077 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.42307693, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.46923077, 0.47692308, 0.47692308, 0.4846154 , 0.4846154 ,\n",
       "            0.4846154 , 0.4846154 , 0.4923077 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.5153846 , 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.6230769 , 0.6230769 , 0.63076925,\n",
       "            0.63076925, 0.64615387, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7153846 , 0.7307692 , 0.74615383, 0.75384617,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.8384615 , 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86923075, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3582, 0.358 , 0.356 , 0.3555, 0.355 , 0.3545, 0.352 ,\n",
       "            0.3508, 0.35  , 0.3499, 0.3489, 0.3486, 0.348 , 0.3477, 0.3445,\n",
       "            0.344 , 0.342 , 0.3406, 0.3394, 0.338 , 0.3345, 0.3337, 0.333 ,\n",
       "            0.3315, 0.3306, 0.33  , 0.3298, 0.3284, 0.3281, 0.3262, 0.3223,\n",
       "            0.3213, 0.3203, 0.317 , 0.3147, 0.3145, 0.3137, 0.3123, 0.311 ,\n",
       "            0.3093, 0.3074, 0.3071, 0.3022, 0.3013, 0.2988, 0.297 , 0.2966,\n",
       "            0.296 , 0.2952, 0.2942, 0.2925, 0.289 , 0.2888, 0.2864, 0.2856,\n",
       "            0.2854, 0.2852, 0.2844, 0.2832, 0.2815, 0.281 , 0.2805, 0.2786,\n",
       "            0.278 , 0.277 , 0.2769, 0.2761, 0.276 , 0.275 , 0.274 , 0.2737,\n",
       "            0.2734, 0.2732, 0.273 , 0.2717, 0.2712, 0.271 , 0.269 , 0.2688,\n",
       "            0.2683, 0.268 , 0.2673, 0.2668, 0.2666, 0.2664, 0.2659, 0.2654,\n",
       "            0.2642, 0.264 , 0.2637, 0.2634, 0.2632, 0.263 , 0.262 , 0.2615,\n",
       "            0.2612, 0.2605, 0.2595, 0.2588, 0.2578, 0.2573, 0.257 , 0.2568,\n",
       "            0.2551, 0.255 , 0.2544, 0.254 , 0.2534, 0.2527, 0.2524, 0.2522,\n",
       "            0.252 , 0.2515, 0.251 , 0.2502, 0.25  , 0.2496, 0.248 , 0.2466,\n",
       "            0.2462, 0.246 , 0.2452, 0.2451, 0.2438, 0.2434, 0.2429, 0.2426,\n",
       "            0.2421, 0.2417, 0.2411, 0.241 , 0.2406, 0.2405, 0.2399, 0.2395,\n",
       "            0.239 , 0.2386, 0.2384, 0.2374, 0.2366, 0.2363, 0.2362, 0.2358,\n",
       "            0.2335, 0.2334, 0.2332, 0.2322, 0.2313, 0.231 , 0.2302, 0.2294,\n",
       "            0.2263, 0.2256, 0.2252, 0.2216, 0.2211, 0.2208, 0.2179, 0.2177,\n",
       "            0.2168, 0.2156, 0.2145, 0.214 , 0.2135, 0.2128, 0.2125, 0.2115,\n",
       "            0.2114, 0.2113, 0.2109, 0.2106, 0.2089, 0.2085, 0.2074, 0.2068,\n",
       "            0.2058, 0.2056, 0.2054, 0.2051, 0.2048, 0.2043, 0.202 , 0.2013,\n",
       "            0.2006, 0.1989, 0.1987, 0.1981, 0.197 , 0.1968, 0.1962, 0.1953,\n",
       "            0.1937, 0.1936, 0.1934, 0.1923, 0.1918, 0.1909, 0.1901, 0.1897,\n",
       "            0.1892, 0.186 , 0.1859, 0.185 , 0.1846, 0.1833, 0.183 , 0.1808,\n",
       "            0.177 , 0.1753, 0.1748, 0.1731, 0.1719, 0.1718, 0.1664, 0.1658,\n",
       "            0.1636, 0.1588, 0.1475], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15833333, 0.16666667, 0.175     , 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.23333333, 0.25      , 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35      , 0.35      , 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.41666666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.59166664, 0.6       , 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.675     , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.71666664, 0.725     , 0.725     , 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.775     , 0.775     , 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8       , 0.80833334,\n",
       "            0.80833334, 0.80833334, 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.80833334, 0.80833334, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.8333333 , 0.84166664,\n",
       "            0.84166664, 0.84166664, 0.85      , 0.85      , 0.85833335,\n",
       "            0.85833335, 0.8666667 , 0.8666667 , 0.8666667 , 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.8833333 , 0.8833333 ,\n",
       "            0.8833333 , 0.89166665, 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.11538462, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16153847, 0.16923077, 0.16923077,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.24615385, 0.26153848, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2846154 , 0.2923077 , 0.2923077 , 0.2923077 , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36153847, 0.36153847,\n",
       "            0.36923078, 0.3846154 , 0.3923077 , 0.4       , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.43846154, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.5       , 0.50769234, 0.50769234, 0.5153846 ,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5692308 , 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.6076923 , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3586, 0.3574, 0.3567, 0.3564, 0.355 , 0.354 , 0.3538,\n",
       "            0.3528, 0.3525, 0.351 , 0.35  , 0.3494, 0.3464, 0.339 , 0.3372,\n",
       "            0.3354, 0.334 , 0.3325, 0.3313, 0.3281, 0.328 , 0.3267, 0.3252,\n",
       "            0.325 , 0.3242, 0.322 , 0.321 , 0.3208, 0.319 , 0.318 , 0.3137,\n",
       "            0.3123, 0.312 , 0.311 , 0.3093, 0.3086, 0.306 , 0.3047, 0.3044,\n",
       "            0.299 , 0.2988, 0.2983, 0.298 , 0.2974, 0.297 , 0.2944, 0.2937,\n",
       "            0.292 , 0.291 , 0.2908, 0.2903, 0.2893, 0.2888, 0.2883, 0.2874,\n",
       "            0.2869, 0.2864, 0.286 , 0.2854, 0.284 , 0.2832, 0.2827, 0.2825,\n",
       "            0.2822, 0.282 , 0.2817, 0.2815, 0.281 , 0.2805, 0.28  , 0.2798,\n",
       "            0.2793, 0.2786, 0.2776, 0.2773, 0.277 , 0.2769, 0.2764, 0.276 ,\n",
       "            0.2742, 0.2737, 0.2734, 0.2722, 0.272 , 0.2712, 0.27  , 0.2698,\n",
       "            0.2693, 0.2686, 0.268 , 0.2678, 0.2676, 0.2673, 0.267 , 0.2656,\n",
       "            0.2646, 0.2637, 0.263 , 0.2627, 0.2625, 0.2612, 0.261 , 0.2603,\n",
       "            0.2598, 0.2595, 0.2588, 0.2583, 0.2576, 0.257 , 0.2568, 0.256 ,\n",
       "            0.2556, 0.2551, 0.2534, 0.2527, 0.2517, 0.2515, 0.251 , 0.2507,\n",
       "            0.2505, 0.2502, 0.25  , 0.2498, 0.2494, 0.2487, 0.2482, 0.2478,\n",
       "            0.2474, 0.2473, 0.247 , 0.2467, 0.2462, 0.2452, 0.2448, 0.2437,\n",
       "            0.2426, 0.2422, 0.2413, 0.241 , 0.2399, 0.2379, 0.2362, 0.2356,\n",
       "            0.2355, 0.234 , 0.2335, 0.2334, 0.2328, 0.2327, 0.2325, 0.2294,\n",
       "            0.2283, 0.228 , 0.2272, 0.2261, 0.226 , 0.2256, 0.2244, 0.224 ,\n",
       "            0.2239, 0.2213, 0.2207, 0.22  , 0.219 , 0.2184, 0.2179, 0.2166,\n",
       "            0.2153, 0.2142, 0.214 , 0.2139, 0.2137, 0.2134, 0.2129, 0.2118,\n",
       "            0.2114, 0.2109, 0.2106, 0.2101, 0.2091, 0.2089, 0.2076, 0.2054,\n",
       "            0.205 , 0.2039, 0.2034, 0.2031, 0.2029, 0.2026, 0.2023, 0.1982,\n",
       "            0.1943, 0.1936, 0.1931, 0.1929, 0.1904, 0.187 , 0.1859, 0.1853,\n",
       "            0.1848, 0.1836, 0.1792, 0.1774, 0.1764, 0.1752, 0.1727, 0.1726,\n",
       "            0.1721, 0.1681, 0.1597, 0.1436], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.025     , 0.03333334, 0.05833333,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.2       , 0.21666667,\n",
       "            0.21666667, 0.225     , 0.24166666, 0.25      , 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.275     , 0.275     , 0.275     , 0.28333333, 0.28333333,\n",
       "            0.29166666, 0.3       , 0.3       , 0.3       , 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.325     , 0.33333334, 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.425     ,\n",
       "            0.425     , 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55      , 0.55      , 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.59166664, 0.6       ,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65833336, 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.675     , 0.675     , 0.675     , 0.68333334,\n",
       "            0.68333334, 0.68333334, 0.68333334, 0.68333334, 0.68333334,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.75      , 0.7583333 , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.84166664,\n",
       "            0.84166664, 0.85      , 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.90833336, 0.90833336, 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.14615385, 0.15384616, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.17692308, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.20769231, 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.22307692, 0.23076923, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2769231 , 0.2846154 ,\n",
       "            0.3       , 0.30769232, 0.30769232, 0.32307693, 0.33076924,\n",
       "            0.34615386, 0.35384616, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3846154 , 0.3923077 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.41538462, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.45384616, 0.46153846, 0.46153846, 0.46153846, 0.46153846,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.56153846, 0.5692308 , 0.5692308 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.61538464, 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6923077 , 0.7       , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.8769231 ,\n",
       "            0.8769231 , 0.8769231 , 0.88461536, 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.367 , 0.3665, 0.3655, 0.3652, 0.3638, 0.3635, 0.3623,\n",
       "            0.3594, 0.357 , 0.3555, 0.351 , 0.346 , 0.3428, 0.3425, 0.3403,\n",
       "            0.3398, 0.339 , 0.336 , 0.3357, 0.3347, 0.3315, 0.3306, 0.3298,\n",
       "            0.3289, 0.3286, 0.3276, 0.3262, 0.3254, 0.3235, 0.323 , 0.3225,\n",
       "            0.3223, 0.3215, 0.3198, 0.3196, 0.319 , 0.3186, 0.3176, 0.3174,\n",
       "            0.3171, 0.3157, 0.3137, 0.3135, 0.3132, 0.3125, 0.3123, 0.3115,\n",
       "            0.3113, 0.3108, 0.31  , 0.309 , 0.3074, 0.307 , 0.3066, 0.3064,\n",
       "            0.306 , 0.3052, 0.3044, 0.304 , 0.3037, 0.3035, 0.3032, 0.3027,\n",
       "            0.3025, 0.3018, 0.301 , 0.3005, 0.2993, 0.299 , 0.298 , 0.2979,\n",
       "            0.2974, 0.2961, 0.2947, 0.292 , 0.291 , 0.2903, 0.29  , 0.289 ,\n",
       "            0.2886, 0.2883, 0.2874, 0.2856, 0.2854, 0.285 , 0.2837, 0.2827,\n",
       "            0.2825, 0.2822, 0.2815, 0.2805, 0.28  , 0.2793, 0.2786, 0.2776,\n",
       "            0.277 , 0.2766, 0.2761, 0.276 , 0.2754, 0.2751, 0.275 , 0.2747,\n",
       "            0.2742, 0.274 , 0.2737, 0.2732, 0.2722, 0.2715, 0.2712, 0.2703,\n",
       "            0.2688, 0.2686, 0.2683, 0.268 , 0.2673, 0.267 , 0.2668, 0.2666,\n",
       "            0.266 , 0.2646, 0.2642, 0.263 , 0.2622, 0.262 , 0.2612, 0.2595,\n",
       "            0.2578, 0.2573, 0.2568, 0.2566, 0.2551, 0.2544, 0.254 , 0.2534,\n",
       "            0.2512, 0.251 , 0.2507, 0.25  , 0.2498, 0.2493, 0.2478, 0.2473,\n",
       "            0.2467, 0.2466, 0.2462, 0.2451, 0.2445, 0.243 , 0.2407, 0.2397,\n",
       "            0.2394, 0.239 , 0.237 , 0.2367, 0.2366, 0.2358, 0.2351, 0.234 ,\n",
       "            0.2339, 0.2316, 0.2311, 0.231 , 0.2294, 0.2292, 0.2286, 0.2281,\n",
       "            0.2252, 0.2239, 0.222 , 0.22  , 0.2197, 0.2194, 0.2185, 0.2184,\n",
       "            0.2181, 0.218 , 0.2157, 0.2139, 0.2133, 0.2128, 0.212 , 0.2054,\n",
       "            0.2043, 0.204 , 0.2035, 0.2034, 0.1978, 0.1942, 0.1918, 0.1892,\n",
       "            0.183 , 0.1823, 0.1821, 0.1813, 0.1796, 0.1763, 0.1678, 0.1665,\n",
       "            0.1449], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.175     , 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.19166666, 0.20833333, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.225     , 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.29166666, 0.3       , 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.375     , 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.525     , 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.6666667 , 0.675     , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.7416667 , 0.7416667 ,\n",
       "            0.75      , 0.75      , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.80833334, 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.8833333 , 0.9       ,\n",
       "            0.90833336, 0.90833336, 0.9166667 , 0.925     , 0.925     ,\n",
       "            0.94166666, 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.9916667 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.1       , 0.10769231, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16923077, 0.17692308, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.22307692, 0.23076923, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.23846154, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.2769231 , 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.32307693, 0.33846155,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4076923 , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.52307695, 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.5538462 , 0.5538462 , 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6       , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7076923 ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.75384617, 0.75384617, 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.8769231 , 0.8769231 , 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3792, 0.3782, 0.3774, 0.3772, 0.377 , 0.3765, 0.3743,\n",
       "            0.374 , 0.3733, 0.3713, 0.3706, 0.3687, 0.3662, 0.365 , 0.3618,\n",
       "            0.3608, 0.3604, 0.3594, 0.3577, 0.3567, 0.3533, 0.351 , 0.3486,\n",
       "            0.3484, 0.3467, 0.3464, 0.3457, 0.3452, 0.3447, 0.3442, 0.3435,\n",
       "            0.3433, 0.343 , 0.3425, 0.3416, 0.341 , 0.3408, 0.3403, 0.3389,\n",
       "            0.3386, 0.3364, 0.3362, 0.335 , 0.3347, 0.3345, 0.334 , 0.3333,\n",
       "            0.3325, 0.3306, 0.33  , 0.3296, 0.329 , 0.3289, 0.3286, 0.3281,\n",
       "            0.328 , 0.3274, 0.3271, 0.327 , 0.3267, 0.3264, 0.325 , 0.3245,\n",
       "            0.3232, 0.3228, 0.3223, 0.3218, 0.3215, 0.3203, 0.3193, 0.3186,\n",
       "            0.318 , 0.316 , 0.3154, 0.3152, 0.3145, 0.3142, 0.3137, 0.313 ,\n",
       "            0.3115, 0.3108, 0.3098, 0.309 , 0.3086, 0.3083, 0.3074, 0.3064,\n",
       "            0.3057, 0.3052, 0.305 , 0.3042, 0.3037, 0.3035, 0.3032, 0.3027,\n",
       "            0.3025, 0.3018, 0.3013, 0.3005, 0.2998, 0.2986, 0.297 , 0.2961,\n",
       "            0.2957, 0.2954, 0.2952, 0.295 , 0.2947, 0.2944, 0.2932, 0.2927,\n",
       "            0.2925, 0.2913, 0.2903, 0.2898, 0.2896, 0.289 , 0.2888, 0.2886,\n",
       "            0.288 , 0.2878, 0.2874, 0.2869, 0.2864, 0.2861, 0.286 , 0.285 ,\n",
       "            0.2847, 0.2844, 0.2834, 0.2815, 0.2812, 0.281 , 0.28  , 0.2793,\n",
       "            0.279 , 0.277 , 0.2766, 0.2754, 0.2722, 0.2705, 0.27  , 0.269 ,\n",
       "            0.2676, 0.2664, 0.2654, 0.2646, 0.264 , 0.2617, 0.2605, 0.2583,\n",
       "            0.2573, 0.2556, 0.2551, 0.2534, 0.251 , 0.2502, 0.2496, 0.2478,\n",
       "            0.2473, 0.2445, 0.2444, 0.2433, 0.2421, 0.2415, 0.2399, 0.2384,\n",
       "            0.2383, 0.2382, 0.2372, 0.2367, 0.2358, 0.2344, 0.2322, 0.2316,\n",
       "            0.2314, 0.2297, 0.2292, 0.2281, 0.2249, 0.2244, 0.224 , 0.2218,\n",
       "            0.2212, 0.2203, 0.219 , 0.2158, 0.2104, 0.2086, 0.2075, 0.2037,\n",
       "            0.2001, 0.1937, 0.1931, 0.1901, 0.1836, 0.18  , 0.1696, 0.1588,\n",
       "            0.15  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.08333334, 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "            0.1       , 0.1       , 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.24166666, 0.25      , 0.25      ,\n",
       "            0.25      , 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.275     , 0.275     , 0.275     , 0.275     , 0.275     ,\n",
       "            0.275     , 0.28333333, 0.28333333, 0.29166666, 0.29166666,\n",
       "            0.29166666, 0.29166666, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.3       , 0.3       , 0.30833334, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.49166667, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.525     , 0.53333336,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7083333 , 0.71666664,\n",
       "            0.71666664, 0.71666664, 0.725     , 0.725     , 0.725     ,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.81666666, 0.825     , 0.825     , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.85833335, 0.85833335, 0.8666667 , 0.8666667 ,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.08461539, 0.1       ,\n",
       "            0.10769231, 0.10769231, 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16153847, 0.16153847, 0.16923077, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.18461539, 0.2       , 0.2       , 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.3       , 0.30769232, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.37692308, 0.37692308,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.43846154, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4923077 , 0.5       , 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.5538462 , 0.56153846, 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.61538464, 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.64615387, 0.64615387,\n",
       "            0.65384614, 0.66923076, 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7153846 , 0.7153846 , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3975, 0.3965, 0.396 , 0.3945, 0.394 , 0.3938, 0.393 ,\n",
       "            0.3918, 0.3914, 0.391 , 0.389 , 0.3882, 0.388 , 0.3875, 0.387 ,\n",
       "            0.3865, 0.3862, 0.3857, 0.3855, 0.385 , 0.3843, 0.384 , 0.3838,\n",
       "            0.3833, 0.3823, 0.382 , 0.381 , 0.3804, 0.3792, 0.3784, 0.3772,\n",
       "            0.377 , 0.3765, 0.3743, 0.3735, 0.372 , 0.3718, 0.3704, 0.37  ,\n",
       "            0.3691, 0.369 , 0.3674, 0.3667, 0.3662, 0.366 , 0.3657, 0.3655,\n",
       "            0.365 , 0.3647, 0.364 , 0.3638, 0.3635, 0.363 , 0.362 , 0.3613,\n",
       "            0.361 , 0.3608, 0.3606, 0.3591, 0.3564, 0.3562, 0.356 , 0.355 ,\n",
       "            0.3542, 0.3538, 0.3533, 0.3525, 0.3516, 0.3506, 0.3503, 0.3499,\n",
       "            0.348 , 0.3467, 0.3455, 0.3442, 0.3428, 0.3425, 0.3418, 0.3416,\n",
       "            0.3408, 0.3403, 0.3396, 0.3394, 0.3386, 0.338 , 0.3376, 0.3372,\n",
       "            0.3362, 0.3357, 0.3354, 0.3352, 0.335 , 0.3347, 0.334 , 0.3325,\n",
       "            0.3323, 0.3313, 0.331 , 0.3308, 0.3306, 0.3298, 0.3296, 0.3293,\n",
       "            0.3289, 0.3286, 0.328 , 0.3274, 0.3271, 0.327 , 0.3267, 0.3254,\n",
       "            0.3252, 0.3247, 0.3245, 0.3242, 0.3235, 0.3225, 0.3223, 0.322 ,\n",
       "            0.3218, 0.3213, 0.321 , 0.3208, 0.32  , 0.3184, 0.318 , 0.317 ,\n",
       "            0.3164, 0.316 , 0.3147, 0.3137, 0.3127, 0.311 , 0.309 , 0.3086,\n",
       "            0.308 , 0.3079, 0.307 , 0.3066, 0.3064, 0.3042, 0.304 , 0.3025,\n",
       "            0.3008, 0.3003, 0.2998, 0.2996, 0.2988, 0.2983, 0.297 , 0.2957,\n",
       "            0.2944, 0.2925, 0.292 , 0.2917, 0.2903, 0.2898, 0.2844, 0.282 ,\n",
       "            0.2805, 0.28  , 0.278 , 0.2769, 0.2761, 0.2747, 0.2742, 0.2727,\n",
       "            0.2722, 0.2703, 0.27  , 0.268 , 0.2678, 0.2673, 0.266 , 0.2654,\n",
       "            0.2646, 0.2642, 0.263 , 0.2625, 0.2546, 0.253 , 0.2522, 0.2498,\n",
       "            0.249 , 0.2489, 0.2463, 0.2458, 0.2451, 0.2424, 0.2418, 0.2407,\n",
       "            0.2391, 0.2355, 0.2325, 0.2283, 0.2281, 0.228 , 0.2274, 0.2247,\n",
       "            0.2238, 0.2224, 0.2203, 0.2175, 0.2144, 0.2133, 0.2104, 0.2096,\n",
       "            0.2068, 0.1995, 0.1765, 0.1641, 0.1594, 0.1521], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05      , 0.06666667, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.08333334, 0.09166667, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.1       , 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.16666667, 0.16666667, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.18333334, 0.18333334,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.23333333, 0.23333333,\n",
       "            0.24166666, 0.24166666, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.25833333, 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.26666668, 0.26666668, 0.275     , 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.36666667,\n",
       "            0.36666667, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.475     , 0.48333332, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.525     , 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65      , 0.65      , 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.71666664, 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.84166664, 0.85      , 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.90833336, 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.01538462, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.07692308, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.15384616, 0.16153847,\n",
       "            0.16153847, 0.16153847, 0.17692308, 0.17692308, 0.1923077 ,\n",
       "            0.20769231, 0.20769231, 0.21538462, 0.21538462, 0.21538462,\n",
       "            0.22307692, 0.22307692, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.2769231 , 0.2846154 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.30769232, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4076923 , 0.42307693,\n",
       "            0.42307693, 0.43076923, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.5923077 , 0.6       , 0.6076923 , 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63076925, 0.63846153, 0.65384614,\n",
       "            0.6615385 , 0.6615385 , 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.7       , 0.7       ,\n",
       "            0.7153846 , 0.73846155, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.86923075, 0.86923075,\n",
       "            0.86923075, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.436 , 0.4355, 0.4321, 0.4316, 0.431 , 0.4307, 0.4304,\n",
       "            0.4297, 0.4287, 0.4272, 0.4255, 0.4246, 0.4243, 0.4219, 0.4214,\n",
       "            0.4202, 0.4197, 0.4187, 0.4182, 0.4177, 0.416 , 0.4158, 0.4148,\n",
       "            0.4146, 0.414 , 0.4128, 0.412 , 0.4116, 0.4111, 0.408 , 0.4077,\n",
       "            0.4067, 0.406 , 0.4058, 0.4053, 0.405 , 0.4048, 0.4045, 0.4043,\n",
       "            0.4036, 0.403 , 0.4028, 0.4026, 0.4023, 0.4019, 0.4011, 0.401 ,\n",
       "            0.4006, 0.4004, 0.4001, 0.3997, 0.3992, 0.399 , 0.3984, 0.3967,\n",
       "            0.3962, 0.396 , 0.3955, 0.3943, 0.3933, 0.3928, 0.3923, 0.3918,\n",
       "            0.3916, 0.391 , 0.3904, 0.3901, 0.3892, 0.3884, 0.388 , 0.3867,\n",
       "            0.3857, 0.3843, 0.384 , 0.3833, 0.3828, 0.3823, 0.382 , 0.3818,\n",
       "            0.3813, 0.3806, 0.3804, 0.38  , 0.379 , 0.3782, 0.378 , 0.3772,\n",
       "            0.3762, 0.376 , 0.375 , 0.3748, 0.3745, 0.3735, 0.3733, 0.373 ,\n",
       "            0.371 , 0.3708, 0.37  , 0.3699, 0.3696, 0.3694, 0.368 , 0.366 ,\n",
       "            0.365 , 0.3647, 0.3645, 0.3628, 0.3625, 0.362 , 0.3616, 0.361 ,\n",
       "            0.3606, 0.3604, 0.3596, 0.3591, 0.356 , 0.3557, 0.3552, 0.355 ,\n",
       "            0.354 , 0.3533, 0.351 , 0.3481, 0.3477, 0.3472, 0.344 , 0.3438,\n",
       "            0.343 , 0.3425, 0.3418, 0.341 , 0.3408, 0.339 , 0.3381, 0.3372,\n",
       "            0.336 , 0.3345, 0.3333, 0.3315, 0.3313, 0.3303, 0.3298, 0.328 ,\n",
       "            0.327 , 0.3242, 0.3235, 0.323 , 0.3228, 0.318 , 0.3176, 0.3154,\n",
       "            0.315 , 0.314 , 0.3137, 0.3135, 0.312 , 0.3118, 0.3115, 0.3105,\n",
       "            0.308 , 0.3079, 0.3076, 0.3062, 0.306 , 0.3057, 0.305 , 0.3008,\n",
       "            0.2969, 0.2964, 0.2932, 0.287 , 0.2866, 0.2864, 0.2834, 0.281 ,\n",
       "            0.2808, 0.28  , 0.2766, 0.2756, 0.2744, 0.2722, 0.268 , 0.2678,\n",
       "            0.2666, 0.266 , 0.2644, 0.2625, 0.2588, 0.2585, 0.2563, 0.2502,\n",
       "            0.2452, 0.2438, 0.2424, 0.2368, 0.2347, 0.233 , 0.2327, 0.2286,\n",
       "            0.2257, 0.2233, 0.2207, 0.2203, 0.2191, 0.219 , 0.2133, 0.2026,\n",
       "            0.1765, 0.1729, 0.1625, 0.149 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.075     , 0.075     , 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.09166667, 0.1       , 0.1       ,\n",
       "            0.1       , 0.10833333, 0.125     , 0.125     , 0.125     ,\n",
       "            0.125     , 0.125     , 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15      , 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.175     , 0.18333334,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.26666668, 0.26666668, 0.275     , 0.275     ,\n",
       "            0.275     , 0.275     , 0.28333333, 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.3       , 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.325     , 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.34166667, 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.425     , 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.85833335, 0.85833335,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.24615385, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.32307693, 0.33076924, 0.33846155, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.3923077 , 0.4076923 ,\n",
       "            0.41538462, 0.41538462, 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46923077, 0.46923077,\n",
       "            0.46923077, 0.46923077, 0.47692308, 0.4846154 , 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.53846157, 0.54615384, 0.56153846, 0.5692308 ,\n",
       "            0.5692308 , 0.5692308 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.6076923 , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.6615385 , 0.6769231 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7076923 , 0.7153846 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.75384617,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.497 , 0.4963, 0.4924, 0.4868, 0.485 , 0.4844, 0.483 ,\n",
       "            0.4824, 0.4814, 0.4778, 0.4766, 0.4746, 0.4736, 0.4727, 0.4722,\n",
       "            0.472 , 0.4702, 0.4695, 0.4688, 0.4666, 0.4656, 0.4648, 0.4636,\n",
       "            0.4634, 0.4622, 0.4617, 0.4597, 0.4585, 0.4583, 0.4573, 0.457 ,\n",
       "            0.456 , 0.4558, 0.4548, 0.4543, 0.454 , 0.4524, 0.4521, 0.4514,\n",
       "            0.4512, 0.451 , 0.4504, 0.45  , 0.4495, 0.4492, 0.4487, 0.4485,\n",
       "            0.4482, 0.4478, 0.4475, 0.4473, 0.447 , 0.4465, 0.4463, 0.446 ,\n",
       "            0.4458, 0.445 , 0.4448, 0.4443, 0.4438, 0.4436, 0.443 , 0.4421,\n",
       "            0.4417, 0.4414, 0.44  , 0.4385, 0.4377, 0.4375, 0.437 , 0.4368,\n",
       "            0.4365, 0.436 , 0.4358, 0.4355, 0.435 , 0.4348, 0.4333, 0.4329,\n",
       "            0.4326, 0.4304, 0.4302, 0.4294, 0.4275, 0.427 , 0.4263, 0.4243,\n",
       "            0.424 , 0.4238, 0.4236, 0.4224, 0.422 , 0.4219, 0.421 , 0.4197,\n",
       "            0.419 , 0.4187, 0.4185, 0.4175, 0.4172, 0.4163, 0.416 , 0.4155,\n",
       "            0.4153, 0.4143, 0.4124, 0.412 , 0.4119, 0.4116, 0.4104, 0.4102,\n",
       "            0.4097, 0.409 , 0.4082, 0.4077, 0.4065, 0.4058, 0.405 , 0.4048,\n",
       "            0.4038, 0.4036, 0.4014, 0.4011, 0.4004, 0.4001, 0.3975, 0.397 ,\n",
       "            0.396 , 0.3955, 0.3936, 0.391 , 0.3896, 0.3855, 0.385 , 0.3838,\n",
       "            0.3804, 0.3796, 0.3794, 0.3777, 0.3728, 0.3716, 0.3691, 0.3684,\n",
       "            0.3677, 0.367 , 0.3662, 0.3652, 0.3618, 0.3613, 0.3606, 0.3594,\n",
       "            0.3582, 0.358 , 0.3574, 0.3567, 0.3545, 0.354 , 0.3538, 0.3523,\n",
       "            0.3506, 0.3499, 0.3496, 0.3484, 0.346 , 0.3452, 0.3433, 0.342 ,\n",
       "            0.3418, 0.3398, 0.3345, 0.334 , 0.3328, 0.3296, 0.3293, 0.328 ,\n",
       "            0.3247, 0.324 , 0.3235, 0.32  , 0.3198, 0.319 , 0.3176, 0.3164,\n",
       "            0.3098, 0.3088, 0.3086, 0.3054, 0.3052, 0.305 , 0.304 , 0.3015,\n",
       "            0.3005, 0.3003, 0.297 , 0.2964, 0.2905, 0.2847, 0.2825, 0.279 ,\n",
       "            0.2744, 0.27  , 0.2695, 0.266 , 0.2656, 0.2646, 0.2605, 0.2598,\n",
       "            0.2517, 0.25  , 0.2474, 0.2375, 0.2346, 0.2224, 0.2186, 0.218 ,\n",
       "            0.2163, 0.213 , 0.2119, 0.2096, 0.1978, 0.1947, 0.1687, 0.1606,\n",
       "            0.1455], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04166667, dtype=float32),\n",
       "    'tpr': array(0.2846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.06666667, 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.1       ,\n",
       "            0.1       , 0.1       , 0.1       , 0.1       , 0.10833333,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.125     , 0.13333334,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15833333, 0.15833333, 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "            0.2       , 0.2       , 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.25      , 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.29166666, 0.3       , 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.525     , 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.69166666, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.9166667 , 0.925     , 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.26923078, 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.32307693, 0.33846155, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.4923077 , 0.50769234, 0.50769234, 0.5153846 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.56153846, 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6230769 , 0.63076925, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.7692308 , 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.567 , 0.5557, 0.5483, 0.5405, 0.5366, 0.5347, 0.533 ,\n",
       "            0.532 , 0.5303, 0.53  , 0.5283, 0.528 , 0.527 , 0.526 , 0.5244,\n",
       "            0.5234, 0.523 , 0.522 , 0.5195, 0.518 , 0.5176, 0.517 , 0.516 ,\n",
       "            0.515 , 0.5127, 0.511 , 0.5103, 0.51  , 0.509 , 0.5083, 0.5073,\n",
       "            0.507 , 0.506 , 0.5044, 0.5015, 0.501 , 0.5005, 0.5   , 0.498 ,\n",
       "            0.4976, 0.497 , 0.4968, 0.496 , 0.4956, 0.4944, 0.494 , 0.4937,\n",
       "            0.4934, 0.4927, 0.4924, 0.4922, 0.492 , 0.4915, 0.491 , 0.4907,\n",
       "            0.4897, 0.4888, 0.488 , 0.4875, 0.4873, 0.4868, 0.4856, 0.485 ,\n",
       "            0.4834, 0.4812, 0.4805, 0.4802, 0.4795, 0.4788, 0.4778, 0.4753,\n",
       "            0.475 , 0.4736, 0.4724, 0.4717, 0.471 , 0.4705, 0.47  , 0.469 ,\n",
       "            0.468 , 0.4668, 0.4656, 0.4644, 0.4639, 0.463 , 0.4624, 0.4617,\n",
       "            0.461 , 0.4602, 0.4595, 0.4592, 0.459 , 0.4585, 0.4573, 0.4565,\n",
       "            0.4563, 0.456 , 0.4558, 0.4543, 0.4534, 0.4526, 0.4492, 0.4485,\n",
       "            0.4473, 0.447 , 0.4446, 0.4438, 0.4424, 0.4417, 0.441 , 0.4387,\n",
       "            0.4382, 0.4363, 0.435 , 0.4343, 0.4314, 0.4297, 0.4292, 0.4263,\n",
       "            0.426 , 0.4238, 0.4236, 0.4216, 0.421 , 0.4202, 0.4192, 0.418 ,\n",
       "            0.417 , 0.4146, 0.413 , 0.409 , 0.4075, 0.4058, 0.4053, 0.4048,\n",
       "            0.4038, 0.4036, 0.4023, 0.3997, 0.3994, 0.399 , 0.3975, 0.3972,\n",
       "            0.397 , 0.392 , 0.3914, 0.3857, 0.3796, 0.3767, 0.3765, 0.3762,\n",
       "            0.37  , 0.365 , 0.3647, 0.361 , 0.3608, 0.3596, 0.3591, 0.3564,\n",
       "            0.353 , 0.3523, 0.349 , 0.3462, 0.344 , 0.3372, 0.3362, 0.333 ,\n",
       "            0.3308, 0.3303, 0.3298, 0.328 , 0.327 , 0.3262, 0.3257, 0.322 ,\n",
       "            0.3196, 0.3193, 0.316 , 0.3137, 0.31  , 0.308 , 0.3074, 0.3013,\n",
       "            0.298 , 0.2969, 0.2964, 0.2913, 0.2908, 0.2896, 0.286 , 0.276 ,\n",
       "            0.2708, 0.2676, 0.264 , 0.2544, 0.2502, 0.2458, 0.2405, 0.2278,\n",
       "            0.2266, 0.217 , 0.2129, 0.2123, 0.208 , 0.206 , 0.2021, 0.1971,\n",
       "            0.1831, 0.1605, 0.1544, 0.138 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.19166666, dtype=float32),\n",
       "    'tpr': array(0.7307692, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.1       , 0.1       ,\n",
       "            0.10833333, 0.10833333, 0.10833333, 0.10833333, 0.10833333,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.175     , 0.175     ,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.31666666, 0.325     , 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.60833335, 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.73333335,\n",
       "            0.7416667 , 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.775     , 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.08461539, 0.09230769, 0.1       , 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.32307693, 0.33846155, 0.34615386, 0.36153847,\n",
       "            0.36923078, 0.36923078, 0.3923077 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.44615385, 0.45384616, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.50769234, 0.5153846 ,\n",
       "            0.5307692 , 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.6615385 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.7307692 , 0.7307692 , 0.7307692 , 0.7307692 ,\n",
       "            0.7307692 , 0.7307692 , 0.73846155, 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6323, 0.6113, 0.601 , 0.5938, 0.5923, 0.588 , 0.585 ,\n",
       "            0.584 , 0.5835, 0.5815, 0.58  , 0.5796, 0.578 , 0.5757, 0.575 ,\n",
       "            0.574 , 0.5723, 0.571 , 0.5703, 0.569 , 0.568 , 0.567 , 0.5664,\n",
       "            0.565 , 0.564 , 0.5625, 0.562 , 0.561 , 0.56  , 0.5596, 0.5566,\n",
       "            0.5557, 0.5547, 0.5537, 0.553 , 0.5527, 0.5522, 0.551 , 0.5503,\n",
       "            0.55  , 0.5493, 0.549 , 0.5474, 0.546 , 0.5425, 0.542 , 0.5415,\n",
       "            0.541 , 0.5405, 0.538 , 0.5376, 0.5366, 0.536 , 0.535 , 0.5347,\n",
       "            0.534 , 0.5337, 0.533 , 0.5327, 0.532 , 0.531 , 0.5293, 0.528 ,\n",
       "            0.5273, 0.5264, 0.526 , 0.5254, 0.525 , 0.524 , 0.5215, 0.52  ,\n",
       "            0.519 , 0.5186, 0.518 , 0.517 , 0.5166, 0.516 , 0.5146, 0.5127,\n",
       "            0.5117, 0.51  , 0.509 , 0.5083, 0.508 , 0.507 , 0.5063, 0.5054,\n",
       "            0.5034, 0.5024, 0.502 , 0.5015, 0.4976, 0.4963, 0.4949, 0.4941,\n",
       "            0.4932, 0.4922, 0.4912, 0.491 , 0.4902, 0.4897, 0.4885, 0.4883,\n",
       "            0.4875, 0.4873, 0.487 , 0.4868, 0.485 , 0.484 , 0.4802, 0.4778,\n",
       "            0.4775, 0.4763, 0.475 , 0.4749, 0.4739, 0.4724, 0.4722, 0.472 ,\n",
       "            0.4685, 0.4658, 0.463 , 0.4624, 0.4607, 0.458 , 0.4546, 0.453 ,\n",
       "            0.4526, 0.4524, 0.4514, 0.4502, 0.4482, 0.4478, 0.4465, 0.4463,\n",
       "            0.445 , 0.444 , 0.4407, 0.4375, 0.4368, 0.4326, 0.431 , 0.43  ,\n",
       "            0.4263, 0.4238, 0.4216, 0.4207, 0.42  , 0.4197, 0.4172, 0.4167,\n",
       "            0.4158, 0.4065, 0.404 , 0.3933, 0.3843, 0.3828, 0.3826, 0.3752,\n",
       "            0.3713, 0.3708, 0.3691, 0.369 , 0.368 , 0.3647, 0.3643, 0.3623,\n",
       "            0.3604, 0.3572, 0.3555, 0.3516, 0.351 , 0.35  , 0.3484, 0.3464,\n",
       "            0.344 , 0.337 , 0.3347, 0.334 , 0.3335, 0.331 , 0.3303, 0.3281,\n",
       "            0.327 , 0.3257, 0.325 , 0.3245, 0.3167, 0.3147, 0.3088, 0.2996,\n",
       "            0.2974, 0.2927, 0.2915, 0.2864, 0.2825, 0.269 , 0.2678, 0.2515,\n",
       "            0.2482, 0.2429, 0.2355, 0.2335, 0.2246, 0.2185, 0.2153, 0.2103,\n",
       "            0.204 , 0.2031, 0.2006, 0.1946, 0.188 , 0.1752, 0.156 , 0.1519,\n",
       "            0.134 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.35, dtype=float32),\n",
       "    'tpr': array(0.8230769, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.1       , 0.10833333, 0.10833333,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.125     , 0.125     , 0.13333334, 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15      , 0.15      , 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.16666667, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.18333334, 0.19166666, 0.19166666, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.24166666, 0.25      , 0.25      ,\n",
       "            0.25      , 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "            0.26666668, 0.275     , 0.275     , 0.28333333, 0.29166666,\n",
       "            0.31666666, 0.325     , 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.375     , 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.7       , 0.7       , 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.41538462, 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.5       , 0.50769234, 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.64615387, 0.6615385 , 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.72307694, 0.72307694, 0.72307694, 0.72307694,\n",
       "            0.7307692 , 0.7307692 , 0.73846155, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.86923075, 0.8769231 , 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6885, 0.6606, 0.6484, 0.648 , 0.6387, 0.6357, 0.6343,\n",
       "            0.6323, 0.628 , 0.6265, 0.626 , 0.625 , 0.6216, 0.621 , 0.618 ,\n",
       "            0.6177, 0.6167, 0.615 , 0.6143, 0.6133, 0.613 , 0.6113, 0.611 ,\n",
       "            0.6104, 0.61  , 0.609 , 0.6084, 0.6045, 0.602 , 0.6016, 0.5996,\n",
       "            0.5986, 0.598 , 0.5977, 0.5967, 0.596 , 0.5947, 0.5938, 0.5933,\n",
       "            0.593 , 0.5913, 0.591 , 0.5903, 0.5884, 0.588 , 0.587 , 0.5864,\n",
       "            0.5854, 0.585 , 0.584 , 0.583 , 0.5815, 0.5806, 0.58  , 0.5796,\n",
       "            0.5786, 0.577 , 0.5747, 0.574 , 0.5737, 0.5728, 0.571 , 0.57  ,\n",
       "            0.5693, 0.569 , 0.5684, 0.5674, 0.5664, 0.566 , 0.5654, 0.565 ,\n",
       "            0.5645, 0.564 , 0.563 , 0.5625, 0.5615, 0.5605, 0.56  , 0.5566,\n",
       "            0.556 , 0.5557, 0.554 , 0.5537, 0.553 , 0.551 , 0.5503, 0.55  ,\n",
       "            0.549 , 0.5483, 0.5474, 0.5464, 0.546 , 0.545 , 0.5435, 0.5415,\n",
       "            0.54  , 0.539 , 0.536 , 0.533 , 0.5293, 0.529 , 0.5283, 0.528 ,\n",
       "            0.5264, 0.526 , 0.5254, 0.525 , 0.523 , 0.52  , 0.517 , 0.5156,\n",
       "            0.515 , 0.5146, 0.5137, 0.5127, 0.511 , 0.5107, 0.5103, 0.51  ,\n",
       "            0.502 , 0.5015, 0.4998, 0.4993, 0.498 , 0.4968, 0.4966, 0.4958,\n",
       "            0.4956, 0.494 , 0.4912, 0.4905, 0.4893, 0.4841, 0.483 , 0.4795,\n",
       "            0.479 , 0.4785, 0.4739, 0.4714, 0.4675, 0.4668, 0.4653, 0.4622,\n",
       "            0.4617, 0.4573, 0.4539, 0.4531, 0.4526, 0.4512, 0.4492, 0.4404,\n",
       "            0.4358, 0.4343, 0.4314, 0.4268, 0.4243, 0.4172, 0.4097, 0.4058,\n",
       "            0.4048, 0.4033, 0.393 , 0.3918, 0.3882, 0.388 , 0.3865, 0.3848,\n",
       "            0.378 , 0.3762, 0.376 , 0.375 , 0.3718, 0.3713, 0.3657, 0.3643,\n",
       "            0.364 , 0.361 , 0.3574, 0.3557, 0.3484, 0.3481, 0.3367, 0.3342,\n",
       "            0.334 , 0.3333, 0.331 , 0.3276, 0.3247, 0.3206, 0.317 , 0.3098,\n",
       "            0.2993, 0.2986, 0.2974, 0.2964, 0.2957, 0.293 , 0.27  , 0.2646,\n",
       "            0.2573, 0.2498, 0.2482, 0.236 , 0.2268, 0.2212, 0.2133, 0.2108,\n",
       "            0.208 , 0.2017, 0.1982, 0.1936, 0.1873, 0.1794, 0.1675, 0.1515,\n",
       "            0.1493, 0.1302], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.44166666, dtype=float32),\n",
       "    'tpr': array(0.88461536, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.11666667, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15      , 0.15      ,\n",
       "            0.15      , 0.15      , 0.15      , 0.15      , 0.15      ,\n",
       "            0.15833333, 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.275     , 0.275     ,\n",
       "            0.275     , 0.275     , 0.28333333, 0.28333333, 0.28333333,\n",
       "            0.29166666, 0.29166666, 0.3       , 0.3       , 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.6       , 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.8333333 , 0.84166664,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16923077, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.32307693, 0.33076924, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3846154 ,\n",
       "            0.3846154 , 0.3846154 , 0.3923077 , 0.4076923 , 0.41538462,\n",
       "            0.43076923, 0.43846154, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.46153846, 0.46153846, 0.47692308, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.50769234, 0.5153846 , 0.5153846 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.54615384, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6076923 , 0.61538464, 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.6615385 , 0.66923076, 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.72307694, 0.7307692 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.8       , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7334, 0.701 , 0.694 , 0.6875, 0.678 , 0.6763, 0.6724,\n",
       "            0.669 , 0.667 , 0.6646, 0.664 , 0.6626, 0.661 , 0.658 , 0.657 ,\n",
       "            0.6567, 0.6553, 0.6533, 0.653 , 0.6523, 0.652 , 0.6514, 0.651 ,\n",
       "            0.6484, 0.647 , 0.646 , 0.6455, 0.645 , 0.643 , 0.642 , 0.64  ,\n",
       "            0.637 , 0.635 , 0.6343, 0.6333, 0.6323, 0.632 , 0.6313, 0.63  ,\n",
       "            0.6284, 0.628 , 0.6265, 0.6255, 0.625 , 0.623 , 0.6216, 0.621 ,\n",
       "            0.62  , 0.6167, 0.6157, 0.615 , 0.6143, 0.614 , 0.6123, 0.611 ,\n",
       "            0.6084, 0.607 , 0.606 , 0.6055, 0.605 , 0.604 , 0.6035, 0.6025,\n",
       "            0.6016, 0.599 , 0.5986, 0.5977, 0.5967, 0.596 , 0.5957, 0.595 ,\n",
       "            0.5947, 0.5938, 0.5923, 0.5913, 0.589 , 0.588 , 0.5864, 0.586 ,\n",
       "            0.584 , 0.5835, 0.583 , 0.582 , 0.581 , 0.5806, 0.58  , 0.5796,\n",
       "            0.577 , 0.5767, 0.5737, 0.573 , 0.57  , 0.5674, 0.567 , 0.5625,\n",
       "            0.562 , 0.5615, 0.56  , 0.5596, 0.5586, 0.558 , 0.5566, 0.554 ,\n",
       "            0.5537, 0.553 , 0.5527, 0.55  , 0.5493, 0.548 , 0.5454, 0.5435,\n",
       "            0.542 , 0.5415, 0.541 , 0.5386, 0.538 , 0.5376, 0.5356, 0.535 ,\n",
       "            0.5347, 0.5337, 0.5317, 0.5312, 0.5303, 0.526 , 0.5254, 0.5166,\n",
       "            0.5137, 0.513 , 0.512 , 0.5117, 0.511 , 0.5083, 0.5063, 0.5024,\n",
       "            0.4985, 0.4949, 0.494 , 0.491 , 0.4902, 0.4875, 0.4873, 0.4805,\n",
       "            0.4797, 0.4795, 0.4685, 0.4658, 0.4653, 0.4648, 0.4492, 0.4487,\n",
       "            0.4456, 0.4453, 0.438 , 0.4355, 0.4329, 0.432 , 0.4253, 0.4238,\n",
       "            0.4214, 0.4211, 0.4192, 0.413 , 0.4016, 0.3958, 0.393 , 0.3926,\n",
       "            0.388 , 0.386 , 0.385 , 0.3828, 0.3813, 0.379 , 0.3784, 0.3772,\n",
       "            0.366 , 0.3647, 0.361 , 0.3499, 0.3394, 0.3376, 0.335 , 0.3345,\n",
       "            0.333 , 0.3274, 0.3262, 0.324 , 0.3174, 0.3154, 0.3108, 0.3044,\n",
       "            0.3042, 0.2957, 0.2944, 0.2783, 0.2712, 0.2617, 0.252 , 0.2456,\n",
       "            0.2302, 0.2213, 0.2186, 0.2119, 0.2064, 0.2045, 0.2001, 0.1946,\n",
       "            0.188 , 0.1815, 0.1726, 0.1616, 0.1482, 0.1476, 0.1276],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.49166667, dtype=float32),\n",
       "    'tpr': array(0.9153846, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.1       ,\n",
       "            0.10833333, 0.10833333, 0.10833333, 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15      , 0.15      ,\n",
       "            0.15      , 0.15      , 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.26666668,\n",
       "            0.26666668, 0.275     , 0.275     , 0.275     , 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.3       , 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.34166667, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.60833335, 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.04615385, 0.05384615, 0.06153846, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.12307692,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.17692308,\n",
       "            0.1923077 , 0.20769231, 0.21538462, 0.23076923, 0.23846154,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.30769232, 0.31538463, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.34615386, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.47692308,\n",
       "            0.47692308, 0.4923077 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5923077 , 0.6       , 0.61538464, 0.61538464,\n",
       "            0.61538464, 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.72307694, 0.72307694,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.8769231 , 0.88461536, 0.88461536, 0.88461536, 0.88461536,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.771 , 0.7363, 0.7314, 0.721 , 0.7144, 0.7134, 0.706 ,\n",
       "            0.705 , 0.7017, 0.6973, 0.697 , 0.695 , 0.693 , 0.6924, 0.6885,\n",
       "            0.6865, 0.686 , 0.6855, 0.6846, 0.683 , 0.6826, 0.681 , 0.6797,\n",
       "            0.679 , 0.678 , 0.6772, 0.676 , 0.6743, 0.674 , 0.6724, 0.6704,\n",
       "            0.6694, 0.666 , 0.6636, 0.6626, 0.6616, 0.6597, 0.6587, 0.658 ,\n",
       "            0.6567, 0.656 , 0.654 , 0.6533, 0.653 , 0.6514, 0.65  , 0.6475,\n",
       "            0.647 , 0.645 , 0.644 , 0.6436, 0.6416, 0.6406, 0.639 , 0.6387,\n",
       "            0.638 , 0.637 , 0.6367, 0.636 , 0.635 , 0.6333, 0.6323, 0.632 ,\n",
       "            0.628 , 0.6274, 0.627 , 0.6265, 0.626 , 0.625 , 0.6235, 0.623 ,\n",
       "            0.622 , 0.6216, 0.621 , 0.62  , 0.6187, 0.6177, 0.617 , 0.616 ,\n",
       "            0.6157, 0.615 , 0.6147, 0.612 , 0.611 , 0.6104, 0.6094, 0.608 ,\n",
       "            0.6055, 0.603 , 0.6025, 0.601 , 0.6006, 0.6   , 0.598 , 0.595 ,\n",
       "            0.594 , 0.593 , 0.5913, 0.591 , 0.5903, 0.59  , 0.589 , 0.5864,\n",
       "            0.586 , 0.5835, 0.5825, 0.5786, 0.578 , 0.5767, 0.576 , 0.5737,\n",
       "            0.5723, 0.572 , 0.5713, 0.571 , 0.5703, 0.567 , 0.5664, 0.562 ,\n",
       "            0.5605, 0.5596, 0.557 , 0.5566, 0.5557, 0.553 , 0.552 , 0.5396,\n",
       "            0.538 , 0.5376, 0.535 , 0.5337, 0.532 , 0.5293, 0.5283, 0.5254,\n",
       "            0.525 , 0.521 , 0.519 , 0.509 , 0.5083, 0.5073, 0.501 , 0.5   ,\n",
       "            0.495 , 0.4932, 0.483 , 0.4822, 0.4802, 0.4783, 0.4763, 0.473 ,\n",
       "            0.4646, 0.4617, 0.4592, 0.4583, 0.4543, 0.4526, 0.452 , 0.447 ,\n",
       "            0.4458, 0.4404, 0.4302, 0.4297, 0.4216, 0.4182, 0.4043, 0.4011,\n",
       "            0.3987, 0.3962, 0.3945, 0.3904, 0.3877, 0.3833, 0.3767, 0.3735,\n",
       "            0.3706, 0.354 , 0.345 , 0.3442, 0.3418, 0.3376, 0.3352, 0.3347,\n",
       "            0.3298, 0.326 , 0.321 , 0.317 , 0.315 , 0.313 , 0.304 , 0.2993,\n",
       "            0.298 , 0.2969, 0.2761, 0.2612, 0.2573, 0.247 , 0.228 , 0.2198,\n",
       "            0.2197, 0.2145, 0.2086, 0.2023, 0.202 , 0.1946, 0.1863, 0.1797,\n",
       "            0.1696, 0.1594, 0.1495, 0.1486, 0.1283], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.51666665, dtype=float32),\n",
       "    'tpr': array(0.93846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.1       , 0.1       ,\n",
       "            0.1       , 0.1       , 0.10833333, 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.16666667, 0.18333334,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.2       , 0.2       , 0.20833333, 0.225     ,\n",
       "            0.225     , 0.225     , 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.29166666, 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.6       , 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.16923077, 0.18461539,\n",
       "            0.2       , 0.21538462, 0.22307692, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26923078, 0.2769231 , 0.2769231 , 0.2846154 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.42307693, 0.43076923, 0.43076923, 0.43076923, 0.43076923,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5538462 , 0.5538462 ,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.6       , 0.61538464,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.805 , 0.769 , 0.7666, 0.7534, 0.748 , 0.7476, 0.746 ,\n",
       "            0.739 , 0.7383, 0.7363, 0.735 , 0.734 , 0.729 , 0.728 , 0.7275,\n",
       "            0.725 , 0.723 , 0.722 , 0.7197, 0.7188, 0.7183, 0.717 , 0.7163,\n",
       "            0.715 , 0.7144, 0.7134, 0.713 , 0.7124, 0.7114, 0.7104, 0.71  ,\n",
       "            0.7085, 0.708 , 0.7075, 0.706 , 0.7036, 0.702 , 0.6987, 0.6973,\n",
       "            0.6934, 0.6914, 0.69  , 0.6895, 0.6885, 0.688 , 0.6865, 0.684 ,\n",
       "            0.681 , 0.6807, 0.678 , 0.6777, 0.6753, 0.675 , 0.6743, 0.674 ,\n",
       "            0.6733, 0.672 , 0.6714, 0.671 , 0.6704, 0.6694, 0.6685, 0.6675,\n",
       "            0.667 , 0.666 , 0.6655, 0.6616, 0.6606, 0.66  , 0.659 , 0.658 ,\n",
       "            0.6577, 0.6567, 0.6562, 0.6553, 0.654 , 0.6523, 0.6514, 0.6504,\n",
       "            0.65  , 0.649 , 0.6484, 0.647 , 0.6436, 0.6426, 0.642 , 0.6416,\n",
       "            0.6406, 0.637 , 0.635 , 0.6343, 0.633 , 0.6323, 0.632 , 0.631 ,\n",
       "            0.6284, 0.628 , 0.6274, 0.6265, 0.6255, 0.6245, 0.624 , 0.622 ,\n",
       "            0.6216, 0.6206, 0.6177, 0.617 , 0.6157, 0.615 , 0.613 , 0.6123,\n",
       "            0.6094, 0.6064, 0.606 , 0.6035, 0.6016, 0.601 , 0.6006, 0.5977,\n",
       "            0.597 , 0.5967, 0.5947, 0.5938, 0.5894, 0.587 , 0.583 , 0.576 ,\n",
       "            0.5713, 0.57  , 0.568 , 0.5664, 0.565 , 0.5645, 0.5615, 0.559 ,\n",
       "            0.554 , 0.548 , 0.5474, 0.5454, 0.544 , 0.538 , 0.5356, 0.534 ,\n",
       "            0.525 , 0.5234, 0.5225, 0.52  , 0.515 , 0.5127, 0.5073, 0.506 ,\n",
       "            0.4988, 0.4956, 0.492 , 0.4912, 0.4905, 0.489 , 0.4873, 0.4836,\n",
       "            0.4822, 0.4702, 0.4688, 0.468 , 0.464 , 0.4573, 0.4553, 0.455 ,\n",
       "            0.4504, 0.4482, 0.425 , 0.4092, 0.409 , 0.405 , 0.4036, 0.398 ,\n",
       "            0.3953, 0.391 , 0.3887, 0.38  , 0.3755, 0.357 , 0.3538, 0.349 ,\n",
       "            0.3489, 0.347 , 0.3418, 0.3394, 0.3357, 0.3308, 0.3286, 0.3274,\n",
       "            0.3262, 0.3228, 0.3203, 0.3176, 0.3027, 0.299 , 0.2969, 0.2793,\n",
       "            0.2612, 0.259 , 0.2462, 0.224 , 0.2191, 0.2162, 0.2152, 0.209 ,\n",
       "            0.2026, 0.1978, 0.1927, 0.1827, 0.1761, 0.1649, 0.1555, 0.1495,\n",
       "            0.1471, 0.1272], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.55833334, dtype=float32),\n",
       "    'tpr': array(0.96153843, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.09166667, 0.09166667, 0.09166667, 0.09166667,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.125     , 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.16666667, 0.175     ,\n",
       "            0.175     , 0.175     , 0.175     , 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "            0.2       , 0.2       , 0.2       , 0.2       , 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.23333333, 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.25833333, 0.26666668, 0.26666668,\n",
       "            0.275     , 0.275     , 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.3       , 0.3       , 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.05384615, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.20769231, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.30769232, 0.31538463, 0.31538463,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.43076923, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.50769234, 0.5153846 , 0.5307692 ,\n",
       "            0.5307692 , 0.5307692 , 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8354, 0.7993, 0.7983, 0.7837, 0.7803, 0.779 , 0.7773,\n",
       "            0.7705, 0.7695, 0.7686, 0.768 , 0.7646, 0.7603, 0.759 , 0.7573,\n",
       "            0.756 , 0.7544, 0.754 , 0.752 , 0.7515, 0.751 , 0.75  , 0.7476,\n",
       "            0.747 , 0.746 , 0.745 , 0.7446, 0.7437, 0.7427, 0.742 , 0.741 ,\n",
       "            0.7407, 0.7397, 0.7383, 0.738 , 0.7373, 0.737 , 0.7324, 0.731 ,\n",
       "            0.73  , 0.723 , 0.7217, 0.7207, 0.7197, 0.719 , 0.718 , 0.714 ,\n",
       "            0.7095, 0.708 , 0.7075, 0.707 , 0.706 , 0.7056, 0.7046, 0.702 ,\n",
       "            0.7017, 0.701 , 0.7007, 0.6987, 0.698 , 0.6978, 0.6973, 0.6963,\n",
       "            0.695 , 0.6943, 0.693 , 0.6914, 0.6904, 0.69  , 0.689 , 0.688 ,\n",
       "            0.687 , 0.6855, 0.684 , 0.6836, 0.682 , 0.681 , 0.68  , 0.679 ,\n",
       "            0.678 , 0.6777, 0.6772, 0.6763, 0.675 , 0.672 , 0.6704, 0.6694,\n",
       "            0.669 , 0.6685, 0.667 , 0.6636, 0.663 , 0.6606, 0.6597, 0.6587,\n",
       "            0.658 , 0.657 , 0.656 , 0.6553, 0.655 , 0.6543, 0.653 , 0.6523,\n",
       "            0.65  , 0.649 , 0.645 , 0.6436, 0.641 , 0.64  , 0.639 , 0.6387,\n",
       "            0.637 , 0.6357, 0.6294, 0.629 , 0.6284, 0.628 , 0.6274, 0.626 ,\n",
       "            0.6206, 0.6157, 0.6104, 0.608 , 0.6045, 0.598 , 0.5957, 0.595 ,\n",
       "            0.594 , 0.5923, 0.5913, 0.589 , 0.5835, 0.5757, 0.57  , 0.5664,\n",
       "            0.5635, 0.561 , 0.559 , 0.5557, 0.554 , 0.5503, 0.548 , 0.542 ,\n",
       "            0.5376, 0.536 , 0.5356, 0.5293, 0.527 , 0.5244, 0.524 , 0.5186,\n",
       "            0.515 , 0.5127, 0.5034, 0.502 , 0.4985, 0.4973, 0.4897, 0.4893,\n",
       "            0.4856, 0.4841, 0.4822, 0.4778, 0.464 , 0.4558, 0.4465, 0.4246,\n",
       "            0.4158, 0.4143, 0.408 , 0.4065, 0.406 , 0.4036, 0.393 , 0.3865,\n",
       "            0.3801, 0.3738, 0.3599, 0.3555, 0.3545, 0.3535, 0.3528, 0.3496,\n",
       "            0.341 , 0.3394, 0.3362, 0.3318, 0.3284, 0.3267, 0.325 , 0.3206,\n",
       "            0.3066, 0.3   , 0.2969, 0.283 , 0.2659, 0.2568, 0.246 , 0.2205,\n",
       "            0.2191, 0.2167, 0.213 , 0.2103, 0.2039, 0.1941, 0.1917, 0.1797,\n",
       "            0.173 , 0.1609, 0.1523, 0.1506, 0.1466, 0.1272], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5833333, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "            0.1       , 0.11666667, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.2       , 0.2       , 0.2       , 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.3       , 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.375     , 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.49166667, 0.5083333 , 0.51666665, 0.525     , 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.18461539, 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.30769232, 0.31538463,\n",
       "            0.33076924, 0.33846155, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.50769234, 0.50769234, 0.50769234, 0.5153846 ,\n",
       "            0.5307692 , 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.56153846, 0.56153846,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.6923077 , 0.7076923 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.7307692 , 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.859 , 0.823 , 0.8076, 0.805 , 0.8037, 0.802 , 0.797 ,\n",
       "            0.7954, 0.7944, 0.792 , 0.789 , 0.786 , 0.7827, 0.7812, 0.781 ,\n",
       "            0.7803, 0.7793, 0.778 , 0.776 , 0.7754, 0.775 , 0.772 , 0.7715,\n",
       "            0.771 , 0.7705, 0.77  , 0.768 , 0.767 , 0.7666, 0.766 , 0.765 ,\n",
       "            0.7646, 0.763 , 0.7627, 0.7617, 0.761 , 0.7607, 0.758 , 0.757 ,\n",
       "            0.755 , 0.7495, 0.747 , 0.7466, 0.7446, 0.743 , 0.7417, 0.741 ,\n",
       "            0.7383, 0.7363, 0.736 , 0.7324, 0.7314, 0.731 , 0.73  , 0.729 ,\n",
       "            0.7285, 0.728 , 0.7275, 0.726 , 0.725 , 0.7236, 0.723 , 0.722 ,\n",
       "            0.7217, 0.721 , 0.7207, 0.72  , 0.7197, 0.719 , 0.7188, 0.7183,\n",
       "            0.718 , 0.7153, 0.7144, 0.714 , 0.7134, 0.711 , 0.7104, 0.709 ,\n",
       "            0.7085, 0.7075, 0.7065, 0.7056, 0.704 , 0.7036, 0.702 , 0.7017,\n",
       "            0.6997, 0.699 , 0.6978, 0.6953, 0.693 , 0.6924, 0.691 , 0.689 ,\n",
       "            0.688 , 0.6875, 0.687 , 0.686 , 0.6846, 0.684 , 0.683 , 0.6826,\n",
       "            0.6816, 0.6807, 0.6797, 0.679 , 0.678 , 0.6777, 0.6772, 0.677 ,\n",
       "            0.6763, 0.6743, 0.674 , 0.673 , 0.67  , 0.6694, 0.6685, 0.666 ,\n",
       "            0.664 , 0.663 , 0.66  , 0.6587, 0.657 , 0.656 , 0.6553, 0.653 ,\n",
       "            0.6523, 0.652 , 0.649 , 0.6406, 0.6333, 0.633 , 0.6304, 0.629 ,\n",
       "            0.6284, 0.619 , 0.614 , 0.6113, 0.6084, 0.604 , 0.5996, 0.5986,\n",
       "            0.5913, 0.5854, 0.584 , 0.5796, 0.5767, 0.576 , 0.574 , 0.572 ,\n",
       "            0.5713, 0.5664, 0.5625, 0.5615, 0.554 , 0.5503, 0.5483, 0.542 ,\n",
       "            0.539 , 0.535 , 0.5293, 0.5283, 0.519 , 0.513 , 0.5127, 0.512 ,\n",
       "            0.51  , 0.508 , 0.5063, 0.493 , 0.486 , 0.472 , 0.465 , 0.4626,\n",
       "            0.438 , 0.4226, 0.4216, 0.42  , 0.4128, 0.412 , 0.4104, 0.3972,\n",
       "            0.392 , 0.391 , 0.3845, 0.3792, 0.3623, 0.3591, 0.3577, 0.3572,\n",
       "            0.3562, 0.3496, 0.3423, 0.3367, 0.3354, 0.3325, 0.327 , 0.3267,\n",
       "            0.323 , 0.3098, 0.301 , 0.2966, 0.2861, 0.2698, 0.2544, 0.2456,\n",
       "            0.2189, 0.2177, 0.217 , 0.211 , 0.2101, 0.2047, 0.1904, 0.177 ,\n",
       "            0.17  , 0.1571, 0.1512, 0.1492, 0.1458, 0.1268], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59166664, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.09166667, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.14166667, 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.175     , 0.175     ,\n",
       "            0.175     , 0.175     , 0.19166666, 0.2       , 0.2       ,\n",
       "            0.2       , 0.20833333, 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.21666667, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25      , 0.25      ,\n",
       "            0.25      , 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.3       , 0.3       ,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.325     , 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.5083333 , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.525     , 0.525     , 0.53333336,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.68333334,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.24615385, 0.25384617, 0.26153848, 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.3       , 0.30769232, 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3846154 , 0.3923077 , 0.4076923 , 0.4076923 , 0.4076923 ,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.43846154, 0.44615385,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4923077 , 0.4923077 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.5692308 , 0.5769231 ,\n",
       "            0.5923077 , 0.5923077 , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8794, 0.846 , 0.8447, 0.8296, 0.8286, 0.826 , 0.824 ,\n",
       "            0.8223, 0.8184, 0.818 , 0.8145, 0.812 , 0.81  , 0.806 , 0.805 ,\n",
       "            0.803 , 0.8022, 0.8003, 0.7993, 0.7983, 0.798 , 0.7974, 0.796 ,\n",
       "            0.7954, 0.7944, 0.7935, 0.793 , 0.7925, 0.7915, 0.789 , 0.7886,\n",
       "            0.788 , 0.7876, 0.787 , 0.7866, 0.784 , 0.7837, 0.783 , 0.7827,\n",
       "            0.7803, 0.7793, 0.779 , 0.774 , 0.771 , 0.7666, 0.7656, 0.765 ,\n",
       "            0.764 , 0.7637, 0.761 , 0.7607, 0.758 , 0.757 , 0.7554, 0.755 ,\n",
       "            0.7544, 0.754 , 0.7534, 0.752 , 0.7515, 0.751 , 0.75  , 0.7495,\n",
       "            0.748 , 0.7476, 0.7466, 0.7446, 0.744 , 0.7437, 0.7427, 0.7417,\n",
       "            0.741 , 0.7407, 0.74  , 0.7393, 0.7383, 0.736 , 0.734 , 0.733 ,\n",
       "            0.732 , 0.7314, 0.729 , 0.7275, 0.727 , 0.7256, 0.7236, 0.721 ,\n",
       "            0.719 , 0.7183, 0.718 , 0.716 , 0.7153, 0.714 , 0.7134, 0.713 ,\n",
       "            0.7124, 0.7114, 0.71  , 0.7075, 0.706 , 0.7056, 0.705 , 0.7036,\n",
       "            0.703 , 0.7026, 0.702 , 0.7007, 0.6997, 0.6978, 0.6973, 0.696 ,\n",
       "            0.692 , 0.691 , 0.6875, 0.6855, 0.684 , 0.682 , 0.678 , 0.6772,\n",
       "            0.6763, 0.676 , 0.675 , 0.669 , 0.6606, 0.6597, 0.657 , 0.6514,\n",
       "            0.65  , 0.645 , 0.6426, 0.642 , 0.6416, 0.6357, 0.632 , 0.628 ,\n",
       "            0.6255, 0.623 , 0.6196, 0.6147, 0.614 , 0.6064, 0.6045, 0.603 ,\n",
       "            0.599 , 0.596 , 0.593 , 0.591 , 0.588 , 0.5854, 0.582 , 0.58  ,\n",
       "            0.5757, 0.5684, 0.565 , 0.563 , 0.56  , 0.557 , 0.548 , 0.5464,\n",
       "            0.541 , 0.5405, 0.5337, 0.526 , 0.5234, 0.523 , 0.516 , 0.503 ,\n",
       "            0.4944, 0.4834, 0.4795, 0.4695, 0.451 , 0.4326, 0.4302, 0.4287,\n",
       "            0.4194, 0.417 , 0.4165, 0.4082, 0.402 , 0.4019, 0.3975, 0.3884,\n",
       "            0.3645, 0.3635, 0.3623, 0.362 , 0.3606, 0.3591, 0.3435, 0.3416,\n",
       "            0.337 , 0.3335, 0.3281, 0.3267, 0.325 , 0.3125, 0.3015, 0.2961,\n",
       "            0.2883, 0.2727, 0.2524, 0.2448, 0.218 , 0.2179, 0.2137, 0.2109,\n",
       "            0.207 , 0.2045, 0.1885, 0.1866, 0.1737, 0.1669, 0.1532, 0.1509,\n",
       "            0.1459, 0.1442, 0.1257], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.60833335, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.10833333, 0.10833333,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.2       , 0.2       ,\n",
       "            0.2       , 0.2       , 0.2       , 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.225     , 0.225     , 0.225     , 0.225     ,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.28333333,\n",
       "            0.29166666, 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.525     , 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.13076924, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23846154, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.2846154 , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.3923077 , 0.4       , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.42307693, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.45384616, 0.46153846, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.54615384,\n",
       "            0.54615384, 0.56153846, 0.56153846, 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.7       , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.72307694, 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8975, 0.8667, 0.865 , 0.85  , 0.847 , 0.8457, 0.8403,\n",
       "            0.84  , 0.836 , 0.8335, 0.8325, 0.8306, 0.8267, 0.8257, 0.825 ,\n",
       "            0.8247, 0.8213, 0.821 , 0.8203, 0.819 , 0.8184, 0.8174, 0.817 ,\n",
       "            0.8154, 0.815 , 0.814 , 0.8105, 0.8096, 0.809 , 0.8076, 0.8066,\n",
       "            0.8057, 0.8047, 0.8022, 0.802 , 0.8013, 0.798 , 0.7944, 0.788 ,\n",
       "            0.787 , 0.7866, 0.786 , 0.785 , 0.7847, 0.783 , 0.7812, 0.781 ,\n",
       "            0.7793, 0.779 , 0.7773, 0.777 , 0.7764, 0.776 , 0.7744, 0.7734,\n",
       "            0.773 , 0.7725, 0.772 , 0.7715, 0.771 , 0.7705, 0.77  , 0.768 ,\n",
       "            0.766 , 0.7656, 0.7637, 0.763 , 0.7627, 0.762 , 0.7617, 0.761 ,\n",
       "            0.76  , 0.7583, 0.758 , 0.7573, 0.7563, 0.755 , 0.754 , 0.751 ,\n",
       "            0.75  , 0.7495, 0.7485, 0.7456, 0.744 , 0.742 , 0.7417, 0.7407,\n",
       "            0.74  , 0.7393, 0.738 , 0.7363, 0.735 , 0.7344, 0.7334, 0.7305,\n",
       "            0.7295, 0.7285, 0.727 , 0.726 , 0.7256, 0.7246, 0.724 , 0.7236,\n",
       "            0.72  , 0.719 , 0.7188, 0.718 , 0.7173, 0.7124, 0.7114, 0.7104,\n",
       "            0.709 , 0.7085, 0.708 , 0.707 , 0.701 , 0.699 , 0.6978, 0.6973,\n",
       "            0.689 , 0.686 , 0.68  , 0.671 , 0.67  , 0.669 , 0.6655, 0.6646,\n",
       "            0.6577, 0.656 , 0.654 , 0.647 , 0.644 , 0.6436, 0.6406, 0.6357,\n",
       "            0.632 , 0.6313, 0.631 , 0.629 , 0.6284, 0.6265, 0.613 , 0.6094,\n",
       "            0.6055, 0.602 , 0.5996, 0.5977, 0.5933, 0.5894, 0.589 , 0.58  ,\n",
       "            0.5767, 0.5737, 0.5728, 0.561 , 0.558 , 0.553 , 0.547 , 0.5347,\n",
       "            0.527 , 0.5156, 0.505 , 0.5044, 0.4895, 0.4783, 0.4668, 0.4487,\n",
       "            0.4407, 0.4363, 0.4307, 0.4294, 0.4287, 0.4265, 0.4229, 0.4082,\n",
       "            0.4055, 0.395 , 0.372 , 0.3716, 0.3704, 0.3694, 0.3667, 0.3508,\n",
       "            0.3472, 0.3396, 0.3367, 0.3325, 0.3298, 0.3293, 0.3184, 0.3047,\n",
       "            0.2983, 0.294 , 0.279 , 0.2527, 0.2467, 0.2212, 0.22  , 0.214 ,\n",
       "            0.2128, 0.2075, 0.2064, 0.1896, 0.1855, 0.1731, 0.1661, 0.1536,\n",
       "            0.1516, 0.1454, 0.1449, 0.1271], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.60833335, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.075     , 0.075     ,\n",
       "            0.09166667, 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.125     , 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.175     , 0.19166666, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.2       , 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.225     ,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.29166666, 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.65      , 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.06153846, 0.06923077, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.16153847, 0.16923077, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.26923078, 0.2769231 ,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.33846155, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.3923077 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46153846, 0.4846154 ,\n",
       "            0.4923077 , 0.4923077 , 0.5       , 0.5       , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5923077 , 0.5923077 , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.7307692 , 0.74615383, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.88461536, 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.914 , 0.8853, 0.8833, 0.869 , 0.8667, 0.8657, 0.86  ,\n",
       "            0.856 , 0.853 , 0.8467, 0.846 , 0.8457, 0.8447, 0.844 , 0.8423,\n",
       "            0.842 , 0.841 , 0.84  , 0.8384, 0.8374, 0.8364, 0.836 , 0.8354,\n",
       "            0.834 , 0.832 , 0.8306, 0.83  , 0.8296, 0.829 , 0.8286, 0.8276,\n",
       "            0.826 , 0.8247, 0.823 , 0.8228, 0.8223, 0.82  , 0.8164, 0.816 ,\n",
       "            0.8105, 0.8086, 0.8076, 0.8066, 0.806 , 0.8057, 0.8037, 0.803 ,\n",
       "            0.8027, 0.8022, 0.802 , 0.8013, 0.799 , 0.7983, 0.798 , 0.797 ,\n",
       "            0.796 , 0.795 , 0.794 , 0.7915, 0.791 , 0.7905, 0.788 , 0.7876,\n",
       "            0.787 , 0.7866, 0.7856, 0.785 , 0.7847, 0.784 , 0.783 , 0.7827,\n",
       "            0.7817, 0.7803, 0.78  , 0.7793, 0.7773, 0.7754, 0.772 , 0.7705,\n",
       "            0.77  , 0.769 , 0.7676, 0.766 , 0.7656, 0.7646, 0.7627, 0.762 ,\n",
       "            0.7607, 0.76  , 0.7593, 0.759 , 0.7583, 0.758 , 0.7573, 0.7554,\n",
       "            0.7544, 0.7534, 0.7524, 0.75  , 0.7495, 0.7485, 0.746 , 0.745 ,\n",
       "            0.744 , 0.743 , 0.7417, 0.7393, 0.7383, 0.7373, 0.736 , 0.7334,\n",
       "            0.7314, 0.73  , 0.7295, 0.7275, 0.7246, 0.7217, 0.7197, 0.717 ,\n",
       "            0.713 , 0.712 , 0.7085, 0.699 , 0.6953, 0.6904, 0.6895, 0.6885,\n",
       "            0.6865, 0.6855, 0.6816, 0.679 , 0.6777, 0.673 , 0.67  , 0.6655,\n",
       "            0.6606, 0.659 , 0.6587, 0.6577, 0.657 , 0.654 , 0.652 , 0.643 ,\n",
       "            0.6367, 0.6265, 0.621 , 0.6196, 0.619 , 0.6167, 0.614 , 0.6104,\n",
       "            0.6035, 0.603 , 0.591 , 0.588 , 0.587 , 0.571 , 0.568 , 0.5654,\n",
       "            0.547 , 0.5464, 0.5376, 0.5283, 0.527 , 0.515 , 0.5   , 0.4878,\n",
       "            0.4834, 0.4653, 0.4597, 0.4517, 0.4512, 0.4448, 0.4385, 0.4365,\n",
       "            0.4302, 0.4153, 0.4143, 0.402 , 0.386 , 0.3813, 0.3782, 0.3774,\n",
       "            0.375 , 0.3735, 0.361 , 0.3518, 0.3433, 0.3406, 0.3376, 0.3354,\n",
       "            0.3325, 0.3247, 0.3088, 0.3013, 0.3003, 0.2864, 0.2537, 0.2494,\n",
       "            0.2255, 0.2229, 0.2179, 0.2128, 0.2113, 0.2068, 0.1913, 0.1852,\n",
       "            0.1735, 0.1664, 0.157 , 0.151 , 0.1473, 0.1448, 0.1294],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6166667, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.125     , 0.125     ,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.2       , 0.2       , 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.225     ,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.23333333,\n",
       "            0.25      , 0.26666668, 0.26666668, 0.275     , 0.275     ,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.375     , 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.39166668, 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16923077, 0.1923077 , 0.20769231, 0.20769231, 0.21538462,\n",
       "            0.23076923, 0.23846154, 0.23846154, 0.26153848, 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.33076924, 0.33846155, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.41538462, 0.41538462, 0.41538462,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.43076923, 0.44615385,\n",
       "            0.46153846, 0.46153846, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.5       ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.928 , 0.902 , 0.9   , 0.8867, 0.886 , 0.8843, 0.8833,\n",
       "            0.878 , 0.8735, 0.873 , 0.8716, 0.871 , 0.8657, 0.8643, 0.8633,\n",
       "            0.863 , 0.862 , 0.8604, 0.8594, 0.859 , 0.857 , 0.856 , 0.8555,\n",
       "            0.854 , 0.852 , 0.85  , 0.849 , 0.848 , 0.8477, 0.846 , 0.845 ,\n",
       "            0.8438, 0.8433, 0.843 , 0.842 , 0.8403, 0.8364, 0.836 , 0.834 ,\n",
       "            0.8286, 0.8276, 0.827 , 0.826 , 0.8257, 0.8247, 0.824 , 0.823 ,\n",
       "            0.8228, 0.822 , 0.8193, 0.8184, 0.818 , 0.8174, 0.8164, 0.8154,\n",
       "            0.815 , 0.8135, 0.813 , 0.812 , 0.8115, 0.811 , 0.8105, 0.81  ,\n",
       "            0.807 , 0.806 , 0.8057, 0.805 , 0.8047, 0.8037, 0.803 , 0.8027,\n",
       "            0.802 , 0.8013, 0.801 , 0.7993, 0.798 , 0.797 , 0.796 , 0.795 ,\n",
       "            0.7925, 0.792 , 0.791 , 0.79  , 0.7896, 0.7886, 0.788 , 0.786 ,\n",
       "            0.784 , 0.783 , 0.782 , 0.78  , 0.7773, 0.777 , 0.776 , 0.7744,\n",
       "            0.774 , 0.771 , 0.7705, 0.7686, 0.7666, 0.765 , 0.764 , 0.763 ,\n",
       "            0.762 , 0.76  , 0.759 , 0.7573, 0.7563, 0.756 , 0.7534, 0.7495,\n",
       "            0.748 , 0.7476, 0.7466, 0.743 , 0.7407, 0.738 , 0.736 , 0.735 ,\n",
       "            0.7275, 0.7183, 0.718 , 0.71  , 0.7075, 0.706 , 0.7036, 0.7   ,\n",
       "            0.6987, 0.6904, 0.689 , 0.688 , 0.687 , 0.6855, 0.685 , 0.6807,\n",
       "            0.677 , 0.675 , 0.6714, 0.6675, 0.6626, 0.6523, 0.6484, 0.647 ,\n",
       "            0.6396, 0.634 , 0.6323, 0.6304, 0.6274, 0.616 , 0.613 , 0.6035,\n",
       "            0.599 , 0.5874, 0.5825, 0.577 , 0.558 , 0.5566, 0.548 , 0.5474,\n",
       "            0.54  , 0.525 , 0.5093, 0.4985, 0.4963, 0.4873, 0.4807, 0.4717,\n",
       "            0.4614, 0.4526, 0.4473, 0.4456, 0.4365, 0.4219, 0.4084, 0.3984,\n",
       "            0.3901, 0.385 , 0.3845, 0.38  , 0.3794, 0.37  , 0.3555, 0.3462,\n",
       "            0.3438, 0.3416, 0.34  , 0.3352, 0.3303, 0.312 , 0.3054, 0.3035,\n",
       "            0.2925, 0.2542, 0.2512, 0.2285, 0.2247, 0.2207, 0.2142, 0.212 ,\n",
       "            0.2064, 0.1924, 0.1843, 0.173 , 0.1659, 0.1594, 0.1498, 0.1486,\n",
       "            0.144 , 0.1309], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6333333, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.06666667, 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.18333334, 0.18333334,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.19166666, 0.20833333,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.225     , 0.225     , 0.23333333, 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.325     , 0.325     , 0.325     , 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13846155, 0.14615385,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.20769231,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23076923,\n",
       "            0.23846154, 0.25384617, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.30769232, 0.31538463, 0.33076924, 0.33846155, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.41538462, 0.41538462, 0.42307693, 0.43846154,\n",
       "            0.45384616, 0.46923077, 0.46923077, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.56153846, 0.5692308 , 0.5692308 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.63076925, 0.63076925, 0.63846153, 0.65384614,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.94  , 0.9165, 0.914 , 0.903 , 0.9023, 0.9014, 0.9   ,\n",
       "            0.8994, 0.894 , 0.891 , 0.89  , 0.888 , 0.887 , 0.883 , 0.8813,\n",
       "            0.881 , 0.88  , 0.8794, 0.8774, 0.8765, 0.8755, 0.8745, 0.874 ,\n",
       "            0.8735, 0.873 , 0.871 , 0.8706, 0.869 , 0.868 , 0.8677, 0.8657,\n",
       "            0.865 , 0.8647, 0.8633, 0.861 , 0.8604, 0.86  , 0.8594, 0.8555,\n",
       "            0.854 , 0.8486, 0.848 , 0.846 , 0.845 , 0.8447, 0.8438, 0.8433,\n",
       "            0.843 , 0.842 , 0.8413, 0.84  , 0.8374, 0.836 , 0.8354, 0.835 ,\n",
       "            0.8345, 0.832 , 0.831 , 0.83  , 0.8296, 0.8286, 0.828 , 0.826 ,\n",
       "            0.8257, 0.824 , 0.8237, 0.823 , 0.8223, 0.822 , 0.8213, 0.821 ,\n",
       "            0.82  , 0.819 , 0.8184, 0.818 , 0.8154, 0.815 , 0.8135, 0.8125,\n",
       "            0.812 , 0.811 , 0.8086, 0.808 , 0.806 , 0.805 , 0.803 , 0.8027,\n",
       "            0.8022, 0.8013, 0.8003, 0.8   , 0.799 , 0.797 , 0.7954, 0.795 ,\n",
       "            0.794 , 0.793 , 0.7925, 0.791 , 0.7896, 0.788 , 0.7876, 0.7847,\n",
       "            0.7837, 0.783 , 0.7827, 0.782 , 0.7817, 0.78  , 0.7773, 0.775 ,\n",
       "            0.7744, 0.769 , 0.7686, 0.7676, 0.766 , 0.7637, 0.762 , 0.761 ,\n",
       "            0.7593, 0.753 , 0.7456, 0.7407, 0.7363, 0.7324, 0.731 , 0.7295,\n",
       "            0.728 , 0.727 , 0.726 , 0.7207, 0.719 , 0.7183, 0.7173, 0.716 ,\n",
       "            0.712 , 0.711 , 0.7104, 0.7085, 0.704 , 0.699 , 0.6963, 0.693 ,\n",
       "            0.6885, 0.6836, 0.6787, 0.6772, 0.6733, 0.669 , 0.661 , 0.649 ,\n",
       "            0.6455, 0.642 , 0.639 , 0.6304, 0.618 , 0.6133, 0.6084, 0.596 ,\n",
       "            0.591 , 0.572 , 0.57  , 0.5693, 0.5605, 0.553 , 0.536 , 0.5215,\n",
       "            0.518 , 0.5166, 0.5073, 0.499 , 0.495 , 0.474 , 0.4634, 0.459 ,\n",
       "            0.4573, 0.4458, 0.4326, 0.4312, 0.418 , 0.4148, 0.402 , 0.395 ,\n",
       "            0.3948, 0.3884, 0.3877, 0.3826, 0.3623, 0.3523, 0.35  , 0.349 ,\n",
       "            0.3481, 0.341 , 0.339 , 0.3186, 0.3142, 0.309 , 0.3022, 0.258 ,\n",
       "            0.2566, 0.2352, 0.2302, 0.2269, 0.2203, 0.2147, 0.2095, 0.1967,\n",
       "            0.1866, 0.1758, 0.1685, 0.1653, 0.153 , 0.1516, 0.1465, 0.1355],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.64166665, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.09166667, 0.09166667, 0.09166667,\n",
       "            0.1       , 0.11666667, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.14166667, 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.16666667, 0.175     , 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.19166666, 0.2       , 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25      , 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.28333333, 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.31538463, 0.32307693, 0.33846155, 0.33846155, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36153847, 0.36153847,\n",
       "            0.36153847, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.45384616, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.5153846 ,\n",
       "            0.5153846 , 0.5153846 , 0.52307695, 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.5538462 , 0.5692308 , 0.5692308 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9507, 0.929 , 0.9272, 0.918 , 0.9165, 0.9155, 0.914 ,\n",
       "            0.9136, 0.909 , 0.9087, 0.907 , 0.905 , 0.904 , 0.9023, 0.899 ,\n",
       "            0.897 , 0.896 , 0.8955, 0.895 , 0.8945, 0.893 , 0.8926, 0.892 ,\n",
       "            0.8906, 0.89  , 0.8896, 0.889 , 0.8887, 0.887 , 0.8867, 0.8853,\n",
       "            0.885 , 0.8843, 0.882 , 0.8813, 0.881 , 0.8804, 0.879 , 0.878 ,\n",
       "            0.877 , 0.8765, 0.876 , 0.875 , 0.8726, 0.871 , 0.868 , 0.8667,\n",
       "            0.866 , 0.8657, 0.8643, 0.862 , 0.8613, 0.861 , 0.8604, 0.8594,\n",
       "            0.859 , 0.8564, 0.856 , 0.855 , 0.8535, 0.853 , 0.8525, 0.8516,\n",
       "            0.8496, 0.8477, 0.847 , 0.846 , 0.845 , 0.8447, 0.8433, 0.843 ,\n",
       "            0.842 , 0.841 , 0.8403, 0.84  , 0.839 , 0.8384, 0.8374, 0.8364,\n",
       "            0.836 , 0.8345, 0.834 , 0.8335, 0.8325, 0.832 , 0.831 , 0.83  ,\n",
       "            0.829 , 0.828 , 0.8257, 0.824 , 0.823 , 0.8228, 0.822 , 0.821 ,\n",
       "            0.82  , 0.8184, 0.814 , 0.8125, 0.8115, 0.811 , 0.8105, 0.81  ,\n",
       "            0.8057, 0.8037, 0.8027, 0.8013, 0.8003, 0.799 , 0.7954, 0.7944,\n",
       "            0.7925, 0.7915, 0.7896, 0.7876, 0.786 , 0.7856, 0.7837, 0.783 ,\n",
       "            0.7817, 0.781 , 0.77  , 0.763 , 0.7627, 0.756 , 0.7534, 0.752 ,\n",
       "            0.7515, 0.7476, 0.7456, 0.744 , 0.7437, 0.742 , 0.7397, 0.7373,\n",
       "            0.737 , 0.7363, 0.734 , 0.731 , 0.729 , 0.726 , 0.7256, 0.716 ,\n",
       "            0.712 , 0.7085, 0.704 , 0.703 , 0.698 , 0.6973, 0.6963, 0.688 ,\n",
       "            0.6636, 0.663 , 0.659 , 0.6553, 0.6436, 0.6313, 0.6274, 0.626 ,\n",
       "            0.608 , 0.6025, 0.59  , 0.5835, 0.5796, 0.571 , 0.5645, 0.546 ,\n",
       "            0.5454, 0.5317, 0.5303, 0.516 , 0.5156, 0.5146, 0.484 , 0.4717,\n",
       "            0.4678, 0.466 , 0.4524, 0.4402, 0.4377, 0.4275, 0.4243, 0.4111,\n",
       "            0.402 , 0.4019, 0.3945, 0.3926, 0.392 , 0.3665, 0.3555, 0.3538,\n",
       "            0.3535, 0.3533, 0.345 , 0.344 , 0.322 , 0.3198, 0.3115, 0.3086,\n",
       "            0.2595, 0.259 , 0.2388, 0.2327, 0.2303, 0.2238, 0.2148, 0.2098,\n",
       "            0.1982, 0.1864, 0.1761, 0.1686, 0.1547, 0.1511, 0.1464, 0.1376],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.64166665, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.23333333, 0.23333333, 0.23333333, 0.23333333,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25      , 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.3       , 0.3       , 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.04615385, 0.05384615, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.13076924, 0.13846155, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.22307692, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.2769231 , 0.2846154 , 0.3       ,\n",
       "            0.31538463, 0.32307693, 0.33846155, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.3846154 , 0.4       , 0.4076923 , 0.42307693, 0.42307693,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.46923077, 0.46923077, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.958 , 0.939 , 0.9365, 0.929 , 0.927 , 0.926 , 0.9243,\n",
       "            0.92  , 0.9194, 0.916 , 0.915 , 0.9136, 0.9106, 0.9087, 0.9077,\n",
       "            0.907 , 0.9062, 0.905 , 0.904 , 0.903 , 0.9023, 0.902 , 0.9014,\n",
       "            0.9004, 0.8994, 0.899 , 0.8984, 0.8965, 0.894 , 0.8936, 0.893 ,\n",
       "            0.8926, 0.8916, 0.8906, 0.8896, 0.889 , 0.8887, 0.8857, 0.8843,\n",
       "            0.884 , 0.882 , 0.8804, 0.8784, 0.876 , 0.875 , 0.8735, 0.873 ,\n",
       "            0.8726, 0.872 , 0.8687, 0.867 , 0.8667, 0.8657, 0.865 , 0.8647,\n",
       "            0.8643, 0.8633, 0.861 , 0.86  , 0.8594, 0.859 , 0.8584, 0.8574,\n",
       "            0.857 , 0.8564, 0.8555, 0.855 , 0.854 , 0.853 , 0.852 , 0.851 ,\n",
       "            0.8506, 0.8496, 0.848 , 0.8477, 0.8467, 0.8447, 0.8438, 0.843 ,\n",
       "            0.8413, 0.84  , 0.8384, 0.8374, 0.837 , 0.8364, 0.836 , 0.8354,\n",
       "            0.835 , 0.8335, 0.832 , 0.8296, 0.828 , 0.8267, 0.8257, 0.825 ,\n",
       "            0.824 , 0.821 , 0.82  , 0.818 , 0.8174, 0.8164, 0.8154, 0.8145,\n",
       "            0.813 , 0.8105, 0.809 , 0.8066, 0.806 , 0.8057, 0.803 , 0.8027,\n",
       "            0.8013, 0.8   , 0.7993, 0.7974, 0.796 , 0.7837, 0.78  , 0.7773,\n",
       "            0.774 , 0.772 , 0.768 , 0.7676, 0.7656, 0.7637, 0.763 , 0.7627,\n",
       "            0.7617, 0.7583, 0.7563, 0.756 , 0.753 , 0.7505, 0.747 , 0.7466,\n",
       "            0.745 , 0.743 , 0.733 , 0.7324, 0.7266, 0.7236, 0.7217, 0.7188,\n",
       "            0.7173, 0.712 , 0.7104, 0.684 , 0.6763, 0.6724, 0.668 , 0.6562,\n",
       "            0.645 , 0.6436, 0.6377, 0.62  , 0.6143, 0.609 , 0.595 , 0.591 ,\n",
       "            0.582 , 0.576 , 0.5713, 0.556 , 0.547 , 0.541 , 0.5356, 0.5303,\n",
       "            0.526 , 0.495 , 0.4814, 0.4783, 0.4768, 0.4612, 0.45  , 0.4465,\n",
       "            0.4417, 0.4329, 0.4219, 0.4114, 0.4111, 0.4036, 0.403 , 0.4   ,\n",
       "            0.373 , 0.3613, 0.3606, 0.3604, 0.3596, 0.3533, 0.3496, 0.3281,\n",
       "            0.328 , 0.3176, 0.317 , 0.2642, 0.2632, 0.2451, 0.2378, 0.2363,\n",
       "            0.2295, 0.2177, 0.2128, 0.2024, 0.189 , 0.1788, 0.174 , 0.1714,\n",
       "            0.1587, 0.1532, 0.1488, 0.1417], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.65, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.09166667, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.225     , 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.24166666, 0.25      ,\n",
       "            0.25      , 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.28333333, 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35      , 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.36666667, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.04615385, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.18461539, 0.2       , 0.20769231, 0.21538462, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.2769231 , 0.2769231 , 0.2923077 , 0.3       ,\n",
       "            0.32307693, 0.33846155, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.37692308, 0.3923077 , 0.3923077 , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.46153846, 0.46923077, 0.46923077, 0.4846154 ,\n",
       "            0.4923077 , 0.50769234, 0.50769234, 0.50769234, 0.5153846 ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5846154 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.65384614, 0.65384614, 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9644, 0.9473, 0.9453, 0.939 , 0.9365, 0.935 , 0.934 ,\n",
       "            0.93  , 0.929 , 0.9263, 0.9253, 0.924 , 0.9214, 0.9194, 0.918 ,\n",
       "            0.917 , 0.916 , 0.9155, 0.915 , 0.9136, 0.913 , 0.9116, 0.911 ,\n",
       "            0.91  , 0.9097, 0.908 , 0.9077, 0.9053, 0.905 , 0.9043, 0.904 ,\n",
       "            0.9033, 0.903 , 0.9023, 0.901 , 0.9004, 0.898 , 0.8975, 0.8965,\n",
       "            0.896 , 0.8936, 0.892 , 0.889 , 0.8887, 0.888 , 0.887 , 0.8867,\n",
       "            0.8857, 0.8853, 0.885 , 0.8813, 0.881 , 0.8804, 0.88  , 0.8784,\n",
       "            0.878 , 0.8774, 0.876 , 0.874 , 0.8735, 0.873 , 0.8726, 0.8716,\n",
       "            0.871 , 0.87  , 0.8696, 0.869 , 0.8687, 0.868 , 0.8667, 0.866 ,\n",
       "            0.8657, 0.865 , 0.8647, 0.864 , 0.8633, 0.863 , 0.8613, 0.861 ,\n",
       "            0.8594, 0.859 , 0.8574, 0.8564, 0.853 , 0.852 , 0.8516, 0.851 ,\n",
       "            0.8506, 0.8477, 0.8457, 0.8447, 0.844 , 0.8403, 0.84  , 0.839 ,\n",
       "            0.8374, 0.837 , 0.8345, 0.834 , 0.832 , 0.831 , 0.829 , 0.828 ,\n",
       "            0.8267, 0.8257, 0.823 , 0.8223, 0.821 , 0.8203, 0.8193, 0.8174,\n",
       "            0.816 , 0.8145, 0.811 , 0.798 , 0.7964, 0.7915, 0.7866, 0.7837,\n",
       "            0.783 , 0.782 , 0.7793, 0.778 , 0.7773, 0.7754, 0.772 , 0.7715,\n",
       "            0.769 , 0.7676, 0.7646, 0.762 , 0.761 , 0.76  , 0.7515, 0.7495,\n",
       "            0.7485, 0.743 , 0.7407, 0.7373, 0.735 , 0.7324, 0.725 , 0.705 ,\n",
       "            0.69  , 0.6855, 0.6807, 0.6694, 0.6626, 0.6562, 0.65  , 0.633 ,\n",
       "            0.628 , 0.6265, 0.6084, 0.6025, 0.597 , 0.5947, 0.589 , 0.5674,\n",
       "            0.563 , 0.556 , 0.5527, 0.547 , 0.537 , 0.5073, 0.4924, 0.4897,\n",
       "            0.4885, 0.4712, 0.461 , 0.4568, 0.4426, 0.434 , 0.422 , 0.4214,\n",
       "            0.4163, 0.4126, 0.4084, 0.3809, 0.3694, 0.3687, 0.3672, 0.3625,\n",
       "            0.3567, 0.3372, 0.3354, 0.3276, 0.3235, 0.2703, 0.2688, 0.2524,\n",
       "            0.244 , 0.2434, 0.2366, 0.2218, 0.217 , 0.2075, 0.1924, 0.1827,\n",
       "            0.1805, 0.1749, 0.1638, 0.1561, 0.152 , 0.147 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.65, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15      , 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.225     , 0.225     , 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.24166666, 0.24166666, 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.275     , 0.275     , 0.28333333, 0.3       , 0.3       ,\n",
       "            0.3       , 0.3       , 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.425     ,\n",
       "            0.425     , 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.13076924, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.1923077 , 0.2       ,\n",
       "            0.21538462, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.32307693, 0.33076924, 0.34615386,\n",
       "            0.34615386, 0.34615386, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.42307693, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.46923077, 0.47692308, 0.50769234, 0.50769234, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.54615384, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7076923 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.97  , 0.9546, 0.953 , 0.9478, 0.945 , 0.9434, 0.943 ,\n",
       "            0.9424, 0.9395, 0.939 , 0.9385, 0.9355, 0.9346, 0.933 , 0.931 ,\n",
       "            0.9287, 0.928 , 0.9277, 0.927 , 0.926 , 0.925 , 0.924 , 0.9233,\n",
       "            0.923 , 0.9214, 0.921 , 0.92  , 0.9185, 0.918 , 0.916 , 0.9155,\n",
       "            0.915 , 0.9146, 0.914 , 0.9136, 0.913 , 0.9116, 0.911 , 0.9106,\n",
       "            0.9097, 0.909 , 0.907 , 0.906 , 0.9053, 0.9043, 0.902 , 0.9014,\n",
       "            0.901 , 0.9   , 0.8994, 0.899 , 0.8984, 0.8975, 0.897 , 0.8965,\n",
       "            0.8936, 0.893 , 0.8926, 0.8916, 0.8906, 0.89  , 0.8896, 0.889 ,\n",
       "            0.888 , 0.887 , 0.886 , 0.8857, 0.8843, 0.883 , 0.8823, 0.881 ,\n",
       "            0.8804, 0.88  , 0.8794, 0.879 , 0.8784, 0.878 , 0.8774, 0.877 ,\n",
       "            0.876 , 0.8755, 0.875 , 0.874 , 0.8726, 0.872 , 0.8716, 0.87  ,\n",
       "            0.869 , 0.8667, 0.8657, 0.865 , 0.8647, 0.8643, 0.864 , 0.8633,\n",
       "            0.863 , 0.861 , 0.86  , 0.859 , 0.858 , 0.8545, 0.854 , 0.8525,\n",
       "            0.852 , 0.8516, 0.8506, 0.85  , 0.847 , 0.845 , 0.8423, 0.8413,\n",
       "            0.8403, 0.8394, 0.837 , 0.8364, 0.8335, 0.832 , 0.831 , 0.83  ,\n",
       "            0.829 , 0.8286, 0.8257, 0.824 , 0.8125, 0.8105, 0.8096, 0.808 ,\n",
       "            0.806 , 0.805 , 0.8022, 0.799 , 0.7954, 0.7944, 0.7935, 0.7925,\n",
       "            0.791 , 0.788 , 0.7866, 0.786 , 0.7837, 0.7783, 0.7773, 0.7764,\n",
       "            0.776 , 0.7695, 0.7686, 0.7646, 0.7617, 0.761 , 0.7554, 0.753 ,\n",
       "            0.7476, 0.7373, 0.723 , 0.701 , 0.6973, 0.692 , 0.6807, 0.6777,\n",
       "            0.6675, 0.6606, 0.644 , 0.6426, 0.636 , 0.6196, 0.6177, 0.6113,\n",
       "            0.6035, 0.598 , 0.5757, 0.575 , 0.5728, 0.5605, 0.5596, 0.5444,\n",
       "            0.5156, 0.499 , 0.4973, 0.496 , 0.4768, 0.4678, 0.4675, 0.4624,\n",
       "            0.448 , 0.4417, 0.4282, 0.4272, 0.4243, 0.4177, 0.4126, 0.3843,\n",
       "            0.3735, 0.372 , 0.3713, 0.3699, 0.3674, 0.359 , 0.3418, 0.3384,\n",
       "            0.3333, 0.3254, 0.272 , 0.2693, 0.2551, 0.2462, 0.2456, 0.239 ,\n",
       "            0.2216, 0.2167, 0.2085, 0.1917, 0.1829, 0.1824, 0.1747, 0.165 ,\n",
       "            0.1554, 0.1516, 0.1486], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.675, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.125     , 0.125     , 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.2       , 0.2       , 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.275     , 0.275     , 0.28333333, 0.3       , 0.3       ,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.45      ,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.15384616, 0.16153847, 0.17692308, 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26923078, 0.2846154 ,\n",
       "            0.3       , 0.31538463, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.37692308, 0.3923077 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.43846154, 0.44615385, 0.46153846, 0.46923077,\n",
       "            0.46923077, 0.5       , 0.50769234, 0.50769234, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.5769231 , 0.5923077 , 0.6       , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.64615387, 0.64615387, 0.64615387, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 , 0.7       ,\n",
       "            0.7153846 , 0.7153846 , 0.7153846 , 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.975 , 0.9614, 0.9595, 0.955 , 0.952 , 0.951 , 0.9507,\n",
       "            0.95  , 0.948 , 0.947 , 0.9463, 0.944 , 0.943 , 0.9414, 0.9395,\n",
       "            0.9375, 0.937 , 0.9365, 0.936 , 0.9355, 0.9346, 0.9336, 0.9326,\n",
       "            0.932 , 0.931 , 0.9307, 0.929 , 0.9277, 0.9272, 0.9263, 0.9253,\n",
       "            0.925 , 0.9243, 0.924 , 0.923 , 0.922 , 0.9214, 0.921 , 0.9204,\n",
       "            0.9194, 0.917 , 0.9165, 0.9155, 0.9146, 0.912 , 0.9116, 0.9106,\n",
       "            0.9097, 0.9087, 0.9077, 0.907 , 0.9067, 0.9043, 0.904 , 0.903 ,\n",
       "            0.902 , 0.9014, 0.9004, 0.9   , 0.8994, 0.8975, 0.897 , 0.8965,\n",
       "            0.8945, 0.894 , 0.893 , 0.892 , 0.8916, 0.8906, 0.89  , 0.889 ,\n",
       "            0.8887, 0.8877, 0.887 , 0.886 , 0.8857, 0.8843, 0.8833, 0.882 ,\n",
       "            0.881 , 0.8794, 0.8774, 0.877 , 0.8765, 0.8755, 0.8745, 0.874 ,\n",
       "            0.8735, 0.8706, 0.867 , 0.8667, 0.8647, 0.8643, 0.864 , 0.863 ,\n",
       "            0.86  , 0.858 , 0.855 , 0.8535, 0.852 , 0.851 , 0.849 , 0.8467,\n",
       "            0.8457, 0.8447, 0.8433, 0.843 , 0.8423, 0.839 , 0.8364, 0.8276,\n",
       "            0.8257, 0.8247, 0.8237, 0.82  , 0.8184, 0.8135, 0.8105, 0.8096,\n",
       "            0.8086, 0.807 , 0.8057, 0.804 , 0.8013, 0.7993, 0.7983, 0.792 ,\n",
       "            0.7915, 0.791 , 0.788 , 0.787 , 0.7812, 0.7803, 0.7793, 0.774 ,\n",
       "            0.773 , 0.7603, 0.7505, 0.742 , 0.7144, 0.71  , 0.7046, 0.6943,\n",
       "            0.694 , 0.68  , 0.673 , 0.6626, 0.6562, 0.6484, 0.644 , 0.6323,\n",
       "            0.624 , 0.6177, 0.611 , 0.593 , 0.592 , 0.588 , 0.576 , 0.573 ,\n",
       "            0.5576, 0.529 , 0.513 , 0.5103, 0.5093, 0.4897, 0.4841, 0.48  ,\n",
       "            0.4758, 0.46  , 0.455 , 0.4407, 0.4397, 0.4382, 0.4297, 0.4236,\n",
       "            0.395 , 0.3848, 0.383 , 0.3818, 0.3801, 0.3792, 0.3691, 0.3533,\n",
       "            0.3486, 0.3452, 0.3352, 0.281 , 0.279 , 0.265 , 0.2556, 0.2546,\n",
       "            0.2483, 0.2292, 0.2242, 0.2166, 0.1985, 0.1917, 0.1893, 0.1813,\n",
       "            0.1726, 0.1614, 0.1578, 0.156 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.69166666, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.23333333, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25      , 0.26666668, 0.275     , 0.275     ,\n",
       "            0.275     , 0.275     , 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.3       , 0.3       , 0.3       , 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35      , 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.45      ,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16153847, 0.17692308, 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26923078, 0.2846154 ,\n",
       "            0.2923077 , 0.30769232, 0.31538463, 0.33076924, 0.34615386,\n",
       "            0.34615386, 0.34615386, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.37692308, 0.37692308,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.42307693, 0.42307693,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.46153846, 0.46923077, 0.46923077, 0.4846154 ,\n",
       "            0.5       , 0.50769234, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.5538462 , 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.64615387, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.83076924, 0.84615386, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.979 , 0.967 , 0.9653, 0.962 , 0.959 , 0.9575, 0.957 ,\n",
       "            0.9556, 0.954 , 0.9536, 0.951 , 0.9507, 0.9487, 0.9473, 0.9453,\n",
       "            0.945 , 0.9443, 0.944 , 0.9434, 0.943 , 0.942 , 0.9414, 0.941 ,\n",
       "            0.9404, 0.9395, 0.939 , 0.938 , 0.9365, 0.936 , 0.935 , 0.934 ,\n",
       "            0.9336, 0.933 , 0.9326, 0.932 , 0.9316, 0.9307, 0.93  , 0.9297,\n",
       "            0.9287, 0.9272, 0.9263, 0.926 , 0.9253, 0.9233, 0.9224, 0.922 ,\n",
       "            0.921 , 0.92  , 0.9185, 0.9175, 0.917 , 0.9165, 0.915 , 0.9146,\n",
       "            0.914 , 0.913 , 0.9126, 0.912 , 0.911 , 0.9106, 0.91  , 0.9097,\n",
       "            0.9087, 0.908 , 0.907 , 0.906 , 0.9053, 0.905 , 0.9043, 0.903 ,\n",
       "            0.9014, 0.901 , 0.9   , 0.899 , 0.8984, 0.897 , 0.8955, 0.894 ,\n",
       "            0.8936, 0.8926, 0.8916, 0.8896, 0.889 , 0.888 , 0.8877, 0.887 ,\n",
       "            0.8867, 0.8857, 0.8853, 0.883 , 0.8823, 0.8804, 0.88  , 0.8794,\n",
       "            0.878 , 0.876 , 0.875 , 0.8745, 0.8716, 0.8706, 0.87  , 0.8667,\n",
       "            0.866 , 0.8657, 0.8647, 0.864 , 0.8613, 0.861 , 0.8574, 0.857 ,\n",
       "            0.8564, 0.856 , 0.8555, 0.852 , 0.8486, 0.842 , 0.8413, 0.839 ,\n",
       "            0.837 , 0.8364, 0.831 , 0.828 , 0.826 , 0.8237, 0.822 , 0.8213,\n",
       "            0.821 , 0.8193, 0.8154, 0.8125, 0.812 , 0.8066, 0.8057, 0.8047,\n",
       "            0.804 , 0.8003, 0.7974, 0.7935, 0.792 , 0.791 , 0.7734, 0.7637,\n",
       "            0.7603, 0.727 , 0.7227, 0.7173, 0.7104, 0.706 , 0.693 , 0.6846,\n",
       "            0.68  , 0.669 , 0.668 , 0.6606, 0.645 , 0.6357, 0.63  , 0.623 ,\n",
       "            0.613 , 0.6074, 0.5996, 0.593 , 0.5845, 0.569 , 0.5415, 0.525 ,\n",
       "            0.5225, 0.5215, 0.5005, 0.4917, 0.4868, 0.4707, 0.4678, 0.4521,\n",
       "            0.452 , 0.451 , 0.4402, 0.4333, 0.404 , 0.3948, 0.3926, 0.3906,\n",
       "            0.39  , 0.3887, 0.3777, 0.3638, 0.3572, 0.3567, 0.343 , 0.289 ,\n",
       "            0.2864, 0.274 , 0.2644, 0.2625, 0.257 , 0.2351, 0.2301, 0.2235,\n",
       "            0.2039, 0.2002, 0.195 , 0.1869, 0.1797, 0.1661, 0.1632, 0.163 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7083333, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.125     , 0.125     , 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.3       , 0.3       , 0.3       , 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.325     , 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.44166666, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.16153847, 0.16153847, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.25384617,\n",
       "            0.26923078, 0.2846154 , 0.2923077 , 0.30769232, 0.31538463,\n",
       "            0.33076924, 0.34615386, 0.34615386, 0.34615386, 0.36153847,\n",
       "            0.36923078, 0.36923078, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.46153846, 0.46923077,\n",
       "            0.4846154 , 0.5       , 0.5       , 0.5       , 0.5153846 ,\n",
       "            0.5307692 , 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63076925, 0.64615387,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7846154 , 0.7923077 ,\n",
       "            0.8076923 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9824, 0.972 , 0.9707, 0.968 , 0.965 , 0.964 , 0.963 ,\n",
       "            0.9624, 0.9604, 0.96  , 0.958 , 0.957 , 0.9556, 0.9546, 0.9526,\n",
       "            0.9517, 0.951 , 0.9507, 0.95  , 0.949 , 0.9487, 0.948 , 0.9478,\n",
       "            0.9473, 0.9463, 0.9453, 0.9443, 0.9434, 0.942 , 0.9414, 0.941 ,\n",
       "            0.9404, 0.94  , 0.939 , 0.9385, 0.938 , 0.9375, 0.9365, 0.9355,\n",
       "            0.935 , 0.9346, 0.933 , 0.9316, 0.931 , 0.9307, 0.929 , 0.9277,\n",
       "            0.9272, 0.927 , 0.9263, 0.9253, 0.925 , 0.9243, 0.924 , 0.923 ,\n",
       "            0.9224, 0.921 , 0.92  , 0.9194, 0.9185, 0.918 , 0.9175, 0.917 ,\n",
       "            0.9165, 0.916 , 0.9146, 0.914 , 0.9136, 0.913 , 0.9126, 0.9116,\n",
       "            0.911 , 0.9106, 0.91  , 0.9097, 0.909 , 0.9087, 0.907 , 0.9062,\n",
       "            0.906 , 0.9053, 0.9043, 0.9033, 0.903 , 0.9004, 0.9   , 0.899 ,\n",
       "            0.8984, 0.8975, 0.8965, 0.8945, 0.893 , 0.891 , 0.8906, 0.887 ,\n",
       "            0.8867, 0.886 , 0.8853, 0.883 , 0.8823, 0.8813, 0.8794, 0.8784,\n",
       "            0.878 , 0.8774, 0.877 , 0.875 , 0.874 , 0.8726, 0.869 , 0.868 ,\n",
       "            0.8677, 0.8643, 0.861 , 0.858 , 0.856 , 0.8555, 0.853 , 0.8525,\n",
       "            0.8486, 0.8433, 0.842 , 0.8413, 0.8374, 0.835 , 0.834 , 0.8325,\n",
       "            0.829 , 0.8257, 0.8247, 0.82  , 0.8193, 0.8184, 0.8174, 0.8145,\n",
       "            0.8105, 0.8076, 0.807 , 0.786 , 0.7783, 0.7764, 0.7397, 0.736 ,\n",
       "            0.7305, 0.727 , 0.719 , 0.7056, 0.6987, 0.6973, 0.693 , 0.6826,\n",
       "            0.6733, 0.659 , 0.6484, 0.6436, 0.636 , 0.6343, 0.6245, 0.6123,\n",
       "            0.61  , 0.5977, 0.5815, 0.555 , 0.5396, 0.536 , 0.535 , 0.518 ,\n",
       "            0.5137, 0.505 , 0.5005, 0.4832, 0.4824, 0.467 , 0.4656, 0.464 ,\n",
       "            0.453 , 0.445 , 0.4153, 0.4067, 0.404 , 0.4026, 0.4016, 0.3997,\n",
       "            0.3884, 0.3765, 0.3704, 0.3684, 0.3535, 0.299 , 0.2966, 0.285 ,\n",
       "            0.2751, 0.2725, 0.2678, 0.2434, 0.2383, 0.2325, 0.2114, 0.2106,\n",
       "            0.2028, 0.1943, 0.1885, 0.1729, 0.1721, 0.1699], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7083333, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.075     , 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.125     , 0.125     ,\n",
       "            0.125     , 0.125     , 0.125     , 0.13333334, 0.15      ,\n",
       "            0.15      , 0.15833333, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.2       , 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.3       , 0.3       , 0.3       ,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.375     , 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.17692308, 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.25384617, 0.26923078,\n",
       "            0.2769231 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.33076924, 0.34615386, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46923077, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.50769234, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.6230769 , 0.63076925,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7076923 , 0.7153846 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.76153845, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.986 , 0.9766, 0.975 , 0.9727, 0.9697, 0.969 , 0.9688,\n",
       "            0.9683, 0.968 , 0.966 , 0.9653, 0.964 , 0.963 , 0.9614, 0.9604,\n",
       "            0.959 , 0.958 , 0.9575, 0.957 , 0.9565, 0.956 , 0.955 , 0.9546,\n",
       "            0.953 , 0.952 , 0.951 , 0.9507, 0.949 , 0.9487, 0.948 , 0.9478,\n",
       "            0.9473, 0.947 , 0.9463, 0.946 , 0.9453, 0.945 , 0.9443, 0.9434,\n",
       "            0.943 , 0.9424, 0.942 , 0.9404, 0.9395, 0.939 , 0.9375, 0.936 ,\n",
       "            0.9355, 0.935 , 0.9346, 0.934 , 0.9336, 0.933 , 0.9326, 0.932 ,\n",
       "            0.9316, 0.931 , 0.929 , 0.9287, 0.928 , 0.9277, 0.9272, 0.927 ,\n",
       "            0.9263, 0.926 , 0.9253, 0.924 , 0.9233, 0.923 , 0.922 , 0.921 ,\n",
       "            0.9204, 0.9194, 0.919 , 0.918 , 0.917 , 0.9165, 0.916 , 0.9136,\n",
       "            0.9126, 0.9116, 0.9106, 0.91  , 0.909 , 0.9077, 0.9067, 0.9062,\n",
       "            0.905 , 0.9043, 0.9033, 0.9023, 0.902 , 0.9014, 0.8975, 0.897 ,\n",
       "            0.8965, 0.8955, 0.893 , 0.892 , 0.8916, 0.89  , 0.889 , 0.8887,\n",
       "            0.8877, 0.886 , 0.8857, 0.8833, 0.8804, 0.88  , 0.8794, 0.879 ,\n",
       "            0.876 , 0.8726, 0.872 , 0.8696, 0.868 , 0.8667, 0.866 , 0.86  ,\n",
       "            0.855 , 0.852 , 0.8506, 0.848 , 0.8477, 0.8457, 0.8447, 0.8423,\n",
       "            0.841 , 0.8384, 0.837 , 0.8354, 0.834 , 0.8335, 0.833 , 0.8325,\n",
       "            0.83  , 0.8296, 0.827 , 0.823 , 0.82  , 0.7983, 0.7954, 0.789 ,\n",
       "            0.752 , 0.748 , 0.743 , 0.7427, 0.7314, 0.7183, 0.716 , 0.7153,\n",
       "            0.709 , 0.695 , 0.6855, 0.6714, 0.66  , 0.656 , 0.6543, 0.6484,\n",
       "            0.64  , 0.626 , 0.6235, 0.6094, 0.5923, 0.5674, 0.551 , 0.5474,\n",
       "            0.5464, 0.534 , 0.5234, 0.5156, 0.5107, 0.4944, 0.493 , 0.48  ,\n",
       "            0.4763, 0.4744, 0.4626, 0.4536, 0.423 , 0.4155, 0.4124, 0.409 ,\n",
       "            0.407 , 0.3955, 0.386 , 0.3809, 0.3757, 0.36  , 0.3052, 0.302 ,\n",
       "            0.2927, 0.2827, 0.2788, 0.2751, 0.2477, 0.2424, 0.2379, 0.2179,\n",
       "            0.215 , 0.2065, 0.1982, 0.1941, 0.178 , 0.1758, 0.1733],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.725, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.075     ,\n",
       "            0.075     , 0.09166667, 0.09166667, 0.09166667, 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15      , 0.15833333,\n",
       "            0.15833333, 0.175     , 0.175     , 0.175     , 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.2       , 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.275     , 0.29166666, 0.29166666, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.375     , 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03846154, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.13076924, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.18461539, 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2846154 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.33846155, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.44615385, 0.46153846, 0.4846154 , 0.5       ,\n",
       "            0.50769234, 0.50769234, 0.52307695, 0.5307692 , 0.54615384,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.6076923 , 0.6230769 , 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.6769231 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8       , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9883, 0.98  , 0.979 , 0.977 , 0.9746, 0.9736, 0.973 ,\n",
       "            0.9707, 0.97  , 0.9688, 0.9683, 0.967 , 0.9663, 0.9644, 0.964 ,\n",
       "            0.9634, 0.963 , 0.9624, 0.962 , 0.961 , 0.9604, 0.959 , 0.9585,\n",
       "            0.9575, 0.9565, 0.956 , 0.9556, 0.955 , 0.9546, 0.954 , 0.9536,\n",
       "            0.953 , 0.9526, 0.952 , 0.9507, 0.95  , 0.949 , 0.9478, 0.947 ,\n",
       "            0.9453, 0.944 , 0.9434, 0.943 , 0.9424, 0.942 , 0.9414, 0.941 ,\n",
       "            0.94  , 0.9395, 0.9375, 0.937 , 0.9365, 0.936 , 0.9355, 0.935 ,\n",
       "            0.9346, 0.934 , 0.9336, 0.9326, 0.932 , 0.931 , 0.9307, 0.93  ,\n",
       "            0.9297, 0.929 , 0.928 , 0.9277, 0.927 , 0.9263, 0.926 , 0.9253,\n",
       "            0.9233, 0.9224, 0.922 , 0.9214, 0.9204, 0.9185, 0.917 , 0.916 ,\n",
       "            0.9155, 0.915 , 0.9146, 0.913 , 0.912 , 0.9116, 0.9077, 0.9067,\n",
       "            0.906 , 0.9053, 0.904 , 0.9033, 0.903 , 0.9023, 0.9004, 0.9   ,\n",
       "            0.899 , 0.898 , 0.8975, 0.896 , 0.893 , 0.891 , 0.8906, 0.89  ,\n",
       "            0.889 , 0.887 , 0.8857, 0.883 , 0.8823, 0.8804, 0.88  , 0.879 ,\n",
       "            0.8706, 0.868 , 0.8677, 0.8657, 0.863 , 0.861 , 0.8604, 0.857 ,\n",
       "            0.8564, 0.856 , 0.8555, 0.851 , 0.8506, 0.848 , 0.847 , 0.846 ,\n",
       "            0.8457, 0.845 , 0.844 , 0.843 , 0.8413, 0.838 , 0.833 , 0.8105,\n",
       "            0.8013, 0.764 , 0.7603, 0.7573, 0.7554, 0.743 , 0.7354, 0.7314,\n",
       "            0.7305, 0.7207, 0.7065, 0.697 , 0.683 , 0.672 , 0.671 , 0.667 ,\n",
       "            0.6597, 0.654 , 0.64  , 0.634 , 0.6196, 0.602 , 0.5776, 0.56  ,\n",
       "            0.5566, 0.5557, 0.547 , 0.5317, 0.524 , 0.519 , 0.504 , 0.5005,\n",
       "            0.49  , 0.484 , 0.482 , 0.4692, 0.4592, 0.4277, 0.4211, 0.4187,\n",
       "            0.4175, 0.413 , 0.4111, 0.3992, 0.3918, 0.3877, 0.3796, 0.363 ,\n",
       "            0.3076, 0.304 , 0.2961, 0.286 , 0.2812, 0.2783, 0.2478, 0.2426,\n",
       "            0.2391, 0.2205, 0.2145, 0.2063, 0.1978, 0.1952, 0.1796, 0.1748,\n",
       "            0.1727], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.73333335, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.075     , 0.075     , 0.09166667, 0.09166667, 0.09166667,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.175     , 0.175     , 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25      , 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.13846155, 0.15384616, 0.15384616,\n",
       "            0.16153847, 0.1923077 , 0.20769231, 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23076923, 0.24615385, 0.25384617,\n",
       "            0.26923078, 0.2846154 , 0.3       , 0.31538463, 0.32307693,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.43846154, 0.44615385, 0.46153846, 0.4923077 ,\n",
       "            0.50769234, 0.50769234, 0.52307695, 0.5307692 , 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.6230769 , 0.6230769 , 0.6230769 ,\n",
       "            0.63846153, 0.65384614, 0.6615385 , 0.6769231 , 0.6846154 ,\n",
       "            0.7       , 0.7       , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.99  , 0.9834, 0.9824, 0.981 , 0.9785, 0.978 , 0.9775,\n",
       "            0.977 , 0.975 , 0.9746, 0.9736, 0.973 , 0.9717, 0.9707, 0.969 ,\n",
       "            0.9688, 0.9683, 0.968 , 0.9673, 0.967 , 0.9663, 0.966 , 0.965 ,\n",
       "            0.9644, 0.964 , 0.9634, 0.963 , 0.9624, 0.962 , 0.961 , 0.9604,\n",
       "            0.96  , 0.9595, 0.959 , 0.9585, 0.958 , 0.957 , 0.9556, 0.9546,\n",
       "            0.9536, 0.952 , 0.9507, 0.9497, 0.949 , 0.9487, 0.948 , 0.9478,\n",
       "            0.9473, 0.947 , 0.946 , 0.945 , 0.9443, 0.944 , 0.9434, 0.943 ,\n",
       "            0.9424, 0.942 , 0.9414, 0.941 , 0.94  , 0.9395, 0.9385, 0.938 ,\n",
       "            0.9375, 0.936 , 0.9355, 0.935 , 0.9346, 0.934 , 0.9336, 0.933 ,\n",
       "            0.932 , 0.9316, 0.931 , 0.93  , 0.929 , 0.9272, 0.9253, 0.925 ,\n",
       "            0.924 , 0.923 , 0.922 , 0.921 , 0.9204, 0.9165, 0.9155, 0.9146,\n",
       "            0.9136, 0.913 , 0.912 , 0.9116, 0.91  , 0.9097, 0.909 , 0.908 ,\n",
       "            0.907 , 0.9053, 0.903 , 0.9014, 0.901 , 0.9004, 0.8994, 0.8984,\n",
       "            0.8975, 0.894 , 0.893 , 0.892 , 0.8906, 0.881 , 0.8804, 0.8794,\n",
       "            0.8784, 0.8765, 0.8745, 0.8735, 0.872 , 0.8696, 0.8677, 0.8657,\n",
       "            0.863 , 0.8604, 0.8594, 0.8584, 0.858 , 0.8574, 0.8525, 0.8516,\n",
       "            0.8457, 0.8257, 0.8223, 0.8135, 0.7764, 0.7725, 0.768 , 0.757 ,\n",
       "            0.756 , 0.7485, 0.743 , 0.733 , 0.719 , 0.709 , 0.6963, 0.6914,\n",
       "            0.683 , 0.68  , 0.673 , 0.6694, 0.6567, 0.646 , 0.6323, 0.6143,\n",
       "            0.591 , 0.573 , 0.5693, 0.569 , 0.564 , 0.544 , 0.5366, 0.5317,\n",
       "            0.5176, 0.512 , 0.505 , 0.4966, 0.4944, 0.4812, 0.4702, 0.438 ,\n",
       "            0.4324, 0.4304, 0.428 , 0.4233, 0.421 , 0.409 , 0.4036, 0.4001,\n",
       "            0.3896, 0.3723, 0.3164, 0.3127, 0.3062, 0.2957, 0.29  , 0.288 ,\n",
       "            0.2546, 0.2493, 0.247 , 0.2299, 0.2205, 0.2125, 0.2039, 0.2029,\n",
       "            0.1874, 0.1803, 0.1783], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.75, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.09166667, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.15      , 0.15      ,\n",
       "            0.16666667, 0.175     , 0.175     , 0.175     , 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.19166666, 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25      , 0.25      ,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.29166666, 0.29166666, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.34166667, 0.35      , 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.36666667, 0.36666667,\n",
       "            0.36666667, 0.36666667, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.45      , 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.13846155, 0.15384616, 0.16153847,\n",
       "            0.18461539, 0.2       , 0.20769231, 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.2769231 , 0.30769232, 0.31538463, 0.32307693, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.37692308, 0.3846154 ,\n",
       "            0.4       , 0.4076923 , 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.43846154, 0.44615385, 0.46153846, 0.4923077 ,\n",
       "            0.50769234, 0.5307692 , 0.53846157, 0.54615384, 0.54615384,\n",
       "            0.5538462 , 0.5769231 , 0.5769231 , 0.5846154 , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.6230769 , 0.6230769 , 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9153846 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.992 , 0.9863, 0.9854, 0.984 , 0.982 , 0.9814, 0.981 ,\n",
       "            0.9805, 0.979 , 0.9785, 0.9775, 0.977 , 0.9756, 0.975 , 0.9736,\n",
       "            0.973 , 0.9727, 0.972 , 0.9717, 0.971 , 0.9707, 0.97  , 0.9697,\n",
       "            0.969 , 0.9688, 0.9683, 0.9673, 0.967 , 0.9663, 0.966 , 0.9653,\n",
       "            0.965 , 0.9644, 0.964 , 0.9634, 0.963 , 0.961 , 0.9604, 0.96  ,\n",
       "            0.9595, 0.958 , 0.957 , 0.9565, 0.956 , 0.9556, 0.955 , 0.9546,\n",
       "            0.954 , 0.9536, 0.953 , 0.9517, 0.951 , 0.9507, 0.95  , 0.9497,\n",
       "            0.9487, 0.948 , 0.9473, 0.946 , 0.9453, 0.945 , 0.944 , 0.9434,\n",
       "            0.943 , 0.9424, 0.942 , 0.9414, 0.941 , 0.9404, 0.94  , 0.939 ,\n",
       "            0.9385, 0.938 , 0.937 , 0.9365, 0.935 , 0.9336, 0.933 , 0.9326,\n",
       "            0.932 , 0.9316, 0.9307, 0.9297, 0.929 , 0.925 , 0.924 , 0.9233,\n",
       "            0.923 , 0.922 , 0.9204, 0.9194, 0.919 , 0.9175, 0.916 , 0.914 ,\n",
       "            0.911 , 0.9106, 0.91  , 0.9097, 0.909 , 0.9087, 0.9077, 0.907 ,\n",
       "            0.9053, 0.9033, 0.903 , 0.9014, 0.892 , 0.8906, 0.89  , 0.886 ,\n",
       "            0.8853, 0.885 , 0.883 , 0.879 , 0.8784, 0.878 , 0.8735, 0.872 ,\n",
       "            0.87  , 0.8696, 0.869 , 0.8643, 0.8633, 0.8574, 0.84  , 0.834 ,\n",
       "            0.825 , 0.788 , 0.7866, 0.785 , 0.7803, 0.777 , 0.7676, 0.764 ,\n",
       "            0.7554, 0.7446, 0.7324, 0.721 , 0.7104, 0.71  , 0.696 , 0.6934,\n",
       "            0.6855, 0.685 , 0.673 , 0.659 , 0.6455, 0.627 , 0.6045, 0.588 ,\n",
       "            0.583 , 0.5825, 0.5815, 0.557 , 0.55  , 0.5454, 0.532 , 0.525 ,\n",
       "            0.5205, 0.5103, 0.508 , 0.494 , 0.482 , 0.4497, 0.4446, 0.4436,\n",
       "            0.44  , 0.4346, 0.4321, 0.4202, 0.4165, 0.4143, 0.401 , 0.3828,\n",
       "            0.327 , 0.3235, 0.3179, 0.3071, 0.3005, 0.2993, 0.2634, 0.2578,\n",
       "            0.2563, 0.2411, 0.2285, 0.2207, 0.2125, 0.2119, 0.1973, 0.1873,\n",
       "            0.1858], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7583333, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.075     , 0.075     ,\n",
       "            0.09166667, 0.09166667, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.13333334, 0.13333334, 0.13333334,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.175     , 0.19166666, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.28333333, 0.28333333,\n",
       "            0.29166666, 0.29166666, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.33333334, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.36666667, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.90833336, 0.9166667 , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.04615385, 0.05384615, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.13846155, 0.15384616, 0.16923077, 0.1923077 ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23846154, 0.25384617,\n",
       "            0.2769231 , 0.3       , 0.30769232, 0.32307693, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.41538462, 0.42307693, 0.43846154, 0.43846154, 0.45384616,\n",
       "            0.46923077, 0.50769234, 0.5153846 , 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.54615384, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.6       , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.6230769 , 0.6230769 , 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7692308 , 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.8       , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.8769231 ,\n",
       "            0.88461536, 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9937, 0.9883, 0.988 , 0.987 , 0.985 , 0.9844, 0.984 ,\n",
       "            0.9834, 0.982 , 0.981 , 0.9805, 0.9795, 0.979 , 0.9775, 0.977 ,\n",
       "            0.9766, 0.976 , 0.9756, 0.975 , 0.9746, 0.9736, 0.973 , 0.9727,\n",
       "            0.9717, 0.9707, 0.97  , 0.9697, 0.969 , 0.9688, 0.9683, 0.968 ,\n",
       "            0.9663, 0.966 , 0.9653, 0.965 , 0.9634, 0.963 , 0.9614, 0.961 ,\n",
       "            0.9604, 0.96  , 0.9595, 0.9575, 0.957 , 0.9565, 0.956 , 0.9556,\n",
       "            0.955 , 0.9546, 0.954 , 0.9536, 0.9526, 0.9517, 0.951 , 0.9507,\n",
       "            0.9497, 0.949 , 0.9487, 0.948 , 0.9478, 0.9473, 0.947 , 0.946 ,\n",
       "            0.945 , 0.9443, 0.9434, 0.9424, 0.942 , 0.941 , 0.9404, 0.94  ,\n",
       "            0.9395, 0.939 , 0.938 , 0.9375, 0.9365, 0.9326, 0.932 , 0.9316,\n",
       "            0.9307, 0.93  , 0.928 , 0.9277, 0.926 , 0.9243, 0.9224, 0.9194,\n",
       "            0.919 , 0.9185, 0.9175, 0.916 , 0.915 , 0.9136, 0.9126, 0.912 ,\n",
       "            0.911 , 0.903 , 0.901 , 0.9004, 0.896 , 0.8955, 0.8945, 0.893 ,\n",
       "            0.891 , 0.8896, 0.888 , 0.8877, 0.885 , 0.8843, 0.8833, 0.8813,\n",
       "            0.881 , 0.8804, 0.88  , 0.876 , 0.8735, 0.8687, 0.853 , 0.8447,\n",
       "            0.836 , 0.7993, 0.799 , 0.7964, 0.796 , 0.7915, 0.7793, 0.779 ,\n",
       "            0.7666, 0.756 , 0.7437, 0.7324, 0.728 , 0.722 , 0.7065, 0.7056,\n",
       "            0.6997, 0.697 , 0.688 , 0.67  , 0.6567, 0.638 , 0.6167, 0.6   ,\n",
       "            0.597 , 0.5947, 0.594 , 0.5684, 0.561 , 0.557 , 0.5444, 0.5356,\n",
       "            0.5347, 0.5215, 0.519 , 0.5044, 0.4917, 0.4587, 0.4548, 0.4546,\n",
       "            0.4495, 0.4434, 0.4407, 0.429 , 0.4275, 0.4263, 0.41  , 0.3909,\n",
       "            0.335 , 0.3315, 0.3274, 0.3164, 0.3086, 0.2695, 0.2637, 0.2505,\n",
       "            0.234 , 0.2264, 0.22  , 0.2175, 0.2053, 0.1923, 0.1912],\n",
       "           dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.76865673, dtype=float32),\n",
       "    'tpr': array(0.7413793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.02238806,\n",
       "            0.02985075, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.07462686, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.10447761, 0.10447761, 0.1119403 , 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.1641791 , 0.18656716,\n",
       "            0.20149253, 0.20895523, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.25373134, 0.26865673, 0.2835821 , 0.29850745, 0.33582088,\n",
       "            0.36567163, 0.40298507, 0.41791046, 0.4552239 , 0.49253732,\n",
       "            0.52238804, 0.53731346, 0.5522388 , 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.619403  , 0.6492537 , 0.6641791 ,\n",
       "            0.6641791 , 0.67164177, 0.6865672 , 0.70149255, 0.7089552 ,\n",
       "            0.7238806 , 0.7238806 , 0.7238806 , 0.74626863, 0.76119405,\n",
       "            0.76865673, 0.7835821 , 0.7910448 , 0.79850745, 0.79850745,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.82835823, 0.8358209 ,\n",
       "            0.8358209 , 0.8507463 , 0.8507463 , 0.85820895, 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9328358 , 0.9328358 , 0.9402985 , 0.9402985 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.95522386, 0.95522386,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.97761196, 0.97761196, 0.98507464,\n",
       "            0.98507464, 0.9925373 , 0.9925373 , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.18965517, 0.19827586, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.22413793, 0.22413793, 0.22413793, 0.23275863, 0.25      ,\n",
       "            0.25862068, 0.27586207, 0.28448275, 0.29310346, 0.31034482,\n",
       "            0.31896552, 0.31896552, 0.3275862 , 0.3275862 , 0.3275862 ,\n",
       "            0.3448276 , 0.36206895, 0.37068966, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.39655173, 0.39655173, 0.39655173, 0.4051724 ,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.46551725, 0.47413793, 0.51724136, 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.57758623, 0.5948276 , 0.6034483 ,\n",
       "            0.62068963, 0.62068963, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.6551724 , 0.6637931 , 0.6637931 , 0.67241377, 0.6896552 ,\n",
       "            0.6896552 , 0.7241379 , 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5854, 0.579 , 0.576 , 0.575 , 0.5728, 0.5723, 0.5693,\n",
       "            0.567 , 0.5664, 0.5654, 0.5645, 0.5625, 0.5586, 0.558 , 0.5576,\n",
       "            0.556 , 0.551 , 0.549 , 0.5464, 0.5454, 0.5425, 0.5415, 0.541 ,\n",
       "            0.54  , 0.5386, 0.538 , 0.537 , 0.5366, 0.536 , 0.5356, 0.535 ,\n",
       "            0.5347, 0.534 , 0.533 , 0.531 , 0.5303, 0.5283, 0.528 , 0.5273,\n",
       "            0.5264, 0.5254, 0.525 , 0.5244, 0.523 , 0.5225, 0.522 , 0.521 ,\n",
       "            0.5205, 0.52  , 0.5195, 0.519 , 0.5186, 0.518 , 0.5176, 0.517 ,\n",
       "            0.5166, 0.516 , 0.5156, 0.515 , 0.5146, 0.514 , 0.5137, 0.513 ,\n",
       "            0.5127, 0.512 , 0.5117, 0.511 , 0.5107, 0.5103, 0.51  , 0.5093,\n",
       "            0.509 , 0.5083, 0.508 , 0.507 , 0.5063, 0.506 , 0.5054, 0.504 ,\n",
       "            0.5034, 0.503 , 0.502 , 0.5015, 0.501 , 0.5005, 0.5   , 0.4998,\n",
       "            0.4995, 0.4993, 0.499 , 0.4985, 0.4983, 0.4978, 0.4968, 0.4963,\n",
       "            0.496 , 0.4956, 0.4954, 0.495 , 0.4949, 0.4946, 0.4944, 0.4941,\n",
       "            0.494 , 0.4934, 0.4932, 0.493 , 0.4927, 0.4924, 0.4922, 0.4917,\n",
       "            0.4907, 0.4905, 0.4895, 0.4893, 0.489 , 0.4888, 0.488 , 0.4875,\n",
       "            0.487 , 0.4868, 0.4854, 0.4849, 0.4844, 0.484 , 0.4836, 0.483 ,\n",
       "            0.4827, 0.482 , 0.4817, 0.4812, 0.4807, 0.4792, 0.4783, 0.4766,\n",
       "            0.4756], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3880597, dtype=float32),\n",
       "    'tpr': array(0.2672414, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.05223881, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.15671642, 0.1641791 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20895523, 0.21641791, 0.23880596, 0.26865673,\n",
       "            0.2835821 , 0.30597016, 0.31343284, 0.32089552, 0.35820895,\n",
       "            0.36567163, 0.3880597 , 0.3955224 , 0.3955224 , 0.41044775,\n",
       "            0.41791046, 0.43283582, 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 ,\n",
       "            0.6641791 , 0.6641791 , 0.6641791 , 0.67164177, 0.6865672 ,\n",
       "            0.69402987, 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.7238806 , 0.7238806 , 0.73134327, 0.73134327,\n",
       "            0.74626863, 0.74626863, 0.75373137, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.76865673, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7835821 , 0.7910448 , 0.7910448 , 0.7910448 , 0.7910448 ,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9029851 , 0.9029851 , 0.9104478 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9477612 , 0.95522386, 0.95522386,\n",
       "            0.95522386, 0.96268654, 0.96268654, 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.97761196, 0.97761196,\n",
       "            0.98507464, 0.98507464, 0.98507464, 0.98507464, 0.98507464,\n",
       "            0.98507464, 0.9925373 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0775862 ,\n",
       "            0.09482758, 0.09482758, 0.10344828, 0.10344828, 0.12068965,\n",
       "            0.12068965, 0.12068965, 0.12931034, 0.12931034, 0.12931034,\n",
       "            0.12931034, 0.13793103, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1724138 , 0.1724138 , 0.18103448, 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.20689656, 0.20689656, 0.20689656,\n",
       "            0.20689656, 0.20689656, 0.21551724, 0.21551724, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.22413793, 0.22413793, 0.22413793,\n",
       "            0.22413793, 0.22413793, 0.2413793 , 0.2413793 , 0.25      ,\n",
       "            0.25      , 0.2672414 , 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.30172414, 0.30172414, 0.31896552, 0.31896552, 0.3275862 ,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.35344827,\n",
       "            0.35344827, 0.35344827, 0.36206895, 0.36206895, 0.37068966,\n",
       "            0.37068966, 0.37068966, 0.37068966, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.37931034, 0.38793105, 0.39655173, 0.39655173,\n",
       "            0.4051724 , 0.4224138 , 0.43965518, 0.43965518, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.5       , 0.5086207 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.6810345 , 0.6896552 , 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.73275864, 0.7413793 , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5522, 0.5503, 0.545 , 0.5425, 0.542 , 0.5415, 0.5376,\n",
       "            0.534 , 0.532 , 0.5317, 0.5303, 0.5293, 0.529 , 0.5283, 0.527 ,\n",
       "            0.5264, 0.526 , 0.525 , 0.5244, 0.524 , 0.5234, 0.523 , 0.521 ,\n",
       "            0.5205, 0.5176, 0.516 , 0.515 , 0.514 , 0.5137, 0.5127, 0.512 ,\n",
       "            0.5117, 0.511 , 0.5107, 0.5103, 0.51  , 0.509 , 0.5083, 0.508 ,\n",
       "            0.5073, 0.507 , 0.5063, 0.506 , 0.5054, 0.505 , 0.5044, 0.5034,\n",
       "            0.503 , 0.5024, 0.502 , 0.5005, 0.4998, 0.4993, 0.4988, 0.498 ,\n",
       "            0.4976, 0.497 , 0.4968, 0.4963, 0.4956, 0.4954, 0.4934, 0.4915,\n",
       "            0.4905, 0.4897, 0.4895, 0.4893, 0.489 , 0.4883, 0.488 , 0.4878,\n",
       "            0.4873, 0.487 , 0.4866, 0.4863, 0.486 , 0.4858, 0.4854, 0.485 ,\n",
       "            0.4846, 0.4844, 0.484 , 0.4836, 0.483 , 0.4827, 0.4824, 0.482 ,\n",
       "            0.4817, 0.4812, 0.481 , 0.4805, 0.4802, 0.48  , 0.4792, 0.479 ,\n",
       "            0.4788, 0.4785, 0.4783, 0.478 , 0.4778, 0.4775, 0.4773, 0.4768,\n",
       "            0.4763, 0.476 , 0.4758, 0.4756, 0.4753, 0.4736, 0.4734, 0.4731,\n",
       "            0.473 , 0.4724, 0.4722, 0.472 , 0.4717, 0.4714, 0.4712, 0.471 ,\n",
       "            0.4697, 0.4695, 0.4692, 0.469 , 0.4688, 0.4673, 0.4666, 0.4653,\n",
       "            0.4648, 0.4644, 0.464 , 0.4634, 0.463 , 0.4624, 0.4622, 0.4617,\n",
       "            0.4614, 0.461 , 0.46  , 0.4597, 0.4592, 0.4585, 0.458 , 0.4568,\n",
       "            0.456 , 0.4558, 0.4556, 0.455 , 0.4548, 0.454 , 0.4539, 0.4536,\n",
       "            0.4526, 0.4514, 0.4512, 0.4507, 0.4504, 0.45  , 0.4492, 0.4485,\n",
       "            0.4482, 0.4478, 0.4473, 0.4468, 0.443 , 0.4426, 0.4424, 0.4395,\n",
       "            0.431 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.14179105, dtype=float32),\n",
       "    'tpr': array(0.10344828, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.13432837, 0.14179105, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1641791 , 0.1716418 , 0.18656716, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.36567163, 0.37313432, 0.3880597 , 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6641791 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.6865672 , 0.6865672 ,\n",
       "            0.69402987, 0.69402987, 0.69402987, 0.69402987, 0.70149255,\n",
       "            0.70149255, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.7238806 , 0.7238806 , 0.7238806 , 0.73134327, 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.75373137, 0.75373137,\n",
       "            0.76119405, 0.76119405, 0.76865673, 0.7761194 , 0.7761194 ,\n",
       "            0.7835821 , 0.7835821 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.80597013, 0.8134328 , 0.8134328 , 0.82835823,\n",
       "            0.8432836 , 0.85820895, 0.86567163, 0.86567163, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8880597 , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.91791046,\n",
       "            0.91791046, 0.91791046, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.95522386, 0.95522386, 0.95522386, 0.96268654,\n",
       "            0.96268654, 0.96268654, 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.97761196, 0.97761196, 0.97761196, 0.98507464, 0.98507464,\n",
       "            0.9925373 , 0.9925373 , 0.9925373 , 0.9925373 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.03448276, 0.04310345, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0862069 , 0.0862069 , 0.0862069 , 0.0862069 ,\n",
       "            0.0862069 , 0.10344828, 0.10344828, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12068965, 0.12068965, 0.12068965, 0.12068965,\n",
       "            0.12068965, 0.12068965, 0.12068965, 0.12068965, 0.12068965,\n",
       "            0.12068965, 0.12931034, 0.12931034, 0.12931034, 0.12931034,\n",
       "            0.12931034, 0.12931034, 0.12931034, 0.12931034, 0.12931034,\n",
       "            0.13793103, 0.13793103, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.15517241, 0.1637931 , 0.1637931 , 0.1637931 , 0.1724138 ,\n",
       "            0.1724138 , 0.18965517, 0.19827586, 0.19827586, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.23275863, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25      , 0.25862068, 0.27586207,\n",
       "            0.28448275, 0.28448275, 0.28448275, 0.28448275, 0.29310346,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.4051724 ,\n",
       "            0.41379312, 0.41379312, 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.43965518, 0.43965518, 0.43965518, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.51724136,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7155172 , 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.82758623, 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8534483 , 0.86206895, 0.86206895, 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5293, 0.523 , 0.521 , 0.52  , 0.519 , 0.5176, 0.5166,\n",
       "            0.516 , 0.5156, 0.515 , 0.5146, 0.514 , 0.5137, 0.512 , 0.5107,\n",
       "            0.5093, 0.509 , 0.5073, 0.506 , 0.504 , 0.5034, 0.503 , 0.5024,\n",
       "            0.5015, 0.501 , 0.5005, 0.4998, 0.4995, 0.4983, 0.4978, 0.4973,\n",
       "            0.4968, 0.4966, 0.4963, 0.496 , 0.495 , 0.4949, 0.4946, 0.4941,\n",
       "            0.494 , 0.4937, 0.493 , 0.4924, 0.4922, 0.492 , 0.4917, 0.4915,\n",
       "            0.491 , 0.4905, 0.4902, 0.49  , 0.4897, 0.4895, 0.4893, 0.4883,\n",
       "            0.4875, 0.4866, 0.4856, 0.4846, 0.4841, 0.484 , 0.4832, 0.4827,\n",
       "            0.4822, 0.482 , 0.481 , 0.4797, 0.4792, 0.4785, 0.4778, 0.4768,\n",
       "            0.4763, 0.476 , 0.4744, 0.4734, 0.4727, 0.4724, 0.4712, 0.471 ,\n",
       "            0.4695, 0.4692, 0.469 , 0.4685, 0.4683, 0.4675, 0.4666, 0.4658,\n",
       "            0.4648, 0.4626, 0.4622, 0.4614, 0.461 , 0.4604, 0.46  , 0.4595,\n",
       "            0.459 , 0.4585, 0.4583, 0.458 , 0.4573, 0.4568, 0.4563, 0.456 ,\n",
       "            0.4556, 0.455 , 0.4543, 0.4539, 0.4536, 0.4524, 0.4512, 0.4507,\n",
       "            0.4504, 0.4502, 0.4497, 0.4495, 0.4487, 0.4475, 0.4473, 0.447 ,\n",
       "            0.4468, 0.4465, 0.4463, 0.4458, 0.4453, 0.4448, 0.4446, 0.4438,\n",
       "            0.443 , 0.4421, 0.4417, 0.4414, 0.4412, 0.4402, 0.44  , 0.439 ,\n",
       "            0.4387, 0.4385, 0.438 , 0.4377, 0.4373, 0.4368, 0.4363, 0.436 ,\n",
       "            0.4358, 0.4355, 0.435 , 0.434 , 0.4336, 0.4329, 0.4321, 0.4302,\n",
       "            0.43  , 0.4297, 0.4294, 0.4292, 0.4287, 0.4285, 0.427 , 0.426 ,\n",
       "            0.4253, 0.424 , 0.4226, 0.4214, 0.4211, 0.421 , 0.4204, 0.42  ,\n",
       "            0.4197, 0.4194, 0.4192, 0.4187, 0.4185, 0.4177, 0.4172, 0.4165,\n",
       "            0.4163, 0.4158, 0.4148, 0.4146, 0.4143, 0.414 , 0.4138, 0.4128,\n",
       "            0.4116, 0.4106, 0.4102, 0.41  , 0.4084, 0.408 , 0.403 , 0.402 ,\n",
       "            0.401 , 0.4006, 0.4001, 0.3843], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.07462686, dtype=float32),\n",
       "    'tpr': array(0.00862069, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.13432837, 0.13432837,\n",
       "            0.14925373, 0.15671642, 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.33582088, 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.619403  , 0.6268657 ,\n",
       "            0.6268657 , 0.6268657 , 0.63432837, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6791045 , 0.6865672 ,\n",
       "            0.6865672 , 0.6865672 , 0.6865672 , 0.69402987, 0.69402987,\n",
       "            0.69402987, 0.69402987, 0.69402987, 0.69402987, 0.69402987,\n",
       "            0.70149255, 0.7164179 , 0.7238806 , 0.7238806 , 0.7238806 ,\n",
       "            0.73134327, 0.73134327, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7761194 ,\n",
       "            0.7835821 , 0.7835821 , 0.7835821 , 0.7835821 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.82835823, 0.8358209 , 0.8358209 , 0.8358209 , 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.8731343 , 0.880597  , 0.8880597 , 0.8880597 ,\n",
       "            0.8955224 , 0.8955224 , 0.9029851 , 0.9104478 , 0.9104478 ,\n",
       "            0.9104478 , 0.9104478 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 0.9925373 , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.04310345, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.06896552, 0.06896552, 0.06896552, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.0862069 , 0.0862069 ,\n",
       "            0.0862069 , 0.10344828, 0.10344828, 0.10344828, 0.10344828,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.10344828, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.1724138 ,\n",
       "            0.18103448, 0.18103448, 0.18103448, 0.18965517, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.33620688,\n",
       "            0.3448276 , 0.3448276 , 0.35344827, 0.35344827, 0.36206895,\n",
       "            0.36206895, 0.37068966, 0.39655173, 0.4051724 , 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.43965518, 0.45689654,\n",
       "            0.46551725, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.54310346, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.7241379 , 0.7241379 , 0.7241379 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.76724136,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.80172414, 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.86206895, 0.87931037, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5137, 0.511 , 0.5107, 0.51  , 0.5083, 0.507 , 0.5063,\n",
       "            0.5034, 0.503 , 0.501 , 0.4985, 0.4932, 0.4924, 0.4922, 0.4917,\n",
       "            0.4915, 0.491 , 0.4902, 0.4897, 0.4893, 0.4888, 0.4885, 0.4883,\n",
       "            0.488 , 0.4878, 0.4875, 0.487 , 0.4866, 0.486 , 0.4856, 0.4854,\n",
       "            0.485 , 0.4849, 0.484 , 0.4832, 0.4827, 0.4824, 0.4822, 0.4817,\n",
       "            0.4812, 0.4807, 0.4802, 0.4795, 0.4788, 0.4783, 0.4778, 0.4775,\n",
       "            0.4773, 0.477 , 0.4766, 0.4763, 0.476 , 0.4758, 0.474 , 0.4731,\n",
       "            0.473 , 0.4722, 0.471 , 0.4707, 0.4702, 0.47  , 0.4692, 0.4678,\n",
       "            0.4668, 0.4666, 0.466 , 0.4639, 0.4631, 0.4617, 0.46  , 0.4595,\n",
       "            0.4592, 0.458 , 0.4575, 0.4563, 0.4558, 0.4553, 0.4514, 0.4512,\n",
       "            0.4495, 0.4492, 0.4473, 0.447 , 0.4465, 0.446 , 0.4429, 0.4426,\n",
       "            0.4421, 0.4407, 0.4402, 0.44  , 0.4395, 0.4385, 0.4375, 0.437 ,\n",
       "            0.4365, 0.4363, 0.436 , 0.4355, 0.4353, 0.435 , 0.4343, 0.4336,\n",
       "            0.4329, 0.4321, 0.4314, 0.4297, 0.4294, 0.4287, 0.4285, 0.4282,\n",
       "            0.427 , 0.4263, 0.4255, 0.4253, 0.4246, 0.4243, 0.4229, 0.4224,\n",
       "            0.4194, 0.4175, 0.4172, 0.417 , 0.4163, 0.416 , 0.4155, 0.4153,\n",
       "            0.415 , 0.4143, 0.414 , 0.4136, 0.413 , 0.4124, 0.412 , 0.4114,\n",
       "            0.411 , 0.4106, 0.4104, 0.41  , 0.407 , 0.4067, 0.4065, 0.4058,\n",
       "            0.4055, 0.4043, 0.404 , 0.403 , 0.4026, 0.4023, 0.4019, 0.4014,\n",
       "            0.4011, 0.401 , 0.4006, 0.4   , 0.3992, 0.3987, 0.3984, 0.398 ,\n",
       "            0.3977, 0.3965, 0.396 , 0.3953, 0.3938, 0.3936, 0.3916, 0.3901,\n",
       "            0.3892, 0.388 , 0.3877, 0.3875, 0.3872, 0.3865, 0.3862, 0.386 ,\n",
       "            0.3855, 0.3853, 0.385 , 0.3848, 0.3835, 0.3833, 0.383 , 0.3823,\n",
       "            0.382 , 0.3816, 0.3804, 0.3801, 0.3792, 0.379 , 0.3782, 0.3777,\n",
       "            0.376 , 0.3745, 0.3743, 0.3716, 0.3699, 0.3677, 0.367 , 0.3652,\n",
       "            0.3635, 0.3625, 0.362 , 0.361 , 0.355 , 0.3396], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.02238806, dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.17910448,\n",
       "            0.18656716, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.30597016, 0.31343284,\n",
       "            0.31343284, 0.32089552, 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41791046, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.619403  , 0.6268657 ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.63432837, 0.63432837,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.67164177, 0.67164177,\n",
       "            0.67164177, 0.67164177, 0.6791045 , 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.70149255, 0.70149255, 0.70149255,\n",
       "            0.70149255, 0.70149255, 0.70149255, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.7238806 , 0.73880595, 0.73880595,\n",
       "            0.75373137, 0.75373137, 0.76119405, 0.76865673, 0.76865673,\n",
       "            0.7835821 , 0.7835821 , 0.7910448 , 0.79850745, 0.79850745,\n",
       "            0.80597013, 0.80597013, 0.8134328 , 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.85820895, 0.85820895,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.880597  , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.95522386, 0.95522386,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.98507464, 0.98507464, 0.9925373 ,\n",
       "            0.9925373 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06034483, 0.06896552,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.13793103, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.23275863, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.37931034, 0.37931034, 0.38793105, 0.38793105,\n",
       "            0.39655173, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43965518, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.5       , 0.5       , 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.6034483 , 0.6034483 , 0.61206895, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.7155172 , 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.8534483 , 0.8534483 , 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.504 , 0.502 , 0.5015, 0.5   , 0.4993, 0.4973, 0.4966,\n",
       "            0.493 , 0.4912, 0.4897, 0.4895, 0.4844, 0.484 , 0.4836, 0.4834,\n",
       "            0.483 , 0.4822, 0.4805, 0.4802, 0.48  , 0.4792, 0.479 , 0.4788,\n",
       "            0.4785, 0.4783, 0.4778, 0.4773, 0.4766, 0.4763, 0.4756, 0.475 ,\n",
       "            0.4749, 0.4744, 0.4736, 0.4734, 0.4727, 0.4722, 0.4705, 0.4702,\n",
       "            0.4697, 0.4695, 0.4688, 0.4678, 0.4673, 0.4666, 0.4656, 0.465 ,\n",
       "            0.4646, 0.4644, 0.464 , 0.4631, 0.463 , 0.462 , 0.4617, 0.4612,\n",
       "            0.4604, 0.4575, 0.457 , 0.4563, 0.4543, 0.4531, 0.4514, 0.451 ,\n",
       "            0.4507, 0.4492, 0.445 , 0.4438, 0.4426, 0.442 , 0.4407, 0.4392,\n",
       "            0.4387, 0.4368, 0.4343, 0.434 , 0.4336, 0.4333, 0.433 , 0.43  ,\n",
       "            0.429 , 0.4253, 0.423 , 0.421 , 0.4204, 0.4182, 0.4177, 0.4167,\n",
       "            0.4163, 0.415 , 0.4146, 0.4138, 0.412 , 0.4116, 0.4114, 0.4104,\n",
       "            0.4102, 0.41  , 0.4087, 0.4084, 0.4077, 0.407 , 0.4067, 0.4058,\n",
       "            0.4045, 0.4043, 0.4001, 0.3997, 0.3994, 0.3975, 0.397 , 0.3955,\n",
       "            0.3953, 0.395 , 0.3948, 0.3936, 0.3933, 0.393 , 0.391 , 0.39  ,\n",
       "            0.3896, 0.3894, 0.388 , 0.3875, 0.387 , 0.3867, 0.3865, 0.3862,\n",
       "            0.3853, 0.3848, 0.3845, 0.384 , 0.3838, 0.383 , 0.382 , 0.3816,\n",
       "            0.3813, 0.381 , 0.3806, 0.3796, 0.3782, 0.3777, 0.3774, 0.3752,\n",
       "            0.3743, 0.374 , 0.3735, 0.3733, 0.373 , 0.3704, 0.3694, 0.3687,\n",
       "            0.3682, 0.3677, 0.367 , 0.3667, 0.3665, 0.3662, 0.3647, 0.364 ,\n",
       "            0.3633, 0.3623, 0.361 , 0.3608, 0.3606, 0.36  , 0.3594, 0.3591,\n",
       "            0.358 , 0.3572, 0.357 , 0.3564, 0.355 , 0.353 , 0.352 , 0.3516,\n",
       "            0.351 , 0.3503, 0.35  , 0.3496, 0.3494, 0.349 , 0.3484, 0.3481,\n",
       "            0.3477, 0.3474, 0.347 , 0.3455, 0.345 , 0.3445, 0.3435, 0.343 ,\n",
       "            0.342 , 0.3408, 0.3406, 0.3396, 0.3364, 0.3335, 0.3306, 0.3293,\n",
       "            0.3289, 0.3262, 0.3257, 0.3252, 0.325 , 0.3232, 0.3203, 0.312 ,\n",
       "            0.298 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.02238806, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.6268657 , 0.6268657 , 0.63432837,\n",
       "            0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 ,\n",
       "            0.6492537 , 0.6567164 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.67164177, 0.6791045 , 0.6791045 , 0.6791045 , 0.6865672 ,\n",
       "            0.6865672 , 0.6865672 , 0.6865672 , 0.70149255, 0.70149255,\n",
       "            0.70149255, 0.70149255, 0.70149255, 0.70149255, 0.70149255,\n",
       "            0.7089552 , 0.7089552 , 0.7238806 , 0.7238806 , 0.73134327,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76119405, 0.76119405, 0.76865673, 0.76865673, 0.7761194 ,\n",
       "            0.7761194 , 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8134328 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.880597  , 0.880597  , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9328358 , 0.9328358 , 0.9328358 ,\n",
       "            0.9328358 , 0.9402985 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.95522386, 0.96268654, 0.96268654, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.97761196, 0.98507464, 0.98507464, 0.98507464,\n",
       "            0.9925373 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.03448276, 0.04310345, 0.05172414,\n",
       "            0.05172414, 0.06034483, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.18965517, 0.19827586, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.23275863, 0.25      , 0.25      , 0.25862068, 0.27586207,\n",
       "            0.28448275, 0.28448275, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.30172414, 0.30172414, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.36206895, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.4051724 ,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.45689654, 0.45689654,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.62068963, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7844828 , 0.80172414, 0.8103448 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4946, 0.4924, 0.4902, 0.4883, 0.4866, 0.4824, 0.4807,\n",
       "            0.4792, 0.4778, 0.4763, 0.4746, 0.4739, 0.473 , 0.4724, 0.4717,\n",
       "            0.4707, 0.4705, 0.4697, 0.4695, 0.4692, 0.469 , 0.4688, 0.4685,\n",
       "            0.4675, 0.4666, 0.466 , 0.4653, 0.465 , 0.4634, 0.4626, 0.462 ,\n",
       "            0.4617, 0.4614, 0.461 , 0.46  , 0.4595, 0.4587, 0.4585, 0.4583,\n",
       "            0.457 , 0.4568, 0.4553, 0.455 , 0.4543, 0.454 , 0.4539, 0.4531,\n",
       "            0.453 , 0.4524, 0.452 , 0.4517, 0.4504, 0.45  , 0.449 , 0.443 ,\n",
       "            0.4424, 0.442 , 0.4412, 0.4402, 0.4385, 0.436 , 0.4353, 0.4329,\n",
       "            0.4263, 0.424 , 0.423 , 0.4226, 0.4204, 0.42  , 0.4192, 0.4182,\n",
       "            0.4163, 0.416 , 0.415 , 0.413 , 0.4116, 0.4106, 0.4102, 0.4097,\n",
       "            0.4092, 0.406 , 0.3972, 0.397 , 0.3967, 0.3962, 0.3958, 0.394 ,\n",
       "            0.3926, 0.3923, 0.392 , 0.39  , 0.3884, 0.388 , 0.3875, 0.3872,\n",
       "            0.386 , 0.3857, 0.3818, 0.3809, 0.3806, 0.3801, 0.3794, 0.3787,\n",
       "            0.3777, 0.3772, 0.375 , 0.3728, 0.371 , 0.37  , 0.3699, 0.3696,\n",
       "            0.3691, 0.3684, 0.3674, 0.3645, 0.3643, 0.3635, 0.3616, 0.361 ,\n",
       "            0.3604, 0.36  , 0.3599, 0.3591, 0.3586, 0.3584, 0.358 , 0.3572,\n",
       "            0.357 , 0.356 , 0.3552, 0.355 , 0.3545, 0.3538, 0.352 , 0.3513,\n",
       "            0.351 , 0.3506, 0.3503, 0.3489, 0.3486, 0.348 , 0.3464, 0.3462,\n",
       "            0.346 , 0.3455, 0.3452, 0.345 , 0.3447, 0.3445, 0.3433, 0.3418,\n",
       "            0.341 , 0.3403, 0.34  , 0.3396, 0.3394, 0.3384, 0.3374, 0.3372,\n",
       "            0.3357, 0.3335, 0.3333, 0.333 , 0.3323, 0.3318, 0.3303, 0.3286,\n",
       "            0.328 , 0.3274, 0.3264, 0.3254, 0.324 , 0.322 , 0.3218, 0.3213,\n",
       "            0.321 , 0.3206, 0.3203, 0.3193, 0.3184, 0.318 , 0.3176, 0.317 ,\n",
       "            0.316 , 0.3154, 0.315 , 0.3147, 0.3135, 0.312 , 0.3115, 0.3105,\n",
       "            0.3098, 0.3096, 0.308 , 0.3074, 0.3071, 0.3062, 0.3052, 0.3042,\n",
       "            0.3032, 0.3022, 0.3005, 0.2993, 0.2952, 0.2922, 0.2898, 0.289 ,\n",
       "            0.2876, 0.2861, 0.2854, 0.28  , 0.2715, 0.2595], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.26119402, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.43283582, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 , 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.619403  , 0.6268657 , 0.6268657 , 0.6268657 , 0.6268657 ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.67164177, 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6865672 , 0.6865672 , 0.6865672 ,\n",
       "            0.6865672 , 0.6865672 , 0.70149255, 0.70149255, 0.70149255,\n",
       "            0.70149255, 0.70149255, 0.70149255, 0.70149255, 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.74626863, 0.75373137, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.76865673, 0.76865673, 0.7761194 , 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.86567163, 0.86567163,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.8731343 , 0.880597  ,\n",
       "            0.880597  , 0.880597  , 0.880597  , 0.880597  , 0.8880597 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.9477612 , 0.95522386, 0.95522386, 0.96268654, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.97761196, 0.98507464,\n",
       "            0.98507464, 0.98507464, 0.9925373 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.04310345, 0.04310345, 0.05172414, 0.05172414,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1724138 ,\n",
       "            0.1724138 , 0.1724138 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.28448275, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.3448276 , 0.3448276 ,\n",
       "            0.35344827, 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.38793105, 0.39655173, 0.39655173, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.49137932, 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5344828 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.62931037, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8534483 , 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4854, 0.4832, 0.483 , 0.481 , 0.4802, 0.4792, 0.4768,\n",
       "            0.4722, 0.472 , 0.4683, 0.4666, 0.4663, 0.466 , 0.4656, 0.4646,\n",
       "            0.4644, 0.4636, 0.4631, 0.4624, 0.4622, 0.462 , 0.4604, 0.46  ,\n",
       "            0.4597, 0.4592, 0.4583, 0.458 , 0.4578, 0.4558, 0.4548, 0.4536,\n",
       "            0.4524, 0.4504, 0.4502, 0.4492, 0.4487, 0.4485, 0.4475, 0.4473,\n",
       "            0.447 , 0.4463, 0.446 , 0.4458, 0.4453, 0.4448, 0.4443, 0.4436,\n",
       "            0.443 , 0.442 , 0.441 , 0.4407, 0.4387, 0.4382, 0.437 , 0.4353,\n",
       "            0.4329, 0.4312, 0.4294, 0.4285, 0.4246, 0.4238, 0.421 , 0.4153,\n",
       "            0.4116, 0.4092, 0.4077, 0.4065, 0.402 , 0.3987, 0.3982, 0.3975,\n",
       "            0.396 , 0.3955, 0.3928, 0.3923, 0.3918, 0.3916, 0.3904, 0.3896,\n",
       "            0.3875, 0.386 , 0.3823, 0.3792, 0.3757, 0.3755, 0.3752, 0.3735,\n",
       "            0.3718, 0.3713, 0.3708, 0.3684, 0.3682, 0.367 , 0.3652, 0.364 ,\n",
       "            0.3618, 0.3606, 0.3604, 0.36  , 0.3577, 0.3555, 0.3547, 0.3545,\n",
       "            0.3535, 0.3523, 0.3499, 0.3486, 0.3467, 0.346 , 0.344 , 0.3433,\n",
       "            0.3423, 0.342 , 0.3418, 0.341 , 0.34  , 0.3398, 0.337 , 0.3367,\n",
       "            0.3364, 0.3357, 0.3345, 0.3342, 0.3333, 0.3325, 0.332 , 0.3306,\n",
       "            0.329 , 0.3286, 0.3274, 0.327 , 0.3267, 0.3264, 0.3257, 0.3252,\n",
       "            0.325 , 0.3245, 0.3215, 0.3213, 0.3208, 0.3206, 0.3203, 0.32  ,\n",
       "            0.3198, 0.319 , 0.3186, 0.3176, 0.317 , 0.3167, 0.3162, 0.3157,\n",
       "            0.3154, 0.315 , 0.3145, 0.3137, 0.3118, 0.311 , 0.31  , 0.3096,\n",
       "            0.3088, 0.3086, 0.308 , 0.3066, 0.3054, 0.3052, 0.304 , 0.3032,\n",
       "            0.301 , 0.2998, 0.2993, 0.2988, 0.298 , 0.2979, 0.2974, 0.2957,\n",
       "            0.2947, 0.2944, 0.294 , 0.2935, 0.292 , 0.2917, 0.2913, 0.2903,\n",
       "            0.2886, 0.2878, 0.2869, 0.2861, 0.2842, 0.2834, 0.282 , 0.281 ,\n",
       "            0.2795, 0.2783, 0.2776, 0.2756, 0.2751, 0.2742, 0.2712, 0.271 ,\n",
       "            0.2695, 0.2673, 0.267 , 0.2668, 0.2664, 0.2634, 0.2605, 0.2568,\n",
       "            0.2544, 0.252 , 0.251 , 0.2494, 0.2487, 0.243 , 0.2343, 0.2246],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.35074627, 0.35820895,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.6268657 , 0.6268657 ,\n",
       "            0.6268657 , 0.6268657 , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.67164177, 0.67164177,\n",
       "            0.67164177, 0.67164177, 0.67164177, 0.67164177, 0.6791045 ,\n",
       "            0.6791045 , 0.6865672 , 0.6865672 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.70149255, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7089552 , 0.7089552 , 0.7238806 , 0.73880595, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.75373137, 0.76119405, 0.76119405,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.80597013, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.82835823, 0.8358209 ,\n",
       "            0.8358209 , 0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.8507463 , 0.86567163, 0.86567163, 0.86567163, 0.86567163,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.880597  , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.97761196, 0.98507464,\n",
       "            0.98507464, 0.98507464, 0.9925373 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.04310345, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.13793103, 0.14655173, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18965517, 0.19827586,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.22413793,\n",
       "            0.23275863, 0.23275863, 0.2413793 , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.3448276 , 0.3448276 , 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.38793105, 0.39655173,\n",
       "            0.39655173, 0.39655173, 0.4051724 , 0.41379312, 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.47413793, 0.4827586 , 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5258621 , 0.5344828 , 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.61206895, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7155172 ,\n",
       "            0.7241379 , 0.7241379 , 0.73275864, 0.73275864, 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8189655 , 0.8362069 ,\n",
       "            0.8448276 , 0.86206895, 0.86206895, 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4758, 0.474 , 0.4731, 0.472 , 0.4702, 0.467 , 0.4631,\n",
       "            0.4617, 0.4602, 0.4575, 0.4565, 0.4563, 0.4556, 0.455 , 0.4546,\n",
       "            0.4543, 0.454 , 0.4539, 0.4536, 0.4534, 0.4517, 0.4514, 0.4512,\n",
       "            0.4507, 0.45  , 0.4475, 0.4465, 0.4463, 0.4436, 0.442 , 0.4414,\n",
       "            0.4412, 0.4392, 0.439 , 0.4387, 0.438 , 0.4375, 0.4373, 0.4365,\n",
       "            0.4363, 0.4358, 0.4355, 0.4353, 0.435 , 0.4346, 0.4343, 0.434 ,\n",
       "            0.431 , 0.4304, 0.4285, 0.4282, 0.426 , 0.424 , 0.4229, 0.4219,\n",
       "            0.417 , 0.4158, 0.415 , 0.4128, 0.4094, 0.4084, 0.406 , 0.3918,\n",
       "            0.3916, 0.391 , 0.39  , 0.3845, 0.3813, 0.381 , 0.3794, 0.3762,\n",
       "            0.376 , 0.3752, 0.372 , 0.3699, 0.3694, 0.367 , 0.3655, 0.363 ,\n",
       "            0.3618, 0.3616, 0.3557, 0.3555, 0.3547, 0.3545, 0.3538, 0.3503,\n",
       "            0.348 , 0.3477, 0.3474, 0.347 , 0.3452, 0.3442, 0.3425, 0.3413,\n",
       "            0.3386, 0.337 , 0.3354, 0.3315, 0.3306, 0.3303, 0.3298, 0.3296,\n",
       "            0.3284, 0.3281, 0.3254, 0.325 , 0.3235, 0.3218, 0.3215, 0.3203,\n",
       "            0.3176, 0.317 , 0.3167, 0.3162, 0.3152, 0.3145, 0.314 , 0.3125,\n",
       "            0.3105, 0.31  , 0.3098, 0.3096, 0.3093, 0.3074, 0.3052, 0.305 ,\n",
       "            0.3037, 0.3032, 0.3018, 0.3013, 0.3005, 0.2993, 0.2988, 0.2986,\n",
       "            0.298 , 0.2976, 0.2974, 0.2966, 0.2964, 0.2957, 0.2952, 0.2944,\n",
       "            0.2932, 0.2925, 0.2922, 0.2905, 0.29  , 0.2886, 0.288 , 0.2874,\n",
       "            0.287 , 0.2869, 0.286 , 0.2854, 0.2852, 0.2834, 0.2817, 0.2815,\n",
       "            0.2808, 0.28  , 0.2793, 0.279 , 0.2778, 0.2751, 0.2737, 0.2708,\n",
       "            0.2703, 0.27  , 0.269 , 0.2688, 0.268 , 0.2668, 0.2666, 0.2651,\n",
       "            0.2646, 0.2644, 0.2642, 0.264 , 0.263 , 0.2612, 0.2607, 0.258 ,\n",
       "            0.2573, 0.255 , 0.2542, 0.2527, 0.2524, 0.2515, 0.2512, 0.251 ,\n",
       "            0.2502, 0.249 , 0.2489, 0.2466, 0.2426, 0.2415, 0.2397, 0.2382,\n",
       "            0.2374, 0.236 , 0.235 , 0.2347, 0.234 , 0.2338, 0.2311, 0.2266,\n",
       "            0.2242, 0.218 , 0.2166, 0.2162, 0.2156, 0.2095, 0.2009, 0.1934],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1716418 , 0.17910448, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.619403  , 0.619403  ,\n",
       "            0.619403  , 0.6268657 , 0.6268657 , 0.6268657 , 0.6268657 ,\n",
       "            0.63432837, 0.63432837, 0.63432837, 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6567164 , 0.6567164 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.67164177, 0.67164177, 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6791045 , 0.6791045 , 0.6791045 ,\n",
       "            0.6791045 , 0.69402987, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7089552 , 0.7089552 , 0.7164179 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76119405, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7835821 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.80597013, 0.80597013,\n",
       "            0.80597013, 0.8134328 , 0.82835823, 0.8358209 , 0.8358209 ,\n",
       "            0.8358209 , 0.8358209 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.8507463 , 0.8507463 , 0.8507463 , 0.8507463 , 0.8507463 ,\n",
       "            0.8507463 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.880597  , 0.880597  , 0.880597  ,\n",
       "            0.8880597 , 0.8880597 , 0.8955224 , 0.8955224 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.9104478 , 0.92537314, 0.92537314,\n",
       "            0.92537314, 0.92537314, 0.9328358 , 0.9328358 , 0.9402985 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.95522386, 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.9701493 , 0.97761196, 0.97761196,\n",
       "            0.97761196, 0.98507464, 0.98507464, 0.9925373 , 0.9925373 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.03448276, 0.03448276, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12068965, 0.12931034, 0.12931034, 0.14655173, 0.15517241,\n",
       "            0.15517241, 0.1637931 , 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.21551724, 0.22413793, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.41379312, 0.4224138 , 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.57758623, 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4663, 0.4646, 0.4634, 0.463 , 0.461 , 0.4602, 0.4573,\n",
       "            0.454 , 0.452 , 0.451 , 0.4487, 0.4485, 0.4473, 0.4465, 0.4463,\n",
       "            0.4458, 0.445 , 0.4448, 0.4446, 0.443 , 0.4426, 0.442 , 0.4417,\n",
       "            0.437 , 0.4368, 0.4353, 0.4326, 0.4321, 0.4307, 0.4304, 0.4287,\n",
       "            0.4285, 0.4282, 0.4277, 0.4275, 0.4272, 0.4268, 0.4265, 0.426 ,\n",
       "            0.4258, 0.4253, 0.4246, 0.4243, 0.4226, 0.4224, 0.4216, 0.42  ,\n",
       "            0.4192, 0.4165, 0.4155, 0.4148, 0.4136, 0.4114, 0.4087, 0.407 ,\n",
       "            0.4023, 0.4016, 0.3958, 0.3953, 0.3945, 0.392 , 0.391 , 0.3755,\n",
       "            0.3738, 0.371 , 0.369 , 0.3647, 0.364 , 0.3604, 0.358 , 0.357 ,\n",
       "            0.3564, 0.3552, 0.3523, 0.3472, 0.3447, 0.344 , 0.3423, 0.3406,\n",
       "            0.3367, 0.3357, 0.3345, 0.334 , 0.3306, 0.3296, 0.3289, 0.3284,\n",
       "            0.3281, 0.3276, 0.3271, 0.326 , 0.3252, 0.3245, 0.3228, 0.3206,\n",
       "            0.3193, 0.3162, 0.3137, 0.3127, 0.311 , 0.3083, 0.3074, 0.3066,\n",
       "            0.3064, 0.306 , 0.3042, 0.304 , 0.303 , 0.3018, 0.2996, 0.298 ,\n",
       "            0.2974, 0.2957, 0.2942, 0.294 , 0.2932, 0.2925, 0.291 , 0.2896,\n",
       "            0.289 , 0.2883, 0.2876, 0.2864, 0.2861, 0.2852, 0.2844, 0.2815,\n",
       "            0.28  , 0.2795, 0.2793, 0.278 , 0.2776, 0.2751, 0.2747, 0.2725,\n",
       "            0.2722, 0.2715, 0.2712, 0.271 , 0.2708, 0.2705, 0.2703, 0.2698,\n",
       "            0.2683, 0.2664, 0.2659, 0.2656, 0.2654, 0.2646, 0.2644, 0.2637,\n",
       "            0.2632, 0.261 , 0.2605, 0.2603, 0.2598, 0.2595, 0.2588, 0.2583,\n",
       "            0.2578, 0.2576, 0.2566, 0.2563, 0.2554, 0.2544, 0.2534, 0.2517,\n",
       "            0.251 , 0.2496, 0.2489, 0.2482, 0.2456, 0.2438, 0.2426, 0.2417,\n",
       "            0.2415, 0.241 , 0.2402, 0.2399, 0.2397, 0.2394, 0.2391, 0.2384,\n",
       "            0.2383, 0.2382, 0.2379, 0.237 , 0.2362, 0.2356, 0.2343, 0.2319,\n",
       "            0.2306, 0.2297, 0.2289, 0.2269, 0.226 , 0.2257, 0.2255, 0.2249,\n",
       "            0.2247, 0.2229, 0.2227, 0.2224, 0.2218, 0.2217, 0.2195, 0.2125,\n",
       "            0.2114, 0.2109, 0.2101, 0.208 , 0.2073, 0.206 , 0.2058, 0.2053,\n",
       "            0.2043, 0.2034, 0.2032, 0.1991, 0.1965, 0.1873, 0.1864, 0.1858,\n",
       "            0.1857, 0.1797, 0.1715, 0.1654], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.29104477, 0.29850745, 0.31343284, 0.32089552, 0.33582088,\n",
       "            0.3432836 , 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.6268657 , 0.6268657 ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6567164 , 0.6567164 , 0.6567164 ,\n",
       "            0.6567164 , 0.6641791 , 0.6641791 , 0.67164177, 0.67164177,\n",
       "            0.67164177, 0.67164177, 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.6865672 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7164179 , 0.7238806 , 0.7238806 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.74626863, 0.75373137, 0.75373137, 0.76865673, 0.7761194 ,\n",
       "            0.7761194 , 0.7761194 , 0.7835821 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.79850745, 0.79850745, 0.79850745,\n",
       "            0.80597013, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8358209 , 0.8358209 , 0.8358209 , 0.8358209 ,\n",
       "            0.8432836 , 0.8432836 , 0.8432836 , 0.8432836 , 0.8432836 ,\n",
       "            0.8507463 , 0.8507463 , 0.8507463 , 0.85820895, 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.8731343 , 0.8731343 , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.8955224 , 0.9029851 ,\n",
       "            0.9029851 , 0.9029851 , 0.9029851 , 0.91791046, 0.91791046,\n",
       "            0.92537314, 0.92537314, 0.92537314, 0.9328358 , 0.9328358 ,\n",
       "            0.9402985 , 0.9402985 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.96268654, 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.97761196, 0.97761196, 0.97761196, 0.98507464, 0.98507464,\n",
       "            0.9925373 , 0.9925373 , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.05172414, 0.06034483,\n",
       "            0.06896552, 0.0775862 , 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12068965, 0.12931034,\n",
       "            0.12931034, 0.12931034, 0.13793103, 0.15517241, 0.1637931 ,\n",
       "            0.1637931 , 0.1637931 , 0.1724138 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.23275863, 0.25      , 0.25862068,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.3448276 , 0.35344827, 0.37068966,\n",
       "            0.37931034, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.55172414, 0.55172414, 0.55172414, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.69827586, 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8362069 , 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.9913793 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.457 , 0.4553, 0.4539, 0.4521, 0.4502, 0.4473, 0.4453,\n",
       "            0.4438, 0.4404, 0.4402, 0.4385, 0.4382, 0.438 , 0.4375, 0.4365,\n",
       "            0.4363, 0.436 , 0.4353, 0.434 , 0.4336, 0.433 , 0.4329, 0.4304,\n",
       "            0.4297, 0.4275, 0.4268, 0.4238, 0.4233, 0.4216, 0.4202, 0.42  ,\n",
       "            0.4194, 0.4192, 0.4187, 0.4185, 0.4177, 0.4175, 0.4163, 0.416 ,\n",
       "            0.4158, 0.4155, 0.4148, 0.413 , 0.4104, 0.4102, 0.4094, 0.408 ,\n",
       "            0.4062, 0.405 , 0.4048, 0.4016, 0.3992, 0.3972, 0.394 , 0.3892,\n",
       "            0.388 , 0.381 , 0.3801, 0.38  , 0.376 , 0.36  , 0.3584, 0.355 ,\n",
       "            0.351 , 0.3489, 0.3467, 0.3418, 0.3416, 0.339 , 0.338 , 0.3372,\n",
       "            0.3328, 0.3286, 0.3257, 0.325 , 0.3228, 0.3218, 0.3184, 0.3179,\n",
       "            0.3154, 0.3147, 0.3127, 0.3125, 0.3103, 0.3098, 0.309 , 0.3086,\n",
       "            0.3076, 0.3074, 0.3062, 0.3057, 0.3047, 0.3037, 0.299 , 0.298 ,\n",
       "            0.2944, 0.2922, 0.2903, 0.2861, 0.286 , 0.2847, 0.284 , 0.2827,\n",
       "            0.2808, 0.2788, 0.2786, 0.278 , 0.2778, 0.2766, 0.2742, 0.2727,\n",
       "            0.2717, 0.2695, 0.269 , 0.267 , 0.2651, 0.265 , 0.264 , 0.2634,\n",
       "            0.2612, 0.26  , 0.2595, 0.2593, 0.2566, 0.2556, 0.255 , 0.2537,\n",
       "            0.2534, 0.251 , 0.2502, 0.2493, 0.2487, 0.2477, 0.2474, 0.2467,\n",
       "            0.2462, 0.2451, 0.2445, 0.2444, 0.2421, 0.2411, 0.2407, 0.2406,\n",
       "            0.2405, 0.2401, 0.2394, 0.2379, 0.2378, 0.2368, 0.2363, 0.236 ,\n",
       "            0.235 , 0.2346, 0.2344, 0.2339, 0.2328, 0.2322, 0.2318, 0.2303,\n",
       "            0.2286, 0.2283, 0.2278, 0.2274, 0.226 , 0.2255, 0.2234, 0.2229,\n",
       "            0.2218, 0.2191, 0.2186, 0.218 , 0.2177, 0.217 , 0.2168, 0.2167,\n",
       "            0.2162, 0.2161, 0.2147, 0.2139, 0.2135, 0.2128, 0.2125, 0.2119,\n",
       "            0.2114, 0.2109, 0.2094, 0.2073, 0.2051, 0.205 , 0.2035, 0.2013,\n",
       "            0.201 , 0.2001, 0.1989, 0.1984, 0.1982, 0.1976, 0.1967, 0.1962,\n",
       "            0.196 , 0.1942, 0.1941, 0.185 , 0.1846, 0.1844, 0.1841, 0.1838,\n",
       "            0.1826, 0.1805, 0.1799, 0.1797, 0.1785, 0.1781, 0.1758, 0.1757,\n",
       "            0.1737, 0.171 , 0.1598, 0.1597, 0.1592, 0.1583, 0.1531, 0.1453,\n",
       "            0.1403], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.3283582 , 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.619403  , 0.6268657 ,\n",
       "            0.6268657 , 0.6268657 , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.64179105, 0.64179105, 0.64179105, 0.6492537 , 0.6492537 ,\n",
       "            0.6567164 , 0.6567164 , 0.6567164 , 0.6641791 , 0.6641791 ,\n",
       "            0.67164177, 0.67164177, 0.67164177, 0.67164177, 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6865672 , 0.6865672 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73134327, 0.73134327, 0.73880595, 0.73880595,\n",
       "            0.74626863, 0.74626863, 0.75373137, 0.75373137, 0.75373137,\n",
       "            0.76119405, 0.76119405, 0.76865673, 0.7761194 , 0.7761194 ,\n",
       "            0.7835821 , 0.7835821 , 0.7910448 , 0.7910448 , 0.79850745,\n",
       "            0.79850745, 0.79850745, 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8432836 , 0.8507463 , 0.85820895, 0.85820895,\n",
       "            0.85820895, 0.86567163, 0.86567163, 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.880597  , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.8955224 , 0.8955224 , 0.9029851 , 0.9029851 ,\n",
       "            0.9104478 , 0.9104478 , 0.91791046, 0.92537314, 0.92537314,\n",
       "            0.92537314, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.95522386, 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.97761196, 0.97761196,\n",
       "            0.97761196, 0.97761196, 0.98507464, 0.9925373 , 0.9925373 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.04310345, 0.05172414, 0.06034483, 0.06896552,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12068965, 0.12931034, 0.12931034,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1637931 , 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.25862068, 0.2672414 , 0.27586207, 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.3448276 , 0.3448276 , 0.35344827, 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.37931034, 0.37931034,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.43103448, 0.44827586, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5       , 0.51724136, 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.55172414, 0.55172414, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.57758623, 0.5948276 ,\n",
       "            0.5948276 , 0.6034483 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.7413793 , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4475 , 0.4463 , 0.4446 , 0.4443 , 0.4434 , 0.4402 ,\n",
       "            0.4373 , 0.4363 , 0.436  , 0.4326 , 0.4314 , 0.4304 , 0.4302 ,\n",
       "            0.43   , 0.4297 , 0.4292 , 0.4282 , 0.428  , 0.4277 , 0.4275 ,\n",
       "            0.4268 , 0.4253 , 0.425  , 0.424  , 0.4185 , 0.418  , 0.4175 ,\n",
       "            0.4165 , 0.4143 , 0.4126 , 0.411  , 0.4106 , 0.4104 , 0.4102 ,\n",
       "            0.41   , 0.4094 , 0.409  , 0.4087 , 0.408  , 0.407  , 0.4067 ,\n",
       "            0.4058 , 0.4053 , 0.405  , 0.4045 , 0.4038 , 0.4028 , 0.3994 ,\n",
       "            0.3987 , 0.3984 , 0.3975 , 0.3943 , 0.393  , 0.3892 , 0.3865 ,\n",
       "            0.385  , 0.3801 , 0.3757 , 0.3745 , 0.3667 , 0.3645 , 0.3625 ,\n",
       "            0.3608 , 0.36   , 0.344  , 0.343  , 0.3376 , 0.3328 , 0.332  ,\n",
       "            0.3296 , 0.325  , 0.3218 , 0.32   , 0.3198 , 0.318  , 0.3137 ,\n",
       "            0.3096 , 0.3066 , 0.3042 , 0.3022 , 0.302  , 0.3005 , 0.2998 ,\n",
       "            0.2974 , 0.2952 , 0.2942 , 0.2925 , 0.2917 , 0.2905 , 0.2903 ,\n",
       "            0.2898 , 0.289  , 0.288  , 0.2878 , 0.286  , 0.2847 , 0.2842 ,\n",
       "            0.284  , 0.2783 , 0.2773 , 0.2732 , 0.2712 , 0.2695 , 0.2664 ,\n",
       "            0.2659 , 0.2644 , 0.2632 , 0.2607 , 0.2605 , 0.2583 , 0.2563 ,\n",
       "            0.2554 , 0.2551 , 0.253  , 0.2522 , 0.2517 , 0.2489 , 0.2487 ,\n",
       "            0.247  , 0.2466 , 0.2451 , 0.2441 , 0.2429 , 0.2428 , 0.2422 ,\n",
       "            0.2399 , 0.2395 , 0.2382 , 0.2378 , 0.2368 , 0.236  , 0.2316 ,\n",
       "            0.2314 , 0.2303 , 0.2302 , 0.228  , 0.2272 , 0.2269 , 0.2268 ,\n",
       "            0.2261 , 0.2246 , 0.2239 , 0.2233 , 0.2225 , 0.2213 , 0.2208 ,\n",
       "            0.2198 , 0.2194 , 0.219  , 0.2172 , 0.2166 , 0.2162 , 0.2157 ,\n",
       "            0.2156 , 0.2152 , 0.2147 , 0.214  , 0.2137 , 0.213  , 0.212  ,\n",
       "            0.2109 , 0.2106 , 0.2104 , 0.2098 , 0.2094 , 0.2089 , 0.2076 ,\n",
       "            0.2058 , 0.205  , 0.2047 , 0.2042 , 0.2037 , 0.201  , 0.2    ,\n",
       "            0.1995 , 0.1989 , 0.1962 , 0.1958 , 0.1956 , 0.1954 , 0.1953 ,\n",
       "            0.1947 , 0.194  , 0.1925 , 0.1918 , 0.1913 , 0.19   , 0.189  ,\n",
       "            0.1882 , 0.1879 , 0.187  , 0.1869 , 0.1849 , 0.1826 , 0.1824 ,\n",
       "            0.1816 , 0.18   , 0.1797 , 0.178  , 0.1779 , 0.1765 , 0.1761 ,\n",
       "            0.1755 , 0.1735 , 0.1731 , 0.173  , 0.1729 , 0.1721 , 0.1709 ,\n",
       "            0.1696 , 0.1615 , 0.1608 , 0.1604 , 0.1603 , 0.1593 , 0.159  ,\n",
       "            0.1578 , 0.1561 , 0.1558 , 0.1545 , 0.1534 , 0.1511 , 0.151  ,\n",
       "            0.1508 , 0.1482 , 0.1361 , 0.1357 , 0.1355 , 0.134  , 0.1298 ,\n",
       "            0.12244, 0.1184 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.18656716, 0.19402985, 0.20895523,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.63432837, 0.64179105, 0.64179105, 0.64179105, 0.64179105,\n",
       "            0.64179105, 0.64179105, 0.6492537 , 0.6567164 , 0.6567164 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.6641791 , 0.67164177,\n",
       "            0.67164177, 0.67164177, 0.6791045 , 0.6791045 , 0.6791045 ,\n",
       "            0.6791045 , 0.6791045 , 0.6791045 , 0.6865672 , 0.6865672 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.73880595, 0.73880595,\n",
       "            0.73880595, 0.73880595, 0.74626863, 0.74626863, 0.74626863,\n",
       "            0.74626863, 0.74626863, 0.75373137, 0.76119405, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7835821 , 0.7835821 ,\n",
       "            0.7910448 , 0.7910448 , 0.7910448 , 0.7910448 , 0.79850745,\n",
       "            0.79850745, 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8507463 , 0.8507463 , 0.85820895, 0.85820895,\n",
       "            0.85820895, 0.86567163, 0.86567163, 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.8955224 , 0.8955224 , 0.9029851 , 0.9104478 , 0.9104478 ,\n",
       "            0.91791046, 0.91791046, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.95522386, 0.95522386, 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.97761196, 0.97761196,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 0.9925373 , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.04310345, 0.05172414, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.12931034, 0.12931034, 0.13793103, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.14655173, 0.15517241, 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.25862068, 0.2672414 , 0.27586207, 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.35344827, 0.36206895, 0.36206895, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.55172414, 0.55172414, 0.55172414,\n",
       "            0.55172414, 0.55172414, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4382 , 0.4368 , 0.4353 , 0.4346 , 0.4343 , 0.43   ,\n",
       "            0.428  , 0.4275 , 0.427  , 0.4248 , 0.4229 , 0.4226 , 0.4224 ,\n",
       "            0.4219 , 0.4202 , 0.4194 , 0.4192 , 0.419  , 0.4177 , 0.4172 ,\n",
       "            0.4163 , 0.4153 , 0.4087 , 0.4062 , 0.4053 , 0.4023 , 0.402  ,\n",
       "            0.4014 , 0.401  , 0.4006 , 0.4004 , 0.3997 , 0.399  , 0.3977 ,\n",
       "            0.3965 , 0.3962 , 0.396  , 0.3955 , 0.3953 , 0.3948 , 0.3938 ,\n",
       "            0.3933 , 0.3926 , 0.3892 , 0.3887 , 0.3867 , 0.382  , 0.3813 ,\n",
       "            0.3809 , 0.3772 , 0.3745 , 0.3733 , 0.367  , 0.363  , 0.3613 ,\n",
       "            0.353  , 0.3499 , 0.3462 , 0.3442 , 0.329  , 0.3281 , 0.3215 ,\n",
       "            0.3179 , 0.3142 , 0.313  , 0.3096 , 0.3035 , 0.3027 , 0.2998 ,\n",
       "            0.2952 , 0.2917 , 0.2893 , 0.285  , 0.2842 , 0.2837 , 0.2832 ,\n",
       "            0.2805 , 0.2773 , 0.2766 , 0.2761 , 0.2751 , 0.2734 , 0.2703 ,\n",
       "            0.2698 , 0.2688 , 0.2678 , 0.266  , 0.2637 , 0.2588 , 0.2576 ,\n",
       "            0.2534 , 0.2524 , 0.2502 , 0.2477 , 0.2445 , 0.244  , 0.2429 ,\n",
       "            0.2397 , 0.2395 , 0.2374 , 0.2366 , 0.2358 , 0.2344 , 0.2335 ,\n",
       "            0.2332 , 0.2327 , 0.231  , 0.2303 , 0.2295 , 0.2277 , 0.226  ,\n",
       "            0.2257 , 0.2235 , 0.223  , 0.2229 , 0.2218 , 0.2217 , 0.2213 ,\n",
       "            0.2181 , 0.2179 , 0.2175 , 0.2167 , 0.2152 , 0.2118 , 0.2104 ,\n",
       "            0.2101 , 0.21   , 0.2094 , 0.209  , 0.2086 , 0.2073 , 0.2065 ,\n",
       "            0.2059 , 0.2054 , 0.2051 , 0.204  , 0.2037 , 0.2023 , 0.2018 ,\n",
       "            0.2009 , 0.1996 , 0.1995 , 0.1991 , 0.1989 , 0.1974 , 0.1964 ,\n",
       "            0.196  , 0.1958 , 0.1953 , 0.195  , 0.1948 , 0.1943 , 0.1942 ,\n",
       "            0.1941 , 0.1936 , 0.1925 , 0.1924 , 0.1915 , 0.1896 , 0.1891 ,\n",
       "            0.1887 , 0.1886 , 0.1877 , 0.1869 , 0.1857 , 0.1849 , 0.1846 ,\n",
       "            0.1843 , 0.1835 , 0.183  , 0.1823 , 0.1803 , 0.179  , 0.1785 ,\n",
       "            0.1775 , 0.177  , 0.1768 , 0.1764 , 0.1763 , 0.1747 , 0.1735 ,\n",
       "            0.173  , 0.1726 , 0.1715 , 0.1708 , 0.1704 , 0.1699 , 0.167  ,\n",
       "            0.1666 , 0.1661 , 0.1654 , 0.1648 , 0.163  , 0.1626 , 0.161  ,\n",
       "            0.1606 , 0.1582 , 0.1573 , 0.1572 , 0.1565 , 0.1556 , 0.1547 ,\n",
       "            0.1526 , 0.1525 , 0.1519 , 0.1514 , 0.151  , 0.1504 , 0.1477 ,\n",
       "            0.1412 , 0.1406 , 0.14   , 0.1387 , 0.1385 , 0.1377 , 0.1376 ,\n",
       "            0.1356 , 0.1342 , 0.1333 , 0.132  , 0.131  , 0.1298 , 0.1295 ,\n",
       "            0.1284 , 0.11597, 0.11554, 0.11475, 0.113  , 0.1099 , 0.1032 ,\n",
       "            0.1    ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.03731343,\n",
       "            0.05223881, 0.05970149, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.18656716,\n",
       "            0.19402985, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.619403  , 0.619403  ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.63432837, 0.63432837, 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6567164 , 0.6567164 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6791045 , 0.6791045 , 0.6791045 ,\n",
       "            0.6791045 , 0.6791045 , 0.6865672 , 0.69402987, 0.69402987,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 , 0.7238806 ,\n",
       "            0.73134327, 0.73134327, 0.73880595, 0.73880595, 0.73880595,\n",
       "            0.74626863, 0.74626863, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7835821 ,\n",
       "            0.7835821 , 0.7835821 , 0.7835821 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.79850745, 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.80597013, 0.80597013, 0.80597013, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.82835823, 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.8507463 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.86567163, 0.86567163, 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.880597  , 0.8880597 , 0.8880597 ,\n",
       "            0.8955224 , 0.8955224 , 0.9029851 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.91791046, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.92537314, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.95522386, 0.95522386, 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.97761196, 0.97761196, 0.98507464, 0.9925373 , 0.9925373 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.05172414, 0.06034483,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12931034, 0.12931034, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.14655173, 0.14655173, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.18965517, 0.20689656, 0.21551724, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.3448276 , 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62068963, 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4282 , 0.427  , 0.4258 , 0.4246 , 0.4194 , 0.4185 ,\n",
       "            0.4163 , 0.4143 , 0.414  , 0.4138 , 0.4128 , 0.4111 , 0.4106 ,\n",
       "            0.4102 , 0.4087 , 0.4084 , 0.408  , 0.4075 , 0.4062 , 0.3994 ,\n",
       "            0.3962 , 0.3938 , 0.3936 , 0.3933 , 0.3928 , 0.3923 , 0.3918 ,\n",
       "            0.3916 , 0.3914 , 0.39   , 0.389  , 0.3887 , 0.3877 , 0.3875 ,\n",
       "            0.3865 , 0.3857 , 0.3845 , 0.384  , 0.3835 , 0.383  , 0.3828 ,\n",
       "            0.3823 , 0.38   , 0.3794 , 0.3792 , 0.375  , 0.372  , 0.3704 ,\n",
       "            0.367  , 0.3662 , 0.3633 , 0.363  , 0.3562 , 0.3508 , 0.3486 ,\n",
       "            0.3398 , 0.3381 , 0.3342 , 0.3315 , 0.3286 , 0.3152 , 0.3147 ,\n",
       "            0.3088 , 0.3044 , 0.3013 , 0.2969 , 0.2954 , 0.29   , 0.2893 ,\n",
       "            0.289  , 0.2815 , 0.2776 , 0.277  , 0.2751 , 0.2703 , 0.27   ,\n",
       "            0.2688 , 0.268  , 0.2646 , 0.2627 , 0.2612 , 0.2595 , 0.259  ,\n",
       "            0.2585 , 0.2556 , 0.255  , 0.2542 , 0.2532 , 0.2522 , 0.252  ,\n",
       "            0.2515 , 0.2487 , 0.2405 , 0.2386 , 0.2372 , 0.2351 , 0.2343 ,\n",
       "            0.2325 , 0.2289 , 0.2247 , 0.2242 , 0.2239 , 0.2211 , 0.2203 ,\n",
       "            0.2195 , 0.2189 , 0.2173 , 0.217  , 0.2158 , 0.215  , 0.2129 ,\n",
       "            0.2114 , 0.2076 , 0.2075 , 0.207  , 0.2069 , 0.206  , 0.2056 ,\n",
       "            0.2054 , 0.2032 , 0.2028 , 0.2026 , 0.2021 , 0.2018 , 0.1973 ,\n",
       "            0.1968 , 0.196  , 0.195  , 0.1943 , 0.1917 , 0.1903 , 0.1901 ,\n",
       "            0.19   , 0.1896 , 0.1885 , 0.1882 , 0.1879 , 0.1869 , 0.1859 ,\n",
       "            0.1858 , 0.1827 , 0.1823 , 0.1816 , 0.1812 , 0.1803 , 0.1799 ,\n",
       "            0.1791 , 0.1788 , 0.1775 , 0.1772 , 0.1768 , 0.1766 , 0.1758 ,\n",
       "            0.1754 , 0.1753 , 0.1749 , 0.1743 , 0.1731 , 0.1729 , 0.1704 ,\n",
       "            0.1703 , 0.1698 , 0.1692 , 0.1688 , 0.1685 , 0.1678 , 0.1677 ,\n",
       "            0.1669 , 0.1656 , 0.1646 , 0.1637 , 0.1631 , 0.1627 , 0.1619 ,\n",
       "            0.1611 , 0.1608 , 0.1606 , 0.16   , 0.1599 , 0.1592 , 0.1564 ,\n",
       "            0.156  , 0.1559 , 0.1555 , 0.1536 , 0.153  , 0.1528 , 0.151  ,\n",
       "            0.1506 , 0.1473 , 0.1465 , 0.1462 , 0.1453 , 0.1437 , 0.1431 ,\n",
       "            0.1411 , 0.1396 , 0.1393 , 0.139  , 0.1387 , 0.1373 , 0.1367 ,\n",
       "            0.1346 , 0.1345 , 0.1335 , 0.1328 , 0.1324 , 0.132  , 0.1315 ,\n",
       "            0.1282 , 0.124  , 0.1236 , 0.12213, 0.122  , 0.12   , 0.119  ,\n",
       "            0.1188 , 0.118  , 0.11554, 0.1152 , 0.1142 , 0.11316, 0.1118 ,\n",
       "            0.11145, 0.11084, 0.09894, 0.09875, 0.0972 , 0.0955 , 0.0933 ,\n",
       "            0.0874 , 0.08496], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.63432837, 0.63432837, 0.63432837, 0.63432837,\n",
       "            0.63432837, 0.64179105, 0.64179105, 0.6492537 , 0.6492537 ,\n",
       "            0.6492537 , 0.6567164 , 0.6567164 , 0.6567164 , 0.6567164 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.6641791 , 0.6791045 ,\n",
       "            0.6791045 , 0.6791045 , 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.69402987, 0.70149255, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.7238806 , 0.7238806 , 0.73134327,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.75373137, 0.76119405, 0.76865673, 0.76865673,\n",
       "            0.76865673, 0.7761194 , 0.7761194 , 0.7835821 , 0.7835821 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.79850745, 0.80597013,\n",
       "            0.80597013, 0.80597013, 0.80597013, 0.80597013, 0.80597013,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8432836 , 0.8432836 , 0.8432836 , 0.8507463 ,\n",
       "            0.8507463 , 0.8507463 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.86567163, 0.86567163, 0.86567163, 0.8731343 , 0.8731343 ,\n",
       "            0.880597  , 0.880597  , 0.8880597 , 0.8880597 , 0.8955224 ,\n",
       "            0.8955224 , 0.9029851 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.91791046, 0.92537314, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.95522386, 0.95522386, 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            0.9925373 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.04310345, 0.04310345, 0.05172414,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.09482758, 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.12931034,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.14655173, 0.14655173,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.20689656, 0.21551724,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37068966, 0.37931034, 0.37931034,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.5       , 0.5       , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.5344828 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.62068963, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4167 , 0.4158 , 0.4146 , 0.4133 , 0.413  , 0.4094 ,\n",
       "            0.4077 , 0.4075 , 0.4065 , 0.4043 , 0.4036 , 0.4026 , 0.4011 ,\n",
       "            0.4004 , 0.4001 , 0.3994 , 0.399  , 0.3977 , 0.397  , 0.3958 ,\n",
       "            0.3955 , 0.3887 , 0.3855 , 0.3845 , 0.3828 , 0.3826 , 0.3818 ,\n",
       "            0.381  , 0.3809 , 0.38   , 0.379  , 0.377  , 0.3767 , 0.3765 ,\n",
       "            0.3762 , 0.376  , 0.3752 , 0.3735 , 0.3726 , 0.372  , 0.371  ,\n",
       "            0.3708 , 0.3704 , 0.3696 , 0.3684 , 0.3677 , 0.3616 , 0.3599 ,\n",
       "            0.3574 , 0.353  , 0.3518 , 0.3503 , 0.3499 , 0.3425 , 0.3367 ,\n",
       "            0.3345 , 0.3252 , 0.3235 , 0.3186 , 0.3157 , 0.3115 , 0.2996 ,\n",
       "            0.2993 , 0.2932 , 0.289  , 0.2847 , 0.28   , 0.2795 , 0.273  ,\n",
       "            0.2727 , 0.2627 , 0.2607 , 0.2585 , 0.258  , 0.253  , 0.2527 ,\n",
       "            0.2524 , 0.2512 , 0.251  , 0.2478 , 0.2462 , 0.2451 , 0.2428 ,\n",
       "            0.2422 , 0.241  , 0.2375 , 0.2367 , 0.2366 , 0.2362 , 0.2347 ,\n",
       "            0.2344 , 0.234  , 0.2332 , 0.2306 , 0.2216 , 0.2198 , 0.2194 ,\n",
       "            0.2177 , 0.2153 , 0.2147 , 0.2101 , 0.2058 , 0.205  , 0.2047 ,\n",
       "            0.2032 , 0.2028 , 0.2006 , 0.1993 , 0.1979 , 0.1976 , 0.1973 ,\n",
       "            0.1923 , 0.1918 , 0.1885 , 0.1884 , 0.188  , 0.1876 , 0.1874 ,\n",
       "            0.1871 , 0.1866 , 0.1855 , 0.185  , 0.1848 , 0.1843 , 0.1829 ,\n",
       "            0.1823 , 0.179  , 0.1771 , 0.1768 , 0.1761 , 0.1749 , 0.1743 ,\n",
       "            0.174  , 0.1724 , 0.1707 , 0.1705 , 0.1704 , 0.1703 , 0.17   ,\n",
       "            0.1677 , 0.1675 , 0.1664 , 0.1636 , 0.1633 , 0.1632 , 0.1626 ,\n",
       "            0.162  , 0.1617 , 0.1616 , 0.1604 , 0.1594 , 0.1592 , 0.159  ,\n",
       "            0.1582 , 0.1573 , 0.1564 , 0.1562 , 0.1558 , 0.1556 , 0.1548 ,\n",
       "            0.1547 , 0.1537 , 0.1519 , 0.1516 , 0.1512 , 0.1508 , 0.1505 ,\n",
       "            0.1498 , 0.1483 , 0.1473 , 0.146  , 0.1456 , 0.1453 , 0.1449 ,\n",
       "            0.1448 , 0.1445 , 0.1442 , 0.144  , 0.1438 , 0.1428 , 0.1412 ,\n",
       "            0.14   , 0.1382 , 0.1376 , 0.1365 , 0.1364 , 0.135  , 0.1343 ,\n",
       "            0.134  , 0.1337 , 0.132  , 0.1307 , 0.1284 , 0.128  , 0.1271 ,\n",
       "            0.1263 , 0.1254 , 0.1251 , 0.1225 , 0.1223 , 0.1219 , 0.1217 ,\n",
       "            0.12115, 0.1201 , 0.1197 , 0.1192 , 0.1174 , 0.1172 , 0.11597,\n",
       "            0.1158 , 0.1144 , 0.1134 , 0.11316, 0.1099 , 0.10724, 0.10706,\n",
       "            0.1058 , 0.10504, 0.1025 , 0.10144, 0.10126, 0.0981 , 0.0979 ,\n",
       "            0.0959 , 0.09436, 0.0937 , 0.0833 , 0.083  , 0.08124, 0.07935,\n",
       "            0.07806, 0.07275, 0.0709 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 ,\n",
       "            0.6119403 , 0.619403  , 0.619403  , 0.63432837, 0.63432837,\n",
       "            0.63432837, 0.63432837, 0.64179105, 0.64179105, 0.64179105,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6791045 , 0.6865672 , 0.6865672 ,\n",
       "            0.6865672 , 0.69402987, 0.69402987, 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.75373137, 0.76119405, 0.76119405, 0.76865673,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7835821 , 0.7835821 ,\n",
       "            0.7835821 , 0.7910448 , 0.7910448 , 0.79850745, 0.79850745,\n",
       "            0.80597013, 0.80597013, 0.8134328 , 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.86567163, 0.86567163, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8880597 , 0.8880597 ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9029851 , 0.9104478 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.9328358 , 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.95522386, 0.95522386, 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.97761196, 0.97761196,\n",
       "            0.98507464, 0.9925373 , 0.9925373 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.03448276, 0.04310345, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12068965,\n",
       "            0.12931034, 0.12931034, 0.13793103, 0.13793103, 0.14655173,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.1637931 , 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.23275863, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.38793105, 0.39655173, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.45689654, 0.46551725, 0.47413793, 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4048 , 0.4038 , 0.4028 , 0.4014 , 0.4011 , 0.3992 ,\n",
       "            0.3967 , 0.3965 , 0.3948 , 0.3945 , 0.3943 , 0.3928 , 0.3918 ,\n",
       "            0.3916 , 0.391  , 0.3901 , 0.39   , 0.3892 , 0.3887 , 0.3884 ,\n",
       "            0.3867 , 0.3865 , 0.385  , 0.3823 , 0.378  , 0.3752 , 0.373  ,\n",
       "            0.3726 , 0.3723 , 0.3716 , 0.3706 , 0.3704 , 0.3662 , 0.366  ,\n",
       "            0.3652 , 0.365  , 0.3645 , 0.364  , 0.3635 , 0.362  , 0.3618 ,\n",
       "            0.361  , 0.3599 , 0.358  , 0.3577 , 0.3574 , 0.3572 , 0.349  ,\n",
       "            0.3481 , 0.3457 , 0.3408 , 0.3396 , 0.338  , 0.3357 , 0.3313 ,\n",
       "            0.3235 , 0.3208 , 0.3118 , 0.3115 , 0.3064 , 0.2998 , 0.2944 ,\n",
       "            0.2864 , 0.2854 , 0.281  , 0.276  , 0.2722 , 0.2664 , 0.2627 ,\n",
       "            0.2605 , 0.2603 , 0.26   , 0.2478 , 0.2456 , 0.2437 , 0.2401 ,\n",
       "            0.2399 , 0.2391 , 0.239  , 0.2384 , 0.2355 , 0.2327 , 0.2322 ,\n",
       "            0.2311 , 0.2281 , 0.2278 , 0.2247 , 0.2239 , 0.2235 , 0.2234 ,\n",
       "            0.223  , 0.2216 , 0.2212 , 0.2175 , 0.217  , 0.2148 , 0.2064 ,\n",
       "            0.2042 , 0.2034 , 0.202  , 0.2004 , 0.197  , 0.1956 , 0.1925 ,\n",
       "            0.19   , 0.1893 , 0.1873 , 0.1864 , 0.1859 , 0.1842 , 0.1812 ,\n",
       "            0.1798 , 0.1776 , 0.1754 , 0.1747 , 0.174  , 0.1733 , 0.172  ,\n",
       "            0.1718 , 0.1709 , 0.1705 , 0.1697 , 0.1682 , 0.1672 , 0.1653 ,\n",
       "            0.1641 , 0.1636 , 0.163  , 0.161  , 0.1589 , 0.1587 , 0.1584 ,\n",
       "            0.1572 , 0.1571 , 0.1558 , 0.1544 , 0.1539 , 0.1531 , 0.1521 ,\n",
       "            0.152  , 0.1504 , 0.1495 , 0.1493 , 0.1484 , 0.148  , 0.1477 ,\n",
       "            0.1464 , 0.1462 , 0.1454 , 0.1442 , 0.1437 , 0.1425 , 0.1414 ,\n",
       "            0.1412 , 0.141  , 0.1393 , 0.1387 , 0.1378 , 0.1377 , 0.137  ,\n",
       "            0.1366 , 0.1362 , 0.1361 , 0.1357 , 0.1342 , 0.1338 , 0.1322 ,\n",
       "            0.1311 , 0.1305 , 0.1301 , 0.1296 , 0.1295 , 0.129  , 0.1284 ,\n",
       "            0.1279 , 0.1274 , 0.1249 , 0.12335, 0.1225 , 0.12244, 0.12213,\n",
       "            0.12177, 0.1213 , 0.1197 , 0.1184 , 0.11816, 0.118  , 0.11676,\n",
       "            0.11536, 0.1118 , 0.11145, 0.1103 , 0.1097 , 0.1095 , 0.1086 ,\n",
       "            0.1074 , 0.1067 , 0.1058 , 0.1052 , 0.1045 , 0.1041 , 0.1036 ,\n",
       "            0.10266, 0.1023 , 0.1011 , 0.1005 , 0.09894, 0.09686, 0.09656,\n",
       "            0.0933 , 0.0932 , 0.09235, 0.0906 , 0.0871 , 0.0862 , 0.086  ,\n",
       "            0.08466, 0.08344, 0.083  , 0.0825 , 0.0804 , 0.07965, 0.07837,\n",
       "            0.06995, 0.0698 , 0.0677 , 0.06573, 0.06525, 0.06076, 0.05975],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.03731343,\n",
       "            0.04477612, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.10447761, 0.1119403 , 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26865673, 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.64179105, 0.64179105, 0.64179105, 0.64179105,\n",
       "            0.64179105, 0.64179105, 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6641791 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.6865672 , 0.6865672 , 0.6865672 , 0.6865672 ,\n",
       "            0.69402987, 0.69402987, 0.70149255, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.74626863, 0.74626863, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76119405, 0.76865673, 0.76865673, 0.76865673,\n",
       "            0.7761194 , 0.7761194 , 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.7910448 , 0.7910448 , 0.79850745, 0.79850745, 0.79850745,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8134328 , 0.8134328 ,\n",
       "            0.8208955 , 0.8358209 , 0.8432836 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.86567163, 0.86567163, 0.86567163, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8880597 , 0.8880597 ,\n",
       "            0.8955224 , 0.8955224 , 0.9029851 , 0.9104478 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.92537314, 0.92537314, 0.9328358 ,\n",
       "            0.9328358 , 0.9402985 , 0.9402985 , 0.9477612 , 0.9477612 ,\n",
       "            0.95522386, 0.95522386, 0.95522386, 0.95522386, 0.96268654,\n",
       "            0.96268654, 0.9701493 , 0.9701493 , 0.9701493 , 0.97761196,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.04310345, 0.06034483, 0.06896552,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.12931034, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.14655173, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.19827586, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.37931034, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.49137932, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.6034483 , 0.6034483 , 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.82758623, 0.82758623, 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.86206895, 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3933 , 0.3928 , 0.392  , 0.39   , 0.389  , 0.3867 ,\n",
       "            0.3845 , 0.3843 , 0.3833 , 0.3826 , 0.381  , 0.3801 , 0.38   ,\n",
       "            0.3792 , 0.379  , 0.3784 , 0.3767 , 0.3762 , 0.3752 , 0.375  ,\n",
       "            0.37   , 0.368  , 0.3652 , 0.3628 , 0.3625 , 0.362  , 0.361  ,\n",
       "            0.3606 , 0.3604 , 0.3596 , 0.3562 , 0.3552 , 0.3547 , 0.354  ,\n",
       "            0.3528 , 0.3523 , 0.352  , 0.3516 , 0.3513 , 0.35   , 0.3481 ,\n",
       "            0.348  , 0.3477 , 0.3467 , 0.346  , 0.3455 , 0.3398 , 0.3372 ,\n",
       "            0.3357 , 0.331  , 0.3303 , 0.3281 , 0.323  , 0.322  , 0.3132 ,\n",
       "            0.3103 , 0.303  , 0.3013 , 0.2974 , 0.2874 , 0.281  , 0.2769 ,\n",
       "            0.2751 , 0.2722 , 0.2664 , 0.2637 , 0.2568 , 0.252  , 0.2515 ,\n",
       "            0.2502 , 0.2394 , 0.2368 , 0.2316 , 0.2314 , 0.2302 , 0.2301 ,\n",
       "            0.2297 , 0.2251 , 0.2247 , 0.2235 , 0.2216 , 0.2185 , 0.2175 ,\n",
       "            0.2167 , 0.2158 , 0.2152 , 0.2145 , 0.2129 , 0.2114 , 0.2095 ,\n",
       "            0.2053 , 0.2021 , 0.1979 , 0.1958 , 0.1934 , 0.191  , 0.1893 ,\n",
       "            0.1876 , 0.1848 , 0.1826 , 0.1816 , 0.181  , 0.1796 , 0.1776 ,\n",
       "            0.1755 , 0.1743 , 0.173  , 0.1704 , 0.1678 , 0.1666 , 0.1665 ,\n",
       "            0.1649 , 0.1646 , 0.1636 , 0.1624 , 0.1611 , 0.1599 , 0.1586 ,\n",
       "            0.1581 , 0.1566 , 0.1564 , 0.156  , 0.1552 , 0.1531 , 0.1511 ,\n",
       "            0.1509 , 0.1497 , 0.1495 , 0.1493 , 0.1486 , 0.1469 , 0.1467 ,\n",
       "            0.144  , 0.1437 , 0.1431 , 0.142  , 0.1417 , 0.1409 , 0.1405 ,\n",
       "            0.1404 , 0.1396 , 0.139  , 0.1389 , 0.1387 , 0.1377 , 0.1371 ,\n",
       "            0.135  , 0.134  , 0.1323 , 0.1312 , 0.131  , 0.1305 , 0.1293 ,\n",
       "            0.1289 , 0.1288 , 0.1271 , 0.1266 , 0.1262 , 0.1257 , 0.1254 ,\n",
       "            0.1252 , 0.12445, 0.1242 , 0.12366, 0.1232 , 0.12286, 0.12177,\n",
       "            0.1213 , 0.12024, 0.1194 , 0.1193 , 0.1188 , 0.1184 , 0.1174 ,\n",
       "            0.1172 , 0.1166 , 0.115  , 0.1144 , 0.1142 , 0.113  , 0.1128 ,\n",
       "            0.1118 , 0.11127, 0.1105 , 0.1084 , 0.1067 , 0.1063 , 0.1052 ,\n",
       "            0.1023 , 0.10126, 0.1011 , 0.0995 , 0.0991 , 0.09894, 0.09875,\n",
       "            0.0986 , 0.09753, 0.0959 , 0.09534, 0.09515, 0.0939 , 0.0937 ,\n",
       "            0.0935 , 0.0925 , 0.09155, 0.0899 , 0.0869 , 0.0868 , 0.0854 ,\n",
       "            0.0851 , 0.0845 , 0.0831 , 0.082  , 0.0788 , 0.07825, 0.0774 ,\n",
       "            0.0771 , 0.07684, 0.075  , 0.0749 , 0.0742 , 0.07135, 0.0712 ,\n",
       "            0.0694 , 0.06244, 0.06232, 0.0601 , 0.05814, 0.058  , 0.054  ,\n",
       "            0.0535 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.619403  , 0.619403  ,\n",
       "            0.619403  , 0.619403  , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.63432837, 0.63432837, 0.64179105,\n",
       "            0.64179105, 0.64179105, 0.64179105, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.6641791 , 0.6641791 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6791045 , 0.6865672 ,\n",
       "            0.6865672 , 0.69402987, 0.69402987, 0.69402987, 0.69402987,\n",
       "            0.70149255, 0.70149255, 0.70149255, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.73880595,\n",
       "            0.74626863, 0.74626863, 0.74626863, 0.75373137, 0.75373137,\n",
       "            0.75373137, 0.76119405, 0.76119405, 0.76119405, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7835821 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.79850745, 0.79850745, 0.79850745,\n",
       "            0.79850745, 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8507463 , 0.8507463 , 0.8507463 , 0.85820895, 0.85820895,\n",
       "            0.86567163, 0.86567163, 0.8731343 , 0.8731343 , 0.8880597 ,\n",
       "            0.8880597 , 0.8880597 , 0.8955224 , 0.8955224 , 0.8955224 ,\n",
       "            0.9029851 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9328358 , 0.9402985 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.95522386, 0.95522386, 0.95522386, 0.95522386,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.03448276, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1637931 , 0.1637931 , 0.1724138 , 0.1724138 ,\n",
       "            0.18103448, 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.5086207 ,\n",
       "            0.5086207 , 0.51724136, 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.54310346, 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.63793105, 0.6465517 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.6896552 , 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.70689654, 0.7155172 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3828 , 0.3823 , 0.3816 , 0.3792 , 0.379  , 0.3782 ,\n",
       "            0.3772 , 0.377  , 0.3748 , 0.3743 , 0.373  , 0.3728 , 0.3708 ,\n",
       "            0.3706 , 0.37   , 0.3699 , 0.3694 , 0.369  , 0.3677 , 0.3667 ,\n",
       "            0.3657 , 0.36   , 0.3591 , 0.3557 , 0.3545 , 0.3528 , 0.3523 ,\n",
       "            0.3513 , 0.3508 , 0.3499 , 0.3489 , 0.3474 , 0.3472 , 0.347  ,\n",
       "            0.3467 , 0.3462 , 0.3447 , 0.344  , 0.3438 , 0.343  , 0.3423 ,\n",
       "            0.3413 , 0.3408 , 0.3406 , 0.3398 , 0.3389 , 0.337  , 0.3345 ,\n",
       "            0.334  , 0.3293 , 0.3289 , 0.3252 , 0.3245 , 0.3218 , 0.318  ,\n",
       "            0.3137 , 0.3074 , 0.304  , 0.3008 , 0.2964 , 0.2961 , 0.2803 ,\n",
       "            0.2732 , 0.2727 , 0.2717 , 0.271  , 0.2646 , 0.2634 , 0.2542 ,\n",
       "            0.2534 , 0.2522 , 0.2515 , 0.244  , 0.2401 , 0.237  , 0.2339 ,\n",
       "            0.2322 , 0.2319 , 0.229  , 0.2225 , 0.2222 , 0.2208 , 0.2195 ,\n",
       "            0.2194 , 0.219  , 0.2179 , 0.2177 , 0.2168 , 0.2163 , 0.2152 ,\n",
       "            0.2147 , 0.2137 , 0.2134 , 0.2124 , 0.206  , 0.201  , 0.199  ,\n",
       "            0.197  , 0.1965 , 0.194  , 0.1936 , 0.1882 , 0.1859 , 0.1835 ,\n",
       "            0.1827 , 0.1824 , 0.182  , 0.1794 , 0.1768 , 0.1754 , 0.172  ,\n",
       "            0.1697 , 0.1692 , 0.1677 , 0.1675 , 0.1652 , 0.1638 , 0.1624 ,\n",
       "            0.1608 , 0.1587 , 0.1584 , 0.1573 , 0.1567 , 0.1547 , 0.1544 ,\n",
       "            0.1537 , 0.1525 , 0.152  , 0.1515 , 0.1512 , 0.1504 , 0.1498 ,\n",
       "            0.1469 , 0.1465 , 0.1456 , 0.1438 , 0.143  , 0.1427 , 0.1422 ,\n",
       "            0.1417 , 0.1412 , 0.1395 , 0.1387 , 0.1385 , 0.1382 , 0.138  ,\n",
       "            0.1376 , 0.1368 , 0.1365 , 0.1364 , 0.1359 , 0.134  , 0.1335 ,\n",
       "            0.1334 , 0.1328 , 0.1305 , 0.1294 , 0.1288 , 0.1287 , 0.128  ,\n",
       "            0.1277 , 0.127  , 0.1265 , 0.1262 , 0.1251 , 0.1249 , 0.124  ,\n",
       "            0.1239 , 0.1232 , 0.1226 , 0.1225 , 0.1216 , 0.12146, 0.12115,\n",
       "            0.1207 , 0.1195 , 0.119  , 0.1186 , 0.11816, 0.118  , 0.11676,\n",
       "            0.11597, 0.115  , 0.11475, 0.1134 , 0.11316, 0.113  , 0.1128 ,\n",
       "            0.112  , 0.11145, 0.11127, 0.10913, 0.10876, 0.1065 , 0.1034 ,\n",
       "            0.103  , 0.1025 , 0.10034, 0.0998 , 0.09845, 0.0981 , 0.0974 ,\n",
       "            0.0967 , 0.0964 , 0.096  , 0.0942 , 0.0939 , 0.0933 , 0.0927 ,\n",
       "            0.0922 , 0.0914 , 0.09125, 0.0899 , 0.0882 , 0.0848 , 0.08417,\n",
       "            0.08405, 0.0806 , 0.0798 , 0.0775 , 0.0763 , 0.0761 , 0.07544,\n",
       "            0.0752 , 0.0742 , 0.07367, 0.07227, 0.0695 , 0.06903, 0.0672 ,\n",
       "            0.0613 , 0.05878, 0.05707, 0.05634, 0.0533 , 0.0532 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.06716418, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.2238806 , 0.23880596, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2835821 , 0.29104477, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.6119403 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.619403  , 0.619403  , 0.619403  , 0.6268657 ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.6641791 , 0.6641791 , 0.6641791 , 0.6641791 , 0.67164177,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.69402987,\n",
       "            0.70149255, 0.70149255, 0.70149255, 0.70149255, 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.73880595, 0.73880595, 0.74626863, 0.75373137, 0.75373137,\n",
       "            0.75373137, 0.75373137, 0.76119405, 0.76119405, 0.76119405,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.79850745, 0.79850745, 0.79850745,\n",
       "            0.79850745, 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8507463 , 0.8507463 , 0.85820895, 0.85820895, 0.85820895,\n",
       "            0.8731343 , 0.880597  , 0.880597  , 0.8880597 , 0.8880597 ,\n",
       "            0.8880597 , 0.8955224 , 0.8955224 , 0.8955224 , 0.9029851 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9402985 , 0.9402985 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.95522386, 0.95522386, 0.95522386,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.97761196, 0.97761196, 0.98507464, 0.9925373 , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.03448276, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.19827586,\n",
       "            0.20689656, 0.20689656, 0.20689656, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.37931034, 0.38793105,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.43965518, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5       , 0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.54310346,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.62068963, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.70689654, 0.70689654, 0.7155172 , 0.7241379 , 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8103448 , 0.8189655 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3745 , 0.374  , 0.3735 , 0.3718 , 0.3699 , 0.3696 ,\n",
       "            0.3674 , 0.3667 , 0.365  , 0.3645 , 0.3643 , 0.3633 , 0.3623 ,\n",
       "            0.3616 , 0.3613 , 0.361  , 0.3608 , 0.3599 , 0.3591 , 0.3584 ,\n",
       "            0.3582 , 0.3552 , 0.353  , 0.3499 , 0.348  , 0.344  , 0.343  ,\n",
       "            0.3425 , 0.341  , 0.3406 , 0.34   , 0.3398 , 0.3396 , 0.3394 ,\n",
       "            0.3389 , 0.3386 , 0.3381 , 0.337  , 0.3364 , 0.336  , 0.3347 ,\n",
       "            0.3315 , 0.3281 , 0.327  , 0.3242 , 0.3235 , 0.3232 , 0.321  ,\n",
       "            0.3186 , 0.3127 , 0.3083 , 0.305  , 0.3042 , 0.301  , 0.298  ,\n",
       "            0.282  , 0.278  , 0.2776 , 0.2754 , 0.2742 , 0.273  , 0.2683 ,\n",
       "            0.263  , 0.2607 , 0.2598 , 0.2595 , 0.2493 , 0.2477 , 0.246  ,\n",
       "            0.2451 , 0.2426 , 0.2417 , 0.237  , 0.2319 , 0.2314 , 0.2306 ,\n",
       "            0.2278 , 0.2272 , 0.2266 , 0.2261 , 0.2252 , 0.2249 , 0.2242 ,\n",
       "            0.2238 , 0.2233 , 0.222  , 0.2217 , 0.2119 , 0.21   , 0.2081 ,\n",
       "            0.208  , 0.2076 , 0.2042 , 0.2023 , 0.202  , 0.1964 , 0.1952 ,\n",
       "            0.1941 , 0.1924 , 0.1912 , 0.1882 , 0.1866 , 0.1853 , 0.1831 ,\n",
       "            0.1819 , 0.1771 , 0.177  , 0.1766 , 0.1743 , 0.173  , 0.1727 ,\n",
       "            0.1721 , 0.1672 , 0.167  , 0.1665 , 0.1664 , 0.1653 , 0.1648 ,\n",
       "            0.1646 , 0.1643 , 0.1641 , 0.1626 , 0.1589 , 0.1588 , 0.1575 ,\n",
       "            0.1567 , 0.1562 , 0.156  , 0.154  , 0.1538 , 0.1527 , 0.1511 ,\n",
       "            0.1498 , 0.1489 , 0.1487 , 0.1481 , 0.1477 , 0.1475 , 0.1461 ,\n",
       "            0.146  , 0.1455 , 0.1451 , 0.1447 , 0.1445 , 0.1423 , 0.1421 ,\n",
       "            0.139  , 0.1389 , 0.1381 , 0.1372 , 0.1364 , 0.1361 , 0.1359 ,\n",
       "            0.1357 , 0.1355 , 0.1349 , 0.1334 , 0.1329 , 0.1324 , 0.132  ,\n",
       "            0.1318 , 0.1313 , 0.1312 , 0.131  , 0.1304 , 0.13   , 0.1288 ,\n",
       "            0.1283 , 0.127  , 0.1268 , 0.1262 , 0.1256 , 0.1243 , 0.1241 ,\n",
       "            0.1232 , 0.1229 , 0.1225 , 0.1219 , 0.121  , 0.12085, 0.1207 ,\n",
       "            0.1188 , 0.1172 , 0.11597, 0.112  , 0.1099 , 0.1097 , 0.1093 ,\n",
       "            0.1076 , 0.10706, 0.1058 , 0.1054 , 0.1052 , 0.1043 , 0.1034 ,\n",
       "            0.1032 , 0.1021 , 0.1019 , 0.10156, 0.1009 , 0.0998 , 0.0993 ,\n",
       "            0.0974 , 0.0942 , 0.0933 , 0.0922 , 0.09204, 0.0898 , 0.0871 ,\n",
       "            0.0866 , 0.08527, 0.0848 , 0.08386, 0.0836 , 0.0831 , 0.0824 ,\n",
       "            0.0805 , 0.0778 , 0.07684, 0.07477, 0.06964, 0.0695 , 0.06683,\n",
       "            0.0651 , 0.06396, 0.0613 , 0.0611 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.6268657 , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6567164 , 0.6641791 , 0.6641791 , 0.67164177, 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6865672 , 0.70149255, 0.70149255,\n",
       "            0.70149255, 0.70149255, 0.7089552 , 0.7089552 , 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7164179 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76119405, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7761194 , 0.7761194 , 0.7835821 , 0.7910448 , 0.7910448 ,\n",
       "            0.79850745, 0.79850745, 0.79850745, 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8134328 , 0.8208955 , 0.82835823, 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.85820895, 0.85820895, 0.86567163, 0.880597  , 0.8880597 ,\n",
       "            0.8880597 , 0.8880597 , 0.8955224 , 0.8955224 , 0.8955224 ,\n",
       "            0.9029851 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9402985 , 0.9402985 , 0.9402985 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.9477612 , 0.95522386,\n",
       "            0.95522386, 0.95522386, 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.97761196, 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.00862069, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06034483, 0.06896552,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.12931034, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.19827586, 0.20689656, 0.20689656,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.30172414, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.3448276 , 0.35344827,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.5086207 , 0.5086207 , 0.51724136, 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7155172 , 0.7155172 , 0.7241379 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3672 , 0.3667 , 0.3662 , 0.3657 , 0.3633 , 0.3613 ,\n",
       "            0.3594 , 0.359  , 0.3582 , 0.3577 , 0.3567 , 0.3564 , 0.3557 ,\n",
       "            0.3555 , 0.3545 , 0.3542 , 0.353  , 0.3525 , 0.3523 , 0.3518 ,\n",
       "            0.3516 , 0.3499 , 0.3484 , 0.3474 , 0.3418 , 0.3413 , 0.3403 ,\n",
       "            0.3396 , 0.3386 , 0.3381 , 0.338  , 0.3372 , 0.337  , 0.3364 ,\n",
       "            0.3362 , 0.336  , 0.3357 , 0.3354 , 0.3345 , 0.3342 , 0.334  ,\n",
       "            0.3335 , 0.3328 , 0.3315 , 0.3298 , 0.3286 , 0.328  , 0.327  ,\n",
       "            0.3247 , 0.3235 , 0.3228 , 0.3137 , 0.3132 , 0.3123 , 0.3115 ,\n",
       "            0.3113 , 0.308  , 0.3027 , 0.2893 , 0.287  , 0.2852 , 0.2847 ,\n",
       "            0.2822 , 0.278  , 0.277  , 0.2764 , 0.2742 , 0.2722 , 0.268  ,\n",
       "            0.263  , 0.2612 , 0.259  , 0.2583 , 0.2556 , 0.2534 , 0.25   ,\n",
       "            0.2483 , 0.2438 , 0.2428 , 0.2421 , 0.2394 , 0.2388 , 0.237  ,\n",
       "            0.2367 , 0.2356 , 0.2338 , 0.2328 , 0.2314 , 0.2311 , 0.2286 ,\n",
       "            0.2274 , 0.2251 , 0.2233 , 0.2211 , 0.2195 , 0.2181 , 0.2163 ,\n",
       "            0.215  , 0.2113 , 0.2096 , 0.2073 , 0.2004 , 0.199  , 0.1984 ,\n",
       "            0.1959 , 0.1925 , 0.191  , 0.1909 , 0.1873 , 0.186  , 0.1848 ,\n",
       "            0.1836 , 0.1823 , 0.1821 , 0.182  , 0.181  , 0.1803 , 0.1794 ,\n",
       "            0.1775 , 0.1749 , 0.1737 , 0.1735 , 0.173  , 0.1727 , 0.172  ,\n",
       "            0.1714 , 0.1677 , 0.1671 , 0.1665 , 0.1648 , 0.1625 , 0.1624 ,\n",
       "            0.1609 , 0.1606 , 0.1594 , 0.1589 , 0.158  , 0.157  , 0.1567 ,\n",
       "            0.1562 , 0.1558 , 0.1542 , 0.1536 , 0.1521 , 0.1508 , 0.1503 ,\n",
       "            0.1494 , 0.1492 , 0.149  , 0.1489 , 0.1478 , 0.1477 , 0.1472 ,\n",
       "            0.1469 , 0.1462 , 0.1449 , 0.1448 , 0.1431 , 0.142  , 0.1418 ,\n",
       "            0.1415 , 0.1414 , 0.1409 , 0.1405 , 0.1404 , 0.1396 , 0.1376 ,\n",
       "            0.1372 , 0.1353 , 0.135  , 0.1349 , 0.1348 , 0.1342 , 0.134  ,\n",
       "            0.1338 , 0.1332 , 0.1324 , 0.1321 , 0.1302 , 0.1301 , 0.1273 ,\n",
       "            0.12274, 0.1222 , 0.12085, 0.12054, 0.1193 , 0.1184 , 0.11694,\n",
       "            0.1158 , 0.11536, 0.11456, 0.1144 , 0.1138 , 0.1134 , 0.1128 ,\n",
       "            0.112  , 0.1103 , 0.1099 , 0.1086 , 0.1054 , 0.10486, 0.1045 ,\n",
       "            0.10175, 0.10144, 0.10034, 0.0972 , 0.096  , 0.0957 , 0.09485,\n",
       "            0.094  , 0.0939 , 0.0935 , 0.09283, 0.0903 , 0.0877 , 0.0859 ,\n",
       "            0.08374, 0.07947, 0.07935, 0.0763 , 0.07465, 0.0729 , 0.07104,\n",
       "            0.07056], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01492537, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.47761193, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.619403  , 0.619403  , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.63432837, 0.63432837, 0.64179105, 0.6492537 , 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.6641791 , 0.6641791 , 0.67164177,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.69402987,\n",
       "            0.69402987, 0.69402987, 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7164179 , 0.7164179 , 0.7238806 , 0.7238806 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7761194 ,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8134328 ,\n",
       "            0.8208955 , 0.8208955 , 0.82835823, 0.82835823, 0.8358209 ,\n",
       "            0.8358209 , 0.8432836 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.85820895, 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8880597 , 0.8955224 , 0.8955224 ,\n",
       "            0.8955224 , 0.9029851 , 0.9029851 , 0.9029851 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9402985 , 0.9477612 , 0.9477612 , 0.9477612 , 0.9477612 ,\n",
       "            0.95522386, 0.95522386, 0.96268654, 0.96268654, 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.97761196, 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.04310345, 0.04310345, 0.05172414, 0.05172414,\n",
       "            0.05172414, 0.06034483, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.4827586 , 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5603448 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.76724136, 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8189655 , 0.8189655 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.362  , 0.3613 , 0.361  , 0.3591 , 0.3586 , 0.3574 ,\n",
       "            0.3545 , 0.3538 , 0.3535 , 0.3528 , 0.3516 , 0.3513 , 0.3494 ,\n",
       "            0.3489 , 0.3484 , 0.348  , 0.3472 , 0.3464 , 0.3455 , 0.3447 ,\n",
       "            0.3433 , 0.343  , 0.3428 , 0.3416 , 0.341  , 0.3408 , 0.3403 ,\n",
       "            0.3398 , 0.3396 , 0.339  , 0.3389 , 0.3386 , 0.3381 , 0.338  ,\n",
       "            0.3376 , 0.3374 , 0.3357 , 0.3354 , 0.335  , 0.3347 , 0.3335 ,\n",
       "            0.3328 , 0.3325 , 0.3315 , 0.3313 , 0.3298 , 0.3296 , 0.3286 ,\n",
       "            0.3271 , 0.326  , 0.3257 , 0.3245 , 0.322  , 0.3188 , 0.3179 ,\n",
       "            0.3154 , 0.3118 , 0.3079 , 0.3066 , 0.3047 , 0.3003 , 0.297  ,\n",
       "            0.2947 , 0.2942 , 0.2932 , 0.2908 , 0.2898 , 0.2852 , 0.2847 ,\n",
       "            0.2834 , 0.282  , 0.2817 , 0.2788 , 0.2769 , 0.2766 , 0.2764 ,\n",
       "            0.269  , 0.2673 , 0.2664 , 0.2637 , 0.2607 , 0.2605 , 0.2595 ,\n",
       "            0.2588 , 0.2576 , 0.2524 , 0.2493 , 0.249  , 0.2474 , 0.2467 ,\n",
       "            0.246  , 0.2428 , 0.2418 , 0.2391 , 0.2384 , 0.2374 , 0.2352 ,\n",
       "            0.233  , 0.2328 , 0.2313 , 0.2311 , 0.2246 , 0.2227 , 0.219  ,\n",
       "            0.2186 , 0.2162 , 0.2145 , 0.2124 , 0.2095 , 0.2079 , 0.2075 ,\n",
       "            0.2063 , 0.206  , 0.2056 , 0.2047 , 0.2045 , 0.2028 , 0.2024 ,\n",
       "            0.2013 , 0.2002 , 0.1971 , 0.1965 , 0.1964 , 0.1958 , 0.1952 ,\n",
       "            0.1913 , 0.1892 , 0.1891 , 0.1887 , 0.1874 , 0.1869 , 0.1858 ,\n",
       "            0.1833 , 0.1805 , 0.1803 , 0.1796 , 0.179  , 0.1788 , 0.1776 ,\n",
       "            0.1775 , 0.1754 , 0.1753 , 0.1752 , 0.1747 , 0.1744 , 0.1733 ,\n",
       "            0.1718 , 0.1704 , 0.1697 , 0.169  , 0.1687 , 0.1686 , 0.1681 ,\n",
       "            0.1677 , 0.1661 , 0.166  , 0.1659 , 0.1649 , 0.164  , 0.1638 ,\n",
       "            0.1631 , 0.163  , 0.1619 , 0.1606 , 0.1593 , 0.159  , 0.1588 ,\n",
       "            0.158  , 0.1572 , 0.1561 , 0.156  , 0.1543 , 0.1536 , 0.1533 ,\n",
       "            0.1528 , 0.1526 , 0.1525 , 0.1509 , 0.1508 , 0.1504 , 0.1498 ,\n",
       "            0.1495 , 0.1488 , 0.1464 , 0.1459 , 0.1443 , 0.1406 , 0.1393 ,\n",
       "            0.1392 , 0.1389 , 0.1378 , 0.1368 , 0.1353 , 0.134  , 0.1333 ,\n",
       "            0.1332 , 0.1327 , 0.1326 , 0.1324 , 0.1316 , 0.131  , 0.1302 ,\n",
       "            0.13   , 0.1289 , 0.1282 , 0.1268 , 0.1266 , 0.12366, 0.12317,\n",
       "            0.1226 , 0.118  , 0.1172 , 0.11475, 0.11395, 0.1118 , 0.11066,\n",
       "            0.1105 , 0.1103 , 0.1067 , 0.1043 , 0.10126, 0.09894, 0.096  ,\n",
       "            0.0959 , 0.0925 , 0.0909 , 0.0883 , 0.0874 , 0.0865 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.25373134, 0.26865673, 0.2761194 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41791046, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 ,\n",
       "            0.6567164 , 0.6567164 , 0.6567164 , 0.6641791 , 0.6865672 ,\n",
       "            0.6865672 , 0.6865672 , 0.70149255, 0.70149255, 0.70149255,\n",
       "            0.70149255, 0.7089552 , 0.7089552 , 0.7164179 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73134327, 0.73134327, 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.74626863, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.76865673, 0.7761194 , 0.7761194 ,\n",
       "            0.7835821 , 0.7835821 , 0.7835821 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.8955224 , 0.9029851 ,\n",
       "            0.9029851 , 0.9029851 , 0.9029851 , 0.9104478 , 0.9104478 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9402985 , 0.9477612 , 0.9477612 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.95522386, 0.96268654, 0.96268654,\n",
       "            0.96268654, 0.96268654, 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.97761196, 0.97761196, 0.98507464, 0.9925373 , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.03448276, 0.04310345, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.04310345, 0.05172414, 0.05172414,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.0862069 , 0.10344828, 0.10344828, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25      , 0.25      , 0.25862068, 0.2672414 , 0.2672414 ,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31034482, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5       , 0.5086207 ,\n",
       "            0.5086207 , 0.51724136, 0.51724136, 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.5689655 , 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.8189655 , 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3608 , 0.3594 , 0.359  , 0.3586 , 0.3584 , 0.3582 ,\n",
       "            0.3577 , 0.354  , 0.3538 , 0.353  , 0.3525 , 0.3513 , 0.351  ,\n",
       "            0.3503 , 0.348  , 0.3477 , 0.3474 , 0.3472 , 0.347  , 0.3467 ,\n",
       "            0.3462 , 0.346  , 0.3457 , 0.3455 , 0.3452 , 0.3447 , 0.3445 ,\n",
       "            0.3442 , 0.344  , 0.3438 , 0.3435 , 0.3433 , 0.343  , 0.3425 ,\n",
       "            0.341  , 0.3398 , 0.3394 , 0.3389 , 0.3386 , 0.3381 , 0.338  ,\n",
       "            0.3372 , 0.3367 , 0.3364 , 0.3357 , 0.3352 , 0.3335 , 0.3328 ,\n",
       "            0.3308 , 0.3289 , 0.3284 , 0.3281 , 0.3276 , 0.3257 , 0.3252 ,\n",
       "            0.3237 , 0.321  , 0.3196 , 0.3193 , 0.3167 , 0.3142 , 0.314  ,\n",
       "            0.3125 , 0.3098 , 0.3096 , 0.3088 , 0.3086 , 0.306  , 0.3037 ,\n",
       "            0.303  , 0.3022 , 0.3005 , 0.2988 , 0.2979 , 0.2961 , 0.2954 ,\n",
       "            0.295  , 0.288  , 0.2876 , 0.2864 , 0.2834 , 0.2825 , 0.2808 ,\n",
       "            0.277  , 0.2766 , 0.275  , 0.2747 , 0.2737 , 0.2715 , 0.2683 ,\n",
       "            0.2659 , 0.265  , 0.2646 , 0.2642 , 0.2637 , 0.2617 , 0.2605 ,\n",
       "            0.256  , 0.255  , 0.2537 , 0.2517 , 0.249  , 0.2485 , 0.2482 ,\n",
       "            0.2451 , 0.2434 , 0.2399 , 0.2384 , 0.2374 , 0.2347 , 0.2318 ,\n",
       "            0.2316 , 0.2313 , 0.231  , 0.2294 , 0.2266 , 0.2257 , 0.2252 ,\n",
       "            0.2247 , 0.2246 , 0.2208 , 0.2195 , 0.2184 , 0.2161 , 0.213  ,\n",
       "            0.2124 , 0.209  , 0.2075 , 0.2073 , 0.2051 , 0.2034 , 0.2023 ,\n",
       "            0.2017 , 0.2009 , 0.1998 , 0.1973 , 0.1971 , 0.1967 , 0.1965 ,\n",
       "            0.1959 , 0.1956 , 0.1954 , 0.1953 , 0.1935 , 0.1924 , 0.1906 ,\n",
       "            0.1897 , 0.1896 , 0.189  , 0.1884 , 0.1882 , 0.1876 , 0.1866 ,\n",
       "            0.186  , 0.1853 , 0.185  , 0.1848 , 0.1842 , 0.1838 , 0.1829 ,\n",
       "            0.1816 , 0.1812 , 0.1808 , 0.1804 , 0.1803 , 0.1796 , 0.179  ,\n",
       "            0.1781 , 0.177  , 0.1768 , 0.1763 , 0.1757 , 0.1752 , 0.1749 ,\n",
       "            0.1747 , 0.1744 , 0.1741 , 0.1733 , 0.1726 , 0.1711 , 0.1707 ,\n",
       "            0.1697 , 0.1678 , 0.1669 , 0.1653 , 0.1646 , 0.162  , 0.1614 ,\n",
       "            0.1611 , 0.1605 , 0.1598 , 0.1592 , 0.1575 , 0.1548 , 0.1545 ,\n",
       "            0.1544 , 0.1543 , 0.1539 , 0.1532 , 0.153  , 0.1527 , 0.151  ,\n",
       "            0.1501 , 0.1495 , 0.1494 , 0.1488 , 0.1473 , 0.1462 , 0.1459 ,\n",
       "            0.145  , 0.1399 , 0.1377 , 0.1366 , 0.1365 , 0.136  , 0.1339 ,\n",
       "            0.1326 , 0.1321 , 0.1313 , 0.131  , 0.128  , 0.127  , 0.12494,\n",
       "            0.1201 , 0.1178 , 0.11676, 0.1166 , 0.113  , 0.11145, 0.1084 ,\n",
       "            0.1076 , 0.1069 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02985075, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.07462686, 0.08955224, 0.08955224, 0.09701493,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.18656716, 0.20149253,\n",
       "            0.20895523, 0.2238806 , 0.23134328, 0.23880596, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.70149255, 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7164179 , 0.7238806 , 0.7238806 ,\n",
       "            0.7238806 , 0.73134327, 0.73134327, 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.76865673,\n",
       "            0.7761194 , 0.7761194 , 0.7761194 , 0.7761194 , 0.7910448 ,\n",
       "            0.79850745, 0.79850745, 0.80597013, 0.8134328 , 0.8134328 ,\n",
       "            0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.880597  , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9328358 , 0.9328358 , 0.9328358 , 0.9402985 , 0.9402985 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.04310345, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.04310345, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06034483, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.0775862 , 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.0862069 , 0.09482758, 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.11206897, 0.11206897,\n",
       "            0.12068965, 0.12068965, 0.12068965, 0.12068965, 0.12068965,\n",
       "            0.12068965, 0.12068965, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.14655173, 0.14655173, 0.14655173,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.19827586,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.31896552, 0.31896552, 0.31896552, 0.31896552,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.39655173, 0.39655173,\n",
       "            0.4051724 , 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.54310346, 0.54310346,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.5948276 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.63793105, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.73275864, 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.82758623, 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3735, 0.3655, 0.3652, 0.3623, 0.3616, 0.3591, 0.3582,\n",
       "            0.3564, 0.3562, 0.356 , 0.3557, 0.3552, 0.3545, 0.3542, 0.353 ,\n",
       "            0.3528, 0.352 , 0.3506, 0.3503, 0.35  , 0.3499, 0.3496, 0.3494,\n",
       "            0.3489, 0.3484, 0.348 , 0.3477, 0.3474, 0.347 , 0.346 , 0.3457,\n",
       "            0.3455, 0.345 , 0.3447, 0.3445, 0.344 , 0.3433, 0.342 , 0.341 ,\n",
       "            0.3406, 0.3403, 0.3396, 0.3394, 0.3389, 0.338 , 0.3376, 0.337 ,\n",
       "            0.3367, 0.3364, 0.3362, 0.3354, 0.333 , 0.3325, 0.3315, 0.3306,\n",
       "            0.3303, 0.33  , 0.329 , 0.328 , 0.3264, 0.3254, 0.325 , 0.3232,\n",
       "            0.3203, 0.3193, 0.318 , 0.3176, 0.3171, 0.3152, 0.3137, 0.3135,\n",
       "            0.3123, 0.3118, 0.3074, 0.3064, 0.306 , 0.304 , 0.2998, 0.2961,\n",
       "            0.2957, 0.2952, 0.294 , 0.2935, 0.292 , 0.2917, 0.2903, 0.2898,\n",
       "            0.2842, 0.2837, 0.282 , 0.2795, 0.2788, 0.2764, 0.2751, 0.2722,\n",
       "            0.2693, 0.2686, 0.2664, 0.2651, 0.265 , 0.2632, 0.263 , 0.2617,\n",
       "            0.2605, 0.2559, 0.2534, 0.2494, 0.248 , 0.2466, 0.2407, 0.2378,\n",
       "            0.237 , 0.2356, 0.2343, 0.234 , 0.2303, 0.2286, 0.2283, 0.2261,\n",
       "            0.226 , 0.2249, 0.2247, 0.2203, 0.2197, 0.219 , 0.218 , 0.2168,\n",
       "            0.2161, 0.2157, 0.215 , 0.2133, 0.213 , 0.212 , 0.2118, 0.211 ,\n",
       "            0.2109, 0.2108, 0.2106, 0.2086, 0.2084, 0.2081, 0.2079, 0.2076,\n",
       "            0.2059, 0.2056, 0.2054, 0.2031, 0.2024, 0.2021, 0.202 , 0.2009,\n",
       "            0.2007, 0.2006, 0.2004, 0.1996, 0.1995, 0.1985, 0.1971, 0.1968,\n",
       "            0.1967, 0.1956, 0.1954, 0.1947, 0.1943, 0.1942, 0.1903, 0.1896,\n",
       "            0.1886, 0.1848, 0.1844, 0.1842, 0.1838, 0.1835, 0.183 , 0.1829,\n",
       "            0.1821, 0.1807, 0.1797, 0.1779, 0.1775, 0.1772, 0.1763, 0.1753,\n",
       "            0.1743, 0.173 , 0.1726, 0.1709, 0.1707, 0.1705, 0.1696, 0.1686,\n",
       "            0.1676, 0.1674, 0.1671, 0.1622, 0.1598, 0.1592, 0.1575, 0.1564,\n",
       "            0.1547, 0.1542, 0.1533, 0.152 , 0.1515, 0.1473, 0.1458, 0.1447,\n",
       "            0.1384, 0.1383, 0.1359, 0.134 , 0.1327, 0.1313, 0.1285, 0.127 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.17910448, 0.19402985, 0.20149253, 0.20895523, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.37313432, 0.37313432, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6492537 , 0.6492537 ,\n",
       "            0.6492537 , 0.6641791 , 0.67164177, 0.6791045 , 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.7238806 , 0.73134327, 0.73134327,\n",
       "            0.73134327, 0.73134327, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7761194 , 0.7835821 , 0.7835821 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.80597013, 0.8134328 ,\n",
       "            0.8134328 , 0.8134328 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.8208955 , 0.8208955 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.86567163, 0.86567163, 0.8731343 , 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9328358 , 0.9328358 , 0.9328358 ,\n",
       "            0.9402985 , 0.9402985 , 0.9477612 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.95522386, 0.95522386, 0.96268654,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.13793103, 0.13793103, 0.14655173,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.1724138 ,\n",
       "            0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 ,\n",
       "            0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 ,\n",
       "            0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 ,\n",
       "            0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 , 0.18103448,\n",
       "            0.18103448, 0.18103448, 0.18103448, 0.18103448, 0.18103448,\n",
       "            0.18965517, 0.18965517, 0.18965517, 0.18965517, 0.18965517,\n",
       "            0.18965517, 0.18965517, 0.18965517, 0.20689656, 0.20689656,\n",
       "            0.20689656, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.2672414 , 0.2672414 , 0.2672414 , 0.27586207, 0.27586207,\n",
       "            0.28448275, 0.28448275, 0.29310346, 0.30172414, 0.30172414,\n",
       "            0.30172414, 0.31034482, 0.31034482, 0.31896552, 0.31896552,\n",
       "            0.31896552, 0.3275862 , 0.3275862 , 0.3275862 , 0.3275862 ,\n",
       "            0.33620688, 0.35344827, 0.36206895, 0.36206895, 0.37068966,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.37931034, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.44827586, 0.44827586,\n",
       "            0.46551725, 0.46551725, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5258621 , 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.54310346, 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5603448 , 0.5689655 , 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7155172 , 0.73275864, 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4011, 0.3997, 0.3982, 0.3928, 0.3906, 0.3904, 0.39  ,\n",
       "            0.389 , 0.3838, 0.3833, 0.3823, 0.3818, 0.3804, 0.373 , 0.3718,\n",
       "            0.3716, 0.3706, 0.3699, 0.3694, 0.3684, 0.3665, 0.3643, 0.3633,\n",
       "            0.3623, 0.3618, 0.3613, 0.361 , 0.3608, 0.3606, 0.3604, 0.36  ,\n",
       "            0.3599, 0.3596, 0.3594, 0.3591, 0.3582, 0.358 , 0.3577, 0.3574,\n",
       "            0.357 , 0.3564, 0.3562, 0.356 , 0.3557, 0.3547, 0.354 , 0.3538,\n",
       "            0.3528, 0.3525, 0.3523, 0.351 , 0.3503, 0.35  , 0.3494, 0.3489,\n",
       "            0.3486, 0.3472, 0.346 , 0.3457, 0.3455, 0.3452, 0.345 , 0.3447,\n",
       "            0.344 , 0.3435, 0.343 , 0.3428, 0.3408, 0.3398, 0.3389, 0.3386,\n",
       "            0.3384, 0.338 , 0.3364, 0.336 , 0.3357, 0.3354, 0.335 , 0.3323,\n",
       "            0.3308, 0.33  , 0.3293, 0.3289, 0.3267, 0.326 , 0.3242, 0.3228,\n",
       "            0.3223, 0.3208, 0.3198, 0.3193, 0.3164, 0.3157, 0.315 , 0.3147,\n",
       "            0.3127, 0.3103, 0.3088, 0.3086, 0.3066, 0.3062, 0.3052, 0.301 ,\n",
       "            0.2954, 0.2908, 0.288 , 0.2874, 0.2852, 0.2827, 0.28  , 0.276 ,\n",
       "            0.275 , 0.2725, 0.2676, 0.2673, 0.2642, 0.264 , 0.2637, 0.2632,\n",
       "            0.2605, 0.259 , 0.2573, 0.2566, 0.2563, 0.2556, 0.2524, 0.252 ,\n",
       "            0.2512, 0.2498, 0.2474, 0.2471, 0.246 , 0.2458, 0.2449, 0.244 ,\n",
       "            0.2437, 0.2428, 0.2426, 0.2422, 0.2405, 0.2397, 0.2384, 0.2383,\n",
       "            0.2378, 0.2375, 0.2366, 0.2363, 0.236 , 0.2351, 0.2347, 0.2343,\n",
       "            0.2338, 0.233 , 0.2328, 0.2327, 0.2323, 0.2318, 0.2316, 0.2297,\n",
       "            0.2295, 0.2294, 0.2285, 0.2283, 0.2278, 0.2277, 0.2266, 0.2252,\n",
       "            0.2249, 0.2247, 0.2238, 0.223 , 0.2222, 0.2205, 0.2194, 0.2186,\n",
       "            0.2184, 0.218 , 0.2173, 0.2167, 0.2161, 0.2148, 0.2144, 0.2119,\n",
       "            0.2115, 0.2113, 0.2109, 0.2108, 0.2103, 0.2101, 0.2081, 0.2076,\n",
       "            0.2063, 0.2056, 0.2051, 0.205 , 0.2047, 0.2045, 0.2031, 0.2015,\n",
       "            0.1993, 0.1976, 0.1964, 0.1946, 0.1943, 0.1935, 0.1924, 0.1882,\n",
       "            0.1873, 0.1865, 0.1852, 0.185 , 0.1846, 0.1799, 0.1792, 0.1736,\n",
       "            0.1726, 0.1694, 0.1682, 0.167 , 0.1665, 0.1664, 0.163 , 0.1594],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.1119403 , 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23134328, 0.23880596, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29850745, 0.30597016, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.6865672 , 0.69402987, 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7238806 , 0.73134327, 0.73134327,\n",
       "            0.73880595, 0.73880595, 0.74626863, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7761194 , 0.7835821 , 0.7835821 , 0.7910448 ,\n",
       "            0.7910448 , 0.7910448 , 0.7910448 , 0.7910448 , 0.79850745,\n",
       "            0.79850745, 0.79850745, 0.79850745, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.8432836 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8507463 , 0.8507463 , 0.8507463 , 0.86567163,\n",
       "            0.8731343 , 0.8731343 , 0.880597  , 0.8880597 , 0.9104478 ,\n",
       "            0.91791046, 0.91791046, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.95522386, 0.96268654, 0.96268654,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.98507464, 0.9925373 , 0.9925373 ,\n",
       "            0.9925373 , 0.9925373 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.29310346, 0.30172414, 0.31034482, 0.31034482,\n",
       "            0.31896552, 0.31896552, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.33620688, 0.33620688, 0.33620688, 0.3448276 , 0.3448276 ,\n",
       "            0.3448276 , 0.35344827, 0.35344827, 0.35344827, 0.35344827,\n",
       "            0.35344827, 0.35344827, 0.35344827, 0.35344827, 0.36206895,\n",
       "            0.36206895, 0.36206895, 0.36206895, 0.36206895, 0.36206895,\n",
       "            0.36206895, 0.36206895, 0.37068966, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.37931034, 0.37931034, 0.37931034, 0.37931034,\n",
       "            0.38793105, 0.38793105, 0.38793105, 0.38793105, 0.39655173,\n",
       "            0.39655173, 0.39655173, 0.4051724 , 0.4051724 , 0.4051724 ,\n",
       "            0.4051724 , 0.41379312, 0.41379312, 0.41379312, 0.41379312,\n",
       "            0.41379312, 0.41379312, 0.41379312, 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43103448, 0.43103448,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43965518, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.46551725, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.5086207 , 0.5258621 , 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.6034483 , 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4548, 0.449 , 0.4453, 0.445 , 0.4438, 0.441 , 0.4387,\n",
       "            0.4373, 0.437 , 0.4316, 0.4307, 0.4272, 0.4246, 0.4207, 0.4202,\n",
       "            0.419 , 0.4165, 0.4133, 0.413 , 0.4097, 0.4094, 0.4087, 0.4048,\n",
       "            0.4038, 0.4026, 0.3982, 0.3977, 0.3953, 0.393 , 0.3926, 0.39  ,\n",
       "            0.3896, 0.3894, 0.3887, 0.3865, 0.3848, 0.384 , 0.381 , 0.3782,\n",
       "            0.3777, 0.3767, 0.3765, 0.3762, 0.376 , 0.3752, 0.3748, 0.3745,\n",
       "            0.3738, 0.3733, 0.373 , 0.3728, 0.3726, 0.3723, 0.372 , 0.3716,\n",
       "            0.371 , 0.3706, 0.3704, 0.37  , 0.3699, 0.3691, 0.3684, 0.3674,\n",
       "            0.367 , 0.3667, 0.3652, 0.3647, 0.3638, 0.3635, 0.3633, 0.363 ,\n",
       "            0.3625, 0.3618, 0.3616, 0.3608, 0.3606, 0.3599, 0.359 , 0.3584,\n",
       "            0.3552, 0.355 , 0.3542, 0.3538, 0.3533, 0.3518, 0.3516, 0.3513,\n",
       "            0.3496, 0.3486, 0.348 , 0.3474, 0.344 , 0.3425, 0.3423, 0.3418,\n",
       "            0.3413, 0.341 , 0.3386, 0.338 , 0.3372, 0.336 , 0.3352, 0.3345,\n",
       "            0.3308, 0.3276, 0.3247, 0.324 , 0.3232, 0.321 , 0.32  , 0.3196,\n",
       "            0.3193, 0.3176, 0.315 , 0.3142, 0.313 , 0.3123, 0.3118, 0.3103,\n",
       "            0.3074, 0.3064, 0.3062, 0.305 , 0.3015, 0.2998, 0.2993, 0.2974,\n",
       "            0.2969, 0.2964, 0.2957, 0.2932, 0.2917, 0.2903, 0.29  , 0.289 ,\n",
       "            0.2886, 0.2883, 0.2874, 0.287 , 0.2864, 0.2861, 0.2847, 0.2842,\n",
       "            0.284 , 0.2837, 0.2832, 0.283 , 0.282 , 0.2788, 0.2783, 0.278 ,\n",
       "            0.2776, 0.2769, 0.2766, 0.2764, 0.276 , 0.2756, 0.2751, 0.275 ,\n",
       "            0.2742, 0.2737, 0.2734, 0.2727, 0.271 , 0.2708, 0.2695, 0.2693,\n",
       "            0.2688, 0.2686, 0.2664, 0.2654, 0.265 , 0.2644, 0.2642, 0.263 ,\n",
       "            0.2625, 0.2622, 0.2615, 0.2607, 0.2605, 0.2595, 0.2588, 0.2585,\n",
       "            0.2583, 0.2554, 0.255 , 0.2546, 0.2544, 0.2534, 0.2532, 0.2522,\n",
       "            0.2502, 0.2498, 0.2471, 0.2458, 0.2456, 0.2452, 0.2448, 0.243 ,\n",
       "            0.2428, 0.2413, 0.2382, 0.2352, 0.2339, 0.2332, 0.2327, 0.2297,\n",
       "            0.2289, 0.2283, 0.2235, 0.2198, 0.2189, 0.2184, 0.2163, 0.2158,\n",
       "            0.2147, 0.213 , 0.209 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.03448276, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.1119403 , 0.12686567, 0.13432837, 0.14179105, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.2761194 , 0.2835821 , 0.30597016, 0.31343284,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.69402987, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.76865673, 0.7835821 , 0.7835821 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.80597013, 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9029851 , 0.9104478 ,\n",
       "            0.9104478 , 0.91791046, 0.91791046, 0.91791046, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.9477612 , 0.95522386,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 0.9925373 , 0.9925373 , 0.9925373 , 0.9925373 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.39655173, 0.39655173, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.41379312, 0.41379312, 0.41379312, 0.41379312, 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.43103448, 0.43103448,\n",
       "            0.43965518, 0.43965518, 0.43965518, 0.43965518, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.43965518, 0.44827586, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.44827586, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.44827586, 0.45689654,\n",
       "            0.45689654, 0.45689654, 0.45689654, 0.45689654, 0.45689654,\n",
       "            0.46551725, 0.46551725, 0.46551725, 0.46551725, 0.46551725,\n",
       "            0.46551725, 0.46551725, 0.46551725, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5       , 0.5086207 , 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5258621 , 0.5258621 , 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.67241377, 0.67241377, 0.67241377, 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7155172 , 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.524 , 0.5117, 0.51  , 0.5054, 0.4973, 0.4963, 0.496 ,\n",
       "            0.4958, 0.4912, 0.491 , 0.484 , 0.4797, 0.4766, 0.4758, 0.474 ,\n",
       "            0.4731, 0.4727, 0.4612, 0.46  , 0.4592, 0.4573, 0.457 , 0.454 ,\n",
       "            0.4539, 0.4514, 0.4512, 0.4487, 0.4475, 0.4473, 0.4468, 0.446 ,\n",
       "            0.4438, 0.4436, 0.4385, 0.4326, 0.4304, 0.4297, 0.4287, 0.427 ,\n",
       "            0.426 , 0.4233, 0.419 , 0.4163, 0.4146, 0.41  , 0.4075, 0.4055,\n",
       "            0.4028, 0.4023, 0.402 , 0.4001, 0.3975, 0.3967, 0.395 , 0.3943,\n",
       "            0.3926, 0.3914, 0.3904, 0.388 , 0.387 , 0.3862, 0.3853, 0.385 ,\n",
       "            0.3848, 0.383 , 0.3823, 0.382 , 0.381 , 0.3806, 0.38  , 0.3796,\n",
       "            0.3784, 0.378 , 0.3774, 0.3772, 0.3767, 0.3757, 0.3755, 0.3743,\n",
       "            0.3738, 0.3718, 0.3716, 0.3684, 0.3674, 0.3672, 0.367 , 0.3667,\n",
       "            0.365 , 0.3638, 0.3635, 0.3633, 0.361 , 0.3599, 0.3591, 0.359 ,\n",
       "            0.3584, 0.3582, 0.3574, 0.3552, 0.3535, 0.3528, 0.351 , 0.35  ,\n",
       "            0.3489, 0.3486, 0.3484, 0.348 , 0.3477, 0.3464, 0.3442, 0.343 ,\n",
       "            0.3425, 0.3413, 0.3408, 0.3403, 0.339 , 0.3389, 0.3386, 0.3381,\n",
       "            0.3376, 0.337 , 0.3364, 0.3352, 0.3347, 0.3345, 0.3342, 0.3335,\n",
       "            0.3325, 0.3318, 0.33  , 0.3298, 0.3296, 0.3293, 0.329 , 0.3289,\n",
       "            0.3286, 0.3271, 0.327 , 0.3267, 0.3264, 0.3254, 0.3245, 0.324 ,\n",
       "            0.3232, 0.323 , 0.3228, 0.3215, 0.3203, 0.32  , 0.3198, 0.3196,\n",
       "            0.3193, 0.3186, 0.3184, 0.3179, 0.3174, 0.3171, 0.317 , 0.3157,\n",
       "            0.3152, 0.3147, 0.3145, 0.3142, 0.314 , 0.3132, 0.313 , 0.3125,\n",
       "            0.3115, 0.3113, 0.3108, 0.31  , 0.3096, 0.3093, 0.309 , 0.3086,\n",
       "            0.3083, 0.3079, 0.307 , 0.3064, 0.3062, 0.3047, 0.3042, 0.3035,\n",
       "            0.3032, 0.3025, 0.3022, 0.302 , 0.3018, 0.3003, 0.3   , 0.2986,\n",
       "            0.2976, 0.293 , 0.2922, 0.2917, 0.2915, 0.2908, 0.2883, 0.2874,\n",
       "            0.2861, 0.286 , 0.2832, 0.2822, 0.2817, 0.2795, 0.2793, 0.279 ,\n",
       "            0.2717, 0.2698, 0.269 , 0.2666], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.31896552, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.13432837, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.18656716, 0.20149253,\n",
       "            0.21641791, 0.2238806 , 0.2238806 , 0.24626866, 0.24626866,\n",
       "            0.25373134, 0.26865673, 0.29104477, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.37313432, 0.37313432, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.47761193, 0.47761193, 0.48507464, 0.49253732, 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5970149 , 0.5970149 , 0.6044776 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6641791 , 0.6641791 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.69402987, 0.7089552 ,\n",
       "            0.7238806 , 0.73134327, 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.8208955 , 0.8208955 , 0.82835823, 0.82835823,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.8507463 , 0.85820895, 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9029851 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.2672414 ,\n",
       "            0.27586207, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.45689654, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.47413793, 0.47413793,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5       , 0.5086207 , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5603448 , 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.5689655 , 0.57758623, 0.5948276 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6551724 , 0.6551724 , 0.6551724 , 0.6637931 , 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.7241379 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7758621 , 0.79310346, 0.79310346, 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.86206895, 0.86206895, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5996, 0.592 , 0.584 , 0.5776, 0.5723, 0.57  , 0.568 ,\n",
       "            0.5674, 0.565 , 0.563 , 0.56  , 0.558 , 0.5527, 0.5444, 0.544 ,\n",
       "            0.533 , 0.532 , 0.529 , 0.5273, 0.5264, 0.52  , 0.519 , 0.518 ,\n",
       "            0.515 , 0.5137, 0.512 , 0.511 , 0.51  , 0.5093, 0.508 , 0.5073,\n",
       "            0.505 , 0.504 , 0.502 , 0.5   , 0.4998, 0.4976, 0.4941, 0.492 ,\n",
       "            0.4895, 0.4858, 0.4722, 0.4653, 0.462 , 0.46  , 0.4563, 0.4539,\n",
       "            0.4492, 0.4456, 0.443 , 0.441 , 0.439 , 0.4373, 0.4333, 0.4329,\n",
       "            0.4326, 0.424 , 0.422 , 0.4219, 0.4202, 0.4187, 0.4185, 0.4177,\n",
       "            0.4143, 0.413 , 0.4124, 0.4104, 0.4087, 0.4082, 0.4062, 0.404 ,\n",
       "            0.4036, 0.4033, 0.403 , 0.402 , 0.4014, 0.4011, 0.4001, 0.4   ,\n",
       "            0.3992, 0.399 , 0.3975, 0.3965, 0.396 , 0.3958, 0.3955, 0.3953,\n",
       "            0.395 , 0.3943, 0.394 , 0.3936, 0.3926, 0.3923, 0.392 , 0.391 ,\n",
       "            0.3909, 0.3906, 0.3901, 0.3892, 0.3887, 0.3884, 0.3872, 0.387 ,\n",
       "            0.3867, 0.3865, 0.386 , 0.3853, 0.385 , 0.3848, 0.3845, 0.3843,\n",
       "            0.3838, 0.3835, 0.3833, 0.3823, 0.382 , 0.3816, 0.381 , 0.3804,\n",
       "            0.3796, 0.3792, 0.379 , 0.3787, 0.3784, 0.3782, 0.378 , 0.3777,\n",
       "            0.3762, 0.376 , 0.3757, 0.3755, 0.3752, 0.375 , 0.374 , 0.3733,\n",
       "            0.373 , 0.372 , 0.3718, 0.371 , 0.3704, 0.37  , 0.3699, 0.3694,\n",
       "            0.369 , 0.3684, 0.3682, 0.3677, 0.3674, 0.3662, 0.366 , 0.3657,\n",
       "            0.3655, 0.3652, 0.3645, 0.3635, 0.3633, 0.3628, 0.3625, 0.361 ,\n",
       "            0.3608, 0.36  , 0.359 , 0.3584, 0.3577, 0.3564, 0.3557, 0.3547,\n",
       "            0.354 , 0.3538, 0.3535, 0.3528, 0.3523, 0.3518, 0.3508, 0.3503,\n",
       "            0.3496, 0.3472, 0.3447, 0.343 , 0.342 , 0.341 , 0.3398, 0.3374,\n",
       "            0.336 , 0.3352, 0.3335, 0.3298, 0.3264, 0.3235, 0.3186, 0.311 ,\n",
       "            0.31  , 0.3088, 0.3083, 0.3022, 0.2751], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.43965518, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.1716418 , 0.18656716, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.2835821 , 0.2835821 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.29850745, 0.30597016, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.36567163,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3880597 , 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5074627 , 0.5298507 ,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.6492537 , 0.6567164 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.70149255, 0.70149255, 0.7089552 , 0.7164179 , 0.7164179 ,\n",
       "            0.7164179 , 0.7164179 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25862068, 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.49137932, 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.5603448 , 0.57758623, 0.57758623, 0.5948276 ,\n",
       "            0.6034483 , 0.62068963, 0.62931037, 0.6465517 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.6896552 , 0.70689654, 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.79310346, 0.8103448 , 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.672 , 0.669 , 0.6685, 0.659 , 0.651 , 0.649 , 0.6445,\n",
       "            0.6406, 0.638 , 0.637 , 0.629 , 0.62  , 0.6104, 0.6064, 0.606 ,\n",
       "            0.6045, 0.604 , 0.598 , 0.596 , 0.594 , 0.5903, 0.586 , 0.585 ,\n",
       "            0.583 , 0.582 , 0.581 , 0.5757, 0.572 , 0.57  , 0.5693, 0.568 ,\n",
       "            0.5664, 0.5645, 0.5615, 0.56  , 0.559 , 0.554 , 0.5522, 0.5503,\n",
       "            0.546 , 0.5312, 0.529 , 0.523 , 0.521 , 0.52  , 0.5156, 0.5137,\n",
       "            0.491 , 0.49  , 0.4832, 0.4795, 0.4792, 0.479 , 0.4785, 0.473 ,\n",
       "            0.4714, 0.4707, 0.4644, 0.462 , 0.4617, 0.461 , 0.4607, 0.46  ,\n",
       "            0.4597, 0.4595, 0.4585, 0.458 , 0.4575, 0.4568, 0.4565, 0.456 ,\n",
       "            0.4558, 0.4556, 0.4553, 0.455 , 0.4548, 0.4546, 0.4543, 0.454 ,\n",
       "            0.4539, 0.4536, 0.4534, 0.4526, 0.4524, 0.4521, 0.452 , 0.451 ,\n",
       "            0.45  , 0.449 , 0.4465, 0.4456, 0.4448, 0.444 , 0.443 , 0.4426,\n",
       "            0.4421, 0.4412, 0.4397, 0.4387, 0.4373, 0.437 , 0.4365, 0.4363,\n",
       "            0.436 , 0.4358, 0.4348, 0.4343, 0.4338, 0.4326, 0.4321, 0.4294,\n",
       "            0.4292, 0.429 , 0.4287, 0.428 , 0.4255, 0.425 , 0.424 , 0.4238,\n",
       "            0.4226, 0.4219, 0.4204, 0.4202, 0.4194, 0.4185, 0.4182, 0.418 ,\n",
       "            0.4165, 0.4155, 0.4148, 0.4143, 0.414 , 0.4138, 0.413 , 0.4124,\n",
       "            0.4104, 0.4102, 0.4077, 0.4072, 0.407 , 0.4067, 0.4058, 0.4053,\n",
       "            0.4048, 0.4038, 0.4036, 0.402 , 0.4001, 0.3984, 0.3972, 0.397 ,\n",
       "            0.393 , 0.3909, 0.3896, 0.3853, 0.3826, 0.3823, 0.382 , 0.3816,\n",
       "            0.3796, 0.3772, 0.3767, 0.3726, 0.371 , 0.3708, 0.3704, 0.3684,\n",
       "            0.3667, 0.3662, 0.3604, 0.3582, 0.3562, 0.3552, 0.3547, 0.35  ,\n",
       "            0.348 , 0.337 , 0.3337, 0.3313, 0.3308, 0.3237, 0.3235, 0.315 ,\n",
       "            0.3093, 0.3062, 0.3037, 0.3035, 0.2993, 0.2703], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.29850745, dtype=float32),\n",
       "    'tpr': array(0.7758621, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.15671642,\n",
       "            0.15671642, 0.1716418 , 0.17910448, 0.17910448, 0.17910448,\n",
       "            0.19402985, 0.21641791, 0.2238806 , 0.23880596, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.26865673, 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.31343284, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3955224 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.54477614, 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.619403  , 0.6268657 , 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.49137932, 0.49137932, 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.7586207 , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7373, 0.7334, 0.732 , 0.731 , 0.7217, 0.7163, 0.704 ,\n",
       "            0.7007, 0.7   , 0.6973, 0.6943, 0.685 , 0.675 , 0.674 , 0.672 ,\n",
       "            0.6675, 0.6616, 0.6606, 0.66  , 0.6597, 0.6567, 0.648 , 0.6475,\n",
       "            0.6455, 0.6436, 0.642 , 0.634 , 0.6333, 0.6304, 0.627 , 0.625 ,\n",
       "            0.6245, 0.6206, 0.616 , 0.615 , 0.61  , 0.605 , 0.6045, 0.6   ,\n",
       "            0.5996, 0.5977, 0.596 , 0.588 , 0.578 , 0.5776, 0.572 , 0.5674,\n",
       "            0.565 , 0.5605, 0.5547, 0.543 , 0.542 , 0.539 , 0.536 , 0.5337,\n",
       "            0.5327, 0.5317, 0.5312, 0.531 , 0.5303, 0.53  , 0.5293, 0.5273,\n",
       "            0.527 , 0.5264, 0.5254, 0.525 , 0.5244, 0.5234, 0.5225, 0.522 ,\n",
       "            0.5215, 0.521 , 0.5205, 0.52  , 0.5195, 0.519 , 0.5186, 0.518 ,\n",
       "            0.5166, 0.5156, 0.5146, 0.514 , 0.5137, 0.513 , 0.5127, 0.512 ,\n",
       "            0.5107, 0.5103, 0.51  , 0.5063, 0.506 , 0.505 , 0.5044, 0.504 ,\n",
       "            0.502 , 0.5005, 0.4998, 0.4993, 0.4983, 0.4976, 0.4973, 0.4966,\n",
       "            0.4949, 0.494 , 0.4932, 0.4927, 0.4922, 0.4917, 0.4915, 0.4905,\n",
       "            0.49  , 0.4895, 0.489 , 0.4878, 0.486 , 0.485 , 0.4846, 0.482 ,\n",
       "            0.4814, 0.4812, 0.4805, 0.4778, 0.4768, 0.476 , 0.4746, 0.474 ,\n",
       "            0.4736, 0.4734, 0.4712, 0.4695, 0.469 , 0.4675, 0.4636, 0.4614,\n",
       "            0.4612, 0.459 , 0.4587, 0.4585, 0.4583, 0.458 , 0.4558, 0.4556,\n",
       "            0.4553, 0.4536, 0.4526, 0.4521, 0.4478, 0.4473, 0.4468, 0.4463,\n",
       "            0.445 , 0.4412, 0.4402, 0.4387, 0.4358, 0.4333, 0.4326, 0.4324,\n",
       "            0.431 , 0.429 , 0.4272, 0.4255, 0.425 , 0.4238, 0.4229, 0.4194,\n",
       "            0.4192, 0.419 , 0.4172, 0.417 , 0.4136, 0.4094, 0.4016, 0.4   ,\n",
       "            0.3958, 0.3896, 0.388 , 0.3872, 0.387 , 0.3853, 0.3848, 0.3816,\n",
       "            0.3757, 0.374 , 0.3735, 0.373 , 0.371 , 0.3696, 0.3655, 0.3638,\n",
       "            0.3591, 0.3584, 0.3567, 0.352 , 0.3506, 0.3367, 0.332 , 0.3315,\n",
       "            0.3298, 0.324 , 0.3208, 0.3115, 0.3079, 0.3044, 0.299 , 0.2983,\n",
       "            0.2969, 0.2659], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.46268657, dtype=float32),\n",
       "    'tpr': array(0.94827586, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.10447761, 0.1119403 ,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14179105, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.18656716,\n",
       "            0.20149253, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.2238806 , 0.23880596, 0.24626866, 0.25373134, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.38059703, 0.3955224 ,\n",
       "            0.40298507, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.43965518, 0.43965518, 0.44827586, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5086207 , 0.5086207 , 0.5086207 , 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5689655 ,\n",
       "            0.5689655 , 0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.62068963, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.67241377, 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7915, 0.791 , 0.782 , 0.7783, 0.778 , 0.7705, 0.7573,\n",
       "            0.749 , 0.7476, 0.747 , 0.7407, 0.7324, 0.732 , 0.727 , 0.722 ,\n",
       "            0.7197, 0.7188, 0.7183, 0.7173, 0.7046, 0.703 , 0.7017, 0.694 ,\n",
       "            0.6934, 0.693 , 0.688 , 0.686 , 0.6855, 0.684 , 0.6797, 0.674 ,\n",
       "            0.672 , 0.6714, 0.665 , 0.6587, 0.658 , 0.6543, 0.6484, 0.647 ,\n",
       "            0.6455, 0.6436, 0.641 , 0.6396, 0.6333, 0.6294, 0.6274, 0.624 ,\n",
       "            0.62  , 0.616 , 0.6147, 0.612 , 0.608 , 0.6074, 0.607 , 0.605 ,\n",
       "            0.6016, 0.601 , 0.6   , 0.599 , 0.5986, 0.5977, 0.596 , 0.5957,\n",
       "            0.595 , 0.594 , 0.592 , 0.588 , 0.587 , 0.5864, 0.5854, 0.585 ,\n",
       "            0.5845, 0.5835, 0.583 , 0.582 , 0.5815, 0.581 , 0.58  , 0.5786,\n",
       "            0.5776, 0.5767, 0.5757, 0.575 , 0.5747, 0.574 , 0.573 , 0.5728,\n",
       "            0.571 , 0.5684, 0.567 , 0.5664, 0.566 , 0.565 , 0.5645, 0.564 ,\n",
       "            0.5625, 0.562 , 0.561 , 0.56  , 0.5596, 0.5576, 0.556 , 0.555 ,\n",
       "            0.5537, 0.553 , 0.5522, 0.552 , 0.5493, 0.5474, 0.5464, 0.5454,\n",
       "            0.545 , 0.5435, 0.543 , 0.5425, 0.542 , 0.5415, 0.541 , 0.538 ,\n",
       "            0.5376, 0.5366, 0.536 , 0.533 , 0.5327, 0.5312, 0.531 , 0.5273,\n",
       "            0.526 , 0.5244, 0.522 , 0.52  , 0.519 , 0.5186, 0.518 , 0.5156,\n",
       "            0.5137, 0.5073, 0.5034, 0.503 , 0.5015, 0.4998, 0.498 , 0.4978,\n",
       "            0.497 , 0.4968, 0.4958, 0.4956, 0.4915, 0.4905, 0.4895, 0.4836,\n",
       "            0.4834, 0.482 , 0.479 , 0.4785, 0.4768, 0.4746, 0.471 , 0.4697,\n",
       "            0.469 , 0.4688, 0.4631, 0.4612, 0.4502, 0.4495, 0.446 , 0.4456,\n",
       "            0.442 , 0.4397, 0.439 , 0.4373, 0.4368, 0.4363, 0.4346, 0.4314,\n",
       "            0.4307, 0.4304, 0.4292, 0.4275, 0.424 , 0.4182, 0.4116, 0.4065,\n",
       "            0.4014, 0.3967, 0.3938, 0.3928, 0.3923, 0.3916, 0.3906, 0.3857,\n",
       "            0.3804, 0.379 , 0.3772, 0.3765, 0.375 , 0.373 , 0.3704, 0.369 ,\n",
       "            0.3628, 0.3606, 0.359 , 0.3557, 0.3516, 0.3367, 0.3328, 0.3308,\n",
       "            0.3286, 0.3242, 0.3188, 0.309 , 0.3066, 0.303 , 0.2954, 0.2947,\n",
       "            0.2944, 0.2622], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5298507, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14179105, 0.14179105,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.15671642, 0.15671642,\n",
       "            0.1716418 , 0.17910448, 0.17910448, 0.18656716, 0.18656716,\n",
       "            0.18656716, 0.19402985, 0.19402985, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.2835821 , 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.3283582 , 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.35820895, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3955224 , 0.41044775, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.38793105,\n",
       "            0.39655173, 0.39655173, 0.4051724 , 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.4827586 , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.55172414, 0.5603448 , 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.62068963, 0.63793105,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 ,\n",
       "            0.7413793 , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.7758621 , 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.835 , 0.832 , 0.821 , 0.816 , 0.8125, 0.7993, 0.7886,\n",
       "            0.787 , 0.785 , 0.7783, 0.777 , 0.7715, 0.771 , 0.7705, 0.7646,\n",
       "            0.762 , 0.7617, 0.756 , 0.75  , 0.739 , 0.7383, 0.735 , 0.733 ,\n",
       "            0.7314, 0.7295, 0.7256, 0.7246, 0.7197, 0.7134, 0.7104, 0.709 ,\n",
       "            0.7075, 0.703 , 0.6987, 0.695 , 0.6943, 0.6914, 0.6865, 0.6846,\n",
       "            0.681 , 0.6807, 0.68  , 0.6763, 0.6753, 0.673 , 0.6704, 0.67  ,\n",
       "            0.6694, 0.6685, 0.6655, 0.665 , 0.6587, 0.6562, 0.656 , 0.6543,\n",
       "            0.654 , 0.6514, 0.6504, 0.6484, 0.648 , 0.6475, 0.647 , 0.6465,\n",
       "            0.6406, 0.6396, 0.639 , 0.6387, 0.6377, 0.636 , 0.6357, 0.6343,\n",
       "            0.632 , 0.6313, 0.631 , 0.6304, 0.63  , 0.629 , 0.628 , 0.6274,\n",
       "            0.627 , 0.6265, 0.625 , 0.6245, 0.623 , 0.6226, 0.622 , 0.621 ,\n",
       "            0.6196, 0.617 , 0.6167, 0.616 , 0.615 , 0.614 , 0.6123, 0.6113,\n",
       "            0.611 , 0.61  , 0.6094, 0.6084, 0.6074, 0.607 , 0.605 , 0.6045,\n",
       "            0.603 , 0.6025, 0.6006, 0.5996, 0.5977, 0.5957, 0.594 , 0.5938,\n",
       "            0.5933, 0.5923, 0.592 , 0.5913, 0.5884, 0.588 , 0.587 , 0.586 ,\n",
       "            0.5854, 0.5825, 0.5767, 0.575 , 0.5747, 0.5728, 0.571 , 0.57  ,\n",
       "            0.5684, 0.5674, 0.5654, 0.56  , 0.559 , 0.556 , 0.5557, 0.552 ,\n",
       "            0.547 , 0.546 , 0.544 , 0.5435, 0.542 , 0.5386, 0.538 , 0.535 ,\n",
       "            0.5337, 0.532 , 0.5303, 0.53  , 0.529 , 0.523 , 0.52  , 0.516 ,\n",
       "            0.515 , 0.508 , 0.502 , 0.4995, 0.4966, 0.4946, 0.494 , 0.489 ,\n",
       "            0.4856, 0.4822, 0.478 , 0.4646, 0.4636, 0.4583, 0.4578, 0.4539,\n",
       "            0.451 , 0.45  , 0.4485, 0.4478, 0.4475, 0.4456, 0.4426, 0.442 ,\n",
       "            0.4414, 0.4404, 0.4368, 0.4338, 0.4265, 0.4204, 0.413 , 0.4072,\n",
       "            0.4028, 0.3994, 0.3987, 0.3982, 0.3962, 0.3958, 0.3901, 0.3848,\n",
       "            0.3823, 0.3809, 0.3806, 0.3796, 0.3784, 0.3765, 0.3745, 0.3733,\n",
       "            0.366 , 0.3625, 0.3606, 0.359 , 0.3525, 0.3367, 0.3333, 0.3298,\n",
       "            0.3276, 0.3242, 0.317 , 0.3066, 0.305 , 0.3013, 0.2925, 0.292 ,\n",
       "            0.2905, 0.2585], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.58208954, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14179105,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1641791 , 0.1641791 , 0.1716418 , 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.18656716, 0.18656716, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23134328, 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.2835821 , 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.3283582 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.5344828 , 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.873 , 0.869 , 0.86  , 0.8564, 0.8506, 0.838 , 0.8257,\n",
       "            0.8247, 0.821 , 0.819 , 0.8174, 0.8145, 0.8125, 0.8086, 0.807 ,\n",
       "            0.8037, 0.8022, 0.794 , 0.792 , 0.776 , 0.7754, 0.775 , 0.774 ,\n",
       "            0.772 , 0.769 , 0.7686, 0.7656, 0.758 , 0.7544, 0.753 , 0.7495,\n",
       "            0.7476, 0.747 , 0.743 , 0.741 , 0.737 , 0.732 , 0.731 , 0.73  ,\n",
       "            0.7295, 0.729 , 0.7266, 0.719 , 0.7163, 0.716 , 0.7144, 0.714 ,\n",
       "            0.713 , 0.7114, 0.7095, 0.708 , 0.706 , 0.7056, 0.705 , 0.7046,\n",
       "            0.7036, 0.702 , 0.7017, 0.698 , 0.695 , 0.6943, 0.694 , 0.6934,\n",
       "            0.6924, 0.692 , 0.6914, 0.6895, 0.689 , 0.6875, 0.6846, 0.681 ,\n",
       "            0.6807, 0.68  , 0.6797, 0.6787, 0.678 , 0.6777, 0.676 , 0.6753,\n",
       "            0.675 , 0.6733, 0.673 , 0.6724, 0.6714, 0.6704, 0.6694, 0.669 ,\n",
       "            0.6685, 0.667 , 0.6655, 0.665 , 0.6646, 0.6626, 0.662 , 0.66  ,\n",
       "            0.659 , 0.658 , 0.657 , 0.656 , 0.6553, 0.655 , 0.6543, 0.654 ,\n",
       "            0.6514, 0.65  , 0.6494, 0.649 , 0.6455, 0.642 , 0.6416, 0.6406,\n",
       "            0.6367, 0.636 , 0.6353, 0.6343, 0.634 , 0.6333, 0.633 , 0.6323,\n",
       "            0.63  , 0.622 , 0.621 , 0.6206, 0.6196, 0.618 , 0.61  , 0.606 ,\n",
       "            0.6045, 0.603 , 0.602 , 0.6006, 0.5957, 0.5938, 0.593 , 0.5923,\n",
       "            0.59  , 0.588 , 0.5874, 0.5864, 0.5815, 0.5806, 0.579 , 0.578 ,\n",
       "            0.572 , 0.571 , 0.57  , 0.569 , 0.565 , 0.5645, 0.5576, 0.5405,\n",
       "            0.538 , 0.536 , 0.5303, 0.5264, 0.522 , 0.5166, 0.513 , 0.512 ,\n",
       "            0.5107, 0.505 , 0.5034, 0.495 , 0.4805, 0.4783, 0.472 , 0.471 ,\n",
       "            0.4668, 0.4636, 0.4622, 0.461 , 0.4604, 0.4595, 0.4585, 0.4558,\n",
       "            0.4536, 0.4534, 0.4475, 0.445 , 0.4355, 0.4314, 0.4202, 0.4133,\n",
       "            0.4106, 0.4072, 0.406 , 0.4043, 0.4019, 0.4014, 0.395 , 0.39  ,\n",
       "            0.3862, 0.3855, 0.3843, 0.3833, 0.3828, 0.3806, 0.3804, 0.3792,\n",
       "            0.3704, 0.3652, 0.3635, 0.3538, 0.3374, 0.3352, 0.3293, 0.3271,\n",
       "            0.3252, 0.3157, 0.3047, 0.3044, 0.3005, 0.291 , 0.2888, 0.2869,\n",
       "            0.2556], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5895522, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.11940298, 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.19402985, 0.19402985, 0.19402985, 0.19402985,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.38059703, 0.3955224 ,\n",
       "            0.3955224 , 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31034482, 0.31896552, 0.31896552, 0.31896552, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.38793105, 0.4051724 ,\n",
       "            0.41379312, 0.41379312, 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.54310346, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.63793105, 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.8189655 , 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9   , 0.895 , 0.887 , 0.883 , 0.878 , 0.8765, 0.866 ,\n",
       "            0.854 , 0.8535, 0.8516, 0.8506, 0.8486, 0.8438, 0.843 , 0.8413,\n",
       "            0.8354, 0.833 , 0.8267, 0.821 , 0.8096, 0.8066, 0.806 , 0.8047,\n",
       "            0.8027, 0.8022, 0.799 , 0.7974, 0.795 , 0.7905, 0.786 , 0.785 ,\n",
       "            0.784 , 0.7827, 0.781 , 0.7793, 0.7734, 0.773 , 0.7725, 0.772 ,\n",
       "            0.7617, 0.7607, 0.7603, 0.7583, 0.7554, 0.755 , 0.753 , 0.7515,\n",
       "            0.751 , 0.75  , 0.7495, 0.749 , 0.747 , 0.746 , 0.7456, 0.745 ,\n",
       "            0.744 , 0.7427, 0.7407, 0.738 , 0.7363, 0.735 , 0.734 , 0.733 ,\n",
       "            0.7324, 0.732 , 0.7314, 0.7295, 0.729 , 0.7285, 0.727 , 0.7266,\n",
       "            0.726 , 0.724 , 0.721 , 0.72  , 0.719 , 0.7183, 0.7173, 0.717 ,\n",
       "            0.7163, 0.716 , 0.7153, 0.714 , 0.7134, 0.712 , 0.711 , 0.7104,\n",
       "            0.709 , 0.707 , 0.7065, 0.705 , 0.704 , 0.7026, 0.702 , 0.7017,\n",
       "            0.701 , 0.6987, 0.698 , 0.697 , 0.696 , 0.6953, 0.695 , 0.693 ,\n",
       "            0.6914, 0.691 , 0.6904, 0.6895, 0.6885, 0.6865, 0.6846, 0.6836,\n",
       "            0.68  , 0.679 , 0.6777, 0.6724, 0.672 , 0.6714, 0.671 , 0.6704,\n",
       "            0.67  , 0.6694, 0.6685, 0.6626, 0.662 , 0.6597, 0.658 , 0.6562,\n",
       "            0.656 , 0.655 , 0.6533, 0.6445, 0.636 , 0.635 , 0.6333, 0.6323,\n",
       "            0.628 , 0.627 , 0.6265, 0.622 , 0.6177, 0.6167, 0.615 , 0.6147,\n",
       "            0.6104, 0.61  , 0.609 , 0.604 , 0.602 , 0.601 , 0.6006, 0.5967,\n",
       "            0.596 , 0.594 , 0.5933, 0.59  , 0.5596, 0.559 , 0.557 , 0.5547,\n",
       "            0.5503, 0.5396, 0.5337, 0.5303, 0.5293, 0.529 , 0.5234, 0.52  ,\n",
       "            0.5107, 0.4934, 0.491 , 0.4841, 0.483 , 0.4783, 0.4756, 0.473 ,\n",
       "            0.471 , 0.4705, 0.4702, 0.4688, 0.4663, 0.4639, 0.4634, 0.4573,\n",
       "            0.4558, 0.4434, 0.4424, 0.4263, 0.4187, 0.4177, 0.416 , 0.412 ,\n",
       "            0.4104, 0.4075, 0.406 , 0.3994, 0.395 , 0.3901, 0.3894, 0.3875,\n",
       "            0.3872, 0.3865, 0.3862, 0.3857, 0.3845, 0.3752, 0.369 , 0.3684,\n",
       "            0.3665, 0.3555, 0.3386, 0.3374, 0.329 , 0.3271, 0.3267, 0.315 ,\n",
       "            0.3047, 0.3035, 0.3005, 0.2903, 0.2864, 0.284 , 0.254 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6044776, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.11940298, 0.11940298, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23880596, 0.23880596, 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3283582 , 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.27586207, 0.28448275, 0.29310346, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.49137932, 0.5       , 0.5086207 , 0.5086207 ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.54310346, 0.55172414, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.7241379 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8448276 , 0.8534483 , 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.923 , 0.917 , 0.911 , 0.906 , 0.902 , 0.899 , 0.8916,\n",
       "            0.8813, 0.879 , 0.8784, 0.8735, 0.8716, 0.8706, 0.868 , 0.8643,\n",
       "            0.8613, 0.861 , 0.857 , 0.847 , 0.8403, 0.836 , 0.8354, 0.835 ,\n",
       "            0.834 , 0.8335, 0.832 , 0.8296, 0.829 , 0.827 , 0.8267, 0.8228,\n",
       "            0.821 , 0.8174, 0.817 , 0.816 , 0.8135, 0.8105, 0.8096, 0.801 ,\n",
       "            0.8003, 0.799 , 0.7983, 0.796 , 0.794 , 0.793 , 0.792 , 0.791 ,\n",
       "            0.7896, 0.789 , 0.788 , 0.7876, 0.7866, 0.785 , 0.7847, 0.7837,\n",
       "            0.78  , 0.7783, 0.777 , 0.7764, 0.775 , 0.7744, 0.774 , 0.7734,\n",
       "            0.773 , 0.772 , 0.771 , 0.7705, 0.77  , 0.769 , 0.768 , 0.765 ,\n",
       "            0.762 , 0.7617, 0.7603, 0.7593, 0.759 , 0.7573, 0.757 , 0.7563,\n",
       "            0.756 , 0.7544, 0.754 , 0.7534, 0.752 , 0.7515, 0.75  , 0.7485,\n",
       "            0.7466, 0.744 , 0.742 , 0.741 , 0.7407, 0.738 , 0.736 , 0.735 ,\n",
       "            0.7344, 0.7334, 0.733 , 0.73  , 0.7295, 0.7285, 0.728 , 0.7275,\n",
       "            0.722 , 0.721 , 0.7188, 0.718 , 0.715 , 0.7124, 0.712 , 0.7114,\n",
       "            0.711 , 0.7095, 0.708 , 0.707 , 0.706 , 0.699 , 0.6973, 0.696 ,\n",
       "            0.6953, 0.693 , 0.6904, 0.69  , 0.6836, 0.6772, 0.6743, 0.6733,\n",
       "            0.672 , 0.6685, 0.6636, 0.6626, 0.6616, 0.6597, 0.6567, 0.6543,\n",
       "            0.6523, 0.649 , 0.648 , 0.646 , 0.642 , 0.6396, 0.638 , 0.636 ,\n",
       "            0.6357, 0.635 , 0.63  , 0.628 , 0.6255, 0.619 , 0.586 , 0.584 ,\n",
       "            0.5796, 0.579 , 0.5786, 0.559 , 0.5537, 0.5503, 0.5493, 0.5474,\n",
       "            0.546 , 0.5386, 0.529 , 0.5103, 0.5063, 0.4988, 0.4973, 0.4927,\n",
       "            0.4897, 0.4873, 0.486 , 0.4841, 0.484 , 0.4836, 0.4834, 0.481 ,\n",
       "            0.4775, 0.4768, 0.4695, 0.4688, 0.4553, 0.4543, 0.4355, 0.4272,\n",
       "            0.4268, 0.421 , 0.4187, 0.4158, 0.4136, 0.4067, 0.4023, 0.3972,\n",
       "            0.3962, 0.3948, 0.3943, 0.394 , 0.3926, 0.391 , 0.382 , 0.3765,\n",
       "            0.374 , 0.3718, 0.3596, 0.3425, 0.342 , 0.3318, 0.3308, 0.3298,\n",
       "            0.317 , 0.3074, 0.305 , 0.303 , 0.2922, 0.287 , 0.2844, 0.2546],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.64179105, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20149253, 0.20149253,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.23880596, 0.23880596,\n",
       "            0.24626866, 0.26865673, 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.2835821 , 0.2835821 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.29850745, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3955224 , 0.3955224 ,\n",
       "            0.3955224 , 0.3955224 , 0.40298507, 0.41044775, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.09482758, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.35344827, 0.35344827, 0.35344827,\n",
       "            0.36206895, 0.37931034, 0.39655173, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.4224138 , 0.43103448, 0.43965518, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5       , 0.5086207 , 0.5086207 , 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6551724 , 0.6637931 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.70689654, 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.7241379 , 0.7241379 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7758621 , 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9404, 0.9346, 0.9297, 0.9243, 0.922 , 0.918 , 0.912 ,\n",
       "            0.906 , 0.9014, 0.9004, 0.895 , 0.8945, 0.8896, 0.888 , 0.8843,\n",
       "            0.8833, 0.8823, 0.8696, 0.8687, 0.8667, 0.8647, 0.861 , 0.8604,\n",
       "            0.86  , 0.8584, 0.856 , 0.8535, 0.853 , 0.852 , 0.8516, 0.851 ,\n",
       "            0.84  , 0.837 , 0.835 , 0.8345, 0.833 , 0.832 , 0.831 , 0.8296,\n",
       "            0.828 , 0.8267, 0.8257, 0.825 , 0.8247, 0.8237, 0.823 , 0.817 ,\n",
       "            0.8164, 0.816 , 0.8154, 0.8145, 0.813 , 0.8125, 0.811 , 0.8105,\n",
       "            0.81  , 0.8086, 0.8076, 0.807 , 0.806 , 0.805 , 0.804 , 0.8013,\n",
       "            0.8   , 0.7993, 0.799 , 0.7974, 0.797 , 0.7964, 0.795 , 0.7925,\n",
       "            0.792 , 0.7915, 0.79  , 0.7896, 0.7886, 0.788 , 0.7876, 0.787 ,\n",
       "            0.7837, 0.782 , 0.7817, 0.78  , 0.7783, 0.7773, 0.7764, 0.776 ,\n",
       "            0.7744, 0.773 , 0.7725, 0.7705, 0.7695, 0.769 , 0.768 , 0.7646,\n",
       "            0.764 , 0.7637, 0.7627, 0.762 , 0.7607, 0.76  , 0.7583, 0.7563,\n",
       "            0.755 , 0.753 , 0.7515, 0.7495, 0.749 , 0.7485, 0.747 , 0.746 ,\n",
       "            0.743 , 0.742 , 0.7393, 0.737 , 0.7334, 0.733 , 0.7314, 0.731 ,\n",
       "            0.7295, 0.724 , 0.722 , 0.7188, 0.7183, 0.717 , 0.709 , 0.7085,\n",
       "            0.706 , 0.698 , 0.6953, 0.6943, 0.692 , 0.691 , 0.686 , 0.6816,\n",
       "            0.68  , 0.6797, 0.679 , 0.6772, 0.677 , 0.6753, 0.6733, 0.672 ,\n",
       "            0.6685, 0.667 , 0.6665, 0.6606, 0.6597, 0.657 , 0.656 , 0.643 ,\n",
       "            0.612 , 0.6113, 0.6064, 0.5986, 0.598 , 0.578 , 0.5723, 0.571 ,\n",
       "            0.568 , 0.567 , 0.5635, 0.556 , 0.5454, 0.526 , 0.521 , 0.512 ,\n",
       "            0.5103, 0.506 , 0.503 , 0.5005, 0.4983, 0.497 , 0.4963, 0.496 ,\n",
       "            0.4958, 0.4937, 0.4902, 0.489 , 0.4807, 0.466 , 0.464 , 0.4438,\n",
       "            0.4353, 0.435 , 0.4287, 0.4263, 0.423 , 0.4202, 0.4128, 0.4084,\n",
       "            0.403 , 0.4016, 0.4011, 0.4004, 0.3997, 0.399 , 0.3977, 0.3965,\n",
       "            0.3875, 0.3816, 0.3782, 0.3757, 0.3625, 0.3447, 0.3445, 0.333 ,\n",
       "            0.3328, 0.331 , 0.3174, 0.308 , 0.305 , 0.3035, 0.2922, 0.2861,\n",
       "            0.2832, 0.2534], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6865672, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.06716418, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.11940298, 0.11940298, 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.14925373, 0.1641791 ,\n",
       "            0.1641791 , 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20149253, 0.20149253, 0.20895523,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.2835821 , 0.2835821 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.29850745, 0.29850745, 0.29850745, 0.29850745, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.3955224 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.46268657, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.2413793 , 0.25      , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.33620688,\n",
       "            0.33620688, 0.3448276 , 0.3448276 , 0.35344827, 0.35344827,\n",
       "            0.37068966, 0.38793105, 0.39655173, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.6034483 , 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.7241379 , 0.7241379 , 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.952 , 0.947 , 0.943 , 0.937 , 0.9355, 0.931 , 0.927 ,\n",
       "            0.9233, 0.918 , 0.9155, 0.9126, 0.9116, 0.91  , 0.906 , 0.9053,\n",
       "            0.902 , 0.901 , 0.8994, 0.8936, 0.89  , 0.8867, 0.8857, 0.8843,\n",
       "            0.882 , 0.8813, 0.8804, 0.88  , 0.8794, 0.879 , 0.878 , 0.8745,\n",
       "            0.874 , 0.8726, 0.8696, 0.864 , 0.862 , 0.8613, 0.86  , 0.859 ,\n",
       "            0.8584, 0.857 , 0.8564, 0.855 , 0.8545, 0.853 , 0.852 , 0.8516,\n",
       "            0.851 , 0.85  , 0.847 , 0.844 , 0.841 , 0.8403, 0.84  , 0.8394,\n",
       "            0.8384, 0.838 , 0.8374, 0.837 , 0.836 , 0.8354, 0.8335, 0.833 ,\n",
       "            0.832 , 0.8306, 0.83  , 0.829 , 0.8286, 0.828 , 0.827 , 0.8267,\n",
       "            0.8257, 0.825 , 0.8237, 0.8228, 0.8203, 0.82  , 0.818 , 0.817 ,\n",
       "            0.8164, 0.815 , 0.8145, 0.814 , 0.811 , 0.8105, 0.81  , 0.8096,\n",
       "            0.8047, 0.804 , 0.803 , 0.8013, 0.8003, 0.7993, 0.7983, 0.798 ,\n",
       "            0.797 , 0.7964, 0.7954, 0.793 , 0.7925, 0.792 , 0.7915, 0.7905,\n",
       "            0.79  , 0.7886, 0.7876, 0.7837, 0.783 , 0.7827, 0.7817, 0.78  ,\n",
       "            0.779 , 0.7783, 0.778 , 0.777 , 0.7754, 0.7734, 0.7715, 0.77  ,\n",
       "            0.766 , 0.7656, 0.765 , 0.762 , 0.7603, 0.7593, 0.7554, 0.753 ,\n",
       "            0.751 , 0.748 , 0.7476, 0.7456, 0.7417, 0.7373, 0.737 , 0.736 ,\n",
       "            0.7334, 0.7275, 0.724 , 0.722 , 0.7197, 0.716 , 0.7075, 0.707 ,\n",
       "            0.7056, 0.7046, 0.7036, 0.703 , 0.702 , 0.701 , 0.7   , 0.699 ,\n",
       "            0.6953, 0.693 , 0.681 , 0.6807, 0.6772, 0.6636, 0.6343, 0.633 ,\n",
       "            0.629 , 0.6157, 0.614 , 0.5938, 0.5884, 0.588 , 0.5845, 0.583 ,\n",
       "            0.578 , 0.571 , 0.56  , 0.5386, 0.533 , 0.5234, 0.5215, 0.517 ,\n",
       "            0.514 , 0.5117, 0.509 , 0.5083, 0.5073, 0.5063, 0.505 , 0.5   ,\n",
       "            0.499 , 0.491 , 0.49  , 0.4753, 0.472 , 0.4502, 0.4424, 0.4421,\n",
       "            0.441 , 0.4348, 0.4321, 0.429 , 0.425 , 0.4177, 0.413 , 0.4075,\n",
       "            0.4067, 0.4058, 0.4053, 0.4038, 0.4026, 0.4014, 0.4006, 0.3918,\n",
       "            0.386 , 0.381 , 0.3787, 0.3643, 0.3467, 0.346 , 0.3345, 0.3333,\n",
       "            0.3313, 0.317 , 0.3083, 0.304 , 0.3035, 0.2917, 0.2842, 0.2808,\n",
       "            0.2517], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7164179, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.11940298, 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1641791 , 0.1716418 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.26865673, 0.2761194 ,\n",
       "            0.2761194 , 0.2835821 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.29850745, 0.29850745, 0.29850745, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.35820895, 0.36567163, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6567164 , 0.6641791 , 0.67164177, 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.3275862 ,\n",
       "            0.3275862 , 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.37931034, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.4827586 , 0.49137932, 0.5086207 , 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 , 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62068963,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.70689654, 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.8103448 , 0.82758623,\n",
       "            0.82758623, 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9624, 0.9575, 0.954 , 0.9487, 0.9473, 0.9434, 0.94  ,\n",
       "            0.938 , 0.932 , 0.9297, 0.929 , 0.928 , 0.9263, 0.924 , 0.9214,\n",
       "            0.9194, 0.9175, 0.915 , 0.9146, 0.9116, 0.906 , 0.904 , 0.903 ,\n",
       "            0.902 , 0.9014, 0.9004, 0.8994, 0.8984, 0.8975, 0.897 , 0.8945,\n",
       "            0.8916, 0.89  , 0.887 , 0.8867, 0.886 , 0.8853, 0.885 , 0.883 ,\n",
       "            0.8804, 0.8794, 0.879 , 0.8784, 0.8774, 0.877 , 0.876 , 0.8755,\n",
       "            0.875 , 0.8745, 0.869 , 0.8657, 0.865 , 0.8643, 0.8633, 0.863 ,\n",
       "            0.8623, 0.862 , 0.8613, 0.8604, 0.859 , 0.8584, 0.858 , 0.857 ,\n",
       "            0.8564, 0.855 , 0.8545, 0.854 , 0.8535, 0.8525, 0.852 , 0.8516,\n",
       "            0.85  , 0.8486, 0.848 , 0.8477, 0.8467, 0.846 , 0.845 , 0.8433,\n",
       "            0.843 , 0.8423, 0.841 , 0.8403, 0.84  , 0.8394, 0.839 , 0.837 ,\n",
       "            0.8364, 0.8354, 0.83  , 0.8286, 0.828 , 0.826 , 0.8247, 0.823 ,\n",
       "            0.8223, 0.822 , 0.821 , 0.82  , 0.8193, 0.8184, 0.818 , 0.8174,\n",
       "            0.8164, 0.816 , 0.8154, 0.815 , 0.8105, 0.8096, 0.8086, 0.808 ,\n",
       "            0.806 , 0.805 , 0.804 , 0.8037, 0.8022, 0.799 , 0.7983, 0.797 ,\n",
       "            0.794 , 0.791 , 0.7905, 0.79  , 0.787 , 0.7866, 0.7803, 0.7783,\n",
       "            0.7773, 0.775 , 0.7734, 0.7686, 0.765 , 0.7646, 0.7637, 0.7603,\n",
       "            0.756 , 0.7534, 0.748 , 0.74  , 0.734 , 0.7314, 0.73  , 0.7295,\n",
       "            0.7285, 0.7275, 0.7246, 0.724 , 0.7236, 0.7217, 0.719 , 0.706 ,\n",
       "            0.7056, 0.702 , 0.697 , 0.684 , 0.658 , 0.655 , 0.6523, 0.6343,\n",
       "            0.6313, 0.611 , 0.6064, 0.6055, 0.604 , 0.6   , 0.5947, 0.5874,\n",
       "            0.576 , 0.5537, 0.5474, 0.536 , 0.5347, 0.5303, 0.5273, 0.525 ,\n",
       "            0.5215, 0.521 , 0.5195, 0.5186, 0.5127, 0.5117, 0.5034, 0.5015,\n",
       "            0.488 , 0.4827, 0.4592, 0.4531, 0.4514, 0.4495, 0.4436, 0.441 ,\n",
       "            0.4375, 0.4324, 0.425 , 0.4207, 0.415 , 0.4148, 0.4146, 0.4119,\n",
       "            0.4111, 0.409 , 0.4077, 0.4075, 0.399 , 0.3936, 0.387 , 0.3845,\n",
       "            0.3691, 0.352 , 0.35  , 0.3389, 0.3367, 0.3347, 0.3198, 0.3115,\n",
       "            0.3066, 0.3064, 0.2944, 0.286 , 0.2822, 0.2534], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7164179, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.11940298, 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.1716418 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20149253, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.25373134, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29850745, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35074627, 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18103448, 0.18965517, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.31034482,\n",
       "            0.31034482, 0.31034482, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.36206895, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.63793105, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.7758621 , 0.7758621 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9707, 0.966 , 0.9634, 0.9585, 0.9575, 0.953 , 0.9507,\n",
       "            0.945 , 0.942 , 0.9414, 0.9395, 0.9355, 0.935 , 0.9336, 0.932 ,\n",
       "            0.9316, 0.931 , 0.93  , 0.9277, 0.926 , 0.9224, 0.9214, 0.9204,\n",
       "            0.9194, 0.9185, 0.917 , 0.916 , 0.914 , 0.913 , 0.9126, 0.912 ,\n",
       "            0.9087, 0.907 , 0.9062, 0.905 , 0.9043, 0.903 , 0.9023, 0.9014,\n",
       "            0.901 , 0.8994, 0.8984, 0.897 , 0.8955, 0.895 , 0.8926, 0.888 ,\n",
       "            0.887 , 0.886 , 0.8857, 0.8853, 0.885 , 0.8833, 0.883 , 0.8823,\n",
       "            0.882 , 0.8813, 0.88  , 0.8794, 0.879 , 0.8784, 0.878 , 0.8765,\n",
       "            0.876 , 0.8745, 0.874 , 0.8726, 0.8716, 0.8706, 0.869 , 0.8687,\n",
       "            0.867 , 0.8667, 0.866 , 0.8643, 0.864 , 0.8633, 0.8623, 0.862 ,\n",
       "            0.861 , 0.86  , 0.8584, 0.8574, 0.8545, 0.854 , 0.853 , 0.8506,\n",
       "            0.848 , 0.847 , 0.8467, 0.8457, 0.845 , 0.843 , 0.8423, 0.8413,\n",
       "            0.841 , 0.8403, 0.8384, 0.838 , 0.8364, 0.8335, 0.833 , 0.832 ,\n",
       "            0.83  , 0.8296, 0.8286, 0.828 , 0.825 , 0.8247, 0.824 , 0.8228,\n",
       "            0.8213, 0.8174, 0.816 , 0.8154, 0.814 , 0.8086, 0.805 , 0.803 ,\n",
       "            0.8022, 0.7935, 0.7925, 0.7915, 0.791 , 0.7886, 0.787 , 0.7847,\n",
       "            0.7837, 0.777 , 0.7744, 0.764 , 0.7627, 0.7617, 0.7603, 0.7554,\n",
       "            0.7534, 0.7515, 0.751 , 0.7495, 0.747 , 0.746 , 0.7456, 0.7324,\n",
       "            0.7305, 0.723 , 0.715 , 0.705 , 0.684 , 0.678 , 0.6772, 0.653 ,\n",
       "            0.6475, 0.6284, 0.627 , 0.625 , 0.6235, 0.6167, 0.61  , 0.604 ,\n",
       "            0.592 , 0.5703, 0.562 , 0.5503, 0.549 , 0.544 , 0.5405, 0.538 ,\n",
       "            0.5347, 0.534 , 0.5337, 0.532 , 0.5312, 0.527 , 0.5254, 0.5156,\n",
       "            0.513 , 0.4985, 0.4944, 0.4692, 0.4617, 0.4602, 0.4587, 0.4524,\n",
       "            0.4497, 0.446 , 0.4407, 0.4326, 0.428 , 0.422 , 0.4216, 0.4214,\n",
       "            0.4192, 0.4177, 0.416 , 0.4148, 0.4143, 0.405 , 0.3994, 0.3923,\n",
       "            0.39  , 0.3735, 0.3555, 0.3538, 0.3418, 0.3396, 0.3376, 0.322 ,\n",
       "            0.3135, 0.3083, 0.3079, 0.296 , 0.2869, 0.2837, 0.2534],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.73134327, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.10447761, 0.11940298, 0.11940298, 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.12686567, 0.13432837, 0.14179105, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.15671642, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.1716418 , 0.17910448, 0.17910448, 0.19402985,\n",
       "            0.20149253, 0.21641791, 0.21641791, 0.21641791, 0.21641791,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.26119402, 0.26865673, 0.26865673,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.32089552, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3880597 , 0.3955224 ,\n",
       "            0.3955224 , 0.40298507, 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.42537314, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1724138 ,\n",
       "            0.1724138 , 0.18965517, 0.18965517, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.25      ,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.29310346,\n",
       "            0.29310346, 0.29310346, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.4051724 ,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.46551725, 0.4827586 , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.5603448 , 0.5689655 , 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.80172414, 0.8103448 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.86206895, 0.86206895, 0.87931037,\n",
       "            0.87931037, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.977 , 0.973 , 0.9707, 0.9663, 0.966 , 0.9614, 0.961 ,\n",
       "            0.96  , 0.955 , 0.9526, 0.9517, 0.951 , 0.95  , 0.9487, 0.9463,\n",
       "            0.946 , 0.9453, 0.944 , 0.9424, 0.9414, 0.9385, 0.938 , 0.937 ,\n",
       "            0.9365, 0.933 , 0.9326, 0.9297, 0.929 , 0.9277, 0.9263, 0.9253,\n",
       "            0.925 , 0.9243, 0.923 , 0.9224, 0.921 , 0.9204, 0.92  , 0.9194,\n",
       "            0.918 , 0.917 , 0.916 , 0.9155, 0.9146, 0.913 , 0.9097, 0.9077,\n",
       "            0.907 , 0.9067, 0.906 , 0.9053, 0.9043, 0.9033, 0.903 , 0.9023,\n",
       "            0.9014, 0.9004, 0.8994, 0.8984, 0.898 , 0.8975, 0.8965, 0.8945,\n",
       "            0.894 , 0.893 , 0.8926, 0.892 , 0.891 , 0.89  , 0.8896, 0.889 ,\n",
       "            0.888 , 0.8877, 0.887 , 0.8857, 0.8853, 0.8843, 0.883 , 0.882 ,\n",
       "            0.8813, 0.8765, 0.876 , 0.8755, 0.875 , 0.874 , 0.8726, 0.8696,\n",
       "            0.8687, 0.868 , 0.867 , 0.8657, 0.8647, 0.8643, 0.864 , 0.8623,\n",
       "            0.86  , 0.857 , 0.856 , 0.8555, 0.854 , 0.8535, 0.8525, 0.852 ,\n",
       "            0.848 , 0.8467, 0.846 , 0.8438, 0.8423, 0.8384, 0.838 , 0.8354,\n",
       "            0.8276, 0.827 , 0.82  , 0.818 , 0.816 , 0.812 , 0.811 , 0.8105,\n",
       "            0.81  , 0.803 , 0.799 , 0.7896, 0.788 , 0.787 , 0.7866, 0.784 ,\n",
       "            0.7773, 0.7754, 0.775 , 0.7725, 0.772 , 0.7715, 0.7686, 0.7656,\n",
       "            0.757 , 0.755 , 0.7437, 0.734 , 0.725 , 0.709 , 0.701 , 0.7007,\n",
       "            0.6714, 0.6655, 0.6475, 0.6465, 0.6455, 0.6416, 0.635 , 0.6274,\n",
       "            0.6216, 0.609 , 0.5864, 0.5776, 0.565 , 0.5635, 0.5586, 0.555 ,\n",
       "            0.553 , 0.55  , 0.5493, 0.548 , 0.547 , 0.5464, 0.5415, 0.5396,\n",
       "            0.53  , 0.5264, 0.513 , 0.5073, 0.4802, 0.4749, 0.4714, 0.4692,\n",
       "            0.4631, 0.4602, 0.4563, 0.45  , 0.4421, 0.4373, 0.4329, 0.431 ,\n",
       "            0.428 , 0.4268, 0.4243, 0.423 , 0.4229, 0.4143, 0.41  , 0.4004,\n",
       "            0.3977, 0.3806, 0.363 , 0.3604, 0.3489, 0.3452, 0.3433, 0.3271,\n",
       "            0.3193, 0.3137, 0.3127, 0.3008, 0.2913, 0.288 , 0.2576],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.73134327, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.09701493, 0.09701493, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.15671642, 0.15671642, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1641791 , 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.17910448, 0.18656716, 0.20149253,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23880596, 0.23880596,\n",
       "            0.24626866, 0.24626866, 0.24626866, 0.24626866, 0.24626866,\n",
       "            0.25373134, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3283582 , 0.33582088,\n",
       "            0.33582088, 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.18103448, 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.2413793 , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.30172414, 0.31034482,\n",
       "            0.31034482, 0.3275862 , 0.33620688, 0.33620688, 0.35344827,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.38793105, 0.4051724 ,\n",
       "            0.4051724 , 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.55172414, 0.55172414, 0.5689655 , 0.57758623,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.6551724 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.79310346, 0.8103448 , 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.982 , 0.9785, 0.977 , 0.9727, 0.9688, 0.9683, 0.9673,\n",
       "            0.9634, 0.962 , 0.9604, 0.96  , 0.9595, 0.9575, 0.956 , 0.9546,\n",
       "            0.954 , 0.952 , 0.9517, 0.951 , 0.95  , 0.948 , 0.9453, 0.9443,\n",
       "            0.942 , 0.941 , 0.94  , 0.9395, 0.939 , 0.938 , 0.9375, 0.937 ,\n",
       "            0.9365, 0.936 , 0.935 , 0.934 , 0.9336, 0.9326, 0.9316, 0.931 ,\n",
       "            0.928 , 0.9263, 0.9243, 0.924 , 0.923 , 0.9224, 0.922 , 0.921 ,\n",
       "            0.9204, 0.9194, 0.919 , 0.9185, 0.9175, 0.916 , 0.9155, 0.9146,\n",
       "            0.914 , 0.9136, 0.912 , 0.9106, 0.91  , 0.9097, 0.908 , 0.9077,\n",
       "            0.907 , 0.9062, 0.9053, 0.905 , 0.9043, 0.904 , 0.9033, 0.903 ,\n",
       "            0.9023, 0.9014, 0.9004, 0.898 , 0.8965, 0.8955, 0.895 , 0.894 ,\n",
       "            0.8916, 0.89  , 0.889 , 0.888 , 0.8877, 0.887 , 0.8867, 0.886 ,\n",
       "            0.8857, 0.8853, 0.885 , 0.8843, 0.8833, 0.8823, 0.882 , 0.8804,\n",
       "            0.878 , 0.877 , 0.876 , 0.8755, 0.8745, 0.8735, 0.8726, 0.869 ,\n",
       "            0.8687, 0.868 , 0.8667, 0.8643, 0.861 , 0.8604, 0.86  , 0.8594,\n",
       "            0.859 , 0.8584, 0.8496, 0.8486, 0.848 , 0.8433, 0.841 , 0.839 ,\n",
       "            0.8354, 0.8345, 0.832 , 0.8306, 0.827 , 0.8267, 0.822 , 0.814 ,\n",
       "            0.813 , 0.811 , 0.8096, 0.808 , 0.7993, 0.799 , 0.7983, 0.795 ,\n",
       "            0.7935, 0.792 , 0.789 , 0.785 , 0.78  , 0.778 , 0.763 , 0.751 ,\n",
       "            0.7446, 0.7324, 0.7246, 0.722 , 0.6895, 0.6816, 0.667 , 0.665 ,\n",
       "            0.663 , 0.658 , 0.651 , 0.6426, 0.6377, 0.6245, 0.602 , 0.593 ,\n",
       "            0.5786, 0.577 , 0.5723, 0.568 , 0.567 , 0.5625, 0.562 , 0.56  ,\n",
       "            0.5596, 0.559 , 0.5547, 0.5522, 0.5425, 0.5376, 0.5244, 0.5186,\n",
       "            0.489 , 0.4841, 0.4802, 0.4778, 0.4714, 0.4683, 0.464 , 0.457 ,\n",
       "            0.449 , 0.4443, 0.4404, 0.4402, 0.4375, 0.434 , 0.433 , 0.4302,\n",
       "            0.429 , 0.4207, 0.4165, 0.4055, 0.4028, 0.3845, 0.367 , 0.3635,\n",
       "            0.352 , 0.3474, 0.3457, 0.3289, 0.3213, 0.3157, 0.3137, 0.3022,\n",
       "            0.2915, 0.2888, 0.2576], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.73134327, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.09701493, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.10447761, 0.10447761, 0.11940298, 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.13432837, 0.13432837,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.17910448, 0.18656716,\n",
       "            0.18656716, 0.20149253, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.23880596, 0.24626866, 0.24626866, 0.24626866, 0.25373134,\n",
       "            0.2761194 , 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.3283582 , 0.3283582 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.11206897, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.1637931 , 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.25      , 0.25862068, 0.25862068, 0.2672414 , 0.28448275,\n",
       "            0.28448275, 0.30172414, 0.31034482, 0.3275862 , 0.3275862 ,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.37931034, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.43965518, 0.44827586, 0.44827586, 0.45689654,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5086207 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.62068963, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6551724 , 0.6551724 ,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.73275864, 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.8189655 , 0.82758623, 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9863, 0.983 , 0.982 , 0.978 , 0.9756, 0.974 , 0.9736,\n",
       "            0.9707, 0.9697, 0.969 , 0.9673, 0.967 , 0.9644, 0.963 , 0.962 ,\n",
       "            0.9614, 0.961 , 0.9604, 0.9595, 0.9565, 0.9556, 0.954 , 0.953 ,\n",
       "            0.952 , 0.9517, 0.951 , 0.9507, 0.9497, 0.949 , 0.9487, 0.9478,\n",
       "            0.9473, 0.9463, 0.9453, 0.945 , 0.9443, 0.9434, 0.9414, 0.9385,\n",
       "            0.938 , 0.9375, 0.9365, 0.936 , 0.9355, 0.935 , 0.934 , 0.9336,\n",
       "            0.933 , 0.932 , 0.9316, 0.9307, 0.93  , 0.929 , 0.9287, 0.928 ,\n",
       "            0.9272, 0.9263, 0.9253, 0.9243, 0.9233, 0.923 , 0.922 , 0.9214,\n",
       "            0.921 , 0.9204, 0.9194, 0.9185, 0.918 , 0.9175, 0.917 , 0.9165,\n",
       "            0.915 , 0.9126, 0.912 , 0.9116, 0.91  , 0.908 , 0.906 , 0.9053,\n",
       "            0.905 , 0.9043, 0.904 , 0.903 , 0.902 , 0.9014, 0.8994, 0.8984,\n",
       "            0.896 , 0.895 , 0.894 , 0.893 , 0.8916, 0.891 , 0.89  , 0.8877,\n",
       "            0.887 , 0.8853, 0.885 , 0.884 , 0.8833, 0.8823, 0.8794, 0.879 ,\n",
       "            0.878 , 0.877 , 0.8765, 0.869 , 0.8677, 0.8667, 0.864 , 0.8613,\n",
       "            0.859 , 0.857 , 0.8555, 0.8545, 0.851 , 0.8496, 0.8486, 0.8423,\n",
       "            0.842 , 0.8354, 0.833 , 0.832 , 0.8276, 0.8203, 0.82  , 0.8193,\n",
       "            0.8164, 0.8125, 0.8105, 0.8086, 0.8037, 0.8013, 0.799 , 0.782 ,\n",
       "            0.767 , 0.7637, 0.7544, 0.746 , 0.743 , 0.707 , 0.6973, 0.6855,\n",
       "            0.6836, 0.6797, 0.6753, 0.667 , 0.6577, 0.6533, 0.64  , 0.6167,\n",
       "            0.607 , 0.592 , 0.5903, 0.585 , 0.581 , 0.5806, 0.5757, 0.5747,\n",
       "            0.5728, 0.5723, 0.572 , 0.5713, 0.5674, 0.565 , 0.555 , 0.549 ,\n",
       "            0.5356, 0.5293, 0.4978, 0.493 , 0.4888, 0.4858, 0.4795, 0.4763,\n",
       "            0.472 , 0.4639, 0.4558, 0.451 , 0.4475, 0.4473, 0.4438, 0.4397,\n",
       "            0.4392, 0.4358, 0.435 , 0.4343, 0.4265, 0.4224, 0.4104, 0.4075,\n",
       "            0.388 , 0.3704, 0.3665, 0.355 , 0.3494, 0.3477, 0.33  , 0.3228,\n",
       "            0.317 , 0.3145, 0.303 , 0.2913, 0.2883, 0.257 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.74626863, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.10447761, 0.11940298, 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.15671642, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20149253, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.21641791, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.23880596, 0.24626866, 0.24626866,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.2761194 , 0.2761194 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35074627, 0.35074627,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.64179105, 0.6492537 , 0.6567164 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06896552, 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.12068965, 0.12931034, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.2413793 , 0.25862068, 0.2672414 , 0.2672414 ,\n",
       "            0.28448275, 0.28448275, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37068966, 0.38793105, 0.38793105, 0.41379312, 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.44827586, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5       , 0.5086207 , 0.5344828 , 0.54310346, 0.5603448 ,\n",
       "            0.57758623, 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.82758623, 0.82758623,\n",
       "            0.8448276 , 0.86206895, 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9893, 0.987 , 0.986 , 0.9824, 0.981 , 0.979 , 0.977 ,\n",
       "            0.9766, 0.9756, 0.9746, 0.973 , 0.9727, 0.972 , 0.971 , 0.9707,\n",
       "            0.97  , 0.9697, 0.969 , 0.9683, 0.968 , 0.9663, 0.9644, 0.964 ,\n",
       "            0.963 , 0.9624, 0.962 , 0.961 , 0.96  , 0.959 , 0.9585, 0.958 ,\n",
       "            0.957 , 0.9565, 0.956 , 0.9556, 0.9526, 0.952 , 0.95  , 0.9497,\n",
       "            0.949 , 0.9487, 0.948 , 0.9478, 0.947 , 0.9463, 0.946 , 0.9453,\n",
       "            0.945 , 0.9443, 0.943 , 0.9424, 0.942 , 0.9414, 0.94  , 0.9395,\n",
       "            0.939 , 0.9385, 0.9365, 0.9355, 0.935 , 0.9346, 0.9336, 0.933 ,\n",
       "            0.932 , 0.9316, 0.9307, 0.93  , 0.9287, 0.9277, 0.927 , 0.9263,\n",
       "            0.925 , 0.9233, 0.923 , 0.921 , 0.9204, 0.92  , 0.9194, 0.919 ,\n",
       "            0.9185, 0.9175, 0.917 , 0.9165, 0.916 , 0.915 , 0.9136, 0.912 ,\n",
       "            0.911 , 0.91  , 0.909 , 0.9087, 0.908 , 0.907 , 0.9062, 0.9043,\n",
       "            0.9014, 0.901 , 0.898 , 0.897 , 0.8965, 0.8945, 0.8936, 0.8916,\n",
       "            0.8906, 0.887 , 0.8853, 0.8843, 0.883 , 0.88  , 0.8774, 0.8765,\n",
       "            0.875 , 0.8735, 0.868 , 0.8677, 0.8613, 0.8564, 0.856 , 0.8535,\n",
       "            0.8525, 0.8467, 0.8403, 0.839 , 0.8364, 0.831 , 0.8286, 0.827 ,\n",
       "            0.822 , 0.819 , 0.8003, 0.7827, 0.782 , 0.776 , 0.768 , 0.763 ,\n",
       "            0.725 , 0.7124, 0.705 , 0.7026, 0.6963, 0.692 , 0.683 , 0.6724,\n",
       "            0.6694, 0.656 , 0.6323, 0.622 , 0.606 , 0.604 , 0.599 , 0.594 ,\n",
       "            0.5884, 0.588 , 0.585 , 0.581 , 0.5786, 0.568 , 0.5605, 0.546 ,\n",
       "            0.541 , 0.5073, 0.5015, 0.4976, 0.495 , 0.4883, 0.4849, 0.4805,\n",
       "            0.4717, 0.4636, 0.4578, 0.4548, 0.4539, 0.4504, 0.4463, 0.4456,\n",
       "            0.4421, 0.4414, 0.4407, 0.4324, 0.428 , 0.4153, 0.4124, 0.3918,\n",
       "            0.3735, 0.3694, 0.3574, 0.3516, 0.3499, 0.3315, 0.3237, 0.3179,\n",
       "            0.3152, 0.3035, 0.2915, 0.2886, 0.2563], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.76119405, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.09701493, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.1716418 , 0.18656716, 0.18656716, 0.20149253,\n",
       "            0.20149253, 0.20149253, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.2238806 , 0.23880596,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35074627, 0.35074627,\n",
       "            0.35074627, 0.35820895, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.3955224 , 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.0775862 , 0.0862069 ,\n",
       "            0.10344828, 0.11206897, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.20689656,\n",
       "            0.21551724, 0.2413793 , 0.2413793 , 0.2672414 , 0.27586207,\n",
       "            0.27586207, 0.30172414, 0.30172414, 0.30172414, 0.31034482,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.51724136,\n",
       "            0.5344828 , 0.54310346, 0.5603448 , 0.5689655 , 0.5689655 ,\n",
       "            0.5689655 , 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.73275864, 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.992 , 0.9897, 0.989 , 0.9863, 0.986 , 0.9854, 0.9834,\n",
       "            0.983 , 0.9814, 0.981 , 0.9785, 0.978 , 0.977 , 0.9766, 0.976 ,\n",
       "            0.974 , 0.9736, 0.972 , 0.971 , 0.97  , 0.9697, 0.969 , 0.9683,\n",
       "            0.9673, 0.967 , 0.966 , 0.9653, 0.965 , 0.9644, 0.964 , 0.9634,\n",
       "            0.9614, 0.9604, 0.9595, 0.959 , 0.9585, 0.9575, 0.957 , 0.9565,\n",
       "            0.956 , 0.9556, 0.9546, 0.9536, 0.953 , 0.9526, 0.952 , 0.951 ,\n",
       "            0.95  , 0.9497, 0.949 , 0.9478, 0.9473, 0.9463, 0.946 , 0.9453,\n",
       "            0.945 , 0.944 , 0.943 , 0.9424, 0.942 , 0.94  , 0.9395, 0.939 ,\n",
       "            0.9375, 0.937 , 0.9365, 0.9355, 0.934 , 0.9336, 0.933 , 0.9326,\n",
       "            0.932 , 0.9316, 0.931 , 0.9307, 0.93  , 0.9297, 0.9287, 0.928 ,\n",
       "            0.9272, 0.927 , 0.9263, 0.9253, 0.9243, 0.9233, 0.923 , 0.922 ,\n",
       "            0.921 , 0.9204, 0.9194, 0.9185, 0.916 , 0.9155, 0.914 , 0.912 ,\n",
       "            0.9097, 0.9087, 0.906 , 0.905 , 0.9043, 0.9033, 0.901 , 0.9   ,\n",
       "            0.8994, 0.8965, 0.8945, 0.894 , 0.892 , 0.89  , 0.886 , 0.8843,\n",
       "            0.884 , 0.8784, 0.8755, 0.8745, 0.873 , 0.872 , 0.8706, 0.8696,\n",
       "            0.864 , 0.8594, 0.8574, 0.857 , 0.8555, 0.848 , 0.8457, 0.844 ,\n",
       "            0.841 , 0.8384, 0.818 , 0.8003, 0.7974, 0.7964, 0.789 , 0.783 ,\n",
       "            0.743 , 0.728 , 0.7246, 0.7217, 0.7134, 0.709 , 0.6997, 0.6875,\n",
       "            0.6855, 0.6714, 0.649 , 0.638 , 0.6206, 0.6187, 0.6143, 0.609 ,\n",
       "            0.6084, 0.603 , 0.602 , 0.5996, 0.599 , 0.5986, 0.596 , 0.5938,\n",
       "            0.582 , 0.5737, 0.558 , 0.554 , 0.5186, 0.5117, 0.508 , 0.506 ,\n",
       "            0.4988, 0.4954, 0.4905, 0.4814, 0.4731, 0.4666, 0.4636, 0.4624,\n",
       "            0.459 , 0.4548, 0.4539, 0.4504, 0.4497, 0.449 , 0.4404, 0.4355,\n",
       "            0.4226, 0.4192, 0.3982, 0.3792, 0.3745, 0.3623, 0.3562, 0.3545,\n",
       "            0.3352, 0.3271, 0.3213, 0.3186, 0.3064, 0.2942, 0.292 , 0.258 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7835821, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.15671642, 0.15671642, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20149253, 0.20149253, 0.21641791,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.2238806 , 0.23880596,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35820895, 0.35820895,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6567164 , 0.6641791 , 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.11206897, 0.12931034, 0.13793103,\n",
       "            0.15517241, 0.1637931 , 0.18103448, 0.18965517, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.22413793, 0.2413793 , 0.25862068,\n",
       "            0.27586207, 0.27586207, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.33620688, 0.3448276 , 0.35344827, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.41379312, 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.46551725, 0.4827586 , 0.4827586 , 0.4827586 , 0.5       ,\n",
       "            0.5258621 , 0.54310346, 0.54310346, 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6551724 , 0.6637931 , 0.6810345 , 0.6810345 ,\n",
       "            0.69827586, 0.70689654, 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.8103448 , 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.994 , 0.992 , 0.9917, 0.9893, 0.989 , 0.9883, 0.9873,\n",
       "            0.9863, 0.9854, 0.985 , 0.9834, 0.983 , 0.9824, 0.982 , 0.9814,\n",
       "            0.981 , 0.9785, 0.9775, 0.977 , 0.9766, 0.976 , 0.9756, 0.975 ,\n",
       "            0.9746, 0.974 , 0.9736, 0.9727, 0.972 , 0.9717, 0.97  , 0.9697,\n",
       "            0.9688, 0.9673, 0.967 , 0.9663, 0.966 , 0.9653, 0.965 , 0.9644,\n",
       "            0.964 , 0.9634, 0.963 , 0.962 , 0.9614, 0.961 , 0.9604, 0.96  ,\n",
       "            0.9595, 0.959 , 0.9585, 0.9575, 0.957 , 0.9565, 0.956 , 0.9556,\n",
       "            0.9546, 0.954 , 0.9536, 0.953 , 0.9526, 0.952 , 0.9517, 0.951 ,\n",
       "            0.949 , 0.9487, 0.9478, 0.9463, 0.9453, 0.9443, 0.944 , 0.9434,\n",
       "            0.943 , 0.9424, 0.942 , 0.9414, 0.941 , 0.94  , 0.9395, 0.9385,\n",
       "            0.938 , 0.937 , 0.9365, 0.936 , 0.9346, 0.9336, 0.9326, 0.931 ,\n",
       "            0.93  , 0.9287, 0.928 , 0.9277, 0.9272, 0.925 , 0.9224, 0.9214,\n",
       "            0.9194, 0.918 , 0.917 , 0.916 , 0.914 , 0.913 , 0.9106, 0.9087,\n",
       "            0.9067, 0.905 , 0.9014, 0.8984, 0.898 , 0.8936, 0.891 , 0.89  ,\n",
       "            0.8896, 0.888 , 0.886 , 0.8833, 0.8794, 0.8755, 0.8735, 0.8726,\n",
       "            0.8716, 0.8643, 0.861 , 0.8604, 0.8574, 0.855 , 0.8545, 0.834 ,\n",
       "            0.818 , 0.815 , 0.814 , 0.807 , 0.8013, 0.7607, 0.745 , 0.742 ,\n",
       "            0.739 , 0.7295, 0.7256, 0.7163, 0.705 , 0.702 , 0.6875, 0.664 ,\n",
       "            0.6533, 0.6353, 0.6333, 0.6294, 0.6245, 0.623 , 0.618 , 0.615 ,\n",
       "            0.614 , 0.6133, 0.6104, 0.6074, 0.5967, 0.587 , 0.574 , 0.5664,\n",
       "            0.5293, 0.5264, 0.5195, 0.516 , 0.5093, 0.506 , 0.501 , 0.491 ,\n",
       "            0.4827, 0.4766, 0.4756, 0.4753, 0.4685, 0.4634, 0.4626, 0.4585,\n",
       "            0.4583, 0.4568, 0.4504, 0.4475, 0.431 , 0.4275, 0.405 , 0.3872,\n",
       "            0.3813, 0.3699, 0.3618, 0.36  , 0.3403, 0.3333, 0.3271, 0.323 ,\n",
       "            0.3118, 0.298 , 0.2954, 0.2622], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7910448, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.05970149, 0.05970149, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.08208955, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.11940298, 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20149253, 0.20149253,\n",
       "            0.20149253, 0.21641791, 0.21641791, 0.21641791, 0.2238806 ,\n",
       "            0.2238806 , 0.2238806 , 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.30597016, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.31343284, 0.32089552, 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3955224 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.03448276, 0.05172414,\n",
       "            0.06034483, 0.0775862 , 0.0862069 , 0.10344828, 0.10344828,\n",
       "            0.12068965, 0.13793103, 0.14655173, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.20689656, 0.22413793, 0.22413793, 0.25      ,\n",
       "            0.2672414 , 0.27586207, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.39655173, 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.49137932, 0.5       , 0.51724136, 0.5344828 , 0.54310346,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 , 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9956, 0.9937, 0.9917, 0.991 , 0.99  , 0.9893, 0.989 ,\n",
       "            0.9883, 0.9873, 0.9863, 0.986 , 0.9854, 0.985 , 0.983 , 0.9824,\n",
       "            0.9814, 0.981 , 0.9805, 0.98  , 0.9795, 0.979 , 0.978 , 0.977 ,\n",
       "            0.9756, 0.975 , 0.9746, 0.974 , 0.9736, 0.973 , 0.9727, 0.972 ,\n",
       "            0.9717, 0.971 , 0.97  , 0.9697, 0.969 , 0.9688, 0.9683, 0.9673,\n",
       "            0.967 , 0.9663, 0.966 , 0.9653, 0.965 , 0.9644, 0.964 , 0.963 ,\n",
       "            0.9624, 0.962 , 0.9614, 0.961 , 0.9604, 0.96  , 0.9595, 0.9585,\n",
       "            0.958 , 0.957 , 0.956 , 0.9556, 0.9546, 0.954 , 0.9536, 0.953 ,\n",
       "            0.9526, 0.952 , 0.9517, 0.951 , 0.9507, 0.95  , 0.9497, 0.948 ,\n",
       "            0.9478, 0.9473, 0.9463, 0.9453, 0.945 , 0.944 , 0.9434, 0.9424,\n",
       "            0.941 , 0.9395, 0.9385, 0.9365, 0.936 , 0.9336, 0.9326, 0.9297,\n",
       "            0.929 , 0.9277, 0.927 , 0.9263, 0.9253, 0.9233, 0.922 , 0.9214,\n",
       "            0.92  , 0.9175, 0.9146, 0.9116, 0.911 , 0.907 , 0.906 , 0.9043,\n",
       "            0.9023, 0.901 , 0.896 , 0.894 , 0.8906, 0.888 , 0.887 , 0.879 ,\n",
       "            0.8755, 0.875 , 0.873 , 0.8706, 0.869 , 0.8496, 0.834 , 0.832 ,\n",
       "            0.8296, 0.8247, 0.8184, 0.778 , 0.761 , 0.7603, 0.756 , 0.746 ,\n",
       "            0.7417, 0.733 , 0.7217, 0.7183, 0.704 , 0.6797, 0.6694, 0.6504,\n",
       "            0.6484, 0.644 , 0.64  , 0.6377, 0.6343, 0.634 , 0.6313, 0.6284,\n",
       "            0.628 , 0.6274, 0.6245, 0.6216, 0.612 , 0.6   , 0.5894, 0.579 ,\n",
       "            0.54  , 0.5312, 0.5264, 0.5205, 0.5166, 0.5117, 0.5005, 0.4927,\n",
       "            0.4873, 0.4866, 0.4783, 0.473 , 0.4712, 0.4678, 0.4668, 0.465 ,\n",
       "            0.4604, 0.4583, 0.4392, 0.4358, 0.412 , 0.395 , 0.388 , 0.377 ,\n",
       "            0.3672, 0.3657, 0.3452, 0.3389, 0.3325, 0.3274, 0.3167, 0.3015,\n",
       "            0.2986, 0.266 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.79850745, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.04477612, 0.05970149,\n",
       "            0.05970149, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.11940298, 0.13432837, 0.13432837, 0.13432837, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20149253,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.2238806 , 0.2238806 ,\n",
       "            0.23880596, 0.23880596, 0.23880596, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.2761194 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.05172414, 0.06034483,\n",
       "            0.0775862 , 0.09482758, 0.10344828, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.21551724, 0.21551724, 0.23275863, 0.25862068,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.3275862 , 0.3448276 ,\n",
       "            0.35344827, 0.37068966, 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.5258621 , 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5862069 , 0.6034483 ,\n",
       "            0.62068963, 0.63793105, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6896552 , 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.7844828 , 0.80172414, 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9966, 0.995 , 0.993 , 0.9927, 0.9917, 0.991 , 0.9907,\n",
       "            0.99  , 0.9897, 0.9893, 0.989 , 0.9883, 0.988 , 0.9863, 0.986 ,\n",
       "            0.9854, 0.985 , 0.9844, 0.984 , 0.983 , 0.9824, 0.9814, 0.98  ,\n",
       "            0.9795, 0.979 , 0.9785, 0.9775, 0.977 , 0.9766, 0.976 , 0.975 ,\n",
       "            0.9746, 0.974 , 0.9736, 0.973 , 0.9727, 0.972 , 0.971 , 0.9707,\n",
       "            0.9697, 0.9688, 0.9683, 0.968 , 0.9663, 0.9653, 0.9644, 0.9634,\n",
       "            0.963 , 0.9624, 0.962 , 0.9614, 0.961 , 0.9604, 0.96  , 0.9595,\n",
       "            0.959 , 0.9585, 0.958 , 0.957 , 0.9565, 0.956 , 0.9556, 0.954 ,\n",
       "            0.9536, 0.953 , 0.9526, 0.952 , 0.9517, 0.95  , 0.9497, 0.9487,\n",
       "            0.948 , 0.9463, 0.944 , 0.943 , 0.94  , 0.9385, 0.9375, 0.937 ,\n",
       "            0.9365, 0.936 , 0.9346, 0.9336, 0.9326, 0.9316, 0.929 , 0.927 ,\n",
       "            0.9233, 0.923 , 0.9194, 0.919 , 0.9185, 0.9175, 0.9155, 0.914 ,\n",
       "            0.907 , 0.9043, 0.902 , 0.901 , 0.9004, 0.8926, 0.8887, 0.888 ,\n",
       "            0.8853, 0.883 , 0.8643, 0.8496, 0.849 , 0.8438, 0.842 , 0.835 ,\n",
       "            0.795 , 0.778 , 0.777 , 0.7725, 0.7627, 0.759 , 0.7495, 0.7373,\n",
       "            0.7344, 0.72  , 0.6953, 0.6855, 0.6655, 0.663 , 0.6597, 0.6553,\n",
       "            0.6523, 0.65  , 0.6494, 0.647 , 0.6436, 0.6426, 0.642 , 0.639 ,\n",
       "            0.636 , 0.6265, 0.614 , 0.604 , 0.5923, 0.5527, 0.5513, 0.5425,\n",
       "            0.537 , 0.5317, 0.528 , 0.5225, 0.5107, 0.503 , 0.4988, 0.4985,\n",
       "            0.4968, 0.4878, 0.4822, 0.4797, 0.4766, 0.4753, 0.4731, 0.47  ,\n",
       "            0.4685, 0.4473, 0.4438, 0.419 , 0.402 , 0.3943, 0.3833, 0.3723,\n",
       "            0.3708, 0.3496, 0.344 , 0.3374, 0.3313, 0.321 , 0.3047, 0.3018,\n",
       "            0.269 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8208955, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.05223881, 0.05970149, 0.05970149, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.13432837, 0.13432837,\n",
       "            0.13432837, 0.14925373, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1641791 , 0.17910448, 0.18656716, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.21641791, 0.21641791, 0.2238806 ,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.36567163, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.06034483,\n",
       "            0.0775862 , 0.09482758, 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.25862068, 0.27586207, 0.30172414,\n",
       "            0.31034482, 0.33620688, 0.36206895, 0.36206895, 0.38793105,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.47413793, 0.49137932, 0.5086207 , 0.5258621 ,\n",
       "            0.55172414, 0.5689655 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.61206895, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6810345 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.7758621 , 0.79310346,\n",
       "            0.79310346, 0.8103448 , 0.8189655 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8448276 , 0.86206895, 0.87068963, 0.87931037, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9976, 0.9966, 0.996 , 0.9946, 0.9937, 0.993 , 0.9927,\n",
       "            0.992 , 0.9917, 0.9907, 0.99  , 0.9897, 0.9893, 0.989 , 0.9883,\n",
       "            0.988 , 0.9873, 0.987 , 0.9863, 0.9854, 0.984 , 0.9834, 0.983 ,\n",
       "            0.9824, 0.982 , 0.9814, 0.9805, 0.98  , 0.9795, 0.979 , 0.9785,\n",
       "            0.978 , 0.9775, 0.977 , 0.9766, 0.976 , 0.9756, 0.9746, 0.974 ,\n",
       "            0.972 , 0.9717, 0.971 , 0.97  , 0.9697, 0.9688, 0.9683, 0.968 ,\n",
       "            0.9673, 0.967 , 0.9663, 0.966 , 0.9653, 0.9644, 0.964 , 0.9634,\n",
       "            0.9624, 0.9614, 0.961 , 0.9604, 0.96  , 0.9595, 0.9585, 0.958 ,\n",
       "            0.9575, 0.957 , 0.955 , 0.9526, 0.952 , 0.9497, 0.9478, 0.947 ,\n",
       "            0.9463, 0.946 , 0.945 , 0.9443, 0.943 , 0.9424, 0.94  , 0.938 ,\n",
       "            0.9336, 0.931 , 0.9307, 0.929 , 0.9277, 0.9263, 0.919 , 0.9175,\n",
       "            0.915 , 0.914 , 0.9126, 0.905 , 0.9014, 0.899 , 0.8955, 0.878 ,\n",
       "            0.8647, 0.858 , 0.857 , 0.851 , 0.811 , 0.795 , 0.792 , 0.7896,\n",
       "            0.7793, 0.7754, 0.7656, 0.7534, 0.7505, 0.7363, 0.7114, 0.702 ,\n",
       "            0.6816, 0.6787, 0.6753, 0.6714, 0.6675, 0.6655, 0.665 , 0.663 ,\n",
       "            0.659 , 0.6577, 0.657 , 0.655 , 0.652 , 0.642 , 0.628 , 0.619 ,\n",
       "            0.607 , 0.567 , 0.564 , 0.5557, 0.5493, 0.544 , 0.54  , 0.5347,\n",
       "            0.522 , 0.514 , 0.511 , 0.5107, 0.508 , 0.4988, 0.4927, 0.4895,\n",
       "            0.4868, 0.485 , 0.483 , 0.481 , 0.4797, 0.4568, 0.4531, 0.4272,\n",
       "            0.4106, 0.402 , 0.3914, 0.3792, 0.3777, 0.3555, 0.3503, 0.3438,\n",
       "            0.3367, 0.327 , 0.3093, 0.3066, 0.274 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8432836, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.04477612,\n",
       "            0.05970149, 0.05970149, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.09701493, 0.1119403 , 0.11940298,\n",
       "            0.11940298, 0.11940298, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.1641791 , 0.1641791 ,\n",
       "            0.17910448, 0.18656716, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.23880596, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.31343284, 0.31343284,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.05172414, 0.06034483,\n",
       "            0.06896552, 0.09482758, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.14655173, 0.1724138 , 0.18103448, 0.19827586, 0.20689656,\n",
       "            0.23275863, 0.25      , 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.3275862 , 0.35344827, 0.36206895, 0.39655173, 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.49137932, 0.5086207 , 0.5344828 , 0.55172414,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.6034483 , 0.6034483 ,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.6465517 , 0.6637931 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7155172 ,\n",
       "            0.7241379 , 0.75      , 0.7586207 , 0.76724136, 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.998 , 0.997 , 0.996 , 0.9956, 0.995 , 0.9946, 0.994 ,\n",
       "            0.9937, 0.993 , 0.9927, 0.992 , 0.9917, 0.991 , 0.9907, 0.99  ,\n",
       "            0.9897, 0.9893, 0.989 , 0.988 , 0.9873, 0.987 , 0.9863, 0.986 ,\n",
       "            0.9854, 0.985 , 0.9844, 0.984 , 0.9834, 0.983 , 0.9824, 0.982 ,\n",
       "            0.9814, 0.981 , 0.9805, 0.98  , 0.979 , 0.9785, 0.977 , 0.9766,\n",
       "            0.976 , 0.9756, 0.975 , 0.974 , 0.9736, 0.973 , 0.9727, 0.972 ,\n",
       "            0.9717, 0.971 , 0.9707, 0.97  , 0.9697, 0.969 , 0.9683, 0.968 ,\n",
       "            0.9673, 0.967 , 0.9663, 0.9653, 0.965 , 0.964 , 0.9634, 0.962 ,\n",
       "            0.9595, 0.957 , 0.9556, 0.954 , 0.9536, 0.953 , 0.9526, 0.952 ,\n",
       "            0.951 , 0.9507, 0.948 , 0.947 , 0.9424, 0.941 , 0.9404, 0.9395,\n",
       "            0.9375, 0.936 , 0.929 , 0.9277, 0.927 , 0.9253, 0.925 , 0.923 ,\n",
       "            0.916 , 0.913 , 0.9126, 0.912 , 0.9106, 0.9067, 0.89  , 0.879 ,\n",
       "            0.878 , 0.8726, 0.8706, 0.865 , 0.826 , 0.8105, 0.807 , 0.8057,\n",
       "            0.795 , 0.7915, 0.7817, 0.77  , 0.766 , 0.752 , 0.7275, 0.7183,\n",
       "            0.6973, 0.695 , 0.6914, 0.688 , 0.6836, 0.6816, 0.681 , 0.675 ,\n",
       "            0.6733, 0.673 , 0.6704, 0.6675, 0.6587, 0.6436, 0.637 , 0.6216,\n",
       "            0.5845, 0.578 , 0.57  , 0.5625, 0.5576, 0.5537, 0.5483, 0.5347,\n",
       "            0.5273, 0.527 , 0.5215, 0.512 , 0.506 , 0.501 , 0.4993, 0.4968,\n",
       "            0.4954, 0.495 , 0.4944, 0.469 , 0.465 , 0.438 , 0.423 , 0.4128,\n",
       "            0.4028, 0.3887, 0.3875, 0.3647, 0.3606, 0.3538, 0.3455, 0.3367,\n",
       "            0.3174, 0.3145, 0.2827], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.880597, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.03731343, 0.05223881, 0.05970149,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.08955224,\n",
       "            0.09701493, 0.11940298, 0.11940298, 0.11940298, 0.13432837,\n",
       "            0.13432837, 0.14925373, 0.14925373, 0.14925373, 0.1641791 ,\n",
       "            0.17910448, 0.17910448, 0.18656716, 0.20149253, 0.21641791,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26865673, 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.31343284, 0.3283582 , 0.3283582 , 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.05172414,\n",
       "            0.06896552, 0.0775862 , 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.1724138 , 0.18103448, 0.19827586, 0.22413793, 0.25      ,\n",
       "            0.27586207, 0.29310346, 0.30172414, 0.31896552, 0.3448276 ,\n",
       "            0.35344827, 0.4051724 , 0.41379312, 0.43965518, 0.43965518,\n",
       "            0.44827586, 0.46551725, 0.4827586 , 0.49137932, 0.5258621 ,\n",
       "            0.55172414, 0.5603448 , 0.5862069 , 0.5862069 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.63793105, 0.6465517 , 0.6637931 ,\n",
       "            0.6810345 , 0.6810345 , 0.70689654, 0.7155172 , 0.73275864,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9985, 0.998 , 0.9976, 0.997 , 0.9966, 0.996 , 0.9956,\n",
       "            0.995 , 0.9946, 0.994 , 0.9937, 0.993 , 0.9927, 0.992 , 0.9917,\n",
       "            0.991 , 0.9907, 0.99  , 0.9897, 0.9893, 0.989 , 0.9883, 0.988 ,\n",
       "            0.9873, 0.987 , 0.9863, 0.986 , 0.9854, 0.985 , 0.9844, 0.984 ,\n",
       "            0.9834, 0.983 , 0.9814, 0.981 , 0.9805, 0.98  , 0.979 , 0.9785,\n",
       "            0.978 , 0.9775, 0.977 , 0.976 , 0.9756, 0.975 , 0.974 , 0.9736,\n",
       "            0.973 , 0.9727, 0.972 , 0.971 , 0.9707, 0.97  , 0.9697, 0.9688,\n",
       "            0.9683, 0.9663, 0.9644, 0.9634, 0.962 , 0.9614, 0.961 , 0.9604,\n",
       "            0.96  , 0.9595, 0.959 , 0.958 , 0.9565, 0.9556, 0.9507, 0.95  ,\n",
       "            0.9497, 0.9487, 0.9473, 0.946 , 0.939 , 0.9385, 0.936 , 0.9355,\n",
       "            0.9346, 0.933 , 0.927 , 0.9243, 0.924 , 0.923 , 0.9224, 0.9175,\n",
       "            0.902 , 0.8926, 0.8906, 0.8867, 0.8813, 0.8794, 0.841 , 0.8267,\n",
       "            0.8223, 0.82  , 0.8105, 0.8066, 0.7964, 0.783 , 0.781 , 0.7666,\n",
       "            0.743 , 0.7344, 0.7124, 0.7095, 0.7065, 0.7026, 0.698 , 0.697 ,\n",
       "            0.6963, 0.695 , 0.69  , 0.688 , 0.687 , 0.6855, 0.6826, 0.673 ,\n",
       "            0.657 , 0.65  , 0.636 , 0.5947, 0.591 , 0.581 , 0.5747, 0.5693,\n",
       "            0.565 , 0.559 , 0.5454, 0.538 , 0.5376, 0.5366, 0.5312, 0.5215,\n",
       "            0.515 , 0.5103, 0.5083, 0.5063, 0.5044, 0.504 , 0.5034, 0.4768,\n",
       "            0.473 , 0.445 , 0.4294, 0.419 , 0.4084, 0.394 , 0.3926, 0.369 ,\n",
       "            0.3647, 0.3577, 0.349 , 0.3398, 0.3203, 0.3176, 0.2847],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.880597, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.05223881, 0.05970149, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.1119403 , 0.11940298, 0.11940298, 0.13432837,\n",
       "            0.13432837, 0.14925373, 0.14925373, 0.1641791 , 0.1641791 ,\n",
       "            0.17910448, 0.18656716, 0.20149253, 0.20149253, 0.21641791,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.26865673, 0.2835821 , 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.3283582 ,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.03448276, 0.06896552,\n",
       "            0.0775862 , 0.12068965, 0.12931034, 0.15517241, 0.18103448,\n",
       "            0.20689656, 0.2413793 , 0.27586207, 0.29310346, 0.30172414,\n",
       "            0.3448276 , 0.3448276 , 0.4051724 , 0.41379312, 0.43103448,\n",
       "            0.44827586, 0.46551725, 0.4827586 , 0.5086207 , 0.5258621 ,\n",
       "            0.5603448 , 0.5689655 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.67241377,\n",
       "            0.67241377, 0.6896552 , 0.69827586, 0.70689654, 0.7241379 ,\n",
       "            0.75      , 0.76724136, 0.7758621 , 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8189655 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.999 , 0.9985, 0.998 , 0.9976, 0.997 , 0.9966, 0.996 ,\n",
       "            0.9956, 0.995 , 0.9946, 0.994 , 0.9937, 0.993 , 0.9927, 0.992 ,\n",
       "            0.9917, 0.991 , 0.9907, 0.99  , 0.9897, 0.9893, 0.989 , 0.9883,\n",
       "            0.988 , 0.9873, 0.987 , 0.9863, 0.9854, 0.985 , 0.9844, 0.984 ,\n",
       "            0.9834, 0.983 , 0.9824, 0.982 , 0.9814, 0.981 , 0.9805, 0.98  ,\n",
       "            0.9795, 0.979 , 0.978 , 0.9775, 0.9766, 0.976 , 0.9756, 0.975 ,\n",
       "            0.9746, 0.974 , 0.972 , 0.9707, 0.9697, 0.9683, 0.968 , 0.9673,\n",
       "            0.967 , 0.966 , 0.9653, 0.965 , 0.9634, 0.963 , 0.9585, 0.958 ,\n",
       "            0.9575, 0.9565, 0.9556, 0.9536, 0.9478, 0.9473, 0.9453, 0.9443,\n",
       "            0.942 , 0.9365, 0.9346, 0.9336, 0.9326, 0.932 , 0.927 , 0.9126,\n",
       "            0.9053, 0.9023, 0.8994, 0.892 , 0.8916, 0.854 , 0.842 , 0.8374,\n",
       "            0.8325, 0.8247, 0.8213, 0.81  , 0.796 , 0.795 , 0.781 , 0.7583,\n",
       "            0.7495, 0.7266, 0.7236, 0.7217, 0.7163, 0.712 , 0.7104, 0.7085,\n",
       "            0.7046, 0.7017, 0.7007, 0.7   , 0.6973, 0.686 , 0.6704, 0.6626,\n",
       "            0.6494, 0.6064, 0.6035, 0.593 , 0.5874, 0.5806, 0.576 , 0.5703,\n",
       "            0.5557, 0.5483, 0.547 , 0.5415, 0.5317, 0.5244, 0.5195, 0.518 ,\n",
       "            0.515 , 0.5137, 0.513 , 0.512 , 0.4854, 0.4812, 0.4524, 0.4365,\n",
       "            0.4255, 0.4148, 0.4   , 0.3984, 0.374 , 0.3699, 0.3628, 0.3535,\n",
       "            0.3445, 0.3242, 0.3218, 0.2883], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.880597, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00746269, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.05223881, 0.05970149, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.13432837, 0.14925373, 0.14925373, 0.1641791 , 0.17910448,\n",
       "            0.18656716, 0.20149253, 0.20149253, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.24626866, 0.25373134, 0.2761194 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3955224 , 0.3955224 ,\n",
       "            0.3955224 , 0.3955224 , 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.43283582, 0.4402985 , 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01724138, 0.04310345, 0.06896552, 0.11206897,\n",
       "            0.12931034, 0.1637931 , 0.19827586, 0.23275863, 0.2672414 ,\n",
       "            0.28448275, 0.3448276 , 0.35344827, 0.39655173, 0.4224138 ,\n",
       "            0.43103448, 0.46551725, 0.4827586 , 0.5       , 0.5344828 ,\n",
       "            0.5689655 , 0.5689655 , 0.5862069 , 0.5948276 , 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.6551724 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.69827586, 0.7241379 , 0.7413793 , 0.7586207 ,\n",
       "            0.76724136, 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.82758623, 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8448276 , 0.86206895, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.999 , 0.9985, 0.998 , 0.9976, 0.997 , 0.9966, 0.996 ,\n",
       "            0.9956, 0.995 , 0.9946, 0.994 , 0.9937, 0.993 , 0.9927, 0.992 ,\n",
       "            0.9917, 0.991 , 0.9907, 0.99  , 0.9897, 0.9893, 0.989 , 0.9883,\n",
       "            0.988 , 0.9873, 0.987 , 0.9863, 0.986 , 0.9854, 0.985 , 0.9844,\n",
       "            0.984 , 0.9834, 0.983 , 0.9824, 0.982 , 0.9814, 0.981 , 0.9805,\n",
       "            0.98  , 0.9785, 0.978 , 0.977 , 0.9756, 0.975 , 0.9736, 0.973 ,\n",
       "            0.972 , 0.9717, 0.9707, 0.97  , 0.9697, 0.969 , 0.9683, 0.9653,\n",
       "            0.965 , 0.9644, 0.964 , 0.9624, 0.961 , 0.955 , 0.953 , 0.9526,\n",
       "            0.95  , 0.9487, 0.9453, 0.9434, 0.9424, 0.9414, 0.936 , 0.9224,\n",
       "            0.917 , 0.9136, 0.9116, 0.9043, 0.9014, 0.8677, 0.856 , 0.8516,\n",
       "            0.8447, 0.839 , 0.8354, 0.8237, 0.8086, 0.7954, 0.7725, 0.764 ,\n",
       "            0.74  , 0.7373, 0.737 , 0.7305, 0.7256, 0.724 , 0.7236, 0.7217,\n",
       "            0.7188, 0.7153, 0.7144, 0.714 , 0.7114, 0.6997, 0.6836, 0.675 ,\n",
       "            0.6626, 0.617 , 0.6157, 0.603 , 0.5986, 0.591 , 0.5864, 0.5806,\n",
       "            0.5654, 0.5586, 0.558 , 0.556 , 0.5503, 0.54  , 0.5327, 0.527 ,\n",
       "            0.526 , 0.523 , 0.522 , 0.5215, 0.52  , 0.492 , 0.488 , 0.458 ,\n",
       "            0.442 , 0.4302, 0.419 , 0.4033, 0.4019, 0.3765, 0.3723, 0.365 ,\n",
       "            0.3552, 0.3462, 0.3252, 0.3223, 0.2886], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8880597, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00746269, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.05970149, 0.07462686, 0.07462686,\n",
       "            0.09701493, 0.11940298, 0.12686567, 0.13432837, 0.14925373,\n",
       "            0.15671642, 0.17910448, 0.17910448, 0.20149253, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.26119402, 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.29850745, 0.29850745, 0.31343284,\n",
       "            0.31343284, 0.3283582 , 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.03448276, 0.06896552, 0.12068965,\n",
       "            0.14655173, 0.18965517, 0.2413793 , 0.2672414 , 0.30172414,\n",
       "            0.3448276 , 0.39655173, 0.4224138 , 0.43103448, 0.47413793,\n",
       "            0.4827586 , 0.51724136, 0.5689655 , 0.57758623, 0.5948276 ,\n",
       "            0.62068963, 0.62068963, 0.6465517 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.69827586, 0.7413793 , 0.7586207 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.82758623,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9995, 0.999 , 0.9985, 0.998 , 0.9976, 0.997 , 0.9966,\n",
       "            0.996 , 0.9956, 0.995 , 0.9946, 0.994 , 0.9937, 0.993 , 0.9927,\n",
       "            0.992 , 0.9917, 0.991 , 0.99  , 0.9897, 0.9893, 0.989 , 0.9883,\n",
       "            0.988 , 0.9873, 0.987 , 0.9863, 0.986 , 0.985 , 0.9844, 0.984 ,\n",
       "            0.9834, 0.983 , 0.982 , 0.9814, 0.981 , 0.9805, 0.979 , 0.9785,\n",
       "            0.9775, 0.9766, 0.976 , 0.9756, 0.9746, 0.974 , 0.9736, 0.973 ,\n",
       "            0.9727, 0.9697, 0.969 , 0.9688, 0.9683, 0.9673, 0.966 , 0.9614,\n",
       "            0.9604, 0.959 , 0.958 , 0.956 , 0.955 , 0.952 , 0.9497, 0.948 ,\n",
       "            0.9434, 0.931 , 0.925 , 0.9224, 0.9194, 0.913 , 0.911 , 0.879 ,\n",
       "            0.8667, 0.8623, 0.8574, 0.851 , 0.847 , 0.8364, 0.8228, 0.822 ,\n",
       "            0.8086, 0.7847, 0.7773, 0.7534, 0.751 , 0.75  , 0.7446, 0.7397,\n",
       "            0.739 , 0.738 , 0.7314, 0.7285, 0.7275, 0.7266, 0.7236, 0.7144,\n",
       "            0.6973, 0.6914, 0.675 , 0.634 , 0.6274, 0.616 , 0.61  , 0.603 ,\n",
       "            0.5986, 0.5923, 0.5757, 0.5737, 0.572 , 0.569 , 0.5625, 0.5522,\n",
       "            0.545 , 0.537 , 0.5366, 0.535 , 0.5327, 0.5293, 0.503 , 0.4988,\n",
       "            0.4675, 0.4543, 0.44  , 0.4302, 0.4119, 0.4104, 0.3843, 0.3818,\n",
       "            0.3745, 0.3628, 0.355 , 0.3318, 0.3289, 0.2966], dtype=float16)}}]],\n",
       " 'roc_results': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.00333333,\n",
       "         0.00333333, 0.00666667, 0.00666667, 0.01      , 0.01      ,\n",
       "         0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,\n",
       "         0.01333333, 0.01666667, 0.02      , 0.02666667, 0.04      ,\n",
       "         0.04666667, 0.05333333, 0.06333333, 0.06666667, 0.07      ,\n",
       "         0.07333333, 0.08666667, 0.09666666, 0.10333333, 0.10333333,\n",
       "         0.10333333, 0.11      , 0.12333333, 0.13333334, 0.13333334,\n",
       "         0.15      , 0.16666667, 0.18666667, 0.19      , 0.19666667,\n",
       "         0.21      , 0.22666667, 0.24      , 0.25666666, 0.26666668,\n",
       "         0.28333333, 0.29333332, 0.30666667, 0.32      , 0.34      ,\n",
       "         0.35      , 0.36      , 0.36666667, 0.37      , 0.38333333,\n",
       "         0.40333334, 0.41333333, 0.41666666, 0.42333335, 0.43333334,\n",
       "         0.44333333, 0.44666666, 0.45666668, 0.46      , 0.46333334,\n",
       "         0.47      , 0.48      , 0.48666668, 0.49      , 0.49      ,\n",
       "         0.49666667, 0.50333333, 0.52      , 0.52666664, 0.53      ,\n",
       "         0.53333336, 0.54      , 0.54333335, 0.55      , 0.55333334,\n",
       "         0.56333333, 0.56333333, 0.57      , 0.5833333 , 0.5933333 ,\n",
       "         0.5966667 , 0.5966667 , 0.61      , 0.61333334, 0.62      ,\n",
       "         0.62666667, 0.6333333 , 0.6333333 , 0.6333333 , 0.63666666,\n",
       "         0.64      , 0.64      , 0.6433333 , 0.65      , 0.6533333 ,\n",
       "         0.6533333 , 0.6566667 , 0.66      , 0.66333336, 0.6666667 ,\n",
       "         0.67333335, 0.6766667 , 0.6766667 , 0.68      , 0.6933333 ,\n",
       "         0.69666666, 0.7       , 0.7033333 , 0.70666665, 0.71      ,\n",
       "         0.7133333 , 0.7133333 , 0.7133333 , 0.72      , 0.72333336,\n",
       "         0.7266667 , 0.7266667 , 0.73      , 0.73      , 0.74      ,\n",
       "         0.74      , 0.74333334, 0.74333334, 0.75      , 0.75333333,\n",
       "         0.75666666, 0.76      , 0.76666665, 0.77      , 0.77      ,\n",
       "         0.77      , 0.7733333 , 0.77666664, 0.78      , 0.78333336,\n",
       "         0.78333336, 0.79      , 0.79333335, 0.7966667 , 0.8       ,\n",
       "         0.81      , 0.82      , 0.82      , 0.82      , 0.82      ,\n",
       "         0.82      , 0.82      , 0.8233333 , 0.82666665, 0.82666665,\n",
       "         0.82666665, 0.83      , 0.83      , 0.83      , 0.8333333 ,\n",
       "         0.83666664, 0.83666664, 0.84      , 0.84      , 0.8433333 ,\n",
       "         0.8433333 , 0.8433333 , 0.8466667 , 0.85      , 0.85      ,\n",
       "         0.85      , 0.85333335, 0.85333335, 0.86      , 0.86333334,\n",
       "         0.86333334, 0.87      , 0.87666667, 0.88      , 0.8833333 ,\n",
       "         0.89      , 0.89      , 0.89      , 0.8933333 , 0.8933333 ,\n",
       "         0.8933333 , 0.8933333 , 0.89666665, 0.89666665, 0.89666665,\n",
       "         0.9       , 0.9033333 , 0.9066667 , 0.9066667 , 0.9066667 ,\n",
       "         0.9066667 , 0.91      , 0.91333336, 0.91333336, 0.9166667 ,\n",
       "         0.9166667 , 0.9166667 , 0.92      , 0.92333335, 0.9266667 ,\n",
       "         0.93      , 0.93333334, 0.93666667, 0.9433333 , 0.94666666,\n",
       "         0.95      , 0.9533333 , 0.9533333 , 0.9533333 , 0.95666665,\n",
       "         0.96      , 0.96      , 0.96      , 0.9633333 , 0.9633333 ,\n",
       "         0.9633333 , 0.96666664, 0.96666664, 0.97      , 0.97333336,\n",
       "         0.97333336, 0.98      , 0.98      , 0.98333335, 0.9866667 ,\n",
       "         0.9866667 , 0.9866667 , 0.9866667 , 0.99      , 0.99333334,\n",
       "         0.99333334, 0.99333334, 0.99333334, 0.99333334, 0.99666667,\n",
       "         0.99666667, 0.99666667, 1.        , 1.        , 1.        ],\n",
       "        dtype=float32),\n",
       "  'tpr': array([0.        , 0.00333333, 0.00666667, 0.01      , 0.02      ,\n",
       "         0.03      , 0.05333333, 0.07333333, 0.07666667, 0.08      ,\n",
       "         0.1       , 0.11333334, 0.12666667, 0.13      , 0.14      ,\n",
       "         0.15      , 0.16      , 0.16666667, 0.17333333, 0.18666667,\n",
       "         0.19      , 0.19333333, 0.20333333, 0.21333334, 0.23333333,\n",
       "         0.23333333, 0.23666666, 0.24666667, 0.25333333, 0.26333332,\n",
       "         0.27333334, 0.28333333, 0.28666666, 0.29333332, 0.3       ,\n",
       "         0.30333334, 0.31333333, 0.31666666, 0.32      , 0.33      ,\n",
       "         0.33333334, 0.34666666, 0.34666666, 0.35333332, 0.36666667,\n",
       "         0.37      , 0.38      , 0.39      , 0.39      , 0.4       ,\n",
       "         0.40666667, 0.41666666, 0.42666668, 0.43333334, 0.43666667,\n",
       "         0.43666667, 0.44333333, 0.45      , 0.45      , 0.46      ,\n",
       "         0.47666666, 0.47666666, 0.48333332, 0.48333332, 0.48666668,\n",
       "         0.48666668, 0.49333334, 0.50666666, 0.51666665, 0.53      ,\n",
       "         0.54333335, 0.55      , 0.55      , 0.5566667 , 0.56666666,\n",
       "         0.56666666, 0.56666666, 0.5733333 , 0.57666665, 0.58666664,\n",
       "         0.5966667 , 0.5966667 , 0.5966667 , 0.60333335, 0.61      ,\n",
       "         0.61333334, 0.62      , 0.62      , 0.62333333, 0.62333333,\n",
       "         0.63      , 0.63      , 0.63666666, 0.63666666, 0.6433333 ,\n",
       "         0.65      , 0.6533333 , 0.6566667 , 0.66      , 0.66333336,\n",
       "         0.6666667 , 0.67333335, 0.6766667 , 0.68      , 0.68666667,\n",
       "         0.68666667, 0.68666667, 0.69      , 0.69666666, 0.69666666,\n",
       "         0.69666666, 0.7       , 0.7       , 0.7       , 0.7033333 ,\n",
       "         0.71      , 0.71666664, 0.71666664, 0.71666664, 0.71666664,\n",
       "         0.72      , 0.72      , 0.73      , 0.73333335, 0.73333335,\n",
       "         0.73333335, 0.73333335, 0.73333335, 0.73333335, 0.7366667 ,\n",
       "         0.74333334, 0.74666667, 0.75      , 0.75      , 0.75      ,\n",
       "         0.75      , 0.75333333, 0.75666666, 0.76      , 0.76      ,\n",
       "         0.7633333 , 0.77      , 0.7733333 , 0.77666664, 0.77666664,\n",
       "         0.78      , 0.78333336, 0.78333336, 0.78333336, 0.7866667 ,\n",
       "         0.79      , 0.79333335, 0.79333335, 0.79333335, 0.79333335,\n",
       "         0.7966667 , 0.7966667 , 0.7966667 , 0.7966667 , 0.7966667 ,\n",
       "         0.7966667 , 0.7966667 , 0.8       , 0.80333334, 0.8066667 ,\n",
       "         0.81      , 0.81333333, 0.81666666, 0.81666666, 0.8233333 ,\n",
       "         0.82666665, 0.83      , 0.8333333 , 0.83666664, 0.83666664,\n",
       "         0.83666664, 0.84      , 0.84      , 0.8433333 , 0.8433333 ,\n",
       "         0.8466667 , 0.85      , 0.85      , 0.85      , 0.85333335,\n",
       "         0.8566667 , 0.86      , 0.86333334, 0.8666667 , 0.8666667 ,\n",
       "         0.87      , 0.87666667, 0.87666667, 0.87666667, 0.87666667,\n",
       "         0.87666667, 0.88      , 0.8833333 , 0.8833333 , 0.88666666,\n",
       "         0.89      , 0.8933333 , 0.8933333 , 0.89666665, 0.9       ,\n",
       "         0.9       , 0.9       , 0.9       , 0.9033333 , 0.9066667 ,\n",
       "         0.91      , 0.91      , 0.91      , 0.91333336, 0.91333336,\n",
       "         0.9166667 , 0.92      , 0.92      , 0.92      , 0.92      ,\n",
       "         0.92      , 0.92      , 0.92      , 0.92      , 0.92333335,\n",
       "         0.92333335, 0.9266667 , 0.93      , 0.93333334, 0.93333334,\n",
       "         0.93666667, 0.94      , 0.9433333 , 0.94666666, 0.95      ,\n",
       "         0.9533333 , 0.9533333 , 0.95666665, 0.95666665, 0.95666665,\n",
       "         0.96      , 0.96      , 0.9633333 , 0.9633333 , 0.9633333 ,\n",
       "         0.96666664, 0.97      , 0.97333336, 0.97333336, 0.97333336,\n",
       "         0.9766667 , 0.98      , 0.98333335, 0.9866667 , 0.9866667 ,\n",
       "         0.99      , 0.99333334, 0.99333334, 0.99666667, 1.        ],\n",
       "        dtype=float32),\n",
       "  'thresholds': array([1.    , 0.5356, 0.535 , 0.5347, 0.534 , 0.5337, 0.533 , 0.5327,\n",
       "         0.532 , 0.5317, 0.5312, 0.531 , 0.5303, 0.53  , 0.5293, 0.529 ,\n",
       "         0.5283, 0.528 , 0.5273, 0.527 , 0.5264, 0.5254, 0.525 , 0.5244,\n",
       "         0.524 , 0.5234, 0.523 , 0.5225, 0.522 , 0.5215, 0.521 , 0.5205,\n",
       "         0.52  , 0.5195, 0.519 , 0.5186, 0.518 , 0.5176, 0.517 , 0.516 ,\n",
       "         0.5156, 0.515 , 0.5146, 0.5137, 0.513 , 0.5127, 0.512 , 0.5117,\n",
       "         0.511 , 0.5107, 0.5103, 0.51  , 0.5093, 0.509 , 0.5083, 0.508 ,\n",
       "         0.5073, 0.507 , 0.5063, 0.506 , 0.5054, 0.505 , 0.5044, 0.504 ,\n",
       "         0.5034, 0.503 , 0.5024, 0.502 , 0.5015, 0.501 , 0.5005, 0.5   ,\n",
       "         0.4998, 0.4995, 0.4993, 0.499 , 0.4988, 0.4985, 0.4983, 0.498 ,\n",
       "         0.4978, 0.4976, 0.4973, 0.497 , 0.4968, 0.4966, 0.4963, 0.4958,\n",
       "         0.4956, 0.4954, 0.495 , 0.4949, 0.4946, 0.4944, 0.4941, 0.4937,\n",
       "         0.4934, 0.4932, 0.493 , 0.4927, 0.4924, 0.4922, 0.492 , 0.4917,\n",
       "         0.4912, 0.491 , 0.4907, 0.4902, 0.49  , 0.4897, 0.4895, 0.489 ,\n",
       "         0.4885, 0.4883, 0.4868, 0.4863, 0.486 , 0.4856, 0.485 , 0.4849,\n",
       "         0.4844, 0.4841, 0.484 , 0.483 , 0.4827, 0.4822, 0.482 , 0.4812,\n",
       "         0.481 , 0.4807, 0.4805, 0.4802, 0.48  , 0.4797, 0.4795, 0.4792,\n",
       "         0.479 , 0.4788, 0.4783, 0.4778, 0.477 , 0.4768, 0.4766, 0.476 ,\n",
       "         0.4749, 0.4744, 0.474 , 0.4739, 0.4736, 0.4727, 0.4724, 0.472 ,\n",
       "         0.471 , 0.4707, 0.4697, 0.469 , 0.4688, 0.4685, 0.4683, 0.4678,\n",
       "         0.4675, 0.4673, 0.467 , 0.4668, 0.4663, 0.466 , 0.4653, 0.464 ,\n",
       "         0.4639, 0.4634, 0.4631, 0.463 , 0.4626, 0.4624, 0.462 , 0.4617,\n",
       "         0.4614, 0.4612, 0.4602, 0.46  , 0.4597, 0.4595, 0.4592, 0.4587,\n",
       "         0.4583, 0.458 , 0.4575, 0.457 , 0.4568, 0.4563, 0.4558, 0.4553,\n",
       "         0.455 , 0.4548, 0.454 , 0.4521, 0.452 , 0.4512, 0.4504, 0.4502,\n",
       "         0.4495, 0.4482, 0.4475, 0.4473, 0.4463, 0.4453, 0.4448, 0.4436,\n",
       "         0.4426, 0.4424, 0.4412, 0.441 , 0.4407, 0.4402, 0.44  , 0.438 ,\n",
       "         0.4373, 0.4355, 0.435 , 0.4348, 0.4346, 0.434 , 0.4324, 0.432 ,\n",
       "         0.431 , 0.43  , 0.4297, 0.4294, 0.429 , 0.4282, 0.4277, 0.4275,\n",
       "         0.4268, 0.426 , 0.4253, 0.425 , 0.424 , 0.4236, 0.4229, 0.4214,\n",
       "         0.4211, 0.421 , 0.4194, 0.418 , 0.4177, 0.4172, 0.4167, 0.415 ,\n",
       "         0.4138, 0.4136, 0.4128, 0.4106, 0.4094, 0.4082, 0.4053, 0.405 ,\n",
       "         0.4043, 0.3977, 0.3958, 0.381 ], dtype=float16),\n",
       "  'name': 'Original NN data1',\n",
       "  'auc': array(0.6139444, dtype=float32),\n",
       "  'model': LitClassifier(\n",
       "    (model): SimpleClassifier(\n",
       "      (layer_stack): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): BCEWithLogitsLoss()\n",
       "    (train_accuracy): BinaryAccuracy()\n",
       "    (test_accuracy): BinaryAccuracy()\n",
       "    (test_auc): BinaryAUROC()\n",
       "  )},\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x768ad2f304a0>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Save the data\n",
    "save_to_pickle(list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader, filename='pickle/NN_data2_undersampling.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd7c930",
   "metadata": {},
   "source": [
    "# Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0b5b02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Load the data\n",
    "list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader = load_from_pickle(filename='pickle/NN_data2_undersampling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5d9c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275941a6",
   "metadata": {},
   "source": [
    "### Ensemble prediction using voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "586c430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Ensemble ROC Curve by iterating through FPR values ---\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0000\n",
      "Soft Voting -> Achieved [TPR: 0.2600, FPR: 0.0000]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0204\n",
      "Soft Voting -> Achieved [TPR: 0.4833, FPR: 0.0200]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0408\n",
      "Soft Voting -> Achieved [TPR: 0.4933, FPR: 0.0400]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0612\n",
      "Soft Voting -> Achieved [TPR: 0.5133, FPR: 0.0567]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0816\n",
      "Soft Voting -> Achieved [TPR: 0.5233, FPR: 0.0733]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1020\n",
      "Soft Voting -> Achieved [TPR: 0.5633, FPR: 0.0900]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1224\n",
      "Soft Voting -> Achieved [TPR: 0.5900, FPR: 0.1200]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1429\n",
      "Soft Voting -> Achieved [TPR: 0.6100, FPR: 0.1300]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1633\n",
      "Soft Voting -> Achieved [TPR: 0.6500, FPR: 0.1567]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1837\n",
      "Soft Voting -> Achieved [TPR: 0.6700, FPR: 0.1767]\n",
      "Hard Voting -> Resulted in [TPR: 0.6233, FPR: 0.1833]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2041\n",
      "Soft Voting -> Achieved [TPR: 0.6767, FPR: 0.2000]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2245\n",
      "Soft Voting -> Achieved [TPR: 0.7033, FPR: 0.2133]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2449\n",
      "Soft Voting -> Achieved [TPR: 0.7167, FPR: 0.2367]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2653\n",
      "Soft Voting -> Achieved [TPR: 0.7467, FPR: 0.2633]\n",
      "Hard Voting -> Resulted in [TPR: 0.7433, FPR: 0.2567]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2857\n",
      "Soft Voting -> Achieved [TPR: 0.7733, FPR: 0.2767]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3061\n",
      "Soft Voting -> Achieved [TPR: 0.8000, FPR: 0.3033]\n",
      "Hard Voting -> Resulted in [TPR: 0.7633, FPR: 0.2767]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3265\n",
      "Soft Voting -> Achieved [TPR: 0.8133, FPR: 0.3167]\n",
      "Hard Voting -> Resulted in [TPR: 0.7967, FPR: 0.3167]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3469\n",
      "Soft Voting -> Achieved [TPR: 0.8367, FPR: 0.3467]\n",
      "Hard Voting -> Resulted in [TPR: 0.7933, FPR: 0.2900]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3673\n",
      "Soft Voting -> Achieved [TPR: 0.8433, FPR: 0.3600]\n",
      "Hard Voting -> Resulted in [TPR: 0.8400, FPR: 0.3567]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3878\n",
      "Soft Voting -> Achieved [TPR: 0.8633, FPR: 0.3867]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4082\n",
      "Soft Voting -> Achieved [TPR: 0.8733, FPR: 0.4067]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4286\n",
      "Soft Voting -> Achieved [TPR: 0.8800, FPR: 0.4200]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4490\n",
      "Soft Voting -> Achieved [TPR: 0.8933, FPR: 0.4400]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4694\n",
      "Soft Voting -> Achieved [TPR: 0.9167, FPR: 0.4600]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4898\n",
      "Soft Voting -> Achieved [TPR: 0.9333, FPR: 0.4867]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5102\n",
      "Soft Voting -> Achieved [TPR: 0.9400, FPR: 0.4933]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5306\n",
      "Soft Voting -> Achieved [TPR: 0.9600, FPR: 0.5300]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5510\n",
      "Soft Voting -> Achieved [TPR: 0.9733, FPR: 0.5467]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5714\n",
      "Soft Voting -> Achieved [TPR: 0.9900, FPR: 0.5700]\n",
      "Hard Voting -> Resulted in [TPR: 0.9833, FPR: 0.5600]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5918\n",
      "Soft Voting -> Achieved [TPR: 0.9933, FPR: 0.5733]\n",
      "Hard Voting -> Resulted in [TPR: 0.9867, FPR: 0.5633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6122\n",
      "Soft Voting -> Achieved [TPR: 0.9933, FPR: 0.5733]\n",
      "Hard Voting -> Resulted in [TPR: 0.9867, FPR: 0.5633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6327\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6233]\n",
      "Hard Voting -> Resulted in [TPR: 0.9867, FPR: 0.5633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6531\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6233]\n",
      "Hard Voting -> Resulted in [TPR: 0.9867, FPR: 0.5633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6735\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6233]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.6633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6939\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6233]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.6633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.7143\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6233]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.6633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.7347\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6233]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.6633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.7551\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6433]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.6633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.7755\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6433]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.6633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.7959\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6567]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.6667]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.8163\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.6900]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "\n",
      "--- Filtering curves to be monotonic ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Loop through all the FPR values to generate the ensemble ROC curve ---\n",
    "\n",
    "ensemble_results_soft = []\n",
    "ensemble_results_hard = []\n",
    "\n",
    "print(\"\\n--- Generating Ensemble ROC Curve by iterating through FPR values ---\")\n",
    "# We iterate from a low to high target_fpr to trace the curve\n",
    "for target_fpr in np.linspace(0.0, 1.0, 50): \n",
    "    # 1. Assign the function's output to a single variable first.\n",
    "    result_tuple = predict_ensemble_and_evaluate(\n",
    "        list_folds_best_models=list_folds_best_models,\n",
    "        test_loader=test_loader,\n",
    "        target_fpr=target_fpr\n",
    "    )\n",
    "    \n",
    "    if result_tuple is not None:\n",
    "        \n",
    "        for voting_method, metrics in result_tuple.items():\n",
    "            # Create a dictionary for each point and append it to the list\n",
    "            if voting_method == 'soft_voting':\n",
    "                point_dict = {'fpr': metrics['fpr'], 'tpr': metrics['tpr']}\n",
    "                ensemble_results_soft.append(point_dict)\n",
    "            else:\n",
    "                point_dict = {'fpr': metrics['fpr'], 'tpr': metrics['tpr']}\n",
    "                ensemble_results_hard.append(point_dict)\n",
    "            \n",
    "        \n",
    "# Ensure the curve starts at (0, 0)\n",
    "    if not ensemble_results_soft or ensemble_results_soft[0]['fpr'] > 0.0:\n",
    "        ensemble_results_soft.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if ensemble_results_soft[-1]['fpr'] < 1.0 or ensemble_results_soft[-1]['tpr'] < 1.0:\n",
    "        ensemble_results_soft.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    if not ensemble_results_hard or ensemble_results_hard[0]['fpr'] > 0.0:\n",
    "        ensemble_results_hard.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if ensemble_results_hard[-1]['fpr'] < 1.0 or ensemble_results_hard[-1]['tpr'] < 1.0:\n",
    "        ensemble_results_hard.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    # --- NEW: Post-process the lists to make them monotonic ---\n",
    "print(\"\\n--- Filtering curves to be monotonic ---\")\n",
    "ensemble_results_soft = make_curve_monotonic(ensemble_results_soft)\n",
    "ensemble_results_hard = make_curve_monotonic(ensemble_results_hard)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bae1a225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Plotting all ROC curves for comparison ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "results_lists.append(ensemble_results_soft)\n",
    "results_lists.append(ensemble_results_hard)\n",
    "\n",
    "\n",
    "# --- Plot the final comparison ---\n",
    "print(\"\\n--- Plotting all ROC curves for comparison ---\")\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\", \"Ensemble_voting_soft\", \"Ensemble_voting_hard\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54a198",
   "metadata": {},
   "source": [
    "## Check performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ba0e7",
   "metadata": {},
   "source": [
    "## Check performance on test1 and test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f504bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_performance_tester(classifier_list, test_loader):\n",
    "\n",
    "    list_weighted_clfs = []  # Reset the list for final testing\n",
    "    for i, model_info in enumerate(classifier_list):\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "\n",
    "        model = model_info[\"model\"]\n",
    "        raw_threshold = model_info[\"threshold\"]\n",
    "\n",
    "\n",
    "        # CORRECTED: Use isinstance() to check if model is a string\n",
    "        if isinstance(model, str):\n",
    "            print(f\"Skipping model {i+1} as it is a string placeholder: '{model}'\")\n",
    "            continue\n",
    "\n",
    "        # Check if the stored threshold is a NumPy number or a PyTorch Tensor\n",
    "        if isinstance(raw_threshold, (np.number, torch.Tensor)):\n",
    "            # If it is, we can safely call .item() to extract the Python float\n",
    "            threshold = raw_threshold.item()\n",
    "        else:\n",
    "            # Otherwise, it's already a float or something that can be cast to one\n",
    "            threshold = float(raw_threshold)\n",
    "        model.current_test_threshold = threshold  # Set the threshold for this model\n",
    "\n",
    "        # This code will now only run if 'model' is a PyTorch Lightning module\n",
    "        # and not a string.\n",
    "        print(f\"--- Testing model {i+1} ---\")\n",
    "\n",
    "        trainer.test(model, dataloaders=test_loader, ckpt_path=None)\n",
    "        \n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "\n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not list_weighted_clfs or list_weighted_clfs[0]['fpr'] > 0.0:\n",
    "        list_weighted_clfs.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if list_weighted_clfs[-1]['fpr'] < 1.0 or list_weighted_clfs[-1]['tpr'] < 1.0:\n",
    "        list_weighted_clfs.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return list_weighted_clfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLlabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
